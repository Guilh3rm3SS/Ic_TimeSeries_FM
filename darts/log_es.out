/media/work/guisouza/Ic_TimeSeries_FM/darts/darts_forecast.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  full_df = pd.read_csv(url, index_col=0, parse_dates=True)
/media/work/guisouza/Ic_TimeSeries_FM/darts/darts_forecast.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df['dt'] = pd.to_datetime(df['dt'], format='%d/%m/%Y %H:%M')
[I 2025-08-18 01:29:38,549] A new study created in memory with name: no-name-2b168f8a-f1bd-4075-ae81-dd6498cce9dd
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Context length: 7, Horizon length: 1
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 481.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 343.68it/s][I 2025-08-18 01:29:48,276] Trial 0 finished with value: 19.371860008820935 and parameters: {'hidden_dim': 54, 'n_rnn_layers': 3, 'dropout': 0.17826454269659014}. Best is trial 0 with value: 19.371860008820935.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 430.58it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.35it/s][I 2025-08-18 01:29:54,702] Trial 1 finished with value: 15.873649155286346 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 2, 'dropout': 0.26054498650678204}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 370.46it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.14it/s][I 2025-08-18 01:30:01,316] Trial 2 finished with value: 18.199600341336645 and parameters: {'hidden_dim': 27, 'n_rnn_layers': 3, 'dropout': 0.4209486353613262}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.47368188111524434 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 572.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 251.31it/s][I 2025-08-18 01:30:07,317] Trial 3 finished with value: 17.534051381969995 and parameters: {'hidden_dim': 90, 'n_rnn_layers': 1, 'dropout': 0.47368188111524434}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 449.21it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 312.08it/s][I 2025-08-18 01:30:16,029] Trial 4 finished with value: 17.644557682110772 and parameters: {'hidden_dim': 115, 'n_rnn_layers': 2, 'dropout': 0.3285631514737713}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 446.20it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 320.27it/s][I 2025-08-18 01:30:23,919] Trial 5 finished with value: 19.733689723900728 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 2, 'dropout': 0.12262736393099599}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 405.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 230.66it/s][I 2025-08-18 01:30:33,696] Trial 6 finished with value: 19.314443992142788 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 2, 'dropout': 0.0803105816750807}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 535.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 315.10it/s][I 2025-08-18 01:30:43,366] Trial 7 finished with value: 21.404091746202692 and parameters: {'hidden_dim': 68, 'n_rnn_layers': 4, 'dropout': 0.2949622546446663}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 436.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.14it/s][I 2025-08-18 01:30:51,448] Trial 8 finished with value: 19.42389280928862 and parameters: {'hidden_dim': 32, 'n_rnn_layers': 4, 'dropout': 0.342195472428251}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 389.55it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.55it/s][I 2025-08-18 01:30:59,313] Trial 9 finished with value: 23.585269979187427 and parameters: {'hidden_dim': 71, 'n_rnn_layers': 4, 'dropout': 0.0027886072877800205}. Best is trial 1 with value: 15.873649155286346.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20872003311745702 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 431.11it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 355.69it/s][I 2025-08-18 01:31:04,451] Trial 10 finished with value: 11.944257011300635 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.20872003311745702}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2155380793612838 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 533.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 379.75it/s][I 2025-08-18 01:31:09,415] Trial 11 finished with value: 16.84135048456761 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.2155380793612838}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25066578512574816 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.27it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.07it/s][I 2025-08-18 01:31:14,433] Trial 12 finished with value: 16.84135048456761 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.25066578512574816}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15838388269068082 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 427.99it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 297.24it/s][I 2025-08-18 01:31:19,947] Trial 13 finished with value: 15.76585933504413 and parameters: {'hidden_dim': 35, 'n_rnn_layers': 1, 'dropout': 0.15838388269068082}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13866710028544854 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 572.52it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.33it/s][I 2025-08-18 01:31:25,056] Trial 14 finished with value: 15.349141605671871 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 1, 'dropout': 0.13866710028544854}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.04975502731910697 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 481.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.58it/s][I 2025-08-18 01:31:30,269] Trial 15 finished with value: 15.383214452961349 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 1, 'dropout': 0.04975502731910697}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1290846556087505 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 462.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 323.86it/s][I 2025-08-18 01:31:35,492] Trial 16 finished with value: 18.635197192930033 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 1, 'dropout': 0.1290846556087505}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 519.10it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 352.67it/s][I 2025-08-18 01:31:41,933] Trial 17 finished with value: 22.002683884519943 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 3, 'dropout': 0.20129011876356015}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 459.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 284.17it/s][I 2025-08-18 01:31:47,790] Trial 18 finished with value: 15.985137420222413 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 2, 'dropout': 0.07864314315184141}. Best is trial 10 with value: 11.944257011300635.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3433855488729994 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 448.35it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.20it/s][I 2025-08-18 01:31:53,095] Trial 19 finished with value: 18.93937401959981 and parameters: {'hidden_dim': 18, 'n_rnn_layers': 1, 'dropout': 0.3433855488729994}. Best is trial 10 with value: 11.944257011300635.
[I 2025-08-18 01:31:53,096] A new study created in memory with name: no-name-00112a07-8167-4ca7-a1f6-2044677d957c
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.20872003311745702}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 576.62it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 363.62it/s][I 2025-08-18 01:32:03,042] Trial 0 finished with value: 21.58116509337246 and parameters: {'hidden_dim': 83, 'n_rnn_layers': 2, 'dropout': 0.2413237903850587}. Best is trial 0 with value: 21.58116509337246.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 497.43it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 349.88it/s][I 2025-08-18 01:32:10,146] Trial 1 finished with value: 21.73738486549955 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 3, 'dropout': 0.043634446492714696}. Best is trial 0 with value: 21.58116509337246.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 426.25it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.72it/s][I 2025-08-18 01:32:19,187] Trial 2 finished with value: 16.243875282244343 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 4, 'dropout': 0.25766769686572955}. Best is trial 2 with value: 16.243875282244343.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 391.63it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.88it/s][I 2025-08-18 01:32:28,057] Trial 3 finished with value: 21.070339192787834 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 4, 'dropout': 0.3480179405231468}. Best is trial 2 with value: 16.243875282244343.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 337.38it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.47it/s][I 2025-08-18 01:32:37,332] Trial 4 finished with value: 19.206579793601712 and parameters: {'hidden_dim': 51, 'n_rnn_layers': 4, 'dropout': 0.2813916884986003}. Best is trial 2 with value: 16.243875282244343.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4746655512726602 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 538.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 360.77it/s][I 2025-08-18 01:32:42,454] Trial 5 finished with value: 15.647160788481436 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 1, 'dropout': 0.4746655512726602}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 435.09it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.21it/s][I 2025-08-18 01:32:58,467] Trial 6 finished with value: 23.500251121806155 and parameters: {'hidden_dim': 116, 'n_rnn_layers': 3, 'dropout': 0.3104835467746541}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 399.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.85it/s][I 2025-08-18 01:33:05,912] Trial 7 finished with value: 20.238697623050196 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 4, 'dropout': 0.07162924253612063}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 612.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 316.86it/s][I 2025-08-18 01:33:12,029] Trial 8 finished with value: 21.46615977271728 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 3, 'dropout': 0.37458102535377086}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 495.20it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.70it/s][I 2025-08-18 01:33:26,748] Trial 9 finished with value: 18.703712825166203 and parameters: {'hidden_dim': 127, 'n_rnn_layers': 2, 'dropout': 0.4199835881161653}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4995267987231794 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 488.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 340.61it/s][I 2025-08-18 01:33:31,874] Trial 10 finished with value: 16.84135048456761 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.4995267987231794}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1822024646080248 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 407.45it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.77it/s][I 2025-08-18 01:33:36,850] Trial 11 finished with value: 16.84135048456761 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.1822024646080248}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 538.42it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 346.29it/s][I 2025-08-18 01:33:42,476] Trial 12 finished with value: 18.007031528953583 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 2, 'dropout': 0.16319660478575007}. Best is trial 5 with value: 15.647160788481436.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4933011526720108 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 554.51it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 358.21it/s][I 2025-08-18 01:33:47,774] Trial 13 finished with value: 12.919808467375969 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 1, 'dropout': 0.4933011526720108}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4933860120790992 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 478.64it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.22it/s][I 2025-08-18 01:33:53,175] Trial 14 finished with value: 19.251011362900247 and parameters: {'hidden_dim': 33, 'n_rnn_layers': 1, 'dropout': 0.4933860120790992}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4171874435937655 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 599.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.73it/s][I 2025-08-18 01:33:58,501] Trial 15 finished with value: 19.826996095082194 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 1, 'dropout': 0.4171874435937655}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 488.62it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.72it/s][I 2025-08-18 01:34:05,232] Trial 16 finished with value: 19.79869816582849 and parameters: {'hidden_dim': 45, 'n_rnn_layers': 2, 'dropout': 0.44041788867501247}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4566491434540569 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 494.73it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 341.78it/s][I 2025-08-18 01:34:10,534] Trial 17 finished with value: 12.919808467375969 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 1, 'dropout': 0.4566491434540569}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37814691293465397 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 720.18it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 356.29it/s][I 2025-08-18 01:34:15,832] Trial 18 finished with value: 19.8936718389555 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 1, 'dropout': 0.37814691293465397}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 508.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.86it/s][I 2025-08-18 01:34:24,974] Trial 19 finished with value: 15.516269232757141 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 2, 'dropout': 0.4454308061146778}. Best is trial 13 with value: 12.919808467375969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4933011526720108 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 3.7 K  | train
6 | V               | Linear           | 30     | train
-------------------------------------------------------------
3.7 K     Trainable params
0         Non-trainable params
3.7 K     Total params
0.015     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 29, 'n_rnn_layers': 1, 'dropout': 0.4933011526720108}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 336.57it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 368.86it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] Epoch 0:   3%|▎         | 1/29 [00:00<00:00, 115.69it/s]Epoch 0:   3%|▎         | 1/29 [00:00<00:00, 91.94it/s, train_loss=0.0514]Epoch 0:   7%|▋         | 2/29 [00:00<00:00, 133.94it/s, train_loss=0.0514]Epoch 0:   7%|▋         | 2/29 [00:00<00:00, 119.48it/s, train_loss=0.102] Epoch 0:  10%|█         | 3/29 [00:00<00:00, 147.77it/s, train_loss=0.102]Epoch 0:  10%|█         | 3/29 [00:00<00:00, 135.17it/s, train_loss=0.0465]Epoch 0:  14%|█▍        | 4/29 [00:00<00:00, 154.68it/s, train_loss=0.0465]Epoch 0:  14%|█▍        | 4/29 [00:00<00:00, 142.81it/s, train_loss=0.0643]Epoch 0:  17%|█▋        | 5/29 [00:00<00:00, 157.74it/s, train_loss=0.0643]Epoch 0:  17%|█▋        | 5/29 [00:00<00:00, 150.49it/s, train_loss=0.126] Epoch 0:  21%|██        | 6/29 [00:00<00:00, 162.55it/s, train_loss=0.126]Epoch 0:  21%|██        | 6/29 [00:00<00:00, 153.74it/s, train_loss=0.0638]Epoch 0:  24%|██▍       | 7/29 [00:00<00:00, 163.68it/s, train_loss=0.0638]Epoch 0:  24%|██▍       | 7/29 [00:00<00:00, 158.46it/s, train_loss=0.0879]Epoch 0:  28%|██▊       | 8/29 [00:00<00:00, 166.89it/s, train_loss=0.0879]Epoch 0:  28%|██▊       | 8/29 [00:00<00:00, 160.08it/s, train_loss=0.0709]Epoch 0:  31%|███       | 9/29 [00:00<00:00, 167.39it/s, train_loss=0.0709]Epoch 0:  31%|███       | 9/29 [00:00<00:00, 162.79it/s, train_loss=0.0634]Epoch 0:  34%|███▍      | 10/29 [00:00<00:00, 169.32it/s, train_loss=0.0634]Epoch 0:  34%|███▍      | 10/29 [00:00<00:00, 163.72it/s, train_loss=0.0874]Epoch 0:  38%|███▊      | 11/29 [00:00<00:00, 169.28it/s, train_loss=0.0874]Epoch 0:  38%|███▊      | 11/29 [00:00<00:00, 166.16it/s, train_loss=0.0711]Epoch 0:  41%|████▏     | 12/29 [00:00<00:00, 171.29it/s, train_loss=0.0711]Epoch 0:  41%|████▏     | 12/29 [00:00<00:00, 166.69it/s, train_loss=0.0662]Epoch 0:  45%|████▍     | 13/29 [00:00<00:00, 171.33it/s, train_loss=0.0662]Epoch 0:  45%|████▍     | 13/29 [00:00<00:00, 168.07it/s, train_loss=0.0661]Epoch 0:  48%|████▊     | 14/29 [00:00<00:00, 172.33it/s, train_loss=0.0661]Epoch 0:  48%|████▊     | 14/29 [00:00<00:00, 168.46it/s, train_loss=0.105] Epoch 0:  52%|█████▏    | 15/29 [00:00<00:00, 172.40it/s, train_loss=0.105]Epoch 0:  52%|█████▏    | 15/29 [00:00<00:00, 169.94it/s, train_loss=0.0864]Epoch 0:  55%|█████▌    | 16/29 [00:00<00:00, 173.59it/s, train_loss=0.0864]Epoch 0:  55%|█████▌    | 16/29 [00:00<00:00, 170.17it/s, train_loss=0.0713]Epoch 0:  59%|█████▊    | 17/29 [00:00<00:00, 173.56it/s, train_loss=0.0713]Epoch 0:  59%|█████▊    | 17/29 [00:00<00:00, 171.37it/s, train_loss=0.0919]Epoch 0:  62%|██████▏   | 18/29 [00:00<00:00, 174.59it/s, train_loss=0.0919]Epoch 0:  62%|██████▏   | 18/29 [00:00<00:00, 171.50it/s, train_loss=0.085] Epoch 0:  66%|██████▌   | 19/29 [00:00<00:00, 174.41it/s, train_loss=0.085]Epoch 0:  66%|██████▌   | 19/29 [00:00<00:00, 172.12it/s, train_loss=0.060]Epoch 0:  69%|██████▉   | 20/29 [00:00<00:00, 174.91it/s, train_loss=0.060]Epoch 0:  69%|██████▉   | 20/29 [00:00<00:00, 172.21it/s, train_loss=0.0459]Epoch 0:  72%|███████▏  | 21/29 [00:00<00:00, 174.83it/s, train_loss=0.0459]Epoch 0:  72%|███████▏  | 21/29 [00:00<00:00, 172.76it/s, train_loss=0.0752]Epoch 0:  76%|███████▌  | 22/29 [00:00<00:00, 175.06it/s, train_loss=0.0752]Epoch 0:  76%|███████▌  | 22/29 [00:00<00:00, 172.82it/s, train_loss=0.0578]Epoch 0:  79%|███████▉  | 23/29 [00:00<00:00, 175.07it/s, train_loss=0.0578]Epoch 0:  79%|███████▉  | 23/29 [00:00<00:00, 173.18it/s, train_loss=0.086] Epoch 0:  83%|████████▎ | 24/29 [00:00<00:00, 175.29it/s, train_loss=0.086]Epoch 0:  83%|████████▎ | 24/29 [00:00<00:00, 173.16it/s, train_loss=0.0716]Epoch 0:  86%|████████▌ | 25/29 [00:00<00:00, 175.15it/s, train_loss=0.0716]Epoch 0:  86%|████████▌ | 25/29 [00:00<00:00, 173.69it/s, train_loss=0.0777]Epoch 0:  90%|████████▉ | 26/29 [00:00<00:00, 175.57it/s, train_loss=0.0777]Epoch 0:  90%|████████▉ | 26/29 [00:00<00:00, 173.66it/s, train_loss=0.0536]Epoch 0:  93%|█████████▎| 27/29 [00:00<00:00, 175.94it/s, train_loss=0.0536]Epoch 0:  93%|█████████▎| 27/29 [00:00<00:00, 174.24it/s, train_loss=0.0529]Epoch 0:  97%|█████████▋| 28/29 [00:00<00:00, 176.46it/s, train_loss=0.0529]Epoch 0:  97%|█████████▋| 28/29 [00:00<00:00, 174.20it/s, train_loss=0.0526]Epoch 0: 100%|██████████| 29/29 [00:00<00:00, 176.32it/s, train_loss=0.0526]Epoch 0: 100%|██████████| 29/29 [00:00<00:00, 174.72it/s, train_loss=0.0428]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 246.43it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 277.81it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 289.86it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 296.44it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 299.30it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 300.81it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 302.60it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 303.73it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 304.51it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 303.99it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 303.61it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 303.67it/s][A
                                                                         [AEpoch 0: 100%|██████████| 29/29 [00:00<00:00, 136.55it/s, train_loss=0.0428, val_loss=0.0765]Epoch 0: 100%|██████████| 29/29 [00:00<00:00, 135.99it/s, train_loss=0.0428, val_loss=0.0765]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0428, val_loss=0.0765]          Epoch 1:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0428, val_loss=0.0765]Epoch 1:   3%|▎         | 1/29 [00:00<00:00, 190.81it/s, train_loss=0.0428, val_loss=0.0765]Epoch 1:   3%|▎         | 1/29 [00:00<00:00, 157.96it/s, train_loss=0.103, val_loss=0.0765] Epoch 1:   7%|▋         | 2/29 [00:00<00:00, 193.24it/s, train_loss=0.103, val_loss=0.0765]Epoch 1:   7%|▋         | 2/29 [00:00<00:00, 177.98it/s, train_loss=0.0639, val_loss=0.0765]Epoch 1:  10%|█         | 3/29 [00:00<00:00, 196.54it/s, train_loss=0.0639, val_loss=0.0765]Epoch 1:  10%|█         | 3/29 [00:00<00:00, 175.98it/s, train_loss=0.0684, val_loss=0.0765]Epoch 1:  14%|█▍        | 4/29 [00:00<00:00, 190.25it/s, train_loss=0.0684, val_loss=0.0765]Epoch 1:  14%|█▍        | 4/29 [00:00<00:00, 180.64it/s, train_loss=0.0388, val_loss=0.0765]Epoch 1:  17%|█▋        | 5/29 [00:00<00:00, 190.38it/s, train_loss=0.0388, val_loss=0.0765]Epoch 1:  17%|█▋        | 5/29 [00:00<00:00, 178.85it/s, train_loss=0.0583, val_loss=0.0765]Epoch 1:  21%|██        | 6/29 [00:00<00:00, 187.44it/s, train_loss=0.0583, val_loss=0.0765]Epoch 1:  21%|██        | 6/29 [00:00<00:00, 181.97it/s, train_loss=0.0849, val_loss=0.0765]Epoch 1:  24%|██▍       | 7/29 [00:00<00:00, 188.23it/s, train_loss=0.0849, val_loss=0.0765]Epoch 1:  24%|██▍       | 7/29 [00:00<00:00, 180.53it/s, train_loss=0.0306, val_loss=0.0765]Epoch 1:  28%|██▊       | 8/29 [00:00<00:00, 186.55it/s, train_loss=0.0306, val_loss=0.0765]Epoch 1:  28%|██▊       | 8/29 [00:00<00:00, 182.67it/s, train_loss=0.0471, val_loss=0.0765]Epoch 1:  31%|███       | 9/29 [00:00<00:00, 187.63it/s, train_loss=0.0471, val_loss=0.0765]Epoch 1:  31%|███       | 9/29 [00:00<00:00, 181.87it/s, train_loss=0.0635, val_loss=0.0765]Epoch 1:  34%|███▍      | 10/29 [00:00<00:00, 188.06it/s, train_loss=0.0635, val_loss=0.0765]Epoch 1:  34%|███▍      | 10/29 [00:00<00:00, 183.89it/s, train_loss=0.0299, val_loss=0.0765]Epoch 1:  38%|███▊      | 11/29 [00:00<00:00, 189.42it/s, train_loss=0.0299, val_loss=0.0765]Epoch 1:  38%|███▊      | 11/29 [00:00<00:00, 182.82it/s, train_loss=0.100, val_loss=0.0765] Epoch 1:  41%|████▏     | 12/29 [00:00<00:00, 187.80it/s, train_loss=0.100, val_loss=0.0765]Epoch 1:  41%|████▏     | 12/29 [00:00<00:00, 184.46it/s, train_loss=0.0457, val_loss=0.0765]Epoch 1:  45%|████▍     | 13/29 [00:00<00:00, 188.81it/s, train_loss=0.0457, val_loss=0.0765]Epoch 1:  45%|████▍     | 13/29 [00:00<00:00, 183.53it/s, train_loss=0.0444, val_loss=0.0765]Epoch 1:  48%|████▊     | 14/29 [00:00<00:00, 187.70it/s, train_loss=0.0444, val_loss=0.0765]Epoch 1:  48%|████▊     | 14/29 [00:00<00:00, 185.12it/s, train_loss=0.0437, val_loss=0.0765]Epoch 1:  52%|█████▏    | 15/29 [00:00<00:00, 188.71it/s, train_loss=0.0437, val_loss=0.0765]Epoch 1:  52%|█████▏    | 15/29 [00:00<00:00, 184.26it/s, train_loss=0.0322, val_loss=0.0765]Epoch 1:  55%|█████▌    | 16/29 [00:00<00:00, 187.59it/s, train_loss=0.0322, val_loss=0.0765]Epoch 1:  55%|█████▌    | 16/29 [00:00<00:00, 185.50it/s, train_loss=0.0969, val_loss=0.0765]Epoch 1:  59%|█████▊    | 17/29 [00:00<00:00, 188.42it/s, train_loss=0.0969, val_loss=0.0765]Epoch 1:  59%|█████▊    | 17/29 [00:00<00:00, 184.76it/s, train_loss=0.0311, val_loss=0.0765]Epoch 1:  62%|██████▏   | 18/29 [00:00<00:00, 187.74it/s, train_loss=0.0311, val_loss=0.0765]Epoch 1:  62%|██████▏   | 18/29 [00:00<00:00, 186.07it/s, train_loss=0.0491, val_loss=0.0765]Epoch 1:  66%|██████▌   | 19/29 [00:00<00:00, 188.82it/s, train_loss=0.0491, val_loss=0.0765]Epoch 1:  66%|██████▌   | 19/29 [00:00<00:00, 185.33it/s, train_loss=0.0511, val_loss=0.0765]Epoch 1:  69%|██████▉   | 20/29 [00:00<00:00, 187.99it/s, train_loss=0.0511, val_loss=0.0765]Epoch 1:  69%|██████▉   | 20/29 [00:00<00:00, 186.31it/s, train_loss=0.0464, val_loss=0.0765]Epoch 1:  72%|███████▏  | 21/29 [00:00<00:00, 188.71it/s, train_loss=0.0464, val_loss=0.0765]Epoch 1:  72%|███████▏  | 21/29 [00:00<00:00, 185.64it/s, train_loss=0.0771, val_loss=0.0765]Epoch 1:  76%|███████▌  | 22/29 [00:00<00:00, 188.01it/s, train_loss=0.0771, val_loss=0.0765]Epoch 1:  76%|███████▌  | 22/29 [00:00<00:00, 186.52it/s, train_loss=0.0197, val_loss=0.0765]Epoch 1:  79%|███████▉  | 23/29 [00:00<00:00, 188.64it/s, train_loss=0.0197, val_loss=0.0765]Epoch 1:  79%|███████▉  | 23/29 [00:00<00:00, 185.88it/s, train_loss=0.0318, val_loss=0.0765]Epoch 1:  83%|████████▎ | 24/29 [00:00<00:00, 187.98it/s, train_loss=0.0318, val_loss=0.0765]Epoch 1:  83%|████████▎ | 24/29 [00:00<00:00, 186.68it/s, train_loss=0.0241, val_loss=0.0765]Epoch 1:  86%|████████▌ | 25/29 [00:00<00:00, 188.37it/s, train_loss=0.0241, val_loss=0.0765]Epoch 1:  86%|████████▌ | 25/29 [00:00<00:00, 186.08it/s, train_loss=0.0416, val_loss=0.0765]Epoch 1:  90%|████████▉ | 26/29 [00:00<00:00, 187.89it/s, train_loss=0.0416, val_loss=0.0765]Epoch 1:  90%|████████▉ | 26/29 [00:00<00:00, 186.78it/s, train_loss=0.0394, val_loss=0.0765]Epoch 1:  93%|█████████▎| 27/29 [00:00<00:00, 188.41it/s, train_loss=0.0394, val_loss=0.0765]Epoch 1:  93%|█████████▎| 27/29 [00:00<00:00, 186.23it/s, train_loss=0.0496, val_loss=0.0765]Epoch 1:  97%|█████████▋| 28/29 [00:00<00:00, 187.88it/s, train_loss=0.0496, val_loss=0.0765]Epoch 1:  97%|█████████▋| 28/29 [00:00<00:00, 186.78it/s, train_loss=0.0268, val_loss=0.0765]Epoch 1: 100%|██████████| 29/29 [00:00<00:00, 188.95it/s, train_loss=0.0268, val_loss=0.0765]Epoch 1: 100%|██████████| 29/29 [00:00<00:00, 186.37it/s, train_loss=0.0127, val_loss=0.0765]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 282.29it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 314.39it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 324.55it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 327.78it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 328.60it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 330.42it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 329.39it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 328.07it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 326.87it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 325.19it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 323.29it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 321.75it/s][A
                                                                         [AEpoch 1: 100%|██████████| 29/29 [00:00<00:00, 145.93it/s, train_loss=0.0127, val_loss=0.0443]Epoch 1: 100%|██████████| 29/29 [00:00<00:00, 145.33it/s, train_loss=0.0127, val_loss=0.0443]Epoch 1:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0127, val_loss=0.0443]          Epoch 2:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0127, val_loss=0.0443]Epoch 2:   3%|▎         | 1/29 [00:00<00:00, 185.61it/s, train_loss=0.0127, val_loss=0.0443]Epoch 2:   3%|▎         | 1/29 [00:00<00:00, 157.62it/s, train_loss=0.0225, val_loss=0.0443]Epoch 2:   7%|▋         | 2/29 [00:00<00:00, 191.66it/s, train_loss=0.0225, val_loss=0.0443]Epoch 2:   7%|▋         | 2/29 [00:00<00:00, 178.64it/s, train_loss=0.0334, val_loss=0.0443]Epoch 2:  10%|█         | 3/29 [00:00<00:00, 197.29it/s, train_loss=0.0334, val_loss=0.0443]Epoch 2:  10%|█         | 3/29 [00:00<00:00, 176.59it/s, train_loss=0.0399, val_loss=0.0443]Epoch 2:  14%|█▍        | 4/29 [00:00<00:00, 190.81it/s, train_loss=0.0399, val_loss=0.0443]Epoch 2:  14%|█▍        | 4/29 [00:00<00:00, 182.69it/s, train_loss=0.0492, val_loss=0.0443]Epoch 2:  17%|█▋        | 5/29 [00:00<00:00, 193.38it/s, train_loss=0.0492, val_loss=0.0443]Epoch 2:  17%|█▋        | 5/29 [00:00<00:00, 180.68it/s, train_loss=0.041, val_loss=0.0443] Epoch 2:  21%|██        | 6/29 [00:00<00:00, 189.52it/s, train_loss=0.041, val_loss=0.0443]Epoch 2:  21%|██        | 6/29 [00:00<00:00, 184.44it/s, train_loss=0.032, val_loss=0.0443]Epoch 2:  24%|██▍       | 7/29 [00:00<00:00, 190.95it/s, train_loss=0.032, val_loss=0.0443]Epoch 2:  24%|██▍       | 7/29 [00:00<00:00, 182.66it/s, train_loss=0.0386, val_loss=0.0443]Epoch 2:  28%|██▊       | 8/29 [00:00<00:00, 188.67it/s, train_loss=0.0386, val_loss=0.0443]Epoch 2:  28%|██▊       | 8/29 [00:00<00:00, 184.99it/s, train_loss=0.0368, val_loss=0.0443]Epoch 2:  31%|███       | 9/29 [00:00<00:00, 189.54it/s, train_loss=0.0368, val_loss=0.0443]Epoch 2:  31%|███       | 9/29 [00:00<00:00, 183.39it/s, train_loss=0.0303, val_loss=0.0443]Epoch 2:  34%|███▍      | 10/29 [00:00<00:00, 187.93it/s, train_loss=0.0303, val_loss=0.0443]Epoch 2:  34%|███▍      | 10/29 [00:00<00:00, 184.98it/s, train_loss=0.0164, val_loss=0.0443]Epoch 2:  38%|███▊      | 11/29 [00:00<00:00, 189.09it/s, train_loss=0.0164, val_loss=0.0443]Epoch 2:  38%|███▊      | 11/29 [00:00<00:00, 184.45it/s, train_loss=0.0187, val_loss=0.0443]Epoch 2:  41%|████▏     | 12/29 [00:00<00:00, 189.48it/s, train_loss=0.0187, val_loss=0.0443]Epoch 2:  41%|████▏     | 12/29 [00:00<00:00, 186.03it/s, train_loss=0.0179, val_loss=0.0443]Epoch 2:  45%|████▍     | 13/29 [00:00<00:00, 190.09it/s, train_loss=0.0179, val_loss=0.0443]Epoch 2:  45%|████▍     | 13/29 [00:00<00:00, 184.92it/s, train_loss=0.0351, val_loss=0.0443]Epoch 2:  48%|████▊     | 14/29 [00:00<00:00, 189.15it/s, train_loss=0.0351, val_loss=0.0443]Epoch 2:  48%|████▊     | 14/29 [00:00<00:00, 186.20it/s, train_loss=0.0166, val_loss=0.0443]Epoch 2:  52%|█████▏    | 15/29 [00:00<00:00, 189.86it/s, train_loss=0.0166, val_loss=0.0443]Epoch 2:  52%|█████▏    | 15/29 [00:00<00:00, 185.27it/s, train_loss=0.0154, val_loss=0.0443]Epoch 2:  55%|█████▌    | 16/29 [00:00<00:00, 188.65it/s, train_loss=0.0154, val_loss=0.0443]Epoch 2:  55%|█████▌    | 16/29 [00:00<00:00, 186.49it/s, train_loss=0.0332, val_loss=0.0443]Epoch 2:  59%|█████▊    | 17/29 [00:00<00:00, 189.44it/s, train_loss=0.0332, val_loss=0.0443]Epoch 2:  59%|█████▊    | 17/29 [00:00<00:00, 185.67it/s, train_loss=0.0231, val_loss=0.0443]Epoch 2:  62%|██████▏   | 18/29 [00:00<00:00, 188.65it/s, train_loss=0.0231, val_loss=0.0443]Epoch 2:  62%|██████▏   | 18/29 [00:00<00:00, 186.72it/s, train_loss=0.0395, val_loss=0.0443]Epoch 2:  66%|██████▌   | 19/29 [00:00<00:00, 189.41it/s, train_loss=0.0395, val_loss=0.0443]Epoch 2:  66%|██████▌   | 19/29 [00:00<00:00, 185.93it/s, train_loss=0.0234, val_loss=0.0443]Epoch 2:  69%|██████▉   | 20/29 [00:00<00:00, 188.44it/s, train_loss=0.0234, val_loss=0.0443]Epoch 2:  69%|██████▉   | 20/29 [00:00<00:00, 186.89it/s, train_loss=0.0131, val_loss=0.0443]Epoch 2:  72%|███████▏  | 21/29 [00:00<00:00, 188.92it/s, train_loss=0.0131, val_loss=0.0443]Epoch 2:  72%|███████▏  | 21/29 [00:00<00:00, 186.18it/s, train_loss=0.021, val_loss=0.0443] Epoch 2:  76%|███████▌  | 22/29 [00:00<00:00, 188.01it/s, train_loss=0.021, val_loss=0.0443]Epoch 2:  76%|███████▌  | 22/29 [00:00<00:00, 186.80it/s, train_loss=0.0143, val_loss=0.0443]Epoch 2:  79%|███████▉  | 23/29 [00:00<00:00, 188.88it/s, train_loss=0.0143, val_loss=0.0443]Epoch 2:  79%|███████▉  | 23/29 [00:00<00:00, 186.43it/s, train_loss=0.0152, val_loss=0.0443]Epoch 2:  83%|████████▎ | 24/29 [00:00<00:00, 188.45it/s, train_loss=0.0152, val_loss=0.0443]Epoch 2:  83%|████████▎ | 24/29 [00:00<00:00, 187.32it/s, train_loss=0.0389, val_loss=0.0443]Epoch 2:  86%|████████▌ | 25/29 [00:00<00:00, 189.17it/s, train_loss=0.0389, val_loss=0.0443]Epoch 2:  86%|████████▌ | 25/29 [00:00<00:00, 186.76it/s, train_loss=0.0209, val_loss=0.0443]Epoch 2:  90%|████████▉ | 26/29 [00:00<00:00, 188.55it/s, train_loss=0.0209, val_loss=0.0443]Epoch 2:  90%|████████▉ | 26/29 [00:00<00:00, 187.48it/s, train_loss=0.0316, val_loss=0.0443]Epoch 2:  93%|█████████▎| 27/29 [00:00<00:00, 189.14it/s, train_loss=0.0316, val_loss=0.0443]Epoch 2:  93%|█████████▎| 27/29 [00:00<00:00, 186.90it/s, train_loss=0.0195, val_loss=0.0443]Epoch 2:  97%|█████████▋| 28/29 [00:00<00:00, 188.53it/s, train_loss=0.0195, val_loss=0.0443]Epoch 2:  97%|█████████▋| 28/29 [00:00<00:00, 187.48it/s, train_loss=0.0216, val_loss=0.0443]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 29/29 [00:00<00:00, 186.86it/s, train_loss=0.0216, val_loss=0.0443]Epoch 2: 100%|██████████| 29/29 [00:00<00:00, 186.26it/s, train_loss=0.0131, val_loss=0.0443]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 254.80it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 288.44it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 302.69it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 308.47it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 311.61it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 312.68it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 312.46it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 312.39it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 312.27it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 311.32it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 309.77it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 308.89it/s][A
                                                                         [AEpoch 2: 100%|██████████| 29/29 [00:00<00:00, 144.62it/s, train_loss=0.0131, val_loss=0.0309]Epoch 2: 100%|██████████| 29/29 [00:00<00:00, 144.04it/s, train_loss=0.0131, val_loss=0.0309]Epoch 2:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0131, val_loss=0.0309]          Epoch 3:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0131, val_loss=0.0309]Epoch 3:   3%|▎         | 1/29 [00:00<00:00, 197.54it/s, train_loss=0.0131, val_loss=0.0309]Epoch 3:   3%|▎         | 1/29 [00:00<00:00, 160.09it/s, train_loss=0.0289, val_loss=0.0309]Epoch 3:   7%|▋         | 2/29 [00:00<00:00, 195.98it/s, train_loss=0.0289, val_loss=0.0309]Epoch 3:   7%|▋         | 2/29 [00:00<00:00, 181.22it/s, train_loss=0.024, val_loss=0.0309] Epoch 3:  10%|█         | 3/29 [00:00<00:00, 200.16it/s, train_loss=0.024, val_loss=0.0309]Epoch 3:  10%|█         | 3/29 [00:00<00:00, 178.14it/s, train_loss=0.0493, val_loss=0.0309]Epoch 3:  14%|█▍        | 4/29 [00:00<00:00, 192.54it/s, train_loss=0.0493, val_loss=0.0309]Epoch 3:  14%|█▍        | 4/29 [00:00<00:00, 183.57it/s, train_loss=0.032, val_loss=0.0309] Epoch 3:  17%|█▋        | 5/29 [00:00<00:00, 193.30it/s, train_loss=0.032, val_loss=0.0309]Epoch 3:  17%|█▋        | 5/29 [00:00<00:00, 181.15it/s, train_loss=0.0304, val_loss=0.0309]Epoch 3:  21%|██        | 6/29 [00:00<00:00, 189.79it/s, train_loss=0.0304, val_loss=0.0309]Epoch 3:  21%|██        | 6/29 [00:00<00:00, 183.97it/s, train_loss=0.0174, val_loss=0.0309]Epoch 3:  24%|██▍       | 7/29 [00:00<00:00, 190.05it/s, train_loss=0.0174, val_loss=0.0309]Epoch 3:  24%|██▍       | 7/29 [00:00<00:00, 182.23it/s, train_loss=0.0144, val_loss=0.0309]Epoch 3:  28%|██▊       | 8/29 [00:00<00:00, 188.01it/s, train_loss=0.0144, val_loss=0.0309]Epoch 3:  28%|██▊       | 8/29 [00:00<00:00, 184.47it/s, train_loss=0.0129, val_loss=0.0309]Epoch 3:  31%|███       | 9/29 [00:00<00:00, 189.28it/s, train_loss=0.0129, val_loss=0.0309]Epoch 3:  31%|███       | 9/29 [00:00<00:00, 183.31it/s, train_loss=0.0255, val_loss=0.0309]Epoch 3:  34%|███▍      | 10/29 [00:00<00:00, 187.68it/s, train_loss=0.0255, val_loss=0.0309]Epoch 3:  34%|███▍      | 10/29 [00:00<00:00, 184.44it/s, train_loss=0.020, val_loss=0.0309] Epoch 3:  38%|███▊      | 11/29 [00:00<00:00, 189.52it/s, train_loss=0.020, val_loss=0.0309]Epoch 3:  38%|███▊      | 11/29 [00:00<00:00, 184.18it/s, train_loss=0.0282, val_loss=0.0309]Epoch 3:  41%|████▏     | 12/29 [00:00<00:00, 188.88it/s, train_loss=0.0282, val_loss=0.0309]Epoch 3:  41%|████▏     | 12/29 [00:00<00:00, 185.85it/s, train_loss=0.027, val_loss=0.0309] Epoch 3:  45%|████▍     | 13/29 [00:00<00:00, 189.71it/s, train_loss=0.027, val_loss=0.0309]Epoch 3:  45%|████▍     | 13/29 [00:00<00:00, 184.78it/s, train_loss=0.0117, val_loss=0.0309]Epoch 3:  48%|████▊     | 14/29 [00:00<00:00, 188.40it/s, train_loss=0.0117, val_loss=0.0309]Epoch 3:  48%|████▊     | 14/29 [00:00<00:00, 186.13it/s, train_loss=0.0224, val_loss=0.0309]Epoch 3:  52%|█████▏    | 15/29 [00:00<00:00, 189.62it/s, train_loss=0.0224, val_loss=0.0309]Epoch 3:  52%|█████▏    | 15/29 [00:00<00:00, 185.09it/s, train_loss=0.0123, val_loss=0.0309]Epoch 3:  55%|█████▌    | 16/29 [00:00<00:00, 188.53it/s, train_loss=0.0123, val_loss=0.0309]Epoch 3:  55%|█████▌    | 16/29 [00:00<00:00, 186.25it/s, train_loss=0.00992, val_loss=0.0309]Epoch 3:  59%|█████▊    | 17/29 [00:00<00:00, 189.43it/s, train_loss=0.00992, val_loss=0.0309]Epoch 3:  59%|█████▊    | 17/29 [00:00<00:00, 185.39it/s, train_loss=0.014, val_loss=0.0309]  Epoch 3:  62%|██████▏   | 18/29 [00:00<00:00, 188.38it/s, train_loss=0.014, val_loss=0.0309]Epoch 3:  62%|██████▏   | 18/29 [00:00<00:00, 186.39it/s, train_loss=0.013, val_loss=0.0309]Epoch 3:  66%|██████▌   | 19/29 [00:00<00:00, 189.11it/s, train_loss=0.013, val_loss=0.0309]Epoch 3:  66%|██████▌   | 19/29 [00:00<00:00, 185.61it/s, train_loss=0.0116, val_loss=0.0309]Epoch 3:  69%|██████▉   | 20/29 [00:00<00:00, 188.17it/s, train_loss=0.0116, val_loss=0.0309]Epoch 3:  69%|██████▉   | 20/29 [00:00<00:00, 186.45it/s, train_loss=0.0395, val_loss=0.0309]Epoch 3:  72%|███████▏  | 21/29 [00:00<00:00, 188.81it/s, train_loss=0.0395, val_loss=0.0309]Epoch 3:  72%|███████▏  | 21/29 [00:00<00:00, 185.76it/s, train_loss=0.0156, val_loss=0.0309]Epoch 3:  76%|███████▌  | 22/29 [00:00<00:00, 188.21it/s, train_loss=0.0156, val_loss=0.0309]Epoch 3:  76%|███████▌  | 22/29 [00:00<00:00, 186.58it/s, train_loss=0.0206, val_loss=0.0309]Epoch 3:  79%|███████▉  | 23/29 [00:00<00:00, 188.50it/s, train_loss=0.0206, val_loss=0.0309]Epoch 3:  79%|███████▉  | 23/29 [00:00<00:00, 185.93it/s, train_loss=0.0243, val_loss=0.0309]Epoch 3:  83%|████████▎ | 24/29 [00:00<00:00, 188.07it/s, train_loss=0.0243, val_loss=0.0309]Epoch 3:  83%|████████▎ | 24/29 [00:00<00:00, 186.70it/s, train_loss=0.0196, val_loss=0.0309]Epoch 3:  86%|████████▌ | 25/29 [00:00<00:00, 188.58it/s, train_loss=0.0196, val_loss=0.0309]Epoch 3:  86%|████████▌ | 25/29 [00:00<00:00, 186.11it/s, train_loss=0.024, val_loss=0.0309] Epoch 3:  90%|████████▉ | 26/29 [00:00<00:00, 187.99it/s, train_loss=0.024, val_loss=0.0309]Epoch 3:  90%|████████▉ | 26/29 [00:00<00:00, 186.83it/s, train_loss=0.0249, val_loss=0.0309]Epoch 3:  93%|█████████▎| 27/29 [00:00<00:00, 188.60it/s, train_loss=0.0249, val_loss=0.0309]Epoch 3:  93%|█████████▎| 27/29 [00:00<00:00, 186.28it/s, train_loss=0.0212, val_loss=0.0309]Epoch 3:  97%|█████████▋| 28/29 [00:00<00:00, 187.88it/s, train_loss=0.0212, val_loss=0.0309]Epoch 3:  97%|█████████▋| 28/29 [00:00<00:00, 186.84it/s, train_loss=0.0145, val_loss=0.0309]Epoch 3: 100%|██████████| 29/29 [00:00<00:00, 188.40it/s, train_loss=0.0145, val_loss=0.0309]Epoch 3: 100%|██████████| 29/29 [00:00<00:00, 186.38it/s, train_loss=0.00986, val_loss=0.0309]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 306.42it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 328.35it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 336.87it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 341.15it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 342.29it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 341.69it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 338.99it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 337.23it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 335.80it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 333.94it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 331.75it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 330.20it/s][A
                                                                         [AEpoch 3: 100%|██████████| 29/29 [00:00<00:00, 145.95it/s, train_loss=0.00986, val_loss=0.026] Epoch 3: 100%|██████████| 29/29 [00:00<00:00, 145.35it/s, train_loss=0.00986, val_loss=0.026]Epoch 3:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00986, val_loss=0.026]          Epoch 4:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00986, val_loss=0.026]Epoch 4:   3%|▎         | 1/29 [00:00<00:00, 187.28it/s, train_loss=0.00986, val_loss=0.026]Epoch 4:   3%|▎         | 1/29 [00:00<00:00, 158.04it/s, train_loss=0.0225, val_loss=0.026] Epoch 4:   7%|▋         | 2/29 [00:00<00:00, 194.88it/s, train_loss=0.0225, val_loss=0.026]Epoch 4:   7%|▋         | 2/29 [00:00<00:00, 178.67it/s, train_loss=0.0219, val_loss=0.026]Epoch 4:  10%|█         | 3/29 [00:00<00:00, 198.30it/s, train_loss=0.0219, val_loss=0.026]Epoch 4:  10%|█         | 3/29 [00:00<00:00, 176.57it/s, train_loss=0.0263, val_loss=0.026]Epoch 4:  14%|█▍        | 4/29 [00:00<00:00, 191.67it/s, train_loss=0.0263, val_loss=0.026]Epoch 4:  14%|█▍        | 4/29 [00:00<00:00, 183.07it/s, train_loss=0.0214, val_loss=0.026]Epoch 4:  17%|█▋        | 5/29 [00:00<00:00, 193.48it/s, train_loss=0.0214, val_loss=0.026]Epoch 4:  17%|█▋        | 5/29 [00:00<00:00, 180.83it/s, train_loss=0.0114, val_loss=0.026]Epoch 4:  21%|██        | 6/29 [00:00<00:00, 190.07it/s, train_loss=0.0114, val_loss=0.026]Epoch 4:  21%|██        | 6/29 [00:00<00:00, 183.61it/s, train_loss=0.0202, val_loss=0.026]Epoch 4:  24%|██▍       | 7/29 [00:00<00:00, 190.64it/s, train_loss=0.0202, val_loss=0.026]Epoch 4:  24%|██▍       | 7/29 [00:00<00:00, 181.87it/s, train_loss=0.0106, val_loss=0.026]Epoch 4:  28%|██▊       | 8/29 [00:00<00:00, 188.30it/s, train_loss=0.0106, val_loss=0.026]Epoch 4:  28%|██▊       | 8/29 [00:00<00:00, 183.92it/s, train_loss=0.0138, val_loss=0.026]Epoch 4:  31%|███       | 9/29 [00:00<00:00, 188.71it/s, train_loss=0.0138, val_loss=0.026]Epoch 4:  31%|███       | 9/29 [00:00<00:00, 182.65it/s, train_loss=0.0194, val_loss=0.026]Epoch 4:  34%|███▍      | 10/29 [00:00<00:00, 187.08it/s, train_loss=0.0194, val_loss=0.026]Epoch 4:  34%|███▍      | 10/29 [00:00<00:00, 184.04it/s, train_loss=0.019, val_loss=0.026] Epoch 4:  38%|███▊      | 11/29 [00:00<00:00, 187.70it/s, train_loss=0.019, val_loss=0.026]Epoch 4:  38%|███▊      | 11/29 [00:00<00:00, 183.66it/s, train_loss=0.0277, val_loss=0.026]Epoch 4:  41%|████▏     | 12/29 [00:00<00:00, 187.49it/s, train_loss=0.0277, val_loss=0.026]Epoch 4:  41%|████▏     | 12/29 [00:00<00:00, 184.94it/s, train_loss=0.0201, val_loss=0.026]Epoch 4:  45%|████▍     | 13/29 [00:00<00:00, 189.63it/s, train_loss=0.0201, val_loss=0.026]Epoch 4:  45%|████▍     | 13/29 [00:00<00:00, 184.37it/s, train_loss=0.0165, val_loss=0.026]Epoch 4:  48%|████▊     | 14/29 [00:00<00:00, 188.74it/s, train_loss=0.0165, val_loss=0.026]Epoch 4:  48%|████▊     | 14/29 [00:00<00:00, 185.79it/s, train_loss=0.0174, val_loss=0.026]Epoch 4:  52%|█████▏    | 15/29 [00:00<00:00, 190.15it/s, train_loss=0.0174, val_loss=0.026]Epoch 4:  52%|█████▏    | 15/29 [00:00<00:00, 188.68it/s, train_loss=0.0214, val_loss=0.026]Epoch 4:  55%|█████▌    | 16/29 [00:00<00:00, 192.45it/s, train_loss=0.0214, val_loss=0.026]Epoch 4:  55%|█████▌    | 16/29 [00:00<00:00, 190.88it/s, train_loss=0.0177, val_loss=0.026]Epoch 4:  59%|█████▊    | 17/29 [00:00<00:00, 191.54it/s, train_loss=0.0177, val_loss=0.026]Epoch 4:  59%|█████▊    | 17/29 [00:00<00:00, 180.08it/s, train_loss=0.0142, val_loss=0.026]Epoch 4:  62%|██████▏   | 18/29 [00:00<00:00, 163.80it/s, train_loss=0.0142, val_loss=0.026]Epoch 4:  62%|██████▏   | 18/29 [00:00<00:00, 134.06it/s, train_loss=0.015, val_loss=0.026] Epoch 4:  66%|██████▌   | 19/29 [00:00<00:00, 118.48it/s, train_loss=0.015, val_loss=0.026]Epoch 4:  66%|██████▌   | 19/29 [00:00<00:00, 104.03it/s, train_loss=0.0105, val_loss=0.026]Epoch 4:  69%|██████▉   | 20/29 [00:00<00:00, 97.26it/s, train_loss=0.0105, val_loss=0.026] Epoch 4:  69%|██████▉   | 20/29 [00:00<00:00, 87.88it/s, train_loss=0.0114, val_loss=0.026]Epoch 4:  72%|███████▏  | 21/29 [00:00<00:00, 83.96it/s, train_loss=0.0114, val_loss=0.026]Epoch 4:  72%|███████▏  | 21/29 [00:00<00:00, 77.08it/s, train_loss=0.00906, val_loss=0.026]Epoch 4:  76%|███████▌  | 22/29 [00:00<00:00, 74.56it/s, train_loss=0.00906, val_loss=0.026]Epoch 4:  76%|███████▌  | 22/29 [00:00<00:00, 69.37it/s, train_loss=0.0132, val_loss=0.026] Epoch 4:  79%|███████▉  | 23/29 [00:00<00:00, 67.71it/s, train_loss=0.0132, val_loss=0.026]Epoch 4:  79%|███████▉  | 23/29 [00:00<00:00, 63.58it/s, train_loss=0.0207, val_loss=0.026]Epoch 4:  83%|████████▎ | 24/29 [00:00<00:00, 62.43it/s, train_loss=0.0207, val_loss=0.026]Epoch 4:  83%|████████▎ | 24/29 [00:00<00:00, 59.03it/s, train_loss=0.0328, val_loss=0.026]Epoch 4:  86%|████████▌ | 25/29 [00:00<00:00, 58.22it/s, train_loss=0.0328, val_loss=0.026]Epoch 4:  86%|████████▌ | 25/29 [00:00<00:00, 55.27it/s, train_loss=0.0134, val_loss=0.026]Epoch 4:  90%|████████▉ | 26/29 [00:00<00:00, 54.71it/s, train_loss=0.0134, val_loss=0.026]Epoch 4:  90%|████████▉ | 26/29 [00:00<00:00, 52.29it/s, train_loss=0.0175, val_loss=0.026]Epoch 4:  93%|█████████▎| 27/29 [00:00<00:00, 51.91it/s, train_loss=0.0175, val_loss=0.026]Epoch 4:  93%|█████████▎| 27/29 [00:00<00:00, 50.16it/s, train_loss=0.0101, val_loss=0.026]Epoch 4:  97%|█████████▋| 28/29 [00:00<00:00, 51.63it/s, train_loss=0.0101, val_loss=0.026]Epoch 4:  97%|█████████▋| 28/29 [00:00<00:00, 51.54it/s, train_loss=0.0216, val_loss=0.026]Epoch 4: 100%|██████████| 29/29 [00:00<00:00, 52.99it/s, train_loss=0.0216, val_loss=0.026]Epoch 4: 100%|██████████| 29/29 [00:00<00:00, 52.91it/s, train_loss=0.0252, val_loss=0.026]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 157.98it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 192.87it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 221.76it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 248.55it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 266.96it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 280.25it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 291.35it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 300.14it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 306.11it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 310.42it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 312.85it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 316.21it/s][A
                                                                         [AEpoch 4: 100%|██████████| 29/29 [00:00<00:00, 48.81it/s, train_loss=0.0252, val_loss=0.0204]Epoch 4: 100%|██████████| 29/29 [00:00<00:00, 48.75it/s, train_loss=0.0252, val_loss=0.0204]Epoch 4:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0252, val_loss=0.0204]         Epoch 5:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0252, val_loss=0.0204]Epoch 5:   3%|▎         | 1/29 [00:00<00:00, 202.87it/s, train_loss=0.0252, val_loss=0.0204]Epoch 5:   3%|▎         | 1/29 [00:00<00:00, 153.30it/s, train_loss=0.0167, val_loss=0.0204]Epoch 5:   7%|▋         | 2/29 [00:00<00:00, 194.43it/s, train_loss=0.0167, val_loss=0.0204]Epoch 5:   7%|▋         | 2/29 [00:00<00:00, 163.89it/s, train_loss=0.0157, val_loss=0.0204]Epoch 5:  10%|█         | 3/29 [00:00<00:00, 191.13it/s, train_loss=0.0157, val_loss=0.0204]Epoch 5:  10%|█         | 3/29 [00:00<00:00, 167.40it/s, train_loss=0.0221, val_loss=0.0204]Epoch 5:  14%|█▍        | 4/29 [00:00<00:00, 187.12it/s, train_loss=0.0221, val_loss=0.0204]Epoch 5:  14%|█▍        | 4/29 [00:00<00:00, 169.28it/s, train_loss=0.0159, val_loss=0.0204]Epoch 5:  17%|█▋        | 5/29 [00:00<00:00, 184.95it/s, train_loss=0.0159, val_loss=0.0204]Epoch 5:  17%|█▋        | 5/29 [00:00<00:00, 170.83it/s, train_loss=0.0194, val_loss=0.0204]Epoch 5:  21%|██        | 6/29 [00:00<00:00, 181.21it/s, train_loss=0.0194, val_loss=0.0204]Epoch 5:  21%|██        | 6/29 [00:00<00:00, 170.26it/s, train_loss=0.0111, val_loss=0.0204]Epoch 5:  24%|██▍       | 7/29 [00:00<00:00, 179.11it/s, train_loss=0.0111, val_loss=0.0204]Epoch 5:  24%|██▍       | 7/29 [00:00<00:00, 171.04it/s, train_loss=0.0121, val_loss=0.0204]Epoch 5:  28%|██▊       | 8/29 [00:00<00:00, 179.80it/s, train_loss=0.0121, val_loss=0.0204]Epoch 5:  28%|██▊       | 8/29 [00:00<00:00, 171.65it/s, train_loss=0.0113, val_loss=0.0204]Epoch 5:  31%|███       | 9/29 [00:00<00:00, 179.38it/s, train_loss=0.0113, val_loss=0.0204]Epoch 5:  31%|███       | 9/29 [00:00<00:00, 171.99it/s, train_loss=0.00802, val_loss=0.0204]Epoch 5:  34%|███▍      | 10/29 [00:00<00:00, 178.85it/s, train_loss=0.00802, val_loss=0.0204]Epoch 5:  34%|███▍      | 10/29 [00:00<00:00, 172.54it/s, train_loss=0.0101, val_loss=0.0204] Epoch 5:  38%|███▊      | 11/29 [00:00<00:00, 178.66it/s, train_loss=0.0101, val_loss=0.0204]Epoch 5:  38%|███▊      | 11/29 [00:00<00:00, 174.44it/s, train_loss=0.0165, val_loss=0.0204]Epoch 5:  41%|████▏     | 12/29 [00:00<00:00, 178.92it/s, train_loss=0.0165, val_loss=0.0204]Epoch 5:  41%|████▏     | 12/29 [00:00<00:00, 173.37it/s, train_loss=0.0128, val_loss=0.0204]Epoch 5:  45%|████▍     | 13/29 [00:00<00:00, 177.82it/s, train_loss=0.0128, val_loss=0.0204]Epoch 5:  45%|████▍     | 13/29 [00:00<00:00, 173.59it/s, train_loss=0.0148, val_loss=0.0204]Epoch 5:  48%|████▊     | 14/29 [00:00<00:00, 178.22it/s, train_loss=0.0148, val_loss=0.0204]Epoch 5:  48%|████▊     | 14/29 [00:00<00:00, 173.63it/s, train_loss=0.0144, val_loss=0.0204]Epoch 5:  52%|█████▏    | 15/29 [00:00<00:00, 178.91it/s, train_loss=0.0144, val_loss=0.0204]Epoch 5:  52%|█████▏    | 15/29 [00:00<00:00, 177.61it/s, train_loss=0.00934, val_loss=0.0204]Epoch 5:  55%|█████▌    | 16/29 [00:00<00:00, 182.44it/s, train_loss=0.00934, val_loss=0.0204]Epoch 5:  55%|█████▌    | 16/29 [00:00<00:00, 178.53it/s, train_loss=0.0105, val_loss=0.0204] Epoch 5:  59%|█████▊    | 17/29 [00:00<00:00, 183.08it/s, train_loss=0.0105, val_loss=0.0204]Epoch 5:  59%|█████▊    | 17/29 [00:00<00:00, 181.90it/s, train_loss=0.0154, val_loss=0.0204]Epoch 5:  62%|██████▏   | 18/29 [00:00<00:00, 185.36it/s, train_loss=0.0154, val_loss=0.0204]Epoch 5:  62%|██████▏   | 18/29 [00:00<00:00, 181.80it/s, train_loss=0.0151, val_loss=0.0204]Epoch 5:  66%|██████▌   | 19/29 [00:00<00:00, 185.06it/s, train_loss=0.0151, val_loss=0.0204]Epoch 5:  66%|██████▌   | 19/29 [00:00<00:00, 181.46it/s, train_loss=0.0153, val_loss=0.0204]Epoch 5:  69%|██████▉   | 20/29 [00:00<00:00, 185.02it/s, train_loss=0.0153, val_loss=0.0204]Epoch 5:  69%|██████▉   | 20/29 [00:00<00:00, 181.24it/s, train_loss=0.0156, val_loss=0.0204]Epoch 5:  72%|███████▏  | 21/29 [00:00<00:00, 184.35it/s, train_loss=0.0156, val_loss=0.0204]Epoch 5:  72%|███████▏  | 21/29 [00:00<00:00, 180.94it/s, train_loss=0.0126, val_loss=0.0204]Epoch 5:  76%|███████▌  | 22/29 [00:00<00:00, 183.96it/s, train_loss=0.0126, val_loss=0.0204]Epoch 5:  76%|███████▌  | 22/29 [00:00<00:00, 180.80it/s, train_loss=0.0089, val_loss=0.0204]Epoch 5:  79%|███████▉  | 23/29 [00:00<00:00, 183.80it/s, train_loss=0.0089, val_loss=0.0204]Epoch 5:  79%|███████▉  | 23/29 [00:00<00:00, 181.27it/s, train_loss=0.0119, val_loss=0.0204]Epoch 5:  83%|████████▎ | 24/29 [00:00<00:00, 183.57it/s, train_loss=0.0119, val_loss=0.0204]Epoch 5:  83%|████████▎ | 24/29 [00:00<00:00, 180.53it/s, train_loss=0.00906, val_loss=0.0204]Epoch 5:  86%|████████▌ | 25/29 [00:00<00:00, 182.88it/s, train_loss=0.00906, val_loss=0.0204]Epoch 5:  86%|████████▌ | 25/29 [00:00<00:00, 180.37it/s, train_loss=0.00652, val_loss=0.0204]Epoch 5:  90%|████████▉ | 26/29 [00:00<00:00, 182.81it/s, train_loss=0.00652, val_loss=0.0204]Epoch 5:  90%|████████▉ | 26/29 [00:00<00:00, 180.13it/s, train_loss=0.0112, val_loss=0.0204] Epoch 5:  93%|█████████▎| 27/29 [00:00<00:00, 182.48it/s, train_loss=0.0112, val_loss=0.0204]Epoch 5:  93%|█████████▎| 27/29 [00:00<00:00, 179.95it/s, train_loss=0.00588, val_loss=0.0204]Epoch 5:  97%|█████████▋| 28/29 [00:00<00:00, 182.26it/s, train_loss=0.00588, val_loss=0.0204]Epoch 5:  97%|█████████▋| 28/29 [00:00<00:00, 179.85it/s, train_loss=0.0126, val_loss=0.0204] Epoch 5: 100%|██████████| 29/29 [00:00<00:00, 181.65it/s, train_loss=0.0126, val_loss=0.0204]Epoch 5: 100%|██████████| 29/29 [00:00<00:00, 179.26it/s, train_loss=0.00322, val_loss=0.0204]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 52.16it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 86.12it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 111.59it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 130.63it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 145.18it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 156.82it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 169.58it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 182.17it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 193.15it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 202.96it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 211.03it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 218.86it/s][A
                                                                         [AEpoch 5: 100%|██████████| 29/29 [00:00<00:00, 129.52it/s, train_loss=0.00322, val_loss=0.0121]Epoch 5: 100%|██████████| 29/29 [00:00<00:00, 129.10it/s, train_loss=0.00322, val_loss=0.0121]Epoch 5:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00322, val_loss=0.0121]          Epoch 6:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00322, val_loss=0.0121]Epoch 6:   3%|▎         | 1/29 [00:00<00:00, 218.96it/s, train_loss=0.00322, val_loss=0.0121]Epoch 6:   3%|▎         | 1/29 [00:00<00:00, 183.04it/s, train_loss=0.00961, val_loss=0.0121]Epoch 6:   7%|▋         | 2/29 [00:00<00:00, 212.23it/s, train_loss=0.00961, val_loss=0.0121]Epoch 6:   7%|▋         | 2/29 [00:00<00:00, 178.05it/s, train_loss=0.00611, val_loss=0.0121]Epoch 6:  10%|█         | 3/29 [00:00<00:00, 200.36it/s, train_loss=0.00611, val_loss=0.0121]Epoch 6:  10%|█         | 3/29 [00:00<00:00, 176.99it/s, train_loss=0.00792, val_loss=0.0121]Epoch 6:  14%|█▍        | 4/29 [00:00<00:00, 196.75it/s, train_loss=0.00792, val_loss=0.0121]Epoch 6:  14%|█▍        | 4/29 [00:00<00:00, 189.11it/s, train_loss=0.009, val_loss=0.0121]  Epoch 6:  17%|█▋        | 5/29 [00:00<00:00, 201.29it/s, train_loss=0.009, val_loss=0.0121]Epoch 6:  17%|█▋        | 5/29 [00:00<00:00, 191.25it/s, train_loss=0.0103, val_loss=0.0121]Epoch 6:  21%|██        | 6/29 [00:00<00:00, 201.04it/s, train_loss=0.0103, val_loss=0.0121]Epoch 6:  21%|██        | 6/29 [00:00<00:00, 188.30it/s, train_loss=0.0154, val_loss=0.0121]Epoch 6:  24%|██▍       | 7/29 [00:00<00:00, 197.46it/s, train_loss=0.0154, val_loss=0.0121]Epoch 6:  24%|██▍       | 7/29 [00:00<00:00, 186.39it/s, train_loss=0.00884, val_loss=0.0121]Epoch 6:  28%|██▊       | 8/29 [00:00<00:00, 193.32it/s, train_loss=0.00884, val_loss=0.0121]Epoch 6:  28%|██▊       | 8/29 [00:00<00:00, 187.85it/s, train_loss=0.00668, val_loss=0.0121]Epoch 6:  31%|███       | 9/29 [00:00<00:00, 194.18it/s, train_loss=0.00668, val_loss=0.0121]Epoch 6:  31%|███       | 9/29 [00:00<00:00, 186.14it/s, train_loss=0.00784, val_loss=0.0121]Epoch 6:  34%|███▍      | 10/29 [00:00<00:00, 192.64it/s, train_loss=0.00784, val_loss=0.0121]Epoch 6:  34%|███▍      | 10/29 [00:00<00:00, 185.10it/s, train_loss=0.00752, val_loss=0.0121]Epoch 6:  38%|███▊      | 11/29 [00:00<00:00, 191.02it/s, train_loss=0.00752, val_loss=0.0121]Epoch 6:  38%|███▊      | 11/29 [00:00<00:00, 184.06it/s, train_loss=0.0126, val_loss=0.0121] Epoch 6:  41%|████▏     | 12/29 [00:00<00:00, 189.72it/s, train_loss=0.0126, val_loss=0.0121]Epoch 6:  41%|████▏     | 12/29 [00:00<00:00, 183.31it/s, train_loss=0.0146, val_loss=0.0121]Epoch 6:  45%|████▍     | 13/29 [00:00<00:00, 188.56it/s, train_loss=0.0146, val_loss=0.0121]Epoch 6:  45%|████▍     | 13/29 [00:00<00:00, 182.96it/s, train_loss=0.00604, val_loss=0.0121]Epoch 6:  48%|████▊     | 14/29 [00:00<00:00, 186.40it/s, train_loss=0.00604, val_loss=0.0121]Epoch 6:  48%|████▊     | 14/29 [00:00<00:00, 181.37it/s, train_loss=0.0128, val_loss=0.0121] Epoch 6:  52%|█████▏    | 15/29 [00:00<00:00, 185.26it/s, train_loss=0.0128, val_loss=0.0121]Epoch 6:  52%|█████▏    | 15/29 [00:00<00:00, 180.91it/s, train_loss=0.00932, val_loss=0.0121]Epoch 6:  55%|█████▌    | 16/29 [00:00<00:00, 184.79it/s, train_loss=0.00932, val_loss=0.0121]Epoch 6:  55%|█████▌    | 16/29 [00:00<00:00, 180.50it/s, train_loss=0.00817, val_loss=0.0121]Epoch 6:  59%|█████▊    | 17/29 [00:00<00:00, 185.10it/s, train_loss=0.00817, val_loss=0.0121]Epoch 6:  59%|█████▊    | 17/29 [00:00<00:00, 184.14it/s, train_loss=0.00439, val_loss=0.0121]Epoch 6:  62%|██████▏   | 18/29 [00:00<00:00, 188.46it/s, train_loss=0.00439, val_loss=0.0121]Epoch 6:  62%|██████▏   | 18/29 [00:00<00:00, 184.17it/s, train_loss=0.0211, val_loss=0.0121] Epoch 6:  66%|██████▌   | 19/29 [00:00<00:00, 188.38it/s, train_loss=0.0211, val_loss=0.0121]Epoch 6:  66%|██████▌   | 19/29 [00:00<00:00, 187.38it/s, train_loss=0.00484, val_loss=0.0121]Epoch 6:  69%|██████▉   | 20/29 [00:00<00:00, 190.86it/s, train_loss=0.00484, val_loss=0.0121]Epoch 6:  69%|██████▉   | 20/29 [00:00<00:00, 186.91it/s, train_loss=0.00788, val_loss=0.0121]Epoch 6:  72%|███████▏  | 21/29 [00:00<00:00, 190.04it/s, train_loss=0.00788, val_loss=0.0121]Epoch 6:  72%|███████▏  | 21/29 [00:00<00:00, 186.24it/s, train_loss=0.014, val_loss=0.0121]  Epoch 6:  76%|███████▌  | 22/29 [00:00<00:00, 189.46it/s, train_loss=0.014, val_loss=0.0121]Epoch 6:  76%|███████▌  | 22/29 [00:00<00:00, 185.79it/s, train_loss=0.00925, val_loss=0.0121]Epoch 6:  79%|███████▉  | 23/29 [00:00<00:00, 188.70it/s, train_loss=0.00925, val_loss=0.0121]Epoch 6:  79%|███████▉  | 23/29 [00:00<00:00, 185.24it/s, train_loss=0.0108, val_loss=0.0121] Epoch 6:  83%|████████▎ | 24/29 [00:00<00:00, 188.05it/s, train_loss=0.0108, val_loss=0.0121]Epoch 6:  83%|████████▎ | 24/29 [00:00<00:00, 184.83it/s, train_loss=0.00761, val_loss=0.0121]Epoch 6:  86%|████████▌ | 25/29 [00:00<00:00, 187.57it/s, train_loss=0.00761, val_loss=0.0121]Epoch 6:  86%|████████▌ | 25/29 [00:00<00:00, 184.65it/s, train_loss=0.0072, val_loss=0.0121] Epoch 6:  90%|████████▉ | 26/29 [00:00<00:00, 187.20it/s, train_loss=0.0072, val_loss=0.0121]Epoch 6:  90%|████████▉ | 26/29 [00:00<00:00, 186.25it/s, train_loss=0.00633, val_loss=0.0121]Epoch 6:  93%|█████████▎| 27/29 [00:00<00:00, 188.64it/s, train_loss=0.00633, val_loss=0.0121]Epoch 6:  93%|█████████▎| 27/29 [00:00<00:00, 186.27it/s, train_loss=0.00618, val_loss=0.0121]Epoch 6:  97%|█████████▋| 28/29 [00:00<00:00, 188.76it/s, train_loss=0.00618, val_loss=0.0121]Epoch 6:  97%|█████████▋| 28/29 [00:00<00:00, 185.89it/s, train_loss=0.00907, val_loss=0.0121]Epoch 6: 100%|██████████| 29/29 [00:00<00:00, 188.25it/s, train_loss=0.00907, val_loss=0.0121]Epoch 6: 100%|██████████| 29/29 [00:00<00:00, 187.17it/s, train_loss=0.00725, val_loss=0.0121]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 166.11it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 207.95it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 226.48it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 238.21it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 242.95it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 247.10it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 248.88it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 251.35it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 252.47it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 253.14it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 259.92it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 268.81it/s][A
                                                                         [AEpoch 6: 100%|██████████| 29/29 [00:00<00:00, 139.53it/s, train_loss=0.00725, val_loss=0.00986]Epoch 6: 100%|██████████| 29/29 [00:00<00:00, 139.15it/s, train_loss=0.00725, val_loss=0.00986]Epoch 6:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00725, val_loss=0.00986]          Epoch 7:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00725, val_loss=0.00986]Epoch 7:   3%|▎         | 1/29 [00:00<00:00, 228.75it/s, train_loss=0.00725, val_loss=0.00986]Epoch 7:   3%|▎         | 1/29 [00:00<00:00, 156.15it/s, train_loss=0.00711, val_loss=0.00986]Epoch 7:   7%|▋         | 2/29 [00:00<00:00, 203.85it/s, train_loss=0.00711, val_loss=0.00986]Epoch 7:   7%|▋         | 2/29 [00:00<00:00, 192.54it/s, train_loss=0.0169, val_loss=0.00986] Epoch 7:  10%|█         | 3/29 [00:00<00:00, 219.02it/s, train_loss=0.0169, val_loss=0.00986]Epoch 7:  10%|█         | 3/29 [00:00<00:00, 192.27it/s, train_loss=0.00798, val_loss=0.00986]Epoch 7:  14%|█▍        | 4/29 [00:00<00:00, 212.21it/s, train_loss=0.00798, val_loss=0.00986]Epoch 7:  14%|█▍        | 4/29 [00:00<00:00, 204.69it/s, train_loss=0.00683, val_loss=0.00986]Epoch 7:  17%|█▋        | 5/29 [00:00<00:00, 219.57it/s, train_loss=0.00683, val_loss=0.00986]Epoch 7:  17%|█▋        | 5/29 [00:00<00:00, 202.31it/s, train_loss=0.00603, val_loss=0.00986]Epoch 7:  21%|██        | 6/29 [00:00<00:00, 214.10it/s, train_loss=0.00603, val_loss=0.00986]Epoch 7:  21%|██        | 6/29 [00:00<00:00, 208.44it/s, train_loss=0.00847, val_loss=0.00986]Epoch 7:  24%|██▍       | 7/29 [00:00<00:00, 218.00it/s, train_loss=0.00847, val_loss=0.00986]Epoch 7:  24%|██▍       | 7/29 [00:00<00:00, 206.81it/s, train_loss=0.00823, val_loss=0.00986]Epoch 7:  28%|██▊       | 8/29 [00:00<00:00, 213.88it/s, train_loss=0.00823, val_loss=0.00986]Epoch 7:  28%|██▊       | 8/29 [00:00<00:00, 209.75it/s, train_loss=0.00665, val_loss=0.00986]Epoch 7:  31%|███       | 9/29 [00:00<00:00, 215.83it/s, train_loss=0.00665, val_loss=0.00986]Epoch 7:  31%|███       | 9/29 [00:00<00:00, 206.54it/s, train_loss=0.00966, val_loss=0.00986]Epoch 7:  34%|███▍      | 10/29 [00:00<00:00, 212.57it/s, train_loss=0.00966, val_loss=0.00986]Epoch 7:  34%|███▍      | 10/29 [00:00<00:00, 202.99it/s, train_loss=0.00402, val_loss=0.00986]Epoch 7:  38%|███▊      | 11/29 [00:00<00:00, 208.61it/s, train_loss=0.00402, val_loss=0.00986]Epoch 7:  38%|███▊      | 11/29 [00:00<00:00, 200.04it/s, train_loss=0.00683, val_loss=0.00986]Epoch 7:  41%|████▏     | 12/29 [00:00<00:00, 205.49it/s, train_loss=0.00683, val_loss=0.00986]Epoch 7:  41%|████▏     | 12/29 [00:00<00:00, 197.79it/s, train_loss=0.00846, val_loss=0.00986]Epoch 7:  45%|████▍     | 13/29 [00:00<00:00, 202.27it/s, train_loss=0.00846, val_loss=0.00986]Epoch 7:  45%|████▍     | 13/29 [00:00<00:00, 195.90it/s, train_loss=0.00726, val_loss=0.00986]Epoch 7:  48%|████▊     | 14/29 [00:00<00:00, 199.90it/s, train_loss=0.00726, val_loss=0.00986]Epoch 7:  48%|████▊     | 14/29 [00:00<00:00, 193.77it/s, train_loss=0.00823, val_loss=0.00986]Epoch 7:  52%|█████▏    | 15/29 [00:00<00:00, 197.59it/s, train_loss=0.00823, val_loss=0.00986]Epoch 7:  52%|█████▏    | 15/29 [00:00<00:00, 192.30it/s, train_loss=0.0102, val_loss=0.00986] Epoch 7:  55%|█████▌    | 16/29 [00:00<00:00, 196.38it/s, train_loss=0.0102, val_loss=0.00986]Epoch 7:  55%|█████▌    | 16/29 [00:00<00:00, 191.16it/s, train_loss=0.00571, val_loss=0.00986]Epoch 7:  59%|█████▊    | 17/29 [00:00<00:00, 194.93it/s, train_loss=0.00571, val_loss=0.00986]Epoch 7:  59%|█████▊    | 17/29 [00:00<00:00, 190.10it/s, train_loss=0.00738, val_loss=0.00986]Epoch 7:  62%|██████▏   | 18/29 [00:00<00:00, 194.49it/s, train_loss=0.00738, val_loss=0.00986]Epoch 7:  62%|██████▏   | 18/29 [00:00<00:00, 193.38it/s, train_loss=0.0067, val_loss=0.00986] Epoch 7:  66%|██████▌   | 19/29 [00:00<00:00, 197.61it/s, train_loss=0.0067, val_loss=0.00986]Epoch 7:  66%|██████▌   | 19/29 [00:00<00:00, 196.49it/s, train_loss=0.0106, val_loss=0.00986]Epoch 7:  69%|██████▉   | 20/29 [00:00<00:00, 200.09it/s, train_loss=0.0106, val_loss=0.00986]Epoch 7:  69%|██████▉   | 20/29 [00:00<00:00, 196.26it/s, train_loss=0.0063, val_loss=0.00986]Epoch 7:  72%|███████▏  | 21/29 [00:00<00:00, 199.61it/s, train_loss=0.0063, val_loss=0.00986]Epoch 7:  72%|███████▏  | 21/29 [00:00<00:00, 198.60it/s, train_loss=0.00613, val_loss=0.00986]Epoch 7:  76%|███████▌  | 22/29 [00:00<00:00, 201.77it/s, train_loss=0.00613, val_loss=0.00986]Epoch 7:  76%|███████▌  | 22/29 [00:00<00:00, 200.72it/s, train_loss=0.00607, val_loss=0.00986]Epoch 7:  79%|███████▉  | 23/29 [00:00<00:00, 203.79it/s, train_loss=0.00607, val_loss=0.00986]Epoch 7:  79%|███████▉  | 23/29 [00:00<00:00, 200.48it/s, train_loss=0.0134, val_loss=0.00986] Epoch 7:  83%|████████▎ | 24/29 [00:00<00:00, 203.30it/s, train_loss=0.0134, val_loss=0.00986]Epoch 7:  83%|████████▎ | 24/29 [00:00<00:00, 201.89it/s, train_loss=0.00558, val_loss=0.00986]Epoch 7:  86%|████████▌ | 25/29 [00:00<00:00, 204.57it/s, train_loss=0.00558, val_loss=0.00986]Epoch 7:  86%|████████▌ | 25/29 [00:00<00:00, 201.85it/s, train_loss=0.00852, val_loss=0.00986]Epoch 7:  90%|████████▉ | 26/29 [00:00<00:00, 204.24it/s, train_loss=0.00852, val_loss=0.00986]Epoch 7:  90%|████████▉ | 26/29 [00:00<00:00, 200.75it/s, train_loss=0.00448, val_loss=0.00986]Epoch 7:  93%|█████████▎| 27/29 [00:00<00:00, 203.00it/s, train_loss=0.00448, val_loss=0.00986]Epoch 7:  93%|█████████▎| 27/29 [00:00<00:00, 199.83it/s, train_loss=0.0084, val_loss=0.00986] Epoch 7:  97%|█████████▋| 28/29 [00:00<00:00, 200.45it/s, train_loss=0.0084, val_loss=0.00986]Epoch 7:  97%|█████████▋| 28/29 [00:00<00:00, 198.18it/s, train_loss=0.00822, val_loss=0.00986]Epoch 7: 100%|██████████| 29/29 [00:00<00:00, 199.34it/s, train_loss=0.00822, val_loss=0.00986]Epoch 7: 100%|██████████| 29/29 [00:00<00:00, 197.27it/s, train_loss=0.00639, val_loss=0.00986]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 153.74it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 187.12it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 202.46it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 212.87it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 218.34it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 221.15it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 223.38it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 224.96it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 228.53it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 232.43it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 236.03it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 238.90it/s][A
                                                                         [AEpoch 7: 100%|██████████| 29/29 [00:00<00:00, 140.96it/s, train_loss=0.00639, val_loss=0.00836]Epoch 7: 100%|██████████| 29/29 [00:00<00:00, 140.57it/s, train_loss=0.00639, val_loss=0.00836]Epoch 7:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00639, val_loss=0.00836]          Epoch 8:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00639, val_loss=0.00836]Epoch 8:   3%|▎         | 1/29 [00:00<00:00, 237.87it/s, train_loss=0.00639, val_loss=0.00836]Epoch 8:   3%|▎         | 1/29 [00:00<00:00, 176.22it/s, train_loss=0.0122, val_loss=0.00836] Epoch 8:   7%|▋         | 2/29 [00:00<00:00, 216.47it/s, train_loss=0.0122, val_loss=0.00836]Epoch 8:   7%|▋         | 2/29 [00:00<00:00, 185.93it/s, train_loss=0.00583, val_loss=0.00836]Epoch 8:  10%|█         | 3/29 [00:00<00:00, 211.44it/s, train_loss=0.00583, val_loss=0.00836]Epoch 8:  10%|█         | 3/29 [00:00<00:00, 203.75it/s, train_loss=0.00721, val_loss=0.00836]Epoch 8:  14%|█▍        | 4/29 [00:00<00:00, 223.25it/s, train_loss=0.00721, val_loss=0.00836]Epoch 8:  14%|█▍        | 4/29 [00:00<00:00, 200.03it/s, train_loss=0.00439, val_loss=0.00836]Epoch 8:  17%|█▋        | 5/29 [00:00<00:00, 209.64it/s, train_loss=0.00439, val_loss=0.00836]Epoch 8:  17%|█▋        | 5/29 [00:00<00:00, 193.79it/s, train_loss=0.0114, val_loss=0.00836] Epoch 8:  21%|██        | 6/29 [00:00<00:00, 202.05it/s, train_loss=0.0114, val_loss=0.00836]Epoch 8:  21%|██        | 6/29 [00:00<00:00, 189.47it/s, train_loss=0.011, val_loss=0.00836] Epoch 8:  24%|██▍       | 7/29 [00:00<00:00, 199.16it/s, train_loss=0.011, val_loss=0.00836]Epoch 8:  24%|██▍       | 7/29 [00:00<00:00, 187.10it/s, train_loss=0.00833, val_loss=0.00836]Epoch 8:  28%|██▊       | 8/29 [00:00<00:00, 195.47it/s, train_loss=0.00833, val_loss=0.00836]Epoch 8:  28%|██▊       | 8/29 [00:00<00:00, 192.14it/s, train_loss=0.0059, val_loss=0.00836] Epoch 8:  31%|███       | 9/29 [00:00<00:00, 199.08it/s, train_loss=0.0059, val_loss=0.00836]Epoch 8:  31%|███       | 9/29 [00:00<00:00, 195.62it/s, train_loss=0.00646, val_loss=0.00836]Epoch 8:  34%|███▍      | 10/29 [00:00<00:00, 199.23it/s, train_loss=0.00646, val_loss=0.00836]Epoch 8:  34%|███▍      | 10/29 [00:00<00:00, 194.67it/s, train_loss=0.00428, val_loss=0.00836]Epoch 8:  38%|███▊      | 11/29 [00:00<00:00, 200.57it/s, train_loss=0.00428, val_loss=0.00836]Epoch 8:  38%|███▊      | 11/29 [00:00<00:00, 192.65it/s, train_loss=0.00682, val_loss=0.00836]Epoch 8:  41%|████▏     | 12/29 [00:00<00:00, 197.88it/s, train_loss=0.00682, val_loss=0.00836]Epoch 8:  41%|████▏     | 12/29 [00:00<00:00, 190.80it/s, train_loss=0.00698, val_loss=0.00836]Epoch 8:  45%|████▍     | 13/29 [00:00<00:00, 195.74it/s, train_loss=0.00698, val_loss=0.00836]Epoch 8:  45%|████▍     | 13/29 [00:00<00:00, 189.36it/s, train_loss=0.00512, val_loss=0.00836]Epoch 8:  48%|████▊     | 14/29 [00:00<00:00, 193.99it/s, train_loss=0.00512, val_loss=0.00836]Epoch 8:  48%|████▊     | 14/29 [00:00<00:00, 188.27it/s, train_loss=0.00485, val_loss=0.00836]Epoch 8:  52%|█████▏    | 15/29 [00:00<00:00, 192.10it/s, train_loss=0.00485, val_loss=0.00836]Epoch 8:  52%|█████▏    | 15/29 [00:00<00:00, 188.14it/s, train_loss=0.00391, val_loss=0.00836]Epoch 8:  55%|█████▌    | 16/29 [00:00<00:00, 191.78it/s, train_loss=0.00391, val_loss=0.00836]Epoch 8:  55%|█████▌    | 16/29 [00:00<00:00, 187.07it/s, train_loss=0.00741, val_loss=0.00836]Epoch 8:  59%|█████▊    | 17/29 [00:00<00:00, 189.79it/s, train_loss=0.00741, val_loss=0.00836]Epoch 8:  59%|█████▊    | 17/29 [00:00<00:00, 186.22it/s, train_loss=0.00417, val_loss=0.00836]Epoch 8:  62%|██████▏   | 18/29 [00:00<00:00, 189.54it/s, train_loss=0.00417, val_loss=0.00836]Epoch 8:  62%|██████▏   | 18/29 [00:00<00:00, 185.51it/s, train_loss=0.00622, val_loss=0.00836]Epoch 8:  66%|██████▌   | 19/29 [00:00<00:00, 188.65it/s, train_loss=0.00622, val_loss=0.00836]Epoch 8:  66%|██████▌   | 19/29 [00:00<00:00, 184.93it/s, train_loss=0.00518, val_loss=0.00836]Epoch 8:  69%|██████▉   | 20/29 [00:00<00:00, 188.80it/s, train_loss=0.00518, val_loss=0.00836]Epoch 8:  69%|██████▉   | 20/29 [00:00<00:00, 187.78it/s, train_loss=0.00932, val_loss=0.00836]Epoch 8:  72%|███████▏  | 21/29 [00:00<00:00, 191.19it/s, train_loss=0.00932, val_loss=0.00836]Epoch 8:  72%|███████▏  | 21/29 [00:00<00:00, 190.26it/s, train_loss=0.00785, val_loss=0.00836]Epoch 8:  76%|███████▌  | 22/29 [00:00<00:00, 193.11it/s, train_loss=0.00785, val_loss=0.00836]Epoch 8:  76%|███████▌  | 22/29 [00:00<00:00, 189.54it/s, train_loss=0.00598, val_loss=0.00836]Epoch 8:  79%|███████▉  | 23/29 [00:00<00:00, 191.63it/s, train_loss=0.00598, val_loss=0.00836]Epoch 8:  79%|███████▉  | 23/29 [00:00<00:00, 188.89it/s, train_loss=0.00587, val_loss=0.00836]Epoch 8:  83%|████████▎ | 24/29 [00:00<00:00, 191.08it/s, train_loss=0.00587, val_loss=0.00836]Epoch 8:  83%|████████▎ | 24/29 [00:00<00:00, 188.22it/s, train_loss=0.00508, val_loss=0.00836]Epoch 8:  86%|████████▌ | 25/29 [00:00<00:00, 190.25it/s, train_loss=0.00508, val_loss=0.00836]Epoch 8:  86%|████████▌ | 25/29 [00:00<00:00, 187.51it/s, train_loss=0.00826, val_loss=0.00836]Epoch 8:  90%|████████▉ | 26/29 [00:00<00:00, 189.44it/s, train_loss=0.00826, val_loss=0.00836]Epoch 8:  90%|████████▉ | 26/29 [00:00<00:00, 186.95it/s, train_loss=0.00637, val_loss=0.00836]Epoch 8:  93%|█████████▎| 27/29 [00:00<00:00, 188.57it/s, train_loss=0.00637, val_loss=0.00836]Epoch 8:  93%|█████████▎| 27/29 [00:00<00:00, 187.62it/s, train_loss=0.0109, val_loss=0.00836] Epoch 8:  97%|█████████▋| 28/29 [00:00<00:00, 189.60it/s, train_loss=0.0109, val_loss=0.00836]Epoch 8:  97%|█████████▋| 28/29 [00:00<00:00, 187.24it/s, train_loss=0.00571, val_loss=0.00836]Epoch 8: 100%|██████████| 29/29 [00:00<00:00, 188.95it/s, train_loss=0.00571, val_loss=0.00836]Epoch 8: 100%|██████████| 29/29 [00:00<00:00, 186.70it/s, train_loss=0.00444, val_loss=0.00836]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 166.33it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 200.85it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 215.07it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 225.42it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 232.04it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 236.29it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 237.92it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 239.08it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 239.86it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 240.38it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 240.61it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 241.35it/s][A
                                                                         [AEpoch 8: 100%|██████████| 29/29 [00:00<00:00, 135.64it/s, train_loss=0.00444, val_loss=0.00759]Epoch 8: 100%|██████████| 29/29 [00:00<00:00, 134.93it/s, train_loss=0.00444, val_loss=0.00759]Epoch 8:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00444, val_loss=0.00759]          Epoch 9:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00444, val_loss=0.00759]Epoch 9:   3%|▎         | 1/29 [00:00<00:00, 199.52it/s, train_loss=0.00444, val_loss=0.00759]Epoch 9:   3%|▎         | 1/29 [00:00<00:00, 177.36it/s, train_loss=0.00469, val_loss=0.00759]Epoch 9:   7%|▋         | 2/29 [00:00<00:00, 205.14it/s, train_loss=0.00469, val_loss=0.00759]Epoch 9:   7%|▋         | 2/29 [00:00<00:00, 178.50it/s, train_loss=0.00666, val_loss=0.00759]Epoch 9:  10%|█         | 3/29 [00:00<00:00, 199.20it/s, train_loss=0.00666, val_loss=0.00759]Epoch 9:  10%|█         | 3/29 [00:00<00:00, 175.66it/s, train_loss=0.00733, val_loss=0.00759]Epoch 9:  14%|█▍        | 4/29 [00:00<00:00, 192.18it/s, train_loss=0.00733, val_loss=0.00759]Epoch 9:  14%|█▍        | 4/29 [00:00<00:00, 174.53it/s, train_loss=0.00751, val_loss=0.00759]Epoch 9:  17%|█▋        | 5/29 [00:00<00:00, 188.05it/s, train_loss=0.00751, val_loss=0.00759]Epoch 9:  17%|█▋        | 5/29 [00:00<00:00, 173.85it/s, train_loss=0.00517, val_loss=0.00759]Epoch 9:  21%|██        | 6/29 [00:00<00:00, 184.72it/s, train_loss=0.00517, val_loss=0.00759]Epoch 9:  21%|██        | 6/29 [00:00<00:00, 173.61it/s, train_loss=0.0085, val_loss=0.00759] Epoch 9:  24%|██▍       | 7/29 [00:00<00:00, 182.63it/s, train_loss=0.0085, val_loss=0.00759]Epoch 9:  24%|██▍       | 7/29 [00:00<00:00, 173.62it/s, train_loss=0.00604, val_loss=0.00759]Epoch 9:  28%|██▊       | 8/29 [00:00<00:00, 179.74it/s, train_loss=0.00604, val_loss=0.00759]Epoch 9:  28%|██▊       | 8/29 [00:00<00:00, 173.32it/s, train_loss=0.00886, val_loss=0.00759]Epoch 9:  31%|███       | 9/29 [00:00<00:00, 179.35it/s, train_loss=0.00886, val_loss=0.00759]Epoch 9:  31%|███       | 9/29 [00:00<00:00, 173.14it/s, train_loss=0.0105, val_loss=0.00759] Epoch 9:  34%|███▍      | 10/29 [00:00<00:00, 178.82it/s, train_loss=0.0105, val_loss=0.00759]Epoch 9:  34%|███▍      | 10/29 [00:00<00:00, 173.21it/s, train_loss=0.00492, val_loss=0.00759]Epoch 9:  38%|███▊      | 11/29 [00:00<00:00, 178.56it/s, train_loss=0.00492, val_loss=0.00759]Epoch 9:  38%|███▊      | 11/29 [00:00<00:00, 173.05it/s, train_loss=0.0089, val_loss=0.00759] Epoch 9:  41%|████▏     | 12/29 [00:00<00:00, 177.76it/s, train_loss=0.0089, val_loss=0.00759]Epoch 9:  41%|████▏     | 12/29 [00:00<00:00, 173.08it/s, train_loss=0.0043, val_loss=0.00759]Epoch 9:  45%|████▍     | 13/29 [00:00<00:00, 177.49it/s, train_loss=0.0043, val_loss=0.00759]Epoch 9:  45%|████▍     | 13/29 [00:00<00:00, 173.12it/s, train_loss=0.00601, val_loss=0.00759]Epoch 9:  48%|████▊     | 14/29 [00:00<00:00, 176.48it/s, train_loss=0.00601, val_loss=0.00759]Epoch 9:  48%|████▊     | 14/29 [00:00<00:00, 173.66it/s, train_loss=0.00436, val_loss=0.00759]Epoch 9:  52%|█████▏    | 15/29 [00:00<00:00, 176.99it/s, train_loss=0.00436, val_loss=0.00759]Epoch 9:  52%|█████▏    | 15/29 [00:00<00:00, 173.55it/s, train_loss=0.00264, val_loss=0.00759]Epoch 9:  55%|█████▌    | 16/29 [00:00<00:00, 176.98it/s, train_loss=0.00264, val_loss=0.00759]Epoch 9:  55%|█████▌    | 16/29 [00:00<00:00, 173.52it/s, train_loss=0.0063, val_loss=0.00759] Epoch 9:  59%|█████▊    | 17/29 [00:00<00:00, 176.61it/s, train_loss=0.0063, val_loss=0.00759]Epoch 9:  59%|█████▊    | 17/29 [00:00<00:00, 173.45it/s, train_loss=0.00539, val_loss=0.00759]Epoch 9:  62%|██████▏   | 18/29 [00:00<00:00, 176.40it/s, train_loss=0.00539, val_loss=0.00759]Epoch 9:  62%|██████▏   | 18/29 [00:00<00:00, 173.47it/s, train_loss=0.00577, val_loss=0.00759]Epoch 9:  66%|██████▌   | 19/29 [00:00<00:00, 176.19it/s, train_loss=0.00577, val_loss=0.00759]Epoch 9:  66%|██████▌   | 19/29 [00:00<00:00, 173.51it/s, train_loss=0.00635, val_loss=0.00759]Epoch 9:  69%|██████▉   | 20/29 [00:00<00:00, 175.50it/s, train_loss=0.00635, val_loss=0.00759]Epoch 9:  69%|██████▉   | 20/29 [00:00<00:00, 173.74it/s, train_loss=0.00613, val_loss=0.00759]Epoch 9:  72%|███████▏  | 21/29 [00:00<00:00, 176.33it/s, train_loss=0.00613, val_loss=0.00759]Epoch 9:  72%|███████▏  | 21/29 [00:00<00:00, 173.61it/s, train_loss=0.00486, val_loss=0.00759]Epoch 9:  76%|███████▌  | 22/29 [00:00<00:00, 176.34it/s, train_loss=0.00486, val_loss=0.00759]Epoch 9:  76%|███████▌  | 22/29 [00:00<00:00, 173.55it/s, train_loss=0.00666, val_loss=0.00759]Epoch 9:  79%|███████▉  | 23/29 [00:00<00:00, 175.92it/s, train_loss=0.00666, val_loss=0.00759]Epoch 9:  79%|███████▉  | 23/29 [00:00<00:00, 173.49it/s, train_loss=0.00887, val_loss=0.00759]Epoch 9:  83%|████████▎ | 24/29 [00:00<00:00, 176.02it/s, train_loss=0.00887, val_loss=0.00759]Epoch 9:  83%|████████▎ | 24/29 [00:00<00:00, 173.51it/s, train_loss=0.00401, val_loss=0.00759]Epoch 9:  86%|████████▌ | 25/29 [00:00<00:00, 175.95it/s, train_loss=0.00401, val_loss=0.00759]Epoch 9:  86%|████████▌ | 25/29 [00:00<00:00, 173.55it/s, train_loss=0.00524, val_loss=0.00759]Epoch 9:  90%|████████▉ | 26/29 [00:00<00:00, 175.28it/s, train_loss=0.00524, val_loss=0.00759]Epoch 9:  90%|████████▉ | 26/29 [00:00<00:00, 173.63it/s, train_loss=0.00473, val_loss=0.00759]Epoch 9:  93%|█████████▎| 27/29 [00:00<00:00, 175.40it/s, train_loss=0.00473, val_loss=0.00759]Epoch 9:  93%|█████████▎| 27/29 [00:00<00:00, 173.56it/s, train_loss=0.0059, val_loss=0.00759] Epoch 9:  97%|█████████▋| 28/29 [00:00<00:00, 175.54it/s, train_loss=0.0059, val_loss=0.00759]Epoch 9:  97%|█████████▋| 28/29 [00:00<00:00, 173.56it/s, train_loss=0.0061, val_loss=0.00759]Epoch 9: 100%|██████████| 29/29 [00:00<00:00, 175.66it/s, train_loss=0.0061, val_loss=0.00759]Epoch 9: 100%|██████████| 29/29 [00:00<00:00, 173.51it/s, train_loss=0.00362, val_loss=0.00759]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 169.49it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 213.24it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 228.68it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 236.96it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 239.81it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 241.20it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 242.13it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 242.88it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 243.28it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 246.03it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 247.13it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 247.23it/s][A
                                                                         [AEpoch 9: 100%|██████████| 29/29 [00:00<00:00, 128.85it/s, train_loss=0.00362, val_loss=0.00661]Epoch 9: 100%|██████████| 29/29 [00:00<00:00, 128.23it/s, train_loss=0.00362, val_loss=0.00661]Epoch 9:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00362, val_loss=0.00661]          Epoch 10:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00362, val_loss=0.00661]Epoch 10:   3%|▎         | 1/29 [00:00<00:00, 183.31it/s, train_loss=0.00362, val_loss=0.00661]Epoch 10:   3%|▎         | 1/29 [00:00<00:00, 146.39it/s, train_loss=0.00531, val_loss=0.00661]Epoch 10:   7%|▋         | 2/29 [00:00<00:00, 185.57it/s, train_loss=0.00531, val_loss=0.00661]Epoch 10:   7%|▋         | 2/29 [00:00<00:00, 158.57it/s, train_loss=0.00533, val_loss=0.00661]Epoch 10:  10%|█         | 3/29 [00:00<00:00, 183.25it/s, train_loss=0.00533, val_loss=0.00661]Epoch 10:  10%|█         | 3/29 [00:00<00:00, 162.44it/s, train_loss=0.00747, val_loss=0.00661]Epoch 10:  14%|█▍        | 4/29 [00:00<00:00, 180.72it/s, train_loss=0.00747, val_loss=0.00661]Epoch 10:  14%|█▍        | 4/29 [00:00<00:00, 164.89it/s, train_loss=0.00479, val_loss=0.00661]Epoch 10:  17%|█▋        | 5/29 [00:00<00:00, 179.25it/s, train_loss=0.00479, val_loss=0.00661]Epoch 10:  17%|█▋        | 5/29 [00:00<00:00, 166.39it/s, train_loss=0.00552, val_loss=0.00661]Epoch 10:  21%|██        | 6/29 [00:00<00:00, 177.32it/s, train_loss=0.00552, val_loss=0.00661]Epoch 10:  21%|██        | 6/29 [00:00<00:00, 173.83it/s, train_loss=0.00743, val_loss=0.00661]Epoch 10:  24%|██▍       | 7/29 [00:00<00:00, 182.64it/s, train_loss=0.00743, val_loss=0.00661]Epoch 10:  24%|██▍       | 7/29 [00:00<00:00, 179.66it/s, train_loss=0.00676, val_loss=0.00661]Epoch 10:  28%|██▊       | 8/29 [00:00<00:00, 185.94it/s, train_loss=0.00676, val_loss=0.00661]Epoch 10:  28%|██▊       | 8/29 [00:00<00:00, 180.51it/s, train_loss=0.00467, val_loss=0.00661]Epoch 10:  31%|███       | 9/29 [00:00<00:00, 186.63it/s, train_loss=0.00467, val_loss=0.00661]Epoch 10:  31%|███       | 9/29 [00:00<00:00, 179.65it/s, train_loss=0.00488, val_loss=0.00661]Epoch 10:  34%|███▍      | 10/29 [00:00<00:00, 185.10it/s, train_loss=0.00488, val_loss=0.00661]Epoch 10:  34%|███▍      | 10/29 [00:00<00:00, 178.88it/s, train_loss=0.0043, val_loss=0.00661] Epoch 10:  38%|███▊      | 11/29 [00:00<00:00, 183.82it/s, train_loss=0.0043, val_loss=0.00661]Epoch 10:  38%|███▊      | 11/29 [00:00<00:00, 178.45it/s, train_loss=0.005, val_loss=0.00661] Epoch 10:  41%|████▏     | 12/29 [00:00<00:00, 184.01it/s, train_loss=0.005, val_loss=0.00661]Epoch 10:  41%|████▏     | 12/29 [00:00<00:00, 178.13it/s, train_loss=0.0069, val_loss=0.00661]Epoch 10:  45%|████▍     | 13/29 [00:00<00:00, 181.93it/s, train_loss=0.0069, val_loss=0.00661]Epoch 10:  45%|████▍     | 13/29 [00:00<00:00, 178.48it/s, train_loss=0.00346, val_loss=0.00661]Epoch 10:  48%|████▊     | 14/29 [00:00<00:00, 182.78it/s, train_loss=0.00346, val_loss=0.00661]Epoch 10:  48%|████▊     | 14/29 [00:00<00:00, 178.05it/s, train_loss=0.00347, val_loss=0.00661]Epoch 10:  52%|█████▏    | 15/29 [00:00<00:00, 182.42it/s, train_loss=0.00347, val_loss=0.00661]Epoch 10:  52%|█████▏    | 15/29 [00:00<00:00, 177.76it/s, train_loss=0.00683, val_loss=0.00661]Epoch 10:  55%|█████▌    | 16/29 [00:00<00:00, 181.74it/s, train_loss=0.00683, val_loss=0.00661]Epoch 10:  55%|█████▌    | 16/29 [00:00<00:00, 177.46it/s, train_loss=0.00425, val_loss=0.00661]Epoch 10:  59%|█████▊    | 17/29 [00:00<00:00, 181.20it/s, train_loss=0.00425, val_loss=0.00661]Epoch 10:  59%|█████▊    | 17/29 [00:00<00:00, 177.22it/s, train_loss=0.00616, val_loss=0.00661]Epoch 10:  62%|██████▏   | 18/29 [00:00<00:00, 180.75it/s, train_loss=0.00616, val_loss=0.00661]Epoch 10:  62%|██████▏   | 18/29 [00:00<00:00, 176.99it/s, train_loss=0.00539, val_loss=0.00661]Epoch 10:  66%|██████▌   | 19/29 [00:00<00:00, 179.33it/s, train_loss=0.00539, val_loss=0.00661]Epoch 10:  66%|██████▌   | 19/29 [00:00<00:00, 177.70it/s, train_loss=0.00382, val_loss=0.00661]Epoch 10:  69%|██████▉   | 20/29 [00:00<00:00, 180.66it/s, train_loss=0.00382, val_loss=0.00661]Epoch 10:  69%|██████▉   | 20/29 [00:00<00:00, 177.34it/s, train_loss=0.00667, val_loss=0.00661]Epoch 10:  72%|███████▏  | 21/29 [00:00<00:00, 180.29it/s, train_loss=0.00667, val_loss=0.00661]Epoch 10:  72%|███████▏  | 21/29 [00:00<00:00, 177.16it/s, train_loss=0.006, val_loss=0.00661]  Epoch 10:  76%|███████▌  | 22/29 [00:00<00:00, 180.69it/s, train_loss=0.006, val_loss=0.00661]Epoch 10:  76%|███████▌  | 22/29 [00:00<00:00, 179.87it/s, train_loss=0.00935, val_loss=0.00661]Epoch 10:  79%|███████▉  | 23/29 [00:00<00:00, 183.18it/s, train_loss=0.00935, val_loss=0.00661]Epoch 10:  79%|███████▉  | 23/29 [00:00<00:00, 179.96it/s, train_loss=0.00502, val_loss=0.00661]Epoch 10:  83%|████████▎ | 24/29 [00:00<00:00, 182.98it/s, train_loss=0.00502, val_loss=0.00661]Epoch 10:  83%|████████▎ | 24/29 [00:00<00:00, 182.06it/s, train_loss=0.00509, val_loss=0.00661]Epoch 10:  86%|████████▌ | 25/29 [00:00<00:00, 185.04it/s, train_loss=0.00509, val_loss=0.00661]Epoch 10:  86%|████████▌ | 25/29 [00:00<00:00, 182.52it/s, train_loss=0.00607, val_loss=0.00661]Epoch 10:  90%|████████▉ | 26/29 [00:00<00:00, 184.43it/s, train_loss=0.00607, val_loss=0.00661]Epoch 10:  90%|████████▉ | 26/29 [00:00<00:00, 182.92it/s, train_loss=0.00324, val_loss=0.00661]Epoch 10:  93%|█████████▎| 27/29 [00:00<00:00, 184.76it/s, train_loss=0.00324, val_loss=0.00661]Epoch 10:  93%|█████████▎| 27/29 [00:00<00:00, 182.47it/s, train_loss=0.00625, val_loss=0.00661]Epoch 10:  97%|█████████▋| 28/29 [00:00<00:00, 184.94it/s, train_loss=0.00625, val_loss=0.00661]Epoch 10:  97%|█████████▋| 28/29 [00:00<00:00, 182.13it/s, train_loss=0.00362, val_loss=0.00661]Epoch 10: 100%|██████████| 29/29 [00:00<00:00, 184.44it/s, train_loss=0.00362, val_loss=0.00661]Epoch 10: 100%|██████████| 29/29 [00:00<00:00, 181.78it/s, train_loss=0.00837, val_loss=0.00661]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 166.59it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 201.10it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 222.45it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 236.22it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 244.80it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 249.50it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 252.61it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 254.13it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 255.57it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 256.23it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 257.92it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 259.74it/s][A
                                                                         [AEpoch 10: 100%|██████████| 29/29 [00:00<00:00, 134.31it/s, train_loss=0.00837, val_loss=0.00604]Epoch 10: 100%|██████████| 29/29 [00:00<00:00, 133.65it/s, train_loss=0.00837, val_loss=0.00604]Epoch 10:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00837, val_loss=0.00604]          Epoch 11:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00837, val_loss=0.00604]Epoch 11:   3%|▎         | 1/29 [00:00<00:00, 175.41it/s, train_loss=0.00837, val_loss=0.00604]Epoch 11:   3%|▎         | 1/29 [00:00<00:00, 126.74it/s, train_loss=0.0055, val_loss=0.00604] Epoch 11:   7%|▋         | 2/29 [00:00<00:00, 170.21it/s, train_loss=0.0055, val_loss=0.00604]Epoch 11:   7%|▋         | 2/29 [00:00<00:00, 146.14it/s, train_loss=0.00399, val_loss=0.00604]Epoch 11:  10%|█         | 3/29 [00:00<00:00, 176.66it/s, train_loss=0.00399, val_loss=0.00604]Epoch 11:  10%|█         | 3/29 [00:00<00:00, 171.26it/s, train_loss=0.00731, val_loss=0.00604]Epoch 11:  14%|█▍        | 4/29 [00:00<00:00, 192.17it/s, train_loss=0.00731, val_loss=0.00604]Epoch 11:  14%|█▍        | 4/29 [00:00<00:00, 173.57it/s, train_loss=0.00511, val_loss=0.00604]Epoch 11:  17%|█▋        | 5/29 [00:00<00:00, 189.40it/s, train_loss=0.00511, val_loss=0.00604]Epoch 11:  17%|█▋        | 5/29 [00:00<00:00, 185.39it/s, train_loss=0.0052, val_loss=0.00604] Epoch 11:  21%|██        | 6/29 [00:00<00:00, 198.43it/s, train_loss=0.0052, val_loss=0.00604]Epoch 11:  21%|██        | 6/29 [00:00<00:00, 185.66it/s, train_loss=0.0061, val_loss=0.00604]Epoch 11:  24%|██▍       | 7/29 [00:00<00:00, 195.73it/s, train_loss=0.0061, val_loss=0.00604]Epoch 11:  24%|██▍       | 7/29 [00:00<00:00, 191.74it/s, train_loss=0.00612, val_loss=0.00604]Epoch 11:  28%|██▊       | 8/29 [00:00<00:00, 196.86it/s, train_loss=0.00612, val_loss=0.00604]Epoch 11:  28%|██▊       | 8/29 [00:00<00:00, 186.70it/s, train_loss=0.00573, val_loss=0.00604]Epoch 11:  31%|███       | 9/29 [00:00<00:00, 193.60it/s, train_loss=0.00573, val_loss=0.00604]Epoch 11:  31%|███       | 9/29 [00:00<00:00, 185.03it/s, train_loss=0.00637, val_loss=0.00604]Epoch 11:  34%|███▍      | 10/29 [00:00<00:00, 191.90it/s, train_loss=0.00637, val_loss=0.00604]Epoch 11:  34%|███▍      | 10/29 [00:00<00:00, 183.66it/s, train_loss=0.0033, val_loss=0.00604] Epoch 11:  38%|███▊      | 11/29 [00:00<00:00, 189.85it/s, train_loss=0.0033, val_loss=0.00604]Epoch 11:  38%|███▊      | 11/29 [00:00<00:00, 182.47it/s, train_loss=0.00521, val_loss=0.00604]Epoch 11:  41%|████▏     | 12/29 [00:00<00:00, 187.92it/s, train_loss=0.00521, val_loss=0.00604]Epoch 11:  41%|████▏     | 12/29 [00:00<00:00, 181.74it/s, train_loss=0.00423, val_loss=0.00604]Epoch 11:  45%|████▍     | 13/29 [00:00<00:00, 186.35it/s, train_loss=0.00423, val_loss=0.00604]Epoch 11:  45%|████▍     | 13/29 [00:00<00:00, 184.56it/s, train_loss=0.00679, val_loss=0.00604]Epoch 11:  48%|████▊     | 14/29 [00:00<00:00, 188.10it/s, train_loss=0.00679, val_loss=0.00604]Epoch 11:  48%|████▊     | 14/29 [00:00<00:00, 182.82it/s, train_loss=0.00502, val_loss=0.00604]Epoch 11:  52%|█████▏    | 15/29 [00:00<00:00, 186.59it/s, train_loss=0.00502, val_loss=0.00604]Epoch 11:  52%|█████▏    | 15/29 [00:00<00:00, 182.12it/s, train_loss=0.00481, val_loss=0.00604]Epoch 11:  55%|█████▌    | 16/29 [00:00<00:00, 186.10it/s, train_loss=0.00481, val_loss=0.00604]Epoch 11:  55%|█████▌    | 16/29 [00:00<00:00, 181.46it/s, train_loss=0.00788, val_loss=0.00604]Epoch 11:  59%|█████▊    | 17/29 [00:00<00:00, 185.33it/s, train_loss=0.00788, val_loss=0.00604]Epoch 11:  59%|█████▊    | 17/29 [00:00<00:00, 180.85it/s, train_loss=0.00298, val_loss=0.00604]Epoch 11:  62%|██████▏   | 18/29 [00:00<00:00, 184.38it/s, train_loss=0.00298, val_loss=0.00604]Epoch 11:  62%|██████▏   | 18/29 [00:00<00:00, 180.46it/s, train_loss=0.00685, val_loss=0.00604]Epoch 11:  66%|██████▌   | 19/29 [00:00<00:00, 183.55it/s, train_loss=0.00685, val_loss=0.00604]Epoch 11:  66%|██████▌   | 19/29 [00:00<00:00, 182.12it/s, train_loss=0.00331, val_loss=0.00604]Epoch 11:  69%|██████▉   | 20/29 [00:00<00:00, 184.48it/s, train_loss=0.00331, val_loss=0.00604]Epoch 11:  69%|██████▉   | 20/29 [00:00<00:00, 181.56it/s, train_loss=0.00571, val_loss=0.00604]Epoch 11:  72%|███████▏  | 21/29 [00:00<00:00, 184.11it/s, train_loss=0.00571, val_loss=0.00604]Epoch 11:  72%|███████▏  | 21/29 [00:00<00:00, 181.16it/s, train_loss=0.00418, val_loss=0.00604]Epoch 11:  76%|███████▌  | 22/29 [00:00<00:00, 183.84it/s, train_loss=0.00418, val_loss=0.00604]Epoch 11:  76%|███████▌  | 22/29 [00:00<00:00, 180.71it/s, train_loss=0.00452, val_loss=0.00604]Epoch 11:  79%|███████▉  | 23/29 [00:00<00:00, 183.92it/s, train_loss=0.00452, val_loss=0.00604]Epoch 11:  79%|███████▉  | 23/29 [00:00<00:00, 183.05it/s, train_loss=0.00404, val_loss=0.00604]Epoch 11:  83%|████████▎ | 24/29 [00:00<00:00, 186.14it/s, train_loss=0.00404, val_loss=0.00604]Epoch 11:  83%|████████▎ | 24/29 [00:00<00:00, 183.21it/s, train_loss=0.00269, val_loss=0.00604]Epoch 11:  86%|████████▌ | 25/29 [00:00<00:00, 186.10it/s, train_loss=0.00269, val_loss=0.00604]Epoch 11:  86%|████████▌ | 25/29 [00:00<00:00, 185.23it/s, train_loss=0.00556, val_loss=0.00604]Epoch 11:  90%|████████▉ | 26/29 [00:00<00:00, 187.89it/s, train_loss=0.00556, val_loss=0.00604]Epoch 11:  90%|████████▉ | 26/29 [00:00<00:00, 187.02it/s, train_loss=0.00421, val_loss=0.00604]Epoch 11:  93%|█████████▎| 27/29 [00:00<00:00, 189.08it/s, train_loss=0.00421, val_loss=0.00604]Epoch 11:  93%|█████████▎| 27/29 [00:00<00:00, 186.54it/s, train_loss=0.00366, val_loss=0.00604]Epoch 11:  97%|█████████▋| 28/29 [00:00<00:00, 188.55it/s, train_loss=0.00366, val_loss=0.00604]Epoch 11:  97%|█████████▋| 28/29 [00:00<00:00, 186.04it/s, train_loss=0.00435, val_loss=0.00604]Epoch 11: 100%|██████████| 29/29 [00:00<00:00, 188.40it/s, train_loss=0.00435, val_loss=0.00604]Epoch 11: 100%|██████████| 29/29 [00:00<00:00, 185.57it/s, train_loss=0.00828, val_loss=0.00604]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 183.99it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 227.54it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 243.22it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 253.53it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 258.05it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 261.11it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 262.64it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 264.42it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 266.10it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 268.11it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 268.29it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 268.29it/s][A
                                                                         [AEpoch 11: 100%|██████████| 29/29 [00:00<00:00, 138.25it/s, train_loss=0.00828, val_loss=0.00573]Epoch 11: 100%|██████████| 29/29 [00:00<00:00, 137.56it/s, train_loss=0.00828, val_loss=0.00573]Epoch 11:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00828, val_loss=0.00573]          Epoch 12:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00828, val_loss=0.00573]Epoch 12:   3%|▎         | 1/29 [00:00<00:00, 204.16it/s, train_loss=0.00828, val_loss=0.00573]Epoch 12:   3%|▎         | 1/29 [00:00<00:00, 169.58it/s, train_loss=0.00308, val_loss=0.00573]Epoch 12:   7%|▋         | 2/29 [00:00<00:00, 205.68it/s, train_loss=0.00308, val_loss=0.00573]Epoch 12:   7%|▋         | 2/29 [00:00<00:00, 187.83it/s, train_loss=0.00625, val_loss=0.00573]Epoch 12:  10%|█         | 3/29 [00:00<00:00, 202.35it/s, train_loss=0.00625, val_loss=0.00573]Epoch 12:  10%|█         | 3/29 [00:00<00:00, 183.78it/s, train_loss=0.00537, val_loss=0.00573]Epoch 12:  14%|█▍        | 4/29 [00:00<00:00, 197.48it/s, train_loss=0.00537, val_loss=0.00573]Epoch 12:  14%|█▍        | 4/29 [00:00<00:00, 180.17it/s, train_loss=0.00517, val_loss=0.00573]Epoch 12:  17%|█▋        | 5/29 [00:00<00:00, 196.36it/s, train_loss=0.00517, val_loss=0.00573]Epoch 12:  17%|█▋        | 5/29 [00:00<00:00, 191.92it/s, train_loss=0.00384, val_loss=0.00573]Epoch 12:  21%|██        | 6/29 [00:00<00:00, 203.90it/s, train_loss=0.00384, val_loss=0.00573]Epoch 12:  21%|██        | 6/29 [00:00<00:00, 189.75it/s, train_loss=0.00604, val_loss=0.00573]Epoch 12:  24%|██▍       | 7/29 [00:00<00:00, 200.11it/s, train_loss=0.00604, val_loss=0.00573]Epoch 12:  24%|██▍       | 7/29 [00:00<00:00, 196.54it/s, train_loss=0.00405, val_loss=0.00573]Epoch 12:  28%|██▊       | 8/29 [00:00<00:00, 205.22it/s, train_loss=0.00405, val_loss=0.00573]Epoch 12:  28%|██▊       | 8/29 [00:00<00:00, 195.74it/s, train_loss=0.00375, val_loss=0.00573]Epoch 12:  31%|███       | 9/29 [00:00<00:00, 203.13it/s, train_loss=0.00375, val_loss=0.00573]Epoch 12:  31%|███       | 9/29 [00:00<00:00, 198.40it/s, train_loss=0.00394, val_loss=0.00573]Epoch 12:  34%|███▍      | 10/29 [00:00<00:00, 203.07it/s, train_loss=0.00394, val_loss=0.00573]Epoch 12:  34%|███▍      | 10/29 [00:00<00:00, 200.45it/s, train_loss=0.00576, val_loss=0.00573]Epoch 12:  38%|███▊      | 11/29 [00:00<00:00, 204.47it/s, train_loss=0.00576, val_loss=0.00573]Epoch 12:  38%|███▊      | 11/29 [00:00<00:00, 199.37it/s, train_loss=0.00316, val_loss=0.00573]Epoch 12:  41%|████▏     | 12/29 [00:00<00:00, 204.05it/s, train_loss=0.00316, val_loss=0.00573]Epoch 12:  41%|████▏     | 12/29 [00:00<00:00, 196.88it/s, train_loss=0.0028, val_loss=0.00573] Epoch 12:  45%|████▍     | 13/29 [00:00<00:00, 201.58it/s, train_loss=0.0028, val_loss=0.00573]Epoch 12:  45%|████▍     | 13/29 [00:00<00:00, 194.63it/s, train_loss=0.0052, val_loss=0.00573]Epoch 12:  48%|████▊     | 14/29 [00:00<00:00, 199.03it/s, train_loss=0.0052, val_loss=0.00573]Epoch 12:  48%|████▊     | 14/29 [00:00<00:00, 192.97it/s, train_loss=0.00648, val_loss=0.00573]Epoch 12:  52%|█████▏    | 15/29 [00:00<00:00, 197.00it/s, train_loss=0.00648, val_loss=0.00573]Epoch 12:  52%|█████▏    | 15/29 [00:00<00:00, 191.57it/s, train_loss=0.00601, val_loss=0.00573]Epoch 12:  55%|█████▌    | 16/29 [00:00<00:00, 194.31it/s, train_loss=0.00601, val_loss=0.00573]Epoch 12:  55%|█████▌    | 16/29 [00:00<00:00, 191.27it/s, train_loss=0.0062, val_loss=0.00573] Epoch 12:  59%|█████▊    | 17/29 [00:00<00:00, 194.20it/s, train_loss=0.0062, val_loss=0.00573]Epoch 12:  59%|█████▊    | 17/29 [00:00<00:00, 190.05it/s, train_loss=0.00426, val_loss=0.00573]Epoch 12:  62%|██████▏   | 18/29 [00:00<00:00, 193.39it/s, train_loss=0.00426, val_loss=0.00573]Epoch 12:  62%|██████▏   | 18/29 [00:00<00:00, 189.09it/s, train_loss=0.00544, val_loss=0.00573]Epoch 12:  66%|██████▌   | 19/29 [00:00<00:00, 192.07it/s, train_loss=0.00544, val_loss=0.00573]Epoch 12:  66%|██████▌   | 19/29 [00:00<00:00, 188.21it/s, train_loss=0.0033, val_loss=0.00573] Epoch 12:  69%|██████▉   | 20/29 [00:00<00:00, 191.10it/s, train_loss=0.0033, val_loss=0.00573]Epoch 12:  69%|██████▉   | 20/29 [00:00<00:00, 187.48it/s, train_loss=0.00379, val_loss=0.00573]Epoch 12:  72%|███████▏  | 21/29 [00:00<00:00, 190.22it/s, train_loss=0.00379, val_loss=0.00573]Epoch 12:  72%|███████▏  | 21/29 [00:00<00:00, 186.76it/s, train_loss=0.00385, val_loss=0.00573]Epoch 12:  76%|███████▌  | 22/29 [00:00<00:00, 188.94it/s, train_loss=0.00385, val_loss=0.00573]Epoch 12:  76%|███████▌  | 22/29 [00:00<00:00, 186.85it/s, train_loss=0.00728, val_loss=0.00573]Epoch 12:  79%|███████▉  | 23/29 [00:00<00:00, 189.17it/s, train_loss=0.00728, val_loss=0.00573]Epoch 12:  79%|███████▉  | 23/29 [00:00<00:00, 186.11it/s, train_loss=0.0056, val_loss=0.00573] Epoch 12:  83%|████████▎ | 24/29 [00:00<00:00, 189.13it/s, train_loss=0.0056, val_loss=0.00573]Epoch 12:  83%|████████▎ | 24/29 [00:00<00:00, 188.23it/s, train_loss=0.00684, val_loss=0.00573]Epoch 12:  86%|████████▌ | 25/29 [00:00<00:00, 191.16it/s, train_loss=0.00684, val_loss=0.00573]Epoch 12:  86%|████████▌ | 25/29 [00:00<00:00, 188.14it/s, train_loss=0.00442, val_loss=0.00573]Epoch 12:  90%|████████▉ | 26/29 [00:00<00:00, 190.85it/s, train_loss=0.00442, val_loss=0.00573]Epoch 12:  90%|████████▉ | 26/29 [00:00<00:00, 190.01it/s, train_loss=0.0045, val_loss=0.00573] Epoch 12:  93%|█████████▎| 27/29 [00:00<00:00, 192.67it/s, train_loss=0.0045, val_loss=0.00573]Epoch 12:  93%|█████████▎| 27/29 [00:00<00:00, 189.98it/s, train_loss=0.00365, val_loss=0.00573]Epoch 12:  97%|█████████▋| 28/29 [00:00<00:00, 192.45it/s, train_loss=0.00365, val_loss=0.00573]Epoch 12:  97%|█████████▋| 28/29 [00:00<00:00, 191.51it/s, train_loss=0.00356, val_loss=0.00573]Epoch 12: 100%|██████████| 29/29 [00:00<00:00, 193.31it/s, train_loss=0.00356, val_loss=0.00573]Epoch 12: 100%|██████████| 29/29 [00:00<00:00, 190.47it/s, train_loss=0.00254, val_loss=0.00573]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 200.39it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 236.49it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 251.96it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 261.53it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 267.12it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 271.40it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 274.80it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 279.15it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 280.07it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 280.68it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 280.83it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 281.53it/s][A
                                                                         [AEpoch 12: 100%|██████████| 29/29 [00:00<00:00, 142.28it/s, train_loss=0.00254, val_loss=0.00534]Epoch 12: 100%|██████████| 29/29 [00:00<00:00, 141.60it/s, train_loss=0.00254, val_loss=0.00534]Epoch 12:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00254, val_loss=0.00534]          Epoch 13:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00254, val_loss=0.00534]Epoch 13:   3%|▎         | 1/29 [00:00<00:00, 207.89it/s, train_loss=0.00254, val_loss=0.00534]Epoch 13:   3%|▎         | 1/29 [00:00<00:00, 144.72it/s, train_loss=0.00543, val_loss=0.00534]Epoch 13:   7%|▋         | 2/29 [00:00<00:00, 189.56it/s, train_loss=0.00543, val_loss=0.00534]Epoch 13:   7%|▋         | 2/29 [00:00<00:00, 157.07it/s, train_loss=0.00412, val_loss=0.00534]Epoch 13:  10%|█         | 3/29 [00:00<00:00, 184.12it/s, train_loss=0.00412, val_loss=0.00534]Epoch 13:  10%|█         | 3/29 [00:00<00:00, 161.45it/s, train_loss=0.00491, val_loss=0.00534]Epoch 13:  14%|█▍        | 4/29 [00:00<00:00, 180.32it/s, train_loss=0.00491, val_loss=0.00534]Epoch 13:  14%|█▍        | 4/29 [00:00<00:00, 164.12it/s, train_loss=0.0061, val_loss=0.00534] Epoch 13:  17%|█▋        | 5/29 [00:00<00:00, 178.56it/s, train_loss=0.0061, val_loss=0.00534]Epoch 13:  17%|█▋        | 5/29 [00:00<00:00, 165.88it/s, train_loss=0.00593, val_loss=0.00534]Epoch 13:  21%|██        | 6/29 [00:00<00:00, 180.01it/s, train_loss=0.00593, val_loss=0.00534]Epoch 13:  21%|██        | 6/29 [00:00<00:00, 176.92it/s, train_loss=0.0054, val_loss=0.00534] Epoch 13:  24%|██▍       | 7/29 [00:00<00:00, 187.18it/s, train_loss=0.0054, val_loss=0.00534]Epoch 13:  24%|██▍       | 7/29 [00:00<00:00, 179.60it/s, train_loss=0.00424, val_loss=0.00534]Epoch 13:  28%|██▊       | 8/29 [00:00<00:00, 187.76it/s, train_loss=0.00424, val_loss=0.00534]Epoch 13:  28%|██▊       | 8/29 [00:00<00:00, 178.58it/s, train_loss=0.00423, val_loss=0.00534]Epoch 13:  31%|███       | 9/29 [00:00<00:00, 186.15it/s, train_loss=0.00423, val_loss=0.00534]Epoch 13:  31%|███       | 9/29 [00:00<00:00, 177.97it/s, train_loss=0.00478, val_loss=0.00534]Epoch 13:  34%|███▍      | 10/29 [00:00<00:00, 184.90it/s, train_loss=0.00478, val_loss=0.00534]Epoch 13:  34%|███▍      | 10/29 [00:00<00:00, 177.46it/s, train_loss=0.00503, val_loss=0.00534]Epoch 13:  38%|███▊      | 11/29 [00:00<00:00, 183.63it/s, train_loss=0.00503, val_loss=0.00534]Epoch 13:  38%|███▊      | 11/29 [00:00<00:00, 177.04it/s, train_loss=0.00598, val_loss=0.00534]Epoch 13:  41%|████▏     | 12/29 [00:00<00:00, 182.57it/s, train_loss=0.00598, val_loss=0.00534]Epoch 13:  41%|████▏     | 12/29 [00:00<00:00, 176.70it/s, train_loss=0.00462, val_loss=0.00534]Epoch 13:  45%|████▍     | 13/29 [00:00<00:00, 180.92it/s, train_loss=0.00462, val_loss=0.00534]Epoch 13:  45%|████▍     | 13/29 [00:00<00:00, 177.39it/s, train_loss=0.00526, val_loss=0.00534]Epoch 13:  48%|████▊     | 14/29 [00:00<00:00, 181.64it/s, train_loss=0.00526, val_loss=0.00534]Epoch 13:  48%|████▊     | 14/29 [00:00<00:00, 176.90it/s, train_loss=0.00351, val_loss=0.00534]Epoch 13:  52%|█████▏    | 15/29 [00:00<00:00, 181.30it/s, train_loss=0.00351, val_loss=0.00534]Epoch 13:  52%|█████▏    | 15/29 [00:00<00:00, 176.62it/s, train_loss=0.00293, val_loss=0.00534]Epoch 13:  55%|█████▌    | 16/29 [00:00<00:00, 180.45it/s, train_loss=0.00293, val_loss=0.00534]Epoch 13:  55%|█████▌    | 16/29 [00:00<00:00, 176.31it/s, train_loss=0.00401, val_loss=0.00534]Epoch 13:  59%|█████▊    | 17/29 [00:00<00:00, 179.95it/s, train_loss=0.00401, val_loss=0.00534]Epoch 13:  59%|█████▊    | 17/29 [00:00<00:00, 176.05it/s, train_loss=0.0036, val_loss=0.00534] Epoch 13:  62%|██████▏   | 18/29 [00:00<00:00, 179.54it/s, train_loss=0.0036, val_loss=0.00534]Epoch 13:  62%|██████▏   | 18/29 [00:00<00:00, 175.92it/s, train_loss=0.00336, val_loss=0.00534]Epoch 13:  66%|██████▌   | 19/29 [00:00<00:00, 179.06it/s, train_loss=0.00336, val_loss=0.00534]Epoch 13:  66%|██████▌   | 19/29 [00:00<00:00, 176.24it/s, train_loss=0.0037, val_loss=0.00534] Epoch 13:  69%|██████▉   | 20/29 [00:00<00:00, 179.38it/s, train_loss=0.0037, val_loss=0.00534]Epoch 13:  69%|██████▉   | 20/29 [00:00<00:00, 176.03it/s, train_loss=0.00424, val_loss=0.00534]Epoch 13:  72%|███████▏  | 21/29 [00:00<00:00, 179.32it/s, train_loss=0.00424, val_loss=0.00534]Epoch 13:  72%|███████▏  | 21/29 [00:00<00:00, 175.86it/s, train_loss=0.00324, val_loss=0.00534]Epoch 13:  76%|███████▌  | 22/29 [00:00<00:00, 178.96it/s, train_loss=0.00324, val_loss=0.00534]Epoch 13:  76%|███████▌  | 22/29 [00:00<00:00, 175.69it/s, train_loss=0.00394, val_loss=0.00534]Epoch 13:  79%|███████▉  | 23/29 [00:00<00:00, 178.59it/s, train_loss=0.00394, val_loss=0.00534]Epoch 13:  79%|███████▉  | 23/29 [00:00<00:00, 175.59it/s, train_loss=0.00341, val_loss=0.00534]Epoch 13:  83%|████████▎ | 24/29 [00:00<00:00, 178.34it/s, train_loss=0.00341, val_loss=0.00534]Epoch 13:  83%|████████▎ | 24/29 [00:00<00:00, 175.53it/s, train_loss=0.00381, val_loss=0.00534]Epoch 13:  86%|████████▌ | 25/29 [00:00<00:00, 178.40it/s, train_loss=0.00381, val_loss=0.00534]Epoch 13:  86%|████████▌ | 25/29 [00:00<00:00, 175.92it/s, train_loss=0.00457, val_loss=0.00534]Epoch 13:  90%|████████▉ | 26/29 [00:00<00:00, 178.78it/s, train_loss=0.00457, val_loss=0.00534]Epoch 13:  90%|████████▉ | 26/29 [00:00<00:00, 178.12it/s, train_loss=0.00382, val_loss=0.00534]Epoch 13:  93%|█████████▎| 27/29 [00:00<00:00, 180.95it/s, train_loss=0.00382, val_loss=0.00534]Epoch 13:  93%|█████████▎| 27/29 [00:00<00:00, 178.31it/s, train_loss=0.00588, val_loss=0.00534]Epoch 13:  97%|█████████▋| 28/29 [00:00<00:00, 181.07it/s, train_loss=0.00588, val_loss=0.00534]Epoch 13:  97%|█████████▋| 28/29 [00:00<00:00, 180.31it/s, train_loss=0.00338, val_loss=0.00534]Epoch 13: 100%|██████████| 29/29 [00:00<00:00, 182.90it/s, train_loss=0.00338, val_loss=0.00534]Epoch 13: 100%|██████████| 29/29 [00:00<00:00, 180.41it/s, train_loss=0.0062, val_loss=0.00534] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 188.64it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 238.75it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 263.69it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 277.87it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 286.20it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 289.19it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 289.66it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 288.16it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 287.92it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 288.51it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 288.38it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 289.69it/s][A
                                                                         [AEpoch 13: 100%|██████████| 29/29 [00:00<00:00, 137.21it/s, train_loss=0.0062, val_loss=0.00499]Epoch 13: 100%|██████████| 29/29 [00:00<00:00, 136.55it/s, train_loss=0.0062, val_loss=0.00499]Epoch 13:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0062, val_loss=0.00499]          Epoch 14:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0062, val_loss=0.00499]Epoch 14:   3%|▎         | 1/29 [00:00<00:00, 211.15it/s, train_loss=0.0062, val_loss=0.00499]Epoch 14:   3%|▎         | 1/29 [00:00<00:00, 174.38it/s, train_loss=0.00513, val_loss=0.00499]Epoch 14:   7%|▋         | 2/29 [00:00<00:00, 215.85it/s, train_loss=0.00513, val_loss=0.00499]Epoch 14:   7%|▋         | 2/29 [00:00<00:00, 195.00it/s, train_loss=0.00511, val_loss=0.00499]Epoch 14:  10%|█         | 3/29 [00:00<00:00, 214.57it/s, train_loss=0.00511, val_loss=0.00499]Epoch 14:  10%|█         | 3/29 [00:00<00:00, 202.46it/s, train_loss=0.0042, val_loss=0.00499] Epoch 14:  14%|█▍        | 4/29 [00:00<00:00, 216.58it/s, train_loss=0.0042, val_loss=0.00499]Epoch 14:  14%|█▍        | 4/29 [00:00<00:00, 199.03it/s, train_loss=0.00342, val_loss=0.00499]Epoch 14:  17%|█▋        | 5/29 [00:00<00:00, 210.47it/s, train_loss=0.00342, val_loss=0.00499]Epoch 14:  17%|█▋        | 5/29 [00:00<00:00, 193.09it/s, train_loss=0.00413, val_loss=0.00499]Epoch 14:  21%|██        | 6/29 [00:00<00:00, 202.85it/s, train_loss=0.00413, val_loss=0.00499]Epoch 14:  21%|██        | 6/29 [00:00<00:00, 189.06it/s, train_loss=0.00547, val_loss=0.00499]Epoch 14:  24%|██▍       | 7/29 [00:00<00:00, 200.28it/s, train_loss=0.00547, val_loss=0.00499]Epoch 14:  24%|██▍       | 7/29 [00:00<00:00, 196.99it/s, train_loss=0.00402, val_loss=0.00499]Epoch 14:  28%|██▊       | 8/29 [00:00<00:00, 206.34it/s, train_loss=0.00402, val_loss=0.00499]Epoch 14:  28%|██▊       | 8/29 [00:00<00:00, 195.20it/s, train_loss=0.00726, val_loss=0.00499]Epoch 14:  31%|███       | 9/29 [00:00<00:00, 203.85it/s, train_loss=0.00726, val_loss=0.00499]Epoch 14:  31%|███       | 9/29 [00:00<00:00, 201.20it/s, train_loss=0.00581, val_loss=0.00499]Epoch 14:  34%|███▍      | 10/29 [00:00<00:00, 207.56it/s, train_loss=0.00581, val_loss=0.00499]Epoch 14:  34%|███▍      | 10/29 [00:00<00:00, 200.97it/s, train_loss=0.00342, val_loss=0.00499]Epoch 14:  38%|███▊      | 11/29 [00:00<00:00, 206.97it/s, train_loss=0.00342, val_loss=0.00499]Epoch 14:  38%|███▊      | 11/29 [00:00<00:00, 204.63it/s, train_loss=0.0032, val_loss=0.00499] Epoch 14:  41%|████▏     | 12/29 [00:00<00:00, 210.19it/s, train_loss=0.0032, val_loss=0.00499]Epoch 14:  41%|████▏     | 12/29 [00:00<00:00, 203.09it/s, train_loss=0.00455, val_loss=0.00499]Epoch 14:  45%|████▍     | 13/29 [00:00<00:00, 207.97it/s, train_loss=0.00455, val_loss=0.00499]Epoch 14:  45%|████▍     | 13/29 [00:00<00:00, 200.45it/s, train_loss=0.00305, val_loss=0.00499]Epoch 14:  48%|████▊     | 14/29 [00:00<00:00, 204.88it/s, train_loss=0.00305, val_loss=0.00499]Epoch 14:  48%|████▊     | 14/29 [00:00<00:00, 198.20it/s, train_loss=0.00353, val_loss=0.00499]Epoch 14:  52%|█████▏    | 15/29 [00:00<00:00, 202.58it/s, train_loss=0.00353, val_loss=0.00499]Epoch 14:  52%|█████▏    | 15/29 [00:00<00:00, 196.41it/s, train_loss=0.00542, val_loss=0.00499]Epoch 14:  55%|█████▌    | 16/29 [00:00<00:00, 200.26it/s, train_loss=0.00542, val_loss=0.00499]Epoch 14:  55%|█████▌    | 16/29 [00:00<00:00, 198.49it/s, train_loss=0.00314, val_loss=0.00499]Epoch 14:  59%|█████▊    | 17/29 [00:00<00:00, 201.55it/s, train_loss=0.00314, val_loss=0.00499]Epoch 14:  59%|█████▊    | 17/29 [00:00<00:00, 199.88it/s, train_loss=0.00429, val_loss=0.00499]Epoch 14:  62%|██████▏   | 18/29 [00:00<00:00, 203.19it/s, train_loss=0.00429, val_loss=0.00499]Epoch 14:  62%|██████▏   | 18/29 [00:00<00:00, 199.06it/s, train_loss=0.00606, val_loss=0.00499]Epoch 14:  66%|██████▌   | 19/29 [00:00<00:00, 202.23it/s, train_loss=0.00606, val_loss=0.00499]Epoch 14:  66%|██████▌   | 19/29 [00:00<00:00, 197.51it/s, train_loss=0.00279, val_loss=0.00499]Epoch 14:  69%|██████▉   | 20/29 [00:00<00:00, 200.50it/s, train_loss=0.00279, val_loss=0.00499]Epoch 14:  69%|██████▉   | 20/29 [00:00<00:00, 196.05it/s, train_loss=0.00261, val_loss=0.00499]Epoch 14:  72%|███████▏  | 21/29 [00:00<00:00, 198.87it/s, train_loss=0.00261, val_loss=0.00499]Epoch 14:  72%|███████▏  | 21/29 [00:00<00:00, 194.89it/s, train_loss=0.00492, val_loss=0.00499]Epoch 14:  76%|███████▌  | 22/29 [00:00<00:00, 197.55it/s, train_loss=0.00492, val_loss=0.00499]Epoch 14:  76%|███████▌  | 22/29 [00:00<00:00, 193.89it/s, train_loss=0.00464, val_loss=0.00499]Epoch 14:  79%|███████▉  | 23/29 [00:00<00:00, 196.11it/s, train_loss=0.00464, val_loss=0.00499]Epoch 14:  79%|███████▉  | 23/29 [00:00<00:00, 194.03it/s, train_loss=0.00242, val_loss=0.00499]Epoch 14:  83%|████████▎ | 24/29 [00:00<00:00, 196.12it/s, train_loss=0.00242, val_loss=0.00499]Epoch 14:  83%|████████▎ | 24/29 [00:00<00:00, 193.04it/s, train_loss=0.00421, val_loss=0.00499]Epoch 14:  86%|████████▌ | 25/29 [00:00<00:00, 195.22it/s, train_loss=0.00421, val_loss=0.00499]Epoch 14:  86%|████████▌ | 25/29 [00:00<00:00, 192.15it/s, train_loss=0.00451, val_loss=0.00499]Epoch 14:  90%|████████▉ | 26/29 [00:00<00:00, 195.00it/s, train_loss=0.00451, val_loss=0.00499]Epoch 14:  90%|████████▉ | 26/29 [00:00<00:00, 194.18it/s, train_loss=0.0025, val_loss=0.00499] Epoch 14:  93%|█████████▎| 27/29 [00:00<00:00, 197.01it/s, train_loss=0.0025, val_loss=0.00499]Epoch 14:  93%|█████████▎| 27/29 [00:00<00:00, 193.71it/s, train_loss=0.00393, val_loss=0.00499]Epoch 14:  97%|█████████▋| 28/29 [00:00<00:00, 196.20it/s, train_loss=0.00393, val_loss=0.00499]Epoch 14:  97%|█████████▋| 28/29 [00:00<00:00, 195.33it/s, train_loss=0.00257, val_loss=0.00499]Epoch 14: 100%|██████████| 29/29 [00:00<00:00, 197.79it/s, train_loss=0.00257, val_loss=0.00499]Epoch 14: 100%|██████████| 29/29 [00:00<00:00, 195.13it/s, train_loss=0.00448, val_loss=0.00499]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 216.72it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 266.70it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 283.01it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 289.54it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 291.63it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 292.07it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 292.26it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 294.57it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 297.65it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 299.32it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 300.33it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 298.79it/s][A
                                                                         [AEpoch 14: 100%|██████████| 29/29 [00:00<00:00, 146.72it/s, train_loss=0.00448, val_loss=0.00466]Epoch 14: 100%|██████████| 29/29 [00:00<00:00, 146.02it/s, train_loss=0.00448, val_loss=0.00466]Epoch 14:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00448, val_loss=0.00466]          Epoch 15:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00448, val_loss=0.00466]Epoch 15:   3%|▎         | 1/29 [00:00<00:00, 197.47it/s, train_loss=0.00448, val_loss=0.00466]Epoch 15:   3%|▎         | 1/29 [00:00<00:00, 170.26it/s, train_loss=0.00424, val_loss=0.00466]Epoch 15:   7%|▋         | 2/29 [00:00<00:00, 210.80it/s, train_loss=0.00424, val_loss=0.00466]Epoch 15:   7%|▋         | 2/29 [00:00<00:00, 176.65it/s, train_loss=0.00314, val_loss=0.00466]Epoch 15:  10%|█         | 3/29 [00:00<00:00, 201.44it/s, train_loss=0.00314, val_loss=0.00466]Epoch 15:  10%|█         | 3/29 [00:00<00:00, 175.29it/s, train_loss=0.0039, val_loss=0.00466] Epoch 15:  14%|█▍        | 4/29 [00:00<00:00, 193.18it/s, train_loss=0.0039, val_loss=0.00466]Epoch 15:  14%|█▍        | 4/29 [00:00<00:00, 174.41it/s, train_loss=0.00261, val_loss=0.00466]Epoch 15:  17%|█▋        | 5/29 [00:00<00:00, 188.26it/s, train_loss=0.00261, val_loss=0.00466]Epoch 15:  17%|█▋        | 5/29 [00:00<00:00, 174.03it/s, train_loss=0.00376, val_loss=0.00466]Epoch 15:  21%|██        | 6/29 [00:00<00:00, 185.74it/s, train_loss=0.00376, val_loss=0.00466]Epoch 15:  21%|██        | 6/29 [00:00<00:00, 173.90it/s, train_loss=0.00323, val_loss=0.00466]Epoch 15:  24%|██▍       | 7/29 [00:00<00:00, 181.76it/s, train_loss=0.00323, val_loss=0.00466]Epoch 15:  24%|██▍       | 7/29 [00:00<00:00, 175.29it/s, train_loss=0.00528, val_loss=0.00466]Epoch 15:  28%|██▊       | 8/29 [00:00<00:00, 184.74it/s, train_loss=0.00528, val_loss=0.00466]Epoch 15:  28%|██▊       | 8/29 [00:00<00:00, 182.45it/s, train_loss=0.00465, val_loss=0.00466]Epoch 15:  31%|███       | 9/29 [00:00<00:00, 191.60it/s, train_loss=0.00465, val_loss=0.00466]Epoch 15:  31%|███       | 9/29 [00:00<00:00, 182.89it/s, train_loss=0.00278, val_loss=0.00466]Epoch 15:  34%|███▍      | 10/29 [00:00<00:00, 190.81it/s, train_loss=0.00278, val_loss=0.00466]Epoch 15:  34%|███▍      | 10/29 [00:00<00:00, 188.78it/s, train_loss=0.00225, val_loss=0.00466]Epoch 15:  38%|███▊      | 11/29 [00:00<00:00, 195.64it/s, train_loss=0.00225, val_loss=0.00466]Epoch 15:  38%|███▊      | 11/29 [00:00<00:00, 187.99it/s, train_loss=0.00448, val_loss=0.00466]Epoch 15:  41%|████▏     | 12/29 [00:00<00:00, 194.10it/s, train_loss=0.00448, val_loss=0.00466]Epoch 15:  41%|████▏     | 12/29 [00:00<00:00, 191.93it/s, train_loss=0.0063, val_loss=0.00466] Epoch 15:  45%|████▍     | 13/29 [00:00<00:00, 197.51it/s, train_loss=0.0063, val_loss=0.00466]Epoch 15:  45%|████▍     | 13/29 [00:00<00:00, 191.93it/s, train_loss=0.00356, val_loss=0.00466]Epoch 15:  48%|████▊     | 14/29 [00:00<00:00, 196.99it/s, train_loss=0.00356, val_loss=0.00466]Epoch 15:  48%|████▊     | 14/29 [00:00<00:00, 195.02it/s, train_loss=0.00258, val_loss=0.00466]Epoch 15:  52%|█████▏    | 15/29 [00:00<00:00, 199.10it/s, train_loss=0.00258, val_loss=0.00466]Epoch 15:  52%|█████▏    | 15/29 [00:00<00:00, 195.82it/s, train_loss=0.00424, val_loss=0.00466]Epoch 15:  55%|█████▌    | 16/29 [00:00<00:00, 199.69it/s, train_loss=0.00424, val_loss=0.00466]Epoch 15:  55%|█████▌    | 16/29 [00:00<00:00, 194.18it/s, train_loss=0.00274, val_loss=0.00466]Epoch 15:  59%|█████▊    | 17/29 [00:00<00:00, 197.97it/s, train_loss=0.00274, val_loss=0.00466]Epoch 15:  59%|█████▊    | 17/29 [00:00<00:00, 192.80it/s, train_loss=0.00501, val_loss=0.00466]Epoch 15:  62%|██████▏   | 18/29 [00:00<00:00, 196.31it/s, train_loss=0.00501, val_loss=0.00466]Epoch 15:  62%|██████▏   | 18/29 [00:00<00:00, 191.56it/s, train_loss=0.00363, val_loss=0.00466]Epoch 15:  66%|██████▌   | 19/29 [00:00<00:00, 194.79it/s, train_loss=0.00363, val_loss=0.00466]Epoch 15:  66%|██████▌   | 19/29 [00:00<00:00, 190.53it/s, train_loss=0.00627, val_loss=0.00466]Epoch 15:  69%|██████▉   | 20/29 [00:00<00:00, 193.66it/s, train_loss=0.00627, val_loss=0.00466]Epoch 15:  69%|██████▉   | 20/29 [00:00<00:00, 189.68it/s, train_loss=0.00472, val_loss=0.00466]Epoch 15:  72%|███████▏  | 21/29 [00:00<00:00, 191.86it/s, train_loss=0.00472, val_loss=0.00466]Epoch 15:  72%|███████▏  | 21/29 [00:00<00:00, 189.64it/s, train_loss=0.00341, val_loss=0.00466]Epoch 15:  76%|███████▌  | 22/29 [00:00<00:00, 192.06it/s, train_loss=0.00341, val_loss=0.00466]Epoch 15:  76%|███████▌  | 22/29 [00:00<00:00, 188.71it/s, train_loss=0.00324, val_loss=0.00466]Epoch 15:  79%|███████▉  | 23/29 [00:00<00:00, 191.44it/s, train_loss=0.00324, val_loss=0.00466]Epoch 15:  79%|███████▉  | 23/29 [00:00<00:00, 188.06it/s, train_loss=0.00274, val_loss=0.00466]Epoch 15:  83%|████████▎ | 24/29 [00:00<00:00, 190.78it/s, train_loss=0.00274, val_loss=0.00466]Epoch 15:  83%|████████▎ | 24/29 [00:00<00:00, 187.34it/s, train_loss=0.0044, val_loss=0.00466] Epoch 15:  86%|████████▌ | 25/29 [00:00<00:00, 189.85it/s, train_loss=0.0044, val_loss=0.00466]Epoch 15:  86%|████████▌ | 25/29 [00:00<00:00, 186.72it/s, train_loss=0.00486, val_loss=0.00466]Epoch 15:  90%|████████▉ | 26/29 [00:00<00:00, 189.15it/s, train_loss=0.00486, val_loss=0.00466]Epoch 15:  90%|████████▉ | 26/29 [00:00<00:00, 186.12it/s, train_loss=0.00453, val_loss=0.00466]Epoch 15:  93%|█████████▎| 27/29 [00:00<00:00, 188.77it/s, train_loss=0.00453, val_loss=0.00466]Epoch 15:  93%|█████████▎| 27/29 [00:00<00:00, 186.29it/s, train_loss=0.00435, val_loss=0.00466]Epoch 15:  97%|█████████▋| 28/29 [00:00<00:00, 188.75it/s, train_loss=0.00435, val_loss=0.00466]Epoch 15:  97%|█████████▋| 28/29 [00:00<00:00, 188.03it/s, train_loss=0.00314, val_loss=0.00466]Epoch 15: 100%|██████████| 29/29 [00:00<00:00, 190.59it/s, train_loss=0.00314, val_loss=0.00466]Epoch 15: 100%|██████████| 29/29 [00:00<00:00, 188.02it/s, train_loss=0.00424, val_loss=0.00466]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 200.81it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 245.25it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 261.85it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 271.87it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 281.52it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 288.98it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 294.22it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 296.82it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 297.77it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 297.11it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 296.55it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 295.37it/s][A
                                                                         [AEpoch 15: 100%|██████████| 29/29 [00:00<00:00, 142.67it/s, train_loss=0.00424, val_loss=0.00445]Epoch 15: 100%|██████████| 29/29 [00:00<00:00, 142.06it/s, train_loss=0.00424, val_loss=0.00445]Epoch 15:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00424, val_loss=0.00445]          Epoch 16:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00424, val_loss=0.00445]Epoch 16:   3%|▎         | 1/29 [00:00<00:00, 203.84it/s, train_loss=0.00424, val_loss=0.00445]Epoch 16:   3%|▎         | 1/29 [00:00<00:00, 173.18it/s, train_loss=0.00279, val_loss=0.00445]Epoch 16:   7%|▋         | 2/29 [00:00<00:00, 213.71it/s, train_loss=0.00279, val_loss=0.00445]Epoch 16:   7%|▋         | 2/29 [00:00<00:00, 173.42it/s, train_loss=0.00401, val_loss=0.00445]Epoch 16:  10%|█         | 3/29 [00:00<00:00, 200.34it/s, train_loss=0.00401, val_loss=0.00445]Epoch 16:  10%|█         | 3/29 [00:00<00:00, 173.25it/s, train_loss=0.00419, val_loss=0.00445]Epoch 16:  14%|█▍        | 4/29 [00:00<00:00, 191.76it/s, train_loss=0.00419, val_loss=0.00445]Epoch 16:  14%|█▍        | 4/29 [00:00<00:00, 183.67it/s, train_loss=0.0043, val_loss=0.00445] Epoch 16:  17%|█▋        | 5/29 [00:00<00:00, 195.37it/s, train_loss=0.0043, val_loss=0.00445]Epoch 16:  17%|█▋        | 5/29 [00:00<00:00, 188.89it/s, train_loss=0.00508, val_loss=0.00445]Epoch 16:  21%|██        | 6/29 [00:00<00:00, 199.10it/s, train_loss=0.00508, val_loss=0.00445]Epoch 16:  21%|██        | 6/29 [00:00<00:00, 189.33it/s, train_loss=0.00393, val_loss=0.00445]Epoch 16:  24%|██▍       | 7/29 [00:00<00:00, 198.43it/s, train_loss=0.00393, val_loss=0.00445]Epoch 16:  24%|██▍       | 7/29 [00:00<00:00, 186.63it/s, train_loss=0.0044, val_loss=0.00445] Epoch 16:  28%|██▊       | 8/29 [00:00<00:00, 194.29it/s, train_loss=0.0044, val_loss=0.00445]Epoch 16:  28%|██▊       | 8/29 [00:00<00:00, 184.59it/s, train_loss=0.00421, val_loss=0.00445]Epoch 16:  31%|███       | 9/29 [00:00<00:00, 193.42it/s, train_loss=0.00421, val_loss=0.00445]Epoch 16:  31%|███       | 9/29 [00:00<00:00, 191.04it/s, train_loss=0.00266, val_loss=0.00445]Epoch 16:  34%|███▍      | 10/29 [00:00<00:00, 198.70it/s, train_loss=0.00266, val_loss=0.00445]Epoch 16:  34%|███▍      | 10/29 [00:00<00:00, 190.33it/s, train_loss=0.00314, val_loss=0.00445]Epoch 16:  38%|███▊      | 11/29 [00:00<00:00, 197.28it/s, train_loss=0.00314, val_loss=0.00445]Epoch 16:  38%|███▊      | 11/29 [00:00<00:00, 195.04it/s, train_loss=0.00359, val_loss=0.00445]Epoch 16:  41%|████▏     | 12/29 [00:00<00:00, 200.50it/s, train_loss=0.00359, val_loss=0.00445]Epoch 16:  41%|████▏     | 12/29 [00:00<00:00, 195.43it/s, train_loss=0.00314, val_loss=0.00445]Epoch 16:  45%|████▍     | 13/29 [00:00<00:00, 200.83it/s, train_loss=0.00314, val_loss=0.00445]Epoch 16:  45%|████▍     | 13/29 [00:00<00:00, 198.96it/s, train_loss=0.00541, val_loss=0.00445]Epoch 16:  48%|████▊     | 14/29 [00:00<00:00, 203.99it/s, train_loss=0.00541, val_loss=0.00445]Epoch 16:  48%|████▊     | 14/29 [00:00<00:00, 198.09it/s, train_loss=0.00304, val_loss=0.00445]Epoch 16:  52%|█████▏    | 15/29 [00:00<00:00, 202.67it/s, train_loss=0.00304, val_loss=0.00445]Epoch 16:  52%|█████▏    | 15/29 [00:00<00:00, 200.67it/s, train_loss=0.00383, val_loss=0.00445]Epoch 16:  55%|█████▌    | 16/29 [00:00<00:00, 204.67it/s, train_loss=0.00383, val_loss=0.00445]Epoch 16:  55%|█████▌    | 16/29 [00:00<00:00, 200.01it/s, train_loss=0.00262, val_loss=0.00445]Epoch 16:  59%|█████▊    | 17/29 [00:00<00:00, 203.70it/s, train_loss=0.00262, val_loss=0.00445]Epoch 16:  59%|█████▊    | 17/29 [00:00<00:00, 198.22it/s, train_loss=0.00297, val_loss=0.00445]Epoch 16:  62%|██████▏   | 18/29 [00:00<00:00, 201.70it/s, train_loss=0.00297, val_loss=0.00445]Epoch 16:  62%|██████▏   | 18/29 [00:00<00:00, 196.77it/s, train_loss=0.00355, val_loss=0.00445]Epoch 16:  66%|██████▌   | 19/29 [00:00<00:00, 199.34it/s, train_loss=0.00355, val_loss=0.00445]Epoch 16:  66%|██████▌   | 19/29 [00:00<00:00, 196.47it/s, train_loss=0.00522, val_loss=0.00445]Epoch 16:  69%|██████▉   | 20/29 [00:00<00:00, 199.11it/s, train_loss=0.00522, val_loss=0.00445]Epoch 16:  69%|██████▉   | 20/29 [00:00<00:00, 195.11it/s, train_loss=0.00291, val_loss=0.00445]Epoch 16:  72%|███████▏  | 21/29 [00:00<00:00, 197.98it/s, train_loss=0.00291, val_loss=0.00445]Epoch 16:  72%|███████▏  | 21/29 [00:00<00:00, 193.97it/s, train_loss=0.00255, val_loss=0.00445]Epoch 16:  76%|███████▌  | 22/29 [00:00<00:00, 196.73it/s, train_loss=0.00255, val_loss=0.00445]Epoch 16:  76%|███████▌  | 22/29 [00:00<00:00, 192.84it/s, train_loss=0.00392, val_loss=0.00445]Epoch 16:  79%|███████▉  | 23/29 [00:00<00:00, 195.62it/s, train_loss=0.00392, val_loss=0.00445]Epoch 16:  79%|███████▉  | 23/29 [00:00<00:00, 191.89it/s, train_loss=0.00289, val_loss=0.00445]Epoch 16:  83%|████████▎ | 24/29 [00:00<00:00, 194.52it/s, train_loss=0.00289, val_loss=0.00445]Epoch 16:  83%|████████▎ | 24/29 [00:00<00:00, 191.04it/s, train_loss=0.00454, val_loss=0.00445]Epoch 16:  86%|████████▌ | 25/29 [00:00<00:00, 193.23it/s, train_loss=0.00454, val_loss=0.00445]Epoch 16:  86%|████████▌ | 25/29 [00:00<00:00, 190.73it/s, train_loss=0.00405, val_loss=0.00445]Epoch 16:  90%|████████▉ | 26/29 [00:00<00:00, 192.86it/s, train_loss=0.00405, val_loss=0.00445]Epoch 16:  90%|████████▉ | 26/29 [00:00<00:00, 189.86it/s, train_loss=0.00396, val_loss=0.00445]Epoch 16:  93%|█████████▎| 27/29 [00:00<00:00, 192.57it/s, train_loss=0.00396, val_loss=0.00445]Epoch 16:  93%|█████████▎| 27/29 [00:00<00:00, 191.84it/s, train_loss=0.00409, val_loss=0.00445]Epoch 16:  97%|█████████▋| 28/29 [00:00<00:00, 194.50it/s, train_loss=0.00409, val_loss=0.00445]Epoch 16:  97%|█████████▋| 28/29 [00:00<00:00, 191.53it/s, train_loss=0.0033, val_loss=0.00445] Epoch 16: 100%|██████████| 29/29 [00:00<00:00, 194.21it/s, train_loss=0.0033, val_loss=0.00445]Epoch 16: 100%|██████████| 29/29 [00:00<00:00, 193.44it/s, train_loss=0.00526, val_loss=0.00445]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 218.36it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 257.89it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 280.21it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 295.03it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 302.38it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 303.23it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 302.63it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 302.19it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 301.68it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 302.45it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 302.39it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 303.49it/s][A
                                                                         [AEpoch 16: 100%|██████████| 29/29 [00:00<00:00, 147.86it/s, train_loss=0.00526, val_loss=0.00426]Epoch 16: 100%|██████████| 29/29 [00:00<00:00, 147.22it/s, train_loss=0.00526, val_loss=0.00426]Epoch 16:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00526, val_loss=0.00426]          Epoch 17:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00526, val_loss=0.00426]Epoch 17:   3%|▎         | 1/29 [00:00<00:00, 212.64it/s, train_loss=0.00526, val_loss=0.00426]Epoch 17:   3%|▎         | 1/29 [00:00<00:00, 174.64it/s, train_loss=0.00455, val_loss=0.00426]Epoch 17:   7%|▋         | 2/29 [00:00<00:00, 215.20it/s, train_loss=0.00455, val_loss=0.00426]Epoch 17:   7%|▋         | 2/29 [00:00<00:00, 174.40it/s, train_loss=0.00276, val_loss=0.00426]Epoch 17:  10%|█         | 3/29 [00:00<00:00, 199.40it/s, train_loss=0.00276, val_loss=0.00426]Epoch 17:  10%|█         | 3/29 [00:00<00:00, 189.70it/s, train_loss=0.00319, val_loss=0.00426]Epoch 17:  14%|█▍        | 4/29 [00:00<00:00, 204.79it/s, train_loss=0.00319, val_loss=0.00426]Epoch 17:  14%|█▍        | 4/29 [00:00<00:00, 183.85it/s, train_loss=0.00269, val_loss=0.00426]Epoch 17:  17%|█▋        | 5/29 [00:00<00:00, 196.47it/s, train_loss=0.00269, val_loss=0.00426]Epoch 17:  17%|█▋        | 5/29 [00:00<00:00, 181.20it/s, train_loss=0.00438, val_loss=0.00426]Epoch 17:  21%|██        | 6/29 [00:00<00:00, 192.44it/s, train_loss=0.00438, val_loss=0.00426]Epoch 17:  21%|██        | 6/29 [00:00<00:00, 179.39it/s, train_loss=0.00251, val_loss=0.00426]Epoch 17:  24%|██▍       | 7/29 [00:00<00:00, 188.84it/s, train_loss=0.00251, val_loss=0.00426]Epoch 17:  24%|██▍       | 7/29 [00:00<00:00, 178.27it/s, train_loss=0.00387, val_loss=0.00426]Epoch 17:  28%|██▊       | 8/29 [00:00<00:00, 186.36it/s, train_loss=0.00387, val_loss=0.00426]Epoch 17:  28%|██▊       | 8/29 [00:00<00:00, 177.57it/s, train_loss=0.00515, val_loss=0.00426]Epoch 17:  31%|███       | 9/29 [00:00<00:00, 184.49it/s, train_loss=0.00515, val_loss=0.00426]Epoch 17:  31%|███       | 9/29 [00:00<00:00, 181.95it/s, train_loss=0.00412, val_loss=0.00426]Epoch 17:  34%|███▍      | 10/29 [00:00<00:00, 189.14it/s, train_loss=0.00412, val_loss=0.00426]Epoch 17:  34%|███▍      | 10/29 [00:00<00:00, 186.92it/s, train_loss=0.00412, val_loss=0.00426]Epoch 17:  38%|███▊      | 11/29 [00:00<00:00, 193.48it/s, train_loss=0.00412, val_loss=0.00426]Epoch 17:  38%|███▊      | 11/29 [00:00<00:00, 191.85it/s, train_loss=0.0034, val_loss=0.00426] Epoch 17:  41%|████▏     | 12/29 [00:00<00:00, 198.31it/s, train_loss=0.0034, val_loss=0.00426]Epoch 17:  41%|████▏     | 12/29 [00:00<00:00, 191.09it/s, train_loss=0.0031, val_loss=0.00426]Epoch 17:  45%|████▍     | 13/29 [00:00<00:00, 196.69it/s, train_loss=0.0031, val_loss=0.00426]Epoch 17:  45%|████▍     | 13/29 [00:00<00:00, 194.67it/s, train_loss=0.00376, val_loss=0.00426]Epoch 17:  48%|████▊     | 14/29 [00:00<00:00, 199.60it/s, train_loss=0.00376, val_loss=0.00426]Epoch 17:  48%|████▊     | 14/29 [00:00<00:00, 194.24it/s, train_loss=0.00219, val_loss=0.00426]Epoch 17:  52%|█████▏    | 15/29 [00:00<00:00, 198.67it/s, train_loss=0.00219, val_loss=0.00426]Epoch 17:  52%|█████▏    | 15/29 [00:00<00:00, 192.78it/s, train_loss=0.00257, val_loss=0.00426]Epoch 17:  55%|█████▌    | 16/29 [00:00<00:00, 197.05it/s, train_loss=0.00257, val_loss=0.00426]Epoch 17:  55%|█████▌    | 16/29 [00:00<00:00, 191.50it/s, train_loss=0.00319, val_loss=0.00426]Epoch 17:  59%|█████▊    | 17/29 [00:00<00:00, 194.78it/s, train_loss=0.00319, val_loss=0.00426]Epoch 17:  59%|█████▊    | 17/29 [00:00<00:00, 191.38it/s, train_loss=0.00342, val_loss=0.00426]Epoch 17:  62%|██████▏   | 18/29 [00:00<00:00, 194.57it/s, train_loss=0.00342, val_loss=0.00426]Epoch 17:  62%|██████▏   | 18/29 [00:00<00:00, 190.09it/s, train_loss=0.00371, val_loss=0.00426]Epoch 17:  66%|██████▌   | 19/29 [00:00<00:00, 192.86it/s, train_loss=0.00371, val_loss=0.00426]Epoch 17:  66%|██████▌   | 19/29 [00:00<00:00, 189.13it/s, train_loss=0.00323, val_loss=0.00426]Epoch 17:  69%|██████▉   | 20/29 [00:00<00:00, 192.14it/s, train_loss=0.00323, val_loss=0.00426]Epoch 17:  69%|██████▉   | 20/29 [00:00<00:00, 188.15it/s, train_loss=0.00305, val_loss=0.00426]Epoch 17:  72%|███████▏  | 21/29 [00:00<00:00, 190.95it/s, train_loss=0.00305, val_loss=0.00426]Epoch 17:  72%|███████▏  | 21/29 [00:00<00:00, 187.36it/s, train_loss=0.00489, val_loss=0.00426]Epoch 17:  76%|███████▌  | 22/29 [00:00<00:00, 190.13it/s, train_loss=0.00489, val_loss=0.00426]Epoch 17:  76%|███████▌  | 22/29 [00:00<00:00, 186.68it/s, train_loss=0.00285, val_loss=0.00426]Epoch 17:  79%|███████▉  | 23/29 [00:00<00:00, 188.76it/s, train_loss=0.00285, val_loss=0.00426]Epoch 17:  79%|███████▉  | 23/29 [00:00<00:00, 186.76it/s, train_loss=0.00346, val_loss=0.00426]Epoch 17:  83%|████████▎ | 24/29 [00:00<00:00, 188.88it/s, train_loss=0.00346, val_loss=0.00426]Epoch 17:  83%|████████▎ | 24/29 [00:00<00:00, 186.10it/s, train_loss=0.00535, val_loss=0.00426]Epoch 17:  86%|████████▌ | 25/29 [00:00<00:00, 188.27it/s, train_loss=0.00535, val_loss=0.00426]Epoch 17:  86%|████████▌ | 25/29 [00:00<00:00, 185.50it/s, train_loss=0.00274, val_loss=0.00426]Epoch 17:  90%|████████▉ | 26/29 [00:00<00:00, 187.62it/s, train_loss=0.00274, val_loss=0.00426]Epoch 17:  90%|████████▉ | 26/29 [00:00<00:00, 184.97it/s, train_loss=0.004, val_loss=0.00426]  Epoch 17:  93%|█████████▎| 27/29 [00:00<00:00, 187.01it/s, train_loss=0.004, val_loss=0.00426]Epoch 17:  93%|█████████▎| 27/29 [00:00<00:00, 184.53it/s, train_loss=0.00199, val_loss=0.00426]Epoch 17:  97%|█████████▋| 28/29 [00:00<00:00, 187.24it/s, train_loss=0.00199, val_loss=0.00426]Epoch 17:  97%|█████████▋| 28/29 [00:00<00:00, 186.58it/s, train_loss=0.00673, val_loss=0.00426]Epoch 17: 100%|██████████| 29/29 [00:00<00:00, 189.31it/s, train_loss=0.00673, val_loss=0.00426]Epoch 17: 100%|██████████| 29/29 [00:00<00:00, 188.62it/s, train_loss=0.00148, val_loss=0.00426]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 266.46it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 301.33it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 311.57it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 313.21it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 312.52it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 313.60it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 316.29it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 316.37it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 317.13it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 319.34it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 321.63it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 322.51it/s][A
                                                                         [AEpoch 17: 100%|██████████| 29/29 [00:00<00:00, 146.58it/s, train_loss=0.00148, val_loss=0.00409]Epoch 17: 100%|██████████| 29/29 [00:00<00:00, 145.86it/s, train_loss=0.00148, val_loss=0.00409]Epoch 17:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00148, val_loss=0.00409]          Epoch 18:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00148, val_loss=0.00409]Epoch 18:   3%|▎         | 1/29 [00:00<00:00, 217.75it/s, train_loss=0.00148, val_loss=0.00409]Epoch 18:   3%|▎         | 1/29 [00:00<00:00, 175.54it/s, train_loss=0.00439, val_loss=0.00409]Epoch 18:   7%|▋         | 2/29 [00:00<00:00, 209.87it/s, train_loss=0.00439, val_loss=0.00409]Epoch 18:   7%|▋         | 2/29 [00:00<00:00, 180.87it/s, train_loss=0.00237, val_loss=0.00409]Epoch 18:  10%|█         | 3/29 [00:00<00:00, 204.97it/s, train_loss=0.00237, val_loss=0.00409]Epoch 18:  10%|█         | 3/29 [00:00<00:00, 177.44it/s, train_loss=0.00451, val_loss=0.00409]Epoch 18:  14%|█▍        | 4/29 [00:00<00:00, 196.86it/s, train_loss=0.00451, val_loss=0.00409]Epoch 18:  14%|█▍        | 4/29 [00:00<00:00, 175.86it/s, train_loss=0.00461, val_loss=0.00409]Epoch 18:  17%|█▋        | 5/29 [00:00<00:00, 190.31it/s, train_loss=0.00461, val_loss=0.00409]Epoch 18:  17%|█▋        | 5/29 [00:00<00:00, 174.93it/s, train_loss=0.00291, val_loss=0.00409]Epoch 18:  21%|██        | 6/29 [00:00<00:00, 187.30it/s, train_loss=0.00291, val_loss=0.00409]Epoch 18:  21%|██        | 6/29 [00:00<00:00, 174.69it/s, train_loss=0.00267, val_loss=0.00409]Epoch 18:  24%|██▍       | 7/29 [00:00<00:00, 185.06it/s, train_loss=0.00267, val_loss=0.00409]Epoch 18:  24%|██▍       | 7/29 [00:00<00:00, 174.58it/s, train_loss=0.0036, val_loss=0.00409] Epoch 18:  28%|██▊       | 8/29 [00:00<00:00, 182.58it/s, train_loss=0.0036, val_loss=0.00409]Epoch 18:  28%|██▊       | 8/29 [00:00<00:00, 176.18it/s, train_loss=0.00463, val_loss=0.00409]Epoch 18:  31%|███       | 9/29 [00:00<00:00, 183.27it/s, train_loss=0.00463, val_loss=0.00409]Epoch 18:  31%|███       | 9/29 [00:00<00:00, 175.59it/s, train_loss=0.00467, val_loss=0.00409]Epoch 18:  34%|███▍      | 10/29 [00:00<00:00, 182.27it/s, train_loss=0.00467, val_loss=0.00409]Epoch 18:  34%|███▍      | 10/29 [00:00<00:00, 175.41it/s, train_loss=0.0036, val_loss=0.00409] Epoch 18:  38%|███▊      | 11/29 [00:00<00:00, 182.85it/s, train_loss=0.0036, val_loss=0.00409]Epoch 18:  38%|███▊      | 11/29 [00:00<00:00, 180.97it/s, train_loss=0.00298, val_loss=0.00409]Epoch 18:  41%|████▏     | 12/29 [00:00<00:00, 187.53it/s, train_loss=0.00298, val_loss=0.00409]Epoch 18:  41%|████▏     | 12/29 [00:00<00:00, 181.09it/s, train_loss=0.00253, val_loss=0.00409]Epoch 18:  45%|████▍     | 13/29 [00:00<00:00, 187.38it/s, train_loss=0.00253, val_loss=0.00409]Epoch 18:  45%|████▍     | 13/29 [00:00<00:00, 185.66it/s, train_loss=0.00246, val_loss=0.00409]Epoch 18:  48%|████▊     | 14/29 [00:00<00:00, 191.01it/s, train_loss=0.00246, val_loss=0.00409]Epoch 18:  48%|████▊     | 14/29 [00:00<00:00, 185.45it/s, train_loss=0.00245, val_loss=0.00409]Epoch 18:  52%|█████▏    | 15/29 [00:00<00:00, 189.76it/s, train_loss=0.00245, val_loss=0.00409]Epoch 18:  52%|█████▏    | 15/29 [00:00<00:00, 185.40it/s, train_loss=0.00275, val_loss=0.00409]Epoch 18:  55%|█████▌    | 16/29 [00:00<00:00, 189.62it/s, train_loss=0.00275, val_loss=0.00409]Epoch 18:  55%|█████▌    | 16/29 [00:00<00:00, 188.05it/s, train_loss=0.00531, val_loss=0.00409]Epoch 18:  59%|█████▊    | 17/29 [00:00<00:00, 192.24it/s, train_loss=0.00531, val_loss=0.00409]Epoch 18:  59%|█████▊    | 17/29 [00:00<00:00, 188.35it/s, train_loss=0.00364, val_loss=0.00409]Epoch 18:  62%|██████▏   | 18/29 [00:00<00:00, 191.90it/s, train_loss=0.00364, val_loss=0.00409]Epoch 18:  62%|██████▏   | 18/29 [00:00<00:00, 187.42it/s, train_loss=0.00378, val_loss=0.00409]Epoch 18:  66%|██████▌   | 19/29 [00:00<00:00, 191.02it/s, train_loss=0.00378, val_loss=0.00409]Epoch 18:  66%|██████▌   | 19/29 [00:00<00:00, 186.62it/s, train_loss=0.00347, val_loss=0.00409]Epoch 18:  69%|██████▉   | 20/29 [00:00<00:00, 190.01it/s, train_loss=0.00347, val_loss=0.00409]Epoch 18:  69%|██████▉   | 20/29 [00:00<00:00, 185.97it/s, train_loss=0.00386, val_loss=0.00409]Epoch 18:  72%|███████▏  | 21/29 [00:00<00:00, 188.89it/s, train_loss=0.00386, val_loss=0.00409]Epoch 18:  72%|███████▏  | 21/29 [00:00<00:00, 187.49it/s, train_loss=0.00329, val_loss=0.00409]Epoch 18:  76%|███████▌  | 22/29 [00:00<00:00, 190.12it/s, train_loss=0.00329, val_loss=0.00409]Epoch 18:  76%|███████▌  | 22/29 [00:00<00:00, 186.62it/s, train_loss=0.0025, val_loss=0.00409] Epoch 18:  79%|███████▉  | 23/29 [00:00<00:00, 189.29it/s, train_loss=0.0025, val_loss=0.00409]Epoch 18:  79%|███████▉  | 23/29 [00:00<00:00, 186.01it/s, train_loss=0.00291, val_loss=0.00409]Epoch 18:  83%|████████▎ | 24/29 [00:00<00:00, 188.57it/s, train_loss=0.00291, val_loss=0.00409]Epoch 18:  83%|████████▎ | 24/29 [00:00<00:00, 185.39it/s, train_loss=0.00375, val_loss=0.00409]Epoch 18:  86%|████████▌ | 25/29 [00:00<00:00, 187.94it/s, train_loss=0.00375, val_loss=0.00409]Epoch 18:  86%|████████▌ | 25/29 [00:00<00:00, 184.86it/s, train_loss=0.00238, val_loss=0.00409]Epoch 18:  90%|████████▉ | 26/29 [00:00<00:00, 187.22it/s, train_loss=0.00238, val_loss=0.00409]Epoch 18:  90%|████████▉ | 26/29 [00:00<00:00, 184.41it/s, train_loss=0.00319, val_loss=0.00409]Epoch 18:  93%|█████████▎| 27/29 [00:00<00:00, 186.66it/s, train_loss=0.00319, val_loss=0.00409]Epoch 18:  93%|█████████▎| 27/29 [00:00<00:00, 185.50it/s, train_loss=0.00334, val_loss=0.00409]Epoch 18:  97%|█████████▋| 28/29 [00:00<00:00, 187.49it/s, train_loss=0.00334, val_loss=0.00409]Epoch 18:  97%|█████████▋| 28/29 [00:00<00:00, 184.83it/s, train_loss=0.00379, val_loss=0.00409]Epoch 18: 100%|██████████| 29/29 [00:00<00:00, 187.40it/s, train_loss=0.00379, val_loss=0.00409]Epoch 18: 100%|██████████| 29/29 [00:00<00:00, 186.75it/s, train_loss=0.00294, val_loss=0.00409]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 279.84it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 318.03it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 333.93it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 345.77it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 348.40it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 349.34it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 348.96it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 349.17it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 347.65it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 345.60it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 340.56it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 338.26it/s][A
                                                                         [AEpoch 18: 100%|██████████| 29/29 [00:00<00:00, 146.93it/s, train_loss=0.00294, val_loss=0.00399]Epoch 18: 100%|██████████| 29/29 [00:00<00:00, 146.26it/s, train_loss=0.00294, val_loss=0.00399]Epoch 18:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00294, val_loss=0.00399]          Epoch 19:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00294, val_loss=0.00399]Epoch 19:   3%|▎         | 1/29 [00:00<00:00, 208.28it/s, train_loss=0.00294, val_loss=0.00399]Epoch 19:   3%|▎         | 1/29 [00:00<00:00, 142.18it/s, train_loss=0.00424, val_loss=0.00399]Epoch 19:   7%|▋         | 2/29 [00:00<00:00, 186.43it/s, train_loss=0.00424, val_loss=0.00399]Epoch 19:   7%|▋         | 2/29 [00:00<00:00, 155.61it/s, train_loss=0.0044, val_loss=0.00399] Epoch 19:  10%|█         | 3/29 [00:00<00:00, 183.17it/s, train_loss=0.0044, val_loss=0.00399]Epoch 19:  10%|█         | 3/29 [00:00<00:00, 160.63it/s, train_loss=0.00224, val_loss=0.00399]Epoch 19:  14%|█▍        | 4/29 [00:00<00:00, 180.34it/s, train_loss=0.00224, val_loss=0.00399]Epoch 19:  14%|█▍        | 4/29 [00:00<00:00, 163.50it/s, train_loss=0.0043, val_loss=0.00399] Epoch 19:  17%|█▋        | 5/29 [00:00<00:00, 178.22it/s, train_loss=0.0043, val_loss=0.00399]Epoch 19:  17%|█▋        | 5/29 [00:00<00:00, 165.32it/s, train_loss=0.00469, val_loss=0.00399]Epoch 19:  21%|██        | 6/29 [00:00<00:00, 176.85it/s, train_loss=0.00469, val_loss=0.00399]Epoch 19:  21%|██        | 6/29 [00:00<00:00, 172.79it/s, train_loss=0.00275, val_loss=0.00399]Epoch 19:  24%|██▍       | 7/29 [00:00<00:00, 181.99it/s, train_loss=0.00275, val_loss=0.00399]Epoch 19:  24%|██▍       | 7/29 [00:00<00:00, 178.08it/s, train_loss=0.0035, val_loss=0.00399] Epoch 19:  28%|██▊       | 8/29 [00:00<00:00, 186.14it/s, train_loss=0.0035, val_loss=0.00399]Epoch 19:  28%|██▊       | 8/29 [00:00<00:00, 179.45it/s, train_loss=0.00582, val_loss=0.00399]Epoch 19:  31%|███       | 9/29 [00:00<00:00, 186.86it/s, train_loss=0.00582, val_loss=0.00399]Epoch 19:  31%|███       | 9/29 [00:00<00:00, 178.64it/s, train_loss=0.00275, val_loss=0.00399]Epoch 19:  34%|███▍      | 10/29 [00:00<00:00, 185.39it/s, train_loss=0.00275, val_loss=0.00399]Epoch 19:  34%|███▍      | 10/29 [00:00<00:00, 177.93it/s, train_loss=0.00336, val_loss=0.00399]Epoch 19:  38%|███▊      | 11/29 [00:00<00:00, 184.04it/s, train_loss=0.00336, val_loss=0.00399]Epoch 19:  38%|███▊      | 11/29 [00:00<00:00, 177.54it/s, train_loss=0.00222, val_loss=0.00399]Epoch 19:  41%|████▏     | 12/29 [00:00<00:00, 184.30it/s, train_loss=0.00222, val_loss=0.00399]Epoch 19:  41%|████▏     | 12/29 [00:00<00:00, 182.81it/s, train_loss=0.00278, val_loss=0.00399]Epoch 19:  45%|████▍     | 13/29 [00:00<00:00, 188.99it/s, train_loss=0.00278, val_loss=0.00399]Epoch 19:  45%|████▍     | 13/29 [00:00<00:00, 187.33it/s, train_loss=0.0026, val_loss=0.00399] Epoch 19:  48%|████▊     | 14/29 [00:00<00:00, 192.22it/s, train_loss=0.0026, val_loss=0.00399]Epoch 19:  48%|████▊     | 14/29 [00:00<00:00, 188.46it/s, train_loss=0.00421, val_loss=0.00399]Epoch 19:  52%|█████▏    | 15/29 [00:00<00:00, 192.76it/s, train_loss=0.00421, val_loss=0.00399]Epoch 19:  52%|█████▏    | 15/29 [00:00<00:00, 191.27it/s, train_loss=0.00274, val_loss=0.00399]Epoch 19:  55%|█████▌    | 16/29 [00:00<00:00, 195.67it/s, train_loss=0.00274, val_loss=0.00399]Epoch 19:  55%|█████▌    | 16/29 [00:00<00:00, 191.40it/s, train_loss=0.00229, val_loss=0.00399]Epoch 19:  59%|█████▊    | 17/29 [00:00<00:00, 195.51it/s, train_loss=0.00229, val_loss=0.00399]Epoch 19:  59%|█████▊    | 17/29 [00:00<00:00, 193.91it/s, train_loss=0.00311, val_loss=0.00399]Epoch 19:  62%|██████▏   | 18/29 [00:00<00:00, 197.77it/s, train_loss=0.00311, val_loss=0.00399]Epoch 19:  62%|██████▏   | 18/29 [00:00<00:00, 193.89it/s, train_loss=0.0026, val_loss=0.00399] Epoch 19:  66%|██████▌   | 19/29 [00:00<00:00, 197.56it/s, train_loss=0.0026, val_loss=0.00399]Epoch 19:  66%|██████▌   | 19/29 [00:00<00:00, 195.89it/s, train_loss=0.00259, val_loss=0.00399]Epoch 19:  69%|██████▉   | 20/29 [00:00<00:00, 199.27it/s, train_loss=0.00259, val_loss=0.00399]Epoch 19:  69%|██████▉   | 20/29 [00:00<00:00, 196.02it/s, train_loss=0.00302, val_loss=0.00399]Epoch 19:  72%|███████▏  | 21/29 [00:00<00:00, 199.04it/s, train_loss=0.00302, val_loss=0.00399]Epoch 19:  72%|███████▏  | 21/29 [00:00<00:00, 197.71it/s, train_loss=0.00285, val_loss=0.00399]Epoch 19:  76%|███████▌  | 22/29 [00:00<00:00, 200.26it/s, train_loss=0.00285, val_loss=0.00399]Epoch 19:  76%|███████▌  | 22/29 [00:00<00:00, 198.90it/s, train_loss=0.00244, val_loss=0.00399]Epoch 19:  79%|███████▉  | 23/29 [00:00<00:00, 201.34it/s, train_loss=0.00244, val_loss=0.00399]Epoch 19:  79%|███████▉  | 23/29 [00:00<00:00, 198.65it/s, train_loss=0.00309, val_loss=0.00399]Epoch 19:  83%|████████▎ | 24/29 [00:00<00:00, 201.34it/s, train_loss=0.00309, val_loss=0.00399]Epoch 19:  83%|████████▎ | 24/29 [00:00<00:00, 197.43it/s, train_loss=0.00374, val_loss=0.00399]Epoch 19:  86%|████████▌ | 25/29 [00:00<00:00, 199.95it/s, train_loss=0.00374, val_loss=0.00399]Epoch 19:  86%|████████▌ | 25/29 [00:00<00:00, 196.33it/s, train_loss=0.00235, val_loss=0.00399]Epoch 19:  90%|████████▉ | 26/29 [00:00<00:00, 198.74it/s, train_loss=0.00235, val_loss=0.00399]Epoch 19:  90%|████████▉ | 26/29 [00:00<00:00, 195.33it/s, train_loss=0.00334, val_loss=0.00399]Epoch 19:  93%|█████████▎| 27/29 [00:00<00:00, 197.59it/s, train_loss=0.00334, val_loss=0.00399]Epoch 19:  93%|█████████▎| 27/29 [00:00<00:00, 194.47it/s, train_loss=0.00544, val_loss=0.00399]Epoch 19:  97%|█████████▋| 28/29 [00:00<00:00, 196.23it/s, train_loss=0.00544, val_loss=0.00399]Epoch 19:  97%|█████████▋| 28/29 [00:00<00:00, 194.29it/s, train_loss=0.0035, val_loss=0.00399] Epoch 19: 100%|██████████| 29/29 [00:00<00:00, 196.08it/s, train_loss=0.0035, val_loss=0.00399]Epoch 19: 100%|██████████| 29/29 [00:00<00:00, 193.42it/s, train_loss=0.00305, val_loss=0.00399]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 292.31it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 336.61it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 355.48it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 365.17it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 373.68it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 376.26it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 377.08it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 376.45it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 376.00it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 373.75it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 370.73it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 365.67it/s][A
                                                                         [AEpoch 19: 100%|██████████| 29/29 [00:00<00:00, 152.78it/s, train_loss=0.00305, val_loss=0.00385]Epoch 19: 100%|██████████| 29/29 [00:00<00:00, 152.06it/s, train_loss=0.00305, val_loss=0.00385]Epoch 19:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00305, val_loss=0.00385]          Epoch 20:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00305, val_loss=0.00385]Epoch 20:   3%|▎         | 1/29 [00:00<00:00, 210.41it/s, train_loss=0.00305, val_loss=0.00385]Epoch 20:   3%|▎         | 1/29 [00:00<00:00, 183.68it/s, train_loss=0.00264, val_loss=0.00385]Epoch 20:   7%|▋         | 2/29 [00:00<00:00, 221.63it/s, train_loss=0.00264, val_loss=0.00385]Epoch 20:   7%|▋         | 2/29 [00:00<00:00, 179.47it/s, train_loss=0.00511, val_loss=0.00385]Epoch 20:  10%|█         | 3/29 [00:00<00:00, 205.44it/s, train_loss=0.00511, val_loss=0.00385]Epoch 20:  10%|█         | 3/29 [00:00<00:00, 176.79it/s, train_loss=0.0033, val_loss=0.00385] Epoch 20:  14%|█▍        | 4/29 [00:00<00:00, 194.91it/s, train_loss=0.0033, val_loss=0.00385]Epoch 20:  14%|█▍        | 4/29 [00:00<00:00, 175.36it/s, train_loss=0.00379, val_loss=0.00385]Epoch 20:  17%|█▋        | 5/29 [00:00<00:00, 189.85it/s, train_loss=0.00379, val_loss=0.00385]Epoch 20:  17%|█▋        | 5/29 [00:00<00:00, 174.86it/s, train_loss=0.00514, val_loss=0.00385]Epoch 20:  21%|██        | 6/29 [00:00<00:00, 186.74it/s, train_loss=0.00514, val_loss=0.00385]Epoch 20:  21%|██        | 6/29 [00:00<00:00, 174.63it/s, train_loss=0.00465, val_loss=0.00385]Epoch 20:  24%|██▍       | 7/29 [00:00<00:00, 182.78it/s, train_loss=0.00465, val_loss=0.00385]Epoch 20:  24%|██▍       | 7/29 [00:00<00:00, 174.49it/s, train_loss=0.00314, val_loss=0.00385]Epoch 20:  28%|██▊       | 8/29 [00:00<00:00, 182.58it/s, train_loss=0.00314, val_loss=0.00385]Epoch 20:  28%|██▊       | 8/29 [00:00<00:00, 174.31it/s, train_loss=0.00243, val_loss=0.00385]Epoch 20:  31%|███       | 9/29 [00:00<00:00, 182.28it/s, train_loss=0.00243, val_loss=0.00385]Epoch 20:  31%|███       | 9/29 [00:00<00:00, 174.20it/s, train_loss=0.00255, val_loss=0.00385]Epoch 20:  34%|███▍      | 10/29 [00:00<00:00, 181.04it/s, train_loss=0.00255, val_loss=0.00385]Epoch 20:  34%|███▍      | 10/29 [00:00<00:00, 174.06it/s, train_loss=0.00277, val_loss=0.00385]Epoch 20:  38%|███▊      | 11/29 [00:00<00:00, 180.46it/s, train_loss=0.00277, val_loss=0.00385]Epoch 20:  38%|███▊      | 11/29 [00:00<00:00, 173.94it/s, train_loss=0.00205, val_loss=0.00385]Epoch 20:  41%|████▏     | 12/29 [00:00<00:00, 179.45it/s, train_loss=0.00205, val_loss=0.00385]Epoch 20:  41%|████▏     | 12/29 [00:00<00:00, 173.87it/s, train_loss=0.00274, val_loss=0.00385]Epoch 20:  45%|████▍     | 13/29 [00:00<00:00, 179.54it/s, train_loss=0.00274, val_loss=0.00385]Epoch 20:  45%|████▍     | 13/29 [00:00<00:00, 175.04it/s, train_loss=0.003, val_loss=0.00385]  Epoch 20:  48%|████▊     | 14/29 [00:00<00:00, 180.35it/s, train_loss=0.003, val_loss=0.00385]Epoch 20:  48%|████▊     | 14/29 [00:00<00:00, 179.16it/s, train_loss=0.00333, val_loss=0.00385]Epoch 20:  52%|█████▏    | 15/29 [00:00<00:00, 184.45it/s, train_loss=0.00333, val_loss=0.00385]Epoch 20:  52%|█████▏    | 15/29 [00:00<00:00, 179.46it/s, train_loss=0.00267, val_loss=0.00385]Epoch 20:  55%|█████▌    | 16/29 [00:00<00:00, 184.28it/s, train_loss=0.00267, val_loss=0.00385]Epoch 20:  55%|█████▌    | 16/29 [00:00<00:00, 183.02it/s, train_loss=0.00228, val_loss=0.00385]Epoch 20:  59%|█████▊    | 17/29 [00:00<00:00, 187.42it/s, train_loss=0.00228, val_loss=0.00385]Epoch 20:  59%|█████▊    | 17/29 [00:00<00:00, 183.01it/s, train_loss=0.0023, val_loss=0.00385] Epoch 20:  62%|██████▏   | 18/29 [00:00<00:00, 187.14it/s, train_loss=0.0023, val_loss=0.00385]Epoch 20:  62%|██████▏   | 18/29 [00:00<00:00, 185.82it/s, train_loss=0.00359, val_loss=0.00385]Epoch 20:  66%|██████▌   | 19/29 [00:00<00:00, 189.69it/s, train_loss=0.00359, val_loss=0.00385]Epoch 20:  66%|██████▌   | 19/29 [00:00<00:00, 186.05it/s, train_loss=0.00388, val_loss=0.00385]Epoch 20:  69%|██████▉   | 20/29 [00:00<00:00, 189.56it/s, train_loss=0.00388, val_loss=0.00385]Epoch 20:  69%|██████▉   | 20/29 [00:00<00:00, 188.23it/s, train_loss=0.00291, val_loss=0.00385]Epoch 20:  72%|███████▏  | 21/29 [00:00<00:00, 191.04it/s, train_loss=0.00291, val_loss=0.00385]Epoch 20:  72%|███████▏  | 21/29 [00:00<00:00, 188.79it/s, train_loss=0.00373, val_loss=0.00385]Epoch 20:  76%|███████▌  | 22/29 [00:00<00:00, 191.34it/s, train_loss=0.00373, val_loss=0.00385]Epoch 20:  76%|███████▌  | 22/29 [00:00<00:00, 187.89it/s, train_loss=0.0042, val_loss=0.00385] Epoch 20:  79%|███████▉  | 23/29 [00:00<00:00, 190.86it/s, train_loss=0.0042, val_loss=0.00385]Epoch 20:  79%|███████▉  | 23/29 [00:00<00:00, 187.17it/s, train_loss=0.0041, val_loss=0.00385]Epoch 20:  83%|████████▎ | 24/29 [00:00<00:00, 189.89it/s, train_loss=0.0041, val_loss=0.00385]Epoch 20:  83%|████████▎ | 24/29 [00:00<00:00, 186.50it/s, train_loss=0.0025, val_loss=0.00385]Epoch 20:  86%|████████▌ | 25/29 [00:00<00:00, 189.14it/s, train_loss=0.0025, val_loss=0.00385]Epoch 20:  86%|████████▌ | 25/29 [00:00<00:00, 185.91it/s, train_loss=0.00334, val_loss=0.00385]Epoch 20:  90%|████████▉ | 26/29 [00:00<00:00, 188.44it/s, train_loss=0.00334, val_loss=0.00385]Epoch 20:  90%|████████▉ | 26/29 [00:00<00:00, 185.45it/s, train_loss=0.002, val_loss=0.00385]  Epoch 20:  93%|█████████▎| 27/29 [00:00<00:00, 187.60it/s, train_loss=0.002, val_loss=0.00385]Epoch 20:  93%|█████████▎| 27/29 [00:00<00:00, 185.52it/s, train_loss=0.0027, val_loss=0.00385]Epoch 20:  97%|█████████▋| 28/29 [00:00<00:00, 187.64it/s, train_loss=0.0027, val_loss=0.00385]Epoch 20:  97%|█████████▋| 28/29 [00:00<00:00, 185.01it/s, train_loss=0.00289, val_loss=0.00385]Epoch 20: 100%|██████████| 29/29 [00:00<00:00, 187.27it/s, train_loss=0.00289, val_loss=0.00385]Epoch 20: 100%|██████████| 29/29 [00:00<00:00, 184.59it/s, train_loss=0.00339, val_loss=0.00385]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 305.28it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 355.12it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 375.31it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 382.48it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 386.28it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 388.63it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 390.53it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 389.29it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 387.41it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 385.33it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 381.41it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 377.86it/s][A
                                                                         [AEpoch 20: 100%|██████████| 29/29 [00:00<00:00, 147.25it/s, train_loss=0.00339, val_loss=0.00374]Epoch 20: 100%|██████████| 29/29 [00:00<00:00, 146.64it/s, train_loss=0.00339, val_loss=0.00374]Epoch 20:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00339, val_loss=0.00374]          Epoch 21:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00339, val_loss=0.00374]Epoch 21:   3%|▎         | 1/29 [00:00<00:00, 208.53it/s, train_loss=0.00339, val_loss=0.00374]Epoch 21:   3%|▎         | 1/29 [00:00<00:00, 142.75it/s, train_loss=0.00285, val_loss=0.00374]Epoch 21:   7%|▋         | 2/29 [00:00<00:00, 186.43it/s, train_loss=0.00285, val_loss=0.00374]Epoch 21:   7%|▋         | 2/29 [00:00<00:00, 155.66it/s, train_loss=0.00563, val_loss=0.00374]Epoch 21:  10%|█         | 3/29 [00:00<00:00, 184.47it/s, train_loss=0.00563, val_loss=0.00374]Epoch 21:  10%|█         | 3/29 [00:00<00:00, 176.58it/s, train_loss=0.00383, val_loss=0.00374]Epoch 21:  14%|█▍        | 4/29 [00:00<00:00, 196.66it/s, train_loss=0.00383, val_loss=0.00374]Epoch 21:  14%|█▍        | 4/29 [00:00<00:00, 180.17it/s, train_loss=0.00358, val_loss=0.00374]Epoch 21:  17%|█▋        | 5/29 [00:00<00:00, 195.47it/s, train_loss=0.00358, val_loss=0.00374]Epoch 21:  17%|█▋        | 5/29 [00:00<00:00, 178.87it/s, train_loss=0.00297, val_loss=0.00374]Epoch 21:  21%|██        | 6/29 [00:00<00:00, 190.83it/s, train_loss=0.00297, val_loss=0.00374]Epoch 21:  21%|██        | 6/29 [00:00<00:00, 178.07it/s, train_loss=0.00251, val_loss=0.00374]Epoch 21:  24%|██▍       | 7/29 [00:00<00:00, 186.66it/s, train_loss=0.00251, val_loss=0.00374]Epoch 21:  24%|██▍       | 7/29 [00:00<00:00, 178.97it/s, train_loss=0.00239, val_loss=0.00374]Epoch 21:  28%|██▊       | 8/29 [00:00<00:00, 186.67it/s, train_loss=0.00239, val_loss=0.00374]Epoch 21:  28%|██▊       | 8/29 [00:00<00:00, 178.03it/s, train_loss=0.00238, val_loss=0.00374]Epoch 21:  31%|███       | 9/29 [00:00<00:00, 185.85it/s, train_loss=0.00238, val_loss=0.00374]Epoch 21:  31%|███       | 9/29 [00:00<00:00, 177.57it/s, train_loss=0.00284, val_loss=0.00374]Epoch 21:  34%|███▍      | 10/29 [00:00<00:00, 184.77it/s, train_loss=0.00284, val_loss=0.00374]Epoch 21:  34%|███▍      | 10/29 [00:00<00:00, 177.06it/s, train_loss=0.00234, val_loss=0.00374]Epoch 21:  38%|███▊      | 11/29 [00:00<00:00, 183.24it/s, train_loss=0.00234, val_loss=0.00374]Epoch 21:  38%|███▊      | 11/29 [00:00<00:00, 176.73it/s, train_loss=0.00307, val_loss=0.00374]Epoch 21:  41%|████▏     | 12/29 [00:00<00:00, 182.47it/s, train_loss=0.00307, val_loss=0.00374]Epoch 21:  41%|████▏     | 12/29 [00:00<00:00, 176.44it/s, train_loss=0.00327, val_loss=0.00374]Epoch 21:  45%|████▍     | 13/29 [00:00<00:00, 180.58it/s, train_loss=0.00327, val_loss=0.00374]Epoch 21:  45%|████▍     | 13/29 [00:00<00:00, 176.71it/s, train_loss=0.00172, val_loss=0.00374]Epoch 21:  48%|████▊     | 14/29 [00:00<00:00, 181.93it/s, train_loss=0.00172, val_loss=0.00374]Epoch 21:  48%|████▊     | 14/29 [00:00<00:00, 180.74it/s, train_loss=0.00314, val_loss=0.00374]Epoch 21:  52%|█████▏    | 15/29 [00:00<00:00, 185.77it/s, train_loss=0.00314, val_loss=0.00374]Epoch 21:  52%|█████▏    | 15/29 [00:00<00:00, 180.93it/s, train_loss=0.0021, val_loss=0.00374] Epoch 21:  55%|█████▌    | 16/29 [00:00<00:00, 185.71it/s, train_loss=0.0021, val_loss=0.00374]Epoch 21:  55%|█████▌    | 16/29 [00:00<00:00, 184.48it/s, train_loss=0.0032, val_loss=0.00374]Epoch 21:  59%|█████▊    | 17/29 [00:00<00:00, 188.97it/s, train_loss=0.0032, val_loss=0.00374]Epoch 21:  59%|█████▊    | 17/29 [00:00<00:00, 184.35it/s, train_loss=0.0026, val_loss=0.00374]Epoch 21:  62%|██████▏   | 18/29 [00:00<00:00, 188.57it/s, train_loss=0.0026, val_loss=0.00374]Epoch 21:  62%|██████▏   | 18/29 [00:00<00:00, 187.30it/s, train_loss=0.00417, val_loss=0.00374]Epoch 21:  66%|██████▌   | 19/29 [00:00<00:00, 191.11it/s, train_loss=0.00417, val_loss=0.00374]Epoch 21:  66%|██████▌   | 19/29 [00:00<00:00, 187.31it/s, train_loss=0.0024, val_loss=0.00374] Epoch 21:  69%|██████▉   | 20/29 [00:00<00:00, 190.88it/s, train_loss=0.0024, val_loss=0.00374]Epoch 21:  69%|██████▉   | 20/29 [00:00<00:00, 189.57it/s, train_loss=0.00347, val_loss=0.00374]Epoch 21:  72%|███████▏  | 21/29 [00:00<00:00, 192.56it/s, train_loss=0.00347, val_loss=0.00374]Epoch 21:  72%|███████▏  | 21/29 [00:00<00:00, 190.03it/s, train_loss=0.00352, val_loss=0.00374]Epoch 21:  76%|███████▌  | 22/29 [00:00<00:00, 192.83it/s, train_loss=0.00352, val_loss=0.00374]Epoch 21:  76%|███████▌  | 22/29 [00:00<00:00, 189.09it/s, train_loss=0.00225, val_loss=0.00374]Epoch 21:  79%|███████▉  | 23/29 [00:00<00:00, 192.07it/s, train_loss=0.00225, val_loss=0.00374]Epoch 21:  79%|███████▉  | 23/29 [00:00<00:00, 188.35it/s, train_loss=0.00505, val_loss=0.00374]Epoch 21:  83%|████████▎ | 24/29 [00:00<00:00, 191.04it/s, train_loss=0.00505, val_loss=0.00374]Epoch 21:  83%|████████▎ | 24/29 [00:00<00:00, 187.64it/s, train_loss=0.00417, val_loss=0.00374]Epoch 21:  86%|████████▌ | 25/29 [00:00<00:00, 190.31it/s, train_loss=0.00417, val_loss=0.00374]Epoch 21:  86%|████████▌ | 25/29 [00:00<00:00, 187.06it/s, train_loss=0.00351, val_loss=0.00374]Epoch 21:  90%|████████▉ | 26/29 [00:00<00:00, 189.63it/s, train_loss=0.00351, val_loss=0.00374]Epoch 21:  90%|████████▉ | 26/29 [00:00<00:00, 186.54it/s, train_loss=0.00269, val_loss=0.00374]Epoch 21:  93%|█████████▎| 27/29 [00:00<00:00, 188.60it/s, train_loss=0.00269, val_loss=0.00374]Epoch 21:  93%|█████████▎| 27/29 [00:00<00:00, 186.71it/s, train_loss=0.00347, val_loss=0.00374]Epoch 21:  97%|█████████▋| 28/29 [00:00<00:00, 188.73it/s, train_loss=0.00347, val_loss=0.00374]Epoch 21:  97%|█████████▋| 28/29 [00:00<00:00, 186.09it/s, train_loss=0.00271, val_loss=0.00374]Epoch 21: 100%|██████████| 29/29 [00:00<00:00, 188.42it/s, train_loss=0.00271, val_loss=0.00374]Epoch 21: 100%|██████████| 29/29 [00:00<00:00, 185.63it/s, train_loss=0.00183, val_loss=0.00374]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 156.78it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 217.38it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 258.66it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 285.75it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 305.17it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 318.81it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 328.96it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 335.13it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 338.64it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 340.61it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 342.55it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 343.39it/s][A
                                                                         [AEpoch 21: 100%|██████████| 29/29 [00:00<00:00, 144.92it/s, train_loss=0.00183, val_loss=0.00365]Epoch 21: 100%|██████████| 29/29 [00:00<00:00, 144.35it/s, train_loss=0.00183, val_loss=0.00365]Epoch 21:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00183, val_loss=0.00365]          Epoch 22:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00183, val_loss=0.00365]Epoch 22:   3%|▎         | 1/29 [00:00<00:00, 220.86it/s, train_loss=0.00183, val_loss=0.00365]Epoch 22:   3%|▎         | 1/29 [00:00<00:00, 148.96it/s, train_loss=0.00245, val_loss=0.00365]Epoch 22:   7%|▋         | 2/29 [00:00<00:00, 193.42it/s, train_loss=0.00245, val_loss=0.00365]Epoch 22:   7%|▋         | 2/29 [00:00<00:00, 159.06it/s, train_loss=0.00371, val_loss=0.00365]Epoch 22:  10%|█         | 3/29 [00:00<00:00, 186.42it/s, train_loss=0.00371, val_loss=0.00365]Epoch 22:  10%|█         | 3/29 [00:00<00:00, 162.74it/s, train_loss=0.00265, val_loss=0.00365]Epoch 22:  14%|█▍        | 4/29 [00:00<00:00, 182.66it/s, train_loss=0.00265, val_loss=0.00365]Epoch 22:  14%|█▍        | 4/29 [00:00<00:00, 164.80it/s, train_loss=0.00217, val_loss=0.00365]Epoch 22:  17%|█▋        | 5/29 [00:00<00:00, 180.89it/s, train_loss=0.00217, val_loss=0.00365]Epoch 22:  17%|█▋        | 5/29 [00:00<00:00, 175.79it/s, train_loss=0.00413, val_loss=0.00365]Epoch 22:  21%|██        | 6/29 [00:00<00:00, 188.03it/s, train_loss=0.00413, val_loss=0.00365]Epoch 22:  21%|██        | 6/29 [00:00<00:00, 178.68it/s, train_loss=0.00272, val_loss=0.00365]Epoch 22:  24%|██▍       | 7/29 [00:00<00:00, 186.11it/s, train_loss=0.00272, val_loss=0.00365]Epoch 22:  24%|██▍       | 7/29 [00:00<00:00, 178.95it/s, train_loss=0.00295, val_loss=0.00365]Epoch 22:  28%|██▊       | 8/29 [00:00<00:00, 186.54it/s, train_loss=0.00295, val_loss=0.00365]Epoch 22:  28%|██▊       | 8/29 [00:00<00:00, 177.90it/s, train_loss=0.00252, val_loss=0.00365]Epoch 22:  31%|███       | 9/29 [00:00<00:00, 185.47it/s, train_loss=0.00252, val_loss=0.00365]Epoch 22:  31%|███       | 9/29 [00:00<00:00, 177.36it/s, train_loss=0.0055, val_loss=0.00365] Epoch 22:  34%|███▍      | 10/29 [00:00<00:00, 184.26it/s, train_loss=0.0055, val_loss=0.00365]Epoch 22:  34%|███▍      | 10/29 [00:00<00:00, 176.63it/s, train_loss=0.00244, val_loss=0.00365]Epoch 22:  38%|███▊      | 11/29 [00:00<00:00, 183.14it/s, train_loss=0.00244, val_loss=0.00365]Epoch 22:  38%|███▊      | 11/29 [00:00<00:00, 176.26it/s, train_loss=0.00362, val_loss=0.00365]Epoch 22:  41%|████▏     | 12/29 [00:00<00:00, 181.92it/s, train_loss=0.00362, val_loss=0.00365]Epoch 22:  41%|████▏     | 12/29 [00:00<00:00, 176.02it/s, train_loss=0.00228, val_loss=0.00365]Epoch 22:  45%|████▍     | 13/29 [00:00<00:00, 180.45it/s, train_loss=0.00228, val_loss=0.00365]Epoch 22:  45%|████▍     | 13/29 [00:00<00:00, 176.57it/s, train_loss=0.0035, val_loss=0.00365] Epoch 22:  48%|████▊     | 14/29 [00:00<00:00, 180.88it/s, train_loss=0.0035, val_loss=0.00365]Epoch 22:  48%|████▊     | 14/29 [00:00<00:00, 176.19it/s, train_loss=0.00321, val_loss=0.00365]Epoch 22:  52%|█████▏    | 15/29 [00:00<00:00, 181.32it/s, train_loss=0.00321, val_loss=0.00365]Epoch 22:  52%|█████▏    | 15/29 [00:00<00:00, 180.02it/s, train_loss=0.00301, val_loss=0.00365]Epoch 22:  55%|█████▌    | 16/29 [00:00<00:00, 184.86it/s, train_loss=0.00301, val_loss=0.00365]Epoch 22:  55%|█████▌    | 16/29 [00:00<00:00, 180.39it/s, train_loss=0.00174, val_loss=0.00365]Epoch 22:  59%|█████▊    | 17/29 [00:00<00:00, 185.05it/s, train_loss=0.00174, val_loss=0.00365]Epoch 22:  59%|█████▊    | 17/29 [00:00<00:00, 183.68it/s, train_loss=0.00236, val_loss=0.00365]Epoch 22:  62%|██████▏   | 18/29 [00:00<00:00, 188.08it/s, train_loss=0.00236, val_loss=0.00365]Epoch 22:  62%|██████▏   | 18/29 [00:00<00:00, 183.85it/s, train_loss=0.00319, val_loss=0.00365]Epoch 22:  66%|██████▌   | 19/29 [00:00<00:00, 187.01it/s, train_loss=0.00319, val_loss=0.00365]Epoch 22:  66%|██████▌   | 19/29 [00:00<00:00, 183.33it/s, train_loss=0.00178, val_loss=0.00365]Epoch 22:  69%|██████▉   | 20/29 [00:00<00:00, 186.35it/s, train_loss=0.00178, val_loss=0.00365]Epoch 22:  69%|██████▉   | 20/29 [00:00<00:00, 183.75it/s, train_loss=0.00312, val_loss=0.00365]Epoch 22:  72%|███████▏  | 21/29 [00:00<00:00, 186.85it/s, train_loss=0.00312, val_loss=0.00365]Epoch 22:  72%|███████▏  | 21/29 [00:00<00:00, 183.17it/s, train_loss=0.00237, val_loss=0.00365]Epoch 22:  76%|███████▌  | 22/29 [00:00<00:00, 186.38it/s, train_loss=0.00237, val_loss=0.00365]Epoch 22:  76%|███████▌  | 22/29 [00:00<00:00, 182.69it/s, train_loss=0.00384, val_loss=0.00365]Epoch 22:  79%|███████▉  | 23/29 [00:00<00:00, 185.72it/s, train_loss=0.00384, val_loss=0.00365]Epoch 22:  79%|███████▉  | 23/29 [00:00<00:00, 182.25it/s, train_loss=0.00363, val_loss=0.00365]Epoch 22:  83%|████████▎ | 24/29 [00:00<00:00, 185.04it/s, train_loss=0.00363, val_loss=0.00365]Epoch 22:  83%|████████▎ | 24/29 [00:00<00:00, 181.85it/s, train_loss=0.00269, val_loss=0.00365]Epoch 22:  86%|████████▌ | 25/29 [00:00<00:00, 184.59it/s, train_loss=0.00269, val_loss=0.00365]Epoch 22:  86%|████████▌ | 25/29 [00:00<00:00, 181.57it/s, train_loss=0.00308, val_loss=0.00365]Epoch 22:  90%|████████▉ | 26/29 [00:00<00:00, 183.85it/s, train_loss=0.00308, val_loss=0.00365]Epoch 22:  90%|████████▉ | 26/29 [00:00<00:00, 181.83it/s, train_loss=0.0029, val_loss=0.00365] Epoch 22:  93%|█████████▎| 27/29 [00:00<00:00, 184.17it/s, train_loss=0.0029, val_loss=0.00365]Epoch 22:  93%|█████████▎| 27/29 [00:00<00:00, 181.39it/s, train_loss=0.00327, val_loss=0.00365]Epoch 22:  97%|█████████▋| 28/29 [00:00<00:00, 183.72it/s, train_loss=0.00327, val_loss=0.00365]Epoch 22:  97%|█████████▋| 28/29 [00:00<00:00, 181.07it/s, train_loss=0.00461, val_loss=0.00365]Epoch 22: 100%|██████████| 29/29 [00:00<00:00, 183.39it/s, train_loss=0.00461, val_loss=0.00365]Epoch 22: 100%|██████████| 29/29 [00:00<00:00, 180.73it/s, train_loss=0.00298, val_loss=0.00365]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 158.70it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 202.24it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 224.50it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 234.35it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 251.29it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 266.46it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 279.15it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 287.90it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 295.45it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 303.61it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 308.84it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 313.84it/s][A
                                                                         [AEpoch 22: 100%|██████████| 29/29 [00:00<00:00, 139.82it/s, train_loss=0.00298, val_loss=0.00356]Epoch 22: 100%|██████████| 29/29 [00:00<00:00, 139.37it/s, train_loss=0.00298, val_loss=0.00356]Epoch 22:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00356]          Epoch 23:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00356]Epoch 23:   3%|▎         | 1/29 [00:00<00:00, 226.82it/s, train_loss=0.00298, val_loss=0.00356]Epoch 23:   3%|▎         | 1/29 [00:00<00:00, 174.34it/s, train_loss=0.00474, val_loss=0.00356]Epoch 23:   7%|▋         | 2/29 [00:00<00:00, 218.52it/s, train_loss=0.00474, val_loss=0.00356]Epoch 23:   7%|▋         | 2/29 [00:00<00:00, 174.20it/s, train_loss=0.00252, val_loss=0.00356]Epoch 23:  10%|█         | 3/29 [00:00<00:00, 197.40it/s, train_loss=0.00252, val_loss=0.00356]Epoch 23:  10%|█         | 3/29 [00:00<00:00, 174.53it/s, train_loss=0.00274, val_loss=0.00356]Epoch 23:  14%|█▍        | 4/29 [00:00<00:00, 191.30it/s, train_loss=0.00274, val_loss=0.00356]Epoch 23:  14%|█▍        | 4/29 [00:00<00:00, 173.77it/s, train_loss=0.00314, val_loss=0.00356]Epoch 23:  17%|█▋        | 5/29 [00:00<00:00, 189.13it/s, train_loss=0.00314, val_loss=0.00356]Epoch 23:  17%|█▋        | 5/29 [00:00<00:00, 173.63it/s, train_loss=0.00325, val_loss=0.00356]Epoch 23:  21%|██        | 6/29 [00:00<00:00, 185.55it/s, train_loss=0.00325, val_loss=0.00356]Epoch 23:  21%|██        | 6/29 [00:00<00:00, 173.40it/s, train_loss=0.00275, val_loss=0.00356]Epoch 23:  24%|██▍       | 7/29 [00:00<00:00, 183.51it/s, train_loss=0.00275, val_loss=0.00356]Epoch 23:  24%|██▍       | 7/29 [00:00<00:00, 173.40it/s, train_loss=0.00253, val_loss=0.00356]Epoch 23:  28%|██▊       | 8/29 [00:00<00:00, 182.12it/s, train_loss=0.00253, val_loss=0.00356]Epoch 23:  28%|██▊       | 8/29 [00:00<00:00, 173.43it/s, train_loss=0.00344, val_loss=0.00356]Epoch 23:  31%|███       | 9/29 [00:00<00:00, 179.64it/s, train_loss=0.00344, val_loss=0.00356]Epoch 23:  31%|███       | 9/29 [00:00<00:00, 174.81it/s, train_loss=0.00236, val_loss=0.00356]Epoch 23:  34%|███▍      | 10/29 [00:00<00:00, 181.41it/s, train_loss=0.00236, val_loss=0.00356]Epoch 23:  34%|███▍      | 10/29 [00:00<00:00, 174.46it/s, train_loss=0.00307, val_loss=0.00356]Epoch 23:  38%|███▊      | 11/29 [00:00<00:00, 180.85it/s, train_loss=0.00307, val_loss=0.00356]Epoch 23:  38%|███▊      | 11/29 [00:00<00:00, 174.34it/s, train_loss=0.00373, val_loss=0.00356]Epoch 23:  41%|████▏     | 12/29 [00:00<00:00, 179.93it/s, train_loss=0.00373, val_loss=0.00356]Epoch 23:  41%|████▏     | 12/29 [00:00<00:00, 174.25it/s, train_loss=0.00536, val_loss=0.00356]Epoch 23:  45%|████▍     | 13/29 [00:00<00:00, 179.25it/s, train_loss=0.00536, val_loss=0.00356]Epoch 23:  45%|████▍     | 13/29 [00:00<00:00, 174.10it/s, train_loss=0.00279, val_loss=0.00356]Epoch 23:  48%|████▊     | 14/29 [00:00<00:00, 178.89it/s, train_loss=0.00279, val_loss=0.00356]Epoch 23:  48%|████▊     | 14/29 [00:00<00:00, 174.10it/s, train_loss=0.0023, val_loss=0.00356] Epoch 23:  52%|█████▏    | 15/29 [00:00<00:00, 178.02it/s, train_loss=0.0023, val_loss=0.00356]Epoch 23:  52%|█████▏    | 15/29 [00:00<00:00, 174.65it/s, train_loss=0.00298, val_loss=0.00356]Epoch 23:  55%|█████▌    | 16/29 [00:00<00:00, 179.38it/s, train_loss=0.00298, val_loss=0.00356]Epoch 23:  55%|█████▌    | 16/29 [00:00<00:00, 178.49it/s, train_loss=0.00216, val_loss=0.00356]Epoch 23:  59%|█████▊    | 17/29 [00:00<00:00, 183.08it/s, train_loss=0.00216, val_loss=0.00356]Epoch 23:  59%|█████▊    | 17/29 [00:00<00:00, 178.58it/s, train_loss=0.00287, val_loss=0.00356]Epoch 23:  62%|██████▏   | 18/29 [00:00<00:00, 182.86it/s, train_loss=0.00287, val_loss=0.00356]Epoch 23:  62%|██████▏   | 18/29 [00:00<00:00, 181.69it/s, train_loss=0.00298, val_loss=0.00356]Epoch 23:  66%|██████▌   | 19/29 [00:00<00:00, 185.57it/s, train_loss=0.00298, val_loss=0.00356]Epoch 23:  66%|██████▌   | 19/29 [00:00<00:00, 181.85it/s, train_loss=0.00214, val_loss=0.00356]Epoch 23:  69%|██████▉   | 20/29 [00:00<00:00, 185.59it/s, train_loss=0.00214, val_loss=0.00356]Epoch 23:  69%|██████▉   | 20/29 [00:00<00:00, 184.34it/s, train_loss=0.00288, val_loss=0.00356]Epoch 23:  72%|███████▏  | 21/29 [00:00<00:00, 187.64it/s, train_loss=0.00288, val_loss=0.00356]Epoch 23:  72%|███████▏  | 21/29 [00:00<00:00, 184.72it/s, train_loss=0.00346, val_loss=0.00356]Epoch 23:  76%|███████▌  | 22/29 [00:00<00:00, 187.82it/s, train_loss=0.00346, val_loss=0.00356]Epoch 23:  76%|███████▌  | 22/29 [00:00<00:00, 186.65it/s, train_loss=0.00269, val_loss=0.00356]Epoch 23:  79%|███████▉  | 23/29 [00:00<00:00, 189.33it/s, train_loss=0.00269, val_loss=0.00356]Epoch 23:  79%|███████▉  | 23/29 [00:00<00:00, 188.33it/s, train_loss=0.0019, val_loss=0.00356] Epoch 23:  83%|████████▎ | 24/29 [00:00<00:00, 191.08it/s, train_loss=0.0019, val_loss=0.00356]Epoch 23:  83%|████████▎ | 24/29 [00:00<00:00, 187.98it/s, train_loss=0.00248, val_loss=0.00356]Epoch 23:  86%|████████▌ | 25/29 [00:00<00:00, 190.67it/s, train_loss=0.00248, val_loss=0.00356]Epoch 23:  86%|████████▌ | 25/29 [00:00<00:00, 187.40it/s, train_loss=0.00284, val_loss=0.00356]Epoch 23:  90%|████████▉ | 26/29 [00:00<00:00, 189.99it/s, train_loss=0.00284, val_loss=0.00356]Epoch 23:  90%|████████▉ | 26/29 [00:00<00:00, 186.80it/s, train_loss=0.00379, val_loss=0.00356]Epoch 23:  93%|█████████▎| 27/29 [00:00<00:00, 189.26it/s, train_loss=0.00379, val_loss=0.00356]Epoch 23:  93%|█████████▎| 27/29 [00:00<00:00, 186.30it/s, train_loss=0.00331, val_loss=0.00356]Epoch 23:  97%|█████████▋| 28/29 [00:00<00:00, 188.54it/s, train_loss=0.00331, val_loss=0.00356]Epoch 23:  97%|█████████▋| 28/29 [00:00<00:00, 185.85it/s, train_loss=0.00231, val_loss=0.00356]Epoch 23: 100%|██████████| 29/29 [00:00<00:00, 187.79it/s, train_loss=0.00231, val_loss=0.00356]Epoch 23: 100%|██████████| 29/29 [00:00<00:00, 186.11it/s, train_loss=0.00282, val_loss=0.00356]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 164.31it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 203.36it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 221.77it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 233.02it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 238.99it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 245.33it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 257.85it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 271.41it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 281.05it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 289.06it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 294.57it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 299.22it/s][A
                                                                         [AEpoch 23: 100%|██████████| 29/29 [00:00<00:00, 142.09it/s, train_loss=0.00282, val_loss=0.0035] Epoch 23: 100%|██████████| 29/29 [00:00<00:00, 141.59it/s, train_loss=0.00282, val_loss=0.0035]Epoch 23:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00282, val_loss=0.0035]          Epoch 24:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00282, val_loss=0.0035]Epoch 24:   3%|▎         | 1/29 [00:00<00:00, 220.37it/s, train_loss=0.00282, val_loss=0.0035]Epoch 24:   3%|▎         | 1/29 [00:00<00:00, 194.34it/s, train_loss=0.00357, val_loss=0.0035]Epoch 24:   7%|▋         | 2/29 [00:00<00:00, 229.72it/s, train_loss=0.00357, val_loss=0.0035]Epoch 24:   7%|▋         | 2/29 [00:00<00:00, 190.97it/s, train_loss=0.00263, val_loss=0.0035]Epoch 24:  10%|█         | 3/29 [00:00<00:00, 216.06it/s, train_loss=0.00263, val_loss=0.0035]Epoch 24:  10%|█         | 3/29 [00:00<00:00, 184.39it/s, train_loss=0.00425, val_loss=0.0035]Epoch 24:  14%|█▍        | 4/29 [00:00<00:00, 203.29it/s, train_loss=0.00425, val_loss=0.0035]Epoch 24:  14%|█▍        | 4/29 [00:00<00:00, 195.58it/s, train_loss=0.00348, val_loss=0.0035]Epoch 24:  17%|█▋        | 5/29 [00:00<00:00, 209.92it/s, train_loss=0.00348, val_loss=0.0035]Epoch 24:  17%|█▋        | 5/29 [00:00<00:00, 195.73it/s, train_loss=0.00276, val_loss=0.0035]Epoch 24:  21%|██        | 6/29 [00:00<00:00, 206.66it/s, train_loss=0.00276, val_loss=0.0035]Epoch 24:  21%|██        | 6/29 [00:00<00:00, 191.66it/s, train_loss=0.00193, val_loss=0.0035]Epoch 24:  24%|██▍       | 7/29 [00:00<00:00, 200.61it/s, train_loss=0.00193, val_loss=0.0035]Epoch 24:  24%|██▍       | 7/29 [00:00<00:00, 195.48it/s, train_loss=0.00227, val_loss=0.0035]Epoch 24:  28%|██▊       | 8/29 [00:00<00:00, 201.96it/s, train_loss=0.00227, val_loss=0.0035]Epoch 24:  28%|██▊       | 8/29 [00:00<00:00, 198.31it/s, train_loss=0.00282, val_loss=0.0035]Epoch 24:  31%|███       | 9/29 [00:00<00:00, 204.60it/s, train_loss=0.00282, val_loss=0.0035]Epoch 24:  31%|███       | 9/29 [00:00<00:00, 197.09it/s, train_loss=0.00251, val_loss=0.0035]Epoch 24:  34%|███▍      | 10/29 [00:00<00:00, 203.33it/s, train_loss=0.00251, val_loss=0.0035]Epoch 24:  34%|███▍      | 10/29 [00:00<00:00, 194.34it/s, train_loss=0.0024, val_loss=0.0035] Epoch 24:  38%|███▊      | 11/29 [00:00<00:00, 200.02it/s, train_loss=0.0024, val_loss=0.0035]Epoch 24:  38%|███▊      | 11/29 [00:00<00:00, 192.08it/s, train_loss=0.00311, val_loss=0.0035]Epoch 24:  41%|████▏     | 12/29 [00:00<00:00, 197.45it/s, train_loss=0.00311, val_loss=0.0035]Epoch 24:  41%|████▏     | 12/29 [00:00<00:00, 190.42it/s, train_loss=0.00267, val_loss=0.0035]Epoch 24:  45%|████▍     | 13/29 [00:00<00:00, 195.36it/s, train_loss=0.00267, val_loss=0.0035]Epoch 24:  45%|████▍     | 13/29 [00:00<00:00, 189.05it/s, train_loss=0.00392, val_loss=0.0035]Epoch 24:  48%|████▊     | 14/29 [00:00<00:00, 193.08it/s, train_loss=0.00392, val_loss=0.0035]Epoch 24:  48%|████▊     | 14/29 [00:00<00:00, 189.22it/s, train_loss=0.00362, val_loss=0.0035]Epoch 24:  52%|█████▏    | 15/29 [00:00<00:00, 192.99it/s, train_loss=0.00362, val_loss=0.0035]Epoch 24:  52%|█████▏    | 15/29 [00:00<00:00, 187.94it/s, train_loss=0.00279, val_loss=0.0035]Epoch 24:  55%|█████▌    | 16/29 [00:00<00:00, 191.86it/s, train_loss=0.00279, val_loss=0.0035]Epoch 24:  55%|█████▌    | 16/29 [00:00<00:00, 186.88it/s, train_loss=0.00454, val_loss=0.0035]Epoch 24:  59%|█████▊    | 17/29 [00:00<00:00, 191.58it/s, train_loss=0.00454, val_loss=0.0035]Epoch 24:  59%|█████▊    | 17/29 [00:00<00:00, 190.47it/s, train_loss=0.00194, val_loss=0.0035]Epoch 24:  62%|██████▏   | 18/29 [00:00<00:00, 194.96it/s, train_loss=0.00194, val_loss=0.0035]Epoch 24:  62%|██████▏   | 18/29 [00:00<00:00, 193.61it/s, train_loss=0.0039, val_loss=0.0035] Epoch 24:  66%|██████▌   | 19/29 [00:00<00:00, 197.52it/s, train_loss=0.0039, val_loss=0.0035]Epoch 24:  66%|██████▌   | 19/29 [00:00<00:00, 193.17it/s, train_loss=0.00196, val_loss=0.0035]Epoch 24:  69%|██████▉   | 20/29 [00:00<00:00, 196.82it/s, train_loss=0.00196, val_loss=0.0035]Epoch 24:  69%|██████▉   | 20/29 [00:00<00:00, 195.58it/s, train_loss=0.00205, val_loss=0.0035]Epoch 24:  72%|███████▏  | 21/29 [00:00<00:00, 198.63it/s, train_loss=0.00205, val_loss=0.0035]Epoch 24:  72%|███████▏  | 21/29 [00:00<00:00, 197.49it/s, train_loss=0.00323, val_loss=0.0035]Epoch 24:  76%|███████▌  | 22/29 [00:00<00:00, 200.34it/s, train_loss=0.00323, val_loss=0.0035]Epoch 24:  76%|███████▌  | 22/29 [00:00<00:00, 196.55it/s, train_loss=0.00262, val_loss=0.0035]Epoch 24:  79%|███████▉  | 23/29 [00:00<00:00, 199.11it/s, train_loss=0.00262, val_loss=0.0035]Epoch 24:  79%|███████▉  | 23/29 [00:00<00:00, 195.40it/s, train_loss=0.00343, val_loss=0.0035]Epoch 24:  83%|████████▎ | 24/29 [00:00<00:00, 198.00it/s, train_loss=0.00343, val_loss=0.0035]Epoch 24:  83%|████████▎ | 24/29 [00:00<00:00, 194.37it/s, train_loss=0.00218, val_loss=0.0035]Epoch 24:  86%|████████▌ | 25/29 [00:00<00:00, 196.81it/s, train_loss=0.00218, val_loss=0.0035]Epoch 24:  86%|████████▌ | 25/29 [00:00<00:00, 193.40it/s, train_loss=0.00276, val_loss=0.0035]Epoch 24:  90%|████████▉ | 26/29 [00:00<00:00, 195.89it/s, train_loss=0.00276, val_loss=0.0035]Epoch 24:  90%|████████▉ | 26/29 [00:00<00:00, 192.57it/s, train_loss=0.00317, val_loss=0.0035]Epoch 24:  93%|█████████▎| 27/29 [00:00<00:00, 194.95it/s, train_loss=0.00317, val_loss=0.0035]Epoch 24:  93%|█████████▎| 27/29 [00:00<00:00, 193.92it/s, train_loss=0.00225, val_loss=0.0035]Epoch 24:  97%|█████████▋| 28/29 [00:00<00:00, 196.00it/s, train_loss=0.00225, val_loss=0.0035]Epoch 24:  97%|█████████▋| 28/29 [00:00<00:00, 194.98it/s, train_loss=0.00337, val_loss=0.0035]Epoch 24: 100%|██████████| 29/29 [00:00<00:00, 197.15it/s, train_loss=0.00337, val_loss=0.0035]Epoch 24: 100%|██████████| 29/29 [00:00<00:00, 194.93it/s, train_loss=0.00181, val_loss=0.0035]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 161.73it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 203.87it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 224.07it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 234.88it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 243.86it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 250.27it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 253.25it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 252.96it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 253.84it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 261.38it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 270.39it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 278.38it/s][A
                                                                         [AEpoch 24: 100%|██████████| 29/29 [00:00<00:00, 145.78it/s, train_loss=0.00181, val_loss=0.00346]Epoch 24: 100%|██████████| 29/29 [00:00<00:00, 145.34it/s, train_loss=0.00181, val_loss=0.00346]Epoch 24:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00181, val_loss=0.00346]          Epoch 25:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00181, val_loss=0.00346]Epoch 25:   3%|▎         | 1/29 [00:00<00:00, 231.50it/s, train_loss=0.00181, val_loss=0.00346]Epoch 25:   3%|▎         | 1/29 [00:00<00:00, 175.21it/s, train_loss=0.00208, val_loss=0.00346]Epoch 25:   7%|▋         | 2/29 [00:00<00:00, 220.03it/s, train_loss=0.00208, val_loss=0.00346]Epoch 25:   7%|▋         | 2/29 [00:00<00:00, 205.36it/s, train_loss=0.00454, val_loss=0.00346]Epoch 25:  10%|█         | 3/29 [00:00<00:00, 226.06it/s, train_loss=0.00454, val_loss=0.00346]Epoch 25:  10%|█         | 3/29 [00:00<00:00, 199.33it/s, train_loss=0.00252, val_loss=0.00346]Epoch 25:  14%|█▍        | 4/29 [00:00<00:00, 216.57it/s, train_loss=0.00252, val_loss=0.00346]Epoch 25:  14%|█▍        | 4/29 [00:00<00:00, 192.27it/s, train_loss=0.00235, val_loss=0.00346]Epoch 25:  17%|█▋        | 5/29 [00:00<00:00, 206.13it/s, train_loss=0.00235, val_loss=0.00346]Epoch 25:  17%|█▋        | 5/29 [00:00<00:00, 198.74it/s, train_loss=0.00207, val_loss=0.00346]Epoch 25:  21%|██        | 6/29 [00:00<00:00, 208.69it/s, train_loss=0.00207, val_loss=0.00346]Epoch 25:  21%|██        | 6/29 [00:00<00:00, 203.92it/s, train_loss=0.00327, val_loss=0.00346]Epoch 25:  24%|██▍       | 7/29 [00:00<00:00, 212.09it/s, train_loss=0.00327, val_loss=0.00346]Epoch 25:  24%|██▍       | 7/29 [00:00<00:00, 199.47it/s, train_loss=0.00321, val_loss=0.00346]Epoch 25:  28%|██▊       | 8/29 [00:00<00:00, 207.42it/s, train_loss=0.00321, val_loss=0.00346]Epoch 25:  28%|██▊       | 8/29 [00:00<00:00, 195.72it/s, train_loss=0.00252, val_loss=0.00346]Epoch 25:  31%|███       | 9/29 [00:00<00:00, 203.08it/s, train_loss=0.00252, val_loss=0.00346]Epoch 25:  31%|███       | 9/29 [00:00<00:00, 199.40it/s, train_loss=0.00233, val_loss=0.00346]Epoch 25:  34%|███▍      | 10/29 [00:00<00:00, 205.86it/s, train_loss=0.00233, val_loss=0.00346]Epoch 25:  34%|███▍      | 10/29 [00:00<00:00, 198.99it/s, train_loss=0.00293, val_loss=0.00346]Epoch 25:  38%|███▊      | 11/29 [00:00<00:00, 204.47it/s, train_loss=0.00293, val_loss=0.00346]Epoch 25:  38%|███▊      | 11/29 [00:00<00:00, 196.44it/s, train_loss=0.00237, val_loss=0.00346]Epoch 25:  41%|████▏     | 12/29 [00:00<00:00, 200.96it/s, train_loss=0.00237, val_loss=0.00346]Epoch 25:  41%|████▏     | 12/29 [00:00<00:00, 198.19it/s, train_loss=0.00385, val_loss=0.00346]Epoch 25:  45%|████▍     | 13/29 [00:00<00:00, 202.22it/s, train_loss=0.00385, val_loss=0.00346]Epoch 25:  45%|████▍     | 13/29 [00:00<00:00, 195.66it/s, train_loss=0.00316, val_loss=0.00346]Epoch 25:  48%|████▊     | 14/29 [00:00<00:00, 199.58it/s, train_loss=0.00316, val_loss=0.00346]Epoch 25:  48%|████▊     | 14/29 [00:00<00:00, 193.82it/s, train_loss=0.00285, val_loss=0.00346]Epoch 25:  52%|█████▏    | 15/29 [00:00<00:00, 197.97it/s, train_loss=0.00285, val_loss=0.00346]Epoch 25:  52%|█████▏    | 15/29 [00:00<00:00, 192.21it/s, train_loss=0.00319, val_loss=0.00346]Epoch 25:  55%|█████▌    | 16/29 [00:00<00:00, 196.02it/s, train_loss=0.00319, val_loss=0.00346]Epoch 25:  55%|█████▌    | 16/29 [00:00<00:00, 190.98it/s, train_loss=0.00389, val_loss=0.00346]Epoch 25:  59%|█████▊    | 17/29 [00:00<00:00, 194.24it/s, train_loss=0.00389, val_loss=0.00346]Epoch 25:  59%|█████▊    | 17/29 [00:00<00:00, 189.86it/s, train_loss=0.00226, val_loss=0.00346]Epoch 25:  62%|██████▏   | 18/29 [00:00<00:00, 194.05it/s, train_loss=0.00226, val_loss=0.00346]Epoch 25:  62%|██████▏   | 18/29 [00:00<00:00, 192.82it/s, train_loss=0.00228, val_loss=0.00346]Epoch 25:  66%|██████▌   | 19/29 [00:00<00:00, 196.50it/s, train_loss=0.00228, val_loss=0.00346]Epoch 25:  66%|██████▌   | 19/29 [00:00<00:00, 193.54it/s, train_loss=0.00392, val_loss=0.00346]Epoch 25:  69%|██████▉   | 20/29 [00:00<00:00, 196.83it/s, train_loss=0.00392, val_loss=0.00346]Epoch 25:  69%|██████▉   | 20/29 [00:00<00:00, 195.78it/s, train_loss=0.00378, val_loss=0.00346]Epoch 25:  72%|███████▏  | 21/29 [00:00<00:00, 199.11it/s, train_loss=0.00378, val_loss=0.00346]Epoch 25:  72%|███████▏  | 21/29 [00:00<00:00, 195.47it/s, train_loss=0.00249, val_loss=0.00346]Epoch 25:  76%|███████▌  | 22/29 [00:00<00:00, 198.65it/s, train_loss=0.00249, val_loss=0.00346]Epoch 25:  76%|███████▌  | 22/29 [00:00<00:00, 197.47it/s, train_loss=0.00229, val_loss=0.00346]Epoch 25:  79%|███████▉  | 23/29 [00:00<00:00, 200.55it/s, train_loss=0.00229, val_loss=0.00346]Epoch 25:  79%|███████▉  | 23/29 [00:00<00:00, 197.16it/s, train_loss=0.00241, val_loss=0.00346]Epoch 25:  83%|████████▎ | 24/29 [00:00<00:00, 199.93it/s, train_loss=0.00241, val_loss=0.00346]Epoch 25:  83%|████████▎ | 24/29 [00:00<00:00, 198.70it/s, train_loss=0.00334, val_loss=0.00346]Epoch 25:  86%|████████▌ | 25/29 [00:00<00:00, 201.33it/s, train_loss=0.00334, val_loss=0.00346]Epoch 25:  86%|████████▌ | 25/29 [00:00<00:00, 198.63it/s, train_loss=0.00284, val_loss=0.00346]Epoch 25:  90%|████████▉ | 26/29 [00:00<00:00, 200.81it/s, train_loss=0.00284, val_loss=0.00346]Epoch 25:  90%|████████▉ | 26/29 [00:00<00:00, 199.67it/s, train_loss=0.00223, val_loss=0.00346]Epoch 25:  93%|█████████▎| 27/29 [00:00<00:00, 201.76it/s, train_loss=0.00223, val_loss=0.00346]Epoch 25:  93%|█████████▎| 27/29 [00:00<00:00, 198.59it/s, train_loss=0.00303, val_loss=0.00346]Epoch 25:  97%|█████████▋| 28/29 [00:00<00:00, 200.51it/s, train_loss=0.00303, val_loss=0.00346]Epoch 25:  97%|█████████▋| 28/29 [00:00<00:00, 197.57it/s, train_loss=0.00256, val_loss=0.00346]Epoch 25: 100%|██████████| 29/29 [00:00<00:00, 199.60it/s, train_loss=0.00256, val_loss=0.00346]Epoch 25: 100%|██████████| 29/29 [00:00<00:00, 196.57it/s, train_loss=0.00191, val_loss=0.00346]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 164.55it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 207.82it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 227.24it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 239.12it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 247.42it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 251.40it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 254.24it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 256.59it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 257.35it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 259.12it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 260.31it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 266.61it/s][A
                                                                         [AEpoch 25: 100%|██████████| 29/29 [00:00<00:00, 145.58it/s, train_loss=0.00191, val_loss=0.00338]Epoch 25: 100%|██████████| 29/29 [00:00<00:00, 145.10it/s, train_loss=0.00191, val_loss=0.00338]Epoch 25:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00191, val_loss=0.00338]          Epoch 26:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00191, val_loss=0.00338]Epoch 26:   3%|▎         | 1/29 [00:00<00:00, 239.85it/s, train_loss=0.00191, val_loss=0.00338]Epoch 26:   3%|▎         | 1/29 [00:00<00:00, 175.55it/s, train_loss=0.0021, val_loss=0.00338] Epoch 26:   7%|▋         | 2/29 [00:00<00:00, 223.08it/s, train_loss=0.0021, val_loss=0.00338]Epoch 26:   7%|▋         | 2/29 [00:00<00:00, 207.59it/s, train_loss=0.00293, val_loss=0.00338]Epoch 26:  10%|█         | 3/29 [00:00<00:00, 225.94it/s, train_loss=0.00293, val_loss=0.00338]Epoch 26:  10%|█         | 3/29 [00:00<00:00, 202.16it/s, train_loss=0.00198, val_loss=0.00338]Epoch 26:  14%|█▍        | 4/29 [00:00<00:00, 216.85it/s, train_loss=0.00198, val_loss=0.00338]Epoch 26:  14%|█▍        | 4/29 [00:00<00:00, 193.29it/s, train_loss=0.0042, val_loss=0.00338] Epoch 26:  17%|█▋        | 5/29 [00:00<00:00, 206.28it/s, train_loss=0.0042, val_loss=0.00338]Epoch 26:  17%|█▋        | 5/29 [00:00<00:00, 188.64it/s, train_loss=0.00326, val_loss=0.00338]Epoch 26:  21%|██        | 6/29 [00:00<00:00, 200.66it/s, train_loss=0.00326, val_loss=0.00338]Epoch 26:  21%|██        | 6/29 [00:00<00:00, 195.62it/s, train_loss=0.00181, val_loss=0.00338]Epoch 26:  24%|██▍       | 7/29 [00:00<00:00, 200.50it/s, train_loss=0.00181, val_loss=0.00338]Epoch 26:  24%|██▍       | 7/29 [00:00<00:00, 196.22it/s, train_loss=0.00323, val_loss=0.00338]Epoch 26:  28%|██▊       | 8/29 [00:00<00:00, 204.98it/s, train_loss=0.00323, val_loss=0.00338]Epoch 26:  28%|██▊       | 8/29 [00:00<00:00, 193.43it/s, train_loss=0.00323, val_loss=0.00338]Epoch 26:  31%|███       | 9/29 [00:00<00:00, 201.25it/s, train_loss=0.00323, val_loss=0.00338]Epoch 26:  31%|███       | 9/29 [00:00<00:00, 197.76it/s, train_loss=0.00336, val_loss=0.00338]Epoch 26:  34%|███▍      | 10/29 [00:00<00:00, 203.87it/s, train_loss=0.00336, val_loss=0.00338]Epoch 26:  34%|███▍      | 10/29 [00:00<00:00, 197.78it/s, train_loss=0.00285, val_loss=0.00338]Epoch 26:  38%|███▊      | 11/29 [00:00<00:00, 203.18it/s, train_loss=0.00285, val_loss=0.00338]Epoch 26:  38%|███▊      | 11/29 [00:00<00:00, 195.19it/s, train_loss=0.0035, val_loss=0.00338] Epoch 26:  41%|████▏     | 12/29 [00:00<00:00, 200.85it/s, train_loss=0.0035, val_loss=0.00338]Epoch 26:  41%|████▏     | 12/29 [00:00<00:00, 193.17it/s, train_loss=0.00348, val_loss=0.00338]Epoch 26:  45%|████▍     | 13/29 [00:00<00:00, 198.23it/s, train_loss=0.00348, val_loss=0.00338]Epoch 26:  45%|████▍     | 13/29 [00:00<00:00, 191.44it/s, train_loss=0.0026, val_loss=0.00338] Epoch 26:  48%|████▊     | 14/29 [00:00<00:00, 196.44it/s, train_loss=0.0026, val_loss=0.00338]Epoch 26:  48%|████▊     | 14/29 [00:00<00:00, 194.12it/s, train_loss=0.00192, val_loss=0.00338]Epoch 26:  52%|█████▏    | 15/29 [00:00<00:00, 198.51it/s, train_loss=0.00192, val_loss=0.00338]Epoch 26:  52%|█████▏    | 15/29 [00:00<00:00, 194.45it/s, train_loss=0.00189, val_loss=0.00338]Epoch 26:  55%|█████▌    | 16/29 [00:00<00:00, 198.30it/s, train_loss=0.00189, val_loss=0.00338]Epoch 26:  55%|█████▌    | 16/29 [00:00<00:00, 196.30it/s, train_loss=0.00335, val_loss=0.00338]Epoch 26:  59%|█████▊    | 17/29 [00:00<00:00, 199.41it/s, train_loss=0.00335, val_loss=0.00338]Epoch 26:  59%|█████▊    | 17/29 [00:00<00:00, 194.85it/s, train_loss=0.00285, val_loss=0.00338]Epoch 26:  62%|██████▏   | 18/29 [00:00<00:00, 197.73it/s, train_loss=0.00285, val_loss=0.00338]Epoch 26:  62%|██████▏   | 18/29 [00:00<00:00, 193.41it/s, train_loss=0.00334, val_loss=0.00338]Epoch 26:  66%|██████▌   | 19/29 [00:00<00:00, 197.47it/s, train_loss=0.00334, val_loss=0.00338]Epoch 26:  66%|██████▌   | 19/29 [00:00<00:00, 196.28it/s, train_loss=0.00294, val_loss=0.00338]Epoch 26:  69%|██████▉   | 20/29 [00:00<00:00, 200.08it/s, train_loss=0.00294, val_loss=0.00338]Epoch 26:  69%|██████▉   | 20/29 [00:00<00:00, 198.92it/s, train_loss=0.00205, val_loss=0.00338]Epoch 26:  72%|███████▏  | 21/29 [00:00<00:00, 202.53it/s, train_loss=0.00205, val_loss=0.00338]Epoch 26:  72%|███████▏  | 21/29 [00:00<00:00, 198.45it/s, train_loss=0.00267, val_loss=0.00338]Epoch 26:  76%|███████▌  | 22/29 [00:00<00:00, 201.85it/s, train_loss=0.00267, val_loss=0.00338]Epoch 26:  76%|███████▌  | 22/29 [00:00<00:00, 200.71it/s, train_loss=0.00225, val_loss=0.00338]Epoch 26:  79%|███████▉  | 23/29 [00:00<00:00, 203.80it/s, train_loss=0.00225, val_loss=0.00338]Epoch 26:  79%|███████▉  | 23/29 [00:00<00:00, 199.93it/s, train_loss=0.00374, val_loss=0.00338]Epoch 26:  83%|████████▎ | 24/29 [00:00<00:00, 202.16it/s, train_loss=0.00374, val_loss=0.00338]Epoch 26:  83%|████████▎ | 24/29 [00:00<00:00, 199.44it/s, train_loss=0.00285, val_loss=0.00338]Epoch 26:  86%|████████▌ | 25/29 [00:00<00:00, 201.73it/s, train_loss=0.00285, val_loss=0.00338]Epoch 26:  86%|████████▌ | 25/29 [00:00<00:00, 198.14it/s, train_loss=0.002, val_loss=0.00338]  Epoch 26:  90%|████████▉ | 26/29 [00:00<00:00, 200.73it/s, train_loss=0.002, val_loss=0.00338]Epoch 26:  90%|████████▉ | 26/29 [00:00<00:00, 199.52it/s, train_loss=0.00193, val_loss=0.00338]Epoch 26:  93%|█████████▎| 27/29 [00:00<00:00, 201.85it/s, train_loss=0.00193, val_loss=0.00338]Epoch 26:  93%|█████████▎| 27/29 [00:00<00:00, 199.32it/s, train_loss=0.00295, val_loss=0.00338]Epoch 26:  97%|█████████▋| 28/29 [00:00<00:00, 201.52it/s, train_loss=0.00295, val_loss=0.00338]Epoch 26:  97%|█████████▋| 28/29 [00:00<00:00, 198.26it/s, train_loss=0.0036, val_loss=0.00338] Epoch 26: 100%|██████████| 29/29 [00:00<00:00, 200.43it/s, train_loss=0.0036, val_loss=0.00338]Epoch 26: 100%|██████████| 29/29 [00:00<00:00, 197.30it/s, train_loss=0.00298, val_loss=0.00338]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 180.33it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 222.25it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 238.16it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 246.64it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 252.23it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 256.47it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 259.97it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 262.23it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 263.36it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 264.90it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 264.74it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 265.77it/s][A
                                                                         [AEpoch 26: 100%|██████████| 29/29 [00:00<00:00, 143.19it/s, train_loss=0.00298, val_loss=0.00339]Epoch 26: 100%|██████████| 29/29 [00:00<00:00, 142.41it/s, train_loss=0.00298, val_loss=0.00339]Epoch 26:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00339]          Epoch 27:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00339]Epoch 27:   3%|▎         | 1/29 [00:00<00:00, 230.95it/s, train_loss=0.00298, val_loss=0.00339]Epoch 27:   3%|▎         | 1/29 [00:00<00:00, 179.16it/s, train_loss=0.00328, val_loss=0.00339]Epoch 27:   7%|▋         | 2/29 [00:00<00:00, 220.31it/s, train_loss=0.00328, val_loss=0.00339]Epoch 27:   7%|▋         | 2/29 [00:00<00:00, 208.60it/s, train_loss=0.00414, val_loss=0.00339]Epoch 27:  10%|█         | 3/29 [00:00<00:00, 232.75it/s, train_loss=0.00414, val_loss=0.00339]Epoch 27:  10%|█         | 3/29 [00:00<00:00, 200.47it/s, train_loss=0.00326, val_loss=0.00339]Epoch 27:  14%|█▍        | 4/29 [00:00<00:00, 219.50it/s, train_loss=0.00326, val_loss=0.00339]Epoch 27:  14%|█▍        | 4/29 [00:00<00:00, 211.88it/s, train_loss=0.00311, val_loss=0.00339]Epoch 27:  17%|█▋        | 5/29 [00:00<00:00, 224.67it/s, train_loss=0.00311, val_loss=0.00339]Epoch 27:  17%|█▋        | 5/29 [00:00<00:00, 205.01it/s, train_loss=0.00254, val_loss=0.00339]Epoch 27:  21%|██        | 6/29 [00:00<00:00, 216.34it/s, train_loss=0.00254, val_loss=0.00339]Epoch 27:  21%|██        | 6/29 [00:00<00:00, 210.40it/s, train_loss=0.00176, val_loss=0.00339]Epoch 27:  24%|██▍       | 7/29 [00:00<00:00, 219.62it/s, train_loss=0.00176, val_loss=0.00339]Epoch 27:  24%|██▍       | 7/29 [00:00<00:00, 207.74it/s, train_loss=0.00366, val_loss=0.00339]Epoch 27:  28%|██▊       | 8/29 [00:00<00:00, 216.24it/s, train_loss=0.00366, val_loss=0.00339]Epoch 27:  28%|██▊       | 8/29 [00:00<00:00, 211.73it/s, train_loss=0.00342, val_loss=0.00339]Epoch 27:  31%|███       | 9/29 [00:00<00:00, 217.64it/s, train_loss=0.00342, val_loss=0.00339]Epoch 27:  31%|███       | 9/29 [00:00<00:00, 209.87it/s, train_loss=0.00299, val_loss=0.00339]Epoch 27:  34%|███▍      | 10/29 [00:00<00:00, 214.42it/s, train_loss=0.00299, val_loss=0.00339]Epoch 27:  34%|███▍      | 10/29 [00:00<00:00, 205.26it/s, train_loss=0.00191, val_loss=0.00339]Epoch 27:  38%|███▊      | 11/29 [00:00<00:00, 211.04it/s, train_loss=0.00191, val_loss=0.00339]Epoch 27:  38%|███▊      | 11/29 [00:00<00:00, 202.09it/s, train_loss=0.00262, val_loss=0.00339]Epoch 27:  41%|████▏     | 12/29 [00:00<00:00, 207.26it/s, train_loss=0.00262, val_loss=0.00339]Epoch 27:  41%|████▏     | 12/29 [00:00<00:00, 199.20it/s, train_loss=0.00217, val_loss=0.00339]Epoch 27:  45%|████▍     | 13/29 [00:00<00:00, 204.07it/s, train_loss=0.00217, val_loss=0.00339]Epoch 27:  45%|████▍     | 13/29 [00:00<00:00, 196.93it/s, train_loss=0.00241, val_loss=0.00339]Epoch 27:  48%|████▊     | 14/29 [00:00<00:00, 201.24it/s, train_loss=0.00241, val_loss=0.00339]Epoch 27:  48%|████▊     | 14/29 [00:00<00:00, 195.08it/s, train_loss=0.00228, val_loss=0.00339]Epoch 27:  52%|█████▏    | 15/29 [00:00<00:00, 198.42it/s, train_loss=0.00228, val_loss=0.00339]Epoch 27:  52%|█████▏    | 15/29 [00:00<00:00, 194.34it/s, train_loss=0.00242, val_loss=0.00339]Epoch 27:  55%|█████▌    | 16/29 [00:00<00:00, 197.69it/s, train_loss=0.00242, val_loss=0.00339]Epoch 27:  55%|█████▌    | 16/29 [00:00<00:00, 192.76it/s, train_loss=0.00233, val_loss=0.00339]Epoch 27:  59%|█████▊    | 17/29 [00:00<00:00, 196.31it/s, train_loss=0.00233, val_loss=0.00339]Epoch 27:  59%|█████▊    | 17/29 [00:00<00:00, 191.47it/s, train_loss=0.00437, val_loss=0.00339]Epoch 27:  62%|██████▏   | 18/29 [00:00<00:00, 194.85it/s, train_loss=0.00437, val_loss=0.00339]Epoch 27:  62%|██████▏   | 18/29 [00:00<00:00, 190.30it/s, train_loss=0.0027, val_loss=0.00339] Epoch 27:  66%|██████▌   | 19/29 [00:00<00:00, 193.48it/s, train_loss=0.0027, val_loss=0.00339]Epoch 27:  66%|██████▌   | 19/29 [00:00<00:00, 189.31it/s, train_loss=0.00315, val_loss=0.00339]Epoch 27:  69%|██████▉   | 20/29 [00:00<00:00, 193.22it/s, train_loss=0.00315, val_loss=0.00339]Epoch 27:  69%|██████▉   | 20/29 [00:00<00:00, 192.13it/s, train_loss=0.00184, val_loss=0.00339]Epoch 27:  72%|███████▏  | 21/29 [00:00<00:00, 195.79it/s, train_loss=0.00184, val_loss=0.00339]Epoch 27:  72%|███████▏  | 21/29 [00:00<00:00, 194.05it/s, train_loss=0.0022, val_loss=0.00339] Epoch 27:  76%|███████▌  | 22/29 [00:00<00:00, 197.12it/s, train_loss=0.0022, val_loss=0.00339]Epoch 27:  76%|███████▌  | 22/29 [00:00<00:00, 195.97it/s, train_loss=0.00263, val_loss=0.00339]Epoch 27:  79%|███████▉  | 23/29 [00:00<00:00, 199.01it/s, train_loss=0.00263, val_loss=0.00339]Epoch 27:  79%|███████▉  | 23/29 [00:00<00:00, 198.07it/s, train_loss=0.00293, val_loss=0.00339]Epoch 27:  83%|████████▎ | 24/29 [00:00<00:00, 201.01it/s, train_loss=0.00293, val_loss=0.00339]Epoch 27:  83%|████████▎ | 24/29 [00:00<00:00, 197.36it/s, train_loss=0.0029, val_loss=0.00339] Epoch 27:  86%|████████▌ | 25/29 [00:00<00:00, 200.04it/s, train_loss=0.0029, val_loss=0.00339]Epoch 27:  86%|████████▌ | 25/29 [00:00<00:00, 198.84it/s, train_loss=0.00255, val_loss=0.00339]Epoch 27:  90%|████████▉ | 26/29 [00:00<00:00, 201.35it/s, train_loss=0.00255, val_loss=0.00339]Epoch 27:  90%|████████▉ | 26/29 [00:00<00:00, 198.56it/s, train_loss=0.00217, val_loss=0.00339]Epoch 27:  93%|█████████▎| 27/29 [00:00<00:00, 201.04it/s, train_loss=0.00217, val_loss=0.00339]Epoch 27:  93%|█████████▎| 27/29 [00:00<00:00, 199.92it/s, train_loss=0.00381, val_loss=0.00339]Epoch 27:  97%|█████████▋| 28/29 [00:00<00:00, 202.29it/s, train_loss=0.00381, val_loss=0.00339]Epoch 27:  97%|█████████▋| 28/29 [00:00<00:00, 199.74it/s, train_loss=0.00286, val_loss=0.00339]Epoch 27: 100%|██████████| 29/29 [00:00<00:00, 202.08it/s, train_loss=0.00286, val_loss=0.00339]Epoch 27: 100%|██████████| 29/29 [00:00<00:00, 200.90it/s, train_loss=0.00219, val_loss=0.00339]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 187.10it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 221.83it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 237.14it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 246.93it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 252.59it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 256.56it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 260.08it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 263.69it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 266.18it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 268.20it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 268.61it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 267.93it/s][A
                                                                         [AEpoch 27: 100%|██████████| 29/29 [00:00<00:00, 145.64it/s, train_loss=0.00219, val_loss=0.0033] Epoch 27: 100%|██████████| 29/29 [00:00<00:00, 144.87it/s, train_loss=0.00219, val_loss=0.0033]Epoch 27:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00219, val_loss=0.0033]          Epoch 28:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00219, val_loss=0.0033]Epoch 28:   3%|▎         | 1/29 [00:00<00:00, 226.63it/s, train_loss=0.00219, val_loss=0.0033]Epoch 28:   3%|▎         | 1/29 [00:00<00:00, 203.48it/s, train_loss=0.00247, val_loss=0.0033]Epoch 28:   7%|▋         | 2/29 [00:00<00:00, 240.69it/s, train_loss=0.00247, val_loss=0.0033]Epoch 28:   7%|▋         | 2/29 [00:00<00:00, 191.01it/s, train_loss=0.00278, val_loss=0.0033]Epoch 28:  10%|█         | 3/29 [00:00<00:00, 219.69it/s, train_loss=0.00278, val_loss=0.0033]Epoch 28:  10%|█         | 3/29 [00:00<00:00, 210.98it/s, train_loss=0.00261, val_loss=0.0033]Epoch 28:  14%|█▍        | 4/29 [00:00<00:00, 229.35it/s, train_loss=0.00261, val_loss=0.0033]Epoch 28:  14%|█▍        | 4/29 [00:00<00:00, 202.33it/s, train_loss=0.00224, val_loss=0.0033]Epoch 28:  17%|█▋        | 5/29 [00:00<00:00, 216.91it/s, train_loss=0.00224, val_loss=0.0033]Epoch 28:  17%|█▋        | 5/29 [00:00<00:00, 210.46it/s, train_loss=0.00252, val_loss=0.0033]Epoch 28:  21%|██        | 6/29 [00:00<00:00, 221.98it/s, train_loss=0.00252, val_loss=0.0033]Epoch 28:  21%|██        | 6/29 [00:00<00:00, 206.23it/s, train_loss=0.00405, val_loss=0.0033]Epoch 28:  24%|██▍       | 7/29 [00:00<00:00, 215.62it/s, train_loss=0.00405, val_loss=0.0033]Epoch 28:  24%|██▍       | 7/29 [00:00<00:00, 210.99it/s, train_loss=0.00201, val_loss=0.0033]Epoch 28:  28%|██▊       | 8/29 [00:00<00:00, 218.16it/s, train_loss=0.00201, val_loss=0.0033]Epoch 28:  28%|██▊       | 8/29 [00:00<00:00, 214.38it/s, train_loss=0.0023, val_loss=0.0033] Epoch 28:  31%|███       | 9/29 [00:00<00:00, 220.25it/s, train_loss=0.0023, val_loss=0.0033]Epoch 28:  31%|███       | 9/29 [00:00<00:00, 216.77it/s, train_loss=0.00343, val_loss=0.0033]Epoch 28:  34%|███▍      | 10/29 [00:00<00:00, 222.14it/s, train_loss=0.00343, val_loss=0.0033]Epoch 28:  34%|███▍      | 10/29 [00:00<00:00, 213.54it/s, train_loss=0.00168, val_loss=0.0033]Epoch 28:  38%|███▊      | 11/29 [00:00<00:00, 218.89it/s, train_loss=0.00168, val_loss=0.0033]Epoch 28:  38%|███▊      | 11/29 [00:00<00:00, 209.32it/s, train_loss=0.00316, val_loss=0.0033]Epoch 28:  41%|████▏     | 12/29 [00:00<00:00, 213.92it/s, train_loss=0.00316, val_loss=0.0033]Epoch 28:  41%|████▏     | 12/29 [00:00<00:00, 205.64it/s, train_loss=0.00308, val_loss=0.0033]Epoch 28:  45%|████▍     | 13/29 [00:00<00:00, 210.29it/s, train_loss=0.00308, val_loss=0.0033]Epoch 28:  45%|████▍     | 13/29 [00:00<00:00, 202.78it/s, train_loss=0.00315, val_loss=0.0033]Epoch 28:  48%|████▊     | 14/29 [00:00<00:00, 207.02it/s, train_loss=0.00315, val_loss=0.0033]Epoch 28:  48%|████▊     | 14/29 [00:00<00:00, 200.39it/s, train_loss=0.00307, val_loss=0.0033]Epoch 28:  52%|█████▏    | 15/29 [00:00<00:00, 203.55it/s, train_loss=0.00307, val_loss=0.0033]Epoch 28:  52%|█████▏    | 15/29 [00:00<00:00, 199.58it/s, train_loss=0.00232, val_loss=0.0033]Epoch 28:  55%|█████▌    | 16/29 [00:00<00:00, 202.79it/s, train_loss=0.00232, val_loss=0.0033]Epoch 28:  55%|█████▌    | 16/29 [00:00<00:00, 197.57it/s, train_loss=0.00358, val_loss=0.0033]Epoch 28:  59%|█████▊    | 17/29 [00:00<00:00, 200.87it/s, train_loss=0.00358, val_loss=0.0033]Epoch 28:  59%|█████▊    | 17/29 [00:00<00:00, 195.97it/s, train_loss=0.00281, val_loss=0.0033]Epoch 28:  62%|██████▏   | 18/29 [00:00<00:00, 199.19it/s, train_loss=0.00281, val_loss=0.0033]Epoch 28:  62%|██████▏   | 18/29 [00:00<00:00, 194.39it/s, train_loss=0.00308, val_loss=0.0033]Epoch 28:  66%|██████▌   | 19/29 [00:00<00:00, 197.45it/s, train_loss=0.00308, val_loss=0.0033]Epoch 28:  66%|██████▌   | 19/29 [00:00<00:00, 193.11it/s, train_loss=0.00281, val_loss=0.0033]Epoch 28:  69%|██████▉   | 20/29 [00:00<00:00, 196.15it/s, train_loss=0.00281, val_loss=0.0033]Epoch 28:  69%|██████▉   | 20/29 [00:00<00:00, 192.07it/s, train_loss=0.00223, val_loss=0.0033]Epoch 28:  72%|███████▏  | 21/29 [00:00<00:00, 195.09it/s, train_loss=0.00223, val_loss=0.0033]Epoch 28:  72%|███████▏  | 21/29 [00:00<00:00, 192.22it/s, train_loss=0.00341, val_loss=0.0033]Epoch 28:  76%|███████▌  | 22/29 [00:00<00:00, 195.39it/s, train_loss=0.00341, val_loss=0.0033]Epoch 28:  76%|███████▌  | 22/29 [00:00<00:00, 194.52it/s, train_loss=0.00278, val_loss=0.0033]Epoch 28:  79%|███████▉  | 23/29 [00:00<00:00, 197.69it/s, train_loss=0.00278, val_loss=0.0033]Epoch 28:  79%|███████▉  | 23/29 [00:00<00:00, 193.93it/s, train_loss=0.0018, val_loss=0.0033] Epoch 28:  83%|████████▎ | 24/29 [00:00<00:00, 196.93it/s, train_loss=0.0018, val_loss=0.0033]Epoch 28:  83%|████████▎ | 24/29 [00:00<00:00, 195.91it/s, train_loss=0.00382, val_loss=0.0033]Epoch 28:  86%|████████▌ | 25/29 [00:00<00:00, 198.71it/s, train_loss=0.00382, val_loss=0.0033]Epoch 28:  86%|████████▌ | 25/29 [00:00<00:00, 195.36it/s, train_loss=0.00237, val_loss=0.0033]Epoch 28:  90%|████████▉ | 26/29 [00:00<00:00, 197.90it/s, train_loss=0.00237, val_loss=0.0033]Epoch 28:  90%|████████▉ | 26/29 [00:00<00:00, 196.82it/s, train_loss=0.00236, val_loss=0.0033]Epoch 28:  93%|█████████▎| 27/29 [00:00<00:00, 199.28it/s, train_loss=0.00236, val_loss=0.0033]Epoch 28:  93%|█████████▎| 27/29 [00:00<00:00, 196.77it/s, train_loss=0.00208, val_loss=0.0033]Epoch 28:  97%|█████████▋| 28/29 [00:00<00:00, 199.07it/s, train_loss=0.00208, val_loss=0.0033]Epoch 28:  97%|█████████▋| 28/29 [00:00<00:00, 198.06it/s, train_loss=0.00276, val_loss=0.0033]Epoch 28: 100%|██████████| 29/29 [00:00<00:00, 200.18it/s, train_loss=0.00276, val_loss=0.0033]Epoch 28: 100%|██████████| 29/29 [00:00<00:00, 199.19it/s, train_loss=0.00372, val_loss=0.0033]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 193.13it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 231.86it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 247.97it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 252.32it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 260.07it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 265.02it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 269.57it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 272.61it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 273.64it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 274.32it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 274.63it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 274.64it/s][A
                                                                         [AEpoch 28: 100%|██████████| 29/29 [00:00<00:00, 146.19it/s, train_loss=0.00372, val_loss=0.00326]Epoch 28: 100%|██████████| 29/29 [00:00<00:00, 145.48it/s, train_loss=0.00372, val_loss=0.00326]Epoch 28:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00372, val_loss=0.00326]          Epoch 29:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00372, val_loss=0.00326]Epoch 29:   3%|▎         | 1/29 [00:00<00:00, 191.37it/s, train_loss=0.00372, val_loss=0.00326]Epoch 29:   3%|▎         | 1/29 [00:00<00:00, 159.67it/s, train_loss=0.00179, val_loss=0.00326]Epoch 29:   7%|▋         | 2/29 [00:00<00:00, 209.47it/s, train_loss=0.00179, val_loss=0.00326]Epoch 29:   7%|▋         | 2/29 [00:00<00:00, 172.87it/s, train_loss=0.00271, val_loss=0.00326]Epoch 29:  10%|█         | 3/29 [00:00<00:00, 199.96it/s, train_loss=0.00271, val_loss=0.00326]Epoch 29:  10%|█         | 3/29 [00:00<00:00, 192.27it/s, train_loss=0.00269, val_loss=0.00326]Epoch 29:  14%|█▍        | 4/29 [00:00<00:00, 210.79it/s, train_loss=0.00269, val_loss=0.00326]Epoch 29:  14%|█▍        | 4/29 [00:00<00:00, 191.55it/s, train_loss=0.00322, val_loss=0.00326]Epoch 29:  17%|█▋        | 5/29 [00:00<00:00, 202.81it/s, train_loss=0.00322, val_loss=0.00326]Epoch 29:  17%|█▋        | 5/29 [00:00<00:00, 189.04it/s, train_loss=0.00294, val_loss=0.00326]Epoch 29:  21%|██        | 6/29 [00:00<00:00, 199.93it/s, train_loss=0.00294, val_loss=0.00326]Epoch 29:  21%|██        | 6/29 [00:00<00:00, 185.80it/s, train_loss=0.00269, val_loss=0.00326]Epoch 29:  24%|██▍       | 7/29 [00:00<00:00, 195.67it/s, train_loss=0.00269, val_loss=0.00326]Epoch 29:  24%|██▍       | 7/29 [00:00<00:00, 183.84it/s, train_loss=0.00193, val_loss=0.00326]Epoch 29:  28%|██▊       | 8/29 [00:00<00:00, 192.27it/s, train_loss=0.00193, val_loss=0.00326]Epoch 29:  28%|██▊       | 8/29 [00:00<00:00, 182.38it/s, train_loss=0.00283, val_loss=0.00326]Epoch 29:  31%|███       | 9/29 [00:00<00:00, 189.42it/s, train_loss=0.00283, val_loss=0.00326]Epoch 29:  31%|███       | 9/29 [00:00<00:00, 181.36it/s, train_loss=0.00267, val_loss=0.00326]Epoch 29:  34%|███▍      | 10/29 [00:00<00:00, 187.85it/s, train_loss=0.00267, val_loss=0.00326]Epoch 29:  34%|███▍      | 10/29 [00:00<00:00, 180.57it/s, train_loss=0.0027, val_loss=0.00326] Epoch 29:  38%|███▊      | 11/29 [00:00<00:00, 185.44it/s, train_loss=0.0027, val_loss=0.00326]Epoch 29:  38%|███▊      | 11/29 [00:00<00:00, 180.65it/s, train_loss=0.00282, val_loss=0.00326]Epoch 29:  41%|████▏     | 12/29 [00:00<00:00, 186.11it/s, train_loss=0.00282, val_loss=0.00326]Epoch 29:  41%|████▏     | 12/29 [00:00<00:00, 179.81it/s, train_loss=0.00285, val_loss=0.00326]Epoch 29:  45%|████▍     | 13/29 [00:00<00:00, 161.77it/s, train_loss=0.00285, val_loss=0.00326]Epoch 29:  45%|████▍     | 13/29 [00:00<00:00, 160.19it/s, train_loss=0.00249, val_loss=0.00326]Epoch 29:  48%|████▊     | 14/29 [00:00<00:00, 165.46it/s, train_loss=0.00249, val_loss=0.00326]Epoch 29:  48%|████▊     | 14/29 [00:00<00:00, 161.95it/s, train_loss=0.00243, val_loss=0.00326]Epoch 29:  52%|█████▏    | 15/29 [00:00<00:00, 166.16it/s, train_loss=0.00243, val_loss=0.00326]Epoch 29:  52%|█████▏    | 15/29 [00:00<00:00, 163.48it/s, train_loss=0.00272, val_loss=0.00326]Epoch 29:  55%|█████▌    | 16/29 [00:00<00:00, 167.78it/s, train_loss=0.00272, val_loss=0.00326]Epoch 29:  55%|█████▌    | 16/29 [00:00<00:00, 164.00it/s, train_loss=0.00259, val_loss=0.00326]Epoch 29:  59%|█████▊    | 17/29 [00:00<00:00, 168.26it/s, train_loss=0.00259, val_loss=0.00326]Epoch 29:  59%|█████▊    | 17/29 [00:00<00:00, 164.57it/s, train_loss=0.00378, val_loss=0.00326]Epoch 29:  62%|██████▏   | 18/29 [00:00<00:00, 168.48it/s, train_loss=0.00378, val_loss=0.00326]Epoch 29:  62%|██████▏   | 18/29 [00:00<00:00, 164.98it/s, train_loss=0.00233, val_loss=0.00326]Epoch 29:  66%|██████▌   | 19/29 [00:00<00:00, 168.74it/s, train_loss=0.00233, val_loss=0.00326]Epoch 29:  66%|██████▌   | 19/29 [00:00<00:00, 165.42it/s, train_loss=0.0032, val_loss=0.00326] Epoch 29:  69%|██████▉   | 20/29 [00:00<00:00, 168.88it/s, train_loss=0.0032, val_loss=0.00326]Epoch 29:  69%|██████▉   | 20/29 [00:00<00:00, 165.81it/s, train_loss=0.00266, val_loss=0.00326]Epoch 29:  72%|███████▏  | 21/29 [00:00<00:00, 168.63it/s, train_loss=0.00266, val_loss=0.00326]Epoch 29:  72%|███████▏  | 21/29 [00:00<00:00, 166.72it/s, train_loss=0.00297, val_loss=0.00326]Epoch 29:  76%|███████▌  | 22/29 [00:00<00:00, 170.14it/s, train_loss=0.00297, val_loss=0.00326]Epoch 29:  76%|███████▌  | 22/29 [00:00<00:00, 169.56it/s, train_loss=0.00279, val_loss=0.00326]Epoch 29:  79%|███████▉  | 23/29 [00:00<00:00, 172.91it/s, train_loss=0.00279, val_loss=0.00326]Epoch 29:  79%|███████▉  | 23/29 [00:00<00:00, 170.05it/s, train_loss=0.00208, val_loss=0.00326]Epoch 29:  83%|████████▎ | 24/29 [00:00<00:00, 173.26it/s, train_loss=0.00208, val_loss=0.00326]Epoch 29:  83%|████████▎ | 24/29 [00:00<00:00, 172.48it/s, train_loss=0.00279, val_loss=0.00326]Epoch 29:  86%|████████▌ | 25/29 [00:00<00:00, 175.63it/s, train_loss=0.00279, val_loss=0.00326]Epoch 29:  86%|████████▌ | 25/29 [00:00<00:00, 172.93it/s, train_loss=0.0028, val_loss=0.00326] Epoch 29:  90%|████████▉ | 26/29 [00:00<00:00, 175.82it/s, train_loss=0.0028, val_loss=0.00326]Epoch 29:  90%|████████▉ | 26/29 [00:00<00:00, 175.06it/s, train_loss=0.00363, val_loss=0.00326]Epoch 29:  93%|█████████▎| 27/29 [00:00<00:00, 177.76it/s, train_loss=0.00363, val_loss=0.00326]Epoch 29:  93%|█████████▎| 27/29 [00:00<00:00, 175.54it/s, train_loss=0.0028, val_loss=0.00326] Epoch 29:  97%|█████████▋| 28/29 [00:00<00:00, 178.17it/s, train_loss=0.0028, val_loss=0.00326]Epoch 29:  97%|█████████▋| 28/29 [00:00<00:00, 177.27it/s, train_loss=0.0027, val_loss=0.00326]Epoch 29: 100%|██████████| 29/29 [00:00<00:00, 179.52it/s, train_loss=0.0027, val_loss=0.00326]Epoch 29: 100%|██████████| 29/29 [00:00<00:00, 178.04it/s, train_loss=0.00171, val_loss=0.00326]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 163.87it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 206.99it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 226.32it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 237.28it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 245.18it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 253.01it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 258.86it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 263.64it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 266.44it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 266.10it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 265.86it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 266.39it/s][A
                                                                         [AEpoch 29: 100%|██████████| 29/29 [00:00<00:00, 133.92it/s, train_loss=0.00171, val_loss=0.00324]Epoch 29: 100%|██████████| 29/29 [00:00<00:00, 133.35it/s, train_loss=0.00171, val_loss=0.00324]Epoch 29:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00171, val_loss=0.00324]          Epoch 30:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00171, val_loss=0.00324]Epoch 30:   3%|▎         | 1/29 [00:00<00:00, 198.53it/s, train_loss=0.00171, val_loss=0.00324]Epoch 30:   3%|▎         | 1/29 [00:00<00:00, 166.09it/s, train_loss=0.00353, val_loss=0.00324]Epoch 30:   7%|▋         | 2/29 [00:00<00:00, 203.96it/s, train_loss=0.00353, val_loss=0.00324]Epoch 30:   7%|▋         | 2/29 [00:00<00:00, 171.36it/s, train_loss=0.00273, val_loss=0.00324]Epoch 30:  10%|█         | 3/29 [00:00<00:00, 184.91it/s, train_loss=0.00273, val_loss=0.00324]Epoch 30:  10%|█         | 3/29 [00:00<00:00, 171.60it/s, train_loss=0.00268, val_loss=0.00324]Epoch 30:  14%|█▍        | 4/29 [00:00<00:00, 182.26it/s, train_loss=0.00268, val_loss=0.00324]Epoch 30:  14%|█▍        | 4/29 [00:00<00:00, 176.75it/s, train_loss=0.00223, val_loss=0.00324]Epoch 30:  17%|█▋        | 5/29 [00:00<00:00, 183.70it/s, train_loss=0.00223, val_loss=0.00324]Epoch 30:  17%|█▋        | 5/29 [00:00<00:00, 176.25it/s, train_loss=0.0027, val_loss=0.00324] Epoch 30:  21%|██        | 6/29 [00:00<00:00, 183.05it/s, train_loss=0.0027, val_loss=0.00324]Epoch 30:  21%|██        | 6/29 [00:00<00:00, 175.20it/s, train_loss=0.00258, val_loss=0.00324]Epoch 30:  24%|██▍       | 7/29 [00:00<00:00, 178.34it/s, train_loss=0.00258, val_loss=0.00324]Epoch 30:  24%|██▍       | 7/29 [00:00<00:00, 174.68it/s, train_loss=0.00203, val_loss=0.00324]Epoch 30:  28%|██▊       | 8/29 [00:00<00:00, 179.37it/s, train_loss=0.00203, val_loss=0.00324]Epoch 30:  28%|██▊       | 8/29 [00:00<00:00, 174.34it/s, train_loss=0.00255, val_loss=0.00324]Epoch 30:  31%|███       | 9/29 [00:00<00:00, 178.61it/s, train_loss=0.00255, val_loss=0.00324]Epoch 30:  31%|███       | 9/29 [00:00<00:00, 174.17it/s, train_loss=0.00365, val_loss=0.00324]Epoch 30:  34%|███▍      | 10/29 [00:00<00:00, 177.98it/s, train_loss=0.00365, val_loss=0.00324]Epoch 30:  34%|███▍      | 10/29 [00:00<00:00, 175.43it/s, train_loss=0.00348, val_loss=0.00324]Epoch 30:  38%|███▊      | 11/29 [00:00<00:00, 178.96it/s, train_loss=0.00348, val_loss=0.00324]Epoch 30:  38%|███▊      | 11/29 [00:00<00:00, 175.74it/s, train_loss=0.00227, val_loss=0.00324]Epoch 30:  41%|████▏     | 12/29 [00:00<00:00, 179.19it/s, train_loss=0.00227, val_loss=0.00324]Epoch 30:  41%|████▏     | 12/29 [00:00<00:00, 175.48it/s, train_loss=0.00204, val_loss=0.00324]Epoch 30:  45%|████▍     | 13/29 [00:00<00:00, 178.32it/s, train_loss=0.00204, val_loss=0.00324]Epoch 30:  45%|████▍     | 13/29 [00:00<00:00, 175.15it/s, train_loss=0.00235, val_loss=0.00324]Epoch 30:  48%|████▊     | 14/29 [00:00<00:00, 177.81it/s, train_loss=0.00235, val_loss=0.00324]Epoch 30:  48%|████▊     | 14/29 [00:00<00:00, 174.85it/s, train_loss=0.0026, val_loss=0.00324] Epoch 30:  52%|█████▏    | 15/29 [00:00<00:00, 177.39it/s, train_loss=0.0026, val_loss=0.00324]Epoch 30:  52%|█████▏    | 15/29 [00:00<00:00, 174.79it/s, train_loss=0.00322, val_loss=0.00324]Epoch 30:  55%|█████▌    | 16/29 [00:00<00:00, 176.52it/s, train_loss=0.00322, val_loss=0.00324]Epoch 30:  55%|█████▌    | 16/29 [00:00<00:00, 172.46it/s, train_loss=0.00191, val_loss=0.00324]Epoch 30:  59%|█████▊    | 17/29 [00:00<00:00, 174.18it/s, train_loss=0.00191, val_loss=0.00324]Epoch 30:  59%|█████▊    | 17/29 [00:00<00:00, 172.31it/s, train_loss=0.00306, val_loss=0.00324]Epoch 30:  62%|██████▏   | 18/29 [00:00<00:00, 175.43it/s, train_loss=0.00306, val_loss=0.00324]Epoch 30:  62%|██████▏   | 18/29 [00:00<00:00, 172.28it/s, train_loss=0.00286, val_loss=0.00324]Epoch 30:  66%|██████▌   | 19/29 [00:00<00:00, 173.10it/s, train_loss=0.00286, val_loss=0.00324]Epoch 30:  66%|██████▌   | 19/29 [00:00<00:00, 171.61it/s, train_loss=0.00251, val_loss=0.00324]Epoch 30:  69%|██████▉   | 20/29 [00:00<00:00, 173.06it/s, train_loss=0.00251, val_loss=0.00324]Epoch 30:  69%|██████▉   | 20/29 [00:00<00:00, 171.59it/s, train_loss=0.00348, val_loss=0.00324]Epoch 30:  72%|███████▏  | 21/29 [00:00<00:00, 173.17it/s, train_loss=0.00348, val_loss=0.00324]Epoch 30:  72%|███████▏  | 21/29 [00:00<00:00, 171.83it/s, train_loss=0.00264, val_loss=0.00324]Epoch 30:  76%|███████▌  | 22/29 [00:00<00:00, 173.43it/s, train_loss=0.00264, val_loss=0.00324]Epoch 30:  76%|███████▌  | 22/29 [00:00<00:00, 172.60it/s, train_loss=0.00287, val_loss=0.00324]Epoch 30:  79%|███████▉  | 23/29 [00:00<00:00, 175.59it/s, train_loss=0.00287, val_loss=0.00324]Epoch 30:  79%|███████▉  | 23/29 [00:00<00:00, 172.74it/s, train_loss=0.00294, val_loss=0.00324]Epoch 30:  83%|████████▎ | 24/29 [00:00<00:00, 175.52it/s, train_loss=0.00294, val_loss=0.00324]Epoch 30:  83%|████████▎ | 24/29 [00:00<00:00, 172.79it/s, train_loss=0.00188, val_loss=0.00324]Epoch 30:  86%|████████▌ | 25/29 [00:00<00:00, 174.99it/s, train_loss=0.00188, val_loss=0.00324]Epoch 30:  86%|████████▌ | 25/29 [00:00<00:00, 172.81it/s, train_loss=0.00306, val_loss=0.00324]Epoch 30:  90%|████████▉ | 26/29 [00:00<00:00, 175.20it/s, train_loss=0.00306, val_loss=0.00324]Epoch 30:  90%|████████▉ | 26/29 [00:00<00:00, 172.86it/s, train_loss=0.0023, val_loss=0.00324] Epoch 30:  93%|█████████▎| 27/29 [00:00<00:00, 175.13it/s, train_loss=0.0023, val_loss=0.00324]Epoch 30:  93%|█████████▎| 27/29 [00:00<00:00, 172.91it/s, train_loss=0.00313, val_loss=0.00324]Epoch 30:  97%|█████████▋| 28/29 [00:00<00:00, 174.47it/s, train_loss=0.00313, val_loss=0.00324]Epoch 30:  97%|█████████▋| 28/29 [00:00<00:00, 173.22it/s, train_loss=0.00252, val_loss=0.00324]Epoch 30: 100%|██████████| 29/29 [00:00<00:00, 175.57it/s, train_loss=0.00252, val_loss=0.00324]Epoch 30: 100%|██████████| 29/29 [00:00<00:00, 173.16it/s, train_loss=0.00228, val_loss=0.00324]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 180.80it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 222.65it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 242.70it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 253.57it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 263.48it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 269.16it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 273.28it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 276.24it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 279.19it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 280.50it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 281.41it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 281.79it/s][A
                                                                         [AEpoch 30: 100%|██████████| 29/29 [00:00<00:00, 132.26it/s, train_loss=0.00228, val_loss=0.00322]Epoch 30: 100%|██████████| 29/29 [00:00<00:00, 131.63it/s, train_loss=0.00228, val_loss=0.00322]Epoch 30:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00228, val_loss=0.00322]          Epoch 31:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00228, val_loss=0.00322]Epoch 31:   3%|▎         | 1/29 [00:00<00:00, 193.77it/s, train_loss=0.00228, val_loss=0.00322]Epoch 31:   3%|▎         | 1/29 [00:00<00:00, 165.48it/s, train_loss=0.00362, val_loss=0.00322]Epoch 31:   7%|▋         | 2/29 [00:00<00:00, 205.85it/s, train_loss=0.00362, val_loss=0.00322]Epoch 31:   7%|▋         | 2/29 [00:00<00:00, 172.26it/s, train_loss=0.00259, val_loss=0.00322]Epoch 31:  10%|█         | 3/29 [00:00<00:00, 197.68it/s, train_loss=0.00259, val_loss=0.00322]Epoch 31:  10%|█         | 3/29 [00:00<00:00, 172.66it/s, train_loss=0.00352, val_loss=0.00322]Epoch 31:  14%|█▍        | 4/29 [00:00<00:00, 194.57it/s, train_loss=0.00352, val_loss=0.00322]Epoch 31:  14%|█▍        | 4/29 [00:00<00:00, 190.12it/s, train_loss=0.00323, val_loss=0.00322]Epoch 31:  17%|█▋        | 5/29 [00:00<00:00, 204.07it/s, train_loss=0.00323, val_loss=0.00322]Epoch 31:  17%|█▋        | 5/29 [00:00<00:00, 192.06it/s, train_loss=0.00147, val_loss=0.00322]Epoch 31:  21%|██        | 6/29 [00:00<00:00, 203.96it/s, train_loss=0.00147, val_loss=0.00322]Epoch 31:  21%|██        | 6/29 [00:00<00:00, 199.70it/s, train_loss=0.00291, val_loss=0.00322]Epoch 31:  24%|██▍       | 7/29 [00:00<00:00, 210.17it/s, train_loss=0.00291, val_loss=0.00322]Epoch 31:  24%|██▍       | 7/29 [00:00<00:00, 197.55it/s, train_loss=0.00298, val_loss=0.00322]Epoch 31:  28%|██▊       | 8/29 [00:00<00:00, 206.34it/s, train_loss=0.00298, val_loss=0.00322]Epoch 31:  28%|██▊       | 8/29 [00:00<00:00, 203.05it/s, train_loss=0.00251, val_loss=0.00322]Epoch 31:  31%|███       | 9/29 [00:00<00:00, 210.49it/s, train_loss=0.00251, val_loss=0.00322]Epoch 31:  31%|███       | 9/29 [00:00<00:00, 200.86it/s, train_loss=0.00251, val_loss=0.00322]Epoch 31:  34%|███▍      | 10/29 [00:00<00:00, 207.69it/s, train_loss=0.00251, val_loss=0.00322]Epoch 31:  34%|███▍      | 10/29 [00:00<00:00, 204.67it/s, train_loss=0.00323, val_loss=0.00322]Epoch 31:  38%|███▊      | 11/29 [00:00<00:00, 210.50it/s, train_loss=0.00323, val_loss=0.00322]Epoch 31:  38%|███▊      | 11/29 [00:00<00:00, 203.61it/s, train_loss=0.00215, val_loss=0.00322]Epoch 31:  41%|████▏     | 12/29 [00:00<00:00, 209.03it/s, train_loss=0.00215, val_loss=0.00322]Epoch 31:  41%|████▏     | 12/29 [00:00<00:00, 206.40it/s, train_loss=0.00228, val_loss=0.00322]Epoch 31:  45%|████▍     | 13/29 [00:00<00:00, 209.51it/s, train_loss=0.00228, val_loss=0.00322]Epoch 31:  45%|████▍     | 13/29 [00:00<00:00, 205.63it/s, train_loss=0.0025, val_loss=0.00322] Epoch 31:  48%|████▊     | 14/29 [00:00<00:00, 208.91it/s, train_loss=0.0025, val_loss=0.00322]Epoch 31:  48%|████▊     | 14/29 [00:00<00:00, 202.64it/s, train_loss=0.00264, val_loss=0.00322]Epoch 31:  52%|█████▏    | 15/29 [00:00<00:00, 206.49it/s, train_loss=0.00264, val_loss=0.00322]Epoch 31:  52%|█████▏    | 15/29 [00:00<00:00, 200.36it/s, train_loss=0.00368, val_loss=0.00322]Epoch 31:  55%|█████▌    | 16/29 [00:00<00:00, 204.02it/s, train_loss=0.00368, val_loss=0.00322]Epoch 31:  55%|█████▌    | 16/29 [00:00<00:00, 198.33it/s, train_loss=0.00252, val_loss=0.00322]Epoch 31:  59%|█████▊    | 17/29 [00:00<00:00, 202.12it/s, train_loss=0.00252, val_loss=0.00322]Epoch 31:  59%|█████▊    | 17/29 [00:00<00:00, 196.78it/s, train_loss=0.00276, val_loss=0.00322]Epoch 31:  62%|██████▏   | 18/29 [00:00<00:00, 200.19it/s, train_loss=0.00276, val_loss=0.00322]Epoch 31:  62%|██████▏   | 18/29 [00:00<00:00, 195.39it/s, train_loss=0.00251, val_loss=0.00322]Epoch 31:  66%|██████▌   | 19/29 [00:00<00:00, 197.15it/s, train_loss=0.00251, val_loss=0.00322]Epoch 31:  66%|██████▌   | 19/29 [00:00<00:00, 194.59it/s, train_loss=0.00224, val_loss=0.00322]Epoch 31:  69%|██████▉   | 20/29 [00:00<00:00, 197.13it/s, train_loss=0.00224, val_loss=0.00322]Epoch 31:  69%|██████▉   | 20/29 [00:00<00:00, 193.33it/s, train_loss=0.00209, val_loss=0.00322]Epoch 31:  72%|███████▏  | 21/29 [00:00<00:00, 195.96it/s, train_loss=0.00209, val_loss=0.00322]Epoch 31:  72%|███████▏  | 21/29 [00:00<00:00, 192.25it/s, train_loss=0.00304, val_loss=0.00322]Epoch 31:  76%|███████▌  | 22/29 [00:00<00:00, 194.76it/s, train_loss=0.00304, val_loss=0.00322]Epoch 31:  76%|███████▌  | 22/29 [00:00<00:00, 191.27it/s, train_loss=0.00182, val_loss=0.00322]Epoch 31:  79%|███████▉  | 23/29 [00:00<00:00, 193.72it/s, train_loss=0.00182, val_loss=0.00322]Epoch 31:  79%|███████▉  | 23/29 [00:00<00:00, 190.43it/s, train_loss=0.0017, val_loss=0.00322] Epoch 31:  83%|████████▎ | 24/29 [00:00<00:00, 193.60it/s, train_loss=0.0017, val_loss=0.00322]Epoch 31:  83%|████████▎ | 24/29 [00:00<00:00, 192.71it/s, train_loss=0.00318, val_loss=0.00322]Epoch 31:  86%|████████▌ | 25/29 [00:00<00:00, 195.72it/s, train_loss=0.00318, val_loss=0.00322]Epoch 31:  86%|████████▌ | 25/29 [00:00<00:00, 194.82it/s, train_loss=0.00239, val_loss=0.00322]Epoch 31:  90%|████████▉ | 26/29 [00:00<00:00, 196.99it/s, train_loss=0.00239, val_loss=0.00322]Epoch 31:  90%|████████▉ | 26/29 [00:00<00:00, 196.04it/s, train_loss=0.00262, val_loss=0.00322]Epoch 31:  93%|█████████▎| 27/29 [00:00<00:00, 198.63it/s, train_loss=0.00262, val_loss=0.00322]Epoch 31:  93%|█████████▎| 27/29 [00:00<00:00, 195.21it/s, train_loss=0.00328, val_loss=0.00322]Epoch 31:  97%|█████████▋| 28/29 [00:00<00:00, 197.69it/s, train_loss=0.00328, val_loss=0.00322]Epoch 31:  97%|█████████▋| 28/29 [00:00<00:00, 196.66it/s, train_loss=0.00288, val_loss=0.00322]Epoch 31: 100%|██████████| 29/29 [00:00<00:00, 198.97it/s, train_loss=0.00288, val_loss=0.00322]Epoch 31: 100%|██████████| 29/29 [00:00<00:00, 196.57it/s, train_loss=0.00335, val_loss=0.00322]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 195.49it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 239.44it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 259.67it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 270.91it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 275.30it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 279.57it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 280.39it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 281.22it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 282.30it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 283.34it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 284.26it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 283.94it/s][A
                                                                         [AEpoch 31: 100%|██████████| 29/29 [00:00<00:00, 145.53it/s, train_loss=0.00335, val_loss=0.00319]Epoch 31: 100%|██████████| 29/29 [00:00<00:00, 144.83it/s, train_loss=0.00335, val_loss=0.00319]Epoch 31:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00335, val_loss=0.00319]          Epoch 32:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00335, val_loss=0.00319]Epoch 32:   3%|▎         | 1/29 [00:00<00:00, 203.78it/s, train_loss=0.00335, val_loss=0.00319]Epoch 32:   3%|▎         | 1/29 [00:00<00:00, 172.69it/s, train_loss=0.00377, val_loss=0.00319]Epoch 32:   7%|▋         | 2/29 [00:00<00:00, 211.67it/s, train_loss=0.00377, val_loss=0.00319]Epoch 32:   7%|▋         | 2/29 [00:00<00:00, 173.25it/s, train_loss=0.00339, val_loss=0.00319]Epoch 32:  10%|█         | 3/29 [00:00<00:00, 193.42it/s, train_loss=0.00339, val_loss=0.00319]Epoch 32:  10%|█         | 3/29 [00:00<00:00, 175.75it/s, train_loss=0.00195, val_loss=0.00319]Epoch 32:  14%|█▍        | 4/29 [00:00<00:00, 192.87it/s, train_loss=0.00195, val_loss=0.00319]Epoch 32:  14%|█▍        | 4/29 [00:00<00:00, 174.31it/s, train_loss=0.00307, val_loss=0.00319]Epoch 32:  17%|█▋        | 5/29 [00:00<00:00, 191.63it/s, train_loss=0.00307, val_loss=0.00319]Epoch 32:  17%|█▋        | 5/29 [00:00<00:00, 188.20it/s, train_loss=0.00202, val_loss=0.00319]Epoch 32:  21%|██        | 6/29 [00:00<00:00, 201.60it/s, train_loss=0.00202, val_loss=0.00319]Epoch 32:  21%|██        | 6/29 [00:00<00:00, 197.94it/s, train_loss=0.00214, val_loss=0.00319]Epoch 32:  24%|██▍       | 7/29 [00:00<00:00, 208.60it/s, train_loss=0.00214, val_loss=0.00319]Epoch 32:  24%|██▍       | 7/29 [00:00<00:00, 195.02it/s, train_loss=0.00314, val_loss=0.00319]Epoch 32:  28%|██▊       | 8/29 [00:00<00:00, 204.52it/s, train_loss=0.00314, val_loss=0.00319]Epoch 32:  28%|██▊       | 8/29 [00:00<00:00, 201.41it/s, train_loss=0.00206, val_loss=0.00319]Epoch 32:  31%|███       | 9/29 [00:00<00:00, 209.37it/s, train_loss=0.00206, val_loss=0.00319]Epoch 32:  31%|███       | 9/29 [00:00<00:00, 199.25it/s, train_loss=0.00217, val_loss=0.00319]Epoch 32:  34%|███▍      | 10/29 [00:00<00:00, 206.27it/s, train_loss=0.00217, val_loss=0.00319]Epoch 32:  34%|███▍      | 10/29 [00:00<00:00, 203.47it/s, train_loss=0.00224, val_loss=0.00319]Epoch 32:  38%|███▊      | 11/29 [00:00<00:00, 207.80it/s, train_loss=0.00224, val_loss=0.00319]Epoch 32:  38%|███▊      | 11/29 [00:00<00:00, 202.68it/s, train_loss=0.00273, val_loss=0.00319]Epoch 32:  41%|████▏     | 12/29 [00:00<00:00, 207.29it/s, train_loss=0.00273, val_loss=0.00319]Epoch 32:  41%|████▏     | 12/29 [00:00<00:00, 199.58it/s, train_loss=0.00278, val_loss=0.00319]Epoch 32:  45%|████▍     | 13/29 [00:00<00:00, 204.34it/s, train_loss=0.00278, val_loss=0.00319]Epoch 32:  45%|████▍     | 13/29 [00:00<00:00, 197.24it/s, train_loss=0.00358, val_loss=0.00319]Epoch 32:  48%|████▊     | 14/29 [00:00<00:00, 201.65it/s, train_loss=0.00358, val_loss=0.00319]Epoch 32:  48%|████▊     | 14/29 [00:00<00:00, 195.17it/s, train_loss=0.00254, val_loss=0.00319]Epoch 32:  52%|█████▏    | 15/29 [00:00<00:00, 199.11it/s, train_loss=0.00254, val_loss=0.00319]Epoch 32:  52%|█████▏    | 15/29 [00:00<00:00, 193.54it/s, train_loss=0.00296, val_loss=0.00319]Epoch 32:  55%|█████▌    | 16/29 [00:00<00:00, 197.41it/s, train_loss=0.00296, val_loss=0.00319]Epoch 32:  55%|█████▌    | 16/29 [00:00<00:00, 192.23it/s, train_loss=0.00239, val_loss=0.00319]Epoch 32:  59%|█████▊    | 17/29 [00:00<00:00, 194.11it/s, train_loss=0.00239, val_loss=0.00319]Epoch 32:  59%|█████▊    | 17/29 [00:00<00:00, 191.82it/s, train_loss=0.002, val_loss=0.00319]  Epoch 32:  62%|██████▏   | 18/29 [00:00<00:00, 194.86it/s, train_loss=0.002, val_loss=0.00319]Epoch 32:  62%|██████▏   | 18/29 [00:00<00:00, 190.64it/s, train_loss=0.0024, val_loss=0.00319]Epoch 32:  66%|██████▌   | 19/29 [00:00<00:00, 193.84it/s, train_loss=0.0024, val_loss=0.00319]Epoch 32:  66%|██████▌   | 19/29 [00:00<00:00, 189.70it/s, train_loss=0.00219, val_loss=0.00319]Epoch 32:  69%|██████▉   | 20/29 [00:00<00:00, 192.69it/s, train_loss=0.00219, val_loss=0.00319]Epoch 32:  69%|██████▉   | 20/29 [00:00<00:00, 188.78it/s, train_loss=0.00234, val_loss=0.00319]Epoch 32:  72%|███████▏  | 21/29 [00:00<00:00, 191.67it/s, train_loss=0.00234, val_loss=0.00319]Epoch 32:  72%|███████▏  | 21/29 [00:00<00:00, 187.99it/s, train_loss=0.00225, val_loss=0.00319]Epoch 32:  76%|███████▌  | 22/29 [00:00<00:00, 190.80it/s, train_loss=0.00225, val_loss=0.00319]Epoch 32:  76%|███████▌  | 22/29 [00:00<00:00, 187.27it/s, train_loss=0.00276, val_loss=0.00319]Epoch 32:  79%|███████▉  | 23/29 [00:00<00:00, 189.14it/s, train_loss=0.00276, val_loss=0.00319]Epoch 32:  79%|███████▉  | 23/29 [00:00<00:00, 187.22it/s, train_loss=0.00262, val_loss=0.00319]Epoch 32:  83%|████████▎ | 24/29 [00:00<00:00, 189.57it/s, train_loss=0.00262, val_loss=0.00319]Epoch 32:  83%|████████▎ | 24/29 [00:00<00:00, 186.45it/s, train_loss=0.00231, val_loss=0.00319]Epoch 32:  86%|████████▌ | 25/29 [00:00<00:00, 189.52it/s, train_loss=0.00231, val_loss=0.00319]Epoch 32:  86%|████████▌ | 25/29 [00:00<00:00, 188.72it/s, train_loss=0.00223, val_loss=0.00319]Epoch 32:  90%|████████▉ | 26/29 [00:00<00:00, 191.51it/s, train_loss=0.00223, val_loss=0.00319]Epoch 32:  90%|████████▉ | 26/29 [00:00<00:00, 188.36it/s, train_loss=0.00381, val_loss=0.00319]Epoch 32:  93%|█████████▎| 27/29 [00:00<00:00, 191.03it/s, train_loss=0.00381, val_loss=0.00319]Epoch 32:  93%|█████████▎| 27/29 [00:00<00:00, 190.17it/s, train_loss=0.00306, val_loss=0.00319]Epoch 32:  97%|█████████▋| 28/29 [00:00<00:00, 192.68it/s, train_loss=0.00306, val_loss=0.00319]Epoch 32:  97%|█████████▋| 28/29 [00:00<00:00, 190.13it/s, train_loss=0.0032, val_loss=0.00319] Epoch 32: 100%|██████████| 29/29 [00:00<00:00, 192.59it/s, train_loss=0.0032, val_loss=0.00319]Epoch 32: 100%|██████████| 29/29 [00:00<00:00, 191.66it/s, train_loss=0.0043, val_loss=0.00319]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 207.98it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 246.53it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 262.81it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 269.96it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 272.73it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 276.48it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 277.83it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 280.14it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 281.85it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 282.37it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 283.84it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 283.20it/s][A
                                                                         [AEpoch 32: 100%|██████████| 29/29 [00:00<00:00, 143.43it/s, train_loss=0.0043, val_loss=0.00318]Epoch 32: 100%|██████████| 29/29 [00:00<00:00, 142.70it/s, train_loss=0.0043, val_loss=0.00318]Epoch 32:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0043, val_loss=0.00318]          Epoch 33:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0043, val_loss=0.00318]Epoch 33:   3%|▎         | 1/29 [00:00<00:00, 199.95it/s, train_loss=0.0043, val_loss=0.00318]Epoch 33:   3%|▎         | 1/29 [00:00<00:00, 143.69it/s, train_loss=0.00256, val_loss=0.00318]Epoch 33:   7%|▋         | 2/29 [00:00<00:00, 185.67it/s, train_loss=0.00256, val_loss=0.00318]Epoch 33:   7%|▋         | 2/29 [00:00<00:00, 156.12it/s, train_loss=0.00407, val_loss=0.00318]Epoch 33:  10%|█         | 3/29 [00:00<00:00, 182.95it/s, train_loss=0.00407, val_loss=0.00318]Epoch 33:  10%|█         | 3/29 [00:00<00:00, 160.38it/s, train_loss=0.00267, val_loss=0.00318]Epoch 33:  14%|█▍        | 4/29 [00:00<00:00, 178.89it/s, train_loss=0.00267, val_loss=0.00318]Epoch 33:  14%|█▍        | 4/29 [00:00<00:00, 163.01it/s, train_loss=0.00218, val_loss=0.00318]Epoch 33:  17%|█▋        | 5/29 [00:00<00:00, 177.56it/s, train_loss=0.00218, val_loss=0.00318]Epoch 33:  17%|█▋        | 5/29 [00:00<00:00, 164.93it/s, train_loss=0.00242, val_loss=0.00318]Epoch 33:  21%|██        | 6/29 [00:00<00:00, 176.39it/s, train_loss=0.00242, val_loss=0.00318]Epoch 33:  21%|██        | 6/29 [00:00<00:00, 171.09it/s, train_loss=0.00246, val_loss=0.00318]Epoch 33:  24%|██▍       | 7/29 [00:00<00:00, 180.71it/s, train_loss=0.00246, val_loss=0.00318]Epoch 33:  24%|██▍       | 7/29 [00:00<00:00, 178.36it/s, train_loss=0.00271, val_loss=0.00318]Epoch 33:  28%|██▊       | 8/29 [00:00<00:00, 187.19it/s, train_loss=0.00271, val_loss=0.00318]Epoch 33:  28%|██▊       | 8/29 [00:00<00:00, 177.57it/s, train_loss=0.0032, val_loss=0.00318] Epoch 33:  31%|███       | 9/29 [00:00<00:00, 186.19it/s, train_loss=0.0032, val_loss=0.00318]Epoch 33:  31%|███       | 9/29 [00:00<00:00, 183.90it/s, train_loss=0.00259, val_loss=0.00318]Epoch 33:  34%|███▍      | 10/29 [00:00<00:00, 191.29it/s, train_loss=0.00259, val_loss=0.00318]Epoch 33:  34%|███▍      | 10/29 [00:00<00:00, 183.95it/s, train_loss=0.00287, val_loss=0.00318]Epoch 33:  38%|███▊      | 11/29 [00:00<00:00, 190.28it/s, train_loss=0.00287, val_loss=0.00318]Epoch 33:  38%|███▊      | 11/29 [00:00<00:00, 187.81it/s, train_loss=0.00267, val_loss=0.00318]Epoch 33:  41%|████▏     | 12/29 [00:00<00:00, 191.77it/s, train_loss=0.00267, val_loss=0.00318]Epoch 33:  41%|████▏     | 12/29 [00:00<00:00, 189.20it/s, train_loss=0.00242, val_loss=0.00318]Epoch 33:  45%|████▍     | 13/29 [00:00<00:00, 194.34it/s, train_loss=0.00242, val_loss=0.00318]Epoch 33:  45%|████▍     | 13/29 [00:00<00:00, 187.96it/s, train_loss=0.00316, val_loss=0.00318]Epoch 33:  48%|████▊     | 14/29 [00:00<00:00, 191.09it/s, train_loss=0.00316, val_loss=0.00318]Epoch 33:  48%|████▊     | 14/29 [00:00<00:00, 187.90it/s, train_loss=0.00279, val_loss=0.00318]Epoch 33:  52%|█████▏    | 15/29 [00:00<00:00, 192.15it/s, train_loss=0.00279, val_loss=0.00318]Epoch 33:  52%|█████▏    | 15/29 [00:00<00:00, 186.74it/s, train_loss=0.00235, val_loss=0.00318]Epoch 33:  55%|█████▌    | 16/29 [00:00<00:00, 191.00it/s, train_loss=0.00235, val_loss=0.00318]Epoch 33:  55%|█████▌    | 16/29 [00:00<00:00, 185.90it/s, train_loss=0.003, val_loss=0.00318]  Epoch 33:  59%|█████▊    | 17/29 [00:00<00:00, 189.74it/s, train_loss=0.003, val_loss=0.00318]Epoch 33:  59%|█████▊    | 17/29 [00:00<00:00, 185.12it/s, train_loss=0.00238, val_loss=0.00318]Epoch 33:  62%|██████▏   | 18/29 [00:00<00:00, 188.62it/s, train_loss=0.00238, val_loss=0.00318]Epoch 33:  62%|██████▏   | 18/29 [00:00<00:00, 184.49it/s, train_loss=0.00251, val_loss=0.00318]Epoch 33:  66%|██████▌   | 19/29 [00:00<00:00, 187.81it/s, train_loss=0.00251, val_loss=0.00318]Epoch 33:  66%|██████▌   | 19/29 [00:00<00:00, 183.92it/s, train_loss=0.00259, val_loss=0.00318]Epoch 33:  69%|██████▉   | 20/29 [00:00<00:00, 186.03it/s, train_loss=0.00259, val_loss=0.00318]Epoch 33:  69%|██████▉   | 20/29 [00:00<00:00, 184.35it/s, train_loss=0.00335, val_loss=0.00318]Epoch 33:  72%|███████▏  | 21/29 [00:00<00:00, 187.04it/s, train_loss=0.00335, val_loss=0.00318]Epoch 33:  72%|███████▏  | 21/29 [00:00<00:00, 183.69it/s, train_loss=0.0026, val_loss=0.00318] Epoch 33:  76%|███████▌  | 22/29 [00:00<00:00, 186.55it/s, train_loss=0.0026, val_loss=0.00318]Epoch 33:  76%|███████▌  | 22/29 [00:00<00:00, 183.20it/s, train_loss=0.0024, val_loss=0.00318]Epoch 33:  79%|███████▉  | 23/29 [00:00<00:00, 185.72it/s, train_loss=0.0024, val_loss=0.00318]Epoch 33:  79%|███████▉  | 23/29 [00:00<00:00, 182.72it/s, train_loss=0.00218, val_loss=0.00318]Epoch 33:  83%|████████▎ | 24/29 [00:00<00:00, 185.29it/s, train_loss=0.00218, val_loss=0.00318]Epoch 33:  83%|████████▎ | 24/29 [00:00<00:00, 182.33it/s, train_loss=0.00263, val_loss=0.00318]Epoch 33:  86%|████████▌ | 25/29 [00:00<00:00, 184.80it/s, train_loss=0.00263, val_loss=0.00318]Epoch 33:  86%|████████▌ | 25/29 [00:00<00:00, 182.02it/s, train_loss=0.00216, val_loss=0.00318]Epoch 33:  90%|████████▉ | 26/29 [00:00<00:00, 184.80it/s, train_loss=0.00216, val_loss=0.00318]Epoch 33:  90%|████████▉ | 26/29 [00:00<00:00, 182.34it/s, train_loss=0.00282, val_loss=0.00318]Epoch 33:  93%|█████████▎| 27/29 [00:00<00:00, 185.18it/s, train_loss=0.00282, val_loss=0.00318]Epoch 33:  93%|█████████▎| 27/29 [00:00<00:00, 184.49it/s, train_loss=0.00232, val_loss=0.00318]Epoch 33:  97%|█████████▋| 28/29 [00:00<00:00, 187.21it/s, train_loss=0.00232, val_loss=0.00318]Epoch 33:  97%|█████████▋| 28/29 [00:00<00:00, 184.38it/s, train_loss=0.00262, val_loss=0.00318]Epoch 33: 100%|██████████| 29/29 [00:00<00:00, 187.03it/s, train_loss=0.00262, val_loss=0.00318]Epoch 33: 100%|██████████| 29/29 [00:00<00:00, 186.20it/s, train_loss=0.00188, val_loss=0.00318]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 208.01it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 252.19it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 267.76it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 277.33it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 283.45it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 286.01it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 287.05it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 288.54it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 287.24it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 287.37it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 288.10it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 285.42it/s][A
                                                                         [AEpoch 33: 100%|██████████| 29/29 [00:00<00:00, 141.13it/s, train_loss=0.00188, val_loss=0.00319]Epoch 33: 100%|██████████| 29/29 [00:00<00:00, 140.51it/s, train_loss=0.00188, val_loss=0.00319]Epoch 33:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00188, val_loss=0.00319]          Epoch 34:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00188, val_loss=0.00319]Epoch 34:   3%|▎         | 1/29 [00:00<00:00, 214.28it/s, train_loss=0.00188, val_loss=0.00319]Epoch 34:   3%|▎         | 1/29 [00:00<00:00, 172.69it/s, train_loss=0.00226, val_loss=0.00319]Epoch 34:   7%|▋         | 2/29 [00:00<00:00, 215.21it/s, train_loss=0.00226, val_loss=0.00319]Epoch 34:   7%|▋         | 2/29 [00:00<00:00, 172.08it/s, train_loss=0.00241, val_loss=0.00319]Epoch 34:  10%|█         | 3/29 [00:00<00:00, 198.34it/s, train_loss=0.00241, val_loss=0.00319]Epoch 34:  10%|█         | 3/29 [00:00<00:00, 172.30it/s, train_loss=0.00296, val_loss=0.00319]Epoch 34:  14%|█▍        | 4/29 [00:00<00:00, 190.38it/s, train_loss=0.00296, val_loss=0.00319]Epoch 34:  14%|█▍        | 4/29 [00:00<00:00, 181.57it/s, train_loss=0.00304, val_loss=0.00319]Epoch 34:  17%|█▋        | 5/29 [00:00<00:00, 194.10it/s, train_loss=0.00304, val_loss=0.00319]Epoch 34:  17%|█▋        | 5/29 [00:00<00:00, 187.22it/s, train_loss=0.00256, val_loss=0.00319]Epoch 34:  21%|██        | 6/29 [00:00<00:00, 196.78it/s, train_loss=0.00256, val_loss=0.00319]Epoch 34:  21%|██        | 6/29 [00:00<00:00, 190.19it/s, train_loss=0.00282, val_loss=0.00319]Epoch 34:  24%|██▍       | 7/29 [00:00<00:00, 198.42it/s, train_loss=0.00282, val_loss=0.00319]Epoch 34:  24%|██▍       | 7/29 [00:00<00:00, 187.52it/s, train_loss=0.0027, val_loss=0.00319] Epoch 34:  28%|██▊       | 8/29 [00:00<00:00, 197.30it/s, train_loss=0.0027, val_loss=0.00319]Epoch 34:  28%|██▊       | 8/29 [00:00<00:00, 194.80it/s, train_loss=0.00276, val_loss=0.00319]Epoch 34:  31%|███       | 9/29 [00:00<00:00, 203.33it/s, train_loss=0.00276, val_loss=0.00319]Epoch 34:  31%|███       | 9/29 [00:00<00:00, 193.00it/s, train_loss=0.00199, val_loss=0.00319]Epoch 34:  34%|███▍      | 10/29 [00:00<00:00, 200.34it/s, train_loss=0.00199, val_loss=0.00319]Epoch 34:  34%|███▍      | 10/29 [00:00<00:00, 198.02it/s, train_loss=0.0034, val_loss=0.00319] Epoch 34:  38%|███▊      | 11/29 [00:00<00:00, 204.67it/s, train_loss=0.0034, val_loss=0.00319]Epoch 34:  38%|███▊      | 11/29 [00:00<00:00, 196.82it/s, train_loss=0.00278, val_loss=0.00319]Epoch 34:  41%|████▏     | 12/29 [00:00<00:00, 201.82it/s, train_loss=0.00278, val_loss=0.00319]Epoch 34:  41%|████▏     | 12/29 [00:00<00:00, 196.62it/s, train_loss=0.00276, val_loss=0.00319]Epoch 34:  45%|████▍     | 13/29 [00:00<00:00, 201.36it/s, train_loss=0.00276, val_loss=0.00319]Epoch 34:  45%|████▍     | 13/29 [00:00<00:00, 194.43it/s, train_loss=0.00141, val_loss=0.00319]Epoch 34:  48%|████▊     | 14/29 [00:00<00:00, 199.02it/s, train_loss=0.00141, val_loss=0.00319]Epoch 34:  48%|████▊     | 14/29 [00:00<00:00, 192.79it/s, train_loss=0.0031, val_loss=0.00319] Epoch 34:  52%|█████▏    | 15/29 [00:00<00:00, 196.82it/s, train_loss=0.0031, val_loss=0.00319]Epoch 34:  52%|█████▏    | 15/29 [00:00<00:00, 191.33it/s, train_loss=0.00246, val_loss=0.00319]Epoch 34:  55%|█████▌    | 16/29 [00:00<00:00, 195.49it/s, train_loss=0.00246, val_loss=0.00319]Epoch 34:  55%|█████▌    | 16/29 [00:00<00:00, 190.11it/s, train_loss=0.00193, val_loss=0.00319]Epoch 34:  59%|█████▊    | 17/29 [00:00<00:00, 194.03it/s, train_loss=0.00193, val_loss=0.00319]Epoch 34:  59%|█████▊    | 17/29 [00:00<00:00, 189.08it/s, train_loss=0.00242, val_loss=0.00319]Epoch 34:  62%|██████▏   | 18/29 [00:00<00:00, 192.37it/s, train_loss=0.00242, val_loss=0.00319]Epoch 34:  62%|██████▏   | 18/29 [00:00<00:00, 188.71it/s, train_loss=0.00283, val_loss=0.00319]Epoch 34:  66%|██████▌   | 19/29 [00:00<00:00, 192.12it/s, train_loss=0.00283, val_loss=0.00319]Epoch 34:  66%|██████▌   | 19/29 [00:00<00:00, 187.77it/s, train_loss=0.0018, val_loss=0.00319] Epoch 34:  69%|██████▉   | 20/29 [00:00<00:00, 191.11it/s, train_loss=0.0018, val_loss=0.00319]Epoch 34:  69%|██████▉   | 20/29 [00:00<00:00, 186.99it/s, train_loss=0.0019, val_loss=0.00319]Epoch 34:  72%|███████▏  | 21/29 [00:00<00:00, 190.02it/s, train_loss=0.0019, val_loss=0.00319]Epoch 34:  72%|███████▏  | 21/29 [00:00<00:00, 186.22it/s, train_loss=0.00363, val_loss=0.00319]Epoch 34:  76%|███████▌  | 22/29 [00:00<00:00, 189.14it/s, train_loss=0.00363, val_loss=0.00319]Epoch 34:  76%|███████▌  | 22/29 [00:00<00:00, 185.64it/s, train_loss=0.00301, val_loss=0.00319]Epoch 34:  79%|███████▉  | 23/29 [00:00<00:00, 188.07it/s, train_loss=0.00301, val_loss=0.00319]Epoch 34:  79%|███████▉  | 23/29 [00:00<00:00, 185.12it/s, train_loss=0.00358, val_loss=0.00319]Epoch 34:  83%|████████▎ | 24/29 [00:00<00:00, 187.32it/s, train_loss=0.00358, val_loss=0.00319]Epoch 34:  83%|████████▎ | 24/29 [00:00<00:00, 185.26it/s, train_loss=0.0025, val_loss=0.00319] Epoch 34:  86%|████████▌ | 25/29 [00:00<00:00, 187.43it/s, train_loss=0.0025, val_loss=0.00319]Epoch 34:  86%|████████▌ | 25/29 [00:00<00:00, 184.65it/s, train_loss=0.00447, val_loss=0.00319]Epoch 34:  90%|████████▉ | 26/29 [00:00<00:00, 186.88it/s, train_loss=0.00447, val_loss=0.00319]Epoch 34:  90%|████████▉ | 26/29 [00:00<00:00, 184.28it/s, train_loss=0.00273, val_loss=0.00319]Epoch 34:  93%|█████████▎| 27/29 [00:00<00:00, 187.10it/s, train_loss=0.00273, val_loss=0.00319]Epoch 34:  93%|█████████▎| 27/29 [00:00<00:00, 186.25it/s, train_loss=0.00229, val_loss=0.00319]Epoch 34:  97%|█████████▋| 28/29 [00:00<00:00, 188.85it/s, train_loss=0.00229, val_loss=0.00319]Epoch 34:  97%|█████████▋| 28/29 [00:00<00:00, 186.30it/s, train_loss=0.00188, val_loss=0.00319]Epoch 34: 100%|██████████| 29/29 [00:00<00:00, 188.95it/s, train_loss=0.00188, val_loss=0.00319]Epoch 34: 100%|██████████| 29/29 [00:00<00:00, 188.17it/s, train_loss=0.00193, val_loss=0.00319]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 226.34it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 270.39it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 287.98it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 296.61it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 298.23it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 299.32it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 301.47it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 301.56it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 301.28it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 301.09it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 301.17it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 301.74it/s][A
                                                                         [AEpoch 34: 100%|██████████| 29/29 [00:00<00:00, 143.53it/s, train_loss=0.00193, val_loss=0.00316]Epoch 34: 100%|██████████| 29/29 [00:00<00:00, 142.90it/s, train_loss=0.00193, val_loss=0.00316]Epoch 34:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00193, val_loss=0.00316]          Epoch 35:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00193, val_loss=0.00316]Epoch 35:   3%|▎         | 1/29 [00:00<00:00, 192.75it/s, train_loss=0.00193, val_loss=0.00316]Epoch 35:   3%|▎         | 1/29 [00:00<00:00, 163.76it/s, train_loss=0.00184, val_loss=0.00316]Epoch 35:   7%|▋         | 2/29 [00:00<00:00, 196.24it/s, train_loss=0.00184, val_loss=0.00316]Epoch 35:   7%|▋         | 2/29 [00:00<00:00, 173.10it/s, train_loss=0.00184, val_loss=0.00316]Epoch 35:  10%|█         | 3/29 [00:00<00:00, 194.38it/s, train_loss=0.00184, val_loss=0.00316]Epoch 35:  10%|█         | 3/29 [00:00<00:00, 172.49it/s, train_loss=0.00273, val_loss=0.00316]Epoch 35:  14%|█▍        | 4/29 [00:00<00:00, 189.12it/s, train_loss=0.00273, val_loss=0.00316]Epoch 35:  14%|█▍        | 4/29 [00:00<00:00, 172.62it/s, train_loss=0.00288, val_loss=0.00316]Epoch 35:  17%|█▋        | 5/29 [00:00<00:00, 186.12it/s, train_loss=0.00288, val_loss=0.00316]Epoch 35:  17%|█▋        | 5/29 [00:00<00:00, 172.60it/s, train_loss=0.00199, val_loss=0.00316]Epoch 35:  21%|██        | 6/29 [00:00<00:00, 184.03it/s, train_loss=0.00199, val_loss=0.00316]Epoch 35:  21%|██        | 6/29 [00:00<00:00, 172.71it/s, train_loss=0.00341, val_loss=0.00316]Epoch 35:  24%|██▍       | 7/29 [00:00<00:00, 182.69it/s, train_loss=0.00341, val_loss=0.00316]Epoch 35:  24%|██▍       | 7/29 [00:00<00:00, 172.83it/s, train_loss=0.00257, val_loss=0.00316]Epoch 35:  28%|██▊       | 8/29 [00:00<00:00, 180.67it/s, train_loss=0.00257, val_loss=0.00316]Epoch 35:  28%|██▊       | 8/29 [00:00<00:00, 173.98it/s, train_loss=0.00236, val_loss=0.00316]Epoch 35:  31%|███       | 9/29 [00:00<00:00, 182.62it/s, train_loss=0.00236, val_loss=0.00316]Epoch 35:  31%|███       | 9/29 [00:00<00:00, 180.81it/s, train_loss=0.00326, val_loss=0.00316]Epoch 35:  34%|███▍      | 10/29 [00:00<00:00, 188.80it/s, train_loss=0.00326, val_loss=0.00316]Epoch 35:  34%|███▍      | 10/29 [00:00<00:00, 180.82it/s, train_loss=0.00333, val_loss=0.00316]Epoch 35:  38%|███▊      | 11/29 [00:00<00:00, 187.77it/s, train_loss=0.00333, val_loss=0.00316]Epoch 35:  38%|███▊      | 11/29 [00:00<00:00, 185.81it/s, train_loss=0.0027, val_loss=0.00316] Epoch 35:  41%|████▏     | 12/29 [00:00<00:00, 191.99it/s, train_loss=0.0027, val_loss=0.00316]Epoch 35:  41%|████▏     | 12/29 [00:00<00:00, 185.90it/s, train_loss=0.00262, val_loss=0.00316]Epoch 35:  45%|████▍     | 13/29 [00:00<00:00, 191.42it/s, train_loss=0.00262, val_loss=0.00316]Epoch 35:  45%|████▍     | 13/29 [00:00<00:00, 189.32it/s, train_loss=0.00185, val_loss=0.00316]Epoch 35:  48%|████▊     | 14/29 [00:00<00:00, 194.43it/s, train_loss=0.00185, val_loss=0.00316]Epoch 35:  48%|████▊     | 14/29 [00:00<00:00, 189.86it/s, train_loss=0.00375, val_loss=0.00316]Epoch 35:  52%|█████▏    | 15/29 [00:00<00:00, 194.54it/s, train_loss=0.00375, val_loss=0.00316]Epoch 35:  52%|█████▏    | 15/29 [00:00<00:00, 192.73it/s, train_loss=0.0031, val_loss=0.00316] Epoch 35:  55%|█████▌    | 16/29 [00:00<00:00, 196.83it/s, train_loss=0.0031, val_loss=0.00316]Epoch 35:  55%|█████▌    | 16/29 [00:00<00:00, 194.43it/s, train_loss=0.00253, val_loss=0.00316]Epoch 35:  59%|█████▊    | 17/29 [00:00<00:00, 198.35it/s, train_loss=0.00253, val_loss=0.00316]Epoch 35:  59%|█████▊    | 17/29 [00:00<00:00, 196.76it/s, train_loss=0.00204, val_loss=0.00316]Epoch 35:  62%|██████▏   | 18/29 [00:00<00:00, 200.47it/s, train_loss=0.00204, val_loss=0.00316]Epoch 35:  62%|██████▏   | 18/29 [00:00<00:00, 196.59it/s, train_loss=0.00226, val_loss=0.00316]Epoch 35:  66%|██████▌   | 19/29 [00:00<00:00, 199.88it/s, train_loss=0.00226, val_loss=0.00316]Epoch 35:  66%|██████▌   | 19/29 [00:00<00:00, 195.12it/s, train_loss=0.0023, val_loss=0.00316] Epoch 35:  69%|██████▉   | 20/29 [00:00<00:00, 198.20it/s, train_loss=0.0023, val_loss=0.00316]Epoch 35:  69%|██████▉   | 20/29 [00:00<00:00, 193.93it/s, train_loss=0.00185, val_loss=0.00316]Epoch 35:  72%|███████▏  | 21/29 [00:00<00:00, 196.95it/s, train_loss=0.00185, val_loss=0.00316]Epoch 35:  72%|███████▏  | 21/29 [00:00<00:00, 192.94it/s, train_loss=0.0032, val_loss=0.00316] Epoch 35:  76%|███████▌  | 22/29 [00:00<00:00, 195.75it/s, train_loss=0.0032, val_loss=0.00316]Epoch 35:  76%|███████▌  | 22/29 [00:00<00:00, 194.28it/s, train_loss=0.00222, val_loss=0.00316]Epoch 35:  79%|███████▉  | 23/29 [00:00<00:00, 196.85it/s, train_loss=0.00222, val_loss=0.00316]Epoch 35:  79%|███████▉  | 23/29 [00:00<00:00, 193.58it/s, train_loss=0.00291, val_loss=0.00316]Epoch 35:  83%|████████▎ | 24/29 [00:00<00:00, 196.16it/s, train_loss=0.00291, val_loss=0.00316]Epoch 35:  83%|████████▎ | 24/29 [00:00<00:00, 192.63it/s, train_loss=0.0024, val_loss=0.00316] Epoch 35:  86%|████████▌ | 25/29 [00:00<00:00, 195.14it/s, train_loss=0.0024, val_loss=0.00316]Epoch 35:  86%|████████▌ | 25/29 [00:00<00:00, 191.76it/s, train_loss=0.00339, val_loss=0.00316]Epoch 35:  90%|████████▉ | 26/29 [00:00<00:00, 194.22it/s, train_loss=0.00339, val_loss=0.00316]Epoch 35:  90%|████████▉ | 26/29 [00:00<00:00, 191.02it/s, train_loss=0.00202, val_loss=0.00316]Epoch 35:  93%|█████████▎| 27/29 [00:00<00:00, 194.00it/s, train_loss=0.00202, val_loss=0.00316]Epoch 35:  93%|█████████▎| 27/29 [00:00<00:00, 193.30it/s, train_loss=0.0021, val_loss=0.00316] Epoch 35:  97%|█████████▋| 28/29 [00:00<00:00, 196.03it/s, train_loss=0.0021, val_loss=0.00316]Epoch 35:  97%|█████████▋| 28/29 [00:00<00:00, 195.24it/s, train_loss=0.00479, val_loss=0.00316]Epoch 35: 100%|██████████| 29/29 [00:00<00:00, 197.92it/s, train_loss=0.00479, val_loss=0.00316]Epoch 35: 100%|██████████| 29/29 [00:00<00:00, 197.23it/s, train_loss=0.00186, val_loss=0.00316]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 255.31it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 296.25it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 306.96it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 310.24it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 309.34it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 310.28it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 308.66it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 309.94it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 310.95it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 309.48it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 307.34it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 306.95it/s][A
                                                                         [AEpoch 35: 100%|██████████| 29/29 [00:00<00:00, 149.98it/s, train_loss=0.00186, val_loss=0.00316]Epoch 35: 100%|██████████| 29/29 [00:00<00:00, 149.23it/s, train_loss=0.00186, val_loss=0.00316]Epoch 35:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00186, val_loss=0.00316]          Epoch 36:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00186, val_loss=0.00316]Epoch 36:   3%|▎         | 1/29 [00:00<00:00, 195.53it/s, train_loss=0.00186, val_loss=0.00316]Epoch 36:   3%|▎         | 1/29 [00:00<00:00, 166.21it/s, train_loss=0.00147, val_loss=0.00316]Epoch 36:   7%|▋         | 2/29 [00:00<00:00, 205.04it/s, train_loss=0.00147, val_loss=0.00316]Epoch 36:   7%|▋         | 2/29 [00:00<00:00, 173.46it/s, train_loss=0.00254, val_loss=0.00316]Epoch 36:  10%|█         | 3/29 [00:00<00:00, 198.47it/s, train_loss=0.00254, val_loss=0.00316]Epoch 36:  10%|█         | 3/29 [00:00<00:00, 173.24it/s, train_loss=0.00196, val_loss=0.00316]Epoch 36:  14%|█▍        | 4/29 [00:00<00:00, 190.91it/s, train_loss=0.00196, val_loss=0.00316]Epoch 36:  14%|█▍        | 4/29 [00:00<00:00, 172.83it/s, train_loss=0.00153, val_loss=0.00316]Epoch 36:  17%|█▋        | 5/29 [00:00<00:00, 186.82it/s, train_loss=0.00153, val_loss=0.00316]Epoch 36:  17%|█▋        | 5/29 [00:00<00:00, 172.61it/s, train_loss=0.00274, val_loss=0.00316]Epoch 36:  21%|██        | 6/29 [00:00<00:00, 184.08it/s, train_loss=0.00274, val_loss=0.00316]Epoch 36:  21%|██        | 6/29 [00:00<00:00, 172.73it/s, train_loss=0.00252, val_loss=0.00316]Epoch 36:  24%|██▍       | 7/29 [00:00<00:00, 180.52it/s, train_loss=0.00252, val_loss=0.00316]Epoch 36:  24%|██▍       | 7/29 [00:00<00:00, 173.91it/s, train_loss=0.00286, val_loss=0.00316]Epoch 36:  28%|██▊       | 8/29 [00:00<00:00, 181.77it/s, train_loss=0.00286, val_loss=0.00316]Epoch 36:  28%|██▊       | 8/29 [00:00<00:00, 173.53it/s, train_loss=0.00266, val_loss=0.00316]Epoch 36:  31%|███       | 9/29 [00:00<00:00, 180.58it/s, train_loss=0.00266, val_loss=0.00316]Epoch 36:  31%|███       | 9/29 [00:00<00:00, 173.41it/s, train_loss=0.00289, val_loss=0.00316]Epoch 36:  34%|███▍      | 10/29 [00:00<00:00, 181.50it/s, train_loss=0.00289, val_loss=0.00316]Epoch 36:  34%|███▍      | 10/29 [00:00<00:00, 179.68it/s, train_loss=0.00235, val_loss=0.00316]Epoch 36:  38%|███▊      | 11/29 [00:00<00:00, 186.95it/s, train_loss=0.00235, val_loss=0.00316]Epoch 36:  38%|███▊      | 11/29 [00:00<00:00, 179.82it/s, train_loss=0.00285, val_loss=0.00316]Epoch 36:  41%|████▏     | 12/29 [00:00<00:00, 186.08it/s, train_loss=0.00285, val_loss=0.00316]Epoch 36:  41%|████▏     | 12/29 [00:00<00:00, 184.27it/s, train_loss=0.0023, val_loss=0.00316] Epoch 36:  45%|████▍     | 13/29 [00:00<00:00, 189.84it/s, train_loss=0.0023, val_loss=0.00316]Epoch 36:  45%|████▍     | 13/29 [00:00<00:00, 184.81it/s, train_loss=0.003, val_loss=0.00316] Epoch 36:  48%|████▊     | 14/29 [00:00<00:00, 189.47it/s, train_loss=0.003, val_loss=0.00316]Epoch 36:  48%|████▊     | 14/29 [00:00<00:00, 185.61it/s, train_loss=0.00386, val_loss=0.00316]Epoch 36:  52%|█████▏    | 15/29 [00:00<00:00, 189.67it/s, train_loss=0.00386, val_loss=0.00316]Epoch 36:  52%|█████▏    | 15/29 [00:00<00:00, 184.56it/s, train_loss=0.00249, val_loss=0.00316]Epoch 36:  55%|█████▌    | 16/29 [00:00<00:00, 188.70it/s, train_loss=0.00249, val_loss=0.00316]Epoch 36:  55%|█████▌    | 16/29 [00:00<00:00, 183.84it/s, train_loss=0.00273, val_loss=0.00316]Epoch 36:  59%|█████▊    | 17/29 [00:00<00:00, 187.55it/s, train_loss=0.00273, val_loss=0.00316]Epoch 36:  59%|█████▊    | 17/29 [00:00<00:00, 183.05it/s, train_loss=0.00277, val_loss=0.00316]Epoch 36:  62%|██████▏   | 18/29 [00:00<00:00, 186.57it/s, train_loss=0.00277, val_loss=0.00316]Epoch 36:  62%|██████▏   | 18/29 [00:00<00:00, 182.49it/s, train_loss=0.00402, val_loss=0.00316]Epoch 36:  66%|██████▌   | 19/29 [00:00<00:00, 185.89it/s, train_loss=0.00402, val_loss=0.00316]Epoch 36:  66%|██████▌   | 19/29 [00:00<00:00, 182.08it/s, train_loss=0.00227, val_loss=0.00316]Epoch 36:  69%|██████▉   | 20/29 [00:00<00:00, 185.36it/s, train_loss=0.00227, val_loss=0.00316]Epoch 36:  69%|██████▉   | 20/29 [00:00<00:00, 182.36it/s, train_loss=0.00294, val_loss=0.00316]Epoch 36:  72%|███████▏  | 21/29 [00:00<00:00, 185.38it/s, train_loss=0.00294, val_loss=0.00316]Epoch 36:  72%|███████▏  | 21/29 [00:00<00:00, 181.88it/s, train_loss=0.00236, val_loss=0.00316]Epoch 36:  76%|███████▌  | 22/29 [00:00<00:00, 184.80it/s, train_loss=0.00236, val_loss=0.00316]Epoch 36:  76%|███████▌  | 22/29 [00:00<00:00, 181.52it/s, train_loss=0.00271, val_loss=0.00316]Epoch 36:  79%|███████▉  | 23/29 [00:00<00:00, 184.25it/s, train_loss=0.00271, val_loss=0.00316]Epoch 36:  79%|███████▉  | 23/29 [00:00<00:00, 181.16it/s, train_loss=0.00277, val_loss=0.00316]Epoch 36:  83%|████████▎ | 24/29 [00:00<00:00, 183.78it/s, train_loss=0.00277, val_loss=0.00316]Epoch 36:  83%|████████▎ | 24/29 [00:00<00:00, 180.87it/s, train_loss=0.00195, val_loss=0.00316]Epoch 36:  86%|████████▌ | 25/29 [00:00<00:00, 183.35it/s, train_loss=0.00195, val_loss=0.00316]Epoch 36:  86%|████████▌ | 25/29 [00:00<00:00, 180.62it/s, train_loss=0.0019, val_loss=0.00316] Epoch 36:  90%|████████▉ | 26/29 [00:00<00:00, 182.78it/s, train_loss=0.0019, val_loss=0.00316]Epoch 36:  90%|████████▉ | 26/29 [00:00<00:00, 181.07it/s, train_loss=0.00275, val_loss=0.00316]Epoch 36:  93%|█████████▎| 27/29 [00:00<00:00, 183.08it/s, train_loss=0.00275, val_loss=0.00316]Epoch 36:  93%|█████████▎| 27/29 [00:00<00:00, 180.65it/s, train_loss=0.00366, val_loss=0.00316]Epoch 36:  97%|█████████▋| 28/29 [00:00<00:00, 183.29it/s, train_loss=0.00366, val_loss=0.00316]Epoch 36:  97%|█████████▋| 28/29 [00:00<00:00, 182.67it/s, train_loss=0.003, val_loss=0.00316]  Epoch 36: 100%|██████████| 29/29 [00:00<00:00, 185.36it/s, train_loss=0.003, val_loss=0.00316]Epoch 36: 100%|██████████| 29/29 [00:00<00:00, 182.70it/s, train_loss=0.00241, val_loss=0.00316]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 239.37it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 287.42it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 304.78it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 316.09it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 322.43it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 326.15it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 327.98it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 326.27it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 326.40it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 326.17it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 323.71it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 320.98it/s][A
                                                                         [AEpoch 36: 100%|██████████| 29/29 [00:00<00:00, 142.86it/s, train_loss=0.00241, val_loss=0.00315]Epoch 36: 100%|██████████| 29/29 [00:00<00:00, 142.31it/s, train_loss=0.00241, val_loss=0.00315]Epoch 36:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00241, val_loss=0.00315]          Epoch 37:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00241, val_loss=0.00315]Epoch 37:   3%|▎         | 1/29 [00:00<00:00, 205.90it/s, train_loss=0.00241, val_loss=0.00315]Epoch 37:   3%|▎         | 1/29 [00:00<00:00, 173.60it/s, train_loss=0.00244, val_loss=0.00315]Epoch 37:   7%|▋         | 2/29 [00:00<00:00, 204.58it/s, train_loss=0.00244, val_loss=0.00315]Epoch 37:   7%|▋         | 2/29 [00:00<00:00, 172.95it/s, train_loss=0.00278, val_loss=0.00315]Epoch 37:  10%|█         | 3/29 [00:00<00:00, 198.41it/s, train_loss=0.00278, val_loss=0.00315]Epoch 37:  10%|█         | 3/29 [00:00<00:00, 173.17it/s, train_loss=0.00248, val_loss=0.00315]Epoch 37:  14%|█▍        | 4/29 [00:00<00:00, 191.23it/s, train_loss=0.00248, val_loss=0.00315]Epoch 37:  14%|█▍        | 4/29 [00:00<00:00, 183.15it/s, train_loss=0.00324, val_loss=0.00315]Epoch 37:  17%|█▋        | 5/29 [00:00<00:00, 194.94it/s, train_loss=0.00324, val_loss=0.00315]Epoch 37:  17%|█▋        | 5/29 [00:00<00:00, 187.89it/s, train_loss=0.00238, val_loss=0.00315]Epoch 37:  21%|██        | 6/29 [00:00<00:00, 197.87it/s, train_loss=0.00238, val_loss=0.00315]Epoch 37:  21%|██        | 6/29 [00:00<00:00, 191.14it/s, train_loss=0.00223, val_loss=0.00315]Epoch 37:  24%|██▍       | 7/29 [00:00<00:00, 200.20it/s, train_loss=0.00223, val_loss=0.00315]Epoch 37:  24%|██▍       | 7/29 [00:00<00:00, 188.18it/s, train_loss=0.00247, val_loss=0.00315]Epoch 37:  28%|██▊       | 8/29 [00:00<00:00, 195.95it/s, train_loss=0.00247, val_loss=0.00315]Epoch 37:  28%|██▊       | 8/29 [00:00<00:00, 186.13it/s, train_loss=0.00251, val_loss=0.00315]Epoch 37:  31%|███       | 9/29 [00:00<00:00, 193.22it/s, train_loss=0.00251, val_loss=0.00315]Epoch 37:  31%|███       | 9/29 [00:00<00:00, 184.74it/s, train_loss=0.00161, val_loss=0.00315]Epoch 37:  34%|███▍      | 10/29 [00:00<00:00, 191.06it/s, train_loss=0.00161, val_loss=0.00315]Epoch 37:  34%|███▍      | 10/29 [00:00<00:00, 183.64it/s, train_loss=0.00299, val_loss=0.00315]Epoch 37:  38%|███▊      | 11/29 [00:00<00:00, 190.29it/s, train_loss=0.00299, val_loss=0.00315]Epoch 37:  38%|███▊      | 11/29 [00:00<00:00, 184.17it/s, train_loss=0.00179, val_loss=0.00315]Epoch 37:  41%|████▏     | 12/29 [00:00<00:00, 189.92it/s, train_loss=0.00179, val_loss=0.00315]Epoch 37:  41%|████▏     | 12/29 [00:00<00:00, 188.21it/s, train_loss=0.00353, val_loss=0.00315]Epoch 37:  45%|████▍     | 13/29 [00:00<00:00, 193.84it/s, train_loss=0.00353, val_loss=0.00315]Epoch 37:  45%|████▍     | 13/29 [00:00<00:00, 188.47it/s, train_loss=0.00246, val_loss=0.00315]Epoch 37:  48%|████▊     | 14/29 [00:00<00:00, 193.38it/s, train_loss=0.00246, val_loss=0.00315]Epoch 37:  48%|████▊     | 14/29 [00:00<00:00, 191.55it/s, train_loss=0.00227, val_loss=0.00315]Epoch 37:  52%|█████▏    | 15/29 [00:00<00:00, 196.04it/s, train_loss=0.00227, val_loss=0.00315]Epoch 37:  52%|█████▏    | 15/29 [00:00<00:00, 191.73it/s, train_loss=0.00318, val_loss=0.00315]Epoch 37:  55%|█████▌    | 16/29 [00:00<00:00, 196.00it/s, train_loss=0.00318, val_loss=0.00315]Epoch 37:  55%|█████▌    | 16/29 [00:00<00:00, 190.53it/s, train_loss=0.003, val_loss=0.00315]  Epoch 37:  59%|█████▊    | 17/29 [00:00<00:00, 194.51it/s, train_loss=0.003, val_loss=0.00315]Epoch 37:  59%|█████▊    | 17/29 [00:00<00:00, 189.50it/s, train_loss=0.00407, val_loss=0.00315]Epoch 37:  62%|██████▏   | 18/29 [00:00<00:00, 192.83it/s, train_loss=0.00407, val_loss=0.00315]Epoch 37:  62%|██████▏   | 18/29 [00:00<00:00, 189.83it/s, train_loss=0.00334, val_loss=0.00315]Epoch 37:  66%|██████▌   | 19/29 [00:00<00:00, 192.73it/s, train_loss=0.00334, val_loss=0.00315]Epoch 37:  66%|██████▌   | 19/29 [00:00<00:00, 188.80it/s, train_loss=0.00197, val_loss=0.00315]Epoch 37:  69%|██████▉   | 20/29 [00:00<00:00, 192.01it/s, train_loss=0.00197, val_loss=0.00315]Epoch 37:  69%|██████▉   | 20/29 [00:00<00:00, 188.03it/s, train_loss=0.00204, val_loss=0.00315]Epoch 37:  72%|███████▏  | 21/29 [00:00<00:00, 191.10it/s, train_loss=0.00204, val_loss=0.00315]Epoch 37:  72%|███████▏  | 21/29 [00:00<00:00, 187.24it/s, train_loss=0.00151, val_loss=0.00315]Epoch 37:  76%|███████▌  | 22/29 [00:00<00:00, 190.23it/s, train_loss=0.00151, val_loss=0.00315]Epoch 37:  76%|███████▌  | 22/29 [00:00<00:00, 186.56it/s, train_loss=0.00178, val_loss=0.00315]Epoch 37:  79%|███████▉  | 23/29 [00:00<00:00, 189.39it/s, train_loss=0.00178, val_loss=0.00315]Epoch 37:  79%|███████▉  | 23/29 [00:00<00:00, 185.99it/s, train_loss=0.00221, val_loss=0.00315]Epoch 37:  83%|████████▎ | 24/29 [00:00<00:00, 188.13it/s, train_loss=0.00221, val_loss=0.00315]Epoch 37:  83%|████████▎ | 24/29 [00:00<00:00, 186.05it/s, train_loss=0.00248, val_loss=0.00315]Epoch 37:  86%|████████▌ | 25/29 [00:00<00:00, 188.24it/s, train_loss=0.00248, val_loss=0.00315]Epoch 37:  86%|████████▌ | 25/29 [00:00<00:00, 185.42it/s, train_loss=0.00437, val_loss=0.00315]Epoch 37:  90%|████████▉ | 26/29 [00:00<00:00, 187.78it/s, train_loss=0.00437, val_loss=0.00315]Epoch 37:  90%|████████▉ | 26/29 [00:00<00:00, 184.88it/s, train_loss=0.00346, val_loss=0.00315]Epoch 37:  93%|█████████▎| 27/29 [00:00<00:00, 187.23it/s, train_loss=0.00346, val_loss=0.00315]Epoch 37:  93%|█████████▎| 27/29 [00:00<00:00, 184.37it/s, train_loss=0.00309, val_loss=0.00315]Epoch 37:  97%|█████████▋| 28/29 [00:00<00:00, 186.58it/s, train_loss=0.00309, val_loss=0.00315]Epoch 37:  97%|█████████▋| 28/29 [00:00<00:00, 183.93it/s, train_loss=0.00217, val_loss=0.00315]Epoch 37: 100%|██████████| 29/29 [00:00<00:00, 186.67it/s, train_loss=0.00217, val_loss=0.00315]Epoch 37: 100%|██████████| 29/29 [00:00<00:00, 186.04it/s, train_loss=0.00218, val_loss=0.00315]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 269.42it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 317.34it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 332.37it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 339.57it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 339.41it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 340.83it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 341.58it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 342.35it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 339.80it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 335.79it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 334.06it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 332.12it/s][A
                                                                         [AEpoch 37: 100%|██████████| 29/29 [00:00<00:00, 145.08it/s, train_loss=0.00218, val_loss=0.00315]Epoch 37: 100%|██████████| 29/29 [00:00<00:00, 144.42it/s, train_loss=0.00218, val_loss=0.00315]Epoch 37:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00218, val_loss=0.00315]          Epoch 38:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00218, val_loss=0.00315]Epoch 38:   3%|▎         | 1/29 [00:00<00:00, 210.23it/s, train_loss=0.00218, val_loss=0.00315]Epoch 38:   3%|▎         | 1/29 [00:00<00:00, 176.16it/s, train_loss=0.00231, val_loss=0.00315]Epoch 38:   7%|▋         | 2/29 [00:00<00:00, 216.19it/s, train_loss=0.00231, val_loss=0.00315]Epoch 38:   7%|▋         | 2/29 [00:00<00:00, 199.90it/s, train_loss=0.00223, val_loss=0.00315]Epoch 38:  10%|█         | 3/29 [00:00<00:00, 219.07it/s, train_loss=0.00223, val_loss=0.00315]Epoch 38:  10%|█         | 3/29 [00:00<00:00, 206.34it/s, train_loss=0.00242, val_loss=0.00315]Epoch 38:  14%|█▍        | 4/29 [00:00<00:00, 221.04it/s, train_loss=0.00242, val_loss=0.00315]Epoch 38:  14%|█▍        | 4/29 [00:00<00:00, 202.75it/s, train_loss=0.00248, val_loss=0.00315]Epoch 38:  17%|█▋        | 5/29 [00:00<00:00, 214.50it/s, train_loss=0.00248, val_loss=0.00315]Epoch 38:  17%|█▋        | 5/29 [00:00<00:00, 195.77it/s, train_loss=0.00187, val_loss=0.00315]Epoch 38:  21%|██        | 6/29 [00:00<00:00, 205.83it/s, train_loss=0.00187, val_loss=0.00315]Epoch 38:  21%|██        | 6/29 [00:00<00:00, 191.23it/s, train_loss=0.00231, val_loss=0.00315]Epoch 38:  24%|██▍       | 7/29 [00:00<00:00, 200.07it/s, train_loss=0.00231, val_loss=0.00315]Epoch 38:  24%|██▍       | 7/29 [00:00<00:00, 188.50it/s, train_loss=0.00231, val_loss=0.00315]Epoch 38:  28%|██▊       | 8/29 [00:00<00:00, 196.47it/s, train_loss=0.00231, val_loss=0.00315]Epoch 38:  28%|██▊       | 8/29 [00:00<00:00, 186.60it/s, train_loss=0.00187, val_loss=0.00315]Epoch 38:  31%|███       | 9/29 [00:00<00:00, 192.63it/s, train_loss=0.00187, val_loss=0.00315]Epoch 38:  31%|███       | 9/29 [00:00<00:00, 186.41it/s, train_loss=0.00384, val_loss=0.00315]Epoch 38:  34%|███▍      | 10/29 [00:00<00:00, 191.82it/s, train_loss=0.00384, val_loss=0.00315]Epoch 38:  34%|███▍      | 10/29 [00:00<00:00, 184.87it/s, train_loss=0.00343, val_loss=0.00315]Epoch 38:  38%|███▊      | 11/29 [00:00<00:00, 190.25it/s, train_loss=0.00343, val_loss=0.00315]Epoch 38:  38%|███▊      | 11/29 [00:00<00:00, 183.87it/s, train_loss=0.00161, val_loss=0.00315]Epoch 38:  41%|████▏     | 12/29 [00:00<00:00, 190.26it/s, train_loss=0.00161, val_loss=0.00315]Epoch 38:  41%|████▏     | 12/29 [00:00<00:00, 188.58it/s, train_loss=0.0027, val_loss=0.00315] Epoch 38:  45%|████▍     | 13/29 [00:00<00:00, 194.24it/s, train_loss=0.0027, val_loss=0.00315]Epoch 38:  45%|████▍     | 13/29 [00:00<00:00, 188.08it/s, train_loss=0.00248, val_loss=0.00315]Epoch 38:  48%|████▊     | 14/29 [00:00<00:00, 193.14it/s, train_loss=0.00248, val_loss=0.00315]Epoch 38:  48%|████▊     | 14/29 [00:00<00:00, 191.35it/s, train_loss=0.0032, val_loss=0.00315] Epoch 38:  52%|█████▏    | 15/29 [00:00<00:00, 195.87it/s, train_loss=0.0032, val_loss=0.00315]Epoch 38:  52%|█████▏    | 15/29 [00:00<00:00, 191.43it/s, train_loss=0.00242, val_loss=0.00315]Epoch 38:  55%|█████▌    | 16/29 [00:00<00:00, 195.08it/s, train_loss=0.00242, val_loss=0.00315]Epoch 38:  55%|█████▌    | 16/29 [00:00<00:00, 191.07it/s, train_loss=0.00312, val_loss=0.00315]Epoch 38:  59%|█████▊    | 17/29 [00:00<00:00, 194.84it/s, train_loss=0.00312, val_loss=0.00315]Epoch 38:  59%|█████▊    | 17/29 [00:00<00:00, 193.27it/s, train_loss=0.00186, val_loss=0.00315]Epoch 38:  62%|██████▏   | 18/29 [00:00<00:00, 197.08it/s, train_loss=0.00186, val_loss=0.00315]Epoch 38:  62%|██████▏   | 18/29 [00:00<00:00, 193.51it/s, train_loss=0.0026, val_loss=0.00315] Epoch 38:  66%|██████▌   | 19/29 [00:00<00:00, 196.87it/s, train_loss=0.0026, val_loss=0.00315]Epoch 38:  66%|██████▌   | 19/29 [00:00<00:00, 192.27it/s, train_loss=0.00359, val_loss=0.00315]Epoch 38:  69%|██████▉   | 20/29 [00:00<00:00, 195.47it/s, train_loss=0.00359, val_loss=0.00315]Epoch 38:  69%|██████▉   | 20/29 [00:00<00:00, 191.14it/s, train_loss=0.00192, val_loss=0.00315]Epoch 38:  72%|███████▏  | 21/29 [00:00<00:00, 194.17it/s, train_loss=0.00192, val_loss=0.00315]Epoch 38:  72%|███████▏  | 21/29 [00:00<00:00, 190.27it/s, train_loss=0.00357, val_loss=0.00315]Epoch 38:  76%|███████▌  | 22/29 [00:00<00:00, 193.15it/s, train_loss=0.00357, val_loss=0.00315]Epoch 38:  76%|███████▌  | 22/29 [00:00<00:00, 191.80it/s, train_loss=0.00264, val_loss=0.00315]Epoch 38:  79%|███████▉  | 23/29 [00:00<00:00, 194.07it/s, train_loss=0.00264, val_loss=0.00315]Epoch 38:  79%|███████▉  | 23/29 [00:00<00:00, 192.67it/s, train_loss=0.00285, val_loss=0.00315]Epoch 38:  83%|████████▎ | 24/29 [00:00<00:00, 195.10it/s, train_loss=0.00285, val_loss=0.00315]Epoch 38:  83%|████████▎ | 24/29 [00:00<00:00, 193.26it/s, train_loss=0.00246, val_loss=0.00315]Epoch 38:  86%|████████▌ | 25/29 [00:00<00:00, 195.76it/s, train_loss=0.00246, val_loss=0.00315]Epoch 38:  86%|████████▌ | 25/29 [00:00<00:00, 192.37it/s, train_loss=0.00214, val_loss=0.00315]Epoch 38:  90%|████████▉ | 26/29 [00:00<00:00, 194.62it/s, train_loss=0.00214, val_loss=0.00315]Epoch 38:  90%|████████▉ | 26/29 [00:00<00:00, 191.53it/s, train_loss=0.00315, val_loss=0.00315]Epoch 38:  93%|█████████▎| 27/29 [00:00<00:00, 193.65it/s, train_loss=0.00315, val_loss=0.00315]Epoch 38:  93%|█████████▎| 27/29 [00:00<00:00, 190.82it/s, train_loss=0.00354, val_loss=0.00315]Epoch 38:  97%|█████████▋| 28/29 [00:00<00:00, 192.85it/s, train_loss=0.00354, val_loss=0.00315]Epoch 38:  97%|█████████▋| 28/29 [00:00<00:00, 190.18it/s, train_loss=0.00264, val_loss=0.00315]Epoch 38: 100%|██████████| 29/29 [00:00<00:00, 192.07it/s, train_loss=0.00264, val_loss=0.00315]Epoch 38: 100%|██████████| 29/29 [00:00<00:00, 189.99it/s, train_loss=0.00284, val_loss=0.00315]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 302.51it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 333.56it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 342.25it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 344.56it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 343.87it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 344.31it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 345.08it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 343.47it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 342.55it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 341.09it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 340.29it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 339.19it/s][A
                                                                         [AEpoch 38: 100%|██████████| 29/29 [00:00<00:00, 148.55it/s, train_loss=0.00284, val_loss=0.00315]Epoch 38: 100%|██████████| 29/29 [00:00<00:00, 147.89it/s, train_loss=0.00284, val_loss=0.00315]Epoch 38:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00284, val_loss=0.00315]          Epoch 39:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00284, val_loss=0.00315]Epoch 39:   3%|▎         | 1/29 [00:00<00:00, 185.71it/s, train_loss=0.00284, val_loss=0.00315]Epoch 39:   3%|▎         | 1/29 [00:00<00:00, 140.69it/s, train_loss=0.00201, val_loss=0.00315]Epoch 39:   7%|▋         | 2/29 [00:00<00:00, 183.67it/s, train_loss=0.00201, val_loss=0.00315]Epoch 39:   7%|▋         | 2/29 [00:00<00:00, 154.17it/s, train_loss=0.00245, val_loss=0.00315]Epoch 39:  10%|█         | 3/29 [00:00<00:00, 182.40it/s, train_loss=0.00245, val_loss=0.00315]Epoch 39:  10%|█         | 3/29 [00:00<00:00, 159.85it/s, train_loss=0.00255, val_loss=0.00315]Epoch 39:  14%|█▍        | 4/29 [00:00<00:00, 179.00it/s, train_loss=0.00255, val_loss=0.00315]Epoch 39:  14%|█▍        | 4/29 [00:00<00:00, 162.66it/s, train_loss=0.00275, val_loss=0.00315]Epoch 39:  17%|█▋        | 5/29 [00:00<00:00, 176.75it/s, train_loss=0.00275, val_loss=0.00315]Epoch 39:  17%|█▋        | 5/29 [00:00<00:00, 164.66it/s, train_loss=0.00207, val_loss=0.00315]Epoch 39:  21%|██        | 6/29 [00:00<00:00, 176.24it/s, train_loss=0.00207, val_loss=0.00315]Epoch 39:  21%|██        | 6/29 [00:00<00:00, 166.05it/s, train_loss=0.00256, val_loss=0.00315]Epoch 39:  24%|██▍       | 7/29 [00:00<00:00, 174.54it/s, train_loss=0.00256, val_loss=0.00315]Epoch 39:  24%|██▍       | 7/29 [00:00<00:00, 168.38it/s, train_loss=0.0027, val_loss=0.00315] Epoch 39:  28%|██▊       | 8/29 [00:00<00:00, 176.91it/s, train_loss=0.0027, val_loss=0.00315]Epoch 39:  28%|██▊       | 8/29 [00:00<00:00, 168.85it/s, train_loss=0.00232, val_loss=0.00315]Epoch 39:  31%|███       | 9/29 [00:00<00:00, 176.09it/s, train_loss=0.00232, val_loss=0.00315]Epoch 39:  31%|███       | 9/29 [00:00<00:00, 169.37it/s, train_loss=0.00204, val_loss=0.00315]Epoch 39:  34%|███▍      | 10/29 [00:00<00:00, 176.33it/s, train_loss=0.00204, val_loss=0.00315]Epoch 39:  34%|███▍      | 10/29 [00:00<00:00, 169.71it/s, train_loss=0.00301, val_loss=0.00315]Epoch 39:  38%|███▊      | 11/29 [00:00<00:00, 176.08it/s, train_loss=0.00301, val_loss=0.00315]Epoch 39:  38%|███▊      | 11/29 [00:00<00:00, 170.07it/s, train_loss=0.00249, val_loss=0.00315]Epoch 39:  41%|████▏     | 12/29 [00:00<00:00, 175.47it/s, train_loss=0.00249, val_loss=0.00315]Epoch 39:  41%|████▏     | 12/29 [00:00<00:00, 170.34it/s, train_loss=0.00377, val_loss=0.00315]Epoch 39:  45%|████▍     | 13/29 [00:00<00:00, 176.05it/s, train_loss=0.00377, val_loss=0.00315]Epoch 39:  45%|████▍     | 13/29 [00:00<00:00, 172.15it/s, train_loss=0.00286, val_loss=0.00315]Epoch 39:  48%|████▊     | 14/29 [00:00<00:00, 177.44it/s, train_loss=0.00286, val_loss=0.00315]Epoch 39:  48%|████▊     | 14/29 [00:00<00:00, 176.25it/s, train_loss=0.00288, val_loss=0.00315]Epoch 39:  52%|█████▏    | 15/29 [00:00<00:00, 181.17it/s, train_loss=0.00288, val_loss=0.00315]Epoch 39:  52%|█████▏    | 15/29 [00:00<00:00, 176.78it/s, train_loss=0.00343, val_loss=0.00315]Epoch 39:  55%|█████▌    | 16/29 [00:00<00:00, 181.38it/s, train_loss=0.00343, val_loss=0.00315]Epoch 39:  55%|█████▌    | 16/29 [00:00<00:00, 180.05it/s, train_loss=0.0021, val_loss=0.00315] Epoch 39:  59%|█████▊    | 17/29 [00:00<00:00, 184.47it/s, train_loss=0.0021, val_loss=0.00315]Epoch 39:  59%|█████▊    | 17/29 [00:00<00:00, 180.54it/s, train_loss=0.00218, val_loss=0.00315]Epoch 39:  62%|██████▏   | 18/29 [00:00<00:00, 184.10it/s, train_loss=0.00218, val_loss=0.00315]Epoch 39:  62%|██████▏   | 18/29 [00:00<00:00, 180.16it/s, train_loss=0.00287, val_loss=0.00315]Epoch 39:  66%|██████▌   | 19/29 [00:00<00:00, 183.75it/s, train_loss=0.00287, val_loss=0.00315]Epoch 39:  66%|██████▌   | 19/29 [00:00<00:00, 179.86it/s, train_loss=0.00241, val_loss=0.00315]Epoch 39:  69%|██████▉   | 20/29 [00:00<00:00, 182.69it/s, train_loss=0.00241, val_loss=0.00315]Epoch 39:  69%|██████▉   | 20/29 [00:00<00:00, 180.10it/s, train_loss=0.00253, val_loss=0.00315]Epoch 39:  72%|███████▏  | 21/29 [00:00<00:00, 183.01it/s, train_loss=0.00253, val_loss=0.00315]Epoch 39:  72%|███████▏  | 21/29 [00:00<00:00, 179.68it/s, train_loss=0.00253, val_loss=0.00315]Epoch 39:  76%|███████▌  | 22/29 [00:00<00:00, 182.78it/s, train_loss=0.00253, val_loss=0.00315]Epoch 39:  76%|███████▌  | 22/29 [00:00<00:00, 179.40it/s, train_loss=0.00249, val_loss=0.00315]Epoch 39:  79%|███████▉  | 23/29 [00:00<00:00, 182.32it/s, train_loss=0.00249, val_loss=0.00315]Epoch 39:  79%|███████▉  | 23/29 [00:00<00:00, 179.10it/s, train_loss=0.00164, val_loss=0.00315]Epoch 39:  83%|████████▎ | 24/29 [00:00<00:00, 182.04it/s, train_loss=0.00164, val_loss=0.00315]Epoch 39:  83%|████████▎ | 24/29 [00:00<00:00, 178.92it/s, train_loss=0.00395, val_loss=0.00315]Epoch 39:  86%|████████▌ | 25/29 [00:00<00:00, 181.67it/s, train_loss=0.00395, val_loss=0.00315]Epoch 39:  86%|████████▌ | 25/29 [00:00<00:00, 178.73it/s, train_loss=0.00226, val_loss=0.00315]Epoch 39:  90%|████████▉ | 26/29 [00:00<00:00, 180.96it/s, train_loss=0.00226, val_loss=0.00315]Epoch 39:  90%|████████▉ | 26/29 [00:00<00:00, 179.11it/s, train_loss=0.00226, val_loss=0.00315]Epoch 39:  93%|█████████▎| 27/29 [00:00<00:00, 181.28it/s, train_loss=0.00226, val_loss=0.00315]Epoch 39:  93%|█████████▎| 27/29 [00:00<00:00, 178.84it/s, train_loss=0.00275, val_loss=0.00315]Epoch 39:  97%|█████████▋| 28/29 [00:00<00:00, 181.17it/s, train_loss=0.00275, val_loss=0.00315]Epoch 39:  97%|█████████▋| 28/29 [00:00<00:00, 178.63it/s, train_loss=0.00389, val_loss=0.00315]Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 180.89it/s, train_loss=0.00389, val_loss=0.00315]Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 178.43it/s, train_loss=0.00229, val_loss=0.00315]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 286.22it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 332.35it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 348.75it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 357.60it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 365.61it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 369.66it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 368.42it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 368.93it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 365.80it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 362.99it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 359.07it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 356.72it/s][A
                                                                         [AEpoch 39: 100%|██████████| 29/29 [00:00<00:00, 141.96it/s, train_loss=0.00229, val_loss=0.00315]Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 141.44it/s, train_loss=0.00229, val_loss=0.00315]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 134.84it/s, train_loss=0.00229, val_loss=0.00315]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/28 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/28 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▎         | 1/28 [00:00<00:00, 457.74it/s]Predicting DataLoader 0:   7%|▋         | 2/28 [00:00<00:00, 338.77it/s]Predicting DataLoader 0:  11%|█         | 3/28 [00:00<00:00, 282.99it/s]Predicting DataLoader 0:  14%|█▍        | 4/28 [00:00<00:00, 254.12it/s]Predicting DataLoader 0:  18%|█▊        | 5/28 [00:00<00:00, 246.53it/s]Predicting DataLoader 0:  21%|██▏       | 6/28 [00:00<00:00, 238.71it/s]Predicting DataLoader 0:  25%|██▌       | 7/28 [00:00<00:00, 233.82it/s]Predicting DataLoader 0:  29%|██▊       | 8/28 [00:00<00:00, 238.29it/s]Predicting DataLoader 0:  32%|███▏      | 9/28 [00:00<00:00, 241.82it/s]Predicting DataLoader 0:  36%|███▌      | 10/28 [00:00<00:00, 239.35it/s]Predicting DataLoader 0:  39%|███▉      | 11/28 [00:00<00:00, 236.49it/s]Predicting DataLoader 0:  43%|████▎     | 12/28 [00:00<00:00, 233.37it/s]Predicting DataLoader 0:  46%|████▋     | 13/28 [00:00<00:00, 230.97it/s]Predicting DataLoader 0:  50%|█████     | 14/28 [00:00<00:00, 228.73it/s]Predicting DataLoader 0:  54%|█████▎    | 15/28 [00:00<00:00, 227.45it/s]Predicting DataLoader 0:  57%|█████▋    | 16/28 [00:00<00:00, 225.93it/s]Predicting DataLoader 0:  61%|██████    | 17/28 [00:00<00:00, 224.85it/s]Predicting DataLoader 0:  64%|██████▍   | 18/28 [00:00<00:00, 223.73it/s]Predicting DataLoader 0:  68%|██████▊   | 19/28 [00:00<00:00, 222.74it/s]Predicting DataLoader 0:  71%|███████▏  | 20/28 [00:00<00:00, 221.75it/s]Predicting DataLoader 0:  75%|███████▌  | 21/28 [00:00<00:00, 220.44it/s]Predicting DataLoader 0:  79%|███████▊  | 22/28 [00:00<00:00, 219.68it/s]Predicting DataLoader 0:  82%|████████▏ | 23/28 [00:00<00:00, 219.25it/s]Predicting DataLoader 0:  86%|████████▌ | 24/28 [00:00<00:00, 218.42it/s]Predicting DataLoader 0:  89%|████████▉ | 25/28 [00:00<00:00, 217.98it/s]Predicting DataLoader 0:  93%|█████████▎| 26/28 [00:00<00:00, 217.44it/s]Predicting DataLoader 0:  96%|█████████▋| 27/28 [00:00<00:00, 219.85it/s]Predicting DataLoader 0: 100%|██████████| 28/28 [00:00<00:00, 221.18it/s]Predicting DataLoader 0: 100%|██████████| 28/28 [00:00<00:00, 219.11it/s][I 2025-08-18 01:34:34,073] A new study created in memory with name: no-name-c3010aa3-6cc2-485f-944f-15d3ae2434cf
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 7, Horizon length: 7
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.11it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.01it/s][I 2025-08-18 01:34:47,446] Trial 0 finished with value: 26.32654515587876 and parameters: {'hidden_dim': 80, 'n_rnn_layers': 3, 'dropout': 0.13943840330006418}. Best is trial 0 with value: 26.32654515587876.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 283.74it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 232.10it/s][I 2025-08-18 01:34:58,003] Trial 1 finished with value: 26.446635120458666 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 3, 'dropout': 0.17887894504003699}. Best is trial 0 with value: 26.32654515587876.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.69it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.00it/s][I 2025-08-18 01:35:09,629] Trial 2 finished with value: 26.484078191727548 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 4, 'dropout': 0.38796903690626827}. Best is trial 0 with value: 26.32654515587876.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.19it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.96it/s][I 2025-08-18 01:35:19,870] Trial 3 finished with value: 22.39503183502095 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 3, 'dropout': 0.1800924259111133}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 316.46it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.74it/s][I 2025-08-18 01:35:34,871] Trial 4 finished with value: 26.282572332155734 and parameters: {'hidden_dim': 83, 'n_rnn_layers': 2, 'dropout': 0.2766414647106391}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 305.60it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.66it/s][I 2025-08-18 01:35:43,862] Trial 5 finished with value: 24.209900474235134 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 2, 'dropout': 0.0011539888014602262}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.21it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.75it/s][I 2025-08-18 01:35:56,892] Trial 6 finished with value: 28.114346083479244 and parameters: {'hidden_dim': 81, 'n_rnn_layers': 4, 'dropout': 0.11778835472086574}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 258.70it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.06it/s][I 2025-08-18 01:36:13,766] Trial 7 finished with value: 27.040008380934783 and parameters: {'hidden_dim': 93, 'n_rnn_layers': 3, 'dropout': 0.014704027025942368}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 287.38it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.98it/s][I 2025-08-18 01:36:27,559] Trial 8 finished with value: 28.107348586849334 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 3, 'dropout': 0.04283511774647447}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.98it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.22it/s][I 2025-08-18 01:36:36,762] Trial 9 finished with value: 24.119748945519436 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 2, 'dropout': 0.4473440831379142}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.285782709704746 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.79it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.71it/s][I 2025-08-18 01:36:42,594] Trial 10 finished with value: 22.746557078979354 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 1, 'dropout': 0.285782709704746}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28899905138944626 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 353.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.86it/s][I 2025-08-18 01:36:48,132] Trial 11 finished with value: 22.676699228443756 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.28899905138944626}. Best is trial 3 with value: 22.39503183502095.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.34960851411285304 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.58it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 244.04it/s][I 2025-08-18 01:36:53,857] Trial 12 finished with value: 22.302533418326817 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.34960851411285304}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37991690097771474 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.32it/s][I 2025-08-18 01:36:59,703] Trial 13 finished with value: 24.1735735937267 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 1, 'dropout': 0.37991690097771474}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.34it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.14it/s][I 2025-08-18 01:37:10,250] Trial 14 finished with value: 26.532304694777704 and parameters: {'hidden_dim': 51, 'n_rnn_layers': 2, 'dropout': 0.21109681062663216}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 284.77it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.50it/s][I 2025-08-18 01:37:33,140] Trial 15 finished with value: 26.982150845020435 and parameters: {'hidden_dim': 124, 'n_rnn_layers': 4, 'dropout': 0.35970964663062455}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.46224349912553353 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.91it/s][I 2025-08-18 01:37:39,007] Trial 16 finished with value: 22.836392562613835 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 1, 'dropout': 0.46224349912553353}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.29it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.51it/s][I 2025-08-18 01:37:48,208] Trial 17 finished with value: 25.578508989272535 and parameters: {'hidden_dim': 51, 'n_rnn_layers': 2, 'dropout': 0.3305203386173678}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.26it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.10it/s][I 2025-08-18 01:37:57,414] Trial 18 finished with value: 23.930593407824357 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 3, 'dropout': 0.2164955128744974}. Best is trial 12 with value: 22.302533418326817.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.85it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.61it/s][I 2025-08-18 01:38:08,320] Trial 19 finished with value: 26.23544720120805 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 4, 'dropout': 0.08461522662845222}. Best is trial 12 with value: 22.302533418326817.
[I 2025-08-18 01:38:08,321] A new study created in memory with name: no-name-255beef5-158d-40ee-94d2-065b8544a650
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.34960851411285304}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 256.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.32it/s][I 2025-08-18 01:38:17,908] Trial 0 finished with value: 23.080439941737307 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.25678807606839565}. Best is trial 0 with value: 23.080439941737307.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0054260380545843034 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 289.34it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.77it/s][I 2025-08-18 01:38:26,993] Trial 1 finished with value: 22.695542244454398 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 1, 'dropout': 0.0054260380545843034}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.68it/s][I 2025-08-18 01:38:43,749] Trial 2 finished with value: 28.280866104025616 and parameters: {'hidden_dim': 90, 'n_rnn_layers': 3, 'dropout': 0.2394071700165611}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23170787924127723 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.27it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.42it/s][I 2025-08-18 01:38:49,846] Trial 3 finished with value: 23.049465899259722 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 1, 'dropout': 0.23170787924127723}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 295.79it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.83it/s][I 2025-08-18 01:38:58,862] Trial 4 finished with value: 24.73985827787065 and parameters: {'hidden_dim': 54, 'n_rnn_layers': 2, 'dropout': 0.20483758047140838}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.81it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.97it/s][I 2025-08-18 01:39:10,183] Trial 5 finished with value: 27.371417246787782 and parameters: {'hidden_dim': 81, 'n_rnn_layers': 2, 'dropout': 0.07778820464397079}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29242342229645735 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 350.26it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.71it/s][I 2025-08-18 01:39:19,868] Trial 6 finished with value: 24.047654673796046 and parameters: {'hidden_dim': 90, 'n_rnn_layers': 1, 'dropout': 0.29242342229645735}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.55it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.43it/s][I 2025-08-18 01:39:29,752] Trial 7 finished with value: 26.216842180210058 and parameters: {'hidden_dim': 58, 'n_rnn_layers': 2, 'dropout': 0.09797151391173003}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 245.71it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.70it/s][I 2025-08-18 01:39:38,157] Trial 8 finished with value: 28.096095551158864 and parameters: {'hidden_dim': 32, 'n_rnn_layers': 4, 'dropout': 0.1430565164403818}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.77it/s][I 2025-08-18 01:39:48,946] Trial 9 finished with value: 25.740791200463015 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 4, 'dropout': 0.4338437261836613}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01923058767307638 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 340.50it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.71it/s][I 2025-08-18 01:39:57,963] Trial 10 finished with value: 24.37232981516914 and parameters: {'hidden_dim': 38, 'n_rnn_layers': 1, 'dropout': 0.01923058767307638}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3972409592316206 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 296.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.67it/s][I 2025-08-18 01:40:03,885] Trial 11 finished with value: 22.836392562613835 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 1, 'dropout': 0.3972409592316206}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4024827546805959 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.04it/s][I 2025-08-18 01:40:09,843] Trial 12 finished with value: 23.898996276384487 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 1, 'dropout': 0.4024827546805959}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 322.51it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 270.60it/s][I 2025-08-18 01:40:20,518] Trial 13 finished with value: 26.455645198840838 and parameters: {'hidden_dim': 44, 'n_rnn_layers': 3, 'dropout': 0.49597202100379006}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.70it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s][I 2025-08-18 01:40:28,993] Trial 14 finished with value: 24.61043918520847 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 2, 'dropout': 0.3401656544005037}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.374777179883089 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.60it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.47it/s] [I 2025-08-18 01:40:35,913] Trial 15 finished with value: 27.4167992847946 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 1, 'dropout': 0.374777179883089}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.016046647116566115 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 382.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.71it/s][I 2025-08-18 01:40:46,675] Trial 16 finished with value: 22.795442064604632 and parameters: {'hidden_dim': 57, 'n_rnn_layers': 1, 'dropout': 0.016046647116566115}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 305.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 244.92it/s][I 2025-08-18 01:41:00,953] Trial 17 finished with value: 26.07852794153433 and parameters: {'hidden_dim': 127, 'n_rnn_layers': 3, 'dropout': 0.0015519406120803048}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 300.56it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.51it/s][I 2025-08-18 01:41:08,952] Trial 18 finished with value: 25.864587243963694 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 2, 'dropout': 0.06911287826906878}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1463287822850689 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 290.26it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.62it/s][I 2025-08-18 01:41:18,254] Trial 19 finished with value: 23.786666463632944 and parameters: {'hidden_dim': 42, 'n_rnn_layers': 1, 'dropout': 0.1463287822850689}. Best is trial 1 with value: 22.695542244454398.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0054260380545843034 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 6.6 K  | train
6 | V               | Linear           | 40     | train
-------------------------------------------------------------
6.6 K     Trainable params
0         Non-trainable params
6.6 K     Total params
0.026     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 39, 'n_rnn_layers': 1, 'dropout': 0.0054260380545843034}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 372.99it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 402.33it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/29 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] Epoch 0:   3%|▎         | 1/29 [00:00<00:00, 125.50it/s]Epoch 0:   3%|▎         | 1/29 [00:00<00:00, 77.96it/s, train_loss=0.146]Epoch 0:   7%|▋         | 2/29 [00:00<00:00, 114.62it/s, train_loss=0.146]Epoch 0:   7%|▋         | 2/29 [00:00<00:00, 101.32it/s, train_loss=0.115]Epoch 0:  10%|█         | 3/29 [00:00<00:00, 126.04it/s, train_loss=0.115]Epoch 0:  10%|█         | 3/29 [00:00<00:00, 111.46it/s, train_loss=0.149]Epoch 0:  14%|█▍        | 4/29 [00:00<00:00, 130.21it/s, train_loss=0.149]Epoch 0:  14%|█▍        | 4/29 [00:00<00:00, 117.65it/s, train_loss=0.161]Epoch 0:  17%|█▋        | 5/29 [00:00<00:00, 132.78it/s, train_loss=0.161]Epoch 0:  17%|█▋        | 5/29 [00:00<00:00, 121.66it/s, train_loss=0.133]Epoch 0:  21%|██        | 6/29 [00:00<00:00, 134.39it/s, train_loss=0.133]Epoch 0:  21%|██        | 6/29 [00:00<00:00, 124.53it/s, train_loss=0.0892]Epoch 0:  24%|██▍       | 7/29 [00:00<00:00, 135.14it/s, train_loss=0.0892]Epoch 0:  24%|██▍       | 7/29 [00:00<00:00, 126.81it/s, train_loss=0.152] Epoch 0:  28%|██▊       | 8/29 [00:00<00:00, 134.32it/s, train_loss=0.152]Epoch 0:  28%|██▊       | 8/29 [00:00<00:00, 124.47it/s, train_loss=0.140]Epoch 0:  31%|███       | 9/29 [00:00<00:00, 132.04it/s, train_loss=0.140]Epoch 0:  31%|███       | 9/29 [00:00<00:00, 126.31it/s, train_loss=0.108]Epoch 0:  34%|███▍      | 10/29 [00:00<00:00, 132.65it/s, train_loss=0.108]Epoch 0:  34%|███▍      | 10/29 [00:00<00:00, 127.71it/s, train_loss=0.120]Epoch 0:  38%|███▊      | 11/29 [00:00<00:00, 134.08it/s, train_loss=0.120]Epoch 0:  38%|███▊      | 11/29 [00:00<00:00, 128.92it/s, train_loss=0.148]Epoch 0:  41%|████▏     | 12/29 [00:00<00:00, 134.66it/s, train_loss=0.148]Epoch 0:  41%|████▏     | 12/29 [00:00<00:00, 129.98it/s, train_loss=0.141]Epoch 0:  45%|████▍     | 13/29 [00:00<00:00, 135.03it/s, train_loss=0.141]Epoch 0:  45%|████▍     | 13/29 [00:00<00:00, 133.36it/s, train_loss=0.143]Epoch 0:  48%|████▊     | 14/29 [00:00<00:00, 137.54it/s, train_loss=0.143]Epoch 0:  48%|████▊     | 14/29 [00:00<00:00, 133.92it/s, train_loss=0.109]Epoch 0:  52%|█████▏    | 15/29 [00:00<00:00, 138.94it/s, train_loss=0.109]Epoch 0:  52%|█████▏    | 15/29 [00:00<00:00, 134.47it/s, train_loss=0.146]Epoch 0:  55%|█████▌    | 16/29 [00:00<00:00, 139.13it/s, train_loss=0.146]Epoch 0:  55%|█████▌    | 16/29 [00:00<00:00, 134.87it/s, train_loss=0.172]Epoch 0:  59%|█████▊    | 17/29 [00:00<00:00, 139.21it/s, train_loss=0.172]Epoch 0:  59%|█████▊    | 17/29 [00:00<00:00, 135.30it/s, train_loss=0.151]Epoch 0:  62%|██████▏   | 18/29 [00:00<00:00, 139.47it/s, train_loss=0.151]Epoch 0:  62%|██████▏   | 18/29 [00:00<00:00, 135.70it/s, train_loss=0.140]Epoch 0:  66%|██████▌   | 19/29 [00:00<00:00, 139.58it/s, train_loss=0.140]Epoch 0:  66%|██████▌   | 19/29 [00:00<00:00, 137.55it/s, train_loss=0.124]Epoch 0:  69%|██████▉   | 20/29 [00:00<00:00, 140.78it/s, train_loss=0.124]Epoch 0:  69%|██████▉   | 20/29 [00:00<00:00, 137.03it/s, train_loss=0.144]Epoch 0:  72%|███████▏  | 21/29 [00:00<00:00, 140.28it/s, train_loss=0.144]Epoch 0:  72%|███████▏  | 21/29 [00:00<00:00, 137.27it/s, train_loss=0.0906]Epoch 0:  76%|███████▌  | 22/29 [00:00<00:00, 140.51it/s, train_loss=0.0906]Epoch 0:  76%|███████▌  | 22/29 [00:00<00:00, 137.49it/s, train_loss=0.113] Epoch 0:  79%|███████▉  | 23/29 [00:00<00:00, 140.56it/s, train_loss=0.113]Epoch 0:  79%|███████▉  | 23/29 [00:00<00:00, 137.69it/s, train_loss=0.116]Epoch 0:  83%|████████▎ | 24/29 [00:00<00:00, 140.60it/s, train_loss=0.116]Epoch 0:  83%|████████▎ | 24/29 [00:00<00:00, 137.91it/s, train_loss=0.123]Epoch 0:  86%|████████▌ | 25/29 [00:00<00:00, 140.76it/s, train_loss=0.123]Epoch 0:  86%|████████▌ | 25/29 [00:00<00:00, 139.45it/s, train_loss=0.120]Epoch 0:  90%|████████▉ | 26/29 [00:00<00:00, 141.74it/s, train_loss=0.120]Epoch 0:  90%|████████▉ | 26/29 [00:00<00:00, 139.00it/s, train_loss=0.133]Epoch 0:  93%|█████████▎| 27/29 [00:00<00:00, 140.92it/s, train_loss=0.133]Epoch 0:  93%|█████████▎| 27/29 [00:00<00:00, 139.17it/s, train_loss=0.110]Epoch 0:  97%|█████████▋| 28/29 [00:00<00:00, 141.22it/s, train_loss=0.110]Epoch 0:  97%|█████████▋| 28/29 [00:00<00:00, 139.34it/s, train_loss=0.0915]Epoch 0: 100%|██████████| 29/29 [00:00<00:00, 141.52it/s, train_loss=0.0915]Epoch 0: 100%|██████████| 29/29 [00:00<00:00, 139.71it/s, train_loss=0.110] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 173.43it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 206.07it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 220.32it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 226.22it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 230.24it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 232.87it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 234.22it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 235.29it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 238.54it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 238.71it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 239.15it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 239.42it/s][A
                                                                         [AEpoch 0: 100%|██████████| 29/29 [00:00<00:00, 109.56it/s, train_loss=0.110, val_loss=0.128]Epoch 0: 100%|██████████| 29/29 [00:00<00:00, 109.25it/s, train_loss=0.110, val_loss=0.128]Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.110, val_loss=0.128]          Epoch 1:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.110, val_loss=0.128]Epoch 1:   3%|▎         | 1/29 [00:00<00:00, 197.15it/s, train_loss=0.110, val_loss=0.128]Epoch 1:   3%|▎         | 1/29 [00:00<00:00, 172.43it/s, train_loss=0.126, val_loss=0.128]Epoch 1:   7%|▋         | 2/29 [00:00<00:00, 202.99it/s, train_loss=0.126, val_loss=0.128]Epoch 1:   7%|▋         | 2/29 [00:00<00:00, 155.71it/s, train_loss=0.124, val_loss=0.128]Epoch 1:  10%|█         | 3/29 [00:00<00:00, 179.17it/s, train_loss=0.124, val_loss=0.128]Epoch 1:  10%|█         | 3/29 [00:00<00:00, 151.09it/s, train_loss=0.124, val_loss=0.128]Epoch 1:  14%|█▍        | 4/29 [00:00<00:00, 167.66it/s, train_loss=0.124, val_loss=0.128]Epoch 1:  14%|█▍        | 4/29 [00:00<00:00, 148.66it/s, train_loss=0.105, val_loss=0.128]Epoch 1:  17%|█▋        | 5/29 [00:00<00:00, 161.49it/s, train_loss=0.105, val_loss=0.128]Epoch 1:  17%|█▋        | 5/29 [00:00<00:00, 147.33it/s, train_loss=0.0954, val_loss=0.128]Epoch 1:  21%|██        | 6/29 [00:00<00:00, 158.12it/s, train_loss=0.0954, val_loss=0.128]Epoch 1:  21%|██        | 6/29 [00:00<00:00, 146.70it/s, train_loss=0.0985, val_loss=0.128]Epoch 1:  24%|██▍       | 7/29 [00:00<00:00, 155.19it/s, train_loss=0.0985, val_loss=0.128]Epoch 1:  24%|██▍       | 7/29 [00:00<00:00, 152.77it/s, train_loss=0.0837, val_loss=0.128]Epoch 1:  28%|██▊       | 8/29 [00:00<00:00, 161.13it/s, train_loss=0.0837, val_loss=0.128]Epoch 1:  28%|██▊       | 8/29 [00:00<00:00, 151.29it/s, train_loss=0.0748, val_loss=0.128]Epoch 1:  31%|███       | 9/29 [00:00<00:00, 158.15it/s, train_loss=0.0748, val_loss=0.128]Epoch 1:  31%|███       | 9/29 [00:00<00:00, 150.43it/s, train_loss=0.118, val_loss=0.128] Epoch 1:  34%|███▍      | 10/29 [00:00<00:00, 157.70it/s, train_loss=0.118, val_loss=0.128]Epoch 1:  34%|███▍      | 10/29 [00:00<00:00, 149.53it/s, train_loss=0.0779, val_loss=0.128]Epoch 1:  38%|███▊      | 11/29 [00:00<00:00, 155.88it/s, train_loss=0.0779, val_loss=0.128]Epoch 1:  38%|███▊      | 11/29 [00:00<00:00, 148.90it/s, train_loss=0.117, val_loss=0.128] Epoch 1:  41%|████▏     | 12/29 [00:00<00:00, 154.62it/s, train_loss=0.117, val_loss=0.128]Epoch 1:  41%|████▏     | 12/29 [00:00<00:00, 148.44it/s, train_loss=0.0831, val_loss=0.128]Epoch 1:  45%|████▍     | 13/29 [00:00<00:00, 154.03it/s, train_loss=0.0831, val_loss=0.128]Epoch 1:  45%|████▍     | 13/29 [00:00<00:00, 150.84it/s, train_loss=0.0818, val_loss=0.128]Epoch 1:  48%|████▊     | 14/29 [00:00<00:00, 154.87it/s, train_loss=0.0818, val_loss=0.128]Epoch 1:  48%|████▊     | 14/29 [00:00<00:00, 148.88it/s, train_loss=0.102, val_loss=0.128] Epoch 1:  52%|█████▏    | 15/29 [00:00<00:00, 153.09it/s, train_loss=0.102, val_loss=0.128]Epoch 1:  52%|█████▏    | 15/29 [00:00<00:00, 148.53it/s, train_loss=0.0816, val_loss=0.128]Epoch 1:  55%|█████▌    | 16/29 [00:00<00:00, 152.78it/s, train_loss=0.0816, val_loss=0.128]Epoch 1:  55%|█████▌    | 16/29 [00:00<00:00, 148.16it/s, train_loss=0.0452, val_loss=0.128]Epoch 1:  59%|█████▊    | 17/29 [00:00<00:00, 152.20it/s, train_loss=0.0452, val_loss=0.128]Epoch 1:  59%|█████▊    | 17/29 [00:00<00:00, 147.86it/s, train_loss=0.060, val_loss=0.128] Epoch 1:  62%|██████▏   | 18/29 [00:00<00:00, 151.38it/s, train_loss=0.060, val_loss=0.128]Epoch 1:  62%|██████▏   | 18/29 [00:00<00:00, 147.65it/s, train_loss=0.0857, val_loss=0.128]Epoch 1:  66%|██████▌   | 19/29 [00:00<00:00, 150.85it/s, train_loss=0.0857, val_loss=0.128]Epoch 1:  66%|██████▌   | 19/29 [00:00<00:00, 149.82it/s, train_loss=0.064, val_loss=0.128] Epoch 1:  69%|██████▉   | 20/29 [00:00<00:00, 153.03it/s, train_loss=0.064, val_loss=0.128]Epoch 1:  69%|██████▉   | 20/29 [00:00<00:00, 149.44it/s, train_loss=0.0606, val_loss=0.128]Epoch 1:  72%|███████▏  | 21/29 [00:00<00:00, 152.87it/s, train_loss=0.0606, val_loss=0.128]Epoch 1:  72%|███████▏  | 21/29 [00:00<00:00, 149.14it/s, train_loss=0.0664, val_loss=0.128]Epoch 1:  76%|███████▌  | 22/29 [00:00<00:00, 152.55it/s, train_loss=0.0664, val_loss=0.128]Epoch 1:  76%|███████▌  | 22/29 [00:00<00:00, 148.84it/s, train_loss=0.0841, val_loss=0.128]Epoch 1:  79%|███████▉  | 23/29 [00:00<00:00, 152.07it/s, train_loss=0.0841, val_loss=0.128]Epoch 1:  79%|███████▉  | 23/29 [00:00<00:00, 148.59it/s, train_loss=0.0452, val_loss=0.128]Epoch 1:  83%|████████▎ | 24/29 [00:00<00:00, 151.56it/s, train_loss=0.0452, val_loss=0.128]Epoch 1:  83%|████████▎ | 24/29 [00:00<00:00, 148.37it/s, train_loss=0.0487, val_loss=0.128]Epoch 1:  86%|████████▌ | 25/29 [00:00<00:00, 150.74it/s, train_loss=0.0487, val_loss=0.128]Epoch 1:  86%|████████▌ | 25/29 [00:00<00:00, 150.14it/s, train_loss=0.0444, val_loss=0.128]Epoch 1:  90%|████████▉ | 26/29 [00:00<00:00, 152.44it/s, train_loss=0.0444, val_loss=0.128]Epoch 1:  90%|████████▉ | 26/29 [00:00<00:00, 149.84it/s, train_loss=0.0647, val_loss=0.128]Epoch 1:  93%|█████████▎| 27/29 [00:00<00:00, 152.46it/s, train_loss=0.0647, val_loss=0.128]Epoch 1:  93%|█████████▎| 27/29 [00:00<00:00, 149.60it/s, train_loss=0.0755, val_loss=0.128]Epoch 1:  97%|█████████▋| 28/29 [00:00<00:00, 152.12it/s, train_loss=0.0755, val_loss=0.128]Epoch 1:  97%|█████████▋| 28/29 [00:00<00:00, 149.31it/s, train_loss=0.0347, val_loss=0.128]Epoch 1: 100%|██████████| 29/29 [00:00<00:00, 151.76it/s, train_loss=0.0347, val_loss=0.128]Epoch 1: 100%|██████████| 29/29 [00:00<00:00, 151.09it/s, train_loss=0.0573, val_loss=0.128]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 161.11it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 200.68it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 220.83it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 234.01it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 242.51it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 245.55it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 247.55it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 250.87it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 253.14it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 253.48it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 254.30it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 255.58it/s][A
                                                                         [AEpoch 1: 100%|██████████| 29/29 [00:00<00:00, 116.19it/s, train_loss=0.0573, val_loss=0.0533]Epoch 1: 100%|██████████| 29/29 [00:00<00:00, 115.68it/s, train_loss=0.0573, val_loss=0.0533]Epoch 1:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0573, val_loss=0.0533]          Epoch 2:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0573, val_loss=0.0533]Epoch 2:   3%|▎         | 1/29 [00:00<00:00, 173.05it/s, train_loss=0.0573, val_loss=0.0533]Epoch 2:   3%|▎         | 1/29 [00:00<00:00, 118.74it/s, train_loss=0.0409, val_loss=0.0533]Epoch 2:   7%|▋         | 2/29 [00:00<00:00, 164.18it/s, train_loss=0.0409, val_loss=0.0533]Epoch 2:   7%|▋         | 2/29 [00:00<00:00, 129.25it/s, train_loss=0.022, val_loss=0.0533] Epoch 2:  10%|█         | 3/29 [00:00<00:00, 160.13it/s, train_loss=0.022, val_loss=0.0533]Epoch 2:  10%|█         | 3/29 [00:00<00:00, 132.46it/s, train_loss=0.0367, val_loss=0.0533]Epoch 2:  14%|█▍        | 4/29 [00:00<00:00, 153.16it/s, train_loss=0.0367, val_loss=0.0533]Epoch 2:  14%|█▍        | 4/29 [00:00<00:00, 134.06it/s, train_loss=0.0624, val_loss=0.0533]Epoch 2:  17%|█▋        | 5/29 [00:00<00:00, 149.53it/s, train_loss=0.0624, val_loss=0.0533]Epoch 2:  17%|█▋        | 5/29 [00:00<00:00, 135.41it/s, train_loss=0.037, val_loss=0.0533] Epoch 2:  21%|██        | 6/29 [00:00<00:00, 148.20it/s, train_loss=0.037, val_loss=0.0533]Epoch 2:  21%|██        | 6/29 [00:00<00:00, 141.66it/s, train_loss=0.0268, val_loss=0.0533]Epoch 2:  24%|██▍       | 7/29 [00:00<00:00, 151.19it/s, train_loss=0.0268, val_loss=0.0533]Epoch 2:  24%|██▍       | 7/29 [00:00<00:00, 139.68it/s, train_loss=0.0174, val_loss=0.0533]Epoch 2:  28%|██▊       | 8/29 [00:00<00:00, 148.10it/s, train_loss=0.0174, val_loss=0.0533]Epoch 2:  28%|██▊       | 8/29 [00:00<00:00, 140.06it/s, train_loss=0.0344, val_loss=0.0533]Epoch 2:  31%|███       | 9/29 [00:00<00:00, 148.32it/s, train_loss=0.0344, val_loss=0.0533]Epoch 2:  31%|███       | 9/29 [00:00<00:00, 140.18it/s, train_loss=0.0448, val_loss=0.0533]Epoch 2:  34%|███▍      | 10/29 [00:00<00:00, 147.52it/s, train_loss=0.0448, val_loss=0.0533]Epoch 2:  34%|███▍      | 10/29 [00:00<00:00, 140.42it/s, train_loss=0.0325, val_loss=0.0533]Epoch 2:  38%|███▊      | 11/29 [00:00<00:00, 147.03it/s, train_loss=0.0325, val_loss=0.0533]Epoch 2:  38%|███▊      | 11/29 [00:00<00:00, 140.67it/s, train_loss=0.032, val_loss=0.0533] Epoch 2:  41%|████▏     | 12/29 [00:00<00:00, 146.57it/s, train_loss=0.032, val_loss=0.0533]Epoch 2:  41%|████▏     | 12/29 [00:00<00:00, 144.16it/s, train_loss=0.0423, val_loss=0.0533]Epoch 2:  45%|████▍     | 13/29 [00:00<00:00, 148.80it/s, train_loss=0.0423, val_loss=0.0533]Epoch 2:  45%|████▍     | 13/29 [00:00<00:00, 142.73it/s, train_loss=0.0284, val_loss=0.0533]Epoch 2:  48%|████▊     | 14/29 [00:00<00:00, 147.48it/s, train_loss=0.0284, val_loss=0.0533]Epoch 2:  48%|████▊     | 14/29 [00:00<00:00, 142.76it/s, train_loss=0.0234, val_loss=0.0533]Epoch 2:  52%|█████▏    | 15/29 [00:00<00:00, 147.36it/s, train_loss=0.0234, val_loss=0.0533]Epoch 2:  52%|█████▏    | 15/29 [00:00<00:00, 142.76it/s, train_loss=0.0376, val_loss=0.0533]Epoch 2:  55%|█████▌    | 16/29 [00:00<00:00, 147.04it/s, train_loss=0.0376, val_loss=0.0533]Epoch 2:  55%|█████▌    | 16/29 [00:00<00:00, 142.76it/s, train_loss=0.0199, val_loss=0.0533]Epoch 2:  59%|█████▊    | 17/29 [00:00<00:00, 146.96it/s, train_loss=0.0199, val_loss=0.0533]Epoch 2:  59%|█████▊    | 17/29 [00:00<00:00, 142.73it/s, train_loss=0.024, val_loss=0.0533] Epoch 2:  62%|██████▏   | 18/29 [00:00<00:00, 145.63it/s, train_loss=0.024, val_loss=0.0533]Epoch 2:  62%|██████▏   | 18/29 [00:00<00:00, 142.27it/s, train_loss=0.0234, val_loss=0.0533]Epoch 2:  66%|██████▌   | 19/29 [00:00<00:00, 144.64it/s, train_loss=0.0234, val_loss=0.0533]Epoch 2:  66%|██████▌   | 19/29 [00:00<00:00, 142.25it/s, train_loss=0.0299, val_loss=0.0533]Epoch 2:  69%|██████▉   | 20/29 [00:00<00:00, 145.04it/s, train_loss=0.0299, val_loss=0.0533]Epoch 2:  69%|██████▉   | 20/29 [00:00<00:00, 142.33it/s, train_loss=0.0265, val_loss=0.0533]Epoch 2:  72%|███████▏  | 21/29 [00:00<00:00, 144.96it/s, train_loss=0.0265, val_loss=0.0533]Epoch 2:  72%|███████▏  | 21/29 [00:00<00:00, 142.34it/s, train_loss=0.0184, val_loss=0.0533]Epoch 2:  76%|███████▌  | 22/29 [00:00<00:00, 145.44it/s, train_loss=0.0184, val_loss=0.0533]Epoch 2:  76%|███████▌  | 22/29 [00:00<00:00, 142.41it/s, train_loss=0.0159, val_loss=0.0533]Epoch 2:  79%|███████▉  | 23/29 [00:00<00:00, 145.33it/s, train_loss=0.0159, val_loss=0.0533]Epoch 2:  79%|███████▉  | 23/29 [00:00<00:00, 142.45it/s, train_loss=0.0218, val_loss=0.0533]Epoch 2:  83%|████████▎ | 24/29 [00:00<00:00, 144.83it/s, train_loss=0.0218, val_loss=0.0533]Epoch 2:  83%|████████▎ | 24/29 [00:00<00:00, 142.82it/s, train_loss=0.0229, val_loss=0.0533]Epoch 2:  86%|████████▌ | 25/29 [00:00<00:00, 145.24it/s, train_loss=0.0229, val_loss=0.0533]Epoch 2:  86%|████████▌ | 25/29 [00:00<00:00, 142.82it/s, train_loss=0.0266, val_loss=0.0533]Epoch 2:  90%|████████▉ | 26/29 [00:00<00:00, 145.25it/s, train_loss=0.0266, val_loss=0.0533]Epoch 2:  90%|████████▉ | 26/29 [00:00<00:00, 142.85it/s, train_loss=0.0428, val_loss=0.0533]Epoch 2:  93%|█████████▎| 27/29 [00:00<00:00, 145.12it/s, train_loss=0.0428, val_loss=0.0533]Epoch 2:  93%|█████████▎| 27/29 [00:00<00:00, 142.85it/s, train_loss=0.0254, val_loss=0.0533]Epoch 2:  97%|█████████▋| 28/29 [00:00<00:00, 145.06it/s, train_loss=0.0254, val_loss=0.0533]Epoch 2:  97%|█████████▋| 28/29 [00:00<00:00, 142.85it/s, train_loss=0.0153, val_loss=0.0533]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 29/29 [00:00<00:00, 144.56it/s, train_loss=0.0153, val_loss=0.0533]Epoch 2: 100%|██████████| 29/29 [00:00<00:00, 143.11it/s, train_loss=0.0247, val_loss=0.0533]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 176.74it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 209.41it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 219.92it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 227.29it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 230.47it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 233.11it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 239.14it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 240.51it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 241.06it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 240.90it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 240.98it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 241.41it/s][A
                                                                         [AEpoch 2: 100%|██████████| 29/29 [00:00<00:00, 110.49it/s, train_loss=0.0247, val_loss=0.0325]Epoch 2: 100%|██████████| 29/29 [00:00<00:00, 110.04it/s, train_loss=0.0247, val_loss=0.0325]Epoch 2:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0247, val_loss=0.0325]          Epoch 3:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0247, val_loss=0.0325]Epoch 3:   3%|▎         | 1/29 [00:00<00:00, 203.68it/s, train_loss=0.0247, val_loss=0.0325]Epoch 3:   3%|▎         | 1/29 [00:00<00:00, 106.61it/s, train_loss=0.026, val_loss=0.0325] Epoch 3:   7%|▋         | 2/29 [00:00<00:00, 150.48it/s, train_loss=0.026, val_loss=0.0325]Epoch 3:   7%|▋         | 2/29 [00:00<00:00, 121.38it/s, train_loss=0.0245, val_loss=0.0325]Epoch 3:  10%|█         | 3/29 [00:00<00:00, 147.37it/s, train_loss=0.0245, val_loss=0.0325]Epoch 3:  10%|█         | 3/29 [00:00<00:00, 127.24it/s, train_loss=0.0144, val_loss=0.0325]Epoch 3:  14%|█▍        | 4/29 [00:00<00:00, 143.28it/s, train_loss=0.0144, val_loss=0.0325]Epoch 3:  14%|█▍        | 4/29 [00:00<00:00, 131.39it/s, train_loss=0.0186, val_loss=0.0325]Epoch 3:  17%|█▋        | 5/29 [00:00<00:00, 144.57it/s, train_loss=0.0186, val_loss=0.0325]Epoch 3:  17%|█▋        | 5/29 [00:00<00:00, 133.04it/s, train_loss=0.0348, val_loss=0.0325]Epoch 3:  21%|██        | 6/29 [00:00<00:00, 144.16it/s, train_loss=0.0348, val_loss=0.0325]Epoch 3:  21%|██        | 6/29 [00:00<00:00, 134.60it/s, train_loss=0.0292, val_loss=0.0325]Epoch 3:  24%|██▍       | 7/29 [00:00<00:00, 143.81it/s, train_loss=0.0292, val_loss=0.0325]Epoch 3:  24%|██▍       | 7/29 [00:00<00:00, 135.56it/s, train_loss=0.0268, val_loss=0.0325]Epoch 3:  28%|██▊       | 8/29 [00:00<00:00, 143.70it/s, train_loss=0.0268, val_loss=0.0325]Epoch 3:  28%|██▊       | 8/29 [00:00<00:00, 136.46it/s, train_loss=0.0161, val_loss=0.0325]Epoch 3:  31%|███       | 9/29 [00:00<00:00, 143.81it/s, train_loss=0.0161, val_loss=0.0325]Epoch 3:  31%|███       | 9/29 [00:00<00:00, 137.24it/s, train_loss=0.019, val_loss=0.0325] Epoch 3:  34%|███▍      | 10/29 [00:00<00:00, 143.27it/s, train_loss=0.019, val_loss=0.0325]Epoch 3:  34%|███▍      | 10/29 [00:00<00:00, 134.19it/s, train_loss=0.0148, val_loss=0.0325]Epoch 3:  38%|███▊      | 11/29 [00:00<00:00, 139.63it/s, train_loss=0.0148, val_loss=0.0325]Epoch 3:  38%|███▊      | 11/29 [00:00<00:00, 135.04it/s, train_loss=0.0295, val_loss=0.0325]Epoch 3:  41%|████▏     | 12/29 [00:00<00:00, 140.22it/s, train_loss=0.0295, val_loss=0.0325]Epoch 3:  41%|████▏     | 12/29 [00:00<00:00, 135.66it/s, train_loss=0.0241, val_loss=0.0325]Epoch 3:  45%|████▍     | 13/29 [00:00<00:00, 140.43it/s, train_loss=0.0241, val_loss=0.0325]Epoch 3:  45%|████▍     | 13/29 [00:00<00:00, 136.26it/s, train_loss=0.0156, val_loss=0.0325]Epoch 3:  48%|████▊     | 14/29 [00:00<00:00, 140.51it/s, train_loss=0.0156, val_loss=0.0325]Epoch 3:  48%|████▊     | 14/29 [00:00<00:00, 136.72it/s, train_loss=0.0391, val_loss=0.0325]Epoch 3:  52%|█████▏    | 15/29 [00:00<00:00, 140.31it/s, train_loss=0.0391, val_loss=0.0325]Epoch 3:  52%|█████▏    | 15/29 [00:00<00:00, 139.15it/s, train_loss=0.0187, val_loss=0.0325]Epoch 3:  55%|█████▌    | 16/29 [00:00<00:00, 142.68it/s, train_loss=0.0187, val_loss=0.0325]Epoch 3:  55%|█████▌    | 16/29 [00:00<00:00, 139.62it/s, train_loss=0.0176, val_loss=0.0325]Epoch 3:  59%|█████▊    | 17/29 [00:00<00:00, 143.11it/s, train_loss=0.0176, val_loss=0.0325]Epoch 3:  59%|█████▊    | 17/29 [00:00<00:00, 139.83it/s, train_loss=0.021, val_loss=0.0325] Epoch 3:  62%|██████▏   | 18/29 [00:00<00:00, 143.14it/s, train_loss=0.021, val_loss=0.0325]Epoch 3:  62%|██████▏   | 18/29 [00:00<00:00, 140.00it/s, train_loss=0.0157, val_loss=0.0325]Epoch 3:  66%|██████▌   | 19/29 [00:00<00:00, 143.17it/s, train_loss=0.0157, val_loss=0.0325]Epoch 3:  66%|██████▌   | 19/29 [00:00<00:00, 140.15it/s, train_loss=0.0131, val_loss=0.0325]Epoch 3:  69%|██████▉   | 20/29 [00:00<00:00, 143.17it/s, train_loss=0.0131, val_loss=0.0325]Epoch 3:  69%|██████▉   | 20/29 [00:00<00:00, 140.31it/s, train_loss=0.0357, val_loss=0.0325]Epoch 3:  72%|███████▏  | 21/29 [00:00<00:00, 143.25it/s, train_loss=0.0357, val_loss=0.0325]Epoch 3:  72%|███████▏  | 21/29 [00:00<00:00, 142.61it/s, train_loss=0.0317, val_loss=0.0325]Epoch 3:  76%|███████▌  | 22/29 [00:00<00:00, 145.72it/s, train_loss=0.0317, val_loss=0.0325]Epoch 3:  76%|███████▌  | 22/29 [00:00<00:00, 142.52it/s, train_loss=0.0415, val_loss=0.0325]Epoch 3:  79%|███████▉  | 23/29 [00:00<00:00, 145.43it/s, train_loss=0.0415, val_loss=0.0325]Epoch 3:  79%|███████▉  | 23/29 [00:00<00:00, 142.54it/s, train_loss=0.0316, val_loss=0.0325]Epoch 3:  83%|████████▎ | 24/29 [00:00<00:00, 145.19it/s, train_loss=0.0316, val_loss=0.0325]Epoch 3:  83%|████████▎ | 24/29 [00:00<00:00, 142.54it/s, train_loss=0.0181, val_loss=0.0325]Epoch 3:  86%|████████▌ | 25/29 [00:00<00:00, 145.04it/s, train_loss=0.0181, val_loss=0.0325]Epoch 3:  86%|████████▌ | 25/29 [00:00<00:00, 142.55it/s, train_loss=0.0147, val_loss=0.0325]Epoch 3:  90%|████████▉ | 26/29 [00:00<00:00, 144.86it/s, train_loss=0.0147, val_loss=0.0325]Epoch 3:  90%|████████▉ | 26/29 [00:00<00:00, 142.60it/s, train_loss=0.0159, val_loss=0.0325]Epoch 3:  93%|█████████▎| 27/29 [00:00<00:00, 144.64it/s, train_loss=0.0159, val_loss=0.0325]Epoch 3:  93%|█████████▎| 27/29 [00:00<00:00, 144.08it/s, train_loss=0.0165, val_loss=0.0325]Epoch 3:  97%|█████████▋| 28/29 [00:00<00:00, 146.27it/s, train_loss=0.0165, val_loss=0.0325]Epoch 3:  97%|█████████▋| 28/29 [00:00<00:00, 144.09it/s, train_loss=0.0203, val_loss=0.0325]Epoch 3: 100%|██████████| 29/29 [00:00<00:00, 146.27it/s, train_loss=0.0203, val_loss=0.0325]Epoch 3: 100%|██████████| 29/29 [00:00<00:00, 144.31it/s, train_loss=0.00872, val_loss=0.0325]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 165.57it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 182.61it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 198.88it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 211.91it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 220.50it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 223.56it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 224.63it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 226.33it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 227.56it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 228.80it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 230.20it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 232.37it/s][A
                                                                         [AEpoch 3: 100%|██████████| 29/29 [00:00<00:00, 110.63it/s, train_loss=0.00872, val_loss=0.0276]Epoch 3: 100%|██████████| 29/29 [00:00<00:00, 110.20it/s, train_loss=0.00872, val_loss=0.0276]Epoch 3:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00872, val_loss=0.0276]          Epoch 4:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00872, val_loss=0.0276]Epoch 4:   3%|▎         | 1/29 [00:00<00:00, 183.65it/s, train_loss=0.00872, val_loss=0.0276]Epoch 4:   3%|▎         | 1/29 [00:00<00:00, 131.68it/s, train_loss=0.0165, val_loss=0.0276] Epoch 4:   7%|▋         | 2/29 [00:00<00:00, 171.22it/s, train_loss=0.0165, val_loss=0.0276]Epoch 4:   7%|▋         | 2/29 [00:00<00:00, 130.33it/s, train_loss=0.0126, val_loss=0.0276]Epoch 4:  10%|█         | 3/29 [00:00<00:00, 156.33it/s, train_loss=0.0126, val_loss=0.0276]Epoch 4:  10%|█         | 3/29 [00:00<00:00, 133.34it/s, train_loss=0.0233, val_loss=0.0276]Epoch 4:  14%|█▍        | 4/29 [00:00<00:00, 150.99it/s, train_loss=0.0233, val_loss=0.0276]Epoch 4:  14%|█▍        | 4/29 [00:00<00:00, 135.00it/s, train_loss=0.0298, val_loss=0.0276]Epoch 4:  17%|█▋        | 5/29 [00:00<00:00, 149.34it/s, train_loss=0.0298, val_loss=0.0276]Epoch 4:  17%|█▋        | 5/29 [00:00<00:00, 136.54it/s, train_loss=0.0289, val_loss=0.0276]Epoch 4:  21%|██        | 6/29 [00:00<00:00, 148.43it/s, train_loss=0.0289, val_loss=0.0276]Epoch 4:  21%|██        | 6/29 [00:00<00:00, 137.65it/s, train_loss=0.0128, val_loss=0.0276]Epoch 4:  24%|██▍       | 7/29 [00:00<00:00, 147.37it/s, train_loss=0.0128, val_loss=0.0276]Epoch 4:  24%|██▍       | 7/29 [00:00<00:00, 142.54it/s, train_loss=0.0248, val_loss=0.0276]Epoch 4:  28%|██▊       | 8/29 [00:00<00:00, 151.38it/s, train_loss=0.0248, val_loss=0.0276]Epoch 4:  28%|██▊       | 8/29 [00:00<00:00, 142.41it/s, train_loss=0.0171, val_loss=0.0276]Epoch 4:  31%|███       | 9/29 [00:00<00:00, 149.65it/s, train_loss=0.0171, val_loss=0.0276]Epoch 4:  31%|███       | 9/29 [00:00<00:00, 142.46it/s, train_loss=0.0241, val_loss=0.0276]Epoch 4:  34%|███▍      | 10/29 [00:00<00:00, 148.81it/s, train_loss=0.0241, val_loss=0.0276]Epoch 4:  34%|███▍      | 10/29 [00:00<00:00, 142.44it/s, train_loss=0.0244, val_loss=0.0276]Epoch 4:  38%|███▊      | 11/29 [00:00<00:00, 148.08it/s, train_loss=0.0244, val_loss=0.0276]Epoch 4:  38%|███▊      | 11/29 [00:00<00:00, 142.45it/s, train_loss=0.0198, val_loss=0.0276]Epoch 4:  41%|████▏     | 12/29 [00:00<00:00, 147.63it/s, train_loss=0.0198, val_loss=0.0276]Epoch 4:  41%|████▏     | 12/29 [00:00<00:00, 142.60it/s, train_loss=0.0214, val_loss=0.0276]Epoch 4:  45%|████▍     | 13/29 [00:00<00:00, 147.10it/s, train_loss=0.0214, val_loss=0.0276]Epoch 4:  45%|████▍     | 13/29 [00:00<00:00, 145.46it/s, train_loss=0.0172, val_loss=0.0276]Epoch 4:  48%|████▊     | 14/29 [00:00<00:00, 150.19it/s, train_loss=0.0172, val_loss=0.0276]Epoch 4:  48%|████▊     | 14/29 [00:00<00:00, 145.25it/s, train_loss=0.0164, val_loss=0.0276]Epoch 4:  52%|█████▏    | 15/29 [00:00<00:00, 149.33it/s, train_loss=0.0164, val_loss=0.0276]Epoch 4:  52%|█████▏    | 15/29 [00:00<00:00, 145.09it/s, train_loss=0.0205, val_loss=0.0276]Epoch 4:  55%|█████▌    | 16/29 [00:00<00:00, 148.83it/s, train_loss=0.0205, val_loss=0.0276]Epoch 4:  55%|█████▌    | 16/29 [00:00<00:00, 144.97it/s, train_loss=0.0142, val_loss=0.0276]Epoch 4:  59%|█████▊    | 17/29 [00:00<00:00, 148.50it/s, train_loss=0.0142, val_loss=0.0276]Epoch 4:  59%|█████▊    | 17/29 [00:00<00:00, 144.95it/s, train_loss=0.0139, val_loss=0.0276]Epoch 4:  62%|██████▏   | 18/29 [00:00<00:00, 148.27it/s, train_loss=0.0139, val_loss=0.0276]Epoch 4:  62%|██████▏   | 18/29 [00:00<00:00, 144.93it/s, train_loss=0.0198, val_loss=0.0276]Epoch 4:  66%|██████▌   | 19/29 [00:00<00:00, 147.66it/s, train_loss=0.0198, val_loss=0.0276]Epoch 4:  66%|██████▌   | 19/29 [00:00<00:00, 144.30it/s, train_loss=0.0268, val_loss=0.0276]Epoch 4:  69%|██████▉   | 20/29 [00:00<00:00, 146.89it/s, train_loss=0.0268, val_loss=0.0276]Epoch 4:  69%|██████▉   | 20/29 [00:00<00:00, 144.24it/s, train_loss=0.0154, val_loss=0.0276]Epoch 4:  72%|███████▏  | 21/29 [00:00<00:00, 146.67it/s, train_loss=0.0154, val_loss=0.0276]Epoch 4:  72%|███████▏  | 21/29 [00:00<00:00, 144.21it/s, train_loss=0.0114, val_loss=0.0276]Epoch 4:  76%|███████▌  | 22/29 [00:00<00:00, 146.71it/s, train_loss=0.0114, val_loss=0.0276]Epoch 4:  76%|███████▌  | 22/29 [00:00<00:00, 144.17it/s, train_loss=0.0196, val_loss=0.0276]Epoch 4:  79%|███████▉  | 23/29 [00:00<00:00, 147.04it/s, train_loss=0.0196, val_loss=0.0276]Epoch 4:  79%|███████▉  | 23/29 [00:00<00:00, 144.18it/s, train_loss=0.019, val_loss=0.0276] Epoch 4:  83%|████████▎ | 24/29 [00:00<00:00, 146.84it/s, train_loss=0.019, val_loss=0.0276]Epoch 4:  83%|████████▎ | 24/29 [00:00<00:00, 144.43it/s, train_loss=0.0161, val_loss=0.0276]Epoch 4:  86%|████████▌ | 25/29 [00:00<00:00, 147.16it/s, train_loss=0.0161, val_loss=0.0276]Epoch 4:  86%|████████▌ | 25/29 [00:00<00:00, 144.33it/s, train_loss=0.0255, val_loss=0.0276]Epoch 4:  90%|████████▉ | 26/29 [00:00<00:00, 146.75it/s, train_loss=0.0255, val_loss=0.0276]Epoch 4:  90%|████████▉ | 26/29 [00:00<00:00, 144.31it/s, train_loss=0.0191, val_loss=0.0276]Epoch 4:  93%|█████████▎| 27/29 [00:00<00:00, 146.92it/s, train_loss=0.0191, val_loss=0.0276]Epoch 4:  93%|█████████▎| 27/29 [00:00<00:00, 144.24it/s, train_loss=0.0253, val_loss=0.0276]Epoch 4:  97%|█████████▋| 28/29 [00:00<00:00, 146.70it/s, train_loss=0.0253, val_loss=0.0276]Epoch 4:  97%|█████████▋| 28/29 [00:00<00:00, 144.18it/s, train_loss=0.0133, val_loss=0.0276]Epoch 4: 100%|██████████| 29/29 [00:00<00:00, 146.65it/s, train_loss=0.0133, val_loss=0.0276]Epoch 4: 100%|██████████| 29/29 [00:00<00:00, 146.06it/s, train_loss=0.0133, val_loss=0.0276]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 190.13it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 233.32it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 251.92it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 258.09it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 261.65it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 263.62it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 262.51it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 262.23it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 262.10it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 264.93it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 267.73it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 269.44it/s][A
                                                                         [AEpoch 4: 100%|██████████| 29/29 [00:00<00:00, 114.96it/s, train_loss=0.0133, val_loss=0.023] Epoch 4: 100%|██████████| 29/29 [00:00<00:00, 114.47it/s, train_loss=0.0133, val_loss=0.023]Epoch 4:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0133, val_loss=0.023]          Epoch 5:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0133, val_loss=0.023]Epoch 5:   3%|▎         | 1/29 [00:00<00:00, 191.46it/s, train_loss=0.0133, val_loss=0.023]Epoch 5:   3%|▎         | 1/29 [00:00<00:00, 118.97it/s, train_loss=0.0191, val_loss=0.023]Epoch 5:   7%|▋         | 2/29 [00:00<00:00, 162.91it/s, train_loss=0.0191, val_loss=0.023]Epoch 5:   7%|▋         | 2/29 [00:00<00:00, 128.86it/s, train_loss=0.0126, val_loss=0.023]Epoch 5:  10%|█         | 3/29 [00:00<00:00, 154.71it/s, train_loss=0.0126, val_loss=0.023]Epoch 5:  10%|█         | 3/29 [00:00<00:00, 132.42it/s, train_loss=0.0219, val_loss=0.023]Epoch 5:  14%|█▍        | 4/29 [00:00<00:00, 150.77it/s, train_loss=0.0219, val_loss=0.023]Epoch 5:  14%|█▍        | 4/29 [00:00<00:00, 134.79it/s, train_loss=0.0118, val_loss=0.023]Epoch 5:  17%|█▋        | 5/29 [00:00<00:00, 151.30it/s, train_loss=0.0118, val_loss=0.023]Epoch 5:  17%|█▋        | 5/29 [00:00<00:00, 136.15it/s, train_loss=0.0177, val_loss=0.023]Epoch 5:  21%|██        | 6/29 [00:00<00:00, 149.33it/s, train_loss=0.0177, val_loss=0.023]Epoch 5:  21%|██        | 6/29 [00:00<00:00, 142.53it/s, train_loss=0.0128, val_loss=0.023]Epoch 5:  24%|██▍       | 7/29 [00:00<00:00, 152.93it/s, train_loss=0.0128, val_loss=0.023]Epoch 5:  24%|██▍       | 7/29 [00:00<00:00, 140.32it/s, train_loss=0.0169, val_loss=0.023]Epoch 5:  28%|██▊       | 8/29 [00:00<00:00, 150.02it/s, train_loss=0.0169, val_loss=0.023]Epoch 5:  28%|██▊       | 8/29 [00:00<00:00, 140.60it/s, train_loss=0.0121, val_loss=0.023]Epoch 5:  31%|███       | 9/29 [00:00<00:00, 148.71it/s, train_loss=0.0121, val_loss=0.023]Epoch 5:  31%|███       | 9/29 [00:00<00:00, 140.71it/s, train_loss=0.0157, val_loss=0.023]Epoch 5:  34%|███▍      | 10/29 [00:00<00:00, 147.90it/s, train_loss=0.0157, val_loss=0.023]Epoch 5:  34%|███▍      | 10/29 [00:00<00:00, 140.93it/s, train_loss=0.0327, val_loss=0.023]Epoch 5:  38%|███▊      | 11/29 [00:00<00:00, 147.42it/s, train_loss=0.0327, val_loss=0.023]Epoch 5:  38%|███▊      | 11/29 [00:00<00:00, 141.20it/s, train_loss=0.0168, val_loss=0.023]Epoch 5:  41%|████▏     | 12/29 [00:00<00:00, 146.80it/s, train_loss=0.0168, val_loss=0.023]Epoch 5:  41%|████▏     | 12/29 [00:00<00:00, 145.57it/s, train_loss=0.00814, val_loss=0.023]Epoch 5:  45%|████▍     | 13/29 [00:00<00:00, 150.73it/s, train_loss=0.00814, val_loss=0.023]Epoch 5:  45%|████▍     | 13/29 [00:00<00:00, 145.30it/s, train_loss=0.0118, val_loss=0.023] Epoch 5:  48%|████▊     | 14/29 [00:00<00:00, 150.39it/s, train_loss=0.0118, val_loss=0.023]Epoch 5:  48%|████▊     | 14/29 [00:00<00:00, 145.12it/s, train_loss=0.0111, val_loss=0.023]Epoch 5:  52%|█████▏    | 15/29 [00:00<00:00, 149.53it/s, train_loss=0.0111, val_loss=0.023]Epoch 5:  52%|█████▏    | 15/29 [00:00<00:00, 144.97it/s, train_loss=0.0145, val_loss=0.023]Epoch 5:  55%|█████▌    | 16/29 [00:00<00:00, 149.10it/s, train_loss=0.0145, val_loss=0.023]Epoch 5:  55%|█████▌    | 16/29 [00:00<00:00, 144.81it/s, train_loss=0.0173, val_loss=0.023]Epoch 5:  59%|█████▊    | 17/29 [00:00<00:00, 148.78it/s, train_loss=0.0173, val_loss=0.023]Epoch 5:  59%|█████▊    | 17/29 [00:00<00:00, 144.70it/s, train_loss=0.0229, val_loss=0.023]Epoch 5:  62%|██████▏   | 18/29 [00:00<00:00, 148.54it/s, train_loss=0.0229, val_loss=0.023]Epoch 5:  62%|██████▏   | 18/29 [00:00<00:00, 146.82it/s, train_loss=0.0269, val_loss=0.023]Epoch 5:  66%|██████▌   | 19/29 [00:00<00:00, 150.18it/s, train_loss=0.0269, val_loss=0.023]Epoch 5:  66%|██████▌   | 19/29 [00:00<00:00, 145.57it/s, train_loss=0.0117, val_loss=0.023]Epoch 5:  69%|██████▉   | 20/29 [00:00<00:00, 148.85it/s, train_loss=0.0117, val_loss=0.023]Epoch 5:  69%|██████▉   | 20/29 [00:00<00:00, 145.42it/s, train_loss=0.0108, val_loss=0.023]Epoch 5:  72%|███████▏  | 21/29 [00:00<00:00, 148.56it/s, train_loss=0.0108, val_loss=0.023]Epoch 5:  72%|███████▏  | 21/29 [00:00<00:00, 145.27it/s, train_loss=0.0177, val_loss=0.023]Epoch 5:  76%|███████▌  | 22/29 [00:00<00:00, 148.23it/s, train_loss=0.0177, val_loss=0.023]Epoch 5:  76%|███████▌  | 22/29 [00:00<00:00, 145.14it/s, train_loss=0.0165, val_loss=0.023]Epoch 5:  79%|███████▉  | 23/29 [00:00<00:00, 147.95it/s, train_loss=0.0165, val_loss=0.023]Epoch 5:  79%|███████▉  | 23/29 [00:00<00:00, 145.09it/s, train_loss=0.0136, val_loss=0.023]Epoch 5:  83%|████████▎ | 24/29 [00:00<00:00, 147.43it/s, train_loss=0.0136, val_loss=0.023]Epoch 5:  83%|████████▎ | 24/29 [00:00<00:00, 146.80it/s, train_loss=0.00842, val_loss=0.023]Epoch 5:  86%|████████▌ | 25/29 [00:00<00:00, 149.60it/s, train_loss=0.00842, val_loss=0.023]Epoch 5:  86%|████████▌ | 25/29 [00:00<00:00, 146.58it/s, train_loss=0.0122, val_loss=0.023] Epoch 5:  90%|████████▉ | 26/29 [00:00<00:00, 149.45it/s, train_loss=0.0122, val_loss=0.023]Epoch 5:  90%|████████▉ | 26/29 [00:00<00:00, 146.42it/s, train_loss=0.0141, val_loss=0.023]Epoch 5:  93%|█████████▎| 27/29 [00:00<00:00, 149.07it/s, train_loss=0.0141, val_loss=0.023]Epoch 5:  93%|█████████▎| 27/29 [00:00<00:00, 146.28it/s, train_loss=0.0182, val_loss=0.023]Epoch 5:  97%|█████████▋| 28/29 [00:00<00:00, 148.74it/s, train_loss=0.0182, val_loss=0.023]Epoch 5:  97%|█████████▋| 28/29 [00:00<00:00, 146.14it/s, train_loss=0.0166, val_loss=0.023]Epoch 5: 100%|██████████| 29/29 [00:00<00:00, 148.58it/s, train_loss=0.0166, val_loss=0.023]Epoch 5: 100%|██████████| 29/29 [00:00<00:00, 148.02it/s, train_loss=0.0068, val_loss=0.023]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 202.17it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 233.80it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 245.63it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 251.03it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 258.97it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 264.80it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 269.11it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 271.76it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 272.63it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 273.33it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 274.24it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 275.31it/s][A
                                                                         [AEpoch 5: 100%|██████████| 29/29 [00:00<00:00, 117.03it/s, train_loss=0.0068, val_loss=0.0164]Epoch 5: 100%|██████████| 29/29 [00:00<00:00, 116.61it/s, train_loss=0.0068, val_loss=0.0164]Epoch 5:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0068, val_loss=0.0164]          Epoch 6:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0068, val_loss=0.0164]Epoch 6:   3%|▎         | 1/29 [00:00<00:00, 198.88it/s, train_loss=0.0068, val_loss=0.0164]Epoch 6:   3%|▎         | 1/29 [00:00<00:00, 129.64it/s, train_loss=0.0115, val_loss=0.0164]Epoch 6:   7%|▋         | 2/29 [00:00<00:00, 158.52it/s, train_loss=0.0115, val_loss=0.0164]Epoch 6:   7%|▋         | 2/29 [00:00<00:00, 127.93it/s, train_loss=0.0157, val_loss=0.0164]Epoch 6:  10%|█         | 3/29 [00:00<00:00, 153.65it/s, train_loss=0.0157, val_loss=0.0164]Epoch 6:  10%|█         | 3/29 [00:00<00:00, 131.55it/s, train_loss=0.0183, val_loss=0.0164]Epoch 6:  14%|█▍        | 4/29 [00:00<00:00, 149.98it/s, train_loss=0.0183, val_loss=0.0164]Epoch 6:  14%|█▍        | 4/29 [00:00<00:00, 133.62it/s, train_loss=0.013, val_loss=0.0164] Epoch 6:  17%|█▋        | 5/29 [00:00<00:00, 147.71it/s, train_loss=0.013, val_loss=0.0164]Epoch 6:  17%|█▋        | 5/29 [00:00<00:00, 135.24it/s, train_loss=0.00853, val_loss=0.0164]Epoch 6:  21%|██        | 6/29 [00:00<00:00, 146.93it/s, train_loss=0.00853, val_loss=0.0164]Epoch 6:  21%|██        | 6/29 [00:00<00:00, 136.43it/s, train_loss=0.00835, val_loss=0.0164]Epoch 6:  24%|██▍       | 7/29 [00:00<00:00, 147.82it/s, train_loss=0.00835, val_loss=0.0164]Epoch 6:  24%|██▍       | 7/29 [00:00<00:00, 141.05it/s, train_loss=0.00733, val_loss=0.0164]Epoch 6:  28%|██▊       | 8/29 [00:00<00:00, 148.57it/s, train_loss=0.00733, val_loss=0.0164]Epoch 6:  28%|██▊       | 8/29 [00:00<00:00, 139.39it/s, train_loss=0.00761, val_loss=0.0164]Epoch 6:  31%|███       | 9/29 [00:00<00:00, 147.65it/s, train_loss=0.00761, val_loss=0.0164]Epoch 6:  31%|███       | 9/29 [00:00<00:00, 139.60it/s, train_loss=0.0103, val_loss=0.0164] Epoch 6:  34%|███▍      | 10/29 [00:00<00:00, 147.13it/s, train_loss=0.0103, val_loss=0.0164]Epoch 6:  34%|███▍      | 10/29 [00:00<00:00, 139.81it/s, train_loss=0.00886, val_loss=0.0164]Epoch 6:  38%|███▊      | 11/29 [00:00<00:00, 146.54it/s, train_loss=0.00886, val_loss=0.0164]Epoch 6:  38%|███▊      | 11/29 [00:00<00:00, 139.86it/s, train_loss=0.0112, val_loss=0.0164] Epoch 6:  41%|████▏     | 12/29 [00:00<00:00, 146.00it/s, train_loss=0.0112, val_loss=0.0164]Epoch 6:  41%|████▏     | 12/29 [00:00<00:00, 140.16it/s, train_loss=0.0116, val_loss=0.0164]Epoch 6:  45%|████▍     | 13/29 [00:00<00:00, 145.83it/s, train_loss=0.0116, val_loss=0.0164]Epoch 6:  45%|████▍     | 13/29 [00:00<00:00, 143.20it/s, train_loss=0.0101, val_loss=0.0164]Epoch 6:  48%|████▊     | 14/29 [00:00<00:00, 147.63it/s, train_loss=0.0101, val_loss=0.0164]Epoch 6:  48%|████▊     | 14/29 [00:00<00:00, 141.92it/s, train_loss=0.0182, val_loss=0.0164]Epoch 6:  52%|█████▏    | 15/29 [00:00<00:00, 146.43it/s, train_loss=0.0182, val_loss=0.0164]Epoch 6:  52%|█████▏    | 15/29 [00:00<00:00, 141.96it/s, train_loss=0.0152, val_loss=0.0164]Epoch 6:  55%|█████▌    | 16/29 [00:00<00:00, 146.34it/s, train_loss=0.0152, val_loss=0.0164]Epoch 6:  55%|█████▌    | 16/29 [00:00<00:00, 141.95it/s, train_loss=0.00872, val_loss=0.0164]Epoch 6:  59%|█████▊    | 17/29 [00:00<00:00, 146.06it/s, train_loss=0.00872, val_loss=0.0164]Epoch 6:  59%|█████▊    | 17/29 [00:00<00:00, 141.91it/s, train_loss=0.0134, val_loss=0.0164] Epoch 6:  62%|██████▏   | 18/29 [00:00<00:00, 145.44it/s, train_loss=0.0134, val_loss=0.0164]Epoch 6:  62%|██████▏   | 18/29 [00:00<00:00, 142.01it/s, train_loss=0.0109, val_loss=0.0164]Epoch 6:  66%|██████▌   | 19/29 [00:00<00:00, 145.38it/s, train_loss=0.0109, val_loss=0.0164]Epoch 6:  66%|██████▌   | 19/29 [00:00<00:00, 143.95it/s, train_loss=0.00768, val_loss=0.0164]Epoch 6:  69%|██████▉   | 20/29 [00:00<00:00, 147.16it/s, train_loss=0.00768, val_loss=0.0164]Epoch 6:  69%|██████▉   | 20/29 [00:00<00:00, 143.79it/s, train_loss=0.0173, val_loss=0.0164] Epoch 6:  72%|███████▏  | 21/29 [00:00<00:00, 147.04it/s, train_loss=0.0173, val_loss=0.0164]Epoch 6:  72%|███████▏  | 21/29 [00:00<00:00, 143.73it/s, train_loss=0.0123, val_loss=0.0164]Epoch 6:  76%|███████▌  | 22/29 [00:00<00:00, 146.67it/s, train_loss=0.0123, val_loss=0.0164]Epoch 6:  76%|███████▌  | 22/29 [00:00<00:00, 143.66it/s, train_loss=0.00912, val_loss=0.0164]Epoch 6:  79%|███████▉  | 23/29 [00:00<00:00, 146.50it/s, train_loss=0.00912, val_loss=0.0164]Epoch 6:  79%|███████▉  | 23/29 [00:00<00:00, 143.67it/s, train_loss=0.013, val_loss=0.0164]  Epoch 6:  83%|████████▎ | 24/29 [00:00<00:00, 146.42it/s, train_loss=0.013, val_loss=0.0164]Epoch 6:  83%|████████▎ | 24/29 [00:00<00:00, 143.65it/s, train_loss=0.0111, val_loss=0.0164]Epoch 6:  86%|████████▌ | 25/29 [00:00<00:00, 146.11it/s, train_loss=0.0111, val_loss=0.0164]Epoch 6:  86%|████████▌ | 25/29 [00:00<00:00, 145.26it/s, train_loss=0.0148, val_loss=0.0164]Epoch 6:  90%|████████▉ | 26/29 [00:00<00:00, 147.89it/s, train_loss=0.0148, val_loss=0.0164]Epoch 6:  90%|████████▉ | 26/29 [00:00<00:00, 145.06it/s, train_loss=0.0136, val_loss=0.0164]Epoch 6:  93%|█████████▎| 27/29 [00:00<00:00, 147.79it/s, train_loss=0.0136, val_loss=0.0164]Epoch 6:  93%|█████████▎| 27/29 [00:00<00:00, 144.93it/s, train_loss=0.0101, val_loss=0.0164]Epoch 6:  97%|█████████▋| 28/29 [00:00<00:00, 147.57it/s, train_loss=0.0101, val_loss=0.0164]Epoch 6:  97%|█████████▋| 28/29 [00:00<00:00, 144.81it/s, train_loss=0.00994, val_loss=0.0164]Epoch 6: 100%|██████████| 29/29 [00:00<00:00, 147.34it/s, train_loss=0.00994, val_loss=0.0164]Epoch 6: 100%|██████████| 29/29 [00:00<00:00, 144.97it/s, train_loss=0.0315, val_loss=0.0164] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 190.56it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 237.15it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 258.82it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 268.62it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 271.54it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 271.88it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 274.46it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 276.14it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 276.78it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 277.28it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 278.15it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 280.09it/s][A
                                                                         [AEpoch 6: 100%|██████████| 29/29 [00:00<00:00, 115.18it/s, train_loss=0.0315, val_loss=0.0116]Epoch 6: 100%|██████████| 29/29 [00:00<00:00, 114.74it/s, train_loss=0.0315, val_loss=0.0116]Epoch 6:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0315, val_loss=0.0116]          Epoch 7:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0315, val_loss=0.0116]Epoch 7:   3%|▎         | 1/29 [00:00<00:00, 201.69it/s, train_loss=0.0315, val_loss=0.0116]Epoch 7:   3%|▎         | 1/29 [00:00<00:00, 107.05it/s, train_loss=0.00978, val_loss=0.0116]Epoch 7:   7%|▋         | 2/29 [00:00<00:00, 149.32it/s, train_loss=0.00978, val_loss=0.0116]Epoch 7:   7%|▋         | 2/29 [00:00<00:00, 110.20it/s, train_loss=0.0116, val_loss=0.0116] Epoch 7:  10%|█         | 3/29 [00:00<00:00, 136.70it/s, train_loss=0.0116, val_loss=0.0116]Epoch 7:  10%|█         | 3/29 [00:00<00:00, 118.76it/s, train_loss=0.00698, val_loss=0.0116]Epoch 7:  14%|█▍        | 4/29 [00:00<00:00, 137.70it/s, train_loss=0.00698, val_loss=0.0116]Epoch 7:  14%|█▍        | 4/29 [00:00<00:00, 123.63it/s, train_loss=0.00965, val_loss=0.0116]Epoch 7:  17%|█▋        | 5/29 [00:00<00:00, 138.47it/s, train_loss=0.00965, val_loss=0.0116]Epoch 7:  17%|█▋        | 5/29 [00:00<00:00, 126.73it/s, train_loss=0.00889, val_loss=0.0116]Epoch 7:  21%|██        | 6/29 [00:00<00:00, 138.59it/s, train_loss=0.00889, val_loss=0.0116]Epoch 7:  21%|██        | 6/29 [00:00<00:00, 129.20it/s, train_loss=0.0107, val_loss=0.0116] Epoch 7:  24%|██▍       | 7/29 [00:00<00:00, 138.80it/s, train_loss=0.0107, val_loss=0.0116]Epoch 7:  24%|██▍       | 7/29 [00:00<00:00, 135.12it/s, train_loss=0.0131, val_loss=0.0116]Epoch 7:  28%|██▊       | 8/29 [00:00<00:00, 143.02it/s, train_loss=0.0131, val_loss=0.0116]Epoch 7:  28%|██▊       | 8/29 [00:00<00:00, 135.81it/s, train_loss=0.00831, val_loss=0.0116]Epoch 7:  31%|███       | 9/29 [00:00<00:00, 144.48it/s, train_loss=0.00831, val_loss=0.0116]Epoch 7:  31%|███       | 9/29 [00:00<00:00, 136.45it/s, train_loss=0.00764, val_loss=0.0116]Epoch 7:  34%|███▍      | 10/29 [00:00<00:00, 143.89it/s, train_loss=0.00764, val_loss=0.0116]Epoch 7:  34%|███▍      | 10/29 [00:00<00:00, 136.95it/s, train_loss=0.00847, val_loss=0.0116]Epoch 7:  38%|███▊      | 11/29 [00:00<00:00, 143.47it/s, train_loss=0.00847, val_loss=0.0116]Epoch 7:  38%|███▊      | 11/29 [00:00<00:00, 137.43it/s, train_loss=0.00847, val_loss=0.0116]Epoch 7:  41%|████▏     | 12/29 [00:00<00:00, 143.47it/s, train_loss=0.00847, val_loss=0.0116]Epoch 7:  41%|████▏     | 12/29 [00:00<00:00, 137.84it/s, train_loss=0.00965, val_loss=0.0116]Epoch 7:  45%|████▍     | 13/29 [00:00<00:00, 142.91it/s, train_loss=0.00965, val_loss=0.0116]Epoch 7:  45%|████▍     | 13/29 [00:00<00:00, 141.77it/s, train_loss=0.00994, val_loss=0.0116]Epoch 7:  48%|████▊     | 14/29 [00:00<00:00, 146.69it/s, train_loss=0.00994, val_loss=0.0116]Epoch 7:  48%|████▊     | 14/29 [00:00<00:00, 141.78it/s, train_loss=0.0137, val_loss=0.0116] Epoch 7:  52%|█████▏    | 15/29 [00:00<00:00, 146.64it/s, train_loss=0.0137, val_loss=0.0116]Epoch 7:  52%|█████▏    | 15/29 [00:00<00:00, 141.86it/s, train_loss=0.00894, val_loss=0.0116]Epoch 7:  55%|█████▌    | 16/29 [00:00<00:00, 146.13it/s, train_loss=0.00894, val_loss=0.0116]Epoch 7:  55%|█████▌    | 16/29 [00:00<00:00, 141.85it/s, train_loss=0.0159, val_loss=0.0116] Epoch 7:  59%|█████▊    | 17/29 [00:00<00:00, 145.87it/s, train_loss=0.0159, val_loss=0.0116]Epoch 7:  59%|█████▊    | 17/29 [00:00<00:00, 141.89it/s, train_loss=0.00882, val_loss=0.0116]Epoch 7:  62%|██████▏   | 18/29 [00:00<00:00, 145.66it/s, train_loss=0.00882, val_loss=0.0116]Epoch 7:  62%|██████▏   | 18/29 [00:00<00:00, 141.96it/s, train_loss=0.00777, val_loss=0.0116]Epoch 7:  66%|██████▌   | 19/29 [00:00<00:00, 145.38it/s, train_loss=0.00777, val_loss=0.0116]Epoch 7:  66%|██████▌   | 19/29 [00:00<00:00, 144.21it/s, train_loss=0.0123, val_loss=0.0116] Epoch 7:  69%|██████▉   | 20/29 [00:00<00:00, 147.45it/s, train_loss=0.0123, val_loss=0.0116]Epoch 7:  69%|██████▉   | 20/29 [00:00<00:00, 144.10it/s, train_loss=0.0078, val_loss=0.0116]Epoch 7:  72%|███████▏  | 21/29 [00:00<00:00, 147.45it/s, train_loss=0.0078, val_loss=0.0116]Epoch 7:  72%|███████▏  | 21/29 [00:00<00:00, 144.02it/s, train_loss=0.010, val_loss=0.0116] Epoch 7:  76%|███████▌  | 22/29 [00:00<00:00, 147.09it/s, train_loss=0.010, val_loss=0.0116]Epoch 7:  76%|███████▌  | 22/29 [00:00<00:00, 143.96it/s, train_loss=0.0111, val_loss=0.0116]Epoch 7:  79%|███████▉  | 23/29 [00:00<00:00, 146.92it/s, train_loss=0.0111, val_loss=0.0116]Epoch 7:  79%|███████▉  | 23/29 [00:00<00:00, 143.90it/s, train_loss=0.0113, val_loss=0.0116]Epoch 7:  83%|████████▎ | 24/29 [00:00<00:00, 146.77it/s, train_loss=0.0113, val_loss=0.0116]Epoch 7:  83%|████████▎ | 24/29 [00:00<00:00, 143.88it/s, train_loss=0.0162, val_loss=0.0116]Epoch 7:  86%|████████▌ | 25/29 [00:00<00:00, 146.42it/s, train_loss=0.0162, val_loss=0.0116]Epoch 7:  86%|████████▌ | 25/29 [00:00<00:00, 145.29it/s, train_loss=0.00806, val_loss=0.0116]Epoch 7:  90%|████████▉ | 26/29 [00:00<00:00, 147.50it/s, train_loss=0.00806, val_loss=0.0116]Epoch 7:  90%|████████▉ | 26/29 [00:00<00:00, 145.20it/s, train_loss=0.0079, val_loss=0.0116] Epoch 7:  93%|█████████▎| 27/29 [00:00<00:00, 147.66it/s, train_loss=0.0079, val_loss=0.0116]Epoch 7:  93%|█████████▎| 27/29 [00:00<00:00, 145.12it/s, train_loss=0.00626, val_loss=0.0116]Epoch 7:  97%|█████████▋| 28/29 [00:00<00:00, 147.74it/s, train_loss=0.00626, val_loss=0.0116]Epoch 7:  97%|█████████▋| 28/29 [00:00<00:00, 145.01it/s, train_loss=0.0099, val_loss=0.0116] Epoch 7: 100%|██████████| 29/29 [00:00<00:00, 147.59it/s, train_loss=0.0099, val_loss=0.0116]Epoch 7: 100%|██████████| 29/29 [00:00<00:00, 146.86it/s, train_loss=0.0051, val_loss=0.0116]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 217.21it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 257.08it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 275.19it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 287.52it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 292.43it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 291.75it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 290.52it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 290.90it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 291.06it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 289.37it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 288.66it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 288.97it/s][A
                                                                         [AEpoch 7: 100%|██████████| 29/29 [00:00<00:00, 117.88it/s, train_loss=0.0051, val_loss=0.0103]Epoch 7: 100%|██████████| 29/29 [00:00<00:00, 117.50it/s, train_loss=0.0051, val_loss=0.0103]Epoch 7:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0051, val_loss=0.0103]          Epoch 8:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0051, val_loss=0.0103]Epoch 8:   3%|▎         | 1/29 [00:00<00:00, 202.77it/s, train_loss=0.0051, val_loss=0.0103]Epoch 8:   3%|▎         | 1/29 [00:00<00:00, 106.73it/s, train_loss=0.013, val_loss=0.0103] Epoch 8:   7%|▋         | 2/29 [00:00<00:00, 144.28it/s, train_loss=0.013, val_loss=0.0103]Epoch 8:   7%|▋         | 2/29 [00:00<00:00, 121.37it/s, train_loss=0.0112, val_loss=0.0103]Epoch 8:  10%|█         | 3/29 [00:00<00:00, 146.17it/s, train_loss=0.0112, val_loss=0.0103]Epoch 8:  10%|█         | 3/29 [00:00<00:00, 118.03it/s, train_loss=0.00802, val_loss=0.0103]Epoch 8:  14%|█▍        | 4/29 [00:00<00:00, 136.72it/s, train_loss=0.00802, val_loss=0.0103]Epoch 8:  14%|█▍        | 4/29 [00:00<00:00, 123.08it/s, train_loss=0.0139, val_loss=0.0103] Epoch 8:  17%|█▋        | 5/29 [00:00<00:00, 137.60it/s, train_loss=0.0139, val_loss=0.0103]Epoch 8:  17%|█▋        | 5/29 [00:00<00:00, 126.45it/s, train_loss=0.00762, val_loss=0.0103]Epoch 8:  21%|██        | 6/29 [00:00<00:00, 138.09it/s, train_loss=0.00762, val_loss=0.0103]Epoch 8:  21%|██        | 6/29 [00:00<00:00, 128.70it/s, train_loss=0.00745, val_loss=0.0103]Epoch 8:  24%|██▍       | 7/29 [00:00<00:00, 138.89it/s, train_loss=0.00745, val_loss=0.0103]Epoch 8:  24%|██▍       | 7/29 [00:00<00:00, 130.47it/s, train_loss=0.00992, val_loss=0.0103]Epoch 8:  28%|██▊       | 8/29 [00:00<00:00, 138.84it/s, train_loss=0.00992, val_loss=0.0103]Epoch 8:  28%|██▊       | 8/29 [00:00<00:00, 135.69it/s, train_loss=0.00559, val_loss=0.0103]Epoch 8:  31%|███       | 9/29 [00:00<00:00, 142.76it/s, train_loss=0.00559, val_loss=0.0103]Epoch 8:  31%|███       | 9/29 [00:00<00:00, 136.24it/s, train_loss=0.0105, val_loss=0.0103] Epoch 8:  34%|███▍      | 10/29 [00:00<00:00, 143.16it/s, train_loss=0.0105, val_loss=0.0103]Epoch 8:  34%|███▍      | 10/29 [00:00<00:00, 136.81it/s, train_loss=0.0131, val_loss=0.0103]Epoch 8:  38%|███▊      | 11/29 [00:00<00:00, 143.84it/s, train_loss=0.0131, val_loss=0.0103]Epoch 8:  38%|███▊      | 11/29 [00:00<00:00, 137.21it/s, train_loss=0.0129, val_loss=0.0103]Epoch 8:  41%|████▏     | 12/29 [00:00<00:00, 143.06it/s, train_loss=0.0129, val_loss=0.0103]Epoch 8:  41%|████▏     | 12/29 [00:00<00:00, 137.50it/s, train_loss=0.0081, val_loss=0.0103]Epoch 8:  45%|████▍     | 13/29 [00:00<00:00, 142.92it/s, train_loss=0.0081, val_loss=0.0103]Epoch 8:  45%|████▍     | 13/29 [00:00<00:00, 137.90it/s, train_loss=0.00647, val_loss=0.0103]Epoch 8:  48%|████▊     | 14/29 [00:00<00:00, 143.09it/s, train_loss=0.00647, val_loss=0.0103]Epoch 8:  48%|████▊     | 14/29 [00:00<00:00, 140.76it/s, train_loss=0.00854, val_loss=0.0103]Epoch 8:  52%|█████▏    | 15/29 [00:00<00:00, 145.25it/s, train_loss=0.00854, val_loss=0.0103]Epoch 8:  52%|█████▏    | 15/29 [00:00<00:00, 139.73it/s, train_loss=0.00616, val_loss=0.0103]Epoch 8:  55%|█████▌    | 16/29 [00:00<00:00, 144.14it/s, train_loss=0.00616, val_loss=0.0103]Epoch 8:  55%|█████▌    | 16/29 [00:00<00:00, 139.96it/s, train_loss=0.00834, val_loss=0.0103]Epoch 8:  59%|█████▊    | 17/29 [00:00<00:00, 144.02it/s, train_loss=0.00834, val_loss=0.0103]Epoch 8:  59%|█████▊    | 17/29 [00:00<00:00, 140.11it/s, train_loss=0.00681, val_loss=0.0103]Epoch 8:  62%|██████▏   | 18/29 [00:00<00:00, 143.88it/s, train_loss=0.00681, val_loss=0.0103]Epoch 8:  62%|██████▏   | 18/29 [00:00<00:00, 140.29it/s, train_loss=0.00647, val_loss=0.0103]Epoch 8:  66%|██████▌   | 19/29 [00:00<00:00, 143.84it/s, train_loss=0.00647, val_loss=0.0103]Epoch 8:  66%|██████▌   | 19/29 [00:00<00:00, 140.44it/s, train_loss=0.00735, val_loss=0.0103]Epoch 8:  69%|██████▉   | 20/29 [00:00<00:00, 143.60it/s, train_loss=0.00735, val_loss=0.0103]Epoch 8:  69%|██████▉   | 20/29 [00:00<00:00, 142.63it/s, train_loss=0.00907, val_loss=0.0103]Epoch 8:  72%|███████▏  | 21/29 [00:00<00:00, 145.81it/s, train_loss=0.00907, val_loss=0.0103]Epoch 8:  72%|███████▏  | 21/29 [00:00<00:00, 142.58it/s, train_loss=0.00663, val_loss=0.0103]Epoch 8:  76%|███████▌  | 22/29 [00:00<00:00, 145.89it/s, train_loss=0.00663, val_loss=0.0103]Epoch 8:  76%|███████▌  | 22/29 [00:00<00:00, 142.60it/s, train_loss=0.00662, val_loss=0.0103]Epoch 8:  79%|███████▉  | 23/29 [00:00<00:00, 145.61it/s, train_loss=0.00662, val_loss=0.0103]Epoch 8:  79%|███████▉  | 23/29 [00:00<00:00, 142.56it/s, train_loss=0.00923, val_loss=0.0103]Epoch 8:  83%|████████▎ | 24/29 [00:00<00:00, 145.43it/s, train_loss=0.00923, val_loss=0.0103]Epoch 8:  83%|████████▎ | 24/29 [00:00<00:00, 142.56it/s, train_loss=0.00805, val_loss=0.0103]Epoch 8:  86%|████████▌ | 25/29 [00:00<00:00, 145.28it/s, train_loss=0.00805, val_loss=0.0103]Epoch 8:  86%|████████▌ | 25/29 [00:00<00:00, 142.56it/s, train_loss=0.00813, val_loss=0.0103]Epoch 8:  90%|████████▉ | 26/29 [00:00<00:00, 145.17it/s, train_loss=0.00813, val_loss=0.0103]Epoch 8:  90%|████████▉ | 26/29 [00:00<00:00, 144.18it/s, train_loss=0.00756, val_loss=0.0103]Epoch 8:  93%|█████████▎| 27/29 [00:00<00:00, 146.38it/s, train_loss=0.00756, val_loss=0.0103]Epoch 8:  93%|█████████▎| 27/29 [00:00<00:00, 143.39it/s, train_loss=0.00882, val_loss=0.0103]Epoch 8:  97%|█████████▋| 28/29 [00:00<00:00, 145.64it/s, train_loss=0.00882, val_loss=0.0103]Epoch 8:  97%|█████████▋| 28/29 [00:00<00:00, 143.40it/s, train_loss=0.00931, val_loss=0.0103]Epoch 8: 100%|██████████| 29/29 [00:00<00:00, 145.70it/s, train_loss=0.00931, val_loss=0.0103]Epoch 8: 100%|██████████| 29/29 [00:00<00:00, 143.63it/s, train_loss=0.00555, val_loss=0.0103]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 227.25it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 271.64it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 286.61it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 301.08it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 307.98it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 312.78it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 314.91it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 314.32it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 312.66it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 310.69it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 309.27it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 307.89it/s][A
                                                                         [AEpoch 8: 100%|██████████| 29/29 [00:00<00:00, 116.38it/s, train_loss=0.00555, val_loss=0.00899]Epoch 8: 100%|██████████| 29/29 [00:00<00:00, 115.99it/s, train_loss=0.00555, val_loss=0.00899]Epoch 8:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00555, val_loss=0.00899]          Epoch 9:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00555, val_loss=0.00899]Epoch 9:   3%|▎         | 1/29 [00:00<00:00, 202.89it/s, train_loss=0.00555, val_loss=0.00899]Epoch 9:   3%|▎         | 1/29 [00:00<00:00, 105.80it/s, train_loss=0.0124, val_loss=0.00899] Epoch 9:   7%|▋         | 2/29 [00:00<00:00, 150.82it/s, train_loss=0.0124, val_loss=0.00899]Epoch 9:   7%|▋         | 2/29 [00:00<00:00, 121.23it/s, train_loss=0.00586, val_loss=0.00899]Epoch 9:  10%|█         | 3/29 [00:00<00:00, 147.87it/s, train_loss=0.00586, val_loss=0.00899]Epoch 9:  10%|█         | 3/29 [00:00<00:00, 127.30it/s, train_loss=0.012, val_loss=0.00899]  Epoch 9:  14%|█▍        | 4/29 [00:00<00:00, 144.63it/s, train_loss=0.012, val_loss=0.00899]Epoch 9:  14%|█▍        | 4/29 [00:00<00:00, 123.10it/s, train_loss=0.00582, val_loss=0.00899]Epoch 9:  17%|█▋        | 5/29 [00:00<00:00, 136.70it/s, train_loss=0.00582, val_loss=0.00899]Epoch 9:  17%|█▋        | 5/29 [00:00<00:00, 126.56it/s, train_loss=0.00964, val_loss=0.00899]Epoch 9:  21%|██        | 6/29 [00:00<00:00, 138.46it/s, train_loss=0.00964, val_loss=0.00899]Epoch 9:  21%|██        | 6/29 [00:00<00:00, 128.91it/s, train_loss=0.00755, val_loss=0.00899]Epoch 9:  24%|██▍       | 7/29 [00:00<00:00, 139.09it/s, train_loss=0.00755, val_loss=0.00899]Epoch 9:  24%|██▍       | 7/29 [00:00<00:00, 130.62it/s, train_loss=0.012, val_loss=0.00899]  Epoch 9:  28%|██▊       | 8/29 [00:00<00:00, 139.56it/s, train_loss=0.012, val_loss=0.00899]Epoch 9:  28%|██▊       | 8/29 [00:00<00:00, 132.10it/s, train_loss=0.00557, val_loss=0.00899]Epoch 9:  31%|███       | 9/29 [00:00<00:00, 139.47it/s, train_loss=0.00557, val_loss=0.00899]Epoch 9:  31%|███       | 9/29 [00:00<00:00, 136.96it/s, train_loss=0.00663, val_loss=0.00899]Epoch 9:  34%|███▍      | 10/29 [00:00<00:00, 142.77it/s, train_loss=0.00663, val_loss=0.00899]Epoch 9:  34%|███▍      | 10/29 [00:00<00:00, 137.43it/s, train_loss=0.00775, val_loss=0.00899]Epoch 9:  38%|███▊      | 11/29 [00:00<00:00, 143.38it/s, train_loss=0.00775, val_loss=0.00899]Epoch 9:  38%|███▊      | 11/29 [00:00<00:00, 137.97it/s, train_loss=0.00708, val_loss=0.00899]Epoch 9:  41%|████▏     | 12/29 [00:00<00:00, 144.22it/s, train_loss=0.00708, val_loss=0.00899]Epoch 9:  41%|████▏     | 12/29 [00:00<00:00, 138.27it/s, train_loss=0.00811, val_loss=0.00899]Epoch 9:  45%|████▍     | 13/29 [00:00<00:00, 144.07it/s, train_loss=0.00811, val_loss=0.00899]Epoch 9:  45%|████▍     | 13/29 [00:00<00:00, 138.63it/s, train_loss=0.00762, val_loss=0.00899]Epoch 9:  48%|████▊     | 14/29 [00:00<00:00, 144.00it/s, train_loss=0.00762, val_loss=0.00899]Epoch 9:  48%|████▊     | 14/29 [00:00<00:00, 138.95it/s, train_loss=0.00722, val_loss=0.00899]Epoch 9:  52%|█████▏    | 15/29 [00:00<00:00, 143.93it/s, train_loss=0.00722, val_loss=0.00899]Epoch 9:  52%|█████▏    | 15/29 [00:00<00:00, 141.90it/s, train_loss=0.00929, val_loss=0.00899]Epoch 9:  55%|█████▌    | 16/29 [00:00<00:00, 146.08it/s, train_loss=0.00929, val_loss=0.00899]Epoch 9:  55%|█████▌    | 16/29 [00:00<00:00, 140.79it/s, train_loss=0.00525, val_loss=0.00899]Epoch 9:  59%|█████▊    | 17/29 [00:00<00:00, 144.78it/s, train_loss=0.00525, val_loss=0.00899]Epoch 9:  59%|█████▊    | 17/29 [00:00<00:00, 140.91it/s, train_loss=0.00835, val_loss=0.00899]Epoch 9:  62%|██████▏   | 18/29 [00:00<00:00, 144.95it/s, train_loss=0.00835, val_loss=0.00899]Epoch 9:  62%|██████▏   | 18/29 [00:00<00:00, 141.00it/s, train_loss=0.00821, val_loss=0.00899]Epoch 9:  66%|██████▌   | 19/29 [00:00<00:00, 144.77it/s, train_loss=0.00821, val_loss=0.00899]Epoch 9:  66%|██████▌   | 19/29 [00:00<00:00, 141.08it/s, train_loss=0.00823, val_loss=0.00899]Epoch 9:  69%|██████▉   | 20/29 [00:00<00:00, 144.66it/s, train_loss=0.00823, val_loss=0.00899]Epoch 9:  69%|██████▉   | 20/29 [00:00<00:00, 141.16it/s, train_loss=0.00993, val_loss=0.00899]Epoch 9:  72%|███████▏  | 21/29 [00:00<00:00, 144.46it/s, train_loss=0.00993, val_loss=0.00899]Epoch 9:  72%|███████▏  | 21/29 [00:00<00:00, 143.22it/s, train_loss=0.00419, val_loss=0.00899]Epoch 9:  76%|███████▌  | 22/29 [00:00<00:00, 145.89it/s, train_loss=0.00419, val_loss=0.00899]Epoch 9:  76%|███████▌  | 22/29 [00:00<00:00, 142.33it/s, train_loss=0.00697, val_loss=0.00899]Epoch 9:  79%|███████▉  | 23/29 [00:00<00:00, 145.13it/s, train_loss=0.00697, val_loss=0.00899]Epoch 9:  79%|███████▉  | 23/29 [00:00<00:00, 142.35it/s, train_loss=0.00967, val_loss=0.00899]Epoch 9:  83%|████████▎ | 24/29 [00:00<00:00, 145.05it/s, train_loss=0.00967, val_loss=0.00899]Epoch 9:  83%|████████▎ | 24/29 [00:00<00:00, 142.37it/s, train_loss=0.00512, val_loss=0.00899]Epoch 9:  86%|████████▌ | 25/29 [00:00<00:00, 144.97it/s, train_loss=0.00512, val_loss=0.00899]Epoch 9:  86%|████████▌ | 25/29 [00:00<00:00, 142.42it/s, train_loss=0.00722, val_loss=0.00899]Epoch 9:  90%|████████▉ | 26/29 [00:00<00:00, 145.00it/s, train_loss=0.00722, val_loss=0.00899]Epoch 9:  90%|████████▉ | 26/29 [00:00<00:00, 142.50it/s, train_loss=0.00742, val_loss=0.00899]Epoch 9:  93%|█████████▎| 27/29 [00:00<00:00, 144.75it/s, train_loss=0.00742, val_loss=0.00899]Epoch 9:  93%|█████████▎| 27/29 [00:00<00:00, 144.11it/s, train_loss=0.00734, val_loss=0.00899]Epoch 9:  97%|█████████▋| 28/29 [00:00<00:00, 146.22it/s, train_loss=0.00734, val_loss=0.00899]Epoch 9:  97%|█████████▋| 28/29 [00:00<00:00, 144.13it/s, train_loss=0.00674, val_loss=0.00899]Epoch 9: 100%|██████████| 29/29 [00:00<00:00, 146.55it/s, train_loss=0.00674, val_loss=0.00899]Epoch 9: 100%|██████████| 29/29 [00:00<00:00, 145.89it/s, train_loss=0.0041, val_loss=0.00899] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 266.63it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 306.62it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 324.32it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 335.14it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 338.80it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 339.87it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 336.16it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 333.35it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 318.94it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 318.76it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 317.82it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 318.03it/s][A
                                                                         [AEpoch 9: 100%|██████████| 29/29 [00:00<00:00, 118.88it/s, train_loss=0.0041, val_loss=0.00814]Epoch 9: 100%|██████████| 29/29 [00:00<00:00, 118.48it/s, train_loss=0.0041, val_loss=0.00814]Epoch 9:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0041, val_loss=0.00814]          Epoch 10:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0041, val_loss=0.00814]Epoch 10:   3%|▎         | 1/29 [00:00<00:00, 170.27it/s, train_loss=0.0041, val_loss=0.00814]Epoch 10:   3%|▎         | 1/29 [00:00<00:00, 95.17it/s, train_loss=0.00805, val_loss=0.00814]Epoch 10:   7%|▋         | 2/29 [00:00<00:00, 140.52it/s, train_loss=0.00805, val_loss=0.00814]Epoch 10:   7%|▋         | 2/29 [00:00<00:00, 113.67it/s, train_loss=0.00811, val_loss=0.00814]Epoch 10:  10%|█         | 3/29 [00:00<00:00, 141.04it/s, train_loss=0.00811, val_loss=0.00814]Epoch 10:  10%|█         | 3/29 [00:00<00:00, 121.26it/s, train_loss=0.00912, val_loss=0.00814]Epoch 10:  14%|█▍        | 4/29 [00:00<00:00, 140.62it/s, train_loss=0.00912, val_loss=0.00814]Epoch 10:  14%|█▍        | 4/29 [00:00<00:00, 125.63it/s, train_loss=0.00735, val_loss=0.00814]Epoch 10:  17%|█▋        | 5/29 [00:00<00:00, 140.86it/s, train_loss=0.00735, val_loss=0.00814]Epoch 10:  17%|█▋        | 5/29 [00:00<00:00, 128.44it/s, train_loss=0.0104, val_loss=0.00814] Epoch 10:  21%|██        | 6/29 [00:00<00:00, 138.81it/s, train_loss=0.0104, val_loss=0.00814]Epoch 10:  21%|██        | 6/29 [00:00<00:00, 131.63it/s, train_loss=0.00665, val_loss=0.00814]Epoch 10:  24%|██▍       | 7/29 [00:00<00:00, 139.89it/s, train_loss=0.00665, val_loss=0.00814]Epoch 10:  24%|██▍       | 7/29 [00:00<00:00, 132.93it/s, train_loss=0.00423, val_loss=0.00814]Epoch 10:  28%|██▊       | 8/29 [00:00<00:00, 141.77it/s, train_loss=0.00423, val_loss=0.00814]Epoch 10:  28%|██▊       | 8/29 [00:00<00:00, 133.93it/s, train_loss=0.00916, val_loss=0.00814]Epoch 10:  31%|███       | 9/29 [00:00<00:00, 141.63it/s, train_loss=0.00916, val_loss=0.00814]Epoch 10:  31%|███       | 9/29 [00:00<00:00, 134.73it/s, train_loss=0.00739, val_loss=0.00814]Epoch 10:  34%|███▍      | 10/29 [00:00<00:00, 141.67it/s, train_loss=0.00739, val_loss=0.00814]Epoch 10:  34%|███▍      | 10/29 [00:00<00:00, 135.54it/s, train_loss=0.00662, val_loss=0.00814]Epoch 10:  38%|███▊      | 11/29 [00:00<00:00, 141.67it/s, train_loss=0.00662, val_loss=0.00814]Epoch 10:  38%|███▊      | 11/29 [00:00<00:00, 136.25it/s, train_loss=0.00636, val_loss=0.00814]Epoch 10:  41%|████▏     | 12/29 [00:00<00:00, 141.01it/s, train_loss=0.00636, val_loss=0.00814]Epoch 10:  41%|████▏     | 12/29 [00:00<00:00, 136.66it/s, train_loss=0.00693, val_loss=0.00814]Epoch 10:  45%|████▍     | 13/29 [00:00<00:00, 142.34it/s, train_loss=0.00693, val_loss=0.00814]Epoch 10:  45%|████▍     | 13/29 [00:00<00:00, 137.07it/s, train_loss=0.00482, val_loss=0.00814]Epoch 10:  48%|████▊     | 14/29 [00:00<00:00, 142.57it/s, train_loss=0.00482, val_loss=0.00814]Epoch 10:  48%|████▊     | 14/29 [00:00<00:00, 137.28it/s, train_loss=0.00851, val_loss=0.00814]Epoch 10:  52%|█████▏    | 15/29 [00:00<00:00, 142.15it/s, train_loss=0.00851, val_loss=0.00814]Epoch 10:  52%|█████▏    | 15/29 [00:00<00:00, 137.52it/s, train_loss=0.00503, val_loss=0.00814]Epoch 10:  55%|█████▌    | 16/29 [00:00<00:00, 142.11it/s, train_loss=0.00503, val_loss=0.00814]Epoch 10:  55%|█████▌    | 16/29 [00:00<00:00, 137.86it/s, train_loss=0.00605, val_loss=0.00814]Epoch 10:  59%|█████▊    | 17/29 [00:00<00:00, 142.06it/s, train_loss=0.00605, val_loss=0.00814]Epoch 10:  59%|█████▊    | 17/29 [00:00<00:00, 140.19it/s, train_loss=0.00479, val_loss=0.00814]Epoch 10:  62%|██████▏   | 18/29 [00:00<00:00, 143.74it/s, train_loss=0.00479, val_loss=0.00814]Epoch 10:  62%|██████▏   | 18/29 [00:00<00:00, 139.37it/s, train_loss=0.00741, val_loss=0.00814]Epoch 10:  66%|██████▌   | 19/29 [00:00<00:00, 142.95it/s, train_loss=0.00741, val_loss=0.00814]Epoch 10:  66%|██████▌   | 19/29 [00:00<00:00, 139.52it/s, train_loss=0.0101, val_loss=0.00814] Epoch 10:  69%|██████▉   | 20/29 [00:00<00:00, 143.13it/s, train_loss=0.0101, val_loss=0.00814]Epoch 10:  69%|██████▉   | 20/29 [00:00<00:00, 139.64it/s, train_loss=0.00657, val_loss=0.00814]Epoch 10:  72%|███████▏  | 21/29 [00:00<00:00, 143.05it/s, train_loss=0.00657, val_loss=0.00814]Epoch 10:  72%|███████▏  | 21/29 [00:00<00:00, 139.80it/s, train_loss=0.00849, val_loss=0.00814]Epoch 10:  76%|███████▌  | 22/29 [00:00<00:00, 142.99it/s, train_loss=0.00849, val_loss=0.00814]Epoch 10:  76%|███████▌  | 22/29 [00:00<00:00, 139.93it/s, train_loss=0.00513, val_loss=0.00814]Epoch 10:  79%|███████▉  | 23/29 [00:00<00:00, 142.87it/s, train_loss=0.00513, val_loss=0.00814]Epoch 10:  79%|███████▉  | 23/29 [00:00<00:00, 141.52it/s, train_loss=0.0085, val_loss=0.00814] Epoch 10:  83%|████████▎ | 24/29 [00:00<00:00, 143.87it/s, train_loss=0.0085, val_loss=0.00814]Epoch 10:  83%|████████▎ | 24/29 [00:00<00:00, 140.76it/s, train_loss=0.00397, val_loss=0.00814]Epoch 10:  86%|████████▌ | 25/29 [00:00<00:00, 143.37it/s, train_loss=0.00397, val_loss=0.00814]Epoch 10:  86%|████████▌ | 25/29 [00:00<00:00, 140.83it/s, train_loss=0.00619, val_loss=0.00814]Epoch 10:  90%|████████▉ | 26/29 [00:00<00:00, 143.42it/s, train_loss=0.00619, val_loss=0.00814]Epoch 10:  90%|████████▉ | 26/29 [00:00<00:00, 140.84it/s, train_loss=0.00803, val_loss=0.00814]Epoch 10:  93%|█████████▎| 27/29 [00:00<00:00, 143.34it/s, train_loss=0.00803, val_loss=0.00814]Epoch 10:  93%|█████████▎| 27/29 [00:00<00:00, 140.89it/s, train_loss=0.00743, val_loss=0.00814]Epoch 10:  97%|█████████▋| 28/29 [00:00<00:00, 143.37it/s, train_loss=0.00743, val_loss=0.00814]Epoch 10:  97%|█████████▋| 28/29 [00:00<00:00, 140.98it/s, train_loss=0.00715, val_loss=0.00814]Epoch 10: 100%|██████████| 29/29 [00:00<00:00, 143.46it/s, train_loss=0.00715, val_loss=0.00814]Epoch 10: 100%|██████████| 29/29 [00:00<00:00, 142.80it/s, train_loss=0.00571, val_loss=0.00814]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 182.16it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 243.96it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 278.99it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 296.18it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 309.04it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 317.74it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 321.69it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 325.59it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 330.19it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 330.67it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 330.51it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 330.05it/s][A
                                                                         [AEpoch 10: 100%|██████████| 29/29 [00:00<00:00, 117.47it/s, train_loss=0.00571, val_loss=0.0074] Epoch 10: 100%|██████████| 29/29 [00:00<00:00, 117.06it/s, train_loss=0.00571, val_loss=0.0074]Epoch 10:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00571, val_loss=0.0074]          Epoch 11:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00571, val_loss=0.0074]Epoch 11:   3%|▎         | 1/29 [00:00<00:00, 208.19it/s, train_loss=0.00571, val_loss=0.0074]Epoch 11:   3%|▎         | 1/29 [00:00<00:00, 108.13it/s, train_loss=0.00441, val_loss=0.0074]Epoch 11:   7%|▋         | 2/29 [00:00<00:00, 147.75it/s, train_loss=0.00441, val_loss=0.0074]Epoch 11:   7%|▋         | 2/29 [00:00<00:00, 110.72it/s, train_loss=0.00905, val_loss=0.0074]Epoch 11:  10%|█         | 3/29 [00:00<00:00, 136.65it/s, train_loss=0.00905, val_loss=0.0074]Epoch 11:  10%|█         | 3/29 [00:00<00:00, 119.70it/s, train_loss=0.00564, val_loss=0.0074]Epoch 11:  14%|█▍        | 4/29 [00:00<00:00, 138.52it/s, train_loss=0.00564, val_loss=0.0074]Epoch 11:  14%|█▍        | 4/29 [00:00<00:00, 124.32it/s, train_loss=0.00795, val_loss=0.0074]Epoch 11:  17%|█▋        | 5/29 [00:00<00:00, 139.43it/s, train_loss=0.00795, val_loss=0.0074]Epoch 11:  17%|█▋        | 5/29 [00:00<00:00, 127.33it/s, train_loss=0.00906, val_loss=0.0074]Epoch 11:  21%|██        | 6/29 [00:00<00:00, 139.62it/s, train_loss=0.00906, val_loss=0.0074]Epoch 11:  21%|██        | 6/29 [00:00<00:00, 129.63it/s, train_loss=0.00699, val_loss=0.0074]Epoch 11:  24%|██▍       | 7/29 [00:00<00:00, 140.04it/s, train_loss=0.00699, val_loss=0.0074]Epoch 11:  24%|██▍       | 7/29 [00:00<00:00, 136.01it/s, train_loss=0.00507, val_loss=0.0074]Epoch 11:  28%|██▊       | 8/29 [00:00<00:00, 144.04it/s, train_loss=0.00507, val_loss=0.0074]Epoch 11:  28%|██▊       | 8/29 [00:00<00:00, 134.72it/s, train_loss=0.00856, val_loss=0.0074]Epoch 11:  31%|███       | 9/29 [00:00<00:00, 142.30it/s, train_loss=0.00856, val_loss=0.0074]Epoch 11:  31%|███       | 9/29 [00:00<00:00, 135.51it/s, train_loss=0.00867, val_loss=0.0074]Epoch 11:  34%|███▍      | 10/29 [00:00<00:00, 142.54it/s, train_loss=0.00867, val_loss=0.0074]Epoch 11:  34%|███▍      | 10/29 [00:00<00:00, 136.18it/s, train_loss=0.00511, val_loss=0.0074]Epoch 11:  38%|███▊      | 11/29 [00:00<00:00, 142.68it/s, train_loss=0.00511, val_loss=0.0074]Epoch 11:  38%|███▊      | 11/29 [00:00<00:00, 136.73it/s, train_loss=0.00702, val_loss=0.0074]Epoch 11:  41%|████▏     | 12/29 [00:00<00:00, 142.38it/s, train_loss=0.00702, val_loss=0.0074]Epoch 11:  41%|████▏     | 12/29 [00:00<00:00, 137.18it/s, train_loss=0.00678, val_loss=0.0074]Epoch 11:  45%|████▍     | 13/29 [00:00<00:00, 141.84it/s, train_loss=0.00678, val_loss=0.0074]Epoch 11:  45%|████▍     | 13/29 [00:00<00:00, 140.47it/s, train_loss=0.00514, val_loss=0.0074]Epoch 11:  48%|████▊     | 14/29 [00:00<00:00, 145.45it/s, train_loss=0.00514, val_loss=0.0074]Epoch 11:  48%|████▊     | 14/29 [00:00<00:00, 140.53it/s, train_loss=0.0062, val_loss=0.0074] Epoch 11:  52%|█████▏    | 15/29 [00:00<00:00, 145.64it/s, train_loss=0.0062, val_loss=0.0074]Epoch 11:  52%|█████▏    | 15/29 [00:00<00:00, 140.61it/s, train_loss=0.00537, val_loss=0.0074]Epoch 11:  55%|█████▌    | 16/29 [00:00<00:00, 145.32it/s, train_loss=0.00537, val_loss=0.0074]Epoch 11:  55%|█████▌    | 16/29 [00:00<00:00, 140.65it/s, train_loss=0.00562, val_loss=0.0074]Epoch 11:  59%|█████▊    | 17/29 [00:00<00:00, 144.92it/s, train_loss=0.00562, val_loss=0.0074]Epoch 11:  59%|█████▊    | 17/29 [00:00<00:00, 140.77it/s, train_loss=0.00613, val_loss=0.0074]Epoch 11:  62%|██████▏   | 18/29 [00:00<00:00, 144.73it/s, train_loss=0.00613, val_loss=0.0074]Epoch 11:  62%|██████▏   | 18/29 [00:00<00:00, 140.89it/s, train_loss=0.00574, val_loss=0.0074]Epoch 11:  66%|██████▌   | 19/29 [00:00<00:00, 144.66it/s, train_loss=0.00574, val_loss=0.0074]Epoch 11:  66%|██████▌   | 19/29 [00:00<00:00, 143.09it/s, train_loss=0.00744, val_loss=0.0074]Epoch 11:  69%|██████▉   | 20/29 [00:00<00:00, 146.47it/s, train_loss=0.00744, val_loss=0.0074]Epoch 11:  69%|██████▉   | 20/29 [00:00<00:00, 142.29it/s, train_loss=0.00669, val_loss=0.0074]Epoch 11:  72%|███████▏  | 21/29 [00:00<00:00, 145.63it/s, train_loss=0.00669, val_loss=0.0074]Epoch 11:  72%|███████▏  | 21/29 [00:00<00:00, 142.35it/s, train_loss=0.00483, val_loss=0.0074]Epoch 11:  76%|███████▌  | 22/29 [00:00<00:00, 145.51it/s, train_loss=0.00483, val_loss=0.0074]Epoch 11:  76%|███████▌  | 22/29 [00:00<00:00, 142.34it/s, train_loss=0.00707, val_loss=0.0074]Epoch 11:  79%|███████▉  | 23/29 [00:00<00:00, 145.39it/s, train_loss=0.00707, val_loss=0.0074]Epoch 11:  79%|███████▉  | 23/29 [00:00<00:00, 142.40it/s, train_loss=0.00577, val_loss=0.0074]Epoch 11:  83%|████████▎ | 24/29 [00:00<00:00, 145.14it/s, train_loss=0.00577, val_loss=0.0074]Epoch 11:  83%|████████▎ | 24/29 [00:00<00:00, 142.43it/s, train_loss=0.00667, val_loss=0.0074]Epoch 11:  86%|████████▌ | 25/29 [00:00<00:00, 145.09it/s, train_loss=0.00667, val_loss=0.0074]Epoch 11:  86%|████████▌ | 25/29 [00:00<00:00, 144.18it/s, train_loss=0.00428, val_loss=0.0074]Epoch 11:  90%|████████▉ | 26/29 [00:00<00:00, 146.59it/s, train_loss=0.00428, val_loss=0.0074]Epoch 11:  90%|████████▉ | 26/29 [00:00<00:00, 143.39it/s, train_loss=0.00684, val_loss=0.0074]Epoch 11:  93%|█████████▎| 27/29 [00:00<00:00, 145.88it/s, train_loss=0.00684, val_loss=0.0074]Epoch 11:  93%|█████████▎| 27/29 [00:00<00:00, 143.37it/s, train_loss=0.00537, val_loss=0.0074]Epoch 11:  97%|█████████▋| 28/29 [00:00<00:00, 145.72it/s, train_loss=0.00537, val_loss=0.0074]Epoch 11:  97%|█████████▋| 28/29 [00:00<00:00, 143.34it/s, train_loss=0.00716, val_loss=0.0074]Epoch 11: 100%|██████████| 29/29 [00:00<00:00, 145.75it/s, train_loss=0.00716, val_loss=0.0074]Epoch 11: 100%|██████████| 29/29 [00:00<00:00, 145.06it/s, train_loss=0.00695, val_loss=0.0074]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 148.86it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 188.97it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 209.95it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 231.21it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 250.41it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 253.35it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 259.39it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 267.15it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 274.46it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 280.11it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 284.81it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 290.60it/s][A
                                                                         [AEpoch 11: 100%|██████████| 29/29 [00:00<00:00, 116.05it/s, train_loss=0.00695, val_loss=0.00684]Epoch 11: 100%|██████████| 29/29 [00:00<00:00, 115.70it/s, train_loss=0.00695, val_loss=0.00684]Epoch 11:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00695, val_loss=0.00684]          Epoch 12:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00695, val_loss=0.00684]Epoch 12:   3%|▎         | 1/29 [00:00<00:00, 210.05it/s, train_loss=0.00695, val_loss=0.00684]Epoch 12:   3%|▎         | 1/29 [00:00<00:00, 107.81it/s, train_loss=0.00498, val_loss=0.00684]Epoch 12:   7%|▋         | 2/29 [00:00<00:00, 153.90it/s, train_loss=0.00498, val_loss=0.00684]Epoch 12:   7%|▋         | 2/29 [00:00<00:00, 137.28it/s, train_loss=0.00601, val_loss=0.00684]Epoch 12:  10%|█         | 3/29 [00:00<00:00, 161.88it/s, train_loss=0.00601, val_loss=0.00684]Epoch 12:  10%|█         | 3/29 [00:00<00:00, 133.74it/s, train_loss=0.00548, val_loss=0.00684]Epoch 12:  14%|█▍        | 4/29 [00:00<00:00, 152.73it/s, train_loss=0.00548, val_loss=0.00684]Epoch 12:  14%|█▍        | 4/29 [00:00<00:00, 135.60it/s, train_loss=0.00612, val_loss=0.00684]Epoch 12:  17%|█▋        | 5/29 [00:00<00:00, 149.31it/s, train_loss=0.00612, val_loss=0.00684]Epoch 12:  17%|█▋        | 5/29 [00:00<00:00, 136.72it/s, train_loss=0.00632, val_loss=0.00684]Epoch 12:  21%|██        | 6/29 [00:00<00:00, 148.06it/s, train_loss=0.00632, val_loss=0.00684]Epoch 12:  21%|██        | 6/29 [00:00<00:00, 137.79it/s, train_loss=0.00829, val_loss=0.00684]Epoch 12:  24%|██▍       | 7/29 [00:00<00:00, 147.68it/s, train_loss=0.00829, val_loss=0.00684]Epoch 12:  24%|██▍       | 7/29 [00:00<00:00, 138.54it/s, train_loss=0.00397, val_loss=0.00684]Epoch 12:  28%|██▊       | 8/29 [00:00<00:00, 146.66it/s, train_loss=0.00397, val_loss=0.00684]Epoch 12:  28%|██▊       | 8/29 [00:00<00:00, 144.56it/s, train_loss=0.00604, val_loss=0.00684]Epoch 12:  31%|███       | 9/29 [00:00<00:00, 152.00it/s, train_loss=0.00604, val_loss=0.00684]Epoch 12:  31%|███       | 9/29 [00:00<00:00, 144.47it/s, train_loss=0.00521, val_loss=0.00684]Epoch 12:  34%|███▍      | 10/29 [00:00<00:00, 151.61it/s, train_loss=0.00521, val_loss=0.00684]Epoch 12:  34%|███▍      | 10/29 [00:00<00:00, 144.26it/s, train_loss=0.00635, val_loss=0.00684]Epoch 12:  38%|███▊      | 11/29 [00:00<00:00, 150.41it/s, train_loss=0.00635, val_loss=0.00684]Epoch 12:  38%|███▊      | 11/29 [00:00<00:00, 144.07it/s, train_loss=0.00467, val_loss=0.00684]Epoch 12:  41%|████▏     | 12/29 [00:00<00:00, 149.65it/s, train_loss=0.00467, val_loss=0.00684]Epoch 12:  41%|████▏     | 12/29 [00:00<00:00, 144.01it/s, train_loss=0.00534, val_loss=0.00684]Epoch 12:  45%|████▍     | 13/29 [00:00<00:00, 149.08it/s, train_loss=0.00534, val_loss=0.00684]Epoch 12:  45%|████▍     | 13/29 [00:00<00:00, 144.00it/s, train_loss=0.00545, val_loss=0.00684]Epoch 12:  48%|████▊     | 14/29 [00:00<00:00, 148.32it/s, train_loss=0.00545, val_loss=0.00684]Epoch 12:  48%|████▊     | 14/29 [00:00<00:00, 146.82it/s, train_loss=0.00777, val_loss=0.00684]Epoch 12:  52%|█████▏    | 15/29 [00:00<00:00, 150.85it/s, train_loss=0.00777, val_loss=0.00684]Epoch 12:  52%|█████▏    | 15/29 [00:00<00:00, 146.64it/s, train_loss=0.00456, val_loss=0.00684]Epoch 12:  55%|█████▌    | 16/29 [00:00<00:00, 151.42it/s, train_loss=0.00456, val_loss=0.00684]Epoch 12:  55%|█████▌    | 16/29 [00:00<00:00, 146.41it/s, train_loss=0.0048, val_loss=0.00684] Epoch 12:  59%|█████▊    | 17/29 [00:00<00:00, 150.78it/s, train_loss=0.0048, val_loss=0.00684]Epoch 12:  59%|█████▊    | 17/29 [00:00<00:00, 146.15it/s, train_loss=0.00665, val_loss=0.00684]Epoch 12:  62%|██████▏   | 18/29 [00:00<00:00, 150.23it/s, train_loss=0.00665, val_loss=0.00684]Epoch 12:  62%|██████▏   | 18/29 [00:00<00:00, 145.88it/s, train_loss=0.00504, val_loss=0.00684]Epoch 12:  66%|██████▌   | 19/29 [00:00<00:00, 149.71it/s, train_loss=0.00504, val_loss=0.00684]Epoch 12:  66%|██████▌   | 19/29 [00:00<00:00, 145.69it/s, train_loss=0.00699, val_loss=0.00684]Epoch 12:  69%|██████▉   | 20/29 [00:00<00:00, 149.34it/s, train_loss=0.00699, val_loss=0.00684]Epoch 12:  69%|██████▉   | 20/29 [00:00<00:00, 147.51it/s, train_loss=0.00639, val_loss=0.00684]Epoch 12:  72%|███████▏  | 21/29 [00:00<00:00, 150.71it/s, train_loss=0.00639, val_loss=0.00684]Epoch 12:  72%|███████▏  | 21/29 [00:00<00:00, 146.49it/s, train_loss=0.00673, val_loss=0.00684]Epoch 12:  76%|███████▌  | 22/29 [00:00<00:00, 149.64it/s, train_loss=0.00673, val_loss=0.00684]Epoch 12:  76%|███████▌  | 22/29 [00:00<00:00, 146.32it/s, train_loss=0.0072, val_loss=0.00684] Epoch 12:  79%|███████▉  | 23/29 [00:00<00:00, 149.31it/s, train_loss=0.0072, val_loss=0.00684]Epoch 12:  79%|███████▉  | 23/29 [00:00<00:00, 146.15it/s, train_loss=0.0063, val_loss=0.00684]Epoch 12:  83%|████████▎ | 24/29 [00:00<00:00, 148.98it/s, train_loss=0.0063, val_loss=0.00684]Epoch 12:  83%|████████▎ | 24/29 [00:00<00:00, 146.02it/s, train_loss=0.00408, val_loss=0.00684]Epoch 12:  86%|████████▌ | 25/29 [00:00<00:00, 148.65it/s, train_loss=0.00408, val_loss=0.00684]Epoch 12:  86%|████████▌ | 25/29 [00:00<00:00, 145.92it/s, train_loss=0.00675, val_loss=0.00684]Epoch 12:  90%|████████▉ | 26/29 [00:00<00:00, 148.33it/s, train_loss=0.00675, val_loss=0.00684]Epoch 12:  90%|████████▉ | 26/29 [00:00<00:00, 147.54it/s, train_loss=0.00751, val_loss=0.00684]Epoch 12:  93%|█████████▎| 27/29 [00:00<00:00, 149.94it/s, train_loss=0.00751, val_loss=0.00684]Epoch 12:  93%|█████████▎| 27/29 [00:00<00:00, 147.32it/s, train_loss=0.00669, val_loss=0.00684]Epoch 12:  97%|█████████▋| 28/29 [00:00<00:00, 149.76it/s, train_loss=0.00669, val_loss=0.00684]Epoch 12:  97%|█████████▋| 28/29 [00:00<00:00, 147.13it/s, train_loss=0.00468, val_loss=0.00684]Epoch 12: 100%|██████████| 29/29 [00:00<00:00, 149.56it/s, train_loss=0.00468, val_loss=0.00684]Epoch 12: 100%|██████████| 29/29 [00:00<00:00, 148.88it/s, train_loss=0.00501, val_loss=0.00684]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 151.80it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 186.40it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 204.64it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 216.65it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 223.88it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 227.60it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 236.46it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 247.97it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 258.91it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 266.64it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 273.25it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 278.90it/s][A
                                                                         [AEpoch 12: 100%|██████████| 29/29 [00:00<00:00, 118.70it/s, train_loss=0.00501, val_loss=0.00641]Epoch 12: 100%|██████████| 29/29 [00:00<00:00, 118.37it/s, train_loss=0.00501, val_loss=0.00641]Epoch 12:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00501, val_loss=0.00641]          Epoch 13:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00501, val_loss=0.00641]Epoch 13:   3%|▎         | 1/29 [00:00<00:00, 212.00it/s, train_loss=0.00501, val_loss=0.00641]Epoch 13:   3%|▎         | 1/29 [00:00<00:00, 106.20it/s, train_loss=0.0105, val_loss=0.00641] Epoch 13:   7%|▋         | 2/29 [00:00<00:00, 152.01it/s, train_loss=0.0105, val_loss=0.00641]Epoch 13:   7%|▋         | 2/29 [00:00<00:00, 121.43it/s, train_loss=0.00567, val_loss=0.00641]Epoch 13:  10%|█         | 3/29 [00:00<00:00, 148.85it/s, train_loss=0.00567, val_loss=0.00641]Epoch 13:  10%|█         | 3/29 [00:00<00:00, 127.53it/s, train_loss=0.00654, val_loss=0.00641]Epoch 13:  14%|█▍        | 4/29 [00:00<00:00, 142.86it/s, train_loss=0.00654, val_loss=0.00641]Epoch 13:  14%|█▍        | 4/29 [00:00<00:00, 122.67it/s, train_loss=0.00453, val_loss=0.00641]Epoch 13:  17%|█▋        | 5/29 [00:00<00:00, 136.58it/s, train_loss=0.00453, val_loss=0.00641]Epoch 13:  17%|█▋        | 5/29 [00:00<00:00, 126.29it/s, train_loss=0.00596, val_loss=0.00641]Epoch 13:  21%|██        | 6/29 [00:00<00:00, 138.11it/s, train_loss=0.00596, val_loss=0.00641]Epoch 13:  21%|██        | 6/29 [00:00<00:00, 128.61it/s, train_loss=0.00536, val_loss=0.00641]Epoch 13:  24%|██▍       | 7/29 [00:00<00:00, 138.87it/s, train_loss=0.00536, val_loss=0.00641]Epoch 13:  24%|██▍       | 7/29 [00:00<00:00, 130.32it/s, train_loss=0.00514, val_loss=0.00641]Epoch 13:  28%|██▊       | 8/29 [00:00<00:00, 139.45it/s, train_loss=0.00514, val_loss=0.00641]Epoch 13:  28%|██▊       | 8/29 [00:00<00:00, 131.78it/s, train_loss=0.00524, val_loss=0.00641]Epoch 13:  31%|███       | 9/29 [00:00<00:00, 139.83it/s, train_loss=0.00524, val_loss=0.00641]Epoch 13:  31%|███       | 9/29 [00:00<00:00, 136.74it/s, train_loss=0.00439, val_loss=0.00641]Epoch 13:  34%|███▍      | 10/29 [00:00<00:00, 142.98it/s, train_loss=0.00439, val_loss=0.00641]Epoch 13:  34%|███▍      | 10/29 [00:00<00:00, 135.82it/s, train_loss=0.00608, val_loss=0.00641]Epoch 13:  38%|███▊      | 11/29 [00:00<00:00, 141.81it/s, train_loss=0.00608, val_loss=0.00641]Epoch 13:  38%|███▊      | 11/29 [00:00<00:00, 136.47it/s, train_loss=0.00522, val_loss=0.00641]Epoch 13:  41%|████▏     | 12/29 [00:00<00:00, 142.25it/s, train_loss=0.00522, val_loss=0.00641]Epoch 13:  41%|████▏     | 12/29 [00:00<00:00, 136.87it/s, train_loss=0.00517, val_loss=0.00641]Epoch 13:  45%|████▍     | 13/29 [00:00<00:00, 142.21it/s, train_loss=0.00517, val_loss=0.00641]Epoch 13:  45%|████▍     | 13/29 [00:00<00:00, 137.34it/s, train_loss=0.00444, val_loss=0.00641]Epoch 13:  48%|████▊     | 14/29 [00:00<00:00, 142.23it/s, train_loss=0.00444, val_loss=0.00641]Epoch 13:  48%|████▊     | 14/29 [00:00<00:00, 137.80it/s, train_loss=0.00519, val_loss=0.00641]Epoch 13:  52%|█████▏    | 15/29 [00:00<00:00, 141.66it/s, train_loss=0.00519, val_loss=0.00641]Epoch 13:  52%|█████▏    | 15/29 [00:00<00:00, 137.98it/s, train_loss=0.00662, val_loss=0.00641]Epoch 13:  55%|█████▌    | 16/29 [00:00<00:00, 141.59it/s, train_loss=0.00662, val_loss=0.00641]Epoch 13:  55%|█████▌    | 16/29 [00:00<00:00, 138.23it/s, train_loss=0.00452, val_loss=0.00641]Epoch 13:  59%|█████▊    | 17/29 [00:00<00:00, 142.68it/s, train_loss=0.00452, val_loss=0.00641]Epoch 13:  59%|█████▊    | 17/29 [00:00<00:00, 138.52it/s, train_loss=0.0048, val_loss=0.00641] Epoch 13:  62%|██████▏   | 18/29 [00:00<00:00, 142.54it/s, train_loss=0.0048, val_loss=0.00641]Epoch 13:  62%|██████▏   | 18/29 [00:00<00:00, 138.69it/s, train_loss=0.00542, val_loss=0.00641]Epoch 13:  66%|██████▌   | 19/29 [00:00<00:00, 142.48it/s, train_loss=0.00542, val_loss=0.00641]Epoch 13:  66%|██████▌   | 19/29 [00:00<00:00, 138.89it/s, train_loss=0.00458, val_loss=0.00641]Epoch 13:  69%|██████▉   | 20/29 [00:00<00:00, 142.54it/s, train_loss=0.00458, val_loss=0.00641]Epoch 13:  69%|██████▉   | 20/29 [00:00<00:00, 139.17it/s, train_loss=0.00455, val_loss=0.00641]Epoch 13:  72%|███████▏  | 21/29 [00:00<00:00, 142.21it/s, train_loss=0.00455, val_loss=0.00641]Epoch 13:  72%|███████▏  | 21/29 [00:00<00:00, 138.61it/s, train_loss=0.00621, val_loss=0.00641]Epoch 13:  76%|███████▌  | 22/29 [00:00<00:00, 141.68it/s, train_loss=0.00621, val_loss=0.00641]Epoch 13:  76%|███████▌  | 22/29 [00:00<00:00, 138.76it/s, train_loss=0.00643, val_loss=0.00641]Epoch 13:  79%|███████▉  | 23/29 [00:00<00:00, 141.81it/s, train_loss=0.00643, val_loss=0.00641]Epoch 13:  79%|███████▉  | 23/29 [00:00<00:00, 138.89it/s, train_loss=0.00544, val_loss=0.00641]Epoch 13:  83%|████████▎ | 24/29 [00:00<00:00, 141.75it/s, train_loss=0.00544, val_loss=0.00641]Epoch 13:  83%|████████▎ | 24/29 [00:00<00:00, 139.03it/s, train_loss=0.00575, val_loss=0.00641]Epoch 13:  86%|████████▌ | 25/29 [00:00<00:00, 141.82it/s, train_loss=0.00575, val_loss=0.00641]Epoch 13:  86%|████████▌ | 25/29 [00:00<00:00, 139.20it/s, train_loss=0.00541, val_loss=0.00641]Epoch 13:  90%|████████▉ | 26/29 [00:00<00:00, 141.81it/s, train_loss=0.00541, val_loss=0.00641]Epoch 13:  90%|████████▉ | 26/29 [00:00<00:00, 140.90it/s, train_loss=0.00511, val_loss=0.00641]Epoch 13:  93%|█████████▎| 27/29 [00:00<00:00, 143.06it/s, train_loss=0.00511, val_loss=0.00641]Epoch 13:  93%|█████████▎| 27/29 [00:00<00:00, 140.37it/s, train_loss=0.00586, val_loss=0.00641]Epoch 13:  97%|█████████▋| 28/29 [00:00<00:00, 142.68it/s, train_loss=0.00586, val_loss=0.00641]Epoch 13:  97%|█████████▋| 28/29 [00:00<00:00, 140.45it/s, train_loss=0.00614, val_loss=0.00641]Epoch 13: 100%|██████████| 29/29 [00:00<00:00, 142.85it/s, train_loss=0.00614, val_loss=0.00641]Epoch 13: 100%|██████████| 29/29 [00:00<00:00, 142.19it/s, train_loss=0.00333, val_loss=0.00641]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 148.59it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 183.30it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 181.83it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 195.46it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 205.46it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 211.41it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 215.18it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 218.07it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 221.90it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 231.50it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 239.88it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 247.88it/s][A
                                                                         [AEpoch 13: 100%|██████████| 29/29 [00:00<00:00, 111.24it/s, train_loss=0.00333, val_loss=0.00592]Epoch 13: 100%|██████████| 29/29 [00:00<00:00, 110.92it/s, train_loss=0.00333, val_loss=0.00592]Epoch 13:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00333, val_loss=0.00592]          Epoch 14:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00333, val_loss=0.00592]Epoch 14:   3%|▎         | 1/29 [00:00<00:00, 220.59it/s, train_loss=0.00333, val_loss=0.00592]Epoch 14:   3%|▎         | 1/29 [00:00<00:00, 107.30it/s, train_loss=0.00862, val_loss=0.00592]Epoch 14:   7%|▋         | 2/29 [00:00<00:00, 147.17it/s, train_loss=0.00862, val_loss=0.00592]Epoch 14:   7%|▋         | 2/29 [00:00<00:00, 125.08it/s, train_loss=0.00382, val_loss=0.00592]Epoch 14:  10%|█         | 3/29 [00:00<00:00, 148.98it/s, train_loss=0.00382, val_loss=0.00592]Epoch 14:  10%|█         | 3/29 [00:00<00:00, 130.03it/s, train_loss=0.00502, val_loss=0.00592]Epoch 14:  14%|█▍        | 4/29 [00:00<00:00, 148.81it/s, train_loss=0.00502, val_loss=0.00592]Epoch 14:  14%|█▍        | 4/29 [00:00<00:00, 132.53it/s, train_loss=0.00648, val_loss=0.00592]Epoch 14:  17%|█▋        | 5/29 [00:00<00:00, 147.79it/s, train_loss=0.00648, val_loss=0.00592]Epoch 14:  17%|█▋        | 5/29 [00:00<00:00, 134.11it/s, train_loss=0.00593, val_loss=0.00592]Epoch 14:  21%|██        | 6/29 [00:00<00:00, 146.30it/s, train_loss=0.00593, val_loss=0.00592]Epoch 14:  21%|██        | 6/29 [00:00<00:00, 135.37it/s, train_loss=0.00607, val_loss=0.00592]Epoch 14:  24%|██▍       | 7/29 [00:00<00:00, 145.46it/s, train_loss=0.00607, val_loss=0.00592]Epoch 14:  24%|██▍       | 7/29 [00:00<00:00, 136.33it/s, train_loss=0.00555, val_loss=0.00592]Epoch 14:  28%|██▊       | 8/29 [00:00<00:00, 143.48it/s, train_loss=0.00555, val_loss=0.00592]Epoch 14:  28%|██▊       | 8/29 [00:00<00:00, 132.57it/s, train_loss=0.00572, val_loss=0.00592]Epoch 14:  31%|███       | 9/29 [00:00<00:00, 140.07it/s, train_loss=0.00572, val_loss=0.00592]Epoch 14:  31%|███       | 9/29 [00:00<00:00, 133.59it/s, train_loss=0.00558, val_loss=0.00592]Epoch 14:  34%|███▍      | 10/29 [00:00<00:00, 140.64it/s, train_loss=0.00558, val_loss=0.00592]Epoch 14:  34%|███▍      | 10/29 [00:00<00:00, 134.41it/s, train_loss=0.00386, val_loss=0.00592]Epoch 14:  38%|███▊      | 11/29 [00:00<00:00, 140.95it/s, train_loss=0.00386, val_loss=0.00592]Epoch 14:  38%|███▊      | 11/29 [00:00<00:00, 135.13it/s, train_loss=0.00574, val_loss=0.00592]Epoch 14:  41%|████▏     | 12/29 [00:00<00:00, 141.01it/s, train_loss=0.00574, val_loss=0.00592]Epoch 14:  41%|████▏     | 12/29 [00:00<00:00, 135.75it/s, train_loss=0.00421, val_loss=0.00592]Epoch 14:  45%|████▍     | 13/29 [00:00<00:00, 140.58it/s, train_loss=0.00421, val_loss=0.00592]Epoch 14:  45%|████▍     | 13/29 [00:00<00:00, 139.29it/s, train_loss=0.00428, val_loss=0.00592]Epoch 14:  48%|████▊     | 14/29 [00:00<00:00, 143.61it/s, train_loss=0.00428, val_loss=0.00592]Epoch 14:  48%|████▊     | 14/29 [00:00<00:00, 139.53it/s, train_loss=0.00602, val_loss=0.00592]Epoch 14:  52%|█████▏    | 15/29 [00:00<00:00, 144.14it/s, train_loss=0.00602, val_loss=0.00592]Epoch 14:  52%|█████▏    | 15/29 [00:00<00:00, 139.70it/s, train_loss=0.00467, val_loss=0.00592]Epoch 14:  55%|█████▌    | 16/29 [00:00<00:00, 143.86it/s, train_loss=0.00467, val_loss=0.00592]Epoch 14:  55%|█████▌    | 16/29 [00:00<00:00, 139.85it/s, train_loss=0.00506, val_loss=0.00592]Epoch 14:  59%|█████▊    | 17/29 [00:00<00:00, 144.30it/s, train_loss=0.00506, val_loss=0.00592]Epoch 14:  59%|█████▊    | 17/29 [00:00<00:00, 139.95it/s, train_loss=0.00788, val_loss=0.00592]Epoch 14:  62%|██████▏   | 18/29 [00:00<00:00, 144.12it/s, train_loss=0.00788, val_loss=0.00592]Epoch 14:  62%|██████▏   | 18/29 [00:00<00:00, 140.12it/s, train_loss=0.00357, val_loss=0.00592]Epoch 14:  66%|██████▌   | 19/29 [00:00<00:00, 144.01it/s, train_loss=0.00357, val_loss=0.00592]Epoch 14:  66%|██████▌   | 19/29 [00:00<00:00, 142.49it/s, train_loss=0.00389, val_loss=0.00592]Epoch 14:  69%|██████▉   | 20/29 [00:00<00:00, 145.59it/s, train_loss=0.00389, val_loss=0.00592]Epoch 14:  69%|██████▉   | 20/29 [00:00<00:00, 141.62it/s, train_loss=0.00518, val_loss=0.00592]Epoch 14:  72%|███████▏  | 21/29 [00:00<00:00, 144.86it/s, train_loss=0.00518, val_loss=0.00592]Epoch 14:  72%|███████▏  | 21/29 [00:00<00:00, 141.70it/s, train_loss=0.0041, val_loss=0.00592] Epoch 14:  76%|███████▌  | 22/29 [00:00<00:00, 144.93it/s, train_loss=0.0041, val_loss=0.00592]Epoch 14:  76%|███████▌  | 22/29 [00:00<00:00, 141.70it/s, train_loss=0.00486, val_loss=0.00592]Epoch 14:  79%|███████▉  | 23/29 [00:00<00:00, 144.67it/s, train_loss=0.00486, val_loss=0.00592]Epoch 14:  79%|███████▉  | 23/29 [00:00<00:00, 141.73it/s, train_loss=0.0068, val_loss=0.00592] Epoch 14:  83%|████████▎ | 24/29 [00:00<00:00, 144.68it/s, train_loss=0.0068, val_loss=0.00592]Epoch 14:  83%|████████▎ | 24/29 [00:00<00:00, 141.79it/s, train_loss=0.00422, val_loss=0.00592]Epoch 14:  86%|████████▌ | 25/29 [00:00<00:00, 144.29it/s, train_loss=0.00422, val_loss=0.00592]Epoch 14:  86%|████████▌ | 25/29 [00:00<00:00, 143.69it/s, train_loss=0.00502, val_loss=0.00592]Epoch 14:  90%|████████▉ | 26/29 [00:00<00:00, 146.05it/s, train_loss=0.00502, val_loss=0.00592]Epoch 14:  90%|████████▉ | 26/29 [00:00<00:00, 143.64it/s, train_loss=0.00477, val_loss=0.00592]Epoch 14:  93%|█████████▎| 27/29 [00:00<00:00, 146.26it/s, train_loss=0.00477, val_loss=0.00592]Epoch 14:  93%|█████████▎| 27/29 [00:00<00:00, 143.60it/s, train_loss=0.00426, val_loss=0.00592]Epoch 14:  97%|█████████▋| 28/29 [00:00<00:00, 145.99it/s, train_loss=0.00426, val_loss=0.00592]Epoch 14:  97%|█████████▋| 28/29 [00:00<00:00, 143.54it/s, train_loss=0.00438, val_loss=0.00592]Epoch 14: 100%|██████████| 29/29 [00:00<00:00, 145.91it/s, train_loss=0.00438, val_loss=0.00592]Epoch 14: 100%|██████████| 29/29 [00:00<00:00, 145.24it/s, train_loss=0.00297, val_loss=0.00592]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 150.29it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 191.56it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 211.73it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 222.24it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 227.32it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 230.65it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 233.49it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 234.99it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 234.95it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 236.16it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 242.49it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 250.12it/s][A
                                                                         [AEpoch 14: 100%|██████████| 29/29 [00:00<00:00, 114.12it/s, train_loss=0.00297, val_loss=0.0056] Epoch 14: 100%|██████████| 29/29 [00:00<00:00, 113.81it/s, train_loss=0.00297, val_loss=0.0056]Epoch 14:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.0056]          Epoch 15:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.0056]Epoch 15:   3%|▎         | 1/29 [00:00<00:00, 232.32it/s, train_loss=0.00297, val_loss=0.0056]Epoch 15:   3%|▎         | 1/29 [00:00<00:00, 143.09it/s, train_loss=0.00563, val_loss=0.0056]Epoch 15:   7%|▋         | 2/29 [00:00<00:00, 180.12it/s, train_loss=0.00563, val_loss=0.0056]Epoch 15:   7%|▋         | 2/29 [00:00<00:00, 149.15it/s, train_loss=0.00626, val_loss=0.0056]Epoch 15:  10%|█         | 3/29 [00:00<00:00, 172.82it/s, train_loss=0.00626, val_loss=0.0056]Epoch 15:  10%|█         | 3/29 [00:00<00:00, 146.20it/s, train_loss=0.0044, val_loss=0.0056] Epoch 15:  14%|█▍        | 4/29 [00:00<00:00, 165.92it/s, train_loss=0.0044, val_loss=0.0056]Epoch 15:  14%|█▍        | 4/29 [00:00<00:00, 144.90it/s, train_loss=0.00722, val_loss=0.0056]Epoch 15:  17%|█▋        | 5/29 [00:00<00:00, 159.74it/s, train_loss=0.00722, val_loss=0.0056]Epoch 15:  17%|█▋        | 5/29 [00:00<00:00, 143.91it/s, train_loss=0.00504, val_loss=0.0056]Epoch 15:  21%|██        | 6/29 [00:00<00:00, 156.15it/s, train_loss=0.00504, val_loss=0.0056]Epoch 15:  21%|██        | 6/29 [00:00<00:00, 143.68it/s, train_loss=0.00502, val_loss=0.0056]Epoch 15:  24%|██▍       | 7/29 [00:00<00:00, 154.42it/s, train_loss=0.00502, val_loss=0.0056]Epoch 15:  24%|██▍       | 7/29 [00:00<00:00, 143.54it/s, train_loss=0.00438, val_loss=0.0056]Epoch 15:  28%|██▊       | 8/29 [00:00<00:00, 151.12it/s, train_loss=0.00438, val_loss=0.0056]Epoch 15:  28%|██▊       | 8/29 [00:00<00:00, 139.33it/s, train_loss=0.00696, val_loss=0.0056]Epoch 15:  31%|███       | 9/29 [00:00<00:00, 146.75it/s, train_loss=0.00696, val_loss=0.0056]Epoch 15:  31%|███       | 9/29 [00:00<00:00, 139.69it/s, train_loss=0.00573, val_loss=0.0056]Epoch 15:  34%|███▍      | 10/29 [00:00<00:00, 146.54it/s, train_loss=0.00573, val_loss=0.0056]Epoch 15:  34%|███▍      | 10/29 [00:00<00:00, 139.95it/s, train_loss=0.00588, val_loss=0.0056]Epoch 15:  38%|███▊      | 11/29 [00:00<00:00, 146.14it/s, train_loss=0.00588, val_loss=0.0056]Epoch 15:  38%|███▊      | 11/29 [00:00<00:00, 140.25it/s, train_loss=0.00348, val_loss=0.0056]Epoch 15:  41%|████▏     | 12/29 [00:00<00:00, 146.08it/s, train_loss=0.00348, val_loss=0.0056]Epoch 15:  41%|████▏     | 12/29 [00:00<00:00, 140.51it/s, train_loss=0.00593, val_loss=0.0056]Epoch 15:  45%|████▍     | 13/29 [00:00<00:00, 145.81it/s, train_loss=0.00593, val_loss=0.0056]Epoch 15:  45%|████▍     | 13/29 [00:00<00:00, 143.78it/s, train_loss=0.005, val_loss=0.0056]  Epoch 15:  48%|████▊     | 14/29 [00:00<00:00, 147.94it/s, train_loss=0.005, val_loss=0.0056]Epoch 15:  48%|████▊     | 14/29 [00:00<00:00, 142.43it/s, train_loss=0.00478, val_loss=0.0056]Epoch 15:  52%|█████▏    | 15/29 [00:00<00:00, 146.66it/s, train_loss=0.00478, val_loss=0.0056]Epoch 15:  52%|█████▏    | 15/29 [00:00<00:00, 142.51it/s, train_loss=0.00359, val_loss=0.0056]Epoch 15:  55%|█████▌    | 16/29 [00:00<00:00, 146.64it/s, train_loss=0.00359, val_loss=0.0056]Epoch 15:  55%|█████▌    | 16/29 [00:00<00:00, 142.48it/s, train_loss=0.00578, val_loss=0.0056]Epoch 15:  59%|█████▊    | 17/29 [00:00<00:00, 146.38it/s, train_loss=0.00578, val_loss=0.0056]Epoch 15:  59%|█████▊    | 17/29 [00:00<00:00, 142.50it/s, train_loss=0.00427, val_loss=0.0056]Epoch 15:  62%|██████▏   | 18/29 [00:00<00:00, 146.13it/s, train_loss=0.00427, val_loss=0.0056]Epoch 15:  62%|██████▏   | 18/29 [00:00<00:00, 142.58it/s, train_loss=0.00497, val_loss=0.0056]Epoch 15:  66%|██████▌   | 19/29 [00:00<00:00, 145.79it/s, train_loss=0.00497, val_loss=0.0056]Epoch 15:  66%|██████▌   | 19/29 [00:00<00:00, 144.87it/s, train_loss=0.00347, val_loss=0.0056]Epoch 15:  69%|██████▉   | 20/29 [00:00<00:00, 148.13it/s, train_loss=0.00347, val_loss=0.0056]Epoch 15:  69%|██████▉   | 20/29 [00:00<00:00, 144.72it/s, train_loss=0.00565, val_loss=0.0056]Epoch 15:  72%|███████▏  | 21/29 [00:00<00:00, 148.31it/s, train_loss=0.00565, val_loss=0.0056]Epoch 15:  72%|███████▏  | 21/29 [00:00<00:00, 144.56it/s, train_loss=0.00361, val_loss=0.0056]Epoch 15:  76%|███████▌  | 22/29 [00:00<00:00, 147.84it/s, train_loss=0.00361, val_loss=0.0056]Epoch 15:  76%|███████▌  | 22/29 [00:00<00:00, 144.44it/s, train_loss=0.00437, val_loss=0.0056]Epoch 15:  79%|███████▉  | 23/29 [00:00<00:00, 147.47it/s, train_loss=0.00437, val_loss=0.0056]Epoch 15:  79%|███████▉  | 23/29 [00:00<00:00, 144.34it/s, train_loss=0.00476, val_loss=0.0056]Epoch 15:  83%|████████▎ | 24/29 [00:00<00:00, 147.17it/s, train_loss=0.00476, val_loss=0.0056]Epoch 15:  83%|████████▎ | 24/29 [00:00<00:00, 144.30it/s, train_loss=0.00421, val_loss=0.0056]Epoch 15:  86%|████████▌ | 25/29 [00:00<00:00, 146.83it/s, train_loss=0.00421, val_loss=0.0056]Epoch 15:  86%|████████▌ | 25/29 [00:00<00:00, 146.20it/s, train_loss=0.00462, val_loss=0.0056]Epoch 15:  90%|████████▉ | 26/29 [00:00<00:00, 148.62it/s, train_loss=0.00462, val_loss=0.0056]Epoch 15:  90%|████████▉ | 26/29 [00:00<00:00, 146.05it/s, train_loss=0.00505, val_loss=0.0056]Epoch 15:  93%|█████████▎| 27/29 [00:00<00:00, 148.75it/s, train_loss=0.00505, val_loss=0.0056]Epoch 15:  93%|█████████▎| 27/29 [00:00<00:00, 145.90it/s, train_loss=0.00465, val_loss=0.0056]Epoch 15:  97%|█████████▋| 28/29 [00:00<00:00, 148.33it/s, train_loss=0.00465, val_loss=0.0056]Epoch 15:  97%|█████████▋| 28/29 [00:00<00:00, 145.74it/s, train_loss=0.00425, val_loss=0.0056]Epoch 15: 100%|██████████| 29/29 [00:00<00:00, 147.10it/s, train_loss=0.00425, val_loss=0.0056]Epoch 15: 100%|██████████| 29/29 [00:00<00:00, 146.03it/s, train_loss=0.00346, val_loss=0.0056]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 168.34it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 206.70it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 220.22it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 219.64it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 227.74it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 233.87it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 237.09it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 238.89it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 240.30it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 242.40it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 243.36it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 244.01it/s][A
                                                                         [AEpoch 15: 100%|██████████| 29/29 [00:00<00:00, 112.78it/s, train_loss=0.00346, val_loss=0.00531]Epoch 15: 100%|██████████| 29/29 [00:00<00:00, 112.52it/s, train_loss=0.00346, val_loss=0.00531]Epoch 15:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00346, val_loss=0.00531]          Epoch 16:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00346, val_loss=0.00531]Epoch 16:   3%|▎         | 1/29 [00:00<00:00, 185.82it/s, train_loss=0.00346, val_loss=0.00531]Epoch 16:   3%|▎         | 1/29 [00:00<00:00, 107.17it/s, train_loss=0.00398, val_loss=0.00531]Epoch 16:   7%|▋         | 2/29 [00:00<00:00, 153.11it/s, train_loss=0.00398, val_loss=0.00531]Epoch 16:   7%|▋         | 2/29 [00:00<00:00, 121.93it/s, train_loss=0.00675, val_loss=0.00531]Epoch 16:  10%|█         | 3/29 [00:00<00:00, 151.05it/s, train_loss=0.00675, val_loss=0.00531]Epoch 16:  10%|█         | 3/29 [00:00<00:00, 127.25it/s, train_loss=0.00435, val_loss=0.00531]Epoch 16:  14%|█▍        | 4/29 [00:00<00:00, 147.22it/s, train_loss=0.00435, val_loss=0.00531]Epoch 16:  14%|█▍        | 4/29 [00:00<00:00, 130.27it/s, train_loss=0.00553, val_loss=0.00531]Epoch 16:  17%|█▋        | 5/29 [00:00<00:00, 145.68it/s, train_loss=0.00553, val_loss=0.00531]Epoch 16:  17%|█▋        | 5/29 [00:00<00:00, 132.45it/s, train_loss=0.0041, val_loss=0.00531] Epoch 16:  21%|██        | 6/29 [00:00<00:00, 145.20it/s, train_loss=0.0041, val_loss=0.00531]Epoch 16:  21%|██        | 6/29 [00:00<00:00, 139.70it/s, train_loss=0.0046, val_loss=0.00531]Epoch 16:  24%|██▍       | 7/29 [00:00<00:00, 148.76it/s, train_loss=0.0046, val_loss=0.00531]Epoch 16:  24%|██▍       | 7/29 [00:00<00:00, 137.90it/s, train_loss=0.00394, val_loss=0.00531]Epoch 16:  28%|██▊       | 8/29 [00:00<00:00, 146.58it/s, train_loss=0.00394, val_loss=0.00531]Epoch 16:  28%|██▊       | 8/29 [00:00<00:00, 138.46it/s, train_loss=0.00485, val_loss=0.00531]Epoch 16:  31%|███       | 9/29 [00:00<00:00, 146.35it/s, train_loss=0.00485, val_loss=0.00531]Epoch 16:  31%|███       | 9/29 [00:00<00:00, 138.90it/s, train_loss=0.00557, val_loss=0.00531]Epoch 16:  34%|███▍      | 10/29 [00:00<00:00, 146.08it/s, train_loss=0.00557, val_loss=0.00531]Epoch 16:  34%|███▍      | 10/29 [00:00<00:00, 139.20it/s, train_loss=0.0063, val_loss=0.00531] Epoch 16:  38%|███▊      | 11/29 [00:00<00:00, 145.65it/s, train_loss=0.0063, val_loss=0.00531]Epoch 16:  38%|███▊      | 11/29 [00:00<00:00, 139.52it/s, train_loss=0.0044, val_loss=0.00531]Epoch 16:  41%|████▏     | 12/29 [00:00<00:00, 145.32it/s, train_loss=0.0044, val_loss=0.00531]Epoch 16:  41%|████▏     | 12/29 [00:00<00:00, 143.31it/s, train_loss=0.00295, val_loss=0.00531]Epoch 16:  45%|████▍     | 13/29 [00:00<00:00, 147.98it/s, train_loss=0.00295, val_loss=0.00531]Epoch 16:  45%|████▍     | 13/29 [00:00<00:00, 141.98it/s, train_loss=0.00441, val_loss=0.00531]Epoch 16:  48%|████▊     | 14/29 [00:00<00:00, 146.67it/s, train_loss=0.00441, val_loss=0.00531]Epoch 16:  48%|████▊     | 14/29 [00:00<00:00, 142.03it/s, train_loss=0.00515, val_loss=0.00531]Epoch 16:  52%|█████▏    | 15/29 [00:00<00:00, 146.53it/s, train_loss=0.00515, val_loss=0.00531]Epoch 16:  52%|█████▏    | 15/29 [00:00<00:00, 142.05it/s, train_loss=0.00432, val_loss=0.00531]Epoch 16:  55%|█████▌    | 16/29 [00:00<00:00, 146.24it/s, train_loss=0.00432, val_loss=0.00531]Epoch 16:  55%|█████▌    | 16/29 [00:00<00:00, 142.15it/s, train_loss=0.00465, val_loss=0.00531]Epoch 16:  59%|█████▊    | 17/29 [00:00<00:00, 145.94it/s, train_loss=0.00465, val_loss=0.00531]Epoch 16:  59%|█████▊    | 17/29 [00:00<00:00, 142.29it/s, train_loss=0.00349, val_loss=0.00531]Epoch 16:  62%|██████▏   | 18/29 [00:00<00:00, 145.47it/s, train_loss=0.00349, val_loss=0.00531]Epoch 16:  62%|██████▏   | 18/29 [00:00<00:00, 144.42it/s, train_loss=0.00382, val_loss=0.00531]Epoch 16:  66%|██████▌   | 19/29 [00:00<00:00, 147.50it/s, train_loss=0.00382, val_loss=0.00531]Epoch 16:  66%|██████▌   | 19/29 [00:00<00:00, 144.55it/s, train_loss=0.00385, val_loss=0.00531]Epoch 16:  69%|██████▉   | 20/29 [00:00<00:00, 148.35it/s, train_loss=0.00385, val_loss=0.00531]Epoch 16:  69%|██████▉   | 20/29 [00:00<00:00, 144.43it/s, train_loss=0.00549, val_loss=0.00531]Epoch 16:  72%|███████▏  | 21/29 [00:00<00:00, 147.99it/s, train_loss=0.00549, val_loss=0.00531]Epoch 16:  72%|███████▏  | 21/29 [00:00<00:00, 144.31it/s, train_loss=0.00352, val_loss=0.00531]Epoch 16:  76%|███████▌  | 22/29 [00:00<00:00, 147.67it/s, train_loss=0.00352, val_loss=0.00531]Epoch 16:  76%|███████▌  | 22/29 [00:00<00:00, 144.20it/s, train_loss=0.00478, val_loss=0.00531]Epoch 16:  79%|███████▉  | 23/29 [00:00<00:00, 147.32it/s, train_loss=0.00478, val_loss=0.00531]Epoch 16:  79%|███████▉  | 23/29 [00:00<00:00, 144.16it/s, train_loss=0.006, val_loss=0.00531]  Epoch 16:  83%|████████▎ | 24/29 [00:00<00:00, 146.93it/s, train_loss=0.006, val_loss=0.00531]Epoch 16:  83%|████████▎ | 24/29 [00:00<00:00, 144.17it/s, train_loss=0.00394, val_loss=0.00531]Epoch 16:  86%|████████▌ | 25/29 [00:00<00:00, 146.69it/s, train_loss=0.00394, val_loss=0.00531]Epoch 16:  86%|████████▌ | 25/29 [00:00<00:00, 144.10it/s, train_loss=0.00717, val_loss=0.00531]Epoch 16:  90%|████████▉ | 26/29 [00:00<00:00, 146.82it/s, train_loss=0.00717, val_loss=0.00531]Epoch 16:  90%|████████▉ | 26/29 [00:00<00:00, 144.07it/s, train_loss=0.00397, val_loss=0.00531]Epoch 16:  93%|█████████▎| 27/29 [00:00<00:00, 146.61it/s, train_loss=0.00397, val_loss=0.00531]Epoch 16:  93%|█████████▎| 27/29 [00:00<00:00, 144.00it/s, train_loss=0.004, val_loss=0.00531]  Epoch 16:  97%|█████████▋| 28/29 [00:00<00:00, 146.55it/s, train_loss=0.004, val_loss=0.00531]Epoch 16:  97%|█████████▋| 28/29 [00:00<00:00, 143.94it/s, train_loss=0.00448, val_loss=0.00531]Epoch 16: 100%|██████████| 29/29 [00:00<00:00, 146.35it/s, train_loss=0.00448, val_loss=0.00531]Epoch 16: 100%|██████████| 29/29 [00:00<00:00, 145.68it/s, train_loss=0.00157, val_loss=0.00531]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 181.62it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 216.05it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 230.73it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 236.30it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 239.61it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 241.97it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 243.30it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 245.04it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 247.35it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 248.50it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 248.64it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 249.07it/s][A
                                                                         [AEpoch 16: 100%|██████████| 29/29 [00:00<00:00, 112.67it/s, train_loss=0.00157, val_loss=0.00507]Epoch 16: 100%|██████████| 29/29 [00:00<00:00, 112.16it/s, train_loss=0.00157, val_loss=0.00507]Epoch 16:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00157, val_loss=0.00507]          Epoch 17:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00157, val_loss=0.00507]Epoch 17:   3%|▎         | 1/29 [00:00<00:00, 206.50it/s, train_loss=0.00157, val_loss=0.00507]Epoch 17:   3%|▎         | 1/29 [00:00<00:00, 125.41it/s, train_loss=0.00594, val_loss=0.00507]Epoch 17:   7%|▋         | 2/29 [00:00<00:00, 172.52it/s, train_loss=0.00594, val_loss=0.00507]Epoch 17:   7%|▋         | 2/29 [00:00<00:00, 132.75it/s, train_loss=0.00334, val_loss=0.00507]Epoch 17:  10%|█         | 3/29 [00:00<00:00, 161.84it/s, train_loss=0.00334, val_loss=0.00507]Epoch 17:  10%|█         | 3/29 [00:00<00:00, 134.93it/s, train_loss=0.00581, val_loss=0.00507]Epoch 17:  14%|█▍        | 4/29 [00:00<00:00, 155.32it/s, train_loss=0.00581, val_loss=0.00507]Epoch 17:  14%|█▍        | 4/29 [00:00<00:00, 136.39it/s, train_loss=0.00399, val_loss=0.00507]Epoch 17:  17%|█▋        | 5/29 [00:00<00:00, 152.38it/s, train_loss=0.00399, val_loss=0.00507]Epoch 17:  17%|█▋        | 5/29 [00:00<00:00, 137.49it/s, train_loss=0.0035, val_loss=0.00507] Epoch 17:  21%|██        | 6/29 [00:00<00:00, 149.63it/s, train_loss=0.0035, val_loss=0.00507]Epoch 17:  21%|██        | 6/29 [00:00<00:00, 143.10it/s, train_loss=0.00341, val_loss=0.00507]Epoch 17:  24%|██▍       | 7/29 [00:00<00:00, 151.62it/s, train_loss=0.00341, val_loss=0.00507]Epoch 17:  24%|██▍       | 7/29 [00:00<00:00, 140.77it/s, train_loss=0.00548, val_loss=0.00507]Epoch 17:  28%|██▊       | 8/29 [00:00<00:00, 149.09it/s, train_loss=0.00548, val_loss=0.00507]Epoch 17:  28%|██▊       | 8/29 [00:00<00:00, 141.07it/s, train_loss=0.00353, val_loss=0.00507]Epoch 17:  31%|███       | 9/29 [00:00<00:00, 148.80it/s, train_loss=0.00353, val_loss=0.00507]Epoch 17:  31%|███       | 9/29 [00:00<00:00, 141.08it/s, train_loss=0.00508, val_loss=0.00507]Epoch 17:  34%|███▍      | 10/29 [00:00<00:00, 147.72it/s, train_loss=0.00508, val_loss=0.00507]Epoch 17:  34%|███▍      | 10/29 [00:00<00:00, 141.29it/s, train_loss=0.00462, val_loss=0.00507]Epoch 17:  38%|███▊      | 11/29 [00:00<00:00, 147.31it/s, train_loss=0.00462, val_loss=0.00507]Epoch 17:  38%|███▊      | 11/29 [00:00<00:00, 141.44it/s, train_loss=0.00348, val_loss=0.00507]Epoch 17:  41%|████▏     | 12/29 [00:00<00:00, 147.28it/s, train_loss=0.00348, val_loss=0.00507]Epoch 17:  41%|████▏     | 12/29 [00:00<00:00, 144.96it/s, train_loss=0.00438, val_loss=0.00507]Epoch 17:  45%|████▍     | 13/29 [00:00<00:00, 149.43it/s, train_loss=0.00438, val_loss=0.00507]Epoch 17:  45%|████▍     | 13/29 [00:00<00:00, 143.58it/s, train_loss=0.00558, val_loss=0.00507]Epoch 17:  48%|████▊     | 14/29 [00:00<00:00, 148.21it/s, train_loss=0.00558, val_loss=0.00507]Epoch 17:  48%|████▊     | 14/29 [00:00<00:00, 143.52it/s, train_loss=0.00454, val_loss=0.00507]Epoch 17:  52%|█████▏    | 15/29 [00:00<00:00, 148.20it/s, train_loss=0.00454, val_loss=0.00507]Epoch 17:  52%|█████▏    | 15/29 [00:00<00:00, 143.39it/s, train_loss=0.00344, val_loss=0.00507]Epoch 17:  55%|█████▌    | 16/29 [00:00<00:00, 147.63it/s, train_loss=0.00344, val_loss=0.00507]Epoch 17:  55%|█████▌    | 16/29 [00:00<00:00, 143.37it/s, train_loss=0.00469, val_loss=0.00507]Epoch 17:  59%|█████▊    | 17/29 [00:00<00:00, 147.34it/s, train_loss=0.00469, val_loss=0.00507]Epoch 17:  59%|█████▊    | 17/29 [00:00<00:00, 143.42it/s, train_loss=0.00537, val_loss=0.00507]Epoch 17:  62%|██████▏   | 18/29 [00:00<00:00, 146.98it/s, train_loss=0.00537, val_loss=0.00507]Epoch 17:  62%|██████▏   | 18/29 [00:00<00:00, 145.81it/s, train_loss=0.00459, val_loss=0.00507]Epoch 17:  66%|██████▌   | 19/29 [00:00<00:00, 148.90it/s, train_loss=0.00459, val_loss=0.00507]Epoch 17:  66%|██████▌   | 19/29 [00:00<00:00, 145.65it/s, train_loss=0.00278, val_loss=0.00507]Epoch 17:  69%|██████▉   | 20/29 [00:00<00:00, 148.85it/s, train_loss=0.00278, val_loss=0.00507]Epoch 17:  69%|██████▉   | 20/29 [00:00<00:00, 145.49it/s, train_loss=0.00379, val_loss=0.00507]Epoch 17:  72%|███████▏  | 21/29 [00:00<00:00, 148.94it/s, train_loss=0.00379, val_loss=0.00507]Epoch 17:  72%|███████▏  | 21/29 [00:00<00:00, 145.32it/s, train_loss=0.00391, val_loss=0.00507]Epoch 17:  76%|███████▌  | 22/29 [00:00<00:00, 148.69it/s, train_loss=0.00391, val_loss=0.00507]Epoch 17:  76%|███████▌  | 22/29 [00:00<00:00, 145.21it/s, train_loss=0.00547, val_loss=0.00507]Epoch 17:  79%|███████▉  | 23/29 [00:00<00:00, 148.53it/s, train_loss=0.00547, val_loss=0.00507]Epoch 17:  79%|███████▉  | 23/29 [00:00<00:00, 145.12it/s, train_loss=0.00581, val_loss=0.00507]Epoch 17:  83%|████████▎ | 24/29 [00:00<00:00, 148.09it/s, train_loss=0.00581, val_loss=0.00507]Epoch 17:  83%|████████▎ | 24/29 [00:00<00:00, 146.88it/s, train_loss=0.00482, val_loss=0.00507]Epoch 17:  86%|████████▌ | 25/29 [00:00<00:00, 149.29it/s, train_loss=0.00482, val_loss=0.00507]Epoch 17:  86%|████████▌ | 25/29 [00:00<00:00, 146.07it/s, train_loss=0.00352, val_loss=0.00507]Epoch 17:  90%|████████▉ | 26/29 [00:00<00:00, 148.61it/s, train_loss=0.00352, val_loss=0.00507]Epoch 17:  90%|████████▉ | 26/29 [00:00<00:00, 145.96it/s, train_loss=0.00385, val_loss=0.00507]Epoch 17:  93%|█████████▎| 27/29 [00:00<00:00, 148.54it/s, train_loss=0.00385, val_loss=0.00507]Epoch 17:  93%|█████████▎| 27/29 [00:00<00:00, 145.78it/s, train_loss=0.00363, val_loss=0.00507]Epoch 17:  97%|█████████▋| 28/29 [00:00<00:00, 148.22it/s, train_loss=0.00363, val_loss=0.00507]Epoch 17:  97%|█████████▋| 28/29 [00:00<00:00, 145.67it/s, train_loss=0.00637, val_loss=0.00507]Epoch 17: 100%|██████████| 29/29 [00:00<00:00, 148.02it/s, train_loss=0.00637, val_loss=0.00507]Epoch 17: 100%|██████████| 29/29 [00:00<00:00, 147.37it/s, train_loss=0.00365, val_loss=0.00507]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 169.98it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 206.73it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 226.62it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 235.68it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 241.50it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 245.86it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 247.60it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 249.22it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 250.70it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 252.35it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 254.25it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 255.19it/s][A
                                                                         [AEpoch 17: 100%|██████████| 29/29 [00:00<00:00, 114.27it/s, train_loss=0.00365, val_loss=0.00488]Epoch 17: 100%|██████████| 29/29 [00:00<00:00, 113.77it/s, train_loss=0.00365, val_loss=0.00488]Epoch 17:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00365, val_loss=0.00488]          Epoch 18:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00365, val_loss=0.00488]Epoch 18:   3%|▎         | 1/29 [00:00<00:00, 181.99it/s, train_loss=0.00365, val_loss=0.00488]Epoch 18:   3%|▎         | 1/29 [00:00<00:00, 127.85it/s, train_loss=0.00393, val_loss=0.00488]Epoch 18:   7%|▋         | 2/29 [00:00<00:00, 175.38it/s, train_loss=0.00393, val_loss=0.00488]Epoch 18:   7%|▋         | 2/29 [00:00<00:00, 133.61it/s, train_loss=0.0046, val_loss=0.00488] Epoch 18:  10%|█         | 3/29 [00:00<00:00, 163.27it/s, train_loss=0.0046, val_loss=0.00488]Epoch 18:  10%|█         | 3/29 [00:00<00:00, 135.37it/s, train_loss=0.00527, val_loss=0.00488]Epoch 18:  14%|█▍        | 4/29 [00:00<00:00, 156.67it/s, train_loss=0.00527, val_loss=0.00488]Epoch 18:  14%|█▍        | 4/29 [00:00<00:00, 136.46it/s, train_loss=0.0075, val_loss=0.00488] Epoch 18:  17%|█▋        | 5/29 [00:00<00:00, 152.98it/s, train_loss=0.0075, val_loss=0.00488]Epoch 18:  17%|█▋        | 5/29 [00:00<00:00, 137.59it/s, train_loss=0.00418, val_loss=0.00488]Epoch 18:  21%|██        | 6/29 [00:00<00:00, 150.58it/s, train_loss=0.00418, val_loss=0.00488]Epoch 18:  21%|██        | 6/29 [00:00<00:00, 143.88it/s, train_loss=0.00358, val_loss=0.00488]Epoch 18:  24%|██▍       | 7/29 [00:00<00:00, 153.21it/s, train_loss=0.00358, val_loss=0.00488]Epoch 18:  24%|██▍       | 7/29 [00:00<00:00, 141.61it/s, train_loss=0.00467, val_loss=0.00488]Epoch 18:  28%|██▊       | 8/29 [00:00<00:00, 150.37it/s, train_loss=0.00467, val_loss=0.00488]Epoch 18:  28%|██▊       | 8/29 [00:00<00:00, 141.61it/s, train_loss=0.00524, val_loss=0.00488]Epoch 18:  31%|███       | 9/29 [00:00<00:00, 149.83it/s, train_loss=0.00524, val_loss=0.00488]Epoch 18:  31%|███       | 9/29 [00:00<00:00, 141.61it/s, train_loss=0.00448, val_loss=0.00488]Epoch 18:  34%|███▍      | 10/29 [00:00<00:00, 148.61it/s, train_loss=0.00448, val_loss=0.00488]Epoch 18:  34%|███▍      | 10/29 [00:00<00:00, 141.68it/s, train_loss=0.00281, val_loss=0.00488]Epoch 18:  38%|███▊      | 11/29 [00:00<00:00, 148.02it/s, train_loss=0.00281, val_loss=0.00488]Epoch 18:  38%|███▊      | 11/29 [00:00<00:00, 141.82it/s, train_loss=0.00283, val_loss=0.00488]Epoch 18:  41%|████▏     | 12/29 [00:00<00:00, 147.54it/s, train_loss=0.00283, val_loss=0.00488]Epoch 18:  41%|████▏     | 12/29 [00:00<00:00, 144.83it/s, train_loss=0.00468, val_loss=0.00488]Epoch 18:  45%|████▍     | 13/29 [00:00<00:00, 149.28it/s, train_loss=0.00468, val_loss=0.00488]Epoch 18:  45%|████▍     | 13/29 [00:00<00:00, 143.41it/s, train_loss=0.00431, val_loss=0.00488]Epoch 18:  48%|████▊     | 14/29 [00:00<00:00, 148.05it/s, train_loss=0.00431, val_loss=0.00488]Epoch 18:  48%|████▊     | 14/29 [00:00<00:00, 143.36it/s, train_loss=0.00413, val_loss=0.00488]Epoch 18:  52%|█████▏    | 15/29 [00:00<00:00, 147.95it/s, train_loss=0.00413, val_loss=0.00488]Epoch 18:  52%|█████▏    | 15/29 [00:00<00:00, 143.30it/s, train_loss=0.00369, val_loss=0.00488]Epoch 18:  55%|█████▌    | 16/29 [00:00<00:00, 147.49it/s, train_loss=0.00369, val_loss=0.00488]Epoch 18:  55%|█████▌    | 16/29 [00:00<00:00, 143.32it/s, train_loss=0.00322, val_loss=0.00488]Epoch 18:  59%|█████▊    | 17/29 [00:00<00:00, 147.40it/s, train_loss=0.00322, val_loss=0.00488]Epoch 18:  59%|█████▊    | 17/29 [00:00<00:00, 143.33it/s, train_loss=0.00488, val_loss=0.00488]Epoch 18:  62%|██████▏   | 18/29 [00:00<00:00, 146.67it/s, train_loss=0.00488, val_loss=0.00488]Epoch 18:  62%|██████▏   | 18/29 [00:00<00:00, 145.60it/s, train_loss=0.00436, val_loss=0.00488]Epoch 18:  66%|██████▌   | 19/29 [00:00<00:00, 148.66it/s, train_loss=0.00436, val_loss=0.00488]Epoch 18:  66%|██████▌   | 19/29 [00:00<00:00, 145.47it/s, train_loss=0.00459, val_loss=0.00488]Epoch 18:  69%|██████▉   | 20/29 [00:00<00:00, 148.88it/s, train_loss=0.00459, val_loss=0.00488]Epoch 18:  69%|██████▉   | 20/29 [00:00<00:00, 145.32it/s, train_loss=0.00454, val_loss=0.00488]Epoch 18:  72%|███████▏  | 21/29 [00:00<00:00, 148.41it/s, train_loss=0.00454, val_loss=0.00488]Epoch 18:  72%|███████▏  | 21/29 [00:00<00:00, 145.15it/s, train_loss=0.00308, val_loss=0.00488]Epoch 18:  76%|███████▌  | 22/29 [00:00<00:00, 148.58it/s, train_loss=0.00308, val_loss=0.00488]Epoch 18:  76%|███████▌  | 22/29 [00:00<00:00, 145.00it/s, train_loss=0.00477, val_loss=0.00488]Epoch 18:  79%|███████▉  | 23/29 [00:00<00:00, 148.12it/s, train_loss=0.00477, val_loss=0.00488]Epoch 18:  79%|███████▉  | 23/29 [00:00<00:00, 144.92it/s, train_loss=0.00314, val_loss=0.00488]Epoch 18:  83%|████████▎ | 24/29 [00:00<00:00, 147.99it/s, train_loss=0.00314, val_loss=0.00488]Epoch 18:  83%|████████▎ | 24/29 [00:00<00:00, 146.47it/s, train_loss=0.00422, val_loss=0.00488]Epoch 18:  86%|████████▌ | 25/29 [00:00<00:00, 149.01it/s, train_loss=0.00422, val_loss=0.00488]Epoch 18:  86%|████████▌ | 25/29 [00:00<00:00, 145.60it/s, train_loss=0.0051, val_loss=0.00488] Epoch 18:  90%|████████▉ | 26/29 [00:00<00:00, 148.18it/s, train_loss=0.0051, val_loss=0.00488]Epoch 18:  90%|████████▉ | 26/29 [00:00<00:00, 145.45it/s, train_loss=0.00443, val_loss=0.00488]Epoch 18:  93%|█████████▎| 27/29 [00:00<00:00, 140.57it/s, train_loss=0.00443, val_loss=0.00488]Epoch 18:  93%|█████████▎| 27/29 [00:00<00:00, 137.88it/s, train_loss=0.00424, val_loss=0.00488]Epoch 18:  97%|█████████▋| 28/29 [00:00<00:00, 139.87it/s, train_loss=0.00424, val_loss=0.00488]Epoch 18:  97%|█████████▋| 28/29 [00:00<00:00, 137.56it/s, train_loss=0.00335, val_loss=0.00488]Epoch 18: 100%|██████████| 29/29 [00:00<00:00, 139.89it/s, train_loss=0.00335, val_loss=0.00488]Epoch 18: 100%|██████████| 29/29 [00:00<00:00, 137.88it/s, train_loss=0.00741, val_loss=0.00488]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 168.07it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 206.55it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 227.17it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 235.80it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 242.82it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 248.62it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 250.11it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 252.42it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 254.03it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 255.68it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 257.17it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 258.36it/s][A
                                                                         [AEpoch 18: 100%|██████████| 29/29 [00:00<00:00, 109.46it/s, train_loss=0.00741, val_loss=0.00469]Epoch 18: 100%|██████████| 29/29 [00:00<00:00, 109.06it/s, train_loss=0.00741, val_loss=0.00469]Epoch 18:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00741, val_loss=0.00469]          Epoch 19:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00741, val_loss=0.00469]Epoch 19:   3%|▎         | 1/29 [00:00<00:00, 183.28it/s, train_loss=0.00741, val_loss=0.00469]Epoch 19:   3%|▎         | 1/29 [00:00<00:00, 106.02it/s, train_loss=0.00572, val_loss=0.00469]Epoch 19:   7%|▋         | 2/29 [00:00<00:00, 148.77it/s, train_loss=0.00572, val_loss=0.00469]Epoch 19:   7%|▋         | 2/29 [00:00<00:00, 120.98it/s, train_loss=0.00419, val_loss=0.00469]Epoch 19:  10%|█         | 3/29 [00:00<00:00, 149.84it/s, train_loss=0.00419, val_loss=0.00469]Epoch 19:  10%|█         | 3/29 [00:00<00:00, 135.30it/s, train_loss=0.00415, val_loss=0.00469]Epoch 19:  14%|█▍        | 4/29 [00:00<00:00, 152.69it/s, train_loss=0.00415, val_loss=0.00469]Epoch 19:  14%|█▍        | 4/29 [00:00<00:00, 133.35it/s, train_loss=0.00405, val_loss=0.00469]Epoch 19:  17%|█▋        | 5/29 [00:00<00:00, 148.52it/s, train_loss=0.00405, val_loss=0.00469]Epoch 19:  17%|█▋        | 5/29 [00:00<00:00, 134.99it/s, train_loss=0.00483, val_loss=0.00469]Epoch 19:  21%|██        | 6/29 [00:00<00:00, 147.86it/s, train_loss=0.00483, val_loss=0.00469]Epoch 19:  21%|██        | 6/29 [00:00<00:00, 135.87it/s, train_loss=0.00297, val_loss=0.00469]Epoch 19:  24%|██▍       | 7/29 [00:00<00:00, 146.79it/s, train_loss=0.00297, val_loss=0.00469]Epoch 19:  24%|██▍       | 7/29 [00:00<00:00, 136.62it/s, train_loss=0.00452, val_loss=0.00469]Epoch 19:  28%|██▊       | 8/29 [00:00<00:00, 146.01it/s, train_loss=0.00452, val_loss=0.00469]Epoch 19:  28%|██▊       | 8/29 [00:00<00:00, 137.20it/s, train_loss=0.00414, val_loss=0.00469]Epoch 19:  31%|███       | 9/29 [00:00<00:00, 145.27it/s, train_loss=0.00414, val_loss=0.00469]Epoch 19:  31%|███       | 9/29 [00:00<00:00, 141.66it/s, train_loss=0.00287, val_loss=0.00469]Epoch 19:  34%|███▍      | 10/29 [00:00<00:00, 147.88it/s, train_loss=0.00287, val_loss=0.00469]Epoch 19:  34%|███▍      | 10/29 [00:00<00:00, 140.19it/s, train_loss=0.00381, val_loss=0.00469]Epoch 19:  38%|███▊      | 11/29 [00:00<00:00, 146.30it/s, train_loss=0.00381, val_loss=0.00469]Epoch 19:  38%|███▊      | 11/29 [00:00<00:00, 140.50it/s, train_loss=0.00279, val_loss=0.00469]Epoch 19:  41%|████▏     | 12/29 [00:00<00:00, 146.47it/s, train_loss=0.00279, val_loss=0.00469]Epoch 19:  41%|████▏     | 12/29 [00:00<00:00, 140.60it/s, train_loss=0.00346, val_loss=0.00469]Epoch 19:  45%|████▍     | 13/29 [00:00<00:00, 145.85it/s, train_loss=0.00346, val_loss=0.00469]Epoch 19:  45%|████▍     | 13/29 [00:00<00:00, 140.86it/s, train_loss=0.00297, val_loss=0.00469]Epoch 19:  48%|████▊     | 14/29 [00:00<00:00, 145.52it/s, train_loss=0.00297, val_loss=0.00469]Epoch 19:  48%|████▊     | 14/29 [00:00<00:00, 141.11it/s, train_loss=0.00388, val_loss=0.00469]Epoch 19:  52%|█████▏    | 15/29 [00:00<00:00, 145.05it/s, train_loss=0.00388, val_loss=0.00469]Epoch 19:  52%|█████▏    | 15/29 [00:00<00:00, 141.07it/s, train_loss=0.00517, val_loss=0.00469]Epoch 19:  55%|█████▌    | 16/29 [00:00<00:00, 144.75it/s, train_loss=0.00517, val_loss=0.00469]Epoch 19:  55%|█████▌    | 16/29 [00:00<00:00, 141.14it/s, train_loss=0.00402, val_loss=0.00469]Epoch 19:  59%|█████▊    | 17/29 [00:00<00:00, 145.20it/s, train_loss=0.00402, val_loss=0.00469]Epoch 19:  59%|█████▊    | 17/29 [00:00<00:00, 141.26it/s, train_loss=0.00423, val_loss=0.00469]Epoch 19:  62%|██████▏   | 18/29 [00:00<00:00, 145.13it/s, train_loss=0.00423, val_loss=0.00469]Epoch 19:  62%|██████▏   | 18/29 [00:00<00:00, 141.32it/s, train_loss=0.00422, val_loss=0.00469]Epoch 19:  66%|██████▌   | 19/29 [00:00<00:00, 144.93it/s, train_loss=0.00422, val_loss=0.00469]Epoch 19:  66%|██████▌   | 19/29 [00:00<00:00, 141.41it/s, train_loss=0.0045, val_loss=0.00469] Epoch 19:  69%|██████▉   | 20/29 [00:00<00:00, 144.67it/s, train_loss=0.0045, val_loss=0.00469]Epoch 19:  69%|██████▉   | 20/29 [00:00<00:00, 141.55it/s, train_loss=0.00285, val_loss=0.00469]Epoch 19:  72%|███████▏  | 21/29 [00:00<00:00, 144.25it/s, train_loss=0.00285, val_loss=0.00469]Epoch 19:  72%|███████▏  | 21/29 [00:00<00:00, 140.25it/s, train_loss=0.00491, val_loss=0.00469]Epoch 19:  76%|███████▌  | 22/29 [00:00<00:00, 143.50it/s, train_loss=0.00491, val_loss=0.00469]Epoch 19:  76%|███████▌  | 22/29 [00:00<00:00, 140.37it/s, train_loss=0.00347, val_loss=0.00469]Epoch 19:  79%|███████▉  | 23/29 [00:00<00:00, 143.64it/s, train_loss=0.00347, val_loss=0.00469]Epoch 19:  79%|███████▉  | 23/29 [00:00<00:00, 140.44it/s, train_loss=0.00426, val_loss=0.00469]Epoch 19:  83%|████████▎ | 24/29 [00:00<00:00, 143.54it/s, train_loss=0.00426, val_loss=0.00469]Epoch 19:  83%|████████▎ | 24/29 [00:00<00:00, 140.49it/s, train_loss=0.004, val_loss=0.00469]  Epoch 19:  86%|████████▌ | 25/29 [00:00<00:00, 143.36it/s, train_loss=0.004, val_loss=0.00469]Epoch 19:  86%|████████▌ | 25/29 [00:00<00:00, 140.60it/s, train_loss=0.00468, val_loss=0.00469]Epoch 19:  90%|████████▉ | 26/29 [00:00<00:00, 143.38it/s, train_loss=0.00468, val_loss=0.00469]Epoch 19:  90%|████████▉ | 26/29 [00:00<00:00, 142.19it/s, train_loss=0.00609, val_loss=0.00469]Epoch 19:  93%|█████████▎| 27/29 [00:00<00:00, 144.40it/s, train_loss=0.00609, val_loss=0.00469]Epoch 19:  93%|█████████▎| 27/29 [00:00<00:00, 141.62it/s, train_loss=0.00368, val_loss=0.00469]Epoch 19:  97%|█████████▋| 28/29 [00:00<00:00, 143.95it/s, train_loss=0.00368, val_loss=0.00469]Epoch 19:  97%|█████████▋| 28/29 [00:00<00:00, 141.66it/s, train_loss=0.00445, val_loss=0.00469]Epoch 19: 100%|██████████| 29/29 [00:00<00:00, 144.13it/s, train_loss=0.00445, val_loss=0.00469]Epoch 19: 100%|██████████| 29/29 [00:00<00:00, 143.50it/s, train_loss=0.00274, val_loss=0.00469]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 179.42it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 223.07it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 238.13it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 248.79it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 254.99it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 256.71it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 257.29it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 257.20it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 256.68it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 256.60it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 257.28it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 258.54it/s][A
                                                                         [AEpoch 19: 100%|██████████| 29/29 [00:00<00:00, 112.66it/s, train_loss=0.00274, val_loss=0.00455]Epoch 19: 100%|██████████| 29/29 [00:00<00:00, 112.24it/s, train_loss=0.00274, val_loss=0.00455]Epoch 19:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00274, val_loss=0.00455]          Epoch 20:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00274, val_loss=0.00455]Epoch 20:   3%|▎         | 1/29 [00:00<00:00, 197.32it/s, train_loss=0.00274, val_loss=0.00455]Epoch 20:   3%|▎         | 1/29 [00:00<00:00, 107.23it/s, train_loss=0.00347, val_loss=0.00455]Epoch 20:   7%|▋         | 2/29 [00:00<00:00, 149.95it/s, train_loss=0.00347, val_loss=0.00455]Epoch 20:   7%|▋         | 2/29 [00:00<00:00, 137.67it/s, train_loss=0.00325, val_loss=0.00455]Epoch 20:  10%|█         | 3/29 [00:00<00:00, 158.21it/s, train_loss=0.00325, val_loss=0.00455]Epoch 20:  10%|█         | 3/29 [00:00<00:00, 138.66it/s, train_loss=0.00438, val_loss=0.00455]Epoch 20:  14%|█▍        | 4/29 [00:00<00:00, 158.88it/s, train_loss=0.00438, val_loss=0.00455]Epoch 20:  14%|█▍        | 4/29 [00:00<00:00, 139.46it/s, train_loss=0.00378, val_loss=0.00455]Epoch 20:  17%|█▋        | 5/29 [00:00<00:00, 155.24it/s, train_loss=0.00378, val_loss=0.00455]Epoch 20:  17%|█▋        | 5/29 [00:00<00:00, 139.66it/s, train_loss=0.00557, val_loss=0.00455]Epoch 20:  21%|██        | 6/29 [00:00<00:00, 152.64it/s, train_loss=0.00557, val_loss=0.00455]Epoch 20:  21%|██        | 6/29 [00:00<00:00, 139.98it/s, train_loss=0.00424, val_loss=0.00455]Epoch 20:  24%|██▍       | 7/29 [00:00<00:00, 150.86it/s, train_loss=0.00424, val_loss=0.00455]Epoch 20:  24%|██▍       | 7/29 [00:00<00:00, 140.31it/s, train_loss=0.00354, val_loss=0.00455]Epoch 20:  28%|██▊       | 8/29 [00:00<00:00, 149.57it/s, train_loss=0.00354, val_loss=0.00455]Epoch 20:  28%|██▊       | 8/29 [00:00<00:00, 144.63it/s, train_loss=0.00434, val_loss=0.00455]Epoch 20:  31%|███       | 9/29 [00:00<00:00, 151.73it/s, train_loss=0.00434, val_loss=0.00455]Epoch 20:  31%|███       | 9/29 [00:00<00:00, 142.56it/s, train_loss=0.00329, val_loss=0.00455]Epoch 20:  34%|███▍      | 10/29 [00:00<00:00, 149.32it/s, train_loss=0.00329, val_loss=0.00455]Epoch 20:  34%|███▍      | 10/29 [00:00<00:00, 142.68it/s, train_loss=0.00331, val_loss=0.00455]Epoch 20:  38%|███▊      | 11/29 [00:00<00:00, 149.03it/s, train_loss=0.00331, val_loss=0.00455]Epoch 20:  38%|███▊      | 11/29 [00:00<00:00, 142.68it/s, train_loss=0.00363, val_loss=0.00455]Epoch 20:  41%|████▏     | 12/29 [00:00<00:00, 148.48it/s, train_loss=0.00363, val_loss=0.00455]Epoch 20:  41%|████▏     | 12/29 [00:00<00:00, 142.68it/s, train_loss=0.00434, val_loss=0.00455]Epoch 20:  45%|████▍     | 13/29 [00:00<00:00, 147.99it/s, train_loss=0.00434, val_loss=0.00455]Epoch 20:  45%|████▍     | 13/29 [00:00<00:00, 142.75it/s, train_loss=0.00448, val_loss=0.00455]Epoch 20:  48%|████▊     | 14/29 [00:00<00:00, 147.81it/s, train_loss=0.00448, val_loss=0.00455]Epoch 20:  48%|████▊     | 14/29 [00:00<00:00, 145.28it/s, train_loss=0.00274, val_loss=0.00455]Epoch 20:  52%|█████▏    | 15/29 [00:00<00:00, 149.26it/s, train_loss=0.00274, val_loss=0.00455]Epoch 20:  52%|█████▏    | 15/29 [00:00<00:00, 144.00it/s, train_loss=0.00515, val_loss=0.00455]Epoch 20:  55%|█████▌    | 16/29 [00:00<00:00, 147.98it/s, train_loss=0.00515, val_loss=0.00455]Epoch 20:  55%|█████▌    | 16/29 [00:00<00:00, 143.99it/s, train_loss=0.00347, val_loss=0.00455]Epoch 20:  59%|█████▊    | 17/29 [00:00<00:00, 147.97it/s, train_loss=0.00347, val_loss=0.00455]Epoch 20:  59%|█████▊    | 17/29 [00:00<00:00, 143.92it/s, train_loss=0.00416, val_loss=0.00455]Epoch 20:  62%|██████▏   | 18/29 [00:00<00:00, 147.59it/s, train_loss=0.00416, val_loss=0.00455]Epoch 20:  62%|██████▏   | 18/29 [00:00<00:00, 143.92it/s, train_loss=0.00459, val_loss=0.00455]Epoch 20:  66%|██████▌   | 19/29 [00:00<00:00, 147.47it/s, train_loss=0.00459, val_loss=0.00455]Epoch 20:  66%|██████▌   | 19/29 [00:00<00:00, 143.91it/s, train_loss=0.00422, val_loss=0.00455]Epoch 20:  69%|██████▉   | 20/29 [00:00<00:00, 146.91it/s, train_loss=0.00422, val_loss=0.00455]Epoch 20:  69%|██████▉   | 20/29 [00:00<00:00, 145.99it/s, train_loss=0.00463, val_loss=0.00455]Epoch 20:  72%|███████▏  | 21/29 [00:00<00:00, 148.72it/s, train_loss=0.00463, val_loss=0.00455]Epoch 20:  72%|███████▏  | 21/29 [00:00<00:00, 145.90it/s, train_loss=0.00321, val_loss=0.00455]Epoch 20:  76%|███████▌  | 22/29 [00:00<00:00, 148.92it/s, train_loss=0.00321, val_loss=0.00455]Epoch 20:  76%|███████▌  | 22/29 [00:00<00:00, 145.76it/s, train_loss=0.00397, val_loss=0.00455]Epoch 20:  79%|███████▉  | 23/29 [00:00<00:00, 149.01it/s, train_loss=0.00397, val_loss=0.00455]Epoch 20:  79%|███████▉  | 23/29 [00:00<00:00, 145.57it/s, train_loss=0.00316, val_loss=0.00455]Epoch 20:  83%|████████▎ | 24/29 [00:00<00:00, 148.60it/s, train_loss=0.00316, val_loss=0.00455]Epoch 20:  83%|████████▎ | 24/29 [00:00<00:00, 145.38it/s, train_loss=0.00485, val_loss=0.00455]Epoch 20:  86%|████████▌ | 25/29 [00:00<00:00, 148.30it/s, train_loss=0.00485, val_loss=0.00455]Epoch 20:  86%|████████▌ | 25/29 [00:00<00:00, 145.28it/s, train_loss=0.00331, val_loss=0.00455]Epoch 20:  90%|████████▉ | 26/29 [00:00<00:00, 148.09it/s, train_loss=0.00331, val_loss=0.00455]Epoch 20:  90%|████████▉ | 26/29 [00:00<00:00, 146.73it/s, train_loss=0.00306, val_loss=0.00455]Epoch 20:  93%|█████████▎| 27/29 [00:00<00:00, 149.00it/s, train_loss=0.00306, val_loss=0.00455]Epoch 20:  93%|█████████▎| 27/29 [00:00<00:00, 145.94it/s, train_loss=0.00367, val_loss=0.00455]Epoch 20:  97%|█████████▋| 28/29 [00:00<00:00, 148.27it/s, train_loss=0.00367, val_loss=0.00455]Epoch 20:  97%|█████████▋| 28/29 [00:00<00:00, 145.83it/s, train_loss=0.00505, val_loss=0.00455]Epoch 20: 100%|██████████| 29/29 [00:00<00:00, 148.39it/s, train_loss=0.00505, val_loss=0.00455]Epoch 20: 100%|██████████| 29/29 [00:00<00:00, 147.67it/s, train_loss=0.00371, val_loss=0.00455]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 178.55it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 222.53it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 237.00it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 246.62it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 255.70it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 262.39it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 262.91it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 262.65it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 262.78it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 264.10it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 263.56it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 263.17it/s][A
                                                                         [AEpoch 20: 100%|██████████| 29/29 [00:00<00:00, 115.25it/s, train_loss=0.00371, val_loss=0.00438]Epoch 20: 100%|██████████| 29/29 [00:00<00:00, 114.83it/s, train_loss=0.00371, val_loss=0.00438]Epoch 20:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00371, val_loss=0.00438]          Epoch 21:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00371, val_loss=0.00438]Epoch 21:   3%|▎         | 1/29 [00:00<00:00, 193.09it/s, train_loss=0.00371, val_loss=0.00438]Epoch 21:   3%|▎         | 1/29 [00:00<00:00, 107.89it/s, train_loss=0.00408, val_loss=0.00438]Epoch 21:   7%|▋         | 2/29 [00:00<00:00, 150.89it/s, train_loss=0.00408, val_loss=0.00438]Epoch 21:   7%|▋         | 2/29 [00:00<00:00, 138.31it/s, train_loss=0.00475, val_loss=0.00438]Epoch 21:  10%|█         | 3/29 [00:00<00:00, 159.61it/s, train_loss=0.00475, val_loss=0.00438]Epoch 21:  10%|█         | 3/29 [00:00<00:00, 139.24it/s, train_loss=0.004, val_loss=0.00438]  Epoch 21:  14%|█▍        | 4/29 [00:00<00:00, 157.14it/s, train_loss=0.004, val_loss=0.00438]Epoch 21:  14%|█▍        | 4/29 [00:00<00:00, 139.99it/s, train_loss=0.00292, val_loss=0.00438]Epoch 21:  17%|█▋        | 5/29 [00:00<00:00, 156.43it/s, train_loss=0.00292, val_loss=0.00438]Epoch 21:  17%|█▋        | 5/29 [00:00<00:00, 140.16it/s, train_loss=0.00381, val_loss=0.00438]Epoch 21:  21%|██        | 6/29 [00:00<00:00, 153.33it/s, train_loss=0.00381, val_loss=0.00438]Epoch 21:  21%|██        | 6/29 [00:00<00:00, 140.23it/s, train_loss=0.00354, val_loss=0.00438]Epoch 21:  24%|██▍       | 7/29 [00:00<00:00, 151.37it/s, train_loss=0.00354, val_loss=0.00438]Epoch 21:  24%|██▍       | 7/29 [00:00<00:00, 140.56it/s, train_loss=0.00347, val_loss=0.00438]Epoch 21:  28%|██▊       | 8/29 [00:00<00:00, 149.13it/s, train_loss=0.00347, val_loss=0.00438]Epoch 21:  28%|██▊       | 8/29 [00:00<00:00, 140.75it/s, train_loss=0.00304, val_loss=0.00438]Epoch 21:  31%|███       | 9/29 [00:00<00:00, 147.96it/s, train_loss=0.00304, val_loss=0.00438]Epoch 21:  31%|███       | 9/29 [00:00<00:00, 140.89it/s, train_loss=0.00487, val_loss=0.00438]Epoch 21:  34%|███▍      | 10/29 [00:00<00:00, 148.07it/s, train_loss=0.00487, val_loss=0.00438]Epoch 21:  34%|███▍      | 10/29 [00:00<00:00, 141.05it/s, train_loss=0.00301, val_loss=0.00438]Epoch 21:  38%|███▊      | 11/29 [00:00<00:00, 147.54it/s, train_loss=0.00301, val_loss=0.00438]Epoch 21:  38%|███▊      | 11/29 [00:00<00:00, 140.99it/s, train_loss=0.00422, val_loss=0.00438]Epoch 21:  41%|████▏     | 12/29 [00:00<00:00, 146.81it/s, train_loss=0.00422, val_loss=0.00438]Epoch 21:  41%|████▏     | 12/29 [00:00<00:00, 141.09it/s, train_loss=0.00301, val_loss=0.00438]Epoch 21:  45%|████▍     | 13/29 [00:00<00:00, 146.48it/s, train_loss=0.00301, val_loss=0.00438]Epoch 21:  45%|████▍     | 13/29 [00:00<00:00, 141.21it/s, train_loss=0.00319, val_loss=0.00438]Epoch 21:  48%|████▊     | 14/29 [00:00<00:00, 145.33it/s, train_loss=0.00319, val_loss=0.00438]Epoch 21:  48%|████▊     | 14/29 [00:00<00:00, 138.97it/s, train_loss=0.00435, val_loss=0.00438]Epoch 21:  52%|█████▏    | 15/29 [00:00<00:00, 142.25it/s, train_loss=0.00435, val_loss=0.00438]Epoch 21:  52%|█████▏    | 15/29 [00:00<00:00, 136.25it/s, train_loss=0.00408, val_loss=0.00438]Epoch 21:  55%|█████▌    | 16/29 [00:00<00:00, 140.27it/s, train_loss=0.00408, val_loss=0.00438]Epoch 21:  55%|█████▌    | 16/29 [00:00<00:00, 136.68it/s, train_loss=0.00504, val_loss=0.00438]Epoch 21:  59%|█████▊    | 17/29 [00:00<00:00, 140.72it/s, train_loss=0.00504, val_loss=0.00438]Epoch 21:  59%|█████▊    | 17/29 [00:00<00:00, 137.08it/s, train_loss=0.00301, val_loss=0.00438]Epoch 21:  62%|██████▏   | 18/29 [00:00<00:00, 140.99it/s, train_loss=0.00301, val_loss=0.00438]Epoch 21:  62%|██████▏   | 18/29 [00:00<00:00, 137.46it/s, train_loss=0.00358, val_loss=0.00438]Epoch 21:  66%|██████▌   | 19/29 [00:00<00:00, 140.72it/s, train_loss=0.00358, val_loss=0.00438]Epoch 21:  66%|██████▌   | 19/29 [00:00<00:00, 136.92it/s, train_loss=0.00388, val_loss=0.00438]Epoch 21:  69%|██████▉   | 20/29 [00:00<00:00, 140.27it/s, train_loss=0.00388, val_loss=0.00438]Epoch 21:  69%|██████▉   | 20/29 [00:00<00:00, 137.22it/s, train_loss=0.00335, val_loss=0.00438]Epoch 21:  72%|███████▏  | 21/29 [00:00<00:00, 140.48it/s, train_loss=0.00335, val_loss=0.00438]Epoch 21:  72%|███████▏  | 21/29 [00:00<00:00, 137.48it/s, train_loss=0.00355, val_loss=0.00438]Epoch 21:  76%|███████▌  | 22/29 [00:00<00:00, 140.55it/s, train_loss=0.00355, val_loss=0.00438]Epoch 21:  76%|███████▌  | 22/29 [00:00<00:00, 137.73it/s, train_loss=0.00396, val_loss=0.00438]Epoch 21:  79%|███████▉  | 23/29 [00:00<00:00, 140.68it/s, train_loss=0.00396, val_loss=0.00438]Epoch 21:  79%|███████▉  | 23/29 [00:00<00:00, 137.95it/s, train_loss=0.00298, val_loss=0.00438]Epoch 21:  83%|████████▎ | 24/29 [00:00<00:00, 140.91it/s, train_loss=0.00298, val_loss=0.00438]Epoch 21:  83%|████████▎ | 24/29 [00:00<00:00, 138.20it/s, train_loss=0.00316, val_loss=0.00438]Epoch 21:  86%|████████▌ | 25/29 [00:00<00:00, 140.71it/s, train_loss=0.00316, val_loss=0.00438]Epoch 21:  86%|████████▌ | 25/29 [00:00<00:00, 138.35it/s, train_loss=0.00455, val_loss=0.00438]Epoch 21:  90%|████████▉ | 26/29 [00:00<00:00, 141.22it/s, train_loss=0.00455, val_loss=0.00438]Epoch 21:  90%|████████▉ | 26/29 [00:00<00:00, 138.49it/s, train_loss=0.00617, val_loss=0.00438]Epoch 21:  93%|█████████▎| 27/29 [00:00<00:00, 141.22it/s, train_loss=0.00617, val_loss=0.00438]Epoch 21:  93%|█████████▎| 27/29 [00:00<00:00, 138.62it/s, train_loss=0.00385, val_loss=0.00438]Epoch 21:  97%|█████████▋| 28/29 [00:00<00:00, 141.27it/s, train_loss=0.00385, val_loss=0.00438]Epoch 21:  97%|█████████▋| 28/29 [00:00<00:00, 138.73it/s, train_loss=0.00366, val_loss=0.00438]Epoch 21: 100%|██████████| 29/29 [00:00<00:00, 141.29it/s, train_loss=0.00366, val_loss=0.00438]Epoch 21: 100%|██████████| 29/29 [00:00<00:00, 140.66it/s, train_loss=0.00231, val_loss=0.00438]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 203.28it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 242.49it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 262.77it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 270.98it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 276.22it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 277.93it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 277.17it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 276.87it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 274.28it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 275.47it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 276.55it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 277.69it/s][A
                                                                         [AEpoch 21: 100%|██████████| 29/29 [00:00<00:00, 112.30it/s, train_loss=0.00231, val_loss=0.00426]Epoch 21: 100%|██████████| 29/29 [00:00<00:00, 111.85it/s, train_loss=0.00231, val_loss=0.00426]Epoch 21:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.00426]          Epoch 22:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.00426]Epoch 22:   3%|▎         | 1/29 [00:00<00:00, 179.05it/s, train_loss=0.00231, val_loss=0.00426]Epoch 22:   3%|▎         | 1/29 [00:00<00:00, 121.39it/s, train_loss=0.00473, val_loss=0.00426]Epoch 22:   7%|▋         | 2/29 [00:00<00:00, 165.14it/s, train_loss=0.00473, val_loss=0.00426]Epoch 22:   7%|▋         | 2/29 [00:00<00:00, 130.77it/s, train_loss=0.00391, val_loss=0.00426]Epoch 22:  10%|█         | 3/29 [00:00<00:00, 157.16it/s, train_loss=0.00391, val_loss=0.00426]Epoch 22:  10%|█         | 3/29 [00:00<00:00, 133.81it/s, train_loss=0.00342, val_loss=0.00426]Epoch 22:  14%|█▍        | 4/29 [00:00<00:00, 152.19it/s, train_loss=0.00342, val_loss=0.00426]Epoch 22:  14%|█▍        | 4/29 [00:00<00:00, 135.24it/s, train_loss=0.00391, val_loss=0.00426]Epoch 22:  17%|█▋        | 5/29 [00:00<00:00, 149.82it/s, train_loss=0.00391, val_loss=0.00426]Epoch 22:  17%|█▋        | 5/29 [00:00<00:00, 136.56it/s, train_loss=0.00293, val_loss=0.00426]Epoch 22:  21%|██        | 6/29 [00:00<00:00, 149.73it/s, train_loss=0.00293, val_loss=0.00426]Epoch 22:  21%|██        | 6/29 [00:00<00:00, 142.57it/s, train_loss=0.00425, val_loss=0.00426]Epoch 22:  24%|██▍       | 7/29 [00:00<00:00, 152.45it/s, train_loss=0.00425, val_loss=0.00426]Epoch 22:  24%|██▍       | 7/29 [00:00<00:00, 140.40it/s, train_loss=0.00454, val_loss=0.00426]Epoch 22:  28%|██▊       | 8/29 [00:00<00:00, 149.54it/s, train_loss=0.00454, val_loss=0.00426]Epoch 22:  28%|██▊       | 8/29 [00:00<00:00, 140.71it/s, train_loss=0.00498, val_loss=0.00426]Epoch 22:  31%|███       | 9/29 [00:00<00:00, 149.19it/s, train_loss=0.00498, val_loss=0.00426]Epoch 22:  31%|███       | 9/29 [00:00<00:00, 140.85it/s, train_loss=0.00429, val_loss=0.00426]Epoch 22:  34%|███▍      | 10/29 [00:00<00:00, 148.24it/s, train_loss=0.00429, val_loss=0.00426]Epoch 22:  34%|███▍      | 10/29 [00:00<00:00, 141.00it/s, train_loss=0.00289, val_loss=0.00426]Epoch 22:  38%|███▊      | 11/29 [00:00<00:00, 147.51it/s, train_loss=0.00289, val_loss=0.00426]Epoch 22:  38%|███▊      | 11/29 [00:00<00:00, 141.14it/s, train_loss=0.00301, val_loss=0.00426]Epoch 22:  41%|████▏     | 12/29 [00:00<00:00, 146.95it/s, train_loss=0.00301, val_loss=0.00426]Epoch 22:  41%|████▏     | 12/29 [00:00<00:00, 144.85it/s, train_loss=0.00433, val_loss=0.00426]Epoch 22:  45%|████▍     | 13/29 [00:00<00:00, 149.37it/s, train_loss=0.00433, val_loss=0.00426]Epoch 22:  45%|████▍     | 13/29 [00:00<00:00, 143.32it/s, train_loss=0.00419, val_loss=0.00426]Epoch 22:  48%|████▊     | 14/29 [00:00<00:00, 148.02it/s, train_loss=0.00419, val_loss=0.00426]Epoch 22:  48%|████▊     | 14/29 [00:00<00:00, 143.35it/s, train_loss=0.0025, val_loss=0.00426] Epoch 22:  52%|█████▏    | 15/29 [00:00<00:00, 147.86it/s, train_loss=0.0025, val_loss=0.00426]Epoch 22:  52%|█████▏    | 15/29 [00:00<00:00, 143.35it/s, train_loss=0.00368, val_loss=0.00426]Epoch 22:  55%|█████▌    | 16/29 [00:00<00:00, 147.72it/s, train_loss=0.00368, val_loss=0.00426]Epoch 22:  55%|█████▌    | 16/29 [00:00<00:00, 143.34it/s, train_loss=0.00346, val_loss=0.00426]Epoch 22:  59%|█████▊    | 17/29 [00:00<00:00, 147.36it/s, train_loss=0.00346, val_loss=0.00426]Epoch 22:  59%|█████▊    | 17/29 [00:00<00:00, 143.30it/s, train_loss=0.00406, val_loss=0.00426]Epoch 22:  62%|██████▏   | 18/29 [00:00<00:00, 147.15it/s, train_loss=0.00406, val_loss=0.00426]Epoch 22:  62%|██████▏   | 18/29 [00:00<00:00, 145.57it/s, train_loss=0.00372, val_loss=0.00426]Epoch 22:  66%|██████▌   | 19/29 [00:00<00:00, 148.72it/s, train_loss=0.00372, val_loss=0.00426]Epoch 22:  66%|██████▌   | 19/29 [00:00<00:00, 144.55it/s, train_loss=0.00373, val_loss=0.00426]Epoch 22:  69%|██████▉   | 20/29 [00:00<00:00, 147.80it/s, train_loss=0.00373, val_loss=0.00426]Epoch 22:  69%|██████▉   | 20/29 [00:00<00:00, 144.46it/s, train_loss=0.00417, val_loss=0.00426]Epoch 22:  72%|███████▏  | 21/29 [00:00<00:00, 147.68it/s, train_loss=0.00417, val_loss=0.00426]Epoch 22:  72%|███████▏  | 21/29 [00:00<00:00, 144.33it/s, train_loss=0.003, val_loss=0.00426]  Epoch 22:  76%|███████▌  | 22/29 [00:00<00:00, 147.43it/s, train_loss=0.003, val_loss=0.00426]Epoch 22:  76%|███████▌  | 22/29 [00:00<00:00, 144.24it/s, train_loss=0.00239, val_loss=0.00426]Epoch 22:  79%|███████▉  | 23/29 [00:00<00:00, 146.98it/s, train_loss=0.00239, val_loss=0.00426]Epoch 22:  79%|███████▉  | 23/29 [00:00<00:00, 144.21it/s, train_loss=0.00508, val_loss=0.00426]Epoch 22:  83%|████████▎ | 24/29 [00:00<00:00, 146.53it/s, train_loss=0.00508, val_loss=0.00426]Epoch 22:  83%|████████▎ | 24/29 [00:00<00:00, 144.06it/s, train_loss=0.00313, val_loss=0.00426]Epoch 22:  86%|████████▌ | 25/29 [00:00<00:00, 146.73it/s, train_loss=0.00313, val_loss=0.00426]Epoch 22:  86%|████████▌ | 25/29 [00:00<00:00, 144.01it/s, train_loss=0.00427, val_loss=0.00426]Epoch 22:  90%|████████▉ | 26/29 [00:00<00:00, 146.88it/s, train_loss=0.00427, val_loss=0.00426]Epoch 22:  90%|████████▉ | 26/29 [00:00<00:00, 143.94it/s, train_loss=0.00256, val_loss=0.00426]Epoch 22:  93%|█████████▎| 27/29 [00:00<00:00, 146.59it/s, train_loss=0.00256, val_loss=0.00426]Epoch 22:  93%|█████████▎| 27/29 [00:00<00:00, 143.88it/s, train_loss=0.00263, val_loss=0.00426]Epoch 22:  97%|█████████▋| 28/29 [00:00<00:00, 146.43it/s, train_loss=0.00263, val_loss=0.00426]Epoch 22:  97%|█████████▋| 28/29 [00:00<00:00, 143.82it/s, train_loss=0.00403, val_loss=0.00426]Epoch 22: 100%|██████████| 29/29 [00:00<00:00, 146.33it/s, train_loss=0.00403, val_loss=0.00426]Epoch 22: 100%|██████████| 29/29 [00:00<00:00, 143.98it/s, train_loss=0.00855, val_loss=0.00426]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 210.05it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 241.52it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 253.64it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 264.65it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 270.26it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 272.30it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 273.62it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 274.58it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 276.05it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 277.18it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 277.04it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 276.63it/s][A
                                                                         [AEpoch 22: 100%|██████████| 29/29 [00:00<00:00, 114.58it/s, train_loss=0.00855, val_loss=0.00415]Epoch 22: 100%|██████████| 29/29 [00:00<00:00, 114.10it/s, train_loss=0.00855, val_loss=0.00415]Epoch 22:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00855, val_loss=0.00415]          Epoch 23:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00855, val_loss=0.00415]Epoch 23:   3%|▎         | 1/29 [00:00<00:00, 177.93it/s, train_loss=0.00855, val_loss=0.00415]Epoch 23:   3%|▎         | 1/29 [00:00<00:00, 125.74it/s, train_loss=0.00395, val_loss=0.00415]Epoch 23:   7%|▋         | 2/29 [00:00<00:00, 167.86it/s, train_loss=0.00395, val_loss=0.00415]Epoch 23:   7%|▋         | 2/29 [00:00<00:00, 133.50it/s, train_loss=0.00249, val_loss=0.00415]Epoch 23:  10%|█         | 3/29 [00:00<00:00, 160.10it/s, train_loss=0.00249, val_loss=0.00415]Epoch 23:  10%|█         | 3/29 [00:00<00:00, 135.61it/s, train_loss=0.00461, val_loss=0.00415]Epoch 23:  14%|█▍        | 4/29 [00:00<00:00, 154.31it/s, train_loss=0.00461, val_loss=0.00415]Epoch 23:  14%|█▍        | 4/29 [00:00<00:00, 137.16it/s, train_loss=0.00421, val_loss=0.00415]Epoch 23:  17%|█▋        | 5/29 [00:00<00:00, 151.59it/s, train_loss=0.00421, val_loss=0.00415]Epoch 23:  17%|█▋        | 5/29 [00:00<00:00, 138.04it/s, train_loss=0.00274, val_loss=0.00415]Epoch 23:  21%|██        | 6/29 [00:00<00:00, 149.29it/s, train_loss=0.00274, val_loss=0.00415]Epoch 23:  21%|██        | 6/29 [00:00<00:00, 145.45it/s, train_loss=0.00299, val_loss=0.00415]Epoch 23:  24%|██▍       | 7/29 [00:00<00:00, 155.29it/s, train_loss=0.00299, val_loss=0.00415]Epoch 23:  24%|██▍       | 7/29 [00:00<00:00, 144.68it/s, train_loss=0.00417, val_loss=0.00415]Epoch 23:  28%|██▊       | 8/29 [00:00<00:00, 154.23it/s, train_loss=0.00417, val_loss=0.00415]Epoch 23:  28%|██▊       | 8/29 [00:00<00:00, 144.40it/s, train_loss=0.00385, val_loss=0.00415]Epoch 23:  31%|███       | 9/29 [00:00<00:00, 152.87it/s, train_loss=0.00385, val_loss=0.00415]Epoch 23:  31%|███       | 9/29 [00:00<00:00, 143.97it/s, train_loss=0.0037, val_loss=0.00415] Epoch 23:  34%|███▍      | 10/29 [00:00<00:00, 147.22it/s, train_loss=0.0037, val_loss=0.00415]Epoch 23:  34%|███▍      | 10/29 [00:00<00:00, 139.62it/s, train_loss=0.00324, val_loss=0.00415]Epoch 23:  38%|███▊      | 11/29 [00:00<00:00, 146.20it/s, train_loss=0.00324, val_loss=0.00415]Epoch 23:  38%|███▊      | 11/29 [00:00<00:00, 139.95it/s, train_loss=0.0028, val_loss=0.00415] Epoch 23:  41%|████▏     | 12/29 [00:00<00:00, 145.19it/s, train_loss=0.0028, val_loss=0.00415]Epoch 23:  41%|████▏     | 12/29 [00:00<00:00, 137.72it/s, train_loss=0.00262, val_loss=0.00415]Epoch 23:  45%|████▍     | 13/29 [00:00<00:00, 141.70it/s, train_loss=0.00262, val_loss=0.00415]Epoch 23:  45%|████▍     | 13/29 [00:00<00:00, 134.75it/s, train_loss=0.00433, val_loss=0.00415]Epoch 23:  48%|████▊     | 14/29 [00:00<00:00, 139.65it/s, train_loss=0.00433, val_loss=0.00415]Epoch 23:  48%|████▊     | 14/29 [00:00<00:00, 135.29it/s, train_loss=0.00297, val_loss=0.00415]Epoch 23:  52%|█████▏    | 15/29 [00:00<00:00, 139.88it/s, train_loss=0.00297, val_loss=0.00415]Epoch 23:  52%|█████▏    | 15/29 [00:00<00:00, 135.78it/s, train_loss=0.00386, val_loss=0.00415]Epoch 23:  55%|█████▌    | 16/29 [00:00<00:00, 140.07it/s, train_loss=0.00386, val_loss=0.00415]Epoch 23:  55%|█████▌    | 16/29 [00:00<00:00, 136.31it/s, train_loss=0.00365, val_loss=0.00415]Epoch 23:  59%|█████▊    | 17/29 [00:00<00:00, 139.77it/s, train_loss=0.00365, val_loss=0.00415]Epoch 23:  59%|█████▊    | 17/29 [00:00<00:00, 135.76it/s, train_loss=0.00435, val_loss=0.00415]Epoch 23:  62%|██████▏   | 18/29 [00:00<00:00, 139.13it/s, train_loss=0.00435, val_loss=0.00415]Epoch 23:  62%|██████▏   | 18/29 [00:00<00:00, 136.14it/s, train_loss=0.00247, val_loss=0.00415]Epoch 23:  66%|██████▌   | 19/29 [00:00<00:00, 139.43it/s, train_loss=0.00247, val_loss=0.00415]Epoch 23:  66%|██████▌   | 19/29 [00:00<00:00, 136.50it/s, train_loss=0.00325, val_loss=0.00415]Epoch 23:  69%|██████▉   | 20/29 [00:00<00:00, 139.89it/s, train_loss=0.00325, val_loss=0.00415]Epoch 23:  69%|██████▉   | 20/29 [00:00<00:00, 136.79it/s, train_loss=0.00334, val_loss=0.00415]Epoch 23:  72%|███████▏  | 21/29 [00:00<00:00, 140.09it/s, train_loss=0.00334, val_loss=0.00415]Epoch 23:  72%|███████▏  | 21/29 [00:00<00:00, 137.08it/s, train_loss=0.00353, val_loss=0.00415]Epoch 23:  76%|███████▌  | 22/29 [00:00<00:00, 139.84it/s, train_loss=0.00353, val_loss=0.00415]Epoch 23:  76%|███████▌  | 22/29 [00:00<00:00, 137.21it/s, train_loss=0.00483, val_loss=0.00415]Epoch 23:  79%|███████▉  | 23/29 [00:00<00:00, 139.83it/s, train_loss=0.00483, val_loss=0.00415]Epoch 23:  79%|███████▉  | 23/29 [00:00<00:00, 137.45it/s, train_loss=0.00357, val_loss=0.00415]Epoch 23:  83%|████████▎ | 24/29 [00:00<00:00, 140.18it/s, train_loss=0.00357, val_loss=0.00415]Epoch 23:  83%|████████▎ | 24/29 [00:00<00:00, 137.68it/s, train_loss=0.00295, val_loss=0.00415]Epoch 23:  86%|████████▌ | 25/29 [00:00<00:00, 140.37it/s, train_loss=0.00295, val_loss=0.00415]Epoch 23:  86%|████████▌ | 25/29 [00:00<00:00, 137.86it/s, train_loss=0.00427, val_loss=0.00415]Epoch 23:  90%|████████▉ | 26/29 [00:00<00:00, 140.72it/s, train_loss=0.00427, val_loss=0.00415]Epoch 23:  90%|████████▉ | 26/29 [00:00<00:00, 138.04it/s, train_loss=0.0031, val_loss=0.00415] Epoch 23:  93%|█████████▎| 27/29 [00:00<00:00, 140.70it/s, train_loss=0.0031, val_loss=0.00415]Epoch 23:  93%|█████████▎| 27/29 [00:00<00:00, 138.31it/s, train_loss=0.00394, val_loss=0.00415]Epoch 23:  97%|█████████▋| 28/29 [00:00<00:00, 140.54it/s, train_loss=0.00394, val_loss=0.00415]Epoch 23:  97%|█████████▋| 28/29 [00:00<00:00, 137.91it/s, train_loss=0.00574, val_loss=0.00415]Epoch 23: 100%|██████████| 29/29 [00:00<00:00, 140.35it/s, train_loss=0.00574, val_loss=0.00415]Epoch 23: 100%|██████████| 29/29 [00:00<00:00, 139.81it/s, train_loss=0.00387, val_loss=0.00415]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 188.30it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 226.24it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 241.26it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 252.94it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 260.64it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 266.54it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 270.82it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 271.33it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 271.96it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 272.41it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 272.77it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 273.63it/s][A
                                                                         [AEpoch 23: 100%|██████████| 29/29 [00:00<00:00, 111.97it/s, train_loss=0.00387, val_loss=0.00406]Epoch 23: 100%|██████████| 29/29 [00:00<00:00, 111.56it/s, train_loss=0.00387, val_loss=0.00406]Epoch 23:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00387, val_loss=0.00406]          Epoch 24:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00387, val_loss=0.00406]Epoch 24:   3%|▎         | 1/29 [00:00<00:00, 190.51it/s, train_loss=0.00387, val_loss=0.00406]Epoch 24:   3%|▎         | 1/29 [00:00<00:00, 107.73it/s, train_loss=0.00335, val_loss=0.00406]Epoch 24:   7%|▋         | 2/29 [00:00<00:00, 152.55it/s, train_loss=0.00335, val_loss=0.00406]Epoch 24:   7%|▋         | 2/29 [00:00<00:00, 122.95it/s, train_loss=0.00374, val_loss=0.00406]Epoch 24:  10%|█         | 3/29 [00:00<00:00, 149.91it/s, train_loss=0.00374, val_loss=0.00406]Epoch 24:  10%|█         | 3/29 [00:00<00:00, 129.51it/s, train_loss=0.00318, val_loss=0.00406]Epoch 24:  14%|█▍        | 4/29 [00:00<00:00, 145.24it/s, train_loss=0.00318, val_loss=0.00406]Epoch 24:  14%|█▍        | 4/29 [00:00<00:00, 129.10it/s, train_loss=0.00389, val_loss=0.00406]Epoch 24:  17%|█▋        | 5/29 [00:00<00:00, 142.81it/s, train_loss=0.00389, val_loss=0.00406]Epoch 24:  17%|█▋        | 5/29 [00:00<00:00, 131.39it/s, train_loss=0.00459, val_loss=0.00406]Epoch 24:  21%|██        | 6/29 [00:00<00:00, 143.24it/s, train_loss=0.00459, val_loss=0.00406]Epoch 24:  21%|██        | 6/29 [00:00<00:00, 133.21it/s, train_loss=0.00372, val_loss=0.00406]Epoch 24:  24%|██▍       | 7/29 [00:00<00:00, 143.00it/s, train_loss=0.00372, val_loss=0.00406]Epoch 24:  24%|██▍       | 7/29 [00:00<00:00, 134.74it/s, train_loss=0.0035, val_loss=0.00406] Epoch 24:  28%|██▊       | 8/29 [00:00<00:00, 144.51it/s, train_loss=0.0035, val_loss=0.00406]Epoch 24:  28%|██▊       | 8/29 [00:00<00:00, 135.69it/s, train_loss=0.00457, val_loss=0.00406]Epoch 24:  31%|███       | 9/29 [00:00<00:00, 143.68it/s, train_loss=0.00457, val_loss=0.00406]Epoch 24:  31%|███       | 9/29 [00:00<00:00, 136.59it/s, train_loss=0.00363, val_loss=0.00406]Epoch 24:  34%|███▍      | 10/29 [00:00<00:00, 143.43it/s, train_loss=0.00363, val_loss=0.00406]Epoch 24:  34%|███▍      | 10/29 [00:00<00:00, 137.27it/s, train_loss=0.00377, val_loss=0.00406]Epoch 24:  38%|███▊      | 11/29 [00:00<00:00, 144.06it/s, train_loss=0.00377, val_loss=0.00406]Epoch 24:  38%|███▊      | 11/29 [00:00<00:00, 137.77it/s, train_loss=0.00382, val_loss=0.00406]Epoch 24:  41%|████▏     | 12/29 [00:00<00:00, 143.70it/s, train_loss=0.00382, val_loss=0.00406]Epoch 24:  41%|████▏     | 12/29 [00:00<00:00, 138.17it/s, train_loss=0.00343, val_loss=0.00406]Epoch 24:  45%|████▍     | 13/29 [00:00<00:00, 143.77it/s, train_loss=0.00343, val_loss=0.00406]Epoch 24:  45%|████▍     | 13/29 [00:00<00:00, 138.61it/s, train_loss=0.00412, val_loss=0.00406]Epoch 24:  48%|████▊     | 14/29 [00:00<00:00, 143.68it/s, train_loss=0.00412, val_loss=0.00406]Epoch 24:  48%|████▊     | 14/29 [00:00<00:00, 139.29it/s, train_loss=0.00255, val_loss=0.00406]Epoch 24:  52%|█████▏    | 15/29 [00:00<00:00, 143.38it/s, train_loss=0.00255, val_loss=0.00406]Epoch 24:  52%|█████▏    | 15/29 [00:00<00:00, 138.41it/s, train_loss=0.00266, val_loss=0.00406]Epoch 24:  55%|█████▌    | 16/29 [00:00<00:00, 142.61it/s, train_loss=0.00266, val_loss=0.00406]Epoch 24:  55%|█████▌    | 16/29 [00:00<00:00, 138.74it/s, train_loss=0.00307, val_loss=0.00406]Epoch 24:  59%|█████▊    | 17/29 [00:00<00:00, 142.77it/s, train_loss=0.00307, val_loss=0.00406]Epoch 24:  59%|█████▊    | 17/29 [00:00<00:00, 139.00it/s, train_loss=0.00448, val_loss=0.00406]Epoch 24:  62%|██████▏   | 18/29 [00:00<00:00, 142.78it/s, train_loss=0.00448, val_loss=0.00406]Epoch 24:  62%|██████▏   | 18/29 [00:00<00:00, 139.26it/s, train_loss=0.00222, val_loss=0.00406]Epoch 24:  66%|██████▌   | 19/29 [00:00<00:00, 142.81it/s, train_loss=0.00222, val_loss=0.00406]Epoch 24:  66%|██████▌   | 19/29 [00:00<00:00, 139.57it/s, train_loss=0.00316, val_loss=0.00406]Epoch 24:  69%|██████▉   | 20/29 [00:00<00:00, 142.60it/s, train_loss=0.00316, val_loss=0.00406]Epoch 24:  69%|██████▉   | 20/29 [00:00<00:00, 141.77it/s, train_loss=0.00519, val_loss=0.00406]Epoch 24:  72%|███████▏  | 21/29 [00:00<00:00, 144.54it/s, train_loss=0.00519, val_loss=0.00406]Epoch 24:  72%|███████▏  | 21/29 [00:00<00:00, 142.01it/s, train_loss=0.0028, val_loss=0.00406] Epoch 24:  76%|███████▌  | 22/29 [00:00<00:00, 145.19it/s, train_loss=0.0028, val_loss=0.00406]Epoch 24:  76%|███████▌  | 22/29 [00:00<00:00, 142.11it/s, train_loss=0.00278, val_loss=0.00406]Epoch 24:  79%|███████▉  | 23/29 [00:00<00:00, 145.09it/s, train_loss=0.00278, val_loss=0.00406]Epoch 24:  79%|███████▉  | 23/29 [00:00<00:00, 142.18it/s, train_loss=0.00388, val_loss=0.00406]Epoch 24:  83%|████████▎ | 24/29 [00:00<00:00, 144.98it/s, train_loss=0.00388, val_loss=0.00406]Epoch 24:  83%|████████▎ | 24/29 [00:00<00:00, 142.27it/s, train_loss=0.00369, val_loss=0.00406]Epoch 24:  86%|████████▌ | 25/29 [00:00<00:00, 144.93it/s, train_loss=0.00369, val_loss=0.00406]Epoch 24:  86%|████████▌ | 25/29 [00:00<00:00, 142.41it/s, train_loss=0.00347, val_loss=0.00406]Epoch 24:  90%|████████▉ | 26/29 [00:00<00:00, 144.32it/s, train_loss=0.00347, val_loss=0.00406]Epoch 24:  90%|████████▉ | 26/29 [00:00<00:00, 142.60it/s, train_loss=0.00411, val_loss=0.00406]Epoch 24:  93%|█████████▎| 27/29 [00:00<00:00, 145.08it/s, train_loss=0.00411, val_loss=0.00406]Epoch 24:  93%|█████████▎| 27/29 [00:00<00:00, 142.64it/s, train_loss=0.00298, val_loss=0.00406]Epoch 24:  97%|█████████▋| 28/29 [00:00<00:00, 145.32it/s, train_loss=0.00298, val_loss=0.00406]Epoch 24:  97%|█████████▋| 28/29 [00:00<00:00, 142.69it/s, train_loss=0.00286, val_loss=0.00406]Epoch 24: 100%|██████████| 29/29 [00:00<00:00, 145.27it/s, train_loss=0.00286, val_loss=0.00406]Epoch 24: 100%|██████████| 29/29 [00:00<00:00, 144.62it/s, train_loss=0.00147, val_loss=0.00406]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 195.07it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 237.55it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 256.77it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 268.44it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 273.87it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 275.87it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 277.58it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 277.46it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 278.44it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 277.78it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 278.99it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 280.62it/s][A
                                                                         [AEpoch 24: 100%|██████████| 29/29 [00:00<00:00, 115.25it/s, train_loss=0.00147, val_loss=0.00398]Epoch 24: 100%|██████████| 29/29 [00:00<00:00, 114.85it/s, train_loss=0.00147, val_loss=0.00398]Epoch 24:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00147, val_loss=0.00398]          Epoch 25:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00147, val_loss=0.00398]Epoch 25:   3%|▎         | 1/29 [00:00<00:00, 196.34it/s, train_loss=0.00147, val_loss=0.00398]Epoch 25:   3%|▎         | 1/29 [00:00<00:00, 107.69it/s, train_loss=0.0035, val_loss=0.00398] Epoch 25:   7%|▋         | 2/29 [00:00<00:00, 149.02it/s, train_loss=0.0035, val_loss=0.00398]Epoch 25:   7%|▋         | 2/29 [00:00<00:00, 140.23it/s, train_loss=0.00271, val_loss=0.00398]Epoch 25:  10%|█         | 3/29 [00:00<00:00, 161.96it/s, train_loss=0.00271, val_loss=0.00398]Epoch 25:  10%|█         | 3/29 [00:00<00:00, 140.89it/s, train_loss=0.00256, val_loss=0.00398]Epoch 25:  14%|█▍        | 4/29 [00:00<00:00, 159.16it/s, train_loss=0.00256, val_loss=0.00398]Epoch 25:  14%|█▍        | 4/29 [00:00<00:00, 141.28it/s, train_loss=0.00317, val_loss=0.00398]Epoch 25:  17%|█▋        | 5/29 [00:00<00:00, 155.99it/s, train_loss=0.00317, val_loss=0.00398]Epoch 25:  17%|█▋        | 5/29 [00:00<00:00, 141.17it/s, train_loss=0.00323, val_loss=0.00398]Epoch 25:  21%|██        | 6/29 [00:00<00:00, 153.22it/s, train_loss=0.00323, val_loss=0.00398]Epoch 25:  21%|██        | 6/29 [00:00<00:00, 141.43it/s, train_loss=0.00331, val_loss=0.00398]Epoch 25:  24%|██▍       | 7/29 [00:00<00:00, 151.21it/s, train_loss=0.00331, val_loss=0.00398]Epoch 25:  24%|██▍       | 7/29 [00:00<00:00, 141.72it/s, train_loss=0.005, val_loss=0.00398]  Epoch 25:  28%|██▊       | 8/29 [00:00<00:00, 149.04it/s, train_loss=0.005, val_loss=0.00398]Epoch 25:  28%|██▊       | 8/29 [00:00<00:00, 146.44it/s, train_loss=0.00308, val_loss=0.00398]Epoch 25:  31%|███       | 9/29 [00:00<00:00, 153.91it/s, train_loss=0.00308, val_loss=0.00398]Epoch 25:  31%|███       | 9/29 [00:00<00:00, 146.60it/s, train_loss=0.00294, val_loss=0.00398]Epoch 25:  34%|███▍      | 10/29 [00:00<00:00, 154.31it/s, train_loss=0.00294, val_loss=0.00398]Epoch 25:  34%|███▍      | 10/29 [00:00<00:00, 146.16it/s, train_loss=0.00553, val_loss=0.00398]Epoch 25:  38%|███▊      | 11/29 [00:00<00:00, 152.80it/s, train_loss=0.00553, val_loss=0.00398]Epoch 25:  38%|███▊      | 11/29 [00:00<00:00, 145.77it/s, train_loss=0.00334, val_loss=0.00398]Epoch 25:  41%|████▏     | 12/29 [00:00<00:00, 152.03it/s, train_loss=0.00334, val_loss=0.00398]Epoch 25:  41%|████▏     | 12/29 [00:00<00:00, 145.49it/s, train_loss=0.00383, val_loss=0.00398]Epoch 25:  45%|████▍     | 13/29 [00:00<00:00, 151.14it/s, train_loss=0.00383, val_loss=0.00398]Epoch 25:  45%|████▍     | 13/29 [00:00<00:00, 145.32it/s, train_loss=0.00365, val_loss=0.00398]Epoch 25:  48%|████▊     | 14/29 [00:00<00:00, 150.01it/s, train_loss=0.00365, val_loss=0.00398]Epoch 25:  48%|████▊     | 14/29 [00:00<00:00, 148.64it/s, train_loss=0.004, val_loss=0.00398]  Epoch 25:  52%|█████▏    | 15/29 [00:00<00:00, 152.90it/s, train_loss=0.004, val_loss=0.00398]Epoch 25:  52%|█████▏    | 15/29 [00:00<00:00, 148.31it/s, train_loss=0.00277, val_loss=0.00398]Epoch 25:  55%|█████▌    | 16/29 [00:00<00:00, 152.63it/s, train_loss=0.00277, val_loss=0.00398]Epoch 25:  55%|█████▌    | 16/29 [00:00<00:00, 147.98it/s, train_loss=0.00267, val_loss=0.00398]Epoch 25:  59%|█████▊    | 17/29 [00:00<00:00, 152.10it/s, train_loss=0.00267, val_loss=0.00398]Epoch 25:  59%|█████▊    | 17/29 [00:00<00:00, 147.71it/s, train_loss=0.00336, val_loss=0.00398]Epoch 25:  62%|██████▏   | 18/29 [00:00<00:00, 151.56it/s, train_loss=0.00336, val_loss=0.00398]Epoch 25:  62%|██████▏   | 18/29 [00:00<00:00, 147.47it/s, train_loss=0.00333, val_loss=0.00398]Epoch 25:  66%|██████▌   | 19/29 [00:00<00:00, 151.03it/s, train_loss=0.00333, val_loss=0.00398]Epoch 25:  66%|██████▌   | 19/29 [00:00<00:00, 147.31it/s, train_loss=0.00349, val_loss=0.00398]Epoch 25:  69%|██████▉   | 20/29 [00:00<00:00, 150.31it/s, train_loss=0.00349, val_loss=0.00398]Epoch 25:  69%|██████▉   | 20/29 [00:00<00:00, 149.17it/s, train_loss=0.00351, val_loss=0.00398]Epoch 25:  72%|███████▏  | 21/29 [00:00<00:00, 151.78it/s, train_loss=0.00351, val_loss=0.00398]Epoch 25:  72%|███████▏  | 21/29 [00:00<00:00, 148.83it/s, train_loss=0.00364, val_loss=0.00398]Epoch 25:  76%|███████▌  | 22/29 [00:00<00:00, 151.83it/s, train_loss=0.00364, val_loss=0.00398]Epoch 25:  76%|███████▌  | 22/29 [00:00<00:00, 148.50it/s, train_loss=0.00296, val_loss=0.00398]Epoch 25:  79%|███████▉  | 23/29 [00:00<00:00, 151.43it/s, train_loss=0.00296, val_loss=0.00398]Epoch 25:  79%|███████▉  | 23/29 [00:00<00:00, 148.17it/s, train_loss=0.00318, val_loss=0.00398]Epoch 25:  83%|████████▎ | 24/29 [00:00<00:00, 151.03it/s, train_loss=0.00318, val_loss=0.00398]Epoch 25:  83%|████████▎ | 24/29 [00:00<00:00, 147.86it/s, train_loss=0.00341, val_loss=0.00398]Epoch 25:  86%|████████▌ | 25/29 [00:00<00:00, 150.53it/s, train_loss=0.00341, val_loss=0.00398]Epoch 25:  86%|████████▌ | 25/29 [00:00<00:00, 147.63it/s, train_loss=0.00319, val_loss=0.00398]Epoch 25:  90%|████████▉ | 26/29 [00:00<00:00, 150.25it/s, train_loss=0.00319, val_loss=0.00398]Epoch 25:  90%|████████▉ | 26/29 [00:00<00:00, 149.06it/s, train_loss=0.00274, val_loss=0.00398]Epoch 25:  93%|█████████▎| 27/29 [00:00<00:00, 149.97it/s, train_loss=0.00274, val_loss=0.00398]Epoch 25:  93%|█████████▎| 27/29 [00:00<00:00, 146.55it/s, train_loss=0.00471, val_loss=0.00398]Epoch 25:  97%|█████████▋| 28/29 [00:00<00:00, 149.35it/s, train_loss=0.00471, val_loss=0.00398]Epoch 25:  97%|█████████▋| 28/29 [00:00<00:00, 146.38it/s, train_loss=0.00401, val_loss=0.00398]Epoch 25: 100%|██████████| 29/29 [00:00<00:00, 149.09it/s, train_loss=0.00401, val_loss=0.00398]Epoch 25: 100%|██████████| 29/29 [00:00<00:00, 146.42it/s, train_loss=0.00711, val_loss=0.00398]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 213.32it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 251.11it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 270.04it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 281.84it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 287.36it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 287.98it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 289.68it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 290.92it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 292.15it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 291.97it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 292.17it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 293.13it/s][A
                                                                         [AEpoch 25: 100%|██████████| 29/29 [00:00<00:00, 117.36it/s, train_loss=0.00711, val_loss=0.00391]Epoch 25: 100%|██████████| 29/29 [00:00<00:00, 116.94it/s, train_loss=0.00711, val_loss=0.00391]Epoch 25:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00711, val_loss=0.00391]          Epoch 26:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00711, val_loss=0.00391]Epoch 26:   3%|▎         | 1/29 [00:00<00:00, 201.81it/s, train_loss=0.00711, val_loss=0.00391]Epoch 26:   3%|▎         | 1/29 [00:00<00:00, 106.79it/s, train_loss=0.00343, val_loss=0.00391]Epoch 26:   7%|▋         | 2/29 [00:00<00:00, 154.02it/s, train_loss=0.00343, val_loss=0.00391]Epoch 26:   7%|▋         | 2/29 [00:00<00:00, 120.87it/s, train_loss=0.00529, val_loss=0.00391]Epoch 26:  10%|█         | 3/29 [00:00<00:00, 144.36it/s, train_loss=0.00529, val_loss=0.00391]Epoch 26:  10%|█         | 3/29 [00:00<00:00, 127.73it/s, train_loss=0.004, val_loss=0.00391]  Epoch 26:  14%|█▍        | 4/29 [00:00<00:00, 145.70it/s, train_loss=0.004, val_loss=0.00391]Epoch 26:  14%|█▍        | 4/29 [00:00<00:00, 130.41it/s, train_loss=0.0032, val_loss=0.00391]Epoch 26:  17%|█▋        | 5/29 [00:00<00:00, 145.72it/s, train_loss=0.0032, val_loss=0.00391]Epoch 26:  17%|█▋        | 5/29 [00:00<00:00, 132.10it/s, train_loss=0.0033, val_loss=0.00391]Epoch 26:  21%|██        | 6/29 [00:00<00:00, 144.18it/s, train_loss=0.0033, val_loss=0.00391]Epoch 26:  21%|██        | 6/29 [00:00<00:00, 133.26it/s, train_loss=0.00301, val_loss=0.00391]Epoch 26:  24%|██▍       | 7/29 [00:00<00:00, 143.30it/s, train_loss=0.00301, val_loss=0.00391]Epoch 26:  24%|██▍       | 7/29 [00:00<00:00, 134.36it/s, train_loss=0.00376, val_loss=0.00391]Epoch 26:  28%|██▊       | 8/29 [00:00<00:00, 143.23it/s, train_loss=0.00376, val_loss=0.00391]Epoch 26:  28%|██▊       | 8/29 [00:00<00:00, 135.17it/s, train_loss=0.00221, val_loss=0.00391]Epoch 26:  31%|███       | 9/29 [00:00<00:00, 141.32it/s, train_loss=0.00221, val_loss=0.00391]Epoch 26:  31%|███       | 9/29 [00:00<00:00, 131.73it/s, train_loss=0.00383, val_loss=0.00391]Epoch 26:  34%|███▍      | 10/29 [00:00<00:00, 138.83it/s, train_loss=0.00383, val_loss=0.00391]Epoch 26:  34%|███▍      | 10/29 [00:00<00:00, 132.65it/s, train_loss=0.00236, val_loss=0.00391]Epoch 26:  38%|███▊      | 11/29 [00:00<00:00, 139.71it/s, train_loss=0.00236, val_loss=0.00391]Epoch 26:  38%|███▊      | 11/29 [00:00<00:00, 133.20it/s, train_loss=0.00372, val_loss=0.00391]Epoch 26:  41%|████▏     | 12/29 [00:00<00:00, 139.65it/s, train_loss=0.00372, val_loss=0.00391]Epoch 26:  41%|████▏     | 12/29 [00:00<00:00, 133.80it/s, train_loss=0.00493, val_loss=0.00391]Epoch 26:  45%|████▍     | 13/29 [00:00<00:00, 139.60it/s, train_loss=0.00493, val_loss=0.00391]Epoch 26:  45%|████▍     | 13/29 [00:00<00:00, 134.42it/s, train_loss=0.00299, val_loss=0.00391]Epoch 26:  48%|████▊     | 14/29 [00:00<00:00, 139.83it/s, train_loss=0.00299, val_loss=0.00391]Epoch 26:  48%|████▊     | 14/29 [00:00<00:00, 137.32it/s, train_loss=0.0039, val_loss=0.00391] Epoch 26:  52%|█████▏    | 15/29 [00:00<00:00, 141.78it/s, train_loss=0.0039, val_loss=0.00391]Epoch 26:  52%|█████▏    | 15/29 [00:00<00:00, 136.64it/s, train_loss=0.00448, val_loss=0.00391]Epoch 26:  55%|█████▌    | 16/29 [00:00<00:00, 141.14it/s, train_loss=0.00448, val_loss=0.00391]Epoch 26:  55%|█████▌    | 16/29 [00:00<00:00, 136.92it/s, train_loss=0.00346, val_loss=0.00391]Epoch 26:  59%|█████▊    | 17/29 [00:00<00:00, 141.31it/s, train_loss=0.00346, val_loss=0.00391]Epoch 26:  59%|█████▊    | 17/29 [00:00<00:00, 137.13it/s, train_loss=0.00254, val_loss=0.00391]Epoch 26:  62%|██████▏   | 18/29 [00:00<00:00, 141.21it/s, train_loss=0.00254, val_loss=0.00391]Epoch 26:  62%|██████▏   | 18/29 [00:00<00:00, 137.37it/s, train_loss=0.00302, val_loss=0.00391]Epoch 26:  66%|██████▌   | 19/29 [00:00<00:00, 141.23it/s, train_loss=0.00302, val_loss=0.00391]Epoch 26:  66%|██████▌   | 19/29 [00:00<00:00, 137.58it/s, train_loss=0.00368, val_loss=0.00391]Epoch 26:  69%|██████▉   | 20/29 [00:00<00:00, 141.05it/s, train_loss=0.00368, val_loss=0.00391]Epoch 26:  69%|██████▉   | 20/29 [00:00<00:00, 139.72it/s, train_loss=0.00411, val_loss=0.00391]Epoch 26:  72%|███████▏  | 21/29 [00:00<00:00, 142.62it/s, train_loss=0.00411, val_loss=0.00391]Epoch 26:  72%|███████▏  | 21/29 [00:00<00:00, 139.00it/s, train_loss=0.00386, val_loss=0.00391]Epoch 26:  76%|███████▌  | 22/29 [00:00<00:00, 142.07it/s, train_loss=0.00386, val_loss=0.00391]Epoch 26:  76%|███████▌  | 22/29 [00:00<00:00, 139.12it/s, train_loss=0.0023, val_loss=0.00391] Epoch 26:  79%|███████▉  | 23/29 [00:00<00:00, 142.08it/s, train_loss=0.0023, val_loss=0.00391]Epoch 26:  79%|███████▉  | 23/29 [00:00<00:00, 139.22it/s, train_loss=0.00287, val_loss=0.00391]Epoch 26:  83%|████████▎ | 24/29 [00:00<00:00, 142.02it/s, train_loss=0.00287, val_loss=0.00391]Epoch 26:  83%|████████▎ | 24/29 [00:00<00:00, 139.33it/s, train_loss=0.00343, val_loss=0.00391]Epoch 26:  86%|████████▌ | 25/29 [00:00<00:00, 142.03it/s, train_loss=0.00343, val_loss=0.00391]Epoch 26:  86%|████████▌ | 25/29 [00:00<00:00, 139.44it/s, train_loss=0.00287, val_loss=0.00391]Epoch 26:  90%|████████▉ | 26/29 [00:00<00:00, 142.13it/s, train_loss=0.00287, val_loss=0.00391]Epoch 26:  90%|████████▉ | 26/29 [00:00<00:00, 140.76it/s, train_loss=0.00259, val_loss=0.00391]Epoch 26:  93%|█████████▎| 27/29 [00:00<00:00, 142.89it/s, train_loss=0.00259, val_loss=0.00391]Epoch 26:  93%|█████████▎| 27/29 [00:00<00:00, 140.19it/s, train_loss=0.00344, val_loss=0.00391]Epoch 26:  97%|█████████▋| 28/29 [00:00<00:00, 142.46it/s, train_loss=0.00344, val_loss=0.00391]Epoch 26:  97%|█████████▋| 28/29 [00:00<00:00, 140.22it/s, train_loss=0.00325, val_loss=0.00391]Epoch 26: 100%|██████████| 29/29 [00:00<00:00, 142.90it/s, train_loss=0.00325, val_loss=0.00391]Epoch 26: 100%|██████████| 29/29 [00:00<00:00, 140.48it/s, train_loss=0.00284, val_loss=0.00391]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 214.21it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 260.40it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 278.21it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 288.97it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 296.69it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 298.39it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 299.24it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 300.63it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 301.47it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 300.19it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 298.84it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 296.71it/s][A
                                                                         [AEpoch 26: 100%|██████████| 29/29 [00:00<00:00, 114.20it/s, train_loss=0.00284, val_loss=0.00384]Epoch 26: 100%|██████████| 29/29 [00:00<00:00, 113.81it/s, train_loss=0.00284, val_loss=0.00384]Epoch 26:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00284, val_loss=0.00384]          Epoch 27:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00284, val_loss=0.00384]Epoch 27:   3%|▎         | 1/29 [00:00<00:00, 199.73it/s, train_loss=0.00284, val_loss=0.00384]Epoch 27:   3%|▎         | 1/29 [00:00<00:00, 106.59it/s, train_loss=0.00353, val_loss=0.00384]Epoch 27:   7%|▋         | 2/29 [00:00<00:00, 148.79it/s, train_loss=0.00353, val_loss=0.00384]Epoch 27:   7%|▋         | 2/29 [00:00<00:00, 121.24it/s, train_loss=0.00391, val_loss=0.00384]Epoch 27:  10%|█         | 3/29 [00:00<00:00, 147.97it/s, train_loss=0.00391, val_loss=0.00384]Epoch 27:  10%|█         | 3/29 [00:00<00:00, 126.95it/s, train_loss=0.00388, val_loss=0.00384]Epoch 27:  14%|█▍        | 4/29 [00:00<00:00, 141.90it/s, train_loss=0.00388, val_loss=0.00384]Epoch 27:  14%|█▍        | 4/29 [00:00<00:00, 121.28it/s, train_loss=0.00299, val_loss=0.00384]Epoch 27:  17%|█▋        | 5/29 [00:00<00:00, 135.60it/s, train_loss=0.00299, val_loss=0.00384]Epoch 27:  17%|█▋        | 5/29 [00:00<00:00, 124.66it/s, train_loss=0.00344, val_loss=0.00384]Epoch 27:  21%|██        | 6/29 [00:00<00:00, 136.61it/s, train_loss=0.00344, val_loss=0.00384]Epoch 27:  21%|██        | 6/29 [00:00<00:00, 127.01it/s, train_loss=0.00368, val_loss=0.00384]Epoch 27:  24%|██▍       | 7/29 [00:00<00:00, 137.41it/s, train_loss=0.00368, val_loss=0.00384]Epoch 27:  24%|██▍       | 7/29 [00:00<00:00, 128.75it/s, train_loss=0.00333, val_loss=0.00384]Epoch 27:  28%|██▊       | 8/29 [00:00<00:00, 137.72it/s, train_loss=0.00333, val_loss=0.00384]Epoch 27:  28%|██▊       | 8/29 [00:00<00:00, 130.20it/s, train_loss=0.00262, val_loss=0.00384]Epoch 27:  31%|███       | 9/29 [00:00<00:00, 138.14it/s, train_loss=0.00262, val_loss=0.00384]Epoch 27:  31%|███       | 9/29 [00:00<00:00, 134.22it/s, train_loss=0.00348, val_loss=0.00384]Epoch 27:  34%|███▍      | 10/29 [00:00<00:00, 140.44it/s, train_loss=0.00348, val_loss=0.00384]Epoch 27:  34%|███▍      | 10/29 [00:00<00:00, 133.46it/s, train_loss=0.00382, val_loss=0.00384]Epoch 27:  38%|███▊      | 11/29 [00:00<00:00, 140.32it/s, train_loss=0.00382, val_loss=0.00384]Epoch 27:  38%|███▊      | 11/29 [00:00<00:00, 134.16it/s, train_loss=0.00243, val_loss=0.00384]Epoch 27:  41%|████▏     | 12/29 [00:00<00:00, 140.09it/s, train_loss=0.00243, val_loss=0.00384]Epoch 27:  41%|████▏     | 12/29 [00:00<00:00, 134.72it/s, train_loss=0.00346, val_loss=0.00384]Epoch 27:  45%|████▍     | 13/29 [00:00<00:00, 140.27it/s, train_loss=0.00346, val_loss=0.00384]Epoch 27:  45%|████▍     | 13/29 [00:00<00:00, 135.18it/s, train_loss=0.00235, val_loss=0.00384]Epoch 27:  48%|████▊     | 14/29 [00:00<00:00, 140.59it/s, train_loss=0.00235, val_loss=0.00384]Epoch 27:  48%|████▊     | 14/29 [00:00<00:00, 135.57it/s, train_loss=0.0023, val_loss=0.00384] Epoch 27:  52%|█████▏    | 15/29 [00:00<00:00, 140.52it/s, train_loss=0.0023, val_loss=0.00384]Epoch 27:  52%|█████▏    | 15/29 [00:00<00:00, 137.94it/s, train_loss=0.00399, val_loss=0.00384]Epoch 27:  55%|█████▌    | 16/29 [00:00<00:00, 141.86it/s, train_loss=0.00399, val_loss=0.00384]Epoch 27:  55%|█████▌    | 16/29 [00:00<00:00, 137.24it/s, train_loss=0.00269, val_loss=0.00384]Epoch 27:  59%|█████▊    | 17/29 [00:00<00:00, 141.28it/s, train_loss=0.00269, val_loss=0.00384]Epoch 27:  59%|█████▊    | 17/29 [00:00<00:00, 137.48it/s, train_loss=0.00307, val_loss=0.00384]Epoch 27:  62%|██████▏   | 18/29 [00:00<00:00, 141.41it/s, train_loss=0.00307, val_loss=0.00384]Epoch 27:  62%|██████▏   | 18/29 [00:00<00:00, 137.63it/s, train_loss=0.00294, val_loss=0.00384]Epoch 27:  66%|██████▌   | 19/29 [00:00<00:00, 141.29it/s, train_loss=0.00294, val_loss=0.00384]Epoch 27:  66%|██████▌   | 19/29 [00:00<00:00, 137.85it/s, train_loss=0.00368, val_loss=0.00384]Epoch 27:  69%|██████▉   | 20/29 [00:00<00:00, 141.29it/s, train_loss=0.00368, val_loss=0.00384]Epoch 27:  69%|██████▉   | 20/29 [00:00<00:00, 138.01it/s, train_loss=0.00295, val_loss=0.00384]Epoch 27:  72%|███████▏  | 21/29 [00:00<00:00, 141.30it/s, train_loss=0.00295, val_loss=0.00384]Epoch 27:  72%|███████▏  | 21/29 [00:00<00:00, 139.79it/s, train_loss=0.00508, val_loss=0.00384]Epoch 27:  76%|███████▌  | 22/29 [00:00<00:00, 142.63it/s, train_loss=0.00508, val_loss=0.00384]Epoch 27:  76%|███████▌  | 22/29 [00:00<00:00, 139.19it/s, train_loss=0.00231, val_loss=0.00384]Epoch 27:  79%|███████▉  | 23/29 [00:00<00:00, 142.16it/s, train_loss=0.00231, val_loss=0.00384]Epoch 27:  79%|███████▉  | 23/29 [00:00<00:00, 139.30it/s, train_loss=0.00319, val_loss=0.00384]Epoch 27:  83%|████████▎ | 24/29 [00:00<00:00, 142.22it/s, train_loss=0.00319, val_loss=0.00384]Epoch 27:  83%|████████▎ | 24/29 [00:00<00:00, 139.36it/s, train_loss=0.00305, val_loss=0.00384]Epoch 27:  86%|████████▌ | 25/29 [00:00<00:00, 142.15it/s, train_loss=0.00305, val_loss=0.00384]Epoch 27:  86%|████████▌ | 25/29 [00:00<00:00, 139.45it/s, train_loss=0.00357, val_loss=0.00384]Epoch 27:  90%|████████▉ | 26/29 [00:00<00:00, 142.14it/s, train_loss=0.00357, val_loss=0.00384]Epoch 27:  90%|████████▉ | 26/29 [00:00<00:00, 139.57it/s, train_loss=0.00295, val_loss=0.00384]Epoch 27:  93%|█████████▎| 27/29 [00:00<00:00, 142.06it/s, train_loss=0.00295, val_loss=0.00384]Epoch 27:  93%|█████████▎| 27/29 [00:00<00:00, 140.64it/s, train_loss=0.00497, val_loss=0.00384]Epoch 27:  97%|█████████▋| 28/29 [00:00<00:00, 142.71it/s, train_loss=0.00497, val_loss=0.00384]Epoch 27:  97%|█████████▋| 28/29 [00:00<00:00, 140.14it/s, train_loss=0.00375, val_loss=0.00384]Epoch 27: 100%|██████████| 29/29 [00:00<00:00, 142.47it/s, train_loss=0.00375, val_loss=0.00384]Epoch 27: 100%|██████████| 29/29 [00:00<00:00, 140.46it/s, train_loss=0.00609, val_loss=0.00384]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 227.09it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 273.85it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 291.91it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 299.68it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 303.71it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 309.15it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 314.07it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 316.21it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 316.37it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 313.85it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 311.11it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 309.17it/s][A
                                                                         [AEpoch 27: 100%|██████████| 29/29 [00:00<00:00, 114.16it/s, train_loss=0.00609, val_loss=0.0038] Epoch 27: 100%|██████████| 29/29 [00:00<00:00, 113.75it/s, train_loss=0.00609, val_loss=0.0038]Epoch 27:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00609, val_loss=0.0038]          Epoch 28:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00609, val_loss=0.0038]Epoch 28:   3%|▎         | 1/29 [00:00<00:00, 197.50it/s, train_loss=0.00609, val_loss=0.0038]Epoch 28:   3%|▎         | 1/29 [00:00<00:00, 124.79it/s, train_loss=0.00475, val_loss=0.0038]Epoch 28:   7%|▋         | 2/29 [00:00<00:00, 169.34it/s, train_loss=0.00475, val_loss=0.0038]Epoch 28:   7%|▋         | 2/29 [00:00<00:00, 131.65it/s, train_loss=0.00335, val_loss=0.0038]Epoch 28:  10%|█         | 3/29 [00:00<00:00, 159.39it/s, train_loss=0.00335, val_loss=0.0038]Epoch 28:  10%|█         | 3/29 [00:00<00:00, 134.05it/s, train_loss=0.0029, val_loss=0.0038] Epoch 28:  14%|█▍        | 4/29 [00:00<00:00, 153.53it/s, train_loss=0.0029, val_loss=0.0038]Epoch 28:  14%|█▍        | 4/29 [00:00<00:00, 135.68it/s, train_loss=0.00334, val_loss=0.0038]Epoch 28:  17%|█▋        | 5/29 [00:00<00:00, 150.60it/s, train_loss=0.00334, val_loss=0.0038]Epoch 28:  17%|█▋        | 5/29 [00:00<00:00, 136.80it/s, train_loss=0.00283, val_loss=0.0038]Epoch 28:  21%|██        | 6/29 [00:00<00:00, 148.86it/s, train_loss=0.00283, val_loss=0.0038]Epoch 28:  21%|██        | 6/29 [00:00<00:00, 141.92it/s, train_loss=0.00327, val_loss=0.0038]Epoch 28:  24%|██▍       | 7/29 [00:00<00:00, 150.66it/s, train_loss=0.00327, val_loss=0.0038]Epoch 28:  24%|██▍       | 7/29 [00:00<00:00, 139.72it/s, train_loss=0.00335, val_loss=0.0038]Epoch 28:  28%|██▊       | 8/29 [00:00<00:00, 148.13it/s, train_loss=0.00335, val_loss=0.0038]Epoch 28:  28%|██▊       | 8/29 [00:00<00:00, 139.96it/s, train_loss=0.003, val_loss=0.0038]  Epoch 28:  31%|███       | 9/29 [00:00<00:00, 147.50it/s, train_loss=0.003, val_loss=0.0038]Epoch 28:  31%|███       | 9/29 [00:00<00:00, 140.12it/s, train_loss=0.00386, val_loss=0.0038]Epoch 28:  34%|███▍      | 10/29 [00:00<00:00, 147.08it/s, train_loss=0.00386, val_loss=0.0038]Epoch 28:  34%|███▍      | 10/29 [00:00<00:00, 140.04it/s, train_loss=0.00371, val_loss=0.0038]Epoch 28:  38%|███▊      | 11/29 [00:00<00:00, 146.33it/s, train_loss=0.00371, val_loss=0.0038]Epoch 28:  38%|███▊      | 11/29 [00:00<00:00, 140.25it/s, train_loss=0.00309, val_loss=0.0038]Epoch 28:  41%|████▏     | 12/29 [00:00<00:00, 146.81it/s, train_loss=0.00309, val_loss=0.0038]Epoch 28:  41%|████▏     | 12/29 [00:00<00:00, 143.09it/s, train_loss=0.00445, val_loss=0.0038]Epoch 28:  45%|████▍     | 13/29 [00:00<00:00, 148.35it/s, train_loss=0.00445, val_loss=0.0038]Epoch 28:  45%|████▍     | 13/29 [00:00<00:00, 141.82it/s, train_loss=0.00246, val_loss=0.0038]Epoch 28:  48%|████▊     | 14/29 [00:00<00:00, 146.96it/s, train_loss=0.00246, val_loss=0.0038]Epoch 28:  48%|████▊     | 14/29 [00:00<00:00, 141.76it/s, train_loss=0.00384, val_loss=0.0038]Epoch 28:  52%|█████▏    | 15/29 [00:00<00:00, 146.91it/s, train_loss=0.00384, val_loss=0.0038]Epoch 28:  52%|█████▏    | 15/29 [00:00<00:00, 141.71it/s, train_loss=0.00382, val_loss=0.0038]Epoch 28:  55%|█████▌    | 16/29 [00:00<00:00, 146.27it/s, train_loss=0.00382, val_loss=0.0038]Epoch 28:  55%|█████▌    | 16/29 [00:00<00:00, 141.74it/s, train_loss=0.00288, val_loss=0.0038]Epoch 28:  59%|█████▊    | 17/29 [00:00<00:00, 145.82it/s, train_loss=0.00288, val_loss=0.0038]Epoch 28:  59%|█████▊    | 17/29 [00:00<00:00, 141.80it/s, train_loss=0.00312, val_loss=0.0038]Epoch 28:  62%|██████▏   | 18/29 [00:00<00:00, 145.76it/s, train_loss=0.00312, val_loss=0.0038]Epoch 28:  62%|██████▏   | 18/29 [00:00<00:00, 143.37it/s, train_loss=0.00328, val_loss=0.0038]Epoch 28:  66%|██████▌   | 19/29 [00:00<00:00, 146.62it/s, train_loss=0.00328, val_loss=0.0038]Epoch 28:  66%|██████▌   | 19/29 [00:00<00:00, 142.54it/s, train_loss=0.00343, val_loss=0.0038]Epoch 28:  69%|██████▉   | 20/29 [00:00<00:00, 145.93it/s, train_loss=0.00343, val_loss=0.0038]Epoch 28:  69%|██████▉   | 20/29 [00:00<00:00, 142.49it/s, train_loss=0.00325, val_loss=0.0038]Epoch 28:  72%|███████▏  | 21/29 [00:00<00:00, 145.80it/s, train_loss=0.00325, val_loss=0.0038]Epoch 28:  72%|███████▏  | 21/29 [00:00<00:00, 142.43it/s, train_loss=0.00337, val_loss=0.0038]Epoch 28:  76%|███████▌  | 22/29 [00:00<00:00, 145.43it/s, train_loss=0.00337, val_loss=0.0038]Epoch 28:  76%|███████▌  | 22/29 [00:00<00:00, 142.36it/s, train_loss=0.0039, val_loss=0.0038] Epoch 28:  79%|███████▉  | 23/29 [00:00<00:00, 145.38it/s, train_loss=0.0039, val_loss=0.0038]Epoch 28:  79%|███████▉  | 23/29 [00:00<00:00, 142.39it/s, train_loss=0.00301, val_loss=0.0038]Epoch 28:  83%|████████▎ | 24/29 [00:00<00:00, 145.28it/s, train_loss=0.00301, val_loss=0.0038]Epoch 28:  83%|████████▎ | 24/29 [00:00<00:00, 143.86it/s, train_loss=0.00331, val_loss=0.0038]Epoch 28:  86%|████████▌ | 25/29 [00:00<00:00, 146.30it/s, train_loss=0.00331, val_loss=0.0038]Epoch 28:  86%|████████▌ | 25/29 [00:00<00:00, 143.10it/s, train_loss=0.00232, val_loss=0.0038]Epoch 28:  90%|████████▉ | 26/29 [00:00<00:00, 145.69it/s, train_loss=0.00232, val_loss=0.0038]Epoch 28:  90%|████████▉ | 26/29 [00:00<00:00, 143.05it/s, train_loss=0.00259, val_loss=0.0038]Epoch 28:  93%|█████████▎| 27/29 [00:00<00:00, 145.59it/s, train_loss=0.00259, val_loss=0.0038]Epoch 28:  93%|█████████▎| 27/29 [00:00<00:00, 142.99it/s, train_loss=0.00306, val_loss=0.0038]Epoch 28:  97%|█████████▋| 28/29 [00:00<00:00, 145.46it/s, train_loss=0.00306, val_loss=0.0038]Epoch 28:  97%|█████████▋| 28/29 [00:00<00:00, 142.96it/s, train_loss=0.00324, val_loss=0.0038]Epoch 28: 100%|██████████| 29/29 [00:00<00:00, 145.37it/s, train_loss=0.00324, val_loss=0.0038]Epoch 28: 100%|██████████| 29/29 [00:00<00:00, 144.66it/s, train_loss=0.00207, val_loss=0.0038]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 275.60it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 309.67it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 328.12it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 337.20it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 340.10it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 341.11it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 342.44it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 340.36it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 340.21it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 338.36it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 336.65it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 336.53it/s][A
                                                                         [AEpoch 28: 100%|██████████| 29/29 [00:00<00:00, 119.62it/s, train_loss=0.00207, val_loss=0.00376]Epoch 28: 100%|██████████| 29/29 [00:00<00:00, 119.20it/s, train_loss=0.00207, val_loss=0.00376]Epoch 28:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00207, val_loss=0.00376]          Epoch 29:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00207, val_loss=0.00376]Epoch 29:   3%|▎         | 1/29 [00:00<00:00, 216.11it/s, train_loss=0.00207, val_loss=0.00376]Epoch 29:   3%|▎         | 1/29 [00:00<00:00, 105.65it/s, train_loss=0.00422, val_loss=0.00376]Epoch 29:   7%|▋         | 2/29 [00:00<00:00, 152.77it/s, train_loss=0.00422, val_loss=0.00376]Epoch 29:   7%|▋         | 2/29 [00:00<00:00, 121.08it/s, train_loss=0.00352, val_loss=0.00376]Epoch 29:  10%|█         | 3/29 [00:00<00:00, 148.44it/s, train_loss=0.00352, val_loss=0.00376]Epoch 29:  10%|█         | 3/29 [00:00<00:00, 136.44it/s, train_loss=0.00272, val_loss=0.00376]Epoch 29:  14%|█▍        | 4/29 [00:00<00:00, 152.86it/s, train_loss=0.00272, val_loss=0.00376]Epoch 29:  14%|█▍        | 4/29 [00:00<00:00, 134.24it/s, train_loss=0.00229, val_loss=0.00376]Epoch 29:  17%|█▋        | 5/29 [00:00<00:00, 148.63it/s, train_loss=0.00229, val_loss=0.00376]Epoch 29:  17%|█▋        | 5/29 [00:00<00:00, 135.75it/s, train_loss=0.0033, val_loss=0.00376] Epoch 29:  21%|██        | 6/29 [00:00<00:00, 148.13it/s, train_loss=0.0033, val_loss=0.00376]Epoch 29:  21%|██        | 6/29 [00:00<00:00, 136.48it/s, train_loss=0.00404, val_loss=0.00376]Epoch 29:  24%|██▍       | 7/29 [00:00<00:00, 146.71it/s, train_loss=0.00404, val_loss=0.00376]Epoch 29:  24%|██▍       | 7/29 [00:00<00:00, 137.19it/s, train_loss=0.004, val_loss=0.00376]  Epoch 29:  28%|██▊       | 8/29 [00:00<00:00, 146.07it/s, train_loss=0.004, val_loss=0.00376]Epoch 29:  28%|██▊       | 8/29 [00:00<00:00, 137.97it/s, train_loss=0.00342, val_loss=0.00376]Epoch 29:  31%|███       | 9/29 [00:00<00:00, 145.76it/s, train_loss=0.00342, val_loss=0.00376]Epoch 29:  31%|███       | 9/29 [00:00<00:00, 141.77it/s, train_loss=0.00374, val_loss=0.00376]Epoch 29:  34%|███▍      | 10/29 [00:00<00:00, 145.48it/s, train_loss=0.00374, val_loss=0.00376]Epoch 29:  34%|███▍      | 10/29 [00:00<00:00, 140.34it/s, train_loss=0.00337, val_loss=0.00376]Epoch 29:  38%|███▊      | 11/29 [00:00<00:00, 146.55it/s, train_loss=0.00337, val_loss=0.00376]Epoch 29:  38%|███▊      | 11/29 [00:00<00:00, 140.53it/s, train_loss=0.00234, val_loss=0.00376]Epoch 29:  41%|████▏     | 12/29 [00:00<00:00, 145.94it/s, train_loss=0.00234, val_loss=0.00376]Epoch 29:  41%|████▏     | 12/29 [00:00<00:00, 140.68it/s, train_loss=0.00359, val_loss=0.00376]Epoch 29:  45%|████▍     | 13/29 [00:00<00:00, 146.77it/s, train_loss=0.00359, val_loss=0.00376]Epoch 29:  45%|████▍     | 13/29 [00:00<00:00, 140.75it/s, train_loss=0.00256, val_loss=0.00376]Epoch 29:  48%|████▊     | 14/29 [00:00<00:00, 146.34it/s, train_loss=0.00256, val_loss=0.00376]Epoch 29:  48%|████▊     | 14/29 [00:00<00:00, 140.91it/s, train_loss=0.00247, val_loss=0.00376]Epoch 29:  52%|█████▏    | 15/29 [00:00<00:00, 146.05it/s, train_loss=0.00247, val_loss=0.00376]Epoch 29:  52%|█████▏    | 15/29 [00:00<00:00, 143.70it/s, train_loss=0.00328, val_loss=0.00376]Epoch 29:  55%|█████▌    | 16/29 [00:00<00:00, 147.84it/s, train_loss=0.00328, val_loss=0.00376]Epoch 29:  55%|█████▌    | 16/29 [00:00<00:00, 142.56it/s, train_loss=0.00317, val_loss=0.00376]Epoch 29:  59%|█████▊    | 17/29 [00:00<00:00, 146.70it/s, train_loss=0.00317, val_loss=0.00376]Epoch 29:  59%|█████▊    | 17/29 [00:00<00:00, 142.56it/s, train_loss=0.00412, val_loss=0.00376]Epoch 29:  62%|██████▏   | 18/29 [00:00<00:00, 146.68it/s, train_loss=0.00412, val_loss=0.00376]Epoch 29:  62%|██████▏   | 18/29 [00:00<00:00, 142.51it/s, train_loss=0.00266, val_loss=0.00376]Epoch 29:  66%|██████▌   | 19/29 [00:00<00:00, 146.28it/s, train_loss=0.00266, val_loss=0.00376]Epoch 29:  66%|██████▌   | 19/29 [00:00<00:00, 142.39it/s, train_loss=0.00292, val_loss=0.00376]Epoch 29:  69%|██████▉   | 20/29 [00:00<00:00, 145.70it/s, train_loss=0.00292, val_loss=0.00376]Epoch 29:  69%|██████▉   | 20/29 [00:00<00:00, 142.45it/s, train_loss=0.00314, val_loss=0.00376]Epoch 29:  72%|███████▏  | 21/29 [00:00<00:00, 145.82it/s, train_loss=0.00314, val_loss=0.00376]Epoch 29:  72%|███████▏  | 21/29 [00:00<00:00, 144.21it/s, train_loss=0.00332, val_loss=0.00376]Epoch 29:  76%|███████▌  | 22/29 [00:00<00:00, 146.99it/s, train_loss=0.00332, val_loss=0.00376]Epoch 29:  76%|███████▌  | 22/29 [00:00<00:00, 143.29it/s, train_loss=0.00256, val_loss=0.00376]Epoch 29:  79%|███████▉  | 23/29 [00:00<00:00, 146.17it/s, train_loss=0.00256, val_loss=0.00376]Epoch 29:  79%|███████▉  | 23/29 [00:00<00:00, 143.27it/s, train_loss=0.00344, val_loss=0.00376]Epoch 29:  83%|████████▎ | 24/29 [00:00<00:00, 146.08it/s, train_loss=0.00344, val_loss=0.00376]Epoch 29:  83%|████████▎ | 24/29 [00:00<00:00, 143.20it/s, train_loss=0.00288, val_loss=0.00376]Epoch 29:  86%|████████▌ | 25/29 [00:00<00:00, 145.95it/s, train_loss=0.00288, val_loss=0.00376]Epoch 29:  86%|████████▌ | 25/29 [00:00<00:00, 143.19it/s, train_loss=0.00387, val_loss=0.00376]Epoch 29:  90%|████████▉ | 26/29 [00:00<00:00, 145.87it/s, train_loss=0.00387, val_loss=0.00376]Epoch 29:  90%|████████▉ | 26/29 [00:00<00:00, 143.17it/s, train_loss=0.00309, val_loss=0.00376]Epoch 29:  93%|█████████▎| 27/29 [00:00<00:00, 145.82it/s, train_loss=0.00309, val_loss=0.00376]Epoch 29:  93%|█████████▎| 27/29 [00:00<00:00, 144.74it/s, train_loss=0.00387, val_loss=0.00376]Epoch 29:  97%|█████████▋| 28/29 [00:00<00:00, 146.97it/s, train_loss=0.00387, val_loss=0.00376]Epoch 29:  97%|█████████▋| 28/29 [00:00<00:00, 144.02it/s, train_loss=0.00346, val_loss=0.00376]Epoch 29: 100%|██████████| 29/29 [00:00<00:00, 146.41it/s, train_loss=0.00346, val_loss=0.00376]Epoch 29: 100%|██████████| 29/29 [00:00<00:00, 145.73it/s, train_loss=0.00312, val_loss=0.00376]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 165.01it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 229.43it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 262.95it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 286.64it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 294.83it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 296.68it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 300.61it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 302.79it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 306.58it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 309.43it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 310.76it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 312.46it/s][A
                                                                         [AEpoch 29: 100%|██████████| 29/29 [00:00<00:00, 118.05it/s, train_loss=0.00312, val_loss=0.00372]Epoch 29: 100%|██████████| 29/29 [00:00<00:00, 117.66it/s, train_loss=0.00312, val_loss=0.00372]Epoch 29:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00312, val_loss=0.00372]          Epoch 30:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00312, val_loss=0.00372]Epoch 30:   3%|▎         | 1/29 [00:00<00:00, 193.91it/s, train_loss=0.00312, val_loss=0.00372]Epoch 30:   3%|▎         | 1/29 [00:00<00:00, 123.92it/s, train_loss=0.00242, val_loss=0.00372]Epoch 30:   7%|▋         | 2/29 [00:00<00:00, 168.56it/s, train_loss=0.00242, val_loss=0.00372]Epoch 30:   7%|▋         | 2/29 [00:00<00:00, 131.95it/s, train_loss=0.00253, val_loss=0.00372]Epoch 30:  10%|█         | 3/29 [00:00<00:00, 159.17it/s, train_loss=0.00253, val_loss=0.00372]Epoch 30:  10%|█         | 3/29 [00:00<00:00, 134.43it/s, train_loss=0.00276, val_loss=0.00372]Epoch 30:  14%|█▍        | 4/29 [00:00<00:00, 154.27it/s, train_loss=0.00276, val_loss=0.00372]Epoch 30:  14%|█▍        | 4/29 [00:00<00:00, 135.26it/s, train_loss=0.00335, val_loss=0.00372]Epoch 30:  17%|█▋        | 5/29 [00:00<00:00, 150.73it/s, train_loss=0.00335, val_loss=0.00372]Epoch 30:  17%|█▋        | 5/29 [00:00<00:00, 136.20it/s, train_loss=0.00389, val_loss=0.00372]Epoch 30:  21%|██        | 6/29 [00:00<00:00, 148.77it/s, train_loss=0.00389, val_loss=0.00372]Epoch 30:  21%|██        | 6/29 [00:00<00:00, 142.14it/s, train_loss=0.00339, val_loss=0.00372]Epoch 30:  24%|██▍       | 7/29 [00:00<00:00, 151.33it/s, train_loss=0.00339, val_loss=0.00372]Epoch 30:  24%|██▍       | 7/29 [00:00<00:00, 139.86it/s, train_loss=0.00402, val_loss=0.00372]Epoch 30:  28%|██▊       | 8/29 [00:00<00:00, 148.45it/s, train_loss=0.00402, val_loss=0.00372]Epoch 30:  28%|██▊       | 8/29 [00:00<00:00, 140.05it/s, train_loss=0.00357, val_loss=0.00372]Epoch 30:  31%|███       | 9/29 [00:00<00:00, 148.02it/s, train_loss=0.00357, val_loss=0.00372]Epoch 30:  31%|███       | 9/29 [00:00<00:00, 140.25it/s, train_loss=0.0031, val_loss=0.00372] Epoch 30:  34%|███▍      | 10/29 [00:00<00:00, 147.24it/s, train_loss=0.0031, val_loss=0.00372]Epoch 30:  34%|███▍      | 10/29 [00:00<00:00, 140.49it/s, train_loss=0.0034, val_loss=0.00372]Epoch 30:  38%|███▊      | 11/29 [00:00<00:00, 146.77it/s, train_loss=0.0034, val_loss=0.00372]Epoch 30:  38%|███▊      | 11/29 [00:00<00:00, 140.68it/s, train_loss=0.00237, val_loss=0.00372]Epoch 30:  41%|████▏     | 12/29 [00:00<00:00, 146.44it/s, train_loss=0.00237, val_loss=0.00372]Epoch 30:  41%|████▏     | 12/29 [00:00<00:00, 144.08it/s, train_loss=0.00244, val_loss=0.00372]Epoch 30:  45%|████▍     | 13/29 [00:00<00:00, 148.11it/s, train_loss=0.00244, val_loss=0.00372]Epoch 30:  45%|████▍     | 13/29 [00:00<00:00, 142.57it/s, train_loss=0.0027, val_loss=0.00372] Epoch 30:  48%|████▊     | 14/29 [00:00<00:00, 147.79it/s, train_loss=0.0027, val_loss=0.00372]Epoch 30:  48%|████▊     | 14/29 [00:00<00:00, 142.51it/s, train_loss=0.00286, val_loss=0.00372]Epoch 30:  52%|█████▏    | 15/29 [00:00<00:00, 147.54it/s, train_loss=0.00286, val_loss=0.00372]Epoch 30:  52%|█████▏    | 15/29 [00:00<00:00, 142.47it/s, train_loss=0.00369, val_loss=0.00372]Epoch 30:  55%|█████▌    | 16/29 [00:00<00:00, 147.10it/s, train_loss=0.00369, val_loss=0.00372]Epoch 30:  55%|█████▌    | 16/29 [00:00<00:00, 142.48it/s, train_loss=0.00275, val_loss=0.00372]Epoch 30:  59%|█████▊    | 17/29 [00:00<00:00, 146.88it/s, train_loss=0.00275, val_loss=0.00372]Epoch 30:  59%|█████▊    | 17/29 [00:00<00:00, 142.50it/s, train_loss=0.00323, val_loss=0.00372]Epoch 30:  62%|██████▏   | 18/29 [00:00<00:00, 146.36it/s, train_loss=0.00323, val_loss=0.00372]Epoch 30:  62%|██████▏   | 18/29 [00:00<00:00, 142.62it/s, train_loss=0.00236, val_loss=0.00372]Epoch 30:  66%|██████▌   | 19/29 [00:00<00:00, 146.09it/s, train_loss=0.00236, val_loss=0.00372]Epoch 30:  66%|██████▌   | 19/29 [00:00<00:00, 142.56it/s, train_loss=0.00456, val_loss=0.00372]Epoch 30:  69%|██████▉   | 20/29 [00:00<00:00, 146.24it/s, train_loss=0.00456, val_loss=0.00372]Epoch 30:  69%|██████▉   | 20/29 [00:00<00:00, 142.57it/s, train_loss=0.00388, val_loss=0.00372]Epoch 30:  72%|███████▏  | 21/29 [00:00<00:00, 145.98it/s, train_loss=0.00388, val_loss=0.00372]Epoch 30:  72%|███████▏  | 21/29 [00:00<00:00, 142.53it/s, train_loss=0.00333, val_loss=0.00372]Epoch 30:  76%|███████▌  | 22/29 [00:00<00:00, 145.79it/s, train_loss=0.00333, val_loss=0.00372]Epoch 30:  76%|███████▌  | 22/29 [00:00<00:00, 142.55it/s, train_loss=0.00305, val_loss=0.00372]Epoch 30:  79%|███████▉  | 23/29 [00:00<00:00, 145.59it/s, train_loss=0.00305, val_loss=0.00372]Epoch 30:  79%|███████▉  | 23/29 [00:00<00:00, 142.62it/s, train_loss=0.00375, val_loss=0.00372]Epoch 30:  83%|████████▎ | 24/29 [00:00<00:00, 145.03it/s, train_loss=0.00375, val_loss=0.00372]Epoch 30:  83%|████████▎ | 24/29 [00:00<00:00, 141.87it/s, train_loss=0.00356, val_loss=0.00372]Epoch 30:  86%|████████▌ | 25/29 [00:00<00:00, 144.53it/s, train_loss=0.00356, val_loss=0.00372]Epoch 30:  86%|████████▌ | 25/29 [00:00<00:00, 141.89it/s, train_loss=0.00387, val_loss=0.00372]Epoch 30:  90%|████████▉ | 26/29 [00:00<00:00, 144.56it/s, train_loss=0.00387, val_loss=0.00372]Epoch 30:  90%|████████▉ | 26/29 [00:00<00:00, 141.88it/s, train_loss=0.00345, val_loss=0.00372]Epoch 30:  93%|█████████▎| 27/29 [00:00<00:00, 144.43it/s, train_loss=0.00345, val_loss=0.00372]Epoch 30:  93%|█████████▎| 27/29 [00:00<00:00, 141.90it/s, train_loss=0.00251, val_loss=0.00372]Epoch 30:  97%|█████████▋| 28/29 [00:00<00:00, 144.45it/s, train_loss=0.00251, val_loss=0.00372]Epoch 30:  97%|█████████▋| 28/29 [00:00<00:00, 141.97it/s, train_loss=0.00368, val_loss=0.00372]Epoch 30: 100%|██████████| 29/29 [00:00<00:00, 144.37it/s, train_loss=0.00368, val_loss=0.00372]Epoch 30: 100%|██████████| 29/29 [00:00<00:00, 143.65it/s, train_loss=0.0023, val_loss=0.00372] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 154.55it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 191.96it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 208.54it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 229.13it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 247.36it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 261.58it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 272.57it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 278.43it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 284.60it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 289.33it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 293.69it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 296.80it/s][A
                                                                         [AEpoch 30: 100%|██████████| 29/29 [00:00<00:00, 115.07it/s, train_loss=0.0023, val_loss=0.00369]Epoch 30: 100%|██████████| 29/29 [00:00<00:00, 114.73it/s, train_loss=0.0023, val_loss=0.00369]Epoch 30:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0023, val_loss=0.00369]          Epoch 31:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0023, val_loss=0.00369]Epoch 31:   3%|▎         | 1/29 [00:00<00:00, 186.26it/s, train_loss=0.0023, val_loss=0.00369]Epoch 31:   3%|▎         | 1/29 [00:00<00:00, 124.53it/s, train_loss=0.00266, val_loss=0.00369]Epoch 31:   7%|▋         | 2/29 [00:00<00:00, 170.21it/s, train_loss=0.00266, val_loss=0.00369]Epoch 31:   7%|▋         | 2/29 [00:00<00:00, 132.57it/s, train_loss=0.00304, val_loss=0.00369]Epoch 31:  10%|█         | 3/29 [00:00<00:00, 160.62it/s, train_loss=0.00304, val_loss=0.00369]Epoch 31:  10%|█         | 3/29 [00:00<00:00, 135.09it/s, train_loss=0.00313, val_loss=0.00369]Epoch 31:  14%|█▍        | 4/29 [00:00<00:00, 154.80it/s, train_loss=0.00313, val_loss=0.00369]Epoch 31:  14%|█▍        | 4/29 [00:00<00:00, 136.38it/s, train_loss=0.00297, val_loss=0.00369]Epoch 31:  17%|█▋        | 5/29 [00:00<00:00, 151.34it/s, train_loss=0.00297, val_loss=0.00369]Epoch 31:  17%|█▋        | 5/29 [00:00<00:00, 137.34it/s, train_loss=0.0029, val_loss=0.00369] Epoch 31:  21%|██        | 6/29 [00:00<00:00, 149.69it/s, train_loss=0.0029, val_loss=0.00369]Epoch 31:  21%|██        | 6/29 [00:00<00:00, 143.03it/s, train_loss=0.00345, val_loss=0.00369]Epoch 31:  24%|██▍       | 7/29 [00:00<00:00, 149.86it/s, train_loss=0.00345, val_loss=0.00369]Epoch 31:  24%|██▍       | 7/29 [00:00<00:00, 140.72it/s, train_loss=0.00251, val_loss=0.00369]Epoch 31:  28%|██▊       | 8/29 [00:00<00:00, 149.25it/s, train_loss=0.00251, val_loss=0.00369]Epoch 31:  28%|██▊       | 8/29 [00:00<00:00, 141.00it/s, train_loss=0.00365, val_loss=0.00369]Epoch 31:  31%|███       | 9/29 [00:00<00:00, 148.77it/s, train_loss=0.00365, val_loss=0.00369]Epoch 31:  31%|███       | 9/29 [00:00<00:00, 141.17it/s, train_loss=0.00275, val_loss=0.00369]Epoch 31:  34%|███▍      | 10/29 [00:00<00:00, 148.17it/s, train_loss=0.00275, val_loss=0.00369]Epoch 31:  34%|███▍      | 10/29 [00:00<00:00, 141.37it/s, train_loss=0.00399, val_loss=0.00369]Epoch 31:  38%|███▊      | 11/29 [00:00<00:00, 147.88it/s, train_loss=0.00399, val_loss=0.00369]Epoch 31:  38%|███▊      | 11/29 [00:00<00:00, 141.58it/s, train_loss=0.00319, val_loss=0.00369]Epoch 31:  41%|████▏     | 12/29 [00:00<00:00, 146.83it/s, train_loss=0.00319, val_loss=0.00369]Epoch 31:  41%|████▏     | 12/29 [00:00<00:00, 145.12it/s, train_loss=0.00353, val_loss=0.00369]Epoch 31:  45%|████▍     | 13/29 [00:00<00:00, 149.65it/s, train_loss=0.00353, val_loss=0.00369]Epoch 31:  45%|████▍     | 13/29 [00:00<00:00, 145.08it/s, train_loss=0.00345, val_loss=0.00369]Epoch 31:  48%|████▊     | 14/29 [00:00<00:00, 150.16it/s, train_loss=0.00345, val_loss=0.00369]Epoch 31:  48%|████▊     | 14/29 [00:00<00:00, 144.88it/s, train_loss=0.00327, val_loss=0.00369]Epoch 31:  52%|█████▏    | 15/29 [00:00<00:00, 150.04it/s, train_loss=0.00327, val_loss=0.00369]Epoch 31:  52%|█████▏    | 15/29 [00:00<00:00, 144.72it/s, train_loss=0.00332, val_loss=0.00369]Epoch 31:  55%|█████▌    | 16/29 [00:00<00:00, 149.37it/s, train_loss=0.00332, val_loss=0.00369]Epoch 31:  55%|█████▌    | 16/29 [00:00<00:00, 144.61it/s, train_loss=0.00355, val_loss=0.00369]Epoch 31:  59%|█████▊    | 17/29 [00:00<00:00, 149.07it/s, train_loss=0.00355, val_loss=0.00369]Epoch 31:  59%|█████▊    | 17/29 [00:00<00:00, 144.52it/s, train_loss=0.00317, val_loss=0.00369]Epoch 31:  62%|██████▏   | 18/29 [00:00<00:00, 148.46it/s, train_loss=0.00317, val_loss=0.00369]Epoch 31:  62%|██████▏   | 18/29 [00:00<00:00, 146.41it/s, train_loss=0.00397, val_loss=0.00369]Epoch 31:  66%|██████▌   | 19/29 [00:00<00:00, 148.84it/s, train_loss=0.00397, val_loss=0.00369]Epoch 31:  66%|██████▌   | 19/29 [00:00<00:00, 144.80it/s, train_loss=0.00295, val_loss=0.00369]Epoch 31:  69%|██████▉   | 20/29 [00:00<00:00, 147.09it/s, train_loss=0.00295, val_loss=0.00369]Epoch 31:  69%|██████▉   | 20/29 [00:00<00:00, 144.72it/s, train_loss=0.00336, val_loss=0.00369]Epoch 31:  72%|███████▏  | 21/29 [00:00<00:00, 146.82it/s, train_loss=0.00336, val_loss=0.00369]Epoch 31:  72%|███████▏  | 21/29 [00:00<00:00, 144.62it/s, train_loss=0.00287, val_loss=0.00369]Epoch 31:  76%|███████▌  | 22/29 [00:00<00:00, 146.64it/s, train_loss=0.00287, val_loss=0.00369]Epoch 31:  76%|███████▌  | 22/29 [00:00<00:00, 144.52it/s, train_loss=0.00398, val_loss=0.00369]Epoch 31:  79%|███████▉  | 23/29 [00:00<00:00, 146.68it/s, train_loss=0.00398, val_loss=0.00369]Epoch 31:  79%|███████▉  | 23/29 [00:00<00:00, 144.45it/s, train_loss=0.00365, val_loss=0.00369]Epoch 31:  83%|████████▎ | 24/29 [00:00<00:00, 146.04it/s, train_loss=0.00365, val_loss=0.00369]Epoch 31:  83%|████████▎ | 24/29 [00:00<00:00, 143.76it/s, train_loss=0.00339, val_loss=0.00369]Epoch 31:  86%|████████▌ | 25/29 [00:00<00:00, 145.29it/s, train_loss=0.00339, val_loss=0.00369]Epoch 31:  86%|████████▌ | 25/29 [00:00<00:00, 143.64it/s, train_loss=0.00313, val_loss=0.00369]Epoch 31:  90%|████████▉ | 26/29 [00:00<00:00, 145.46it/s, train_loss=0.00313, val_loss=0.00369]Epoch 31:  90%|████████▉ | 26/29 [00:00<00:00, 143.59it/s, train_loss=0.00239, val_loss=0.00369]Epoch 31:  93%|█████████▎| 27/29 [00:00<00:00, 145.37it/s, train_loss=0.00239, val_loss=0.00369]Epoch 31:  93%|█████████▎| 27/29 [00:00<00:00, 143.53it/s, train_loss=0.00225, val_loss=0.00369]Epoch 31:  97%|█████████▋| 28/29 [00:00<00:00, 145.40it/s, train_loss=0.00225, val_loss=0.00369]Epoch 31:  97%|█████████▋| 28/29 [00:00<00:00, 143.51it/s, train_loss=0.00315, val_loss=0.00369]Epoch 31: 100%|██████████| 29/29 [00:00<00:00, 144.97it/s, train_loss=0.00315, val_loss=0.00369]Epoch 31: 100%|██████████| 29/29 [00:00<00:00, 143.72it/s, train_loss=0.0034, val_loss=0.00369] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 155.74it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 185.51it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 200.85it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 209.79it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 216.22it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 224.76it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 236.66it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 246.89it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 255.54it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 263.06it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 268.97it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 273.24it/s][A
                                                                         [AEpoch 31: 100%|██████████| 29/29 [00:00<00:00, 113.68it/s, train_loss=0.0034, val_loss=0.00366]Epoch 31: 100%|██████████| 29/29 [00:00<00:00, 113.37it/s, train_loss=0.0034, val_loss=0.00366]Epoch 31:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0034, val_loss=0.00366]          Epoch 32:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0034, val_loss=0.00366]Epoch 32:   3%|▎         | 1/29 [00:00<00:00, 193.95it/s, train_loss=0.0034, val_loss=0.00366]Epoch 32:   3%|▎         | 1/29 [00:00<00:00, 124.38it/s, train_loss=0.00369, val_loss=0.00366]Epoch 32:   7%|▋         | 2/29 [00:00<00:00, 167.77it/s, train_loss=0.00369, val_loss=0.00366]Epoch 32:   7%|▋         | 2/29 [00:00<00:00, 132.41it/s, train_loss=0.00337, val_loss=0.00366]Epoch 32:  10%|█         | 3/29 [00:00<00:00, 159.01it/s, train_loss=0.00337, val_loss=0.00366]Epoch 32:  10%|█         | 3/29 [00:00<00:00, 134.79it/s, train_loss=0.00407, val_loss=0.00366]Epoch 32:  14%|█▍        | 4/29 [00:00<00:00, 154.32it/s, train_loss=0.00407, val_loss=0.00366]Epoch 32:  14%|█▍        | 4/29 [00:00<00:00, 136.28it/s, train_loss=0.00236, val_loss=0.00366]Epoch 32:  17%|█▋        | 5/29 [00:00<00:00, 150.63it/s, train_loss=0.00236, val_loss=0.00366]Epoch 32:  17%|█▋        | 5/29 [00:00<00:00, 137.36it/s, train_loss=0.00252, val_loss=0.00366]Epoch 32:  21%|██        | 6/29 [00:00<00:00, 148.77it/s, train_loss=0.00252, val_loss=0.00366]Epoch 32:  21%|██        | 6/29 [00:00<00:00, 144.58it/s, train_loss=0.00364, val_loss=0.00366]Epoch 32:  24%|██▍       | 7/29 [00:00<00:00, 153.82it/s, train_loss=0.00364, val_loss=0.00366]Epoch 32:  24%|██▍       | 7/29 [00:00<00:00, 144.04it/s, train_loss=0.00255, val_loss=0.00366]Epoch 32:  28%|██▊       | 8/29 [00:00<00:00, 152.73it/s, train_loss=0.00255, val_loss=0.00366]Epoch 32:  28%|██▊       | 8/29 [00:00<00:00, 143.71it/s, train_loss=0.00337, val_loss=0.00366]Epoch 32:  31%|███       | 9/29 [00:00<00:00, 151.22it/s, train_loss=0.00337, val_loss=0.00366]Epoch 32:  31%|███       | 9/29 [00:00<00:00, 143.53it/s, train_loss=0.00306, val_loss=0.00366]Epoch 32:  34%|███▍      | 10/29 [00:00<00:00, 150.38it/s, train_loss=0.00306, val_loss=0.00366]Epoch 32:  34%|███▍      | 10/29 [00:00<00:00, 143.29it/s, train_loss=0.00309, val_loss=0.00366]Epoch 32:  38%|███▊      | 11/29 [00:00<00:00, 149.39it/s, train_loss=0.00309, val_loss=0.00366]Epoch 32:  38%|███▊      | 11/29 [00:00<00:00, 143.33it/s, train_loss=0.00334, val_loss=0.00366]Epoch 32:  41%|████▏     | 12/29 [00:00<00:00, 148.71it/s, train_loss=0.00334, val_loss=0.00366]Epoch 32:  41%|████▏     | 12/29 [00:00<00:00, 146.42it/s, train_loss=0.00322, val_loss=0.00366]Epoch 32:  45%|████▍     | 13/29 [00:00<00:00, 151.03it/s, train_loss=0.00322, val_loss=0.00366]Epoch 32:  45%|████▍     | 13/29 [00:00<00:00, 146.09it/s, train_loss=0.00265, val_loss=0.00366]Epoch 32:  48%|████▊     | 14/29 [00:00<00:00, 150.75it/s, train_loss=0.00265, val_loss=0.00366]Epoch 32:  48%|████▊     | 14/29 [00:00<00:00, 145.84it/s, train_loss=0.00513, val_loss=0.00366]Epoch 32:  52%|█████▏    | 15/29 [00:00<00:00, 150.25it/s, train_loss=0.00513, val_loss=0.00366]Epoch 32:  52%|█████▏    | 15/29 [00:00<00:00, 145.62it/s, train_loss=0.00355, val_loss=0.00366]Epoch 32:  55%|█████▌    | 16/29 [00:00<00:00, 150.45it/s, train_loss=0.00355, val_loss=0.00366]Epoch 32:  55%|█████▌    | 16/29 [00:00<00:00, 145.39it/s, train_loss=0.00273, val_loss=0.00366]Epoch 32:  59%|█████▊    | 17/29 [00:00<00:00, 149.90it/s, train_loss=0.00273, val_loss=0.00366]Epoch 32:  59%|█████▊    | 17/29 [00:00<00:00, 145.24it/s, train_loss=0.00317, val_loss=0.00366]Epoch 32:  62%|██████▏   | 18/29 [00:00<00:00, 149.00it/s, train_loss=0.00317, val_loss=0.00366]Epoch 32:  62%|██████▏   | 18/29 [00:00<00:00, 145.19it/s, train_loss=0.00364, val_loss=0.00366]Epoch 32:  66%|██████▌   | 19/29 [00:00<00:00, 148.58it/s, train_loss=0.00364, val_loss=0.00366]Epoch 32:  66%|██████▌   | 19/29 [00:00<00:00, 145.03it/s, train_loss=0.00252, val_loss=0.00366]Epoch 32:  69%|██████▉   | 20/29 [00:00<00:00, 148.48it/s, train_loss=0.00252, val_loss=0.00366]Epoch 32:  69%|██████▉   | 20/29 [00:00<00:00, 144.91it/s, train_loss=0.00294, val_loss=0.00366]Epoch 32:  72%|███████▏  | 21/29 [00:00<00:00, 148.27it/s, train_loss=0.00294, val_loss=0.00366]Epoch 32:  72%|███████▏  | 21/29 [00:00<00:00, 144.83it/s, train_loss=0.00213, val_loss=0.00366]Epoch 32:  76%|███████▌  | 22/29 [00:00<00:00, 148.07it/s, train_loss=0.00213, val_loss=0.00366]Epoch 32:  76%|███████▌  | 22/29 [00:00<00:00, 144.72it/s, train_loss=0.00288, val_loss=0.00366]Epoch 32:  79%|███████▉  | 23/29 [00:00<00:00, 147.72it/s, train_loss=0.00288, val_loss=0.00366]Epoch 32:  79%|███████▉  | 23/29 [00:00<00:00, 144.66it/s, train_loss=0.00352, val_loss=0.00366]Epoch 32:  83%|████████▎ | 24/29 [00:00<00:00, 147.21it/s, train_loss=0.00352, val_loss=0.00366]Epoch 32:  83%|████████▎ | 24/29 [00:00<00:00, 143.00it/s, train_loss=0.00313, val_loss=0.00366]Epoch 32:  86%|████████▌ | 25/29 [00:00<00:00, 145.56it/s, train_loss=0.00313, val_loss=0.00366]Epoch 32:  86%|████████▌ | 25/29 [00:00<00:00, 143.00it/s, train_loss=0.00352, val_loss=0.00366]Epoch 32:  90%|████████▉ | 26/29 [00:00<00:00, 145.68it/s, train_loss=0.00352, val_loss=0.00366]Epoch 32:  90%|████████▉ | 26/29 [00:00<00:00, 143.00it/s, train_loss=0.0025, val_loss=0.00366] Epoch 32:  93%|█████████▎| 27/29 [00:00<00:00, 145.51it/s, train_loss=0.0025, val_loss=0.00366]Epoch 32:  93%|█████████▎| 27/29 [00:00<00:00, 142.99it/s, train_loss=0.00407, val_loss=0.00366]Epoch 32:  97%|█████████▋| 28/29 [00:00<00:00, 145.33it/s, train_loss=0.00407, val_loss=0.00366]Epoch 32:  97%|█████████▋| 28/29 [00:00<00:00, 143.03it/s, train_loss=0.00262, val_loss=0.00366]Epoch 32: 100%|██████████| 29/29 [00:00<00:00, 145.25it/s, train_loss=0.00262, val_loss=0.00366]Epoch 32: 100%|██████████| 29/29 [00:00<00:00, 144.64it/s, train_loss=0.00408, val_loss=0.00366]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 165.42it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 196.90it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 214.84it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 225.45it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 232.06it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 235.37it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 236.85it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 238.16it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 243.94it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 251.76it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 259.46it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 266.43it/s][A
                                                                         [AEpoch 32: 100%|██████████| 29/29 [00:00<00:00, 114.26it/s, train_loss=0.00408, val_loss=0.00365]Epoch 32: 100%|██████████| 29/29 [00:00<00:00, 113.95it/s, train_loss=0.00408, val_loss=0.00365]Epoch 32:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00408, val_loss=0.00365]          Epoch 33:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00408, val_loss=0.00365]Epoch 33:   3%|▎         | 1/29 [00:00<00:00, 205.56it/s, train_loss=0.00408, val_loss=0.00365]Epoch 33:   3%|▎         | 1/29 [00:00<00:00, 124.70it/s, train_loss=0.00228, val_loss=0.00365]Epoch 33:   7%|▋         | 2/29 [00:00<00:00, 168.65it/s, train_loss=0.00228, val_loss=0.00365]Epoch 33:   7%|▋         | 2/29 [00:00<00:00, 132.66it/s, train_loss=0.00271, val_loss=0.00365]Epoch 33:  10%|█         | 3/29 [00:00<00:00, 160.02it/s, train_loss=0.00271, val_loss=0.00365]Epoch 33:  10%|█         | 3/29 [00:00<00:00, 135.22it/s, train_loss=0.00327, val_loss=0.00365]Epoch 33:  14%|█▍        | 4/29 [00:00<00:00, 154.58it/s, train_loss=0.00327, val_loss=0.00365]Epoch 33:  14%|█▍        | 4/29 [00:00<00:00, 136.89it/s, train_loss=0.00286, val_loss=0.00365]Epoch 33:  17%|█▋        | 5/29 [00:00<00:00, 152.04it/s, train_loss=0.00286, val_loss=0.00365]Epoch 33:  17%|█▋        | 5/29 [00:00<00:00, 138.01it/s, train_loss=0.00269, val_loss=0.00365]Epoch 33:  21%|██        | 6/29 [00:00<00:00, 150.58it/s, train_loss=0.00269, val_loss=0.00365]Epoch 33:  21%|██        | 6/29 [00:00<00:00, 144.96it/s, train_loss=0.0031, val_loss=0.00365] Epoch 33:  24%|██▍       | 7/29 [00:00<00:00, 153.91it/s, train_loss=0.0031, val_loss=0.00365]Epoch 33:  24%|██▍       | 7/29 [00:00<00:00, 141.90it/s, train_loss=0.00322, val_loss=0.00365]Epoch 33:  28%|██▊       | 8/29 [00:00<00:00, 149.55it/s, train_loss=0.00322, val_loss=0.00365]Epoch 33:  28%|██▊       | 8/29 [00:00<00:00, 142.10it/s, train_loss=0.00244, val_loss=0.00365]Epoch 33:  31%|███       | 9/29 [00:00<00:00, 147.53it/s, train_loss=0.00244, val_loss=0.00365]Epoch 33:  31%|███       | 9/29 [00:00<00:00, 137.49it/s, train_loss=0.00307, val_loss=0.00365]Epoch 33:  34%|███▍      | 10/29 [00:00<00:00, 144.53it/s, train_loss=0.00307, val_loss=0.00365]Epoch 33:  34%|███▍      | 10/29 [00:00<00:00, 138.02it/s, train_loss=0.00339, val_loss=0.00365]Epoch 33:  38%|███▊      | 11/29 [00:00<00:00, 144.28it/s, train_loss=0.00339, val_loss=0.00365]Epoch 33:  38%|███▊      | 11/29 [00:00<00:00, 138.53it/s, train_loss=0.0033, val_loss=0.00365] Epoch 33:  41%|████▏     | 12/29 [00:00<00:00, 143.19it/s, train_loss=0.0033, val_loss=0.00365]Epoch 33:  41%|████▏     | 12/29 [00:00<00:00, 137.59it/s, train_loss=0.00312, val_loss=0.00365]Epoch 33:  45%|████▍     | 13/29 [00:00<00:00, 142.71it/s, train_loss=0.00312, val_loss=0.00365]Epoch 33:  45%|████▍     | 13/29 [00:00<00:00, 137.95it/s, train_loss=0.0032, val_loss=0.00365] Epoch 33:  48%|████▊     | 14/29 [00:00<00:00, 142.75it/s, train_loss=0.0032, val_loss=0.00365]Epoch 33:  48%|████▊     | 14/29 [00:00<00:00, 138.25it/s, train_loss=0.00192, val_loss=0.00365]Epoch 33:  52%|█████▏    | 15/29 [00:00<00:00, 142.85it/s, train_loss=0.00192, val_loss=0.00365]Epoch 33:  52%|█████▏    | 15/29 [00:00<00:00, 138.52it/s, train_loss=0.00482, val_loss=0.00365]Epoch 33:  55%|█████▌    | 16/29 [00:00<00:00, 142.76it/s, train_loss=0.00482, val_loss=0.00365]Epoch 33:  55%|█████▌    | 16/29 [00:00<00:00, 138.83it/s, train_loss=0.00425, val_loss=0.00365]Epoch 33:  59%|█████▊    | 17/29 [00:00<00:00, 143.09it/s, train_loss=0.00425, val_loss=0.00365]Epoch 33:  59%|█████▊    | 17/29 [00:00<00:00, 139.23it/s, train_loss=0.00369, val_loss=0.00365]Epoch 33:  62%|██████▏   | 18/29 [00:00<00:00, 143.09it/s, train_loss=0.00369, val_loss=0.00365]Epoch 33:  62%|██████▏   | 18/29 [00:00<00:00, 139.33it/s, train_loss=0.00275, val_loss=0.00365]Epoch 33:  66%|██████▌   | 19/29 [00:00<00:00, 143.14it/s, train_loss=0.00275, val_loss=0.00365]Epoch 33:  66%|██████▌   | 19/29 [00:00<00:00, 139.46it/s, train_loss=0.0036, val_loss=0.00365] Epoch 33:  69%|██████▉   | 20/29 [00:00<00:00, 143.16it/s, train_loss=0.0036, val_loss=0.00365]Epoch 33:  69%|██████▉   | 20/29 [00:00<00:00, 139.60it/s, train_loss=0.00301, val_loss=0.00365]Epoch 33:  72%|███████▏  | 21/29 [00:00<00:00, 143.09it/s, train_loss=0.00301, val_loss=0.00365]Epoch 33:  72%|███████▏  | 21/29 [00:00<00:00, 139.75it/s, train_loss=0.0034, val_loss=0.00365] Epoch 33:  76%|███████▌  | 22/29 [00:00<00:00, 143.08it/s, train_loss=0.0034, val_loss=0.00365]Epoch 33:  76%|███████▌  | 22/29 [00:00<00:00, 139.82it/s, train_loss=0.00381, val_loss=0.00365]Epoch 33:  79%|███████▉  | 23/29 [00:00<00:00, 142.65it/s, train_loss=0.00381, val_loss=0.00365]Epoch 33:  79%|███████▉  | 23/29 [00:00<00:00, 138.52it/s, train_loss=0.00332, val_loss=0.00365]Epoch 33:  83%|████████▎ | 24/29 [00:00<00:00, 141.37it/s, train_loss=0.00332, val_loss=0.00365]Epoch 33:  83%|████████▎ | 24/29 [00:00<00:00, 138.69it/s, train_loss=0.00294, val_loss=0.00365]Epoch 33:  86%|████████▌ | 25/29 [00:00<00:00, 141.53it/s, train_loss=0.00294, val_loss=0.00365]Epoch 33:  86%|████████▌ | 25/29 [00:00<00:00, 138.84it/s, train_loss=0.0022, val_loss=0.00365] Epoch 33:  90%|████████▉ | 26/29 [00:00<00:00, 141.55it/s, train_loss=0.0022, val_loss=0.00365]Epoch 33:  90%|████████▉ | 26/29 [00:00<00:00, 138.96it/s, train_loss=0.00397, val_loss=0.00365]Epoch 33:  93%|█████████▎| 27/29 [00:00<00:00, 141.55it/s, train_loss=0.00397, val_loss=0.00365]Epoch 33:  93%|█████████▎| 27/29 [00:00<00:00, 139.12it/s, train_loss=0.00309, val_loss=0.00365]Epoch 33:  97%|█████████▋| 28/29 [00:00<00:00, 141.59it/s, train_loss=0.00309, val_loss=0.00365]Epoch 33:  97%|█████████▋| 28/29 [00:00<00:00, 140.72it/s, train_loss=0.00272, val_loss=0.00365]Epoch 33: 100%|██████████| 29/29 [00:00<00:00, 142.97it/s, train_loss=0.00272, val_loss=0.00365]Epoch 33: 100%|██████████| 29/29 [00:00<00:00, 140.60it/s, train_loss=0.00751, val_loss=0.00365]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 156.52it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 193.22it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 210.89it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 223.19it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 229.51it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 234.44it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 236.28it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 238.31it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 239.26it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 239.99it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 245.40it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 252.58it/s][A
                                                                         [AEpoch 33: 100%|██████████| 29/29 [00:00<00:00, 111.23it/s, train_loss=0.00751, val_loss=0.00363]Epoch 33: 100%|██████████| 29/29 [00:00<00:00, 110.97it/s, train_loss=0.00751, val_loss=0.00363]Epoch 33:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00751, val_loss=0.00363]          Epoch 34:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00751, val_loss=0.00363]Epoch 34:   3%|▎         | 1/29 [00:00<00:00, 242.66it/s, train_loss=0.00751, val_loss=0.00363]Epoch 34:   3%|▎         | 1/29 [00:00<00:00, 142.58it/s, train_loss=0.00298, val_loss=0.00363]Epoch 34:   7%|▋         | 2/29 [00:00<00:00, 191.69it/s, train_loss=0.00298, val_loss=0.00363]Epoch 34:   7%|▋         | 2/29 [00:00<00:00, 140.61it/s, train_loss=0.00387, val_loss=0.00363]Epoch 34:  10%|█         | 3/29 [00:00<00:00, 169.22it/s, train_loss=0.00387, val_loss=0.00363]Epoch 34:  10%|█         | 3/29 [00:00<00:00, 140.87it/s, train_loss=0.00223, val_loss=0.00363]Epoch 34:  14%|█▍        | 4/29 [00:00<00:00, 161.18it/s, train_loss=0.00223, val_loss=0.00363]Epoch 34:  14%|█▍        | 4/29 [00:00<00:00, 149.32it/s, train_loss=0.00281, val_loss=0.00363]Epoch 34:  17%|█▋        | 5/29 [00:00<00:00, 163.29it/s, train_loss=0.00281, val_loss=0.00363]Epoch 34:  17%|█▋        | 5/29 [00:00<00:00, 145.87it/s, train_loss=0.00347, val_loss=0.00363]Epoch 34:  21%|██        | 6/29 [00:00<00:00, 157.82it/s, train_loss=0.00347, val_loss=0.00363]Epoch 34:  21%|██        | 6/29 [00:00<00:00, 144.86it/s, train_loss=0.0043, val_loss=0.00363] Epoch 34:  24%|██▍       | 7/29 [00:00<00:00, 155.34it/s, train_loss=0.0043, val_loss=0.00363]Epoch 34:  24%|██▍       | 7/29 [00:00<00:00, 144.40it/s, train_loss=0.00252, val_loss=0.00363]Epoch 34:  28%|██▊       | 8/29 [00:00<00:00, 153.86it/s, train_loss=0.00252, val_loss=0.00363]Epoch 34:  28%|██▊       | 8/29 [00:00<00:00, 144.02it/s, train_loss=0.00411, val_loss=0.00363]Epoch 34:  31%|███       | 9/29 [00:00<00:00, 152.12it/s, train_loss=0.00411, val_loss=0.00363]Epoch 34:  31%|███       | 9/29 [00:00<00:00, 143.78it/s, train_loss=0.00465, val_loss=0.00363]Epoch 34:  34%|███▍      | 10/29 [00:00<00:00, 150.88it/s, train_loss=0.00465, val_loss=0.00363]Epoch 34:  34%|███▍      | 10/29 [00:00<00:00, 147.89it/s, train_loss=0.00316, val_loss=0.00363]Epoch 34:  38%|███▊      | 11/29 [00:00<00:00, 153.62it/s, train_loss=0.00316, val_loss=0.00363]Epoch 34:  38%|███▊      | 11/29 [00:00<00:00, 146.35it/s, train_loss=0.0022, val_loss=0.00363] Epoch 34:  41%|████▏     | 12/29 [00:00<00:00, 151.91it/s, train_loss=0.0022, val_loss=0.00363]Epoch 34:  41%|████▏     | 12/29 [00:00<00:00, 146.02it/s, train_loss=0.00275, val_loss=0.00363]Epoch 34:  45%|████▍     | 13/29 [00:00<00:00, 151.29it/s, train_loss=0.00275, val_loss=0.00363]Epoch 34:  45%|████▍     | 13/29 [00:00<00:00, 145.70it/s, train_loss=0.00319, val_loss=0.00363]Epoch 34:  48%|████▊     | 14/29 [00:00<00:00, 150.65it/s, train_loss=0.00319, val_loss=0.00363]Epoch 34:  48%|████▊     | 14/29 [00:00<00:00, 145.51it/s, train_loss=0.00279, val_loss=0.00363]Epoch 34:  52%|█████▏    | 15/29 [00:00<00:00, 150.03it/s, train_loss=0.00279, val_loss=0.00363]Epoch 34:  52%|█████▏    | 15/29 [00:00<00:00, 145.35it/s, train_loss=0.00322, val_loss=0.00363]Epoch 34:  55%|█████▌    | 16/29 [00:00<00:00, 149.66it/s, train_loss=0.00322, val_loss=0.00363]Epoch 34:  55%|█████▌    | 16/29 [00:00<00:00, 147.71it/s, train_loss=0.00289, val_loss=0.00363]Epoch 34:  59%|█████▊    | 17/29 [00:00<00:00, 151.28it/s, train_loss=0.00289, val_loss=0.00363]Epoch 34:  59%|█████▊    | 17/29 [00:00<00:00, 146.74it/s, train_loss=0.00326, val_loss=0.00363]Epoch 34:  62%|██████▏   | 18/29 [00:00<00:00, 150.87it/s, train_loss=0.00326, val_loss=0.00363]Epoch 34:  62%|██████▏   | 18/29 [00:00<00:00, 146.47it/s, train_loss=0.00283, val_loss=0.00363]Epoch 34:  66%|██████▌   | 19/29 [00:00<00:00, 150.47it/s, train_loss=0.00283, val_loss=0.00363]Epoch 34:  66%|██████▌   | 19/29 [00:00<00:00, 146.24it/s, train_loss=0.00229, val_loss=0.00363]Epoch 34:  69%|██████▉   | 20/29 [00:00<00:00, 150.00it/s, train_loss=0.00229, val_loss=0.00363]Epoch 34:  69%|██████▉   | 20/29 [00:00<00:00, 146.05it/s, train_loss=0.00473, val_loss=0.00363]Epoch 34:  72%|███████▏  | 21/29 [00:00<00:00, 149.66it/s, train_loss=0.00473, val_loss=0.00363]Epoch 34:  72%|███████▏  | 21/29 [00:00<00:00, 145.88it/s, train_loss=0.00325, val_loss=0.00363]Epoch 34:  76%|███████▌  | 22/29 [00:00<00:00, 149.23it/s, train_loss=0.00325, val_loss=0.00363]Epoch 34:  76%|███████▌  | 22/29 [00:00<00:00, 147.71it/s, train_loss=0.00273, val_loss=0.00363]Epoch 34:  79%|███████▉  | 23/29 [00:00<00:00, 150.48it/s, train_loss=0.00273, val_loss=0.00363]Epoch 34:  79%|███████▉  | 23/29 [00:00<00:00, 146.94it/s, train_loss=0.00264, val_loss=0.00363]Epoch 34:  83%|████████▎ | 24/29 [00:00<00:00, 149.73it/s, train_loss=0.00264, val_loss=0.00363]Epoch 34:  83%|████████▎ | 24/29 [00:00<00:00, 146.77it/s, train_loss=0.00266, val_loss=0.00363]Epoch 34:  86%|████████▌ | 25/29 [00:00<00:00, 149.73it/s, train_loss=0.00266, val_loss=0.00363]Epoch 34:  86%|████████▌ | 25/29 [00:00<00:00, 146.59it/s, train_loss=0.00332, val_loss=0.00363]Epoch 34:  90%|████████▉ | 26/29 [00:00<00:00, 149.40it/s, train_loss=0.00332, val_loss=0.00363]Epoch 34:  90%|████████▉ | 26/29 [00:00<00:00, 146.45it/s, train_loss=0.00347, val_loss=0.00363]Epoch 34:  93%|█████████▎| 27/29 [00:00<00:00, 149.14it/s, train_loss=0.00347, val_loss=0.00363]Epoch 34:  93%|█████████▎| 27/29 [00:00<00:00, 146.32it/s, train_loss=0.00323, val_loss=0.00363]Epoch 34:  97%|█████████▋| 28/29 [00:00<00:00, 148.72it/s, train_loss=0.00323, val_loss=0.00363]Epoch 34:  97%|█████████▋| 28/29 [00:00<00:00, 146.18it/s, train_loss=0.00278, val_loss=0.00363]Epoch 34: 100%|██████████| 29/29 [00:00<00:00, 148.46it/s, train_loss=0.00278, val_loss=0.00363]Epoch 34: 100%|██████████| 29/29 [00:00<00:00, 147.82it/s, train_loss=0.0029, val_loss=0.00363] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 160.60it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 201.54it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 220.23it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 230.57it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 234.03it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 236.54it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 239.05it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 242.27it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 243.94it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 245.77it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 246.81it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 248.07it/s][A
                                                                         [AEpoch 34: 100%|██████████| 29/29 [00:00<00:00, 115.44it/s, train_loss=0.0029, val_loss=0.00361]Epoch 34: 100%|██████████| 29/29 [00:00<00:00, 115.11it/s, train_loss=0.0029, val_loss=0.00361]Epoch 34:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0029, val_loss=0.00361]          Epoch 35:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.0029, val_loss=0.00361]Epoch 35:   3%|▎         | 1/29 [00:00<00:00, 246.99it/s, train_loss=0.0029, val_loss=0.00361]Epoch 35:   3%|▎         | 1/29 [00:00<00:00, 141.59it/s, train_loss=0.00321, val_loss=0.00361]Epoch 35:   7%|▋         | 2/29 [00:00<00:00, 191.22it/s, train_loss=0.00321, val_loss=0.00361]Epoch 35:   7%|▋         | 2/29 [00:00<00:00, 140.05it/s, train_loss=0.00416, val_loss=0.00361]Epoch 35:  10%|█         | 3/29 [00:00<00:00, 169.55it/s, train_loss=0.00416, val_loss=0.00361]Epoch 35:  10%|█         | 3/29 [00:00<00:00, 140.01it/s, train_loss=0.00404, val_loss=0.00361]Epoch 35:  14%|█▍        | 4/29 [00:00<00:00, 160.11it/s, train_loss=0.00404, val_loss=0.00361]Epoch 35:  14%|█▍        | 4/29 [00:00<00:00, 148.29it/s, train_loss=0.00323, val_loss=0.00361]Epoch 35:  17%|█▋        | 5/29 [00:00<00:00, 162.69it/s, train_loss=0.00323, val_loss=0.00361]Epoch 35:  17%|█▋        | 5/29 [00:00<00:00, 144.41it/s, train_loss=0.00254, val_loss=0.00361]Epoch 35:  21%|██        | 6/29 [00:00<00:00, 156.37it/s, train_loss=0.00254, val_loss=0.00361]Epoch 35:  21%|██        | 6/29 [00:00<00:00, 143.71it/s, train_loss=0.00291, val_loss=0.00361]Epoch 35:  24%|██▍       | 7/29 [00:00<00:00, 154.27it/s, train_loss=0.00291, val_loss=0.00361]Epoch 35:  24%|██▍       | 7/29 [00:00<00:00, 143.15it/s, train_loss=0.00331, val_loss=0.00361]Epoch 35:  28%|██▊       | 8/29 [00:00<00:00, 152.32it/s, train_loss=0.00331, val_loss=0.00361]Epoch 35:  28%|██▊       | 8/29 [00:00<00:00, 142.78it/s, train_loss=0.00402, val_loss=0.00361]Epoch 35:  31%|███       | 9/29 [00:00<00:00, 151.10it/s, train_loss=0.00402, val_loss=0.00361]Epoch 35:  31%|███       | 9/29 [00:00<00:00, 142.63it/s, train_loss=0.00321, val_loss=0.00361]Epoch 35:  34%|███▍      | 10/29 [00:00<00:00, 149.58it/s, train_loss=0.00321, val_loss=0.00361]Epoch 35:  34%|███▍      | 10/29 [00:00<00:00, 145.96it/s, train_loss=0.00333, val_loss=0.00361]Epoch 35:  38%|███▊      | 11/29 [00:00<00:00, 146.67it/s, train_loss=0.00333, val_loss=0.00361]Epoch 35:  38%|███▊      | 11/29 [00:00<00:00, 140.41it/s, train_loss=0.00267, val_loss=0.00361]Epoch 35:  41%|████▏     | 12/29 [00:00<00:00, 146.30it/s, train_loss=0.00267, val_loss=0.00361]Epoch 35:  41%|████▏     | 12/29 [00:00<00:00, 140.50it/s, train_loss=0.00407, val_loss=0.00361]Epoch 35:  45%|████▍     | 13/29 [00:00<00:00, 145.80it/s, train_loss=0.00407, val_loss=0.00361]Epoch 35:  45%|████▍     | 13/29 [00:00<00:00, 140.63it/s, train_loss=0.0031, val_loss=0.00361] Epoch 35:  48%|████▊     | 14/29 [00:00<00:00, 145.28it/s, train_loss=0.0031, val_loss=0.00361]Epoch 35:  48%|████▊     | 14/29 [00:00<00:00, 140.75it/s, train_loss=0.0028, val_loss=0.00361]Epoch 35:  52%|█████▏    | 15/29 [00:00<00:00, 145.45it/s, train_loss=0.0028, val_loss=0.00361]Epoch 35:  52%|█████▏    | 15/29 [00:00<00:00, 140.83it/s, train_loss=0.00201, val_loss=0.00361]Epoch 35:  55%|█████▌    | 16/29 [00:00<00:00, 144.65it/s, train_loss=0.00201, val_loss=0.00361]Epoch 35:  55%|█████▌    | 16/29 [00:00<00:00, 138.59it/s, train_loss=0.00429, val_loss=0.00361]Epoch 35:  59%|█████▊    | 17/29 [00:00<00:00, 142.48it/s, train_loss=0.00429, val_loss=0.00361]Epoch 35:  59%|█████▊    | 17/29 [00:00<00:00, 138.80it/s, train_loss=0.00286, val_loss=0.00361]Epoch 35:  62%|██████▏   | 18/29 [00:00<00:00, 142.58it/s, train_loss=0.00286, val_loss=0.00361]Epoch 35:  62%|██████▏   | 18/29 [00:00<00:00, 138.92it/s, train_loss=0.00285, val_loss=0.00361]Epoch 35:  66%|██████▌   | 19/29 [00:00<00:00, 142.90it/s, train_loss=0.00285, val_loss=0.00361]Epoch 35:  66%|██████▌   | 19/29 [00:00<00:00, 138.98it/s, train_loss=0.00389, val_loss=0.00361]Epoch 35:  69%|██████▉   | 20/29 [00:00<00:00, 142.68it/s, train_loss=0.00389, val_loss=0.00361]Epoch 35:  69%|██████▉   | 20/29 [00:00<00:00, 139.10it/s, train_loss=0.00373, val_loss=0.00361]Epoch 35:  72%|███████▏  | 21/29 [00:00<00:00, 142.81it/s, train_loss=0.00373, val_loss=0.00361]Epoch 35:  72%|███████▏  | 21/29 [00:00<00:00, 140.80it/s, train_loss=0.00291, val_loss=0.00361]Epoch 35:  76%|███████▌  | 22/29 [00:00<00:00, 143.88it/s, train_loss=0.00291, val_loss=0.00361]Epoch 35:  76%|███████▌  | 22/29 [00:00<00:00, 140.09it/s, train_loss=0.00245, val_loss=0.00361]Epoch 35:  79%|███████▉  | 23/29 [00:00<00:00, 143.13it/s, train_loss=0.00245, val_loss=0.00361]Epoch 35:  79%|███████▉  | 23/29 [00:00<00:00, 140.18it/s, train_loss=0.0024, val_loss=0.00361] Epoch 35:  83%|████████▎ | 24/29 [00:00<00:00, 143.26it/s, train_loss=0.0024, val_loss=0.00361]Epoch 35:  83%|████████▎ | 24/29 [00:00<00:00, 140.22it/s, train_loss=0.00285, val_loss=0.00361]Epoch 35:  86%|████████▌ | 25/29 [00:00<00:00, 142.43it/s, train_loss=0.00285, val_loss=0.00361]Epoch 35:  86%|████████▌ | 25/29 [00:00<00:00, 138.51it/s, train_loss=0.00274, val_loss=0.00361]Epoch 35:  90%|████████▉ | 26/29 [00:00<00:00, 141.24it/s, train_loss=0.00274, val_loss=0.00361]Epoch 35:  90%|████████▉ | 26/29 [00:00<00:00, 138.61it/s, train_loss=0.00284, val_loss=0.00361]Epoch 35:  93%|█████████▎| 27/29 [00:00<00:00, 140.88it/s, train_loss=0.00284, val_loss=0.00361]Epoch 35:  93%|█████████▎| 27/29 [00:00<00:00, 137.49it/s, train_loss=0.00305, val_loss=0.00361]Epoch 35:  97%|█████████▋| 28/29 [00:00<00:00, 139.89it/s, train_loss=0.00305, val_loss=0.00361]Epoch 35:  97%|█████████▋| 28/29 [00:00<00:00, 137.61it/s, train_loss=0.00258, val_loss=0.00361]Epoch 35: 100%|██████████| 29/29 [00:00<00:00, 140.08it/s, train_loss=0.00258, val_loss=0.00361]Epoch 35: 100%|██████████| 29/29 [00:00<00:00, 137.97it/s, train_loss=0.00212, val_loss=0.00361]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 159.81it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 199.42it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 216.03it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 223.70it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 232.40it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 238.67it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 243.15it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 245.37it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 248.21it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 250.19it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 250.09it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 250.08it/s][A
                                                                         [AEpoch 35: 100%|██████████| 29/29 [00:00<00:00, 108.50it/s, train_loss=0.00212, val_loss=0.0036] Epoch 35: 100%|██████████| 29/29 [00:00<00:00, 108.04it/s, train_loss=0.00212, val_loss=0.0036]Epoch 35:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00212, val_loss=0.0036]          Epoch 36:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00212, val_loss=0.0036]Epoch 36:   3%|▎         | 1/29 [00:00<00:00, 239.11it/s, train_loss=0.00212, val_loss=0.0036]Epoch 36:   3%|▎         | 1/29 [00:00<00:00, 142.28it/s, train_loss=0.00308, val_loss=0.0036]Epoch 36:   7%|▋         | 2/29 [00:00<00:00, 192.05it/s, train_loss=0.00308, val_loss=0.0036]Epoch 36:   7%|▋         | 2/29 [00:00<00:00, 158.86it/s, train_loss=0.00319, val_loss=0.0036]Epoch 36:  10%|█         | 3/29 [00:00<00:00, 182.87it/s, train_loss=0.00319, val_loss=0.0036]Epoch 36:  10%|█         | 3/29 [00:00<00:00, 148.64it/s, train_loss=0.00303, val_loss=0.0036]Epoch 36:  14%|█▍        | 4/29 [00:00<00:00, 167.87it/s, train_loss=0.00303, val_loss=0.0036]Epoch 36:  14%|█▍        | 4/29 [00:00<00:00, 146.09it/s, train_loss=0.00362, val_loss=0.0036]Epoch 36:  17%|█▋        | 5/29 [00:00<00:00, 161.86it/s, train_loss=0.00362, val_loss=0.0036]Epoch 36:  17%|█▋        | 5/29 [00:00<00:00, 144.81it/s, train_loss=0.00319, val_loss=0.0036]Epoch 36:  21%|██        | 6/29 [00:00<00:00, 157.53it/s, train_loss=0.00319, val_loss=0.0036]Epoch 36:  21%|██        | 6/29 [00:00<00:00, 143.97it/s, train_loss=0.00348, val_loss=0.0036]Epoch 36:  24%|██▍       | 7/29 [00:00<00:00, 154.53it/s, train_loss=0.00348, val_loss=0.0036]Epoch 36:  24%|██▍       | 7/29 [00:00<00:00, 143.67it/s, train_loss=0.0021, val_loss=0.0036] Epoch 36:  28%|██▊       | 8/29 [00:00<00:00, 152.91it/s, train_loss=0.0021, val_loss=0.0036]Epoch 36:  28%|██▊       | 8/29 [00:00<00:00, 147.53it/s, train_loss=0.00293, val_loss=0.0036]Epoch 36:  31%|███       | 9/29 [00:00<00:00, 154.92it/s, train_loss=0.00293, val_loss=0.0036]Epoch 36:  31%|███       | 9/29 [00:00<00:00, 145.58it/s, train_loss=0.00297, val_loss=0.0036]Epoch 36:  34%|███▍      | 10/29 [00:00<00:00, 152.36it/s, train_loss=0.00297, val_loss=0.0036]Epoch 36:  34%|███▍      | 10/29 [00:00<00:00, 145.16it/s, train_loss=0.0029, val_loss=0.0036] Epoch 36:  38%|███▊      | 11/29 [00:00<00:00, 151.51it/s, train_loss=0.0029, val_loss=0.0036]Epoch 36:  38%|███▊      | 11/29 [00:00<00:00, 144.85it/s, train_loss=0.00395, val_loss=0.0036]Epoch 36:  41%|████▏     | 12/29 [00:00<00:00, 150.73it/s, train_loss=0.00395, val_loss=0.0036]Epoch 36:  41%|████▏     | 12/29 [00:00<00:00, 144.62it/s, train_loss=0.00256, val_loss=0.0036]Epoch 36:  45%|████▍     | 13/29 [00:00<00:00, 149.99it/s, train_loss=0.00256, val_loss=0.0036]Epoch 36:  45%|████▍     | 13/29 [00:00<00:00, 144.39it/s, train_loss=0.00235, val_loss=0.0036]Epoch 36:  48%|████▊     | 14/29 [00:00<00:00, 149.35it/s, train_loss=0.00235, val_loss=0.0036]Epoch 36:  48%|████▊     | 14/29 [00:00<00:00, 146.78it/s, train_loss=0.00317, val_loss=0.0036]Epoch 36:  52%|█████▏    | 15/29 [00:00<00:00, 151.00it/s, train_loss=0.00317, val_loss=0.0036]Epoch 36:  52%|█████▏    | 15/29 [00:00<00:00, 145.60it/s, train_loss=0.00255, val_loss=0.0036]Epoch 36:  55%|█████▌    | 16/29 [00:00<00:00, 149.52it/s, train_loss=0.00255, val_loss=0.0036]Epoch 36:  55%|█████▌    | 16/29 [00:00<00:00, 145.37it/s, train_loss=0.00471, val_loss=0.0036]Epoch 36:  59%|█████▊    | 17/29 [00:00<00:00, 149.40it/s, train_loss=0.00471, val_loss=0.0036]Epoch 36:  59%|█████▊    | 17/29 [00:00<00:00, 145.14it/s, train_loss=0.00307, val_loss=0.0036]Epoch 36:  62%|██████▏   | 18/29 [00:00<00:00, 148.89it/s, train_loss=0.00307, val_loss=0.0036]Epoch 36:  62%|██████▏   | 18/29 [00:00<00:00, 144.92it/s, train_loss=0.00292, val_loss=0.0036]Epoch 36:  66%|██████▌   | 19/29 [00:00<00:00, 148.49it/s, train_loss=0.00292, val_loss=0.0036]Epoch 36:  66%|██████▌   | 19/29 [00:00<00:00, 144.76it/s, train_loss=0.00354, val_loss=0.0036]Epoch 36:  69%|██████▉   | 20/29 [00:00<00:00, 148.71it/s, train_loss=0.00354, val_loss=0.0036]Epoch 36:  69%|██████▉   | 20/29 [00:00<00:00, 146.50it/s, train_loss=0.0022, val_loss=0.0036] Epoch 36:  72%|███████▏  | 21/29 [00:00<00:00, 149.81it/s, train_loss=0.0022, val_loss=0.0036]Epoch 36:  72%|███████▏  | 21/29 [00:00<00:00, 145.62it/s, train_loss=0.00362, val_loss=0.0036]Epoch 36:  76%|███████▌  | 22/29 [00:00<00:00, 148.79it/s, train_loss=0.00362, val_loss=0.0036]Epoch 36:  76%|███████▌  | 22/29 [00:00<00:00, 145.49it/s, train_loss=0.00317, val_loss=0.0036]Epoch 36:  79%|███████▉  | 23/29 [00:00<00:00, 148.77it/s, train_loss=0.00317, val_loss=0.0036]Epoch 36:  79%|███████▉  | 23/29 [00:00<00:00, 145.32it/s, train_loss=0.00345, val_loss=0.0036]Epoch 36:  83%|████████▎ | 24/29 [00:00<00:00, 148.44it/s, train_loss=0.00345, val_loss=0.0036]Epoch 36:  83%|████████▎ | 24/29 [00:00<00:00, 145.17it/s, train_loss=0.00267, val_loss=0.0036]Epoch 36:  86%|████████▌ | 25/29 [00:00<00:00, 148.05it/s, train_loss=0.00267, val_loss=0.0036]Epoch 36:  86%|████████▌ | 25/29 [00:00<00:00, 145.06it/s, train_loss=0.00368, val_loss=0.0036]Epoch 36:  90%|████████▉ | 26/29 [00:00<00:00, 147.81it/s, train_loss=0.00368, val_loss=0.0036]Epoch 36:  90%|████████▉ | 26/29 [00:00<00:00, 146.44it/s, train_loss=0.00388, val_loss=0.0036]Epoch 36:  93%|█████████▎| 27/29 [00:00<00:00, 148.88it/s, train_loss=0.00388, val_loss=0.0036]Epoch 36:  93%|█████████▎| 27/29 [00:00<00:00, 145.80it/s, train_loss=0.00313, val_loss=0.0036]Epoch 36:  97%|█████████▋| 28/29 [00:00<00:00, 148.04it/s, train_loss=0.00313, val_loss=0.0036]Epoch 36:  97%|█████████▋| 28/29 [00:00<00:00, 145.70it/s, train_loss=0.00273, val_loss=0.0036]Epoch 36: 100%|██████████| 29/29 [00:00<00:00, 148.28it/s, train_loss=0.00273, val_loss=0.0036]Epoch 36: 100%|██████████| 29/29 [00:00<00:00, 147.59it/s, train_loss=0.00202, val_loss=0.0036]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 174.51it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 216.58it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 230.74it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 229.03it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 234.22it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 238.68it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 242.24it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 244.12it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 246.62it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 248.58it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 249.04it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 249.39it/s][A
                                                                         [AEpoch 36: 100%|██████████| 29/29 [00:00<00:00, 114.19it/s, train_loss=0.00202, val_loss=0.0036]Epoch 36: 100%|██████████| 29/29 [00:00<00:00, 113.73it/s, train_loss=0.00202, val_loss=0.0036]Epoch 36:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00202, val_loss=0.0036]          Epoch 37:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00202, val_loss=0.0036]Epoch 37:   3%|▎         | 1/29 [00:00<00:00, 208.64it/s, train_loss=0.00202, val_loss=0.0036]Epoch 37:   3%|▎         | 1/29 [00:00<00:00, 131.15it/s, train_loss=0.00311, val_loss=0.0036]Epoch 37:   7%|▋         | 2/29 [00:00<00:00, 175.50it/s, train_loss=0.00311, val_loss=0.0036]Epoch 37:   7%|▋         | 2/29 [00:00<00:00, 131.54it/s, train_loss=0.00241, val_loss=0.0036]Epoch 37:  10%|█         | 3/29 [00:00<00:00, 159.47it/s, train_loss=0.00241, val_loss=0.0036]Epoch 37:  10%|█         | 3/29 [00:00<00:00, 134.22it/s, train_loss=0.00294, val_loss=0.0036]Epoch 37:  14%|█▍        | 4/29 [00:00<00:00, 155.24it/s, train_loss=0.00294, val_loss=0.0036]Epoch 37:  14%|█▍        | 4/29 [00:00<00:00, 135.73it/s, train_loss=0.00336, val_loss=0.0036]Epoch 37:  17%|█▋        | 5/29 [00:00<00:00, 151.51it/s, train_loss=0.00336, val_loss=0.0036]Epoch 37:  17%|█▋        | 5/29 [00:00<00:00, 136.57it/s, train_loss=0.00309, val_loss=0.0036]Epoch 37:  21%|██        | 6/29 [00:00<00:00, 149.53it/s, train_loss=0.00309, val_loss=0.0036]Epoch 37:  21%|██        | 6/29 [00:00<00:00, 137.40it/s, train_loss=0.00299, val_loss=0.0036]Epoch 37:  24%|██▍       | 7/29 [00:00<00:00, 148.16it/s, train_loss=0.00299, val_loss=0.0036]Epoch 37:  24%|██▍       | 7/29 [00:00<00:00, 142.79it/s, train_loss=0.00232, val_loss=0.0036]Epoch 37:  28%|██▊       | 8/29 [00:00<00:00, 151.38it/s, train_loss=0.00232, val_loss=0.0036]Epoch 37:  28%|██▊       | 8/29 [00:00<00:00, 140.55it/s, train_loss=0.00358, val_loss=0.0036]Epoch 37:  31%|███       | 9/29 [00:00<00:00, 148.37it/s, train_loss=0.00358, val_loss=0.0036]Epoch 37:  31%|███       | 9/29 [00:00<00:00, 140.83it/s, train_loss=0.00305, val_loss=0.0036]Epoch 37:  34%|███▍      | 10/29 [00:00<00:00, 148.07it/s, train_loss=0.00305, val_loss=0.0036]Epoch 37:  34%|███▍      | 10/29 [00:00<00:00, 140.96it/s, train_loss=0.0039, val_loss=0.0036] Epoch 37:  38%|███▊      | 11/29 [00:00<00:00, 147.47it/s, train_loss=0.0039, val_loss=0.0036]Epoch 37:  38%|███▊      | 11/29 [00:00<00:00, 141.10it/s, train_loss=0.00308, val_loss=0.0036]Epoch 37:  41%|████▏     | 12/29 [00:00<00:00, 147.23it/s, train_loss=0.00308, val_loss=0.0036]Epoch 37:  41%|████▏     | 12/29 [00:00<00:00, 141.23it/s, train_loss=0.00251, val_loss=0.0036]Epoch 37:  45%|████▍     | 13/29 [00:00<00:00, 146.90it/s, train_loss=0.00251, val_loss=0.0036]Epoch 37:  45%|████▍     | 13/29 [00:00<00:00, 143.36it/s, train_loss=0.00261, val_loss=0.0036]Epoch 37:  48%|████▊     | 14/29 [00:00<00:00, 147.80it/s, train_loss=0.00261, val_loss=0.0036]Epoch 37:  48%|████▊     | 14/29 [00:00<00:00, 142.31it/s, train_loss=0.00318, val_loss=0.0036]Epoch 37:  52%|█████▏    | 15/29 [00:00<00:00, 146.70it/s, train_loss=0.00318, val_loss=0.0036]Epoch 37:  52%|█████▏    | 15/29 [00:00<00:00, 142.40it/s, train_loss=0.0035, val_loss=0.0036] Epoch 37:  55%|█████▌    | 16/29 [00:00<00:00, 146.67it/s, train_loss=0.0035, val_loss=0.0036]Epoch 37:  55%|█████▌    | 16/29 [00:00<00:00, 142.40it/s, train_loss=0.00297, val_loss=0.0036]Epoch 37:  59%|█████▊    | 17/29 [00:00<00:00, 146.44it/s, train_loss=0.00297, val_loss=0.0036]Epoch 37:  59%|█████▊    | 17/29 [00:00<00:00, 142.45it/s, train_loss=0.00296, val_loss=0.0036]Epoch 37:  62%|██████▏   | 18/29 [00:00<00:00, 146.26it/s, train_loss=0.00296, val_loss=0.0036]Epoch 37:  62%|██████▏   | 18/29 [00:00<00:00, 142.48it/s, train_loss=0.00308, val_loss=0.0036]Epoch 37:  66%|██████▌   | 19/29 [00:00<00:00, 146.08it/s, train_loss=0.00308, val_loss=0.0036]Epoch 37:  66%|██████▌   | 19/29 [00:00<00:00, 144.71it/s, train_loss=0.00289, val_loss=0.0036]Epoch 37:  69%|██████▉   | 20/29 [00:00<00:00, 147.76it/s, train_loss=0.00289, val_loss=0.0036]Epoch 37:  69%|██████▉   | 20/29 [00:00<00:00, 143.96it/s, train_loss=0.0037, val_loss=0.0036] Epoch 37:  72%|███████▏  | 21/29 [00:00<00:00, 147.00it/s, train_loss=0.0037, val_loss=0.0036]Epoch 37:  72%|███████▏  | 21/29 [00:00<00:00, 143.94it/s, train_loss=0.00371, val_loss=0.0036]Epoch 37:  76%|███████▌  | 22/29 [00:00<00:00, 147.41it/s, train_loss=0.00371, val_loss=0.0036]Epoch 37:  76%|███████▌  | 22/29 [00:00<00:00, 143.86it/s, train_loss=0.00366, val_loss=0.0036]Epoch 37:  79%|███████▉  | 23/29 [00:00<00:00, 147.17it/s, train_loss=0.00366, val_loss=0.0036]Epoch 37:  79%|███████▉  | 23/29 [00:00<00:00, 143.81it/s, train_loss=0.00361, val_loss=0.0036]Epoch 37:  83%|████████▎ | 24/29 [00:00<00:00, 146.91it/s, train_loss=0.00361, val_loss=0.0036]Epoch 37:  83%|████████▎ | 24/29 [00:00<00:00, 143.80it/s, train_loss=0.00284, val_loss=0.0036]Epoch 37:  86%|████████▌ | 25/29 [00:00<00:00, 146.53it/s, train_loss=0.00284, val_loss=0.0036]Epoch 37:  86%|████████▌ | 25/29 [00:00<00:00, 145.72it/s, train_loss=0.00416, val_loss=0.0036]Epoch 37:  90%|████████▉ | 26/29 [00:00<00:00, 148.25it/s, train_loss=0.00416, val_loss=0.0036]Epoch 37:  90%|████████▉ | 26/29 [00:00<00:00, 145.61it/s, train_loss=0.00264, val_loss=0.0036]Epoch 37:  93%|█████████▎| 27/29 [00:00<00:00, 146.96it/s, train_loss=0.00264, val_loss=0.0036]Epoch 37:  93%|█████████▎| 27/29 [00:00<00:00, 143.87it/s, train_loss=0.00314, val_loss=0.0036]Epoch 37:  97%|█████████▋| 28/29 [00:00<00:00, 146.43it/s, train_loss=0.00314, val_loss=0.0036]Epoch 37:  97%|█████████▋| 28/29 [00:00<00:00, 143.80it/s, train_loss=0.00267, val_loss=0.0036]Epoch 37: 100%|██████████| 29/29 [00:00<00:00, 146.30it/s, train_loss=0.00267, val_loss=0.0036]Epoch 37: 100%|██████████| 29/29 [00:00<00:00, 145.68it/s, train_loss=0.00258, val_loss=0.0036]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 162.68it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 201.27it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 219.19it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 229.17it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 235.33it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 241.97it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 244.69it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 247.17it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 248.68it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 249.27it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 249.75it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 251.38it/s][A
                                                                         [AEpoch 37: 100%|██████████| 29/29 [00:00<00:00, 112.75it/s, train_loss=0.00258, val_loss=0.0036]Epoch 37: 100%|██████████| 29/29 [00:00<00:00, 112.30it/s, train_loss=0.00258, val_loss=0.0036]Epoch 37:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00258, val_loss=0.0036]          Epoch 38:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00258, val_loss=0.0036]Epoch 38:   3%|▎         | 1/29 [00:00<00:00, 176.48it/s, train_loss=0.00258, val_loss=0.0036]Epoch 38:   3%|▎         | 1/29 [00:00<00:00, 113.00it/s, train_loss=0.00395, val_loss=0.0036]Epoch 38:   7%|▋         | 2/29 [00:00<00:00, 155.61it/s, train_loss=0.00395, val_loss=0.0036]Epoch 38:   7%|▋         | 2/29 [00:00<00:00, 125.75it/s, train_loss=0.00276, val_loss=0.0036]Epoch 38:  10%|█         | 3/29 [00:00<00:00, 155.84it/s, train_loss=0.00276, val_loss=0.0036]Epoch 38:  10%|█         | 3/29 [00:00<00:00, 130.31it/s, train_loss=0.00398, val_loss=0.0036]Epoch 38:  14%|█▍        | 4/29 [00:00<00:00, 150.29it/s, train_loss=0.00398, val_loss=0.0036]Epoch 38:  14%|█▍        | 4/29 [00:00<00:00, 132.72it/s, train_loss=0.00378, val_loss=0.0036]Epoch 38:  17%|█▋        | 5/29 [00:00<00:00, 148.12it/s, train_loss=0.00378, val_loss=0.0036]Epoch 38:  17%|█▋        | 5/29 [00:00<00:00, 134.58it/s, train_loss=0.00326, val_loss=0.0036]Epoch 38:  21%|██        | 6/29 [00:00<00:00, 146.34it/s, train_loss=0.00326, val_loss=0.0036]Epoch 38:  21%|██        | 6/29 [00:00<00:00, 136.02it/s, train_loss=0.00364, val_loss=0.0036]Epoch 38:  24%|██▍       | 7/29 [00:00<00:00, 145.45it/s, train_loss=0.00364, val_loss=0.0036]Epoch 38:  24%|██▍       | 7/29 [00:00<00:00, 136.85it/s, train_loss=0.00285, val_loss=0.0036]Epoch 38:  28%|██▊       | 8/29 [00:00<00:00, 146.07it/s, train_loss=0.00285, val_loss=0.0036]Epoch 38:  28%|██▊       | 8/29 [00:00<00:00, 137.65it/s, train_loss=0.00346, val_loss=0.0036]Epoch 38:  31%|███       | 9/29 [00:00<00:00, 145.64it/s, train_loss=0.00346, val_loss=0.0036]Epoch 38:  31%|███       | 9/29 [00:00<00:00, 138.06it/s, train_loss=0.00244, val_loss=0.0036]Epoch 38:  34%|███▍      | 10/29 [00:00<00:00, 145.15it/s, train_loss=0.00244, val_loss=0.0036]Epoch 38:  34%|███▍      | 10/29 [00:00<00:00, 138.51it/s, train_loss=0.00289, val_loss=0.0036]Epoch 38:  38%|███▊      | 11/29 [00:00<00:00, 144.76it/s, train_loss=0.00289, val_loss=0.0036]Epoch 38:  38%|███▊      | 11/29 [00:00<00:00, 138.87it/s, train_loss=0.00229, val_loss=0.0036]Epoch 38:  41%|████▏     | 12/29 [00:00<00:00, 143.88it/s, train_loss=0.00229, val_loss=0.0036]Epoch 38:  41%|████▏     | 12/29 [00:00<00:00, 136.34it/s, train_loss=0.00381, val_loss=0.0036]Epoch 38:  45%|████▍     | 13/29 [00:00<00:00, 141.46it/s, train_loss=0.00381, val_loss=0.0036]Epoch 38:  45%|████▍     | 13/29 [00:00<00:00, 136.84it/s, train_loss=0.00252, val_loss=0.0036]Epoch 38:  48%|████▊     | 14/29 [00:00<00:00, 141.83it/s, train_loss=0.00252, val_loss=0.0036]Epoch 38:  48%|████▊     | 14/29 [00:00<00:00, 137.18it/s, train_loss=0.00406, val_loss=0.0036]Epoch 38:  52%|█████▏    | 15/29 [00:00<00:00, 141.69it/s, train_loss=0.00406, val_loss=0.0036]Epoch 38:  52%|█████▏    | 15/29 [00:00<00:00, 137.51it/s, train_loss=0.00298, val_loss=0.0036]Epoch 38:  55%|█████▌    | 16/29 [00:00<00:00, 141.77it/s, train_loss=0.00298, val_loss=0.0036]Epoch 38:  55%|█████▌    | 16/29 [00:00<00:00, 137.86it/s, train_loss=0.00355, val_loss=0.0036]Epoch 38:  59%|█████▊    | 17/29 [00:00<00:00, 141.67it/s, train_loss=0.00355, val_loss=0.0036]Epoch 38:  59%|█████▊    | 17/29 [00:00<00:00, 140.53it/s, train_loss=0.00347, val_loss=0.0036]Epoch 38:  62%|██████▏   | 18/29 [00:00<00:00, 143.87it/s, train_loss=0.00347, val_loss=0.0036]Epoch 38:  62%|██████▏   | 18/29 [00:00<00:00, 140.63it/s, train_loss=0.00373, val_loss=0.0036]Epoch 38:  66%|██████▌   | 19/29 [00:00<00:00, 144.04it/s, train_loss=0.00373, val_loss=0.0036]Epoch 38:  66%|██████▌   | 19/29 [00:00<00:00, 140.77it/s, train_loss=0.00315, val_loss=0.0036]Epoch 38:  69%|██████▉   | 20/29 [00:00<00:00, 144.09it/s, train_loss=0.00315, val_loss=0.0036]Epoch 38:  69%|██████▉   | 20/29 [00:00<00:00, 140.91it/s, train_loss=0.00296, val_loss=0.0036]Epoch 38:  72%|███████▏  | 21/29 [00:00<00:00, 144.03it/s, train_loss=0.00296, val_loss=0.0036]Epoch 38:  72%|███████▏  | 21/29 [00:00<00:00, 141.01it/s, train_loss=0.00289, val_loss=0.0036]Epoch 38:  76%|███████▌  | 22/29 [00:00<00:00, 143.93it/s, train_loss=0.00289, val_loss=0.0036]Epoch 38:  76%|███████▌  | 22/29 [00:00<00:00, 141.12it/s, train_loss=0.0026, val_loss=0.0036] Epoch 38:  79%|███████▉  | 23/29 [00:00<00:00, 144.12it/s, train_loss=0.0026, val_loss=0.0036]Epoch 38:  79%|███████▉  | 23/29 [00:00<00:00, 141.19it/s, train_loss=0.00261, val_loss=0.0036]Epoch 38:  83%|████████▎ | 24/29 [00:00<00:00, 143.96it/s, train_loss=0.00261, val_loss=0.0036]Epoch 38:  83%|████████▎ | 24/29 [00:00<00:00, 141.22it/s, train_loss=0.00252, val_loss=0.0036]Epoch 38:  86%|████████▌ | 25/29 [00:00<00:00, 144.05it/s, train_loss=0.00252, val_loss=0.0036]Epoch 38:  86%|████████▌ | 25/29 [00:00<00:00, 141.26it/s, train_loss=0.00359, val_loss=0.0036]Epoch 38:  90%|████████▉ | 26/29 [00:00<00:00, 143.99it/s, train_loss=0.00359, val_loss=0.0036]Epoch 38:  90%|████████▉ | 26/29 [00:00<00:00, 141.32it/s, train_loss=0.00229, val_loss=0.0036]Epoch 38:  93%|█████████▎| 27/29 [00:00<00:00, 143.95it/s, train_loss=0.00229, val_loss=0.0036]Epoch 38:  93%|█████████▎| 27/29 [00:00<00:00, 141.37it/s, train_loss=0.00252, val_loss=0.0036]Epoch 38:  97%|█████████▋| 28/29 [00:00<00:00, 143.98it/s, train_loss=0.00252, val_loss=0.0036]Epoch 38:  97%|█████████▋| 28/29 [00:00<00:00, 141.41it/s, train_loss=0.00307, val_loss=0.0036]Epoch 38: 100%|██████████| 29/29 [00:00<00:00, 143.66it/s, train_loss=0.00307, val_loss=0.0036]Epoch 38: 100%|██████████| 29/29 [00:00<00:00, 142.10it/s, train_loss=0.00231, val_loss=0.0036]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 168.76it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 212.91it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 234.45it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 246.86it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 254.07it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 257.10it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 256.92it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 257.16it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 257.73it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 236.20it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 237.60it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 240.10it/s][A
                                                                         [AEpoch 38: 100%|██████████| 29/29 [00:00<00:00, 110.48it/s, train_loss=0.00231, val_loss=0.0036]Epoch 38: 100%|██████████| 29/29 [00:00<00:00, 110.05it/s, train_loss=0.00231, val_loss=0.0036]Epoch 38:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.0036]          Epoch 39:   0%|          | 0/29 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.0036]Epoch 39:   3%|▎         | 1/29 [00:00<00:00, 187.26it/s, train_loss=0.00231, val_loss=0.0036]Epoch 39:   3%|▎         | 1/29 [00:00<00:00, 106.77it/s, train_loss=0.00282, val_loss=0.0036]Epoch 39:   7%|▋         | 2/29 [00:00<00:00, 150.98it/s, train_loss=0.00282, val_loss=0.0036]Epoch 39:   7%|▋         | 2/29 [00:00<00:00, 121.74it/s, train_loss=0.0034, val_loss=0.0036] Epoch 39:  10%|█         | 3/29 [00:00<00:00, 147.71it/s, train_loss=0.0034, val_loss=0.0036]Epoch 39:  10%|█         | 3/29 [00:00<00:00, 137.10it/s, train_loss=0.00406, val_loss=0.0036]Epoch 39:  14%|█▍        | 4/29 [00:00<00:00, 152.59it/s, train_loss=0.00406, val_loss=0.0036]Epoch 39:  14%|█▍        | 4/29 [00:00<00:00, 137.76it/s, train_loss=0.00325, val_loss=0.0036]Epoch 39:  17%|█▋        | 5/29 [00:00<00:00, 153.38it/s, train_loss=0.00325, val_loss=0.0036]Epoch 39:  17%|█▋        | 5/29 [00:00<00:00, 138.29it/s, train_loss=0.00262, val_loss=0.0036]Epoch 39:  21%|██        | 6/29 [00:00<00:00, 150.21it/s, train_loss=0.00262, val_loss=0.0036]Epoch 39:  21%|██        | 6/29 [00:00<00:00, 138.70it/s, train_loss=0.00325, val_loss=0.0036]Epoch 39:  24%|██▍       | 7/29 [00:00<00:00, 149.14it/s, train_loss=0.00325, val_loss=0.0036]Epoch 39:  24%|██▍       | 7/29 [00:00<00:00, 139.03it/s, train_loss=0.00269, val_loss=0.0036]Epoch 39:  28%|██▊       | 8/29 [00:00<00:00, 148.16it/s, train_loss=0.00269, val_loss=0.0036]Epoch 39:  28%|██▊       | 8/29 [00:00<00:00, 139.44it/s, train_loss=0.00322, val_loss=0.0036]Epoch 39:  31%|███       | 9/29 [00:00<00:00, 147.70it/s, train_loss=0.00322, val_loss=0.0036]Epoch 39:  31%|███       | 9/29 [00:00<00:00, 143.93it/s, train_loss=0.00275, val_loss=0.0036]Epoch 39:  34%|███▍      | 10/29 [00:00<00:00, 150.20it/s, train_loss=0.00275, val_loss=0.0036]Epoch 39:  34%|███▍      | 10/29 [00:00<00:00, 141.73it/s, train_loss=0.00283, val_loss=0.0036]Epoch 39:  38%|███▊      | 11/29 [00:00<00:00, 147.99it/s, train_loss=0.00283, val_loss=0.0036]Epoch 39:  38%|███▊      | 11/29 [00:00<00:00, 141.87it/s, train_loss=0.004, val_loss=0.0036]  Epoch 39:  41%|████▏     | 12/29 [00:00<00:00, 147.85it/s, train_loss=0.004, val_loss=0.0036]Epoch 39:  41%|████▏     | 12/29 [00:00<00:00, 141.91it/s, train_loss=0.00285, val_loss=0.0036]Epoch 39:  45%|████▍     | 13/29 [00:00<00:00, 147.49it/s, train_loss=0.00285, val_loss=0.0036]Epoch 39:  45%|████▍     | 13/29 [00:00<00:00, 141.97it/s, train_loss=0.00232, val_loss=0.0036]Epoch 39:  48%|████▊     | 14/29 [00:00<00:00, 147.09it/s, train_loss=0.00232, val_loss=0.0036]Epoch 39:  48%|████▊     | 14/29 [00:00<00:00, 142.11it/s, train_loss=0.00247, val_loss=0.0036]Epoch 39:  52%|█████▏    | 15/29 [00:00<00:00, 146.45it/s, train_loss=0.00247, val_loss=0.0036]Epoch 39:  52%|█████▏    | 15/29 [00:00<00:00, 145.26it/s, train_loss=0.00318, val_loss=0.0036]Epoch 39:  55%|█████▌    | 16/29 [00:00<00:00, 149.09it/s, train_loss=0.00318, val_loss=0.0036]Epoch 39:  55%|█████▌    | 16/29 [00:00<00:00, 145.16it/s, train_loss=0.00309, val_loss=0.0036]Epoch 39:  59%|█████▊    | 17/29 [00:00<00:00, 149.23it/s, train_loss=0.00309, val_loss=0.0036]Epoch 39:  59%|█████▊    | 17/29 [00:00<00:00, 144.97it/s, train_loss=0.00392, val_loss=0.0036]Epoch 39:  62%|██████▏   | 18/29 [00:00<00:00, 148.74it/s, train_loss=0.00392, val_loss=0.0036]Epoch 39:  62%|██████▏   | 18/29 [00:00<00:00, 144.82it/s, train_loss=0.00292, val_loss=0.0036]Epoch 39:  66%|██████▌   | 19/29 [00:00<00:00, 148.36it/s, train_loss=0.00292, val_loss=0.0036]Epoch 39:  66%|██████▌   | 19/29 [00:00<00:00, 144.72it/s, train_loss=0.00301, val_loss=0.0036]Epoch 39:  69%|██████▉   | 20/29 [00:00<00:00, 147.97it/s, train_loss=0.00301, val_loss=0.0036]Epoch 39:  69%|██████▉   | 20/29 [00:00<00:00, 144.68it/s, train_loss=0.00289, val_loss=0.0036]Epoch 39:  72%|███████▏  | 21/29 [00:00<00:00, 147.74it/s, train_loss=0.00289, val_loss=0.0036]Epoch 39:  72%|███████▏  | 21/29 [00:00<00:00, 146.59it/s, train_loss=0.00318, val_loss=0.0036]Epoch 39:  76%|███████▌  | 22/29 [00:00<00:00, 149.15it/s, train_loss=0.00318, val_loss=0.0036]Epoch 39:  76%|███████▌  | 22/29 [00:00<00:00, 146.38it/s, train_loss=0.00251, val_loss=0.0036]Epoch 39:  79%|███████▉  | 23/29 [00:00<00:00, 149.18it/s, train_loss=0.00251, val_loss=0.0036]Epoch 39:  79%|███████▉  | 23/29 [00:00<00:00, 146.22it/s, train_loss=0.00388, val_loss=0.0036]Epoch 39:  83%|████████▎ | 24/29 [00:00<00:00, 149.40it/s, train_loss=0.00388, val_loss=0.0036]Epoch 39:  83%|████████▎ | 24/29 [00:00<00:00, 146.06it/s, train_loss=0.0033, val_loss=0.0036] Epoch 39:  86%|████████▌ | 25/29 [00:00<00:00, 149.00it/s, train_loss=0.0033, val_loss=0.0036]Epoch 39:  86%|████████▌ | 25/29 [00:00<00:00, 145.90it/s, train_loss=0.00407, val_loss=0.0036]Epoch 39:  90%|████████▉ | 26/29 [00:00<00:00, 148.68it/s, train_loss=0.00407, val_loss=0.0036]Epoch 39:  90%|████████▉ | 26/29 [00:00<00:00, 145.80it/s, train_loss=0.00242, val_loss=0.0036]Epoch 39:  93%|█████████▎| 27/29 [00:00<00:00, 148.52it/s, train_loss=0.00242, val_loss=0.0036]Epoch 39:  93%|█████████▎| 27/29 [00:00<00:00, 147.32it/s, train_loss=0.00365, val_loss=0.0036]Epoch 39:  97%|█████████▋| 28/29 [00:00<00:00, 149.58it/s, train_loss=0.00365, val_loss=0.0036]Epoch 39:  97%|█████████▋| 28/29 [00:00<00:00, 146.35it/s, train_loss=0.00296, val_loss=0.0036]Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 148.76it/s, train_loss=0.00296, val_loss=0.0036]Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 148.22it/s, train_loss=0.00334, val_loss=0.0036]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 182.59it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 228.28it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 248.03it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 260.06it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 263.12it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 263.98it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 264.00it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 264.19it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 265.48it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 265.37it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 266.56it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 268.22it/s][A
                                                                         [AEpoch 39: 100%|██████████| 29/29 [00:00<00:00, 116.06it/s, train_loss=0.00334, val_loss=0.00359]Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 115.59it/s, train_loss=0.00334, val_loss=0.00359]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 29/29 [00:00<00:00, 111.04it/s, train_loss=0.00334, val_loss=0.00359]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▎         | 1/27 [00:00<00:00, 260.13it/s]Predicting DataLoader 0:   7%|▋         | 2/27 [00:00<00:00, 222.63it/s]Predicting DataLoader 0:  11%|█         | 3/27 [00:00<00:00, 218.03it/s]Predicting DataLoader 0:  15%|█▍        | 4/27 [00:00<00:00, 213.32it/s]Predicting DataLoader 0:  19%|█▊        | 5/27 [00:00<00:00, 207.47it/s]Predicting DataLoader 0:  22%|██▏       | 6/27 [00:00<00:00, 202.52it/s]Predicting DataLoader 0:  26%|██▌       | 7/27 [00:00<00:00, 199.58it/s]Predicting DataLoader 0:  30%|██▉       | 8/27 [00:00<00:00, 199.83it/s]Predicting DataLoader 0:  33%|███▎      | 9/27 [00:00<00:00, 200.47it/s]Predicting DataLoader 0:  37%|███▋      | 10/27 [00:00<00:00, 199.46it/s]Predicting DataLoader 0:  41%|████      | 11/27 [00:00<00:00, 198.75it/s]Predicting DataLoader 0:  44%|████▍     | 12/27 [00:00<00:00, 196.38it/s]Predicting DataLoader 0:  48%|████▊     | 13/27 [00:00<00:00, 196.31it/s]Predicting DataLoader 0:  52%|█████▏    | 14/27 [00:00<00:00, 197.64it/s]Predicting DataLoader 0:  56%|█████▌    | 15/27 [00:00<00:00, 197.75it/s]Predicting DataLoader 0:  59%|█████▉    | 16/27 [00:00<00:00, 197.37it/s]Predicting DataLoader 0:  63%|██████▎   | 17/27 [00:00<00:00, 196.69it/s]Predicting DataLoader 0:  67%|██████▋   | 18/27 [00:00<00:00, 192.57it/s]Predicting DataLoader 0:  70%|███████   | 19/27 [00:00<00:00, 189.99it/s]Predicting DataLoader 0:  74%|███████▍  | 20/27 [00:00<00:00, 191.29it/s]Predicting DataLoader 0:  78%|███████▊  | 21/27 [00:00<00:00, 191.34it/s]Predicting DataLoader 0:  81%|████████▏ | 22/27 [00:00<00:00, 191.35it/s]Predicting DataLoader 0:  85%|████████▌ | 23/27 [00:00<00:00, 191.18it/s]Predicting DataLoader 0:  89%|████████▉ | 24/27 [00:00<00:00, 191.23it/s]Predicting DataLoader 0:  93%|█████████▎| 25/27 [00:00<00:00, 191.18it/s]Predicting DataLoader 0:  96%|█████████▋| 26/27 [00:00<00:00, 192.04it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 192.82it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 190.46it/s][I 2025-08-18 01:41:29,027] A new study created in memory with name: no-name-bdbe805d-a270-4b6b-9fa3-005d570449f4
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 7, Horizon length: 15
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.26it/s][I 2025-08-18 01:41:40,281] Trial 0 finished with value: 21.88662313833809 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 3, 'dropout': 0.25016423616866906}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.13it/s][I 2025-08-18 01:42:04,434] Trial 1 finished with value: 25.980042308938696 and parameters: {'hidden_dim': 121, 'n_rnn_layers': 3, 'dropout': 0.20644565567816836}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4688094553945122 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 233.93it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.05it/s][I 2025-08-18 01:42:14,279] Trial 2 finished with value: 29.748995114048384 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 1, 'dropout': 0.4688094553945122}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.95it/s][I 2025-08-18 01:42:29,282] Trial 3 finished with value: 27.40487462077463 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 4, 'dropout': 0.39933996892552237}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.52it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.10it/s][I 2025-08-18 01:42:39,502] Trial 4 finished with value: 48.13220229799513 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 2, 'dropout': 0.30833030162157266}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35369351485377193 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.88it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.77it/s][I 2025-08-18 01:42:50,676] Trial 5 finished with value: 33.59598331411845 and parameters: {'hidden_dim': 93, 'n_rnn_layers': 1, 'dropout': 0.35369351485377193}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.00it/s][I 2025-08-18 01:43:02,342] Trial 6 finished with value: 31.171775953668483 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 2, 'dropout': 0.48425788988953883}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.18it/s][I 2025-08-18 01:43:22,539] Trial 7 finished with value: 31.365486540966252 and parameters: {'hidden_dim': 56, 'n_rnn_layers': 4, 'dropout': 0.3124365030117956}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19288451212127788 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.36it/s][I 2025-08-18 01:43:32,851] Trial 8 finished with value: 31.068962411564193 and parameters: {'hidden_dim': 40, 'n_rnn_layers': 1, 'dropout': 0.19288451212127788}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.80it/s][I 2025-08-18 01:43:45,909] Trial 9 finished with value: 25.98234199632262 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.15258155380821437}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.77it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.06it/s][I 2025-08-18 01:43:59,644] Trial 10 finished with value: 26.908002656811313 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 3, 'dropout': 0.031302206628781304}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.56it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.60it/s][I 2025-08-18 01:44:19,277] Trial 11 finished with value: 35.8939351022884 and parameters: {'hidden_dim': 122, 'n_rnn_layers': 3, 'dropout': 0.20266051907132043}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.01it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.99it/s][I 2025-08-18 01:44:34,234] Trial 12 finished with value: 25.536817430976836 and parameters: {'hidden_dim': 62, 'n_rnn_layers': 3, 'dropout': 0.07138376244631711}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.69it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.14it/s][I 2025-08-18 01:44:48,871] Trial 13 finished with value: 22.598336755249786 and parameters: {'hidden_dim': 56, 'n_rnn_layers': 3, 'dropout': 0.062387774136851246}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.97it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.35it/s][I 2025-08-18 01:45:00,830] Trial 14 finished with value: 24.905564714283454 and parameters: {'hidden_dim': 51, 'n_rnn_layers': 2, 'dropout': 0.12116498183155117}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.75it/s][I 2025-08-18 01:45:14,142] Trial 15 finished with value: 33.65478939657399 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 3, 'dropout': 0.005321310160981141}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.71it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.48it/s][I 2025-08-18 01:45:28,355] Trial 16 finished with value: 26.356399955101228 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 2, 'dropout': 0.26456428509319324}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.80it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.90it/s][I 2025-08-18 01:45:41,992] Trial 17 finished with value: 23.99339195824996 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 4, 'dropout': 0.1020945468939205}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.50it/s][I 2025-08-18 01:45:56,623] Trial 18 finished with value: 29.468438859866385 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 3, 'dropout': 0.25504174034631755}. Best is trial 0 with value: 21.88662313833809.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 22.06it/s][I 2025-08-18 01:46:07,185] Trial 19 finished with value: 34.410492819492454 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 2, 'dropout': 0.15070433381723558}. Best is trial 0 with value: 21.88662313833809.
[I 2025-08-18 01:46:07,186] A new study created in memory with name: no-name-c2750b5a-8175-4e40-aeec-d92e04b25f6f
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 20, 'n_rnn_layers': 3, 'dropout': 0.25016423616866906}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.82it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.35it/s][I 2025-08-18 01:46:23,331] Trial 0 finished with value: 32.86018329496969 and parameters: {'hidden_dim': 62, 'n_rnn_layers': 2, 'dropout': 0.1466692216808278}. Best is trial 0 with value: 32.86018329496969.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.97it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.47it/s][I 2025-08-18 01:46:36,297] Trial 1 finished with value: 24.40781713571264 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.3768316987084888}. Best is trial 1 with value: 24.40781713571264.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.60it/s][I 2025-08-18 01:46:52,683] Trial 2 finished with value: 24.252078166518213 and parameters: {'hidden_dim': 33, 'n_rnn_layers': 4, 'dropout': 0.45099546739743723}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.330488396362428 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.09it/s][I 2025-08-18 01:47:06,733] Trial 3 finished with value: 44.76777775955188 and parameters: {'hidden_dim': 50, 'n_rnn_layers': 1, 'dropout': 0.330488396362428}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.15it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.51it/s][I 2025-08-18 01:47:26,789] Trial 4 finished with value: 36.01220512782275 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 4, 'dropout': 0.4170360537911879}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.94it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.08it/s][I 2025-08-18 01:47:47,116] Trial 5 finished with value: 40.34403483860344 and parameters: {'hidden_dim': 50, 'n_rnn_layers': 4, 'dropout': 0.4539521958291258}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.93it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.06it/s][I 2025-08-18 01:48:04,092] Trial 6 finished with value: 34.10506117045432 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 4, 'dropout': 0.2464471619127271}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.27it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.12it/s][I 2025-08-18 01:48:25,444] Trial 7 finished with value: 25.380458376369422 and parameters: {'hidden_dim': 91, 'n_rnn_layers': 2, 'dropout': 0.3227123571318786}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.09it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.41it/s][I 2025-08-18 01:48:45,046] Trial 8 finished with value: 35.39236581764772 and parameters: {'hidden_dim': 41, 'n_rnn_layers': 4, 'dropout': 0.314999822826723}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.23it/s][I 2025-08-18 01:49:10,866] Trial 9 finished with value: 39.69978928955911 and parameters: {'hidden_dim': 108, 'n_rnn_layers': 2, 'dropout': 0.34133848694008884}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.81it/s][I 2025-08-18 01:49:24,808] Trial 10 finished with value: 34.39549256700242 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 3, 'dropout': 0.014628766439793772}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.82it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.59it/s][I 2025-08-18 01:49:35,504] Trial 11 finished with value: 31.045254878649395 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 3, 'dropout': 0.48235378248702787}. Best is trial 2 with value: 24.252078166518213.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.72it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.55it/s][I 2025-08-18 01:49:49,591] Trial 12 finished with value: 23.11102957882259 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 3, 'dropout': 0.4066328613104243}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.76it/s][I 2025-08-18 01:50:04,046] Trial 13 finished with value: 26.24591576900892 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 3, 'dropout': 0.21549206968457227}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.95it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.05it/s][I 2025-08-18 01:50:17,845] Trial 14 finished with value: 30.897092169529817 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 3, 'dropout': 0.4886296882684723}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.27it/s][I 2025-08-18 01:50:31,834] Trial 15 finished with value: 39.5941342563178 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 3, 'dropout': 0.40238593612282203}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16924540014126635 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.13it/s][I 2025-08-18 01:50:40,803] Trial 16 finished with value: 37.58309224792442 and parameters: {'hidden_dim': 32, 'n_rnn_layers': 1, 'dropout': 0.16924540014126635}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.20it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s][I 2025-08-18 01:50:55,045] Trial 17 finished with value: 41.39173719012844 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 4, 'dropout': 0.4325805604633159}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.86it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s][I 2025-08-18 01:51:10,837] Trial 18 finished with value: 42.42287013023882 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 3, 'dropout': 0.04516357331976378}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.41it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.22it/s][I 2025-08-18 01:51:21,658] Trial 19 finished with value: 31.916932221160497 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 2, 'dropout': 0.27035814500183075}. Best is trial 12 with value: 23.11102957882259.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 14.2 K | train
6 | V               | Linear           | 27     | train
-------------------------------------------------------------
14.3 K    Trainable params
0         Non-trainable params
14.3 K    Total params
0.057     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 26, 'n_rnn_layers': 3, 'dropout': 0.4066328613104243}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 351.93it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 363.57it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/28 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s] Epoch 0:   4%|▎         | 1/28 [00:00<00:00, 98.58it/s]Epoch 0:   4%|▎         | 1/28 [00:00<00:00, 59.33it/s, train_loss=0.256]Epoch 0:   7%|▋         | 2/28 [00:00<00:00, 89.67it/s, train_loss=0.256]Epoch 0:   7%|▋         | 2/28 [00:00<00:00, 71.08it/s, train_loss=0.244]Epoch 0:  11%|█         | 3/28 [00:00<00:00, 89.35it/s, train_loss=0.244]Epoch 0:  11%|█         | 3/28 [00:00<00:00, 76.35it/s, train_loss=0.246]Epoch 0:  14%|█▍        | 4/28 [00:00<00:00, 88.76it/s, train_loss=0.246]Epoch 0:  14%|█▍        | 4/28 [00:00<00:00, 80.16it/s, train_loss=0.320]Epoch 0:  18%|█▊        | 5/28 [00:00<00:00, 90.14it/s, train_loss=0.320]Epoch 0:  18%|█▊        | 5/28 [00:00<00:00, 81.74it/s, train_loss=0.278]Epoch 0:  21%|██▏       | 6/28 [00:00<00:00, 89.52it/s, train_loss=0.278]Epoch 0:  21%|██▏       | 6/28 [00:00<00:00, 83.03it/s, train_loss=0.307]Epoch 0:  25%|██▌       | 7/28 [00:00<00:00, 90.05it/s, train_loss=0.307]Epoch 0:  25%|██▌       | 7/28 [00:00<00:00, 86.40it/s, train_loss=0.276]Epoch 0:  29%|██▊       | 8/28 [00:00<00:00, 91.98it/s, train_loss=0.276]Epoch 0:  29%|██▊       | 8/28 [00:00<00:00, 88.67it/s, train_loss=0.265]Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 93.94it/s, train_loss=0.265]Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 88.74it/s, train_loss=0.300]Epoch 0:  36%|███▌      | 10/28 [00:00<00:00, 93.41it/s, train_loss=0.300]Epoch 0:  36%|███▌      | 10/28 [00:00<00:00, 90.71it/s, train_loss=0.260]Epoch 0:  39%|███▉      | 11/28 [00:00<00:00, 94.96it/s, train_loss=0.260]Epoch 0:  39%|███▉      | 11/28 [00:00<00:00, 90.66it/s, train_loss=0.314]Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 94.60it/s, train_loss=0.314]Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 92.46it/s, train_loss=0.282]Epoch 0:  46%|████▋     | 13/28 [00:00<00:00, 95.79it/s, train_loss=0.282]Epoch 0:  46%|████▋     | 13/28 [00:00<00:00, 92.23it/s, train_loss=0.259]Epoch 0:  50%|█████     | 14/28 [00:00<00:00, 95.48it/s, train_loss=0.259]Epoch 0:  50%|█████     | 14/28 [00:00<00:00, 92.09it/s, train_loss=0.276]Epoch 0:  54%|█████▎    | 15/28 [00:00<00:00, 94.80it/s, train_loss=0.276]Epoch 0:  54%|█████▎    | 15/28 [00:00<00:00, 91.98it/s, train_loss=0.290]Epoch 0:  57%|█████▋    | 16/28 [00:00<00:00, 94.72it/s, train_loss=0.290]Epoch 0:  57%|█████▋    | 16/28 [00:00<00:00, 92.90it/s, train_loss=0.267]Epoch 0:  61%|██████    | 17/28 [00:00<00:00, 95.44it/s, train_loss=0.267]Epoch 0:  61%|██████    | 17/28 [00:00<00:00, 92.38it/s, train_loss=0.247]Epoch 0:  64%|██████▍   | 18/28 [00:00<00:00, 94.86it/s, train_loss=0.247]Epoch 0:  64%|██████▍   | 18/28 [00:00<00:00, 92.28it/s, train_loss=0.207]Epoch 0:  68%|██████▊   | 19/28 [00:00<00:00, 94.61it/s, train_loss=0.207]Epoch 0:  68%|██████▊   | 19/28 [00:00<00:00, 92.17it/s, train_loss=0.272]Epoch 0:  71%|███████▏  | 20/28 [00:00<00:00, 94.39it/s, train_loss=0.272]Epoch 0:  71%|███████▏  | 20/28 [00:00<00:00, 92.99it/s, train_loss=0.304]Epoch 0:  75%|███████▌  | 21/28 [00:00<00:00, 94.99it/s, train_loss=0.304]Epoch 0:  75%|███████▌  | 21/28 [00:00<00:00, 92.57it/s, train_loss=0.310]Epoch 0:  79%|███████▊  | 22/28 [00:00<00:00, 94.56it/s, train_loss=0.310]Epoch 0:  79%|███████▊  | 22/28 [00:00<00:00, 92.47it/s, train_loss=0.203]Epoch 0:  82%|████████▏ | 23/28 [00:00<00:00, 94.51it/s, train_loss=0.203]Epoch 0:  82%|████████▏ | 23/28 [00:00<00:00, 92.34it/s, train_loss=0.272]Epoch 0:  86%|████████▌ | 24/28 [00:00<00:00, 94.24it/s, train_loss=0.272]Epoch 0:  86%|████████▌ | 24/28 [00:00<00:00, 93.24it/s, train_loss=0.253]Epoch 0:  89%|████████▉ | 25/28 [00:00<00:00, 95.06it/s, train_loss=0.253]Epoch 0:  89%|████████▉ | 25/28 [00:00<00:00, 93.10it/s, train_loss=0.262]Epoch 0:  93%|█████████▎| 26/28 [00:00<00:00, 94.96it/s, train_loss=0.262]Epoch 0:  93%|█████████▎| 26/28 [00:00<00:00, 93.76it/s, train_loss=0.273]Epoch 0:  96%|█████████▋| 27/28 [00:00<00:00, 95.51it/s, train_loss=0.273]Epoch 0:  96%|█████████▋| 27/28 [00:00<00:00, 94.38it/s, train_loss=0.273]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 96.03it/s, train_loss=0.273]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 95.03it/s, train_loss=0.267]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 182.39it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 212.49it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 223.59it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 232.34it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 237.31it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 240.48it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 242.49it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 243.89it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 244.98it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 245.85it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 244.75it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 245.22it/s][A
                                                                         [AEpoch 0: 100%|██████████| 28/28 [00:00<00:00, 79.70it/s, train_loss=0.267, val_loss=0.268]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 79.49it/s, train_loss=0.267, val_loss=0.268]Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.267, val_loss=0.268]         Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.267, val_loss=0.268]Epoch 1:   4%|▎         | 1/28 [00:00<00:00, 151.15it/s, train_loss=0.267, val_loss=0.268]Epoch 1:   4%|▎         | 1/28 [00:00<00:00, 74.01it/s, train_loss=0.257, val_loss=0.268] Epoch 1:   7%|▋         | 2/28 [00:00<00:00, 101.90it/s, train_loss=0.257, val_loss=0.268]Epoch 1:   7%|▋         | 2/28 [00:00<00:00, 74.46it/s, train_loss=0.217, val_loss=0.268] Epoch 1:  11%|█         | 3/28 [00:00<00:00, 91.65it/s, train_loss=0.217, val_loss=0.268]Epoch 1:  11%|█         | 3/28 [00:00<00:00, 78.64it/s, train_loss=0.243, val_loss=0.268]Epoch 1:  14%|█▍        | 4/28 [00:00<00:00, 91.08it/s, train_loss=0.243, val_loss=0.268]Epoch 1:  14%|█▍        | 4/28 [00:00<00:00, 81.12it/s, train_loss=0.219, val_loss=0.268]Epoch 1:  18%|█▊        | 5/28 [00:00<00:00, 90.82it/s, train_loss=0.219, val_loss=0.268]Epoch 1:  18%|█▊        | 5/28 [00:00<00:00, 84.91it/s, train_loss=0.249, val_loss=0.268]Epoch 1:  21%|██▏       | 6/28 [00:00<00:00, 92.44it/s, train_loss=0.249, val_loss=0.268]Epoch 1:  21%|██▏       | 6/28 [00:00<00:00, 84.84it/s, train_loss=0.216, val_loss=0.268]Epoch 1:  25%|██▌       | 7/28 [00:00<00:00, 91.46it/s, train_loss=0.216, val_loss=0.268]Epoch 1:  25%|██▌       | 7/28 [00:00<00:00, 85.44it/s, train_loss=0.225, val_loss=0.268]Epoch 1:  29%|██▊       | 8/28 [00:00<00:00, 91.50it/s, train_loss=0.225, val_loss=0.268]Epoch 1:  29%|██▊       | 8/28 [00:00<00:00, 85.95it/s, train_loss=0.205, val_loss=0.268]Epoch 1:  32%|███▏      | 9/28 [00:00<00:00, 91.37it/s, train_loss=0.205, val_loss=0.268]Epoch 1:  32%|███▏      | 9/28 [00:00<00:00, 87.84it/s, train_loss=0.217, val_loss=0.268]Epoch 1:  36%|███▌      | 10/28 [00:00<00:00, 92.38it/s, train_loss=0.217, val_loss=0.268]Epoch 1:  36%|███▌      | 10/28 [00:00<00:00, 86.84it/s, train_loss=0.214, val_loss=0.268]Epoch 1:  39%|███▉      | 11/28 [00:00<00:00, 91.20it/s, train_loss=0.214, val_loss=0.268]Epoch 1:  39%|███▉      | 11/28 [00:00<00:00, 87.05it/s, train_loss=0.240, val_loss=0.268]Epoch 1:  43%|████▎     | 12/28 [00:00<00:00, 90.99it/s, train_loss=0.240, val_loss=0.268]Epoch 1:  43%|████▎     | 12/28 [00:00<00:00, 87.23it/s, train_loss=0.238, val_loss=0.268]Epoch 1:  46%|████▋     | 13/28 [00:00<00:00, 90.82it/s, train_loss=0.238, val_loss=0.268]Epoch 1:  46%|████▋     | 13/28 [00:00<00:00, 88.46it/s, train_loss=0.181, val_loss=0.268]Epoch 1:  50%|█████     | 14/28 [00:00<00:00, 91.69it/s, train_loss=0.181, val_loss=0.268]Epoch 1:  50%|█████     | 14/28 [00:00<00:00, 87.78it/s, train_loss=0.181, val_loss=0.268]Epoch 1:  54%|█████▎    | 15/28 [00:00<00:00, 90.90it/s, train_loss=0.181, val_loss=0.268]Epoch 1:  54%|█████▎    | 15/28 [00:00<00:00, 87.89it/s, train_loss=0.173, val_loss=0.268]Epoch 1:  57%|█████▋    | 16/28 [00:00<00:00, 90.79it/s, train_loss=0.173, val_loss=0.268]Epoch 1:  57%|█████▋    | 16/28 [00:00<00:00, 89.16it/s, train_loss=0.200, val_loss=0.268]Epoch 1:  61%|██████    | 17/28 [00:00<00:00, 91.80it/s, train_loss=0.200, val_loss=0.268]Epoch 1:  61%|██████    | 17/28 [00:00<00:00, 89.23it/s, train_loss=0.189, val_loss=0.268]Epoch 1:  64%|██████▍   | 18/28 [00:00<00:00, 91.56it/s, train_loss=0.189, val_loss=0.268]Epoch 1:  64%|██████▍   | 18/28 [00:00<00:00, 88.48it/s, train_loss=0.154, val_loss=0.268]Epoch 1:  68%|██████▊   | 19/28 [00:00<00:00, 90.79it/s, train_loss=0.154, val_loss=0.268]Epoch 1:  68%|██████▊   | 19/28 [00:00<00:00, 88.57it/s, train_loss=0.130, val_loss=0.268]Epoch 1:  71%|███████▏  | 20/28 [00:00<00:00, 90.81it/s, train_loss=0.130, val_loss=0.268]Epoch 1:  71%|███████▏  | 20/28 [00:00<00:00, 88.65it/s, train_loss=0.237, val_loss=0.268]Epoch 1:  75%|███████▌  | 21/28 [00:00<00:00, 90.76it/s, train_loss=0.237, val_loss=0.268]Epoch 1:  75%|███████▌  | 21/28 [00:00<00:00, 89.47it/s, train_loss=0.140, val_loss=0.268]Epoch 1:  79%|███████▊  | 22/28 [00:00<00:00, 91.16it/s, train_loss=0.140, val_loss=0.268]Epoch 1:  79%|███████▊  | 22/28 [00:00<00:00, 89.19it/s, train_loss=0.133, val_loss=0.268]Epoch 1:  82%|████████▏ | 23/28 [00:00<00:00, 91.13it/s, train_loss=0.133, val_loss=0.268]Epoch 1:  82%|████████▏ | 23/28 [00:00<00:00, 89.24it/s, train_loss=0.131, val_loss=0.268]Epoch 1:  86%|████████▌ | 24/28 [00:00<00:00, 91.15it/s, train_loss=0.131, val_loss=0.268]Epoch 1:  86%|████████▌ | 24/28 [00:00<00:00, 90.05it/s, train_loss=0.149, val_loss=0.268]Epoch 1:  89%|████████▉ | 25/28 [00:00<00:00, 91.86it/s, train_loss=0.149, val_loss=0.268]Epoch 1:  89%|████████▉ | 25/28 [00:00<00:00, 90.82it/s, train_loss=0.208, val_loss=0.268]Epoch 1:  93%|█████████▎| 26/28 [00:00<00:00, 92.36it/s, train_loss=0.208, val_loss=0.268]Epoch 1:  93%|█████████▎| 26/28 [00:00<00:00, 91.39it/s, train_loss=0.128, val_loss=0.268]Epoch 1:  96%|█████████▋| 27/28 [00:00<00:00, 92.84it/s, train_loss=0.128, val_loss=0.268]Epoch 1:  96%|█████████▋| 27/28 [00:00<00:00, 91.35it/s, train_loss=0.170, val_loss=0.268]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 92.99it/s, train_loss=0.170, val_loss=0.268]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 92.05it/s, train_loss=0.152, val_loss=0.268]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 191.43it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 217.73it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 233.47it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 244.25it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 248.20it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 252.55it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 254.26it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 257.50it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 259.54it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 260.54it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 261.46it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 262.93it/s][A
                                                                         [AEpoch 1: 100%|██████████| 28/28 [00:00<00:00, 78.41it/s, train_loss=0.152, val_loss=0.139]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 78.21it/s, train_loss=0.152, val_loss=0.139]Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.152, val_loss=0.139]         Epoch 2:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.152, val_loss=0.139]Epoch 2:   4%|▎         | 1/28 [00:00<00:00, 149.73it/s, train_loss=0.152, val_loss=0.139]Epoch 2:   4%|▎         | 1/28 [00:00<00:00, 74.71it/s, train_loss=0.111, val_loss=0.139] Epoch 2:   7%|▋         | 2/28 [00:00<00:00, 105.70it/s, train_loss=0.111, val_loss=0.139]Epoch 2:   7%|▋         | 2/28 [00:00<00:00, 81.31it/s, train_loss=0.113, val_loss=0.139] Epoch 2:  11%|█         | 3/28 [00:00<00:00, 98.63it/s, train_loss=0.113, val_loss=0.139]Epoch 2:  11%|█         | 3/28 [00:00<00:00, 83.82it/s, train_loss=0.0903, val_loss=0.139]Epoch 2:  14%|█▍        | 4/28 [00:00<00:00, 96.15it/s, train_loss=0.0903, val_loss=0.139]Epoch 2:  14%|█▍        | 4/28 [00:00<00:00, 85.26it/s, train_loss=0.094, val_loss=0.139] Epoch 2:  18%|█▊        | 5/28 [00:00<00:00, 95.26it/s, train_loss=0.094, val_loss=0.139]Epoch 2:  18%|█▊        | 5/28 [00:00<00:00, 86.00it/s, train_loss=0.0828, val_loss=0.139]Epoch 2:  21%|██▏       | 6/28 [00:00<00:00, 94.15it/s, train_loss=0.0828, val_loss=0.139]Epoch 2:  21%|██▏       | 6/28 [00:00<00:00, 86.65it/s, train_loss=0.084, val_loss=0.139] Epoch 2:  25%|██▌       | 7/28 [00:00<00:00, 92.95it/s, train_loss=0.084, val_loss=0.139]Epoch 2:  25%|██▌       | 7/28 [00:00<00:00, 87.14it/s, train_loss=0.0902, val_loss=0.139]Epoch 2:  29%|██▊       | 8/28 [00:00<00:00, 92.91it/s, train_loss=0.0902, val_loss=0.139]Epoch 2:  29%|██▊       | 8/28 [00:00<00:00, 87.40it/s, train_loss=0.0705, val_loss=0.139]Epoch 2:  32%|███▏      | 9/28 [00:00<00:00, 92.56it/s, train_loss=0.0705, val_loss=0.139]Epoch 2:  32%|███▏      | 9/28 [00:00<00:00, 87.57it/s, train_loss=0.0541, val_loss=0.139]Epoch 2:  36%|███▌      | 10/28 [00:00<00:00, 92.17it/s, train_loss=0.0541, val_loss=0.139]Epoch 2:  36%|███▌      | 10/28 [00:00<00:00, 87.72it/s, train_loss=0.0626, val_loss=0.139]Epoch 2:  39%|███▉      | 11/28 [00:00<00:00, 91.62it/s, train_loss=0.0626, val_loss=0.139]Epoch 2:  39%|███▉      | 11/28 [00:00<00:00, 86.39it/s, train_loss=0.0354, val_loss=0.139]Epoch 2:  43%|████▎     | 12/28 [00:00<00:00, 90.42it/s, train_loss=0.0354, val_loss=0.139]Epoch 2:  43%|████▎     | 12/28 [00:00<00:00, 86.54it/s, train_loss=0.0458, val_loss=0.139]Epoch 2:  46%|████▋     | 13/28 [00:00<00:00, 90.27it/s, train_loss=0.0458, val_loss=0.139]Epoch 2:  46%|████▋     | 13/28 [00:00<00:00, 86.67it/s, train_loss=0.0381, val_loss=0.139]Epoch 2:  50%|█████     | 14/28 [00:00<00:00, 90.10it/s, train_loss=0.0381, val_loss=0.139]Epoch 2:  50%|█████     | 14/28 [00:00<00:00, 86.82it/s, train_loss=0.0342, val_loss=0.139]Epoch 2:  54%|█████▎    | 15/28 [00:00<00:00, 89.80it/s, train_loss=0.0342, val_loss=0.139]Epoch 2:  54%|█████▎    | 15/28 [00:00<00:00, 86.88it/s, train_loss=0.0351, val_loss=0.139]Epoch 2:  57%|█████▋    | 16/28 [00:00<00:00, 89.85it/s, train_loss=0.0351, val_loss=0.139]Epoch 2:  57%|█████▋    | 16/28 [00:00<00:00, 86.92it/s, train_loss=0.0453, val_loss=0.139]Epoch 2:  61%|██████    | 17/28 [00:00<00:00, 89.59it/s, train_loss=0.0453, val_loss=0.139]Epoch 2:  61%|██████    | 17/28 [00:00<00:00, 86.99it/s, train_loss=0.0429, val_loss=0.139]Epoch 2:  64%|██████▍   | 18/28 [00:00<00:00, 89.44it/s, train_loss=0.0429, val_loss=0.139]Epoch 2:  64%|██████▍   | 18/28 [00:00<00:00, 87.06it/s, train_loss=0.0426, val_loss=0.139]Epoch 2:  68%|██████▊   | 19/28 [00:00<00:00, 89.48it/s, train_loss=0.0426, val_loss=0.139]Epoch 2:  68%|██████▊   | 19/28 [00:00<00:00, 87.08it/s, train_loss=0.033, val_loss=0.139] Epoch 2:  71%|███████▏  | 20/28 [00:00<00:00, 89.41it/s, train_loss=0.033, val_loss=0.139]Epoch 2:  71%|███████▏  | 20/28 [00:00<00:00, 87.11it/s, train_loss=0.0308, val_loss=0.139]Epoch 2:  75%|███████▌  | 21/28 [00:00<00:00, 89.30it/s, train_loss=0.0308, val_loss=0.139]Epoch 2:  75%|███████▌  | 21/28 [00:00<00:00, 87.17it/s, train_loss=0.0368, val_loss=0.139]Epoch 2:  79%|███████▊  | 22/28 [00:00<00:00, 89.16it/s, train_loss=0.0368, val_loss=0.139]Epoch 2:  79%|███████▊  | 22/28 [00:00<00:00, 86.57it/s, train_loss=0.0491, val_loss=0.139]Epoch 2:  82%|████████▏ | 23/28 [00:00<00:00, 88.52it/s, train_loss=0.0491, val_loss=0.139]Epoch 2:  82%|████████▏ | 23/28 [00:00<00:00, 86.63it/s, train_loss=0.0305, val_loss=0.139]Epoch 2:  86%|████████▌ | 24/28 [00:00<00:00, 88.50it/s, train_loss=0.0305, val_loss=0.139]Epoch 2:  86%|████████▌ | 24/28 [00:00<00:00, 86.68it/s, train_loss=0.0438, val_loss=0.139]Epoch 2:  89%|████████▉ | 25/28 [00:00<00:00, 88.49it/s, train_loss=0.0438, val_loss=0.139]Epoch 2:  89%|████████▉ | 25/28 [00:00<00:00, 87.31it/s, train_loss=0.0399, val_loss=0.139]Epoch 2:  93%|█████████▎| 26/28 [00:00<00:00, 89.02it/s, train_loss=0.0399, val_loss=0.139]Epoch 2:  93%|█████████▎| 26/28 [00:00<00:00, 86.98it/s, train_loss=0.0366, val_loss=0.139]Epoch 2:  96%|█████████▋| 27/28 [00:00<00:00, 88.71it/s, train_loss=0.0366, val_loss=0.139]Epoch 2:  96%|█████████▋| 27/28 [00:00<00:00, 87.02it/s, train_loss=0.0275, val_loss=0.139]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 88.38it/s, train_loss=0.0275, val_loss=0.139]Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 87.12it/s, train_loss=0.042, val_loss=0.139] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 216.35it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 250.17it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 259.44it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 266.55it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 269.18it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 271.34it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 273.54it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 275.01it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 275.18it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 273.37it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 273.81it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 274.76it/s][A
                                                                         [AEpoch 2: 100%|██████████| 28/28 [00:00<00:00, 75.26it/s, train_loss=0.042, val_loss=0.0414]Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 75.11it/s, train_loss=0.042, val_loss=0.0414]Epoch 2:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.042, val_loss=0.0414]         Epoch 3:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.042, val_loss=0.0414]Epoch 3:   4%|▎         | 1/28 [00:00<00:00, 151.25it/s, train_loss=0.042, val_loss=0.0414]Epoch 3:   4%|▎         | 1/28 [00:00<00:00, 73.63it/s, train_loss=0.0367, val_loss=0.0414]Epoch 3:   7%|▋         | 2/28 [00:00<00:00, 104.49it/s, train_loss=0.0367, val_loss=0.0414]Epoch 3:   7%|▋         | 2/28 [00:00<00:00, 80.27it/s, train_loss=0.0195, val_loss=0.0414] Epoch 3:  11%|█         | 3/28 [00:00<00:00, 97.48it/s, train_loss=0.0195, val_loss=0.0414]Epoch 3:  11%|█         | 3/28 [00:00<00:00, 79.98it/s, train_loss=0.0449, val_loss=0.0414]Epoch 3:  14%|█▍        | 4/28 [00:00<00:00, 92.49it/s, train_loss=0.0449, val_loss=0.0414]Epoch 3:  14%|█▍        | 4/28 [00:00<00:00, 81.74it/s, train_loss=0.0331, val_loss=0.0414]Epoch 3:  18%|█▊        | 5/28 [00:00<00:00, 91.50it/s, train_loss=0.0331, val_loss=0.0414]Epoch 3:  18%|█▊        | 5/28 [00:00<00:00, 82.85it/s, train_loss=0.0375, val_loss=0.0414]Epoch 3:  21%|██▏       | 6/28 [00:00<00:00, 90.85it/s, train_loss=0.0375, val_loss=0.0414]Epoch 3:  21%|██▏       | 6/28 [00:00<00:00, 85.59it/s, train_loss=0.0398, val_loss=0.0414]Epoch 3:  25%|██▌       | 7/28 [00:00<00:00, 92.06it/s, train_loss=0.0398, val_loss=0.0414]Epoch 3:  25%|██▌       | 7/28 [00:00<00:00, 84.75it/s, train_loss=0.0287, val_loss=0.0414]Epoch 3:  29%|██▊       | 8/28 [00:00<00:00, 90.57it/s, train_loss=0.0287, val_loss=0.0414]Epoch 3:  29%|██▊       | 8/28 [00:00<00:00, 85.20it/s, train_loss=0.0471, val_loss=0.0414]Epoch 3:  32%|███▏      | 9/28 [00:00<00:00, 90.45it/s, train_loss=0.0471, val_loss=0.0414]Epoch 3:  32%|███▏      | 9/28 [00:00<00:00, 85.55it/s, train_loss=0.031, val_loss=0.0414] Epoch 3:  36%|███▌      | 10/28 [00:00<00:00, 90.29it/s, train_loss=0.031, val_loss=0.0414]Epoch 3:  36%|███▌      | 10/28 [00:00<00:00, 87.42it/s, train_loss=0.0329, val_loss=0.0414]Epoch 3:  39%|███▉      | 11/28 [00:00<00:00, 91.16it/s, train_loss=0.0329, val_loss=0.0414]Epoch 3:  39%|███▉      | 11/28 [00:00<00:00, 86.54it/s, train_loss=0.0241, val_loss=0.0414]Epoch 3:  43%|████▎     | 12/28 [00:00<00:00, 90.60it/s, train_loss=0.0241, val_loss=0.0414]Epoch 3:  43%|████▎     | 12/28 [00:00<00:00, 86.67it/s, train_loss=0.0239, val_loss=0.0414]Epoch 3:  46%|████▋     | 13/28 [00:00<00:00, 90.47it/s, train_loss=0.0239, val_loss=0.0414]Epoch 3:  46%|████▋     | 13/28 [00:00<00:00, 86.80it/s, train_loss=0.0224, val_loss=0.0414]Epoch 3:  50%|█████     | 14/28 [00:00<00:00, 90.30it/s, train_loss=0.0224, val_loss=0.0414]Epoch 3:  50%|█████     | 14/28 [00:00<00:00, 88.02it/s, train_loss=0.0301, val_loss=0.0414]Epoch 3:  54%|█████▎    | 15/28 [00:00<00:00, 91.14it/s, train_loss=0.0301, val_loss=0.0414]Epoch 3:  54%|█████▎    | 15/28 [00:00<00:00, 87.42it/s, train_loss=0.0213, val_loss=0.0414]Epoch 3:  57%|█████▋    | 16/28 [00:00<00:00, 90.38it/s, train_loss=0.0213, val_loss=0.0414]Epoch 3:  57%|█████▋    | 16/28 [00:00<00:00, 87.44it/s, train_loss=0.0402, val_loss=0.0414]Epoch 3:  61%|██████    | 17/28 [00:00<00:00, 90.27it/s, train_loss=0.0402, val_loss=0.0414]Epoch 3:  61%|██████    | 17/28 [00:00<00:00, 87.46it/s, train_loss=0.029, val_loss=0.0414] Epoch 3:  64%|██████▍   | 18/28 [00:00<00:00, 89.92it/s, train_loss=0.029, val_loss=0.0414]Epoch 3:  64%|██████▍   | 18/28 [00:00<00:00, 88.35it/s, train_loss=0.0311, val_loss=0.0414]Epoch 3:  68%|██████▊   | 19/28 [00:00<00:00, 90.68it/s, train_loss=0.0311, val_loss=0.0414]Epoch 3:  68%|██████▊   | 19/28 [00:00<00:00, 88.11it/s, train_loss=0.0478, val_loss=0.0414]Epoch 3:  71%|███████▏  | 20/28 [00:00<00:00, 90.42it/s, train_loss=0.0478, val_loss=0.0414]Epoch 3:  71%|███████▏  | 20/28 [00:00<00:00, 88.12it/s, train_loss=0.0254, val_loss=0.0414]Epoch 3:  75%|███████▌  | 21/28 [00:00<00:00, 90.34it/s, train_loss=0.0254, val_loss=0.0414]Epoch 3:  75%|███████▌  | 21/28 [00:00<00:00, 88.12it/s, train_loss=0.0323, val_loss=0.0414]Epoch 3:  79%|███████▊  | 22/28 [00:00<00:00, 90.27it/s, train_loss=0.0323, val_loss=0.0414]Epoch 3:  79%|███████▊  | 22/28 [00:00<00:00, 88.88it/s, train_loss=0.0207, val_loss=0.0414]Epoch 3:  82%|████████▏ | 23/28 [00:00<00:00, 90.79it/s, train_loss=0.0207, val_loss=0.0414]Epoch 3:  82%|████████▏ | 23/28 [00:00<00:00, 88.44it/s, train_loss=0.0305, val_loss=0.0414]Epoch 3:  86%|████████▌ | 24/28 [00:00<00:00, 90.34it/s, train_loss=0.0305, val_loss=0.0414]Epoch 3:  86%|████████▌ | 24/28 [00:00<00:00, 88.44it/s, train_loss=0.0326, val_loss=0.0414]Epoch 3:  89%|████████▉ | 25/28 [00:00<00:00, 90.28it/s, train_loss=0.0326, val_loss=0.0414]Epoch 3:  89%|████████▉ | 25/28 [00:00<00:00, 88.44it/s, train_loss=0.0327, val_loss=0.0414]Epoch 3:  93%|█████████▎| 26/28 [00:00<00:00, 90.18it/s, train_loss=0.0327, val_loss=0.0414]Epoch 3:  93%|█████████▎| 26/28 [00:00<00:00, 88.52it/s, train_loss=0.0349, val_loss=0.0414]Epoch 3:  96%|█████████▋| 27/28 [00:00<00:00, 90.11it/s, train_loss=0.0349, val_loss=0.0414]Epoch 3:  96%|█████████▋| 27/28 [00:00<00:00, 88.51it/s, train_loss=0.0192, val_loss=0.0414]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 90.14it/s, train_loss=0.0192, val_loss=0.0414]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 88.54it/s, train_loss=0.0225, val_loss=0.0414]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 142.83it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 174.31it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 198.67it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 220.58it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 235.13it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 243.48it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 251.51it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 257.12it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 260.77it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 262.82it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 264.88it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 267.10it/s][A
                                                                         [AEpoch 3: 100%|██████████| 28/28 [00:00<00:00, 75.56it/s, train_loss=0.0225, val_loss=0.0383]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 75.42it/s, train_loss=0.0225, val_loss=0.0383]Epoch 3:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0225, val_loss=0.0383]         Epoch 4:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0225, val_loss=0.0383]Epoch 4:   4%|▎         | 1/28 [00:00<00:00, 150.92it/s, train_loss=0.0225, val_loss=0.0383]Epoch 4:   4%|▎         | 1/28 [00:00<00:00, 73.55it/s, train_loss=0.0268, val_loss=0.0383] Epoch 4:   7%|▋         | 2/28 [00:00<00:00, 103.93it/s, train_loss=0.0268, val_loss=0.0383]Epoch 4:   7%|▋         | 2/28 [00:00<00:00, 79.96it/s, train_loss=0.0265, val_loss=0.0383] Epoch 4:  11%|█         | 3/28 [00:00<00:00, 97.44it/s, train_loss=0.0265, val_loss=0.0383]Epoch 4:  11%|█         | 3/28 [00:00<00:00, 79.72it/s, train_loss=0.0231, val_loss=0.0383]Epoch 4:  14%|█▍        | 4/28 [00:00<00:00, 92.45it/s, train_loss=0.0231, val_loss=0.0383]Epoch 4:  14%|█▍        | 4/28 [00:00<00:00, 81.41it/s, train_loss=0.0447, val_loss=0.0383]Epoch 4:  18%|█▊        | 5/28 [00:00<00:00, 91.13it/s, train_loss=0.0447, val_loss=0.0383]Epoch 4:  18%|█▊        | 5/28 [00:00<00:00, 82.57it/s, train_loss=0.0289, val_loss=0.0383]Epoch 4:  21%|██▏       | 6/28 [00:00<00:00, 90.68it/s, train_loss=0.0289, val_loss=0.0383]Epoch 4:  21%|██▏       | 6/28 [00:00<00:00, 85.41it/s, train_loss=0.0265, val_loss=0.0383]Epoch 4:  25%|██▌       | 7/28 [00:00<00:00, 91.83it/s, train_loss=0.0265, val_loss=0.0383]Epoch 4:  25%|██▌       | 7/28 [00:00<00:00, 84.60it/s, train_loss=0.0256, val_loss=0.0383]Epoch 4:  29%|██▊       | 8/28 [00:00<00:00, 90.43it/s, train_loss=0.0256, val_loss=0.0383]Epoch 4:  29%|██▊       | 8/28 [00:00<00:00, 85.10it/s, train_loss=0.043, val_loss=0.0383] Epoch 4:  32%|███▏      | 9/28 [00:00<00:00, 90.23it/s, train_loss=0.043, val_loss=0.0383]Epoch 4:  32%|███▏      | 9/28 [00:00<00:00, 85.54it/s, train_loss=0.0353, val_loss=0.0383]Epoch 4:  36%|███▌      | 10/28 [00:00<00:00, 90.19it/s, train_loss=0.0353, val_loss=0.0383]Epoch 4:  36%|███▌      | 10/28 [00:00<00:00, 85.88it/s, train_loss=0.0382, val_loss=0.0383]Epoch 4:  39%|███▉      | 11/28 [00:00<00:00, 89.89it/s, train_loss=0.0382, val_loss=0.0383]Epoch 4:  39%|███▉      | 11/28 [00:00<00:00, 86.12it/s, train_loss=0.0246, val_loss=0.0383]Epoch 4:  43%|████▎     | 12/28 [00:00<00:00, 90.06it/s, train_loss=0.0246, val_loss=0.0383]Epoch 4:  43%|████▎     | 12/28 [00:00<00:00, 86.30it/s, train_loss=0.023, val_loss=0.0383] Epoch 4:  46%|████▋     | 13/28 [00:00<00:00, 89.91it/s, train_loss=0.023, val_loss=0.0383]Epoch 4:  46%|████▋     | 13/28 [00:00<00:00, 86.45it/s, train_loss=0.0187, val_loss=0.0383]Epoch 4:  50%|█████     | 14/28 [00:00<00:00, 89.66it/s, train_loss=0.0187, val_loss=0.0383]Epoch 4:  50%|█████     | 14/28 [00:00<00:00, 87.65it/s, train_loss=0.0223, val_loss=0.0383]Epoch 4:  54%|█████▎    | 15/28 [00:00<00:00, 90.39it/s, train_loss=0.0223, val_loss=0.0383]Epoch 4:  54%|█████▎    | 15/28 [00:00<00:00, 87.69it/s, train_loss=0.0251, val_loss=0.0383]Epoch 4:  57%|█████▋    | 16/28 [00:00<00:00, 89.51it/s, train_loss=0.0251, val_loss=0.0383]Epoch 4:  57%|█████▋    | 16/28 [00:00<00:00, 86.70it/s, train_loss=0.0265, val_loss=0.0383]Epoch 4:  61%|██████    | 17/28 [00:00<00:00, 89.51it/s, train_loss=0.0265, val_loss=0.0383]Epoch 4:  61%|██████    | 17/28 [00:00<00:00, 86.80it/s, train_loss=0.0316, val_loss=0.0383]Epoch 4:  64%|██████▍   | 18/28 [00:00<00:00, 89.28it/s, train_loss=0.0316, val_loss=0.0383]Epoch 4:  64%|██████▍   | 18/28 [00:00<00:00, 87.14it/s, train_loss=0.0257, val_loss=0.0383]Epoch 4:  68%|██████▊   | 19/28 [00:00<00:00, 89.65it/s, train_loss=0.0257, val_loss=0.0383]Epoch 4:  68%|██████▊   | 19/28 [00:00<00:00, 87.16it/s, train_loss=0.0228, val_loss=0.0383]Epoch 4:  71%|███████▏  | 20/28 [00:00<00:00, 89.55it/s, train_loss=0.0228, val_loss=0.0383]Epoch 4:  71%|███████▏  | 20/28 [00:00<00:00, 87.19it/s, train_loss=0.0261, val_loss=0.0383]Epoch 4:  75%|███████▌  | 21/28 [00:00<00:00, 89.43it/s, train_loss=0.0261, val_loss=0.0383]Epoch 4:  75%|███████▌  | 21/28 [00:00<00:00, 87.23it/s, train_loss=0.0289, val_loss=0.0383]Epoch 4:  79%|███████▊  | 22/28 [00:00<00:00, 89.08it/s, train_loss=0.0289, val_loss=0.0383]Epoch 4:  79%|███████▊  | 22/28 [00:00<00:00, 86.60it/s, train_loss=0.0384, val_loss=0.0383]Epoch 4:  82%|████████▏ | 23/28 [00:00<00:00, 88.56it/s, train_loss=0.0384, val_loss=0.0383]Epoch 4:  82%|████████▏ | 23/28 [00:00<00:00, 86.70it/s, train_loss=0.034, val_loss=0.0383] Epoch 4:  86%|████████▌ | 24/28 [00:00<00:00, 88.59it/s, train_loss=0.034, val_loss=0.0383]Epoch 4:  86%|████████▌ | 24/28 [00:00<00:00, 86.77it/s, train_loss=0.018, val_loss=0.0383]Epoch 4:  89%|████████▉ | 25/28 [00:00<00:00, 88.58it/s, train_loss=0.018, val_loss=0.0383]Epoch 4:  89%|████████▉ | 25/28 [00:00<00:00, 86.83it/s, train_loss=0.0316, val_loss=0.0383]Epoch 4:  93%|█████████▎| 26/28 [00:00<00:00, 88.54it/s, train_loss=0.0316, val_loss=0.0383]Epoch 4:  93%|█████████▎| 26/28 [00:00<00:00, 86.88it/s, train_loss=0.0278, val_loss=0.0383]Epoch 4:  96%|█████████▋| 27/28 [00:00<00:00, 88.59it/s, train_loss=0.0278, val_loss=0.0383]Epoch 4:  96%|█████████▋| 27/28 [00:00<00:00, 86.91it/s, train_loss=0.0274, val_loss=0.0383]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 88.55it/s, train_loss=0.0274, val_loss=0.0383]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 87.02it/s, train_loss=0.0358, val_loss=0.0383]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 151.80it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 180.86it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 191.83it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 200.82it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 206.20it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 210.96it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 213.54it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 215.61it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 216.73it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 217.55it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 223.60it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 229.29it/s][A
                                                                         [AEpoch 4: 100%|██████████| 28/28 [00:00<00:00, 73.14it/s, train_loss=0.0358, val_loss=0.0361]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 73.01it/s, train_loss=0.0358, val_loss=0.0361]Epoch 4:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0358, val_loss=0.0361]         Epoch 5:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0358, val_loss=0.0361]Epoch 5:   4%|▎         | 1/28 [00:00<00:00, 158.69it/s, train_loss=0.0358, val_loss=0.0361]Epoch 5:   4%|▎         | 1/28 [00:00<00:00, 78.46it/s, train_loss=0.0488, val_loss=0.0361] Epoch 5:   7%|▋         | 2/28 [00:00<00:00, 110.44it/s, train_loss=0.0488, val_loss=0.0361]Epoch 5:   7%|▋         | 2/28 [00:00<00:00, 82.42it/s, train_loss=0.0202, val_loss=0.0361] Epoch 5:  11%|█         | 3/28 [00:00<00:00, 101.44it/s, train_loss=0.0202, val_loss=0.0361]Epoch 5:  11%|█         | 3/28 [00:00<00:00, 84.16it/s, train_loss=0.0253, val_loss=0.0361] Epoch 5:  14%|█▍        | 4/28 [00:00<00:00, 97.31it/s, train_loss=0.0253, val_loss=0.0361]Epoch 5:  14%|█▍        | 4/28 [00:00<00:00, 88.88it/s, train_loss=0.0197, val_loss=0.0361]Epoch 5:  18%|█▊        | 5/28 [00:00<00:00, 98.43it/s, train_loss=0.0197, val_loss=0.0361]Epoch 5:  18%|█▊        | 5/28 [00:00<00:00, 86.89it/s, train_loss=0.0249, val_loss=0.0361]Epoch 5:  21%|██▏       | 6/28 [00:00<00:00, 94.66it/s, train_loss=0.0249, val_loss=0.0361]Epoch 5:  21%|██▏       | 6/28 [00:00<00:00, 87.04it/s, train_loss=0.0242, val_loss=0.0361]Epoch 5:  25%|██▌       | 7/28 [00:00<00:00, 94.00it/s, train_loss=0.0242, val_loss=0.0361]Epoch 5:  25%|██▌       | 7/28 [00:00<00:00, 87.11it/s, train_loss=0.0283, val_loss=0.0361]Epoch 5:  29%|██▊       | 8/28 [00:00<00:00, 93.14it/s, train_loss=0.0283, val_loss=0.0361]Epoch 5:  29%|██▊       | 8/28 [00:00<00:00, 89.18it/s, train_loss=0.0232, val_loss=0.0361]Epoch 5:  32%|███▏      | 9/28 [00:00<00:00, 94.37it/s, train_loss=0.0232, val_loss=0.0361]Epoch 5:  32%|███▏      | 9/28 [00:00<00:00, 88.09it/s, train_loss=0.0282, val_loss=0.0361]Epoch 5:  36%|███▌      | 10/28 [00:00<00:00, 92.77it/s, train_loss=0.0282, val_loss=0.0361]Epoch 5:  36%|███▌      | 10/28 [00:00<00:00, 88.15it/s, train_loss=0.0253, val_loss=0.0361]Epoch 5:  39%|███▉      | 11/28 [00:00<00:00, 92.34it/s, train_loss=0.0253, val_loss=0.0361]Epoch 5:  39%|███▉      | 11/28 [00:00<00:00, 88.21it/s, train_loss=0.0406, val_loss=0.0361]Epoch 5:  43%|████▎     | 12/28 [00:00<00:00, 92.12it/s, train_loss=0.0406, val_loss=0.0361]Epoch 5:  43%|████▎     | 12/28 [00:00<00:00, 89.59it/s, train_loss=0.0389, val_loss=0.0361]Epoch 5:  46%|████▋     | 13/28 [00:00<00:00, 92.99it/s, train_loss=0.0389, val_loss=0.0361]Epoch 5:  46%|████▋     | 13/28 [00:00<00:00, 88.81it/s, train_loss=0.0227, val_loss=0.0361]Epoch 5:  50%|█████     | 14/28 [00:00<00:00, 92.03it/s, train_loss=0.0227, val_loss=0.0361]Epoch 5:  50%|█████     | 14/28 [00:00<00:00, 88.78it/s, train_loss=0.0179, val_loss=0.0361]Epoch 5:  54%|█████▎    | 15/28 [00:00<00:00, 91.89it/s, train_loss=0.0179, val_loss=0.0361]Epoch 5:  54%|█████▎    | 15/28 [00:00<00:00, 88.77it/s, train_loss=0.0241, val_loss=0.0361]Epoch 5:  57%|█████▋    | 16/28 [00:00<00:00, 91.72it/s, train_loss=0.0241, val_loss=0.0361]Epoch 5:  57%|█████▋    | 16/28 [00:00<00:00, 88.85it/s, train_loss=0.0255, val_loss=0.0361]Epoch 5:  61%|██████    | 17/28 [00:00<00:00, 91.40it/s, train_loss=0.0255, val_loss=0.0361]Epoch 5:  61%|██████    | 17/28 [00:00<00:00, 88.85it/s, train_loss=0.0265, val_loss=0.0361]Epoch 5:  64%|██████▍   | 18/28 [00:00<00:00, 91.36it/s, train_loss=0.0265, val_loss=0.0361]Epoch 5:  64%|██████▍   | 18/28 [00:00<00:00, 88.82it/s, train_loss=0.0225, val_loss=0.0361]Epoch 5:  68%|██████▊   | 19/28 [00:00<00:00, 91.38it/s, train_loss=0.0225, val_loss=0.0361]Epoch 5:  68%|██████▊   | 19/28 [00:00<00:00, 88.79it/s, train_loss=0.023, val_loss=0.0361] Epoch 5:  71%|███████▏  | 20/28 [00:00<00:00, 91.11it/s, train_loss=0.023, val_loss=0.0361]Epoch 5:  71%|███████▏  | 20/28 [00:00<00:00, 88.72it/s, train_loss=0.0255, val_loss=0.0361]Epoch 5:  75%|███████▌  | 21/28 [00:00<00:00, 90.95it/s, train_loss=0.0255, val_loss=0.0361]Epoch 5:  75%|███████▌  | 21/28 [00:00<00:00, 88.68it/s, train_loss=0.0264, val_loss=0.0361]Epoch 5:  79%|███████▊  | 22/28 [00:00<00:00, 90.82it/s, train_loss=0.0264, val_loss=0.0361]Epoch 5:  79%|███████▊  | 22/28 [00:00<00:00, 88.64it/s, train_loss=0.0317, val_loss=0.0361]Epoch 5:  82%|████████▏ | 23/28 [00:00<00:00, 90.72it/s, train_loss=0.0317, val_loss=0.0361]Epoch 5:  82%|████████▏ | 23/28 [00:00<00:00, 88.67it/s, train_loss=0.0209, val_loss=0.0361]Epoch 5:  86%|████████▌ | 24/28 [00:00<00:00, 90.57it/s, train_loss=0.0209, val_loss=0.0361]Epoch 5:  86%|████████▌ | 24/28 [00:00<00:00, 88.29it/s, train_loss=0.0251, val_loss=0.0361]Epoch 5:  89%|████████▉ | 25/28 [00:00<00:00, 90.08it/s, train_loss=0.0251, val_loss=0.0361]Epoch 5:  89%|████████▉ | 25/28 [00:00<00:00, 88.28it/s, train_loss=0.0291, val_loss=0.0361]Epoch 5:  93%|█████████▎| 26/28 [00:00<00:00, 90.05it/s, train_loss=0.0291, val_loss=0.0361]Epoch 5:  93%|█████████▎| 26/28 [00:00<00:00, 88.28it/s, train_loss=0.0208, val_loss=0.0361]Epoch 5:  96%|█████████▋| 27/28 [00:00<00:00, 89.94it/s, train_loss=0.0208, val_loss=0.0361]Epoch 5:  96%|█████████▋| 27/28 [00:00<00:00, 88.28it/s, train_loss=0.0257, val_loss=0.0361]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 89.79it/s, train_loss=0.0257, val_loss=0.0361]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 88.34it/s, train_loss=0.043, val_loss=0.0361] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 153.18it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 185.99it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 201.56it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 209.11it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 212.90it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 215.36it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 217.09it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 219.54it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 220.95it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 222.54it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 223.27it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 224.52it/s][A
                                                                         [AEpoch 5: 100%|██████████| 28/28 [00:00<00:00, 73.94it/s, train_loss=0.043, val_loss=0.0338]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 73.76it/s, train_loss=0.043, val_loss=0.0338]Epoch 5:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.043, val_loss=0.0338]         Epoch 6:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.043, val_loss=0.0338]Epoch 6:   4%|▎         | 1/28 [00:00<00:00, 150.91it/s, train_loss=0.043, val_loss=0.0338]Epoch 6:   4%|▎         | 1/28 [00:00<00:00, 73.70it/s, train_loss=0.033, val_loss=0.0338] Epoch 6:   7%|▋         | 2/28 [00:00<00:00, 104.46it/s, train_loss=0.033, val_loss=0.0338]Epoch 6:   7%|▋         | 2/28 [00:00<00:00, 79.73it/s, train_loss=0.0324, val_loss=0.0338]Epoch 6:  11%|█         | 3/28 [00:00<00:00, 97.26it/s, train_loss=0.0324, val_loss=0.0338]Epoch 6:  11%|█         | 3/28 [00:00<00:00, 81.72it/s, train_loss=0.0221, val_loss=0.0338]Epoch 6:  14%|█▍        | 4/28 [00:00<00:00, 95.11it/s, train_loss=0.0221, val_loss=0.0338]Epoch 6:  14%|█▍        | 4/28 [00:00<00:00, 82.95it/s, train_loss=0.0363, val_loss=0.0338]Epoch 6:  18%|█▊        | 5/28 [00:00<00:00, 93.21it/s, train_loss=0.0363, val_loss=0.0338]Epoch 6:  18%|█▊        | 5/28 [00:00<00:00, 83.84it/s, train_loss=0.0302, val_loss=0.0338]Epoch 6:  21%|██▏       | 6/28 [00:00<00:00, 92.06it/s, train_loss=0.0302, val_loss=0.0338]Epoch 6:  21%|██▏       | 6/28 [00:00<00:00, 86.46it/s, train_loss=0.0194, val_loss=0.0338]Epoch 6:  25%|██▌       | 7/28 [00:00<00:00, 92.85it/s, train_loss=0.0194, val_loss=0.0338]Epoch 6:  25%|██▌       | 7/28 [00:00<00:00, 86.65it/s, train_loss=0.0322, val_loss=0.0338]Epoch 6:  29%|██▊       | 8/28 [00:00<00:00, 92.60it/s, train_loss=0.0322, val_loss=0.0338]Epoch 6:  29%|██▊       | 8/28 [00:00<00:00, 86.87it/s, train_loss=0.0247, val_loss=0.0338]Epoch 6:  32%|███▏      | 9/28 [00:00<00:00, 92.08it/s, train_loss=0.0247, val_loss=0.0338]Epoch 6:  32%|███▏      | 9/28 [00:00<00:00, 87.05it/s, train_loss=0.0173, val_loss=0.0338]Epoch 6:  36%|███▌      | 10/28 [00:00<00:00, 91.44it/s, train_loss=0.0173, val_loss=0.0338]Epoch 6:  36%|███▌      | 10/28 [00:00<00:00, 87.18it/s, train_loss=0.0273, val_loss=0.0338]Epoch 6:  39%|███▉      | 11/28 [00:00<00:00, 91.34it/s, train_loss=0.0273, val_loss=0.0338]Epoch 6:  39%|███▉      | 11/28 [00:00<00:00, 87.28it/s, train_loss=0.0224, val_loss=0.0338]Epoch 6:  43%|████▎     | 12/28 [00:00<00:00, 91.19it/s, train_loss=0.0224, val_loss=0.0338]Epoch 6:  43%|████▎     | 12/28 [00:00<00:00, 87.35it/s, train_loss=0.0269, val_loss=0.0338]Epoch 6:  46%|████▋     | 13/28 [00:00<00:00, 90.87it/s, train_loss=0.0269, val_loss=0.0338]Epoch 6:  46%|████▋     | 13/28 [00:00<00:00, 87.56it/s, train_loss=0.0204, val_loss=0.0338]Epoch 6:  50%|█████     | 14/28 [00:00<00:00, 90.62it/s, train_loss=0.0204, val_loss=0.0338]Epoch 6:  50%|█████     | 14/28 [00:00<00:00, 86.98it/s, train_loss=0.0252, val_loss=0.0338]Epoch 6:  54%|█████▎    | 15/28 [00:00<00:00, 89.96it/s, train_loss=0.0252, val_loss=0.0338]Epoch 6:  54%|█████▎    | 15/28 [00:00<00:00, 87.10it/s, train_loss=0.0161, val_loss=0.0338]Epoch 6:  57%|█████▋    | 16/28 [00:00<00:00, 89.84it/s, train_loss=0.0161, val_loss=0.0338]Epoch 6:  57%|█████▋    | 16/28 [00:00<00:00, 87.22it/s, train_loss=0.0194, val_loss=0.0338]Epoch 6:  61%|██████    | 17/28 [00:00<00:00, 89.90it/s, train_loss=0.0194, val_loss=0.0338]Epoch 6:  61%|██████    | 17/28 [00:00<00:00, 87.31it/s, train_loss=0.0209, val_loss=0.0338]Epoch 6:  64%|██████▍   | 18/28 [00:00<00:00, 89.63it/s, train_loss=0.0209, val_loss=0.0338]Epoch 6:  64%|██████▍   | 18/28 [00:00<00:00, 87.35it/s, train_loss=0.0232, val_loss=0.0338]Epoch 6:  68%|██████▊   | 19/28 [00:00<00:00, 89.70it/s, train_loss=0.0232, val_loss=0.0338]Epoch 6:  68%|██████▊   | 19/28 [00:00<00:00, 87.40it/s, train_loss=0.0274, val_loss=0.0338]Epoch 6:  71%|███████▏  | 20/28 [00:00<00:00, 89.63it/s, train_loss=0.0274, val_loss=0.0338]Epoch 6:  71%|███████▏  | 20/28 [00:00<00:00, 87.47it/s, train_loss=0.032, val_loss=0.0338] Epoch 6:  75%|███████▌  | 21/28 [00:00<00:00, 89.53it/s, train_loss=0.032, val_loss=0.0338]Epoch 6:  75%|███████▌  | 21/28 [00:00<00:00, 88.15it/s, train_loss=0.0128, val_loss=0.0338]Epoch 6:  79%|███████▊  | 22/28 [00:00<00:00, 90.14it/s, train_loss=0.0128, val_loss=0.0338]Epoch 6:  79%|███████▊  | 22/28 [00:00<00:00, 88.17it/s, train_loss=0.0211, val_loss=0.0338]Epoch 6:  82%|████████▏ | 23/28 [00:00<00:00, 90.23it/s, train_loss=0.0211, val_loss=0.0338]Epoch 6:  82%|████████▏ | 23/28 [00:00<00:00, 88.16it/s, train_loss=0.0238, val_loss=0.0338]Epoch 6:  86%|████████▌ | 24/28 [00:00<00:00, 90.13it/s, train_loss=0.0238, val_loss=0.0338]Epoch 6:  86%|████████▌ | 24/28 [00:00<00:00, 88.19it/s, train_loss=0.0288, val_loss=0.0338]Epoch 6:  89%|████████▉ | 25/28 [00:00<00:00, 89.96it/s, train_loss=0.0288, val_loss=0.0338]Epoch 6:  89%|████████▉ | 25/28 [00:00<00:00, 88.30it/s, train_loss=0.0304, val_loss=0.0338]Epoch 6:  93%|█████████▎| 26/28 [00:00<00:00, 90.01it/s, train_loss=0.0304, val_loss=0.0338]Epoch 6:  93%|█████████▎| 26/28 [00:00<00:00, 88.29it/s, train_loss=0.0196, val_loss=0.0338]Epoch 6:  96%|█████████▋| 27/28 [00:00<00:00, 90.03it/s, train_loss=0.0196, val_loss=0.0338]Epoch 6:  96%|█████████▋| 27/28 [00:00<00:00, 88.28it/s, train_loss=0.0203, val_loss=0.0338]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 89.89it/s, train_loss=0.0203, val_loss=0.0338]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 88.35it/s, train_loss=0.024, val_loss=0.0338] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 152.25it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 187.53it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 204.97it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 215.35it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 221.63it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 225.87it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 228.09it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 228.72it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 229.06it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 229.92it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 230.75it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 232.30it/s][A
                                                                         [AEpoch 6: 100%|██████████| 28/28 [00:00<00:00, 74.22it/s, train_loss=0.024, val_loss=0.0283]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 74.03it/s, train_loss=0.024, val_loss=0.0283]Epoch 6:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.024, val_loss=0.0283]         Epoch 7:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.024, val_loss=0.0283]Epoch 7:   4%|▎         | 1/28 [00:00<00:00, 140.32it/s, train_loss=0.024, val_loss=0.0283]Epoch 7:   4%|▎         | 1/28 [00:00<00:00, 78.58it/s, train_loss=0.0238, val_loss=0.0283]Epoch 7:   7%|▋         | 2/28 [00:00<00:00, 107.44it/s, train_loss=0.0238, val_loss=0.0283]Epoch 7:   7%|▋         | 2/28 [00:00<00:00, 82.77it/s, train_loss=0.023, val_loss=0.0283]  Epoch 7:  11%|█         | 3/28 [00:00<00:00, 95.70it/s, train_loss=0.023, val_loss=0.0283]Epoch 7:  11%|█         | 3/28 [00:00<00:00, 84.31it/s, train_loss=0.027, val_loss=0.0283]Epoch 7:  14%|█▍        | 4/28 [00:00<00:00, 96.27it/s, train_loss=0.027, val_loss=0.0283]Epoch 7:  14%|█▍        | 4/28 [00:00<00:00, 89.11it/s, train_loss=0.0243, val_loss=0.0283]Epoch 7:  18%|█▊        | 5/28 [00:00<00:00, 98.65it/s, train_loss=0.0243, val_loss=0.0283]Epoch 7:  18%|█▊        | 5/28 [00:00<00:00, 87.72it/s, train_loss=0.0267, val_loss=0.0283]Epoch 7:  21%|██▏       | 6/28 [00:00<00:00, 96.03it/s, train_loss=0.0267, val_loss=0.0283]Epoch 7:  21%|██▏       | 6/28 [00:00<00:00, 87.75it/s, train_loss=0.0252, val_loss=0.0283]Epoch 7:  25%|██▌       | 7/28 [00:00<00:00, 94.55it/s, train_loss=0.0252, val_loss=0.0283]Epoch 7:  25%|██▌       | 7/28 [00:00<00:00, 87.82it/s, train_loss=0.0229, val_loss=0.0283]Epoch 7:  29%|██▊       | 8/28 [00:00<00:00, 93.51it/s, train_loss=0.0229, val_loss=0.0283]Epoch 7:  29%|██▊       | 8/28 [00:00<00:00, 87.97it/s, train_loss=0.024, val_loss=0.0283] Epoch 7:  32%|███▏      | 9/28 [00:00<00:00, 93.02it/s, train_loss=0.024, val_loss=0.0283]Epoch 7:  32%|███▏      | 9/28 [00:00<00:00, 87.93it/s, train_loss=0.0233, val_loss=0.0283]Epoch 7:  36%|███▌      | 10/28 [00:00<00:00, 91.80it/s, train_loss=0.0233, val_loss=0.0283]Epoch 7:  36%|███▌      | 10/28 [00:00<00:00, 87.93it/s, train_loss=0.0262, val_loss=0.0283]Epoch 7:  39%|███▉      | 11/28 [00:00<00:00, 92.03it/s, train_loss=0.0262, val_loss=0.0283]Epoch 7:  39%|███▉      | 11/28 [00:00<00:00, 88.04it/s, train_loss=0.0125, val_loss=0.0283]Epoch 7:  43%|████▎     | 12/28 [00:00<00:00, 91.75it/s, train_loss=0.0125, val_loss=0.0283]Epoch 7:  43%|████▎     | 12/28 [00:00<00:00, 88.00it/s, train_loss=0.0171, val_loss=0.0283]Epoch 7:  46%|████▋     | 13/28 [00:00<00:00, 91.40it/s, train_loss=0.0171, val_loss=0.0283]Epoch 7:  46%|████▋     | 13/28 [00:00<00:00, 88.05it/s, train_loss=0.0288, val_loss=0.0283]Epoch 7:  50%|█████     | 14/28 [00:00<00:00, 91.34it/s, train_loss=0.0288, val_loss=0.0283]Epoch 7:  50%|█████     | 14/28 [00:00<00:00, 88.06it/s, train_loss=0.0141, val_loss=0.0283]Epoch 7:  54%|█████▎    | 15/28 [00:00<00:00, 91.15it/s, train_loss=0.0141, val_loss=0.0283]Epoch 7:  54%|█████▎    | 15/28 [00:00<00:00, 88.09it/s, train_loss=0.0195, val_loss=0.0283]Epoch 7:  57%|█████▋    | 16/28 [00:00<00:00, 90.71it/s, train_loss=0.0195, val_loss=0.0283]Epoch 7:  57%|█████▋    | 16/28 [00:00<00:00, 87.28it/s, train_loss=0.0146, val_loss=0.0283]Epoch 7:  61%|██████    | 17/28 [00:00<00:00, 89.94it/s, train_loss=0.0146, val_loss=0.0283]Epoch 7:  61%|██████    | 17/28 [00:00<00:00, 87.33it/s, train_loss=0.0199, val_loss=0.0283]Epoch 7:  64%|██████▍   | 18/28 [00:00<00:00, 89.86it/s, train_loss=0.0199, val_loss=0.0283]Epoch 7:  64%|██████▍   | 18/28 [00:00<00:00, 87.41it/s, train_loss=0.0149, val_loss=0.0283]Epoch 7:  68%|██████▊   | 19/28 [00:00<00:00, 89.77it/s, train_loss=0.0149, val_loss=0.0283]Epoch 7:  68%|██████▊   | 19/28 [00:00<00:00, 88.26it/s, train_loss=0.016, val_loss=0.0283] Epoch 7:  71%|███████▏  | 20/28 [00:00<00:00, 90.36it/s, train_loss=0.016, val_loss=0.0283]Epoch 7:  71%|███████▏  | 20/28 [00:00<00:00, 87.80it/s, train_loss=0.0119, val_loss=0.0283]Epoch 7:  75%|███████▌  | 21/28 [00:00<00:00, 89.94it/s, train_loss=0.0119, val_loss=0.0283]Epoch 7:  75%|███████▌  | 21/28 [00:00<00:00, 87.85it/s, train_loss=0.0124, val_loss=0.0283]Epoch 7:  79%|███████▊  | 22/28 [00:00<00:00, 89.87it/s, train_loss=0.0124, val_loss=0.0283]Epoch 7:  79%|███████▊  | 22/28 [00:00<00:00, 87.88it/s, train_loss=0.0238, val_loss=0.0283]Epoch 7:  82%|████████▏ | 23/28 [00:00<00:00, 89.82it/s, train_loss=0.0238, val_loss=0.0283]Epoch 7:  82%|████████▏ | 23/28 [00:00<00:00, 88.56it/s, train_loss=0.0211, val_loss=0.0283]Epoch 7:  86%|████████▌ | 24/28 [00:00<00:00, 90.31it/s, train_loss=0.0211, val_loss=0.0283]Epoch 7:  86%|████████▌ | 24/28 [00:00<00:00, 88.35it/s, train_loss=0.0151, val_loss=0.0283]Epoch 7:  89%|████████▉ | 25/28 [00:00<00:00, 90.24it/s, train_loss=0.0151, val_loss=0.0283]Epoch 7:  89%|████████▉ | 25/28 [00:00<00:00, 88.34it/s, train_loss=0.0194, val_loss=0.0283]Epoch 7:  93%|█████████▎| 26/28 [00:00<00:00, 90.17it/s, train_loss=0.0194, val_loss=0.0283]Epoch 7:  93%|█████████▎| 26/28 [00:00<00:00, 88.33it/s, train_loss=0.022, val_loss=0.0283] Epoch 7:  96%|█████████▋| 27/28 [00:00<00:00, 90.04it/s, train_loss=0.022, val_loss=0.0283]Epoch 7:  96%|█████████▋| 27/28 [00:00<00:00, 88.44it/s, train_loss=0.0166, val_loss=0.0283]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 90.04it/s, train_loss=0.0166, val_loss=0.0283]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 88.49it/s, train_loss=0.018, val_loss=0.0283] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 177.82it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 211.97it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 225.98it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 233.75it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 236.06it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 238.05it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 240.38it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 241.43it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 242.41it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 241.91it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 242.37it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 243.60it/s][A
                                                                         [AEpoch 7: 100%|██████████| 28/28 [00:00<00:00, 74.71it/s, train_loss=0.018, val_loss=0.0176]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 74.53it/s, train_loss=0.018, val_loss=0.0176]Epoch 7:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.018, val_loss=0.0176]         Epoch 8:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.018, val_loss=0.0176]Epoch 8:   4%|▎         | 1/28 [00:00<00:00, 146.73it/s, train_loss=0.018, val_loss=0.0176]Epoch 8:   4%|▎         | 1/28 [00:00<00:00, 73.23it/s, train_loss=0.0219, val_loss=0.0176]Epoch 8:   7%|▋         | 2/28 [00:00<00:00, 102.71it/s, train_loss=0.0219, val_loss=0.0176]Epoch 8:   7%|▋         | 2/28 [00:00<00:00, 80.03it/s, train_loss=0.0194, val_loss=0.0176] Epoch 8:  11%|█         | 3/28 [00:00<00:00, 96.95it/s, train_loss=0.0194, val_loss=0.0176]Epoch 8:  11%|█         | 3/28 [00:00<00:00, 82.18it/s, train_loss=0.0183, val_loss=0.0176]Epoch 8:  14%|█▍        | 4/28 [00:00<00:00, 94.31it/s, train_loss=0.0183, val_loss=0.0176]Epoch 8:  14%|█▍        | 4/28 [00:00<00:00, 83.53it/s, train_loss=0.0193, val_loss=0.0176]Epoch 8:  18%|█▊        | 5/28 [00:00<00:00, 92.85it/s, train_loss=0.0193, val_loss=0.0176]Epoch 8:  18%|█▊        | 5/28 [00:00<00:00, 84.49it/s, train_loss=0.0127, val_loss=0.0176]Epoch 8:  21%|██▏       | 6/28 [00:00<00:00, 91.84it/s, train_loss=0.0127, val_loss=0.0176]Epoch 8:  21%|██▏       | 6/28 [00:00<00:00, 85.20it/s, train_loss=0.0113, val_loss=0.0176]Epoch 8:  25%|██▌       | 7/28 [00:00<00:00, 91.49it/s, train_loss=0.0113, val_loss=0.0176]Epoch 8:  25%|██▌       | 7/28 [00:00<00:00, 85.98it/s, train_loss=0.0126, val_loss=0.0176]Epoch 8:  29%|██▊       | 8/28 [00:00<00:00, 92.15it/s, train_loss=0.0126, val_loss=0.0176]Epoch 8:  29%|██▊       | 8/28 [00:00<00:00, 86.28it/s, train_loss=0.0162, val_loss=0.0176]Epoch 8:  32%|███▏      | 9/28 [00:00<00:00, 91.58it/s, train_loss=0.0162, val_loss=0.0176]Epoch 8:  32%|███▏      | 9/28 [00:00<00:00, 86.52it/s, train_loss=0.0116, val_loss=0.0176]Epoch 8:  36%|███▌      | 10/28 [00:00<00:00, 91.47it/s, train_loss=0.0116, val_loss=0.0176]Epoch 8:  36%|███▌      | 10/28 [00:00<00:00, 86.71it/s, train_loss=0.0132, val_loss=0.0176]Epoch 8:  39%|███▉      | 11/28 [00:00<00:00, 90.97it/s, train_loss=0.0132, val_loss=0.0176]Epoch 8:  39%|███▉      | 11/28 [00:00<00:00, 86.10it/s, train_loss=0.0188, val_loss=0.0176]Epoch 8:  43%|████▎     | 12/28 [00:00<00:00, 90.00it/s, train_loss=0.0188, val_loss=0.0176]Epoch 8:  43%|████▎     | 12/28 [00:00<00:00, 86.28it/s, train_loss=0.0146, val_loss=0.0176]Epoch 8:  46%|████▋     | 13/28 [00:00<00:00, 89.88it/s, train_loss=0.0146, val_loss=0.0176]Epoch 8:  46%|████▋     | 13/28 [00:00<00:00, 86.44it/s, train_loss=0.0147, val_loss=0.0176]Epoch 8:  50%|█████     | 14/28 [00:00<00:00, 89.77it/s, train_loss=0.0147, val_loss=0.0176]Epoch 8:  50%|█████     | 14/28 [00:00<00:00, 86.60it/s, train_loss=0.0136, val_loss=0.0176]Epoch 8:  54%|█████▎    | 15/28 [00:00<00:00, 89.28it/s, train_loss=0.0136, val_loss=0.0176]Epoch 8:  54%|█████▎    | 15/28 [00:00<00:00, 86.68it/s, train_loss=0.0161, val_loss=0.0176]Epoch 8:  57%|█████▋    | 16/28 [00:00<00:00, 89.08it/s, train_loss=0.0161, val_loss=0.0176]Epoch 8:  57%|█████▋    | 16/28 [00:00<00:00, 85.72it/s, train_loss=0.0205, val_loss=0.0176]Epoch 8:  61%|██████    | 17/28 [00:00<00:00, 87.96it/s, train_loss=0.0205, val_loss=0.0176]Epoch 8:  61%|██████    | 17/28 [00:00<00:00, 85.86it/s, train_loss=0.0143, val_loss=0.0176]Epoch 8:  64%|██████▍   | 18/28 [00:00<00:00, 87.35it/s, train_loss=0.0143, val_loss=0.0176]Epoch 8:  64%|██████▍   | 18/28 [00:00<00:00, 85.20it/s, train_loss=0.0155, val_loss=0.0176]Epoch 8:  68%|██████▊   | 19/28 [00:00<00:00, 86.82it/s, train_loss=0.0155, val_loss=0.0176]Epoch 8:  68%|██████▊   | 19/28 [00:00<00:00, 84.46it/s, train_loss=0.0173, val_loss=0.0176]Epoch 8:  71%|███████▏  | 20/28 [00:00<00:00, 85.99it/s, train_loss=0.0173, val_loss=0.0176]Epoch 8:  71%|███████▏  | 20/28 [00:00<00:00, 83.99it/s, train_loss=0.0199, val_loss=0.0176]Epoch 8:  75%|███████▌  | 21/28 [00:00<00:00, 85.58it/s, train_loss=0.0199, val_loss=0.0176]Epoch 8:  75%|███████▌  | 21/28 [00:00<00:00, 83.80it/s, train_loss=0.0227, val_loss=0.0176]Epoch 8:  79%|███████▊  | 22/28 [00:00<00:00, 85.41it/s, train_loss=0.0227, val_loss=0.0176]Epoch 8:  79%|███████▊  | 22/28 [00:00<00:00, 84.03it/s, train_loss=0.0124, val_loss=0.0176]Epoch 8:  82%|████████▏ | 23/28 [00:00<00:00, 85.36it/s, train_loss=0.0124, val_loss=0.0176]Epoch 8:  82%|████████▏ | 23/28 [00:00<00:00, 83.51it/s, train_loss=0.0126, val_loss=0.0176]Epoch 8:  86%|████████▌ | 24/28 [00:00<00:00, 84.59it/s, train_loss=0.0126, val_loss=0.0176]Epoch 8:  86%|████████▌ | 24/28 [00:00<00:00, 83.59it/s, train_loss=0.0184, val_loss=0.0176]Epoch 8:  89%|████████▉ | 25/28 [00:00<00:00, 85.06it/s, train_loss=0.0184, val_loss=0.0176]Epoch 8:  89%|████████▉ | 25/28 [00:00<00:00, 83.78it/s, train_loss=0.0164, val_loss=0.0176]Epoch 8:  93%|█████████▎| 26/28 [00:00<00:00, 85.22it/s, train_loss=0.0164, val_loss=0.0176]Epoch 8:  93%|█████████▎| 26/28 [00:00<00:00, 83.95it/s, train_loss=0.018, val_loss=0.0176] Epoch 8:  96%|█████████▋| 27/28 [00:00<00:00, 85.35it/s, train_loss=0.018, val_loss=0.0176]Epoch 8:  96%|█████████▋| 27/28 [00:00<00:00, 84.13it/s, train_loss=0.0112, val_loss=0.0176]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 85.38it/s, train_loss=0.0112, val_loss=0.0176]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 84.39it/s, train_loss=0.0178, val_loss=0.0176]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 195.30it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 215.26it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 223.03it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 226.73it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 228.56it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 227.64it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 228.02it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 227.66it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 227.33it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 226.96it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 226.73it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 227.06it/s][A
                                                                         [AEpoch 8: 100%|██████████| 28/28 [00:00<00:00, 71.35it/s, train_loss=0.0178, val_loss=0.0146]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 71.18it/s, train_loss=0.0178, val_loss=0.0146]Epoch 8:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0178, val_loss=0.0146]         Epoch 9:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0178, val_loss=0.0146]Epoch 9:   4%|▎         | 1/28 [00:00<00:00, 131.66it/s, train_loss=0.0178, val_loss=0.0146]Epoch 9:   4%|▎         | 1/28 [00:00<00:00, 80.88it/s, train_loss=0.0137, val_loss=0.0146] Epoch 9:   7%|▋         | 2/28 [00:00<00:00, 106.18it/s, train_loss=0.0137, val_loss=0.0146]Epoch 9:   7%|▋         | 2/28 [00:00<00:00, 84.18it/s, train_loss=0.0137, val_loss=0.0146] Epoch 9:  11%|█         | 3/28 [00:00<00:00, 100.91it/s, train_loss=0.0137, val_loss=0.0146]Epoch 9:  11%|█         | 3/28 [00:00<00:00, 85.25it/s, train_loss=0.0216, val_loss=0.0146] Epoch 9:  14%|█▍        | 4/28 [00:00<00:00, 97.52it/s, train_loss=0.0216, val_loss=0.0146]Epoch 9:  14%|█▍        | 4/28 [00:00<00:00, 89.61it/s, train_loss=0.00962, val_loss=0.0146]Epoch 9:  18%|█▊        | 5/28 [00:00<00:00, 97.74it/s, train_loss=0.00962, val_loss=0.0146]Epoch 9:  18%|█▊        | 5/28 [00:00<00:00, 88.82it/s, train_loss=0.0168, val_loss=0.0146] Epoch 9:  21%|██▏       | 6/28 [00:00<00:00, 96.59it/s, train_loss=0.0168, val_loss=0.0146]Epoch 9:  21%|██▏       | 6/28 [00:00<00:00, 88.81it/s, train_loss=0.014, val_loss=0.0146] Epoch 9:  25%|██▌       | 7/28 [00:00<00:00, 95.45it/s, train_loss=0.014, val_loss=0.0146]Epoch 9:  25%|██▌       | 7/28 [00:00<00:00, 88.82it/s, train_loss=0.0129, val_loss=0.0146]Epoch 9:  29%|██▊       | 8/28 [00:00<00:00, 94.70it/s, train_loss=0.0129, val_loss=0.0146]Epoch 9:  29%|██▊       | 8/28 [00:00<00:00, 88.78it/s, train_loss=0.0156, val_loss=0.0146]Epoch 9:  32%|███▏      | 9/28 [00:00<00:00, 93.17it/s, train_loss=0.0156, val_loss=0.0146]Epoch 9:  32%|███▏      | 9/28 [00:00<00:00, 88.75it/s, train_loss=0.014, val_loss=0.0146] Epoch 9:  36%|███▌      | 10/28 [00:00<00:00, 93.33it/s, train_loss=0.014, val_loss=0.0146]Epoch 9:  36%|███▌      | 10/28 [00:00<00:00, 88.73it/s, train_loss=0.0106, val_loss=0.0146]Epoch 9:  39%|███▉      | 11/28 [00:00<00:00, 92.77it/s, train_loss=0.0106, val_loss=0.0146]Epoch 9:  39%|███▉      | 11/28 [00:00<00:00, 88.74it/s, train_loss=0.0142, val_loss=0.0146]Epoch 9:  43%|████▎     | 12/28 [00:00<00:00, 92.25it/s, train_loss=0.0142, val_loss=0.0146]Epoch 9:  43%|████▎     | 12/28 [00:00<00:00, 88.78it/s, train_loss=0.0102, val_loss=0.0146]Epoch 9:  46%|████▋     | 13/28 [00:00<00:00, 92.27it/s, train_loss=0.0102, val_loss=0.0146]Epoch 9:  46%|████▋     | 13/28 [00:00<00:00, 88.74it/s, train_loss=0.0181, val_loss=0.0146]Epoch 9:  50%|█████     | 14/28 [00:00<00:00, 92.16it/s, train_loss=0.0181, val_loss=0.0146]Epoch 9:  50%|█████     | 14/28 [00:00<00:00, 88.72it/s, train_loss=0.00948, val_loss=0.0146]Epoch 9:  54%|█████▎    | 15/28 [00:00<00:00, 91.87it/s, train_loss=0.00948, val_loss=0.0146]Epoch 9:  54%|█████▎    | 15/28 [00:00<00:00, 88.73it/s, train_loss=0.0125, val_loss=0.0146] Epoch 9:  57%|█████▋    | 16/28 [00:00<00:00, 91.19it/s, train_loss=0.0125, val_loss=0.0146]Epoch 9:  57%|█████▋    | 16/28 [00:00<00:00, 87.77it/s, train_loss=0.0119, val_loss=0.0146]Epoch 9:  61%|██████    | 17/28 [00:00<00:00, 90.44it/s, train_loss=0.0119, val_loss=0.0146]Epoch 9:  61%|██████    | 17/28 [00:00<00:00, 87.78it/s, train_loss=0.0176, val_loss=0.0146]Epoch 9:  64%|██████▍   | 18/28 [00:00<00:00, 90.36it/s, train_loss=0.0176, val_loss=0.0146]Epoch 9:  64%|██████▍   | 18/28 [00:00<00:00, 87.82it/s, train_loss=0.0112, val_loss=0.0146]Epoch 9:  68%|██████▊   | 19/28 [00:00<00:00, 90.22it/s, train_loss=0.0112, val_loss=0.0146]Epoch 9:  68%|██████▊   | 19/28 [00:00<00:00, 87.84it/s, train_loss=0.0188, val_loss=0.0146]Epoch 9:  71%|███████▏  | 20/28 [00:00<00:00, 89.81it/s, train_loss=0.0188, val_loss=0.0146]Epoch 9:  71%|███████▏  | 20/28 [00:00<00:00, 87.89it/s, train_loss=0.012, val_loss=0.0146] Epoch 9:  75%|███████▌  | 21/28 [00:00<00:00, 90.08it/s, train_loss=0.012, val_loss=0.0146]Epoch 9:  75%|███████▌  | 21/28 [00:00<00:00, 87.88it/s, train_loss=0.0162, val_loss=0.0146]Epoch 9:  79%|███████▊  | 22/28 [00:00<00:00, 89.95it/s, train_loss=0.0162, val_loss=0.0146]Epoch 9:  79%|███████▊  | 22/28 [00:00<00:00, 87.91it/s, train_loss=0.0158, val_loss=0.0146]Epoch 9:  82%|████████▏ | 23/28 [00:00<00:00, 89.73it/s, train_loss=0.0158, val_loss=0.0146]Epoch 9:  82%|████████▏ | 23/28 [00:00<00:00, 87.89it/s, train_loss=0.0124, val_loss=0.0146]Epoch 9:  86%|████████▌ | 24/28 [00:00<00:00, 89.30it/s, train_loss=0.0124, val_loss=0.0146]Epoch 9:  86%|████████▌ | 24/28 [00:00<00:00, 87.23it/s, train_loss=0.0145, val_loss=0.0146]Epoch 9:  89%|████████▉ | 25/28 [00:00<00:00, 88.92it/s, train_loss=0.0145, val_loss=0.0146]Epoch 9:  89%|████████▉ | 25/28 [00:00<00:00, 87.26it/s, train_loss=0.00908, val_loss=0.0146]Epoch 9:  93%|█████████▎| 26/28 [00:00<00:00, 88.92it/s, train_loss=0.00908, val_loss=0.0146]Epoch 9:  93%|█████████▎| 26/28 [00:00<00:00, 87.87it/s, train_loss=0.0164, val_loss=0.0146] Epoch 9:  96%|█████████▋| 27/28 [00:00<00:00, 89.18it/s, train_loss=0.0164, val_loss=0.0146]Epoch 9:  96%|█████████▋| 27/28 [00:00<00:00, 87.77it/s, train_loss=0.0128, val_loss=0.0146]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 89.23it/s, train_loss=0.0128, val_loss=0.0146]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 87.85it/s, train_loss=0.0156, val_loss=0.0146]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 145.68it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 189.61it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 212.03it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 226.50it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 236.64it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 243.86it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 249.88it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 254.42it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 257.27it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 259.28it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 260.71it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 262.53it/s][A
                                                                         [AEpoch 9: 100%|██████████| 28/28 [00:00<00:00, 74.86it/s, train_loss=0.0156, val_loss=0.0128]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 74.70it/s, train_loss=0.0156, val_loss=0.0128]Epoch 9:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0156, val_loss=0.0128]         Epoch 10:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0156, val_loss=0.0128]Epoch 10:   4%|▎         | 1/28 [00:00<00:00, 146.21it/s, train_loss=0.0156, val_loss=0.0128]Epoch 10:   4%|▎         | 1/28 [00:00<00:00, 73.87it/s, train_loss=0.0135, val_loss=0.0128] Epoch 10:   7%|▋         | 2/28 [00:00<00:00, 104.14it/s, train_loss=0.0135, val_loss=0.0128]Epoch 10:   7%|▋         | 2/28 [00:00<00:00, 81.56it/s, train_loss=0.0119, val_loss=0.0128] Epoch 10:  11%|█         | 3/28 [00:00<00:00, 96.83it/s, train_loss=0.0119, val_loss=0.0128]Epoch 10:  11%|█         | 3/28 [00:00<00:00, 81.26it/s, train_loss=0.0091, val_loss=0.0128]Epoch 10:  14%|█▍        | 4/28 [00:00<00:00, 93.62it/s, train_loss=0.0091, val_loss=0.0128]Epoch 10:  14%|█▍        | 4/28 [00:00<00:00, 83.08it/s, train_loss=0.0123, val_loss=0.0128]Epoch 10:  18%|█▊        | 5/28 [00:00<00:00, 92.78it/s, train_loss=0.0123, val_loss=0.0128]Epoch 10:  18%|█▊        | 5/28 [00:00<00:00, 84.26it/s, train_loss=0.0134, val_loss=0.0128]Epoch 10:  21%|██▏       | 6/28 [00:00<00:00, 92.25it/s, train_loss=0.0134, val_loss=0.0128]Epoch 10:  21%|██▏       | 6/28 [00:00<00:00, 85.43it/s, train_loss=0.0148, val_loss=0.0128]Epoch 10:  25%|██▌       | 7/28 [00:00<00:00, 91.16it/s, train_loss=0.0148, val_loss=0.0128]Epoch 10:  25%|██▌       | 7/28 [00:00<00:00, 85.89it/s, train_loss=0.0108, val_loss=0.0128]Epoch 10:  29%|██▊       | 8/28 [00:00<00:00, 91.61it/s, train_loss=0.0108, val_loss=0.0128]Epoch 10:  29%|██▊       | 8/28 [00:00<00:00, 86.27it/s, train_loss=0.0109, val_loss=0.0128]Epoch 10:  32%|███▏      | 9/28 [00:00<00:00, 91.46it/s, train_loss=0.0109, val_loss=0.0128]Epoch 10:  32%|███▏      | 9/28 [00:00<00:00, 86.59it/s, train_loss=0.0131, val_loss=0.0128]Epoch 10:  36%|███▌      | 10/28 [00:00<00:00, 90.80it/s, train_loss=0.0131, val_loss=0.0128]Epoch 10:  36%|███▌      | 10/28 [00:00<00:00, 86.79it/s, train_loss=0.0176, val_loss=0.0128]Epoch 10:  39%|███▉      | 11/28 [00:00<00:00, 90.74it/s, train_loss=0.0176, val_loss=0.0128]Epoch 10:  39%|███▉      | 11/28 [00:00<00:00, 87.04it/s, train_loss=0.00996, val_loss=0.0128]Epoch 10:  43%|████▎     | 12/28 [00:00<00:00, 90.72it/s, train_loss=0.00996, val_loss=0.0128]Epoch 10:  43%|████▎     | 12/28 [00:00<00:00, 87.19it/s, train_loss=0.0134, val_loss=0.0128] Epoch 10:  46%|████▋     | 13/28 [00:00<00:00, 90.66it/s, train_loss=0.0134, val_loss=0.0128]Epoch 10:  46%|████▋     | 13/28 [00:00<00:00, 87.37it/s, train_loss=0.00996, val_loss=0.0128]Epoch 10:  50%|█████     | 14/28 [00:00<00:00, 90.02it/s, train_loss=0.00996, val_loss=0.0128]Epoch 10:  50%|█████     | 14/28 [00:00<00:00, 86.66it/s, train_loss=0.0117, val_loss=0.0128] Epoch 10:  54%|█████▎    | 15/28 [00:00<00:00, 89.76it/s, train_loss=0.0117, val_loss=0.0128]Epoch 10:  54%|█████▎    | 15/28 [00:00<00:00, 86.80it/s, train_loss=0.0106, val_loss=0.0128]Epoch 10:  57%|█████▋    | 16/28 [00:00<00:00, 89.75it/s, train_loss=0.0106, val_loss=0.0128]Epoch 10:  57%|█████▋    | 16/28 [00:00<00:00, 86.95it/s, train_loss=0.0134, val_loss=0.0128]Epoch 10:  61%|██████    | 17/28 [00:00<00:00, 89.74it/s, train_loss=0.0134, val_loss=0.0128]Epoch 10:  61%|██████    | 17/28 [00:00<00:00, 87.17it/s, train_loss=0.0113, val_loss=0.0128]Epoch 10:  64%|██████▍   | 18/28 [00:00<00:00, 89.34it/s, train_loss=0.0113, val_loss=0.0128]Epoch 10:  64%|██████▍   | 18/28 [00:00<00:00, 87.26it/s, train_loss=0.0103, val_loss=0.0128]Epoch 10:  68%|██████▊   | 19/28 [00:00<00:00, 89.59it/s, train_loss=0.0103, val_loss=0.0128]Epoch 10:  68%|██████▊   | 19/28 [00:00<00:00, 87.31it/s, train_loss=0.0113, val_loss=0.0128]Epoch 10:  71%|███████▏  | 20/28 [00:00<00:00, 89.59it/s, train_loss=0.0113, val_loss=0.0128]Epoch 10:  71%|███████▏  | 20/28 [00:00<00:00, 87.40it/s, train_loss=0.0093, val_loss=0.0128]Epoch 10:  75%|███████▌  | 21/28 [00:00<00:00, 89.35it/s, train_loss=0.0093, val_loss=0.0128]Epoch 10:  75%|███████▌  | 21/28 [00:00<00:00, 87.47it/s, train_loss=0.0136, val_loss=0.0128]Epoch 10:  79%|███████▊  | 22/28 [00:00<00:00, 89.42it/s, train_loss=0.0136, val_loss=0.0128]Epoch 10:  79%|███████▊  | 22/28 [00:00<00:00, 87.54it/s, train_loss=0.0143, val_loss=0.0128]Epoch 10:  82%|████████▏ | 23/28 [00:00<00:00, 89.52it/s, train_loss=0.0143, val_loss=0.0128]Epoch 10:  82%|████████▏ | 23/28 [00:00<00:00, 87.57it/s, train_loss=0.0138, val_loss=0.0128]Epoch 10:  86%|████████▌ | 24/28 [00:00<00:00, 89.46it/s, train_loss=0.0138, val_loss=0.0128]Epoch 10:  86%|████████▌ | 24/28 [00:00<00:00, 87.74it/s, train_loss=0.0102, val_loss=0.0128]Epoch 10:  89%|████████▉ | 25/28 [00:00<00:00, 89.01it/s, train_loss=0.0102, val_loss=0.0128]Epoch 10:  89%|████████▉ | 25/28 [00:00<00:00, 87.27it/s, train_loss=0.0108, val_loss=0.0128]Epoch 10:  93%|█████████▎| 26/28 [00:00<00:00, 88.94it/s, train_loss=0.0108, val_loss=0.0128]Epoch 10:  93%|█████████▎| 26/28 [00:00<00:00, 87.35it/s, train_loss=0.0147, val_loss=0.0128]Epoch 10:  96%|█████████▋| 27/28 [00:00<00:00, 88.99it/s, train_loss=0.0147, val_loss=0.0128]Epoch 10:  96%|█████████▋| 27/28 [00:00<00:00, 87.42it/s, train_loss=0.0133, val_loss=0.0128]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 89.02it/s, train_loss=0.0133, val_loss=0.0128]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 87.59it/s, train_loss=0.0152, val_loss=0.0128]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 142.90it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 172.14it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 184.93it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 192.65it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 194.86it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 196.91it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 199.12it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 205.57it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 213.28it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 219.42it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 224.69it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 230.20it/s][A
                                                                         [AEpoch 10: 100%|██████████| 28/28 [00:00<00:00, 73.79it/s, train_loss=0.0152, val_loss=0.0111]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 73.64it/s, train_loss=0.0152, val_loss=0.0111]Epoch 10:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0152, val_loss=0.0111]         Epoch 11:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0152, val_loss=0.0111]Epoch 11:   4%|▎         | 1/28 [00:00<00:00, 131.11it/s, train_loss=0.0152, val_loss=0.0111]Epoch 11:   4%|▎         | 1/28 [00:00<00:00, 77.96it/s, train_loss=0.0124, val_loss=0.0111] Epoch 11:   7%|▋         | 2/28 [00:00<00:00, 107.36it/s, train_loss=0.0124, val_loss=0.0111]Epoch 11:   7%|▋         | 2/28 [00:00<00:00, 81.73it/s, train_loss=0.0122, val_loss=0.0111] Epoch 11:  11%|█         | 3/28 [00:00<00:00, 99.11it/s, train_loss=0.0122, val_loss=0.0111]Epoch 11:  11%|█         | 3/28 [00:00<00:00, 83.11it/s, train_loss=0.0177, val_loss=0.0111]Epoch 11:  14%|█▍        | 4/28 [00:00<00:00, 95.66it/s, train_loss=0.0177, val_loss=0.0111]Epoch 11:  14%|█▍        | 4/28 [00:00<00:00, 86.17it/s, train_loss=0.0121, val_loss=0.0111]Epoch 11:  18%|█▊        | 5/28 [00:00<00:00, 94.71it/s, train_loss=0.0121, val_loss=0.0111]Epoch 11:  18%|█▊        | 5/28 [00:00<00:00, 84.93it/s, train_loss=0.0108, val_loss=0.0111]Epoch 11:  21%|██▏       | 6/28 [00:00<00:00, 93.01it/s, train_loss=0.0108, val_loss=0.0111]Epoch 11:  21%|██▏       | 6/28 [00:00<00:00, 85.21it/s, train_loss=0.0167, val_loss=0.0111]Epoch 11:  25%|██▌       | 7/28 [00:00<00:00, 91.80it/s, train_loss=0.0167, val_loss=0.0111]Epoch 11:  25%|██▌       | 7/28 [00:00<00:00, 85.48it/s, train_loss=0.0125, val_loss=0.0111]Epoch 11:  29%|██▊       | 8/28 [00:00<00:00, 91.29it/s, train_loss=0.0125, val_loss=0.0111]Epoch 11:  29%|██▊       | 8/28 [00:00<00:00, 86.83it/s, train_loss=0.0125, val_loss=0.0111]Epoch 11:  32%|███▏      | 9/28 [00:00<00:00, 91.17it/s, train_loss=0.0125, val_loss=0.0111]Epoch 11:  32%|███▏      | 9/28 [00:00<00:00, 86.07it/s, train_loss=0.00819, val_loss=0.0111]Epoch 11:  36%|███▌      | 10/28 [00:00<00:00, 90.61it/s, train_loss=0.00819, val_loss=0.0111]Epoch 11:  36%|███▌      | 10/28 [00:00<00:00, 86.14it/s, train_loss=0.0145, val_loss=0.0111] Epoch 11:  39%|███▉      | 11/28 [00:00<00:00, 90.18it/s, train_loss=0.0145, val_loss=0.0111]Epoch 11:  39%|███▉      | 11/28 [00:00<00:00, 86.25it/s, train_loss=0.0145, val_loss=0.0111]Epoch 11:  43%|████▎     | 12/28 [00:00<00:00, 90.09it/s, train_loss=0.0145, val_loss=0.0111]Epoch 11:  43%|████▎     | 12/28 [00:00<00:00, 87.27it/s, train_loss=0.011, val_loss=0.0111] Epoch 11:  46%|████▋     | 13/28 [00:00<00:00, 90.34it/s, train_loss=0.011, val_loss=0.0111]Epoch 11:  46%|████▋     | 13/28 [00:00<00:00, 86.71it/s, train_loss=0.0151, val_loss=0.0111]Epoch 11:  50%|█████     | 14/28 [00:00<00:00, 89.96it/s, train_loss=0.0151, val_loss=0.0111]Epoch 11:  50%|█████     | 14/28 [00:00<00:00, 86.73it/s, train_loss=0.0078, val_loss=0.0111]Epoch 11:  54%|█████▎    | 15/28 [00:00<00:00, 89.70it/s, train_loss=0.0078, val_loss=0.0111]Epoch 11:  54%|█████▎    | 15/28 [00:00<00:00, 86.77it/s, train_loss=0.0103, val_loss=0.0111]Epoch 11:  57%|█████▋    | 16/28 [00:00<00:00, 89.50it/s, train_loss=0.0103, val_loss=0.0111]Epoch 11:  57%|█████▋    | 16/28 [00:00<00:00, 87.57it/s, train_loss=0.00843, val_loss=0.0111]Epoch 11:  61%|██████    | 17/28 [00:00<00:00, 89.98it/s, train_loss=0.00843, val_loss=0.0111]Epoch 11:  61%|██████    | 17/28 [00:00<00:00, 87.34it/s, train_loss=0.0103, val_loss=0.0111] Epoch 11:  64%|██████▍   | 18/28 [00:00<00:00, 89.91it/s, train_loss=0.0103, val_loss=0.0111]Epoch 11:  64%|██████▍   | 18/28 [00:00<00:00, 87.28it/s, train_loss=0.00882, val_loss=0.0111]Epoch 11:  68%|██████▊   | 19/28 [00:00<00:00, 89.78it/s, train_loss=0.00882, val_loss=0.0111]Epoch 11:  68%|██████▊   | 19/28 [00:00<00:00, 87.27it/s, train_loss=0.00902, val_loss=0.0111]Epoch 11:  71%|███████▏  | 20/28 [00:00<00:00, 89.61it/s, train_loss=0.00902, val_loss=0.0111]Epoch 11:  71%|███████▏  | 20/28 [00:00<00:00, 87.82it/s, train_loss=0.0107, val_loss=0.0111] Epoch 11:  75%|███████▌  | 21/28 [00:00<00:00, 89.72it/s, train_loss=0.0107, val_loss=0.0111]Epoch 11:  75%|███████▌  | 21/28 [00:00<00:00, 87.47it/s, train_loss=0.00877, val_loss=0.0111]Epoch 11:  79%|███████▊  | 22/28 [00:00<00:00, 89.51it/s, train_loss=0.00877, val_loss=0.0111]Epoch 11:  79%|███████▊  | 22/28 [00:00<00:00, 87.45it/s, train_loss=0.00935, val_loss=0.0111]Epoch 11:  82%|████████▏ | 23/28 [00:00<00:00, 89.41it/s, train_loss=0.00935, val_loss=0.0111]Epoch 11:  82%|████████▏ | 23/28 [00:00<00:00, 87.45it/s, train_loss=0.0112, val_loss=0.0111] Epoch 11:  86%|████████▌ | 24/28 [00:00<00:00, 89.34it/s, train_loss=0.0112, val_loss=0.0111]Epoch 11:  86%|████████▌ | 24/28 [00:00<00:00, 87.99it/s, train_loss=0.0108, val_loss=0.0111]Epoch 11:  89%|████████▉ | 25/28 [00:00<00:00, 89.52it/s, train_loss=0.0108, val_loss=0.0111]Epoch 11:  89%|████████▉ | 25/28 [00:00<00:00, 87.69it/s, train_loss=0.00846, val_loss=0.0111]Epoch 11:  93%|█████████▎| 26/28 [00:00<00:00, 89.40it/s, train_loss=0.00846, val_loss=0.0111]Epoch 11:  93%|█████████▎| 26/28 [00:00<00:00, 87.69it/s, train_loss=0.0132, val_loss=0.0111] Epoch 11:  96%|█████████▋| 27/28 [00:00<00:00, 89.36it/s, train_loss=0.0132, val_loss=0.0111]Epoch 11:  96%|█████████▋| 27/28 [00:00<00:00, 87.67it/s, train_loss=0.00987, val_loss=0.0111]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 89.25it/s, train_loss=0.00987, val_loss=0.0111]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 88.21it/s, train_loss=0.0114, val_loss=0.0111] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 145.92it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 177.74it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 192.09it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 200.18it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 205.13it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 208.13it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 208.45it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 208.47it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 208.71it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 210.27it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 211.27it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 212.41it/s][A
                                                                         [AEpoch 11: 100%|██████████| 28/28 [00:00<00:00, 73.17it/s, train_loss=0.0114, val_loss=0.0105]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 73.03it/s, train_loss=0.0114, val_loss=0.0105]Epoch 11:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0114, val_loss=0.0105]         Epoch 12:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0114, val_loss=0.0105]Epoch 12:   4%|▎         | 1/28 [00:00<00:00, 138.95it/s, train_loss=0.0114, val_loss=0.0105]Epoch 12:   4%|▎         | 1/28 [00:00<00:00, 78.83it/s, train_loss=0.00795, val_loss=0.0105]Epoch 12:   7%|▋         | 2/28 [00:00<00:00, 105.77it/s, train_loss=0.00795, val_loss=0.0105]Epoch 12:   7%|▋         | 2/28 [00:00<00:00, 82.35it/s, train_loss=0.0116, val_loss=0.0105]  Epoch 12:  11%|█         | 3/28 [00:00<00:00, 98.16it/s, train_loss=0.0116, val_loss=0.0105]Epoch 12:  11%|█         | 3/28 [00:00<00:00, 83.59it/s, train_loss=0.0129, val_loss=0.0105]Epoch 12:  14%|█▍        | 4/28 [00:00<00:00, 94.95it/s, train_loss=0.0129, val_loss=0.0105]Epoch 12:  14%|█▍        | 4/28 [00:00<00:00, 86.99it/s, train_loss=0.0126, val_loss=0.0105]Epoch 12:  18%|█▊        | 5/28 [00:00<00:00, 94.89it/s, train_loss=0.0126, val_loss=0.0105]Epoch 12:  18%|█▊        | 5/28 [00:00<00:00, 85.87it/s, train_loss=0.00983, val_loss=0.0105]Epoch 12:  21%|██▏       | 6/28 [00:00<00:00, 92.79it/s, train_loss=0.00983, val_loss=0.0105]Epoch 12:  21%|██▏       | 6/28 [00:00<00:00, 86.16it/s, train_loss=0.00936, val_loss=0.0105]Epoch 12:  25%|██▌       | 7/28 [00:00<00:00, 92.17it/s, train_loss=0.00936, val_loss=0.0105]Epoch 12:  25%|██▌       | 7/28 [00:00<00:00, 86.42it/s, train_loss=0.00975, val_loss=0.0105]Epoch 12:  29%|██▊       | 8/28 [00:00<00:00, 91.57it/s, train_loss=0.00975, val_loss=0.0105]Epoch 12:  29%|██▊       | 8/28 [00:00<00:00, 88.21it/s, train_loss=0.0127, val_loss=0.0105] Epoch 12:  32%|███▏      | 9/28 [00:00<00:00, 92.32it/s, train_loss=0.0127, val_loss=0.0105]Epoch 12:  32%|███▏      | 9/28 [00:00<00:00, 87.22it/s, train_loss=0.0123, val_loss=0.0105]Epoch 12:  36%|███▌      | 10/28 [00:00<00:00, 91.25it/s, train_loss=0.0123, val_loss=0.0105]Epoch 12:  36%|███▌      | 10/28 [00:00<00:00, 87.23it/s, train_loss=0.00808, val_loss=0.0105]Epoch 12:  39%|███▉      | 11/28 [00:00<00:00, 89.23it/s, train_loss=0.00808, val_loss=0.0105]Epoch 12:  39%|███▉      | 11/28 [00:00<00:00, 85.87it/s, train_loss=0.00945, val_loss=0.0105]Epoch 12:  43%|████▎     | 12/28 [00:00<00:00, 89.11it/s, train_loss=0.00945, val_loss=0.0105]Epoch 12:  43%|████▎     | 12/28 [00:00<00:00, 87.05it/s, train_loss=0.0104, val_loss=0.0105] Epoch 12:  46%|████▋     | 13/28 [00:00<00:00, 89.45it/s, train_loss=0.0104, val_loss=0.0105]Epoch 12:  46%|████▋     | 13/28 [00:00<00:00, 85.67it/s, train_loss=0.0122, val_loss=0.0105]Epoch 12:  50%|█████     | 14/28 [00:00<00:00, 88.42it/s, train_loss=0.0122, val_loss=0.0105]Epoch 12:  50%|█████     | 14/28 [00:00<00:00, 85.78it/s, train_loss=0.0115, val_loss=0.0105]Epoch 12:  54%|█████▎    | 15/28 [00:00<00:00, 88.38it/s, train_loss=0.0115, val_loss=0.0105]Epoch 12:  54%|█████▎    | 15/28 [00:00<00:00, 85.88it/s, train_loss=0.0109, val_loss=0.0105]Epoch 12:  57%|█████▋    | 16/28 [00:00<00:00, 88.34it/s, train_loss=0.0109, val_loss=0.0105]Epoch 12:  57%|█████▋    | 16/28 [00:00<00:00, 86.12it/s, train_loss=0.0116, val_loss=0.0105]Epoch 12:  61%|██████    | 17/28 [00:00<00:00, 88.59it/s, train_loss=0.0116, val_loss=0.0105]Epoch 12:  61%|██████    | 17/28 [00:00<00:00, 86.19it/s, train_loss=0.00999, val_loss=0.0105]Epoch 12:  64%|██████▍   | 18/28 [00:00<00:00, 88.64it/s, train_loss=0.00999, val_loss=0.0105]Epoch 12:  64%|██████▍   | 18/28 [00:00<00:00, 86.29it/s, train_loss=0.00919, val_loss=0.0105]Epoch 12:  68%|██████▊   | 19/28 [00:00<00:00, 88.66it/s, train_loss=0.00919, val_loss=0.0105]Epoch 12:  68%|██████▊   | 19/28 [00:00<00:00, 86.38it/s, train_loss=0.0099, val_loss=0.0105] Epoch 12:  71%|███████▏  | 20/28 [00:00<00:00, 88.48it/s, train_loss=0.0099, val_loss=0.0105]Epoch 12:  71%|███████▏  | 20/28 [00:00<00:00, 85.89it/s, train_loss=0.00803, val_loss=0.0105]Epoch 12:  75%|███████▌  | 21/28 [00:00<00:00, 88.04it/s, train_loss=0.00803, val_loss=0.0105]Epoch 12:  75%|███████▌  | 21/28 [00:00<00:00, 85.99it/s, train_loss=0.00857, val_loss=0.0105]Epoch 12:  79%|███████▊  | 22/28 [00:00<00:00, 88.16it/s, train_loss=0.00857, val_loss=0.0105]Epoch 12:  79%|███████▊  | 22/28 [00:00<00:00, 86.08it/s, train_loss=0.0107, val_loss=0.0105] Epoch 12:  82%|████████▏ | 23/28 [00:00<00:00, 88.14it/s, train_loss=0.0107, val_loss=0.0105]Epoch 12:  82%|████████▏ | 23/28 [00:00<00:00, 86.71it/s, train_loss=0.0118, val_loss=0.0105]Epoch 12:  86%|████████▌ | 24/28 [00:00<00:00, 88.41it/s, train_loss=0.0118, val_loss=0.0105]Epoch 12:  86%|████████▌ | 24/28 [00:00<00:00, 86.46it/s, train_loss=0.0106, val_loss=0.0105]Epoch 12:  89%|████████▉ | 25/28 [00:00<00:00, 88.27it/s, train_loss=0.0106, val_loss=0.0105]Epoch 12:  89%|████████▉ | 25/28 [00:00<00:00, 86.53it/s, train_loss=0.0116, val_loss=0.0105]Epoch 12:  93%|█████████▎| 26/28 [00:00<00:00, 88.29it/s, train_loss=0.0116, val_loss=0.0105]Epoch 12:  93%|█████████▎| 26/28 [00:00<00:00, 85.98it/s, train_loss=0.00805, val_loss=0.0105]Epoch 12:  96%|█████████▋| 27/28 [00:00<00:00, 87.62it/s, train_loss=0.00805, val_loss=0.0105]Epoch 12:  96%|█████████▋| 27/28 [00:00<00:00, 86.55it/s, train_loss=0.0102, val_loss=0.0105] Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 87.96it/s, train_loss=0.0102, val_loss=0.0105]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 86.63it/s, train_loss=0.00784, val_loss=0.0105]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 164.77it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 197.42it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 208.95it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 213.26it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 217.24it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 219.84it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 221.59it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 223.44it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 225.01it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 226.00it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 226.81it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 229.00it/s][A
                                                                         [AEpoch 12: 100%|██████████| 28/28 [00:00<00:00, 72.80it/s, train_loss=0.00784, val_loss=0.00932]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 72.62it/s, train_loss=0.00784, val_loss=0.00932]Epoch 12:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00784, val_loss=0.00932]         Epoch 13:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00784, val_loss=0.00932]Epoch 13:   4%|▎         | 1/28 [00:00<00:00, 143.19it/s, train_loss=0.00784, val_loss=0.00932]Epoch 13:   4%|▎         | 1/28 [00:00<00:00, 72.85it/s, train_loss=0.00876, val_loss=0.00932] Epoch 13:   7%|▋         | 2/28 [00:00<00:00, 103.16it/s, train_loss=0.00876, val_loss=0.00932]Epoch 13:   7%|▋         | 2/28 [00:00<00:00, 79.39it/s, train_loss=0.011, val_loss=0.00932]   Epoch 13:  11%|█         | 3/28 [00:00<00:00, 96.05it/s, train_loss=0.011, val_loss=0.00932]Epoch 13:  11%|█         | 3/28 [00:00<00:00, 83.05it/s, train_loss=0.0117, val_loss=0.00932]Epoch 13:  14%|█▍        | 4/28 [00:00<00:00, 96.25it/s, train_loss=0.0117, val_loss=0.00932]Epoch 13:  14%|█▍        | 4/28 [00:00<00:00, 83.98it/s, train_loss=0.00919, val_loss=0.00932]Epoch 13:  18%|█▊        | 5/28 [00:00<00:00, 93.59it/s, train_loss=0.00919, val_loss=0.00932]Epoch 13:  18%|█▊        | 5/28 [00:00<00:00, 84.66it/s, train_loss=0.00948, val_loss=0.00932]Epoch 13:  21%|██▏       | 6/28 [00:00<00:00, 92.94it/s, train_loss=0.00948, val_loss=0.00932]Epoch 13:  21%|██▏       | 6/28 [00:00<00:00, 85.20it/s, train_loss=0.00982, val_loss=0.00932]Epoch 13:  25%|██▌       | 7/28 [00:00<00:00, 91.12it/s, train_loss=0.00982, val_loss=0.00932]Epoch 13:  25%|██▌       | 7/28 [00:00<00:00, 86.05it/s, train_loss=0.00828, val_loss=0.00932]Epoch 13:  29%|██▊       | 8/28 [00:00<00:00, 91.96it/s, train_loss=0.00828, val_loss=0.00932]Epoch 13:  29%|██▊       | 8/28 [00:00<00:00, 86.26it/s, train_loss=0.00821, val_loss=0.00932]Epoch 13:  32%|███▏      | 9/28 [00:00<00:00, 91.74it/s, train_loss=0.00821, val_loss=0.00932]Epoch 13:  32%|███▏      | 9/28 [00:00<00:00, 86.43it/s, train_loss=0.00984, val_loss=0.00932]Epoch 13:  36%|███▌      | 10/28 [00:00<00:00, 91.35it/s, train_loss=0.00984, val_loss=0.00932]Epoch 13:  36%|███▌      | 10/28 [00:00<00:00, 86.65it/s, train_loss=0.0104, val_loss=0.00932] Epoch 13:  39%|███▉      | 11/28 [00:00<00:00, 90.38it/s, train_loss=0.0104, val_loss=0.00932]Epoch 13:  39%|███▉      | 11/28 [00:00<00:00, 86.14it/s, train_loss=0.0113, val_loss=0.00932]Epoch 13:  43%|████▎     | 12/28 [00:00<00:00, 89.98it/s, train_loss=0.0113, val_loss=0.00932]Epoch 13:  43%|████▎     | 12/28 [00:00<00:00, 86.26it/s, train_loss=0.00805, val_loss=0.00932]Epoch 13:  46%|████▋     | 13/28 [00:00<00:00, 89.87it/s, train_loss=0.00805, val_loss=0.00932]Epoch 13:  46%|████▋     | 13/28 [00:00<00:00, 86.39it/s, train_loss=0.0108, val_loss=0.00932] Epoch 13:  50%|█████     | 14/28 [00:00<00:00, 89.34it/s, train_loss=0.0108, val_loss=0.00932]Epoch 13:  50%|█████     | 14/28 [00:00<00:00, 87.49it/s, train_loss=0.011, val_loss=0.00932] Epoch 13:  54%|█████▎    | 15/28 [00:00<00:00, 90.12it/s, train_loss=0.011, val_loss=0.00932]Epoch 13:  54%|█████▎    | 15/28 [00:00<00:00, 87.34it/s, train_loss=0.00752, val_loss=0.00932]Epoch 13:  57%|█████▋    | 16/28 [00:00<00:00, 90.09it/s, train_loss=0.00752, val_loss=0.00932]Epoch 13:  57%|█████▋    | 16/28 [00:00<00:00, 87.38it/s, train_loss=0.0103, val_loss=0.00932] Epoch 13:  61%|██████    | 17/28 [00:00<00:00, 90.07it/s, train_loss=0.0103, val_loss=0.00932]Epoch 13:  61%|██████    | 17/28 [00:00<00:00, 87.41it/s, train_loss=0.00701, val_loss=0.00932]Epoch 13:  64%|██████▍   | 18/28 [00:00<00:00, 90.01it/s, train_loss=0.00701, val_loss=0.00932]Epoch 13:  64%|██████▍   | 18/28 [00:00<00:00, 88.22it/s, train_loss=0.00831, val_loss=0.00932]Epoch 13:  68%|██████▊   | 19/28 [00:00<00:00, 90.30it/s, train_loss=0.00831, val_loss=0.00932]Epoch 13:  68%|██████▊   | 19/28 [00:00<00:00, 87.83it/s, train_loss=0.00987, val_loss=0.00932]Epoch 13:  71%|███████▏  | 20/28 [00:00<00:00, 90.06it/s, train_loss=0.00987, val_loss=0.00932]Epoch 13:  71%|███████▏  | 20/28 [00:00<00:00, 87.85it/s, train_loss=0.00957, val_loss=0.00932]Epoch 13:  75%|███████▌  | 21/28 [00:00<00:00, 89.84it/s, train_loss=0.00957, val_loss=0.00932]Epoch 13:  75%|███████▌  | 21/28 [00:00<00:00, 87.90it/s, train_loss=0.0073, val_loss=0.00932] Epoch 13:  79%|███████▊  | 22/28 [00:00<00:00, 90.04it/s, train_loss=0.0073, val_loss=0.00932]Epoch 13:  79%|███████▊  | 22/28 [00:00<00:00, 88.61it/s, train_loss=0.0106, val_loss=0.00932]Epoch 13:  82%|████████▏ | 23/28 [00:00<00:00, 90.38it/s, train_loss=0.0106, val_loss=0.00932]Epoch 13:  82%|████████▏ | 23/28 [00:00<00:00, 88.24it/s, train_loss=0.0094, val_loss=0.00932]Epoch 13:  86%|████████▌ | 24/28 [00:00<00:00, 90.23it/s, train_loss=0.0094, val_loss=0.00932]Epoch 13:  86%|████████▌ | 24/28 [00:00<00:00, 88.22it/s, train_loss=0.0134, val_loss=0.00932]Epoch 13:  89%|████████▉ | 25/28 [00:00<00:00, 90.13it/s, train_loss=0.0134, val_loss=0.00932]Epoch 13:  89%|████████▉ | 25/28 [00:00<00:00, 88.22it/s, train_loss=0.00952, val_loss=0.00932]Epoch 13:  93%|█████████▎| 26/28 [00:00<00:00, 90.03it/s, train_loss=0.00952, val_loss=0.00932]Epoch 13:  93%|█████████▎| 26/28 [00:00<00:00, 88.24it/s, train_loss=0.010, val_loss=0.00932]  Epoch 13:  96%|█████████▋| 27/28 [00:00<00:00, 89.66it/s, train_loss=0.010, val_loss=0.00932]Epoch 13:  96%|█████████▋| 27/28 [00:00<00:00, 88.25it/s, train_loss=0.0105, val_loss=0.00932]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 89.88it/s, train_loss=0.0105, val_loss=0.00932]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 88.96it/s, train_loss=0.00848, val_loss=0.00932]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 162.88it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 196.71it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 211.04it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 220.66it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 226.57it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 231.58it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 234.58it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 236.86it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 238.65it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 239.40it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 240.36it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 241.53it/s][A
                                                                         [AEpoch 13: 100%|██████████| 28/28 [00:00<00:00, 75.16it/s, train_loss=0.00848, val_loss=0.00876]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 74.97it/s, train_loss=0.00848, val_loss=0.00876]Epoch 13:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00848, val_loss=0.00876]         Epoch 14:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00848, val_loss=0.00876]Epoch 14:   4%|▎         | 1/28 [00:00<00:00, 145.64it/s, train_loss=0.00848, val_loss=0.00876]Epoch 14:   4%|▎         | 1/28 [00:00<00:00, 73.44it/s, train_loss=0.0083, val_loss=0.00876]  Epoch 14:   7%|▋         | 2/28 [00:00<00:00, 103.71it/s, train_loss=0.0083, val_loss=0.00876]Epoch 14:   7%|▋         | 2/28 [00:00<00:00, 86.65it/s, train_loss=0.00718, val_loss=0.00876]Epoch 14:  11%|█         | 3/28 [00:00<00:00, 101.11it/s, train_loss=0.00718, val_loss=0.00876]Epoch 14:  11%|█         | 3/28 [00:00<00:00, 84.75it/s, train_loss=0.00837, val_loss=0.00876] Epoch 14:  14%|█▍        | 4/28 [00:00<00:00, 97.37it/s, train_loss=0.00837, val_loss=0.00876]Epoch 14:  14%|█▍        | 4/28 [00:00<00:00, 85.44it/s, train_loss=0.00903, val_loss=0.00876]Epoch 14:  18%|█▊        | 5/28 [00:00<00:00, 96.24it/s, train_loss=0.00903, val_loss=0.00876]Epoch 14:  18%|█▊        | 5/28 [00:00<00:00, 85.82it/s, train_loss=0.0104, val_loss=0.00876] Epoch 14:  21%|██▏       | 6/28 [00:00<00:00, 94.31it/s, train_loss=0.0104, val_loss=0.00876]Epoch 14:  21%|██▏       | 6/28 [00:00<00:00, 88.14it/s, train_loss=0.00886, val_loss=0.00876]Epoch 14:  25%|██▌       | 7/28 [00:00<00:00, 94.36it/s, train_loss=0.00886, val_loss=0.00876]Epoch 14:  25%|██▌       | 7/28 [00:00<00:00, 87.16it/s, train_loss=0.00927, val_loss=0.00876]Epoch 14:  29%|██▊       | 8/28 [00:00<00:00, 93.22it/s, train_loss=0.00927, val_loss=0.00876]Epoch 14:  29%|██▊       | 8/28 [00:00<00:00, 87.27it/s, train_loss=0.012, val_loss=0.00876]  Epoch 14:  32%|███▏      | 9/28 [00:00<00:00, 92.70it/s, train_loss=0.012, val_loss=0.00876]Epoch 14:  32%|███▏      | 9/28 [00:00<00:00, 87.36it/s, train_loss=0.00813, val_loss=0.00876]Epoch 14:  36%|███▌      | 10/28 [00:00<00:00, 92.27it/s, train_loss=0.00813, val_loss=0.00876]Epoch 14:  36%|███▌      | 10/28 [00:00<00:00, 88.96it/s, train_loss=0.00751, val_loss=0.00876]Epoch 14:  39%|███▉      | 11/28 [00:00<00:00, 92.60it/s, train_loss=0.00751, val_loss=0.00876]Epoch 14:  39%|███▉      | 11/28 [00:00<00:00, 88.16it/s, train_loss=0.0109, val_loss=0.00876] Epoch 14:  43%|████▎     | 12/28 [00:00<00:00, 92.09it/s, train_loss=0.0109, val_loss=0.00876]Epoch 14:  43%|████▎     | 12/28 [00:00<00:00, 88.16it/s, train_loss=0.00981, val_loss=0.00876]Epoch 14:  46%|████▋     | 13/28 [00:00<00:00, 91.88it/s, train_loss=0.00981, val_loss=0.00876]Epoch 14:  46%|████▋     | 13/28 [00:00<00:00, 88.16it/s, train_loss=0.00808, val_loss=0.00876]Epoch 14:  50%|█████     | 14/28 [00:00<00:00, 91.61it/s, train_loss=0.00808, val_loss=0.00876]Epoch 14:  50%|█████     | 14/28 [00:00<00:00, 89.38it/s, train_loss=0.0106, val_loss=0.00876] Epoch 14:  54%|█████▎    | 15/28 [00:00<00:00, 92.05it/s, train_loss=0.0106, val_loss=0.00876]Epoch 14:  54%|█████▎    | 15/28 [00:00<00:00, 88.70it/s, train_loss=0.0099, val_loss=0.00876]Epoch 14:  57%|█████▋    | 16/28 [00:00<00:00, 91.47it/s, train_loss=0.0099, val_loss=0.00876]Epoch 14:  57%|█████▋    | 16/28 [00:00<00:00, 88.64it/s, train_loss=0.0105, val_loss=0.00876]Epoch 14:  61%|██████    | 17/28 [00:00<00:00, 91.32it/s, train_loss=0.0105, val_loss=0.00876]Epoch 14:  61%|██████    | 17/28 [00:00<00:00, 88.60it/s, train_loss=0.00862, val_loss=0.00876]Epoch 14:  64%|██████▍   | 18/28 [00:00<00:00, 91.20it/s, train_loss=0.00862, val_loss=0.00876]Epoch 14:  64%|██████▍   | 18/28 [00:00<00:00, 89.49it/s, train_loss=0.0084, val_loss=0.00876] Epoch 14:  68%|██████▊   | 19/28 [00:00<00:00, 91.56it/s, train_loss=0.0084, val_loss=0.00876]Epoch 14:  68%|██████▊   | 19/28 [00:00<00:00, 89.03it/s, train_loss=0.00985, val_loss=0.00876]Epoch 14:  71%|███████▏  | 20/28 [00:00<00:00, 91.31it/s, train_loss=0.00985, val_loss=0.00876]Epoch 14:  71%|███████▏  | 20/28 [00:00<00:00, 88.99it/s, train_loss=0.00968, val_loss=0.00876]Epoch 14:  75%|███████▌  | 21/28 [00:00<00:00, 91.20it/s, train_loss=0.00968, val_loss=0.00876]Epoch 14:  75%|███████▌  | 21/28 [00:00<00:00, 88.96it/s, train_loss=0.0114, val_loss=0.00876] Epoch 14:  79%|███████▊  | 22/28 [00:00<00:00, 90.86it/s, train_loss=0.0114, val_loss=0.00876]Epoch 14:  79%|███████▊  | 22/28 [00:00<00:00, 89.02it/s, train_loss=0.00857, val_loss=0.00876]Epoch 14:  82%|████████▏ | 23/28 [00:00<00:00, 90.68it/s, train_loss=0.00857, val_loss=0.00876]Epoch 14:  82%|████████▏ | 23/28 [00:00<00:00, 89.00it/s, train_loss=0.00628, val_loss=0.00876]Epoch 14:  86%|████████▌ | 24/28 [00:00<00:00, 90.79it/s, train_loss=0.00628, val_loss=0.00876]Epoch 14:  86%|████████▌ | 24/28 [00:00<00:00, 88.94it/s, train_loss=0.0079, val_loss=0.00876] Epoch 14:  89%|████████▉ | 25/28 [00:00<00:00, 90.84it/s, train_loss=0.0079, val_loss=0.00876]Epoch 14:  89%|████████▉ | 25/28 [00:00<00:00, 88.87it/s, train_loss=0.0079, val_loss=0.00876]Epoch 14:  93%|█████████▎| 26/28 [00:00<00:00, 90.61it/s, train_loss=0.0079, val_loss=0.00876]Epoch 14:  93%|█████████▎| 26/28 [00:00<00:00, 89.40it/s, train_loss=0.00745, val_loss=0.00876]Epoch 14:  96%|█████████▋| 27/28 [00:00<00:00, 90.94it/s, train_loss=0.00745, val_loss=0.00876]Epoch 14:  96%|█████████▋| 27/28 [00:00<00:00, 89.34it/s, train_loss=0.0088, val_loss=0.00876] Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 91.01it/s, train_loss=0.0088, val_loss=0.00876]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 90.03it/s, train_loss=0.00684, val_loss=0.00876]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 181.57it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 214.76it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 226.66it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 234.32it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 239.57it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 242.17it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 243.84it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 245.18it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 245.71it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 246.16it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 246.49it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 247.81it/s][A
                                                                         [AEpoch 14: 100%|██████████| 28/28 [00:00<00:00, 76.34it/s, train_loss=0.00684, val_loss=0.00809]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 76.17it/s, train_loss=0.00684, val_loss=0.00809]Epoch 14:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00684, val_loss=0.00809]         Epoch 15:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00684, val_loss=0.00809]Epoch 15:   4%|▎         | 1/28 [00:00<00:00, 149.08it/s, train_loss=0.00684, val_loss=0.00809]Epoch 15:   4%|▎         | 1/28 [00:00<00:00, 73.38it/s, train_loss=0.00859, val_loss=0.00809] Epoch 15:   7%|▋         | 2/28 [00:00<00:00, 103.79it/s, train_loss=0.00859, val_loss=0.00809]Epoch 15:   7%|▋         | 2/28 [00:00<00:00, 80.10it/s, train_loss=0.00709, val_loss=0.00809] Epoch 15:  11%|█         | 3/28 [00:00<00:00, 95.32it/s, train_loss=0.00709, val_loss=0.00809]Epoch 15:  11%|█         | 3/28 [00:00<00:00, 80.19it/s, train_loss=0.00914, val_loss=0.00809]Epoch 15:  14%|█▍        | 4/28 [00:00<00:00, 92.73it/s, train_loss=0.00914, val_loss=0.00809]Epoch 15:  14%|█▍        | 4/28 [00:00<00:00, 82.01it/s, train_loss=0.00877, val_loss=0.00809]Epoch 15:  18%|█▊        | 5/28 [00:00<00:00, 91.43it/s, train_loss=0.00877, val_loss=0.00809]Epoch 15:  18%|█▊        | 5/28 [00:00<00:00, 83.27it/s, train_loss=0.00813, val_loss=0.00809]Epoch 15:  21%|██▏       | 6/28 [00:00<00:00, 90.99it/s, train_loss=0.00813, val_loss=0.00809]Epoch 15:  21%|██▏       | 6/28 [00:00<00:00, 86.34it/s, train_loss=0.00939, val_loss=0.00809]Epoch 15:  25%|██▌       | 7/28 [00:00<00:00, 92.28it/s, train_loss=0.00939, val_loss=0.00809]Epoch 15:  25%|██▌       | 7/28 [00:00<00:00, 86.26it/s, train_loss=0.0064, val_loss=0.00809] Epoch 15:  29%|██▊       | 8/28 [00:00<00:00, 92.61it/s, train_loss=0.0064, val_loss=0.00809]Epoch 15:  29%|██▊       | 8/28 [00:00<00:00, 86.56it/s, train_loss=0.0083, val_loss=0.00809]Epoch 15:  32%|███▏      | 9/28 [00:00<00:00, 92.13it/s, train_loss=0.0083, val_loss=0.00809]Epoch 15:  32%|███▏      | 9/28 [00:00<00:00, 86.78it/s, train_loss=0.00621, val_loss=0.00809]Epoch 15:  36%|███▌      | 10/28 [00:00<00:00, 91.72it/s, train_loss=0.00621, val_loss=0.00809]Epoch 15:  36%|███▌      | 10/28 [00:00<00:00, 87.00it/s, train_loss=0.00781, val_loss=0.00809]Epoch 15:  39%|███▉      | 11/28 [00:00<00:00, 90.74it/s, train_loss=0.00781, val_loss=0.00809]Epoch 15:  39%|███▉      | 11/28 [00:00<00:00, 87.07it/s, train_loss=0.00772, val_loss=0.00809]Epoch 15:  43%|████▎     | 12/28 [00:00<00:00, 91.03it/s, train_loss=0.00772, val_loss=0.00809]Epoch 15:  43%|████▎     | 12/28 [00:00<00:00, 87.16it/s, train_loss=0.00854, val_loss=0.00809]Epoch 15:  46%|████▋     | 13/28 [00:00<00:00, 90.81it/s, train_loss=0.00854, val_loss=0.00809]Epoch 15:  46%|████▋     | 13/28 [00:00<00:00, 87.26it/s, train_loss=0.0109, val_loss=0.00809] Epoch 15:  50%|█████     | 14/28 [00:00<00:00, 90.15it/s, train_loss=0.0109, val_loss=0.00809]Epoch 15:  50%|█████     | 14/28 [00:00<00:00, 87.45it/s, train_loss=0.00692, val_loss=0.00809]Epoch 15:  54%|█████▎    | 15/28 [00:00<00:00, 90.53it/s, train_loss=0.00692, val_loss=0.00809]Epoch 15:  54%|█████▎    | 15/28 [00:00<00:00, 87.53it/s, train_loss=0.010, val_loss=0.00809]  Epoch 15:  57%|█████▋    | 16/28 [00:00<00:00, 90.43it/s, train_loss=0.010, val_loss=0.00809]Epoch 15:  57%|█████▋    | 16/28 [00:00<00:00, 87.54it/s, train_loss=0.00727, val_loss=0.00809]Epoch 15:  61%|██████    | 17/28 [00:00<00:00, 90.26it/s, train_loss=0.00727, val_loss=0.00809]Epoch 15:  61%|██████    | 17/28 [00:00<00:00, 87.62it/s, train_loss=0.00694, val_loss=0.00809]Epoch 15:  64%|██████▍   | 18/28 [00:00<00:00, 89.91it/s, train_loss=0.00694, val_loss=0.00809]Epoch 15:  64%|██████▍   | 18/28 [00:00<00:00, 86.93it/s, train_loss=0.00745, val_loss=0.00809]Epoch 15:  68%|██████▊   | 19/28 [00:00<00:00, 89.33it/s, train_loss=0.00745, val_loss=0.00809]Epoch 15:  68%|██████▊   | 19/28 [00:00<00:00, 87.02it/s, train_loss=0.00847, val_loss=0.00809]Epoch 15:  71%|███████▏  | 20/28 [00:00<00:00, 89.33it/s, train_loss=0.00847, val_loss=0.00809]Epoch 15:  71%|███████▏  | 20/28 [00:00<00:00, 87.09it/s, train_loss=0.00976, val_loss=0.00809]Epoch 15:  75%|███████▌  | 21/28 [00:00<00:00, 89.30it/s, train_loss=0.00976, val_loss=0.00809]Epoch 15:  75%|███████▌  | 21/28 [00:00<00:00, 87.18it/s, train_loss=0.00983, val_loss=0.00809]Epoch 15:  79%|███████▊  | 22/28 [00:00<00:00, 88.92it/s, train_loss=0.00983, val_loss=0.00809]Epoch 15:  79%|███████▊  | 22/28 [00:00<00:00, 87.24it/s, train_loss=0.00782, val_loss=0.00809]Epoch 15:  82%|████████▏ | 23/28 [00:00<00:00, 89.18it/s, train_loss=0.00782, val_loss=0.00809]Epoch 15:  82%|████████▏ | 23/28 [00:00<00:00, 87.28it/s, train_loss=0.0124, val_loss=0.00809] Epoch 15:  86%|████████▌ | 24/28 [00:00<00:00, 89.15it/s, train_loss=0.0124, val_loss=0.00809]Epoch 15:  86%|████████▌ | 24/28 [00:00<00:00, 87.34it/s, train_loss=0.00713, val_loss=0.00809]Epoch 15:  89%|████████▉ | 25/28 [00:00<00:00, 88.97it/s, train_loss=0.00713, val_loss=0.00809]Epoch 15:  89%|████████▉ | 25/28 [00:00<00:00, 87.94it/s, train_loss=0.00754, val_loss=0.00809]Epoch 15:  93%|█████████▎| 26/28 [00:00<00:00, 89.45it/s, train_loss=0.00754, val_loss=0.00809]Epoch 15:  93%|█████████▎| 26/28 [00:00<00:00, 87.97it/s, train_loss=0.00971, val_loss=0.00809]Epoch 15:  96%|█████████▋| 27/28 [00:00<00:00, 89.75it/s, train_loss=0.00971, val_loss=0.00809]Epoch 15:  96%|█████████▋| 27/28 [00:00<00:00, 87.96it/s, train_loss=0.00825, val_loss=0.00809]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 89.38it/s, train_loss=0.00825, val_loss=0.00809]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 88.02it/s, train_loss=0.0101, val_loss=0.00809] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 201.58it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 234.42it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 247.76it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 253.28it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 257.29it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 259.60it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 261.05it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 261.92it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 262.77it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 263.67it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 262.12it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 247.90it/s][A
                                                                         [AEpoch 15: 100%|██████████| 28/28 [00:00<00:00, 74.76it/s, train_loss=0.0101, val_loss=0.00769]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 74.59it/s, train_loss=0.0101, val_loss=0.00769]Epoch 15:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0101, val_loss=0.00769]         Epoch 16:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0101, val_loss=0.00769]Epoch 16:   4%|▎         | 1/28 [00:00<00:00, 135.43it/s, train_loss=0.0101, val_loss=0.00769]Epoch 16:   4%|▎         | 1/28 [00:00<00:00, 74.49it/s, train_loss=0.0088, val_loss=0.00769] Epoch 16:   7%|▋         | 2/28 [00:00<00:00, 104.06it/s, train_loss=0.0088, val_loss=0.00769]Epoch 16:   7%|▋         | 2/28 [00:00<00:00, 80.69it/s, train_loss=0.00997, val_loss=0.00769]Epoch 16:  11%|█         | 3/28 [00:00<00:00, 98.58it/s, train_loss=0.00997, val_loss=0.00769]Epoch 16:  11%|█         | 3/28 [00:00<00:00, 82.76it/s, train_loss=0.00627, val_loss=0.00769]Epoch 16:  14%|█▍        | 4/28 [00:00<00:00, 95.27it/s, train_loss=0.00627, val_loss=0.00769]Epoch 16:  14%|█▍        | 4/28 [00:00<00:00, 84.07it/s, train_loss=0.00822, val_loss=0.00769]Epoch 16:  18%|█▊        | 5/28 [00:00<00:00, 92.31it/s, train_loss=0.00822, val_loss=0.00769]Epoch 16:  18%|█▊        | 5/28 [00:00<00:00, 82.59it/s, train_loss=0.00921, val_loss=0.00769]Epoch 16:  21%|██▏       | 6/28 [00:00<00:00, 90.44it/s, train_loss=0.00921, val_loss=0.00769]Epoch 16:  21%|██▏       | 6/28 [00:00<00:00, 83.52it/s, train_loss=0.00978, val_loss=0.00769]Epoch 16:  25%|██▌       | 7/28 [00:00<00:00, 90.42it/s, train_loss=0.00978, val_loss=0.00769]Epoch 16:  25%|██▌       | 7/28 [00:00<00:00, 84.16it/s, train_loss=0.00711, val_loss=0.00769]Epoch 16:  29%|██▊       | 8/28 [00:00<00:00, 89.91it/s, train_loss=0.00711, val_loss=0.00769]Epoch 16:  29%|██▊       | 8/28 [00:00<00:00, 86.52it/s, train_loss=0.00764, val_loss=0.00769]Epoch 16:  32%|███▏      | 9/28 [00:00<00:00, 90.98it/s, train_loss=0.00764, val_loss=0.00769]Epoch 16:  32%|███▏      | 9/28 [00:00<00:00, 86.34it/s, train_loss=0.00977, val_loss=0.00769]Epoch 16:  36%|███▌      | 10/28 [00:00<00:00, 91.33it/s, train_loss=0.00977, val_loss=0.00769]Epoch 16:  36%|███▌      | 10/28 [00:00<00:00, 86.53it/s, train_loss=0.00804, val_loss=0.00769]Epoch 16:  39%|███▉      | 11/28 [00:00<00:00, 90.99it/s, train_loss=0.00804, val_loss=0.00769]Epoch 16:  39%|███▉      | 11/28 [00:00<00:00, 86.75it/s, train_loss=0.0068, val_loss=0.00769] Epoch 16:  43%|████▎     | 12/28 [00:00<00:00, 90.91it/s, train_loss=0.0068, val_loss=0.00769]Epoch 16:  43%|████▎     | 12/28 [00:00<00:00, 86.91it/s, train_loss=0.010, val_loss=0.00769] Epoch 16:  46%|████▋     | 13/28 [00:00<00:00, 90.05it/s, train_loss=0.010, val_loss=0.00769]Epoch 16:  46%|████▋     | 13/28 [00:00<00:00, 87.03it/s, train_loss=0.00602, val_loss=0.00769]Epoch 16:  50%|█████     | 14/28 [00:00<00:00, 90.41it/s, train_loss=0.00602, val_loss=0.00769]Epoch 16:  50%|█████     | 14/28 [00:00<00:00, 87.08it/s, train_loss=0.00646, val_loss=0.00769]Epoch 16:  54%|█████▎    | 15/28 [00:00<00:00, 90.18it/s, train_loss=0.00646, val_loss=0.00769]Epoch 16:  54%|█████▎    | 15/28 [00:00<00:00, 87.19it/s, train_loss=0.00753, val_loss=0.00769]Epoch 16:  57%|█████▋    | 16/28 [00:00<00:00, 89.69it/s, train_loss=0.00753, val_loss=0.00769]Epoch 16:  57%|█████▋    | 16/28 [00:00<00:00, 87.31it/s, train_loss=0.00678, val_loss=0.00769]Epoch 16:  61%|██████    | 17/28 [00:00<00:00, 89.98it/s, train_loss=0.00678, val_loss=0.00769]Epoch 16:  61%|██████    | 17/28 [00:00<00:00, 87.37it/s, train_loss=0.00794, val_loss=0.00769]Epoch 16:  64%|██████▍   | 18/28 [00:00<00:00, 89.98it/s, train_loss=0.00794, val_loss=0.00769]Epoch 16:  64%|██████▍   | 18/28 [00:00<00:00, 87.42it/s, train_loss=0.0084, val_loss=0.00769] Epoch 16:  68%|██████▊   | 19/28 [00:00<00:00, 89.93it/s, train_loss=0.0084, val_loss=0.00769]Epoch 16:  68%|██████▊   | 19/28 [00:00<00:00, 87.49it/s, train_loss=0.00782, val_loss=0.00769]Epoch 16:  71%|███████▏  | 20/28 [00:00<00:00, 89.55it/s, train_loss=0.00782, val_loss=0.00769]Epoch 16:  71%|███████▏  | 20/28 [00:00<00:00, 86.88it/s, train_loss=0.00697, val_loss=0.00769]Epoch 16:  75%|███████▌  | 21/28 [00:00<00:00, 89.08it/s, train_loss=0.00697, val_loss=0.00769]Epoch 16:  75%|███████▌  | 21/28 [00:00<00:00, 86.93it/s, train_loss=0.00912, val_loss=0.00769]Epoch 16:  79%|███████▊  | 22/28 [00:00<00:00, 89.04it/s, train_loss=0.00912, val_loss=0.00769]Epoch 16:  79%|███████▊  | 22/28 [00:00<00:00, 86.98it/s, train_loss=0.00886, val_loss=0.00769]Epoch 16:  82%|████████▏ | 23/28 [00:00<00:00, 88.93it/s, train_loss=0.00886, val_loss=0.00769]Epoch 16:  82%|████████▏ | 23/28 [00:00<00:00, 87.71it/s, train_loss=0.00876, val_loss=0.00769]Epoch 16:  86%|████████▌ | 24/28 [00:00<00:00, 89.30it/s, train_loss=0.00876, val_loss=0.00769]Epoch 16:  86%|████████▌ | 24/28 [00:00<00:00, 87.41it/s, train_loss=0.00887, val_loss=0.00769]Epoch 16:  89%|████████▉ | 25/28 [00:00<00:00, 89.20it/s, train_loss=0.00887, val_loss=0.00769]Epoch 16:  89%|████████▉ | 25/28 [00:00<00:00, 87.45it/s, train_loss=0.00867, val_loss=0.00769]Epoch 16:  93%|█████████▎| 26/28 [00:00<00:00, 89.18it/s, train_loss=0.00867, val_loss=0.00769]Epoch 16:  93%|█████████▎| 26/28 [00:00<00:00, 87.48it/s, train_loss=0.00716, val_loss=0.00769]Epoch 16:  96%|█████████▋| 27/28 [00:00<00:00, 89.06it/s, train_loss=0.00716, val_loss=0.00769]Epoch 16:  96%|█████████▋| 27/28 [00:00<00:00, 87.59it/s, train_loss=0.00912, val_loss=0.00769]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 89.00it/s, train_loss=0.00912, val_loss=0.00769]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 87.69it/s, train_loss=0.00833, val_loss=0.00769]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 231.82it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 263.38it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 275.98it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 280.65it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 284.07it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 284.74it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 285.23it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 284.17it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 282.87it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 281.87it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 279.97it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 279.20it/s][A
                                                                         [AEpoch 16: 100%|██████████| 28/28 [00:00<00:00, 75.98it/s, train_loss=0.00833, val_loss=0.00725]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 75.82it/s, train_loss=0.00833, val_loss=0.00725]Epoch 16:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00833, val_loss=0.00725]         Epoch 17:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00833, val_loss=0.00725]Epoch 17:   4%|▎         | 1/28 [00:00<00:00, 137.25it/s, train_loss=0.00833, val_loss=0.00725]Epoch 17:   4%|▎         | 1/28 [00:00<00:00, 79.05it/s, train_loss=0.0106, val_loss=0.00725]  Epoch 17:   7%|▋         | 2/28 [00:00<00:00, 110.19it/s, train_loss=0.0106, val_loss=0.00725]Epoch 17:   7%|▋         | 2/28 [00:00<00:00, 83.21it/s, train_loss=0.00729, val_loss=0.00725]Epoch 17:  11%|█         | 3/28 [00:00<00:00, 101.67it/s, train_loss=0.00729, val_loss=0.00725]Epoch 17:  11%|█         | 3/28 [00:00<00:00, 84.51it/s, train_loss=0.00833, val_loss=0.00725] Epoch 17:  14%|█▍        | 4/28 [00:00<00:00, 97.41it/s, train_loss=0.00833, val_loss=0.00725]Epoch 17:  14%|█▍        | 4/28 [00:00<00:00, 88.98it/s, train_loss=0.00787, val_loss=0.00725]Epoch 17:  18%|█▊        | 5/28 [00:00<00:00, 97.10it/s, train_loss=0.00787, val_loss=0.00725]Epoch 17:  18%|█▊        | 5/28 [00:00<00:00, 87.13it/s, train_loss=0.00594, val_loss=0.00725]Epoch 17:  21%|██▏       | 6/28 [00:00<00:00, 95.15it/s, train_loss=0.00594, val_loss=0.00725]Epoch 17:  21%|██▏       | 6/28 [00:00<00:00, 87.39it/s, train_loss=0.00903, val_loss=0.00725]Epoch 17:  25%|██▌       | 7/28 [00:00<00:00, 94.23it/s, train_loss=0.00903, val_loss=0.00725]Epoch 17:  25%|██▌       | 7/28 [00:00<00:00, 87.55it/s, train_loss=0.00776, val_loss=0.00725]Epoch 17:  29%|██▊       | 8/28 [00:00<00:00, 93.51it/s, train_loss=0.00776, val_loss=0.00725]Epoch 17:  29%|██▊       | 8/28 [00:00<00:00, 89.65it/s, train_loss=0.00663, val_loss=0.00725]Epoch 17:  32%|███▏      | 9/28 [00:00<00:00, 94.04it/s, train_loss=0.00663, val_loss=0.00725]Epoch 17:  32%|███▏      | 9/28 [00:00<00:00, 88.68it/s, train_loss=0.00808, val_loss=0.00725]Epoch 17:  36%|███▌      | 10/28 [00:00<00:00, 93.24it/s, train_loss=0.00808, val_loss=0.00725]Epoch 17:  36%|███▌      | 10/28 [00:00<00:00, 88.68it/s, train_loss=0.00671, val_loss=0.00725]Epoch 17:  39%|███▉      | 11/28 [00:00<00:00, 92.62it/s, train_loss=0.00671, val_loss=0.00725]Epoch 17:  39%|███▉      | 11/28 [00:00<00:00, 88.68it/s, train_loss=0.0106, val_loss=0.00725] Epoch 17:  43%|████▎     | 12/28 [00:00<00:00, 92.71it/s, train_loss=0.0106, val_loss=0.00725]Epoch 17:  43%|████▎     | 12/28 [00:00<00:00, 89.98it/s, train_loss=0.00799, val_loss=0.00725]Epoch 17:  46%|████▋     | 13/28 [00:00<00:00, 93.25it/s, train_loss=0.00799, val_loss=0.00725]Epoch 17:  46%|████▋     | 13/28 [00:00<00:00, 89.28it/s, train_loss=0.00732, val_loss=0.00725]Epoch 17:  50%|█████     | 14/28 [00:00<00:00, 92.73it/s, train_loss=0.00732, val_loss=0.00725]Epoch 17:  50%|█████     | 14/28 [00:00<00:00, 89.19it/s, train_loss=0.00631, val_loss=0.00725]Epoch 17:  54%|█████▎    | 15/28 [00:00<00:00, 92.41it/s, train_loss=0.00631, val_loss=0.00725]Epoch 17:  54%|█████▎    | 15/28 [00:00<00:00, 89.17it/s, train_loss=0.00642, val_loss=0.00725]Epoch 17:  57%|█████▋    | 16/28 [00:00<00:00, 92.17it/s, train_loss=0.00642, val_loss=0.00725]Epoch 17:  57%|█████▋    | 16/28 [00:00<00:00, 90.05it/s, train_loss=0.00729, val_loss=0.00725]Epoch 17:  61%|██████    | 17/28 [00:00<00:00, 92.39it/s, train_loss=0.00729, val_loss=0.00725]Epoch 17:  61%|██████    | 17/28 [00:00<00:00, 89.44it/s, train_loss=0.00838, val_loss=0.00725]Epoch 17:  64%|██████▍   | 18/28 [00:00<00:00, 92.05it/s, train_loss=0.00838, val_loss=0.00725]Epoch 17:  64%|██████▍   | 18/28 [00:00<00:00, 89.38it/s, train_loss=0.00657, val_loss=0.00725]Epoch 17:  68%|██████▊   | 19/28 [00:00<00:00, 91.82it/s, train_loss=0.00657, val_loss=0.00725]Epoch 17:  68%|██████▊   | 19/28 [00:00<00:00, 89.31it/s, train_loss=0.00699, val_loss=0.00725]Epoch 17:  71%|███████▏  | 20/28 [00:00<00:00, 91.64it/s, train_loss=0.00699, val_loss=0.00725]Epoch 17:  71%|███████▏  | 20/28 [00:00<00:00, 90.06it/s, train_loss=0.00763, val_loss=0.00725]Epoch 17:  75%|███████▌  | 21/28 [00:00<00:00, 91.94it/s, train_loss=0.00763, val_loss=0.00725]Epoch 17:  75%|███████▌  | 21/28 [00:00<00:00, 89.61it/s, train_loss=0.00734, val_loss=0.00725]Epoch 17:  79%|███████▊  | 22/28 [00:00<00:00, 91.48it/s, train_loss=0.00734, val_loss=0.00725]Epoch 17:  79%|███████▊  | 22/28 [00:00<00:00, 89.58it/s, train_loss=0.00872, val_loss=0.00725]Epoch 17:  82%|████████▏ | 23/28 [00:00<00:00, 91.56it/s, train_loss=0.00872, val_loss=0.00725]Epoch 17:  82%|████████▏ | 23/28 [00:00<00:00, 89.54it/s, train_loss=0.00864, val_loss=0.00725]Epoch 17:  86%|████████▌ | 24/28 [00:00<00:00, 91.49it/s, train_loss=0.00864, val_loss=0.00725]Epoch 17:  86%|████████▌ | 24/28 [00:00<00:00, 90.15it/s, train_loss=0.00722, val_loss=0.00725]Epoch 17:  89%|████████▉ | 25/28 [00:00<00:00, 91.74it/s, train_loss=0.00722, val_loss=0.00725]Epoch 17:  89%|████████▉ | 25/28 [00:00<00:00, 89.76it/s, train_loss=0.00792, val_loss=0.00725]Epoch 17:  93%|█████████▎| 26/28 [00:00<00:00, 91.48it/s, train_loss=0.00792, val_loss=0.00725]Epoch 17:  93%|█████████▎| 26/28 [00:00<00:00, 89.73it/s, train_loss=0.00852, val_loss=0.00725]Epoch 17:  96%|█████████▋| 27/28 [00:00<00:00, 91.41it/s, train_loss=0.00852, val_loss=0.00725]Epoch 17:  96%|█████████▋| 27/28 [00:00<00:00, 89.68it/s, train_loss=0.00776, val_loss=0.00725]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 91.26it/s, train_loss=0.00776, val_loss=0.00725]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 90.26it/s, train_loss=0.00541, val_loss=0.00725]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 144.36it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 189.32it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 218.72it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 237.24it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 249.51it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 257.69it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 263.18it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 267.24it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 270.25it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 271.62it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 273.47it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 275.45it/s][A
                                                                         [AEpoch 17: 100%|██████████| 28/28 [00:00<00:00, 77.22it/s, train_loss=0.00541, val_loss=0.00689]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 77.07it/s, train_loss=0.00541, val_loss=0.00689]Epoch 17:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00541, val_loss=0.00689]         Epoch 18:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00541, val_loss=0.00689]Epoch 18:   4%|▎         | 1/28 [00:00<00:00, 156.74it/s, train_loss=0.00541, val_loss=0.00689]Epoch 18:   4%|▎         | 1/28 [00:00<00:00, 86.00it/s, train_loss=0.00636, val_loss=0.00689] Epoch 18:   7%|▋         | 2/28 [00:00<00:00, 111.15it/s, train_loss=0.00636, val_loss=0.00689]Epoch 18:   7%|▋         | 2/28 [00:00<00:00, 83.31it/s, train_loss=0.00936, val_loss=0.00689] Epoch 18:  11%|█         | 3/28 [00:00<00:00, 101.77it/s, train_loss=0.00936, val_loss=0.00689]Epoch 18:  11%|█         | 3/28 [00:00<00:00, 84.67it/s, train_loss=0.00851, val_loss=0.00689] Epoch 18:  14%|█▍        | 4/28 [00:00<00:00, 97.89it/s, train_loss=0.00851, val_loss=0.00689]Epoch 18:  14%|█▍        | 4/28 [00:00<00:00, 85.43it/s, train_loss=0.00711, val_loss=0.00689]Epoch 18:  18%|█▊        | 5/28 [00:00<00:00, 95.56it/s, train_loss=0.00711, val_loss=0.00689]Epoch 18:  18%|█▊        | 5/28 [00:00<00:00, 88.71it/s, train_loss=0.00716, val_loss=0.00689]Epoch 18:  21%|██▏       | 6/28 [00:00<00:00, 95.79it/s, train_loss=0.00716, val_loss=0.00689]Epoch 18:  21%|██▏       | 6/28 [00:00<00:00, 87.44it/s, train_loss=0.00806, val_loss=0.00689]Epoch 18:  25%|██▌       | 7/28 [00:00<00:00, 94.10it/s, train_loss=0.00806, val_loss=0.00689]Epoch 18:  25%|██▌       | 7/28 [00:00<00:00, 87.68it/s, train_loss=0.00806, val_loss=0.00689]Epoch 18:  29%|██▊       | 8/28 [00:00<00:00, 93.57it/s, train_loss=0.00806, val_loss=0.00689]Epoch 18:  29%|██▊       | 8/28 [00:00<00:00, 87.83it/s, train_loss=0.006, val_loss=0.00689]  Epoch 18:  32%|███▏      | 9/28 [00:00<00:00, 93.04it/s, train_loss=0.006, val_loss=0.00689]Epoch 18:  32%|███▏      | 9/28 [00:00<00:00, 87.97it/s, train_loss=0.00593, val_loss=0.00689]Epoch 18:  36%|███▌      | 10/28 [00:00<00:00, 91.82it/s, train_loss=0.00593, val_loss=0.00689]Epoch 18:  36%|███▌      | 10/28 [00:00<00:00, 88.06it/s, train_loss=0.00715, val_loss=0.00689]Epoch 18:  39%|███▉      | 11/28 [00:00<00:00, 92.14it/s, train_loss=0.00715, val_loss=0.00689]Epoch 18:  39%|███▉      | 11/28 [00:00<00:00, 88.09it/s, train_loss=0.00621, val_loss=0.00689]Epoch 18:  43%|████▎     | 12/28 [00:00<00:00, 91.86it/s, train_loss=0.00621, val_loss=0.00689]Epoch 18:  43%|████▎     | 12/28 [00:00<00:00, 88.17it/s, train_loss=0.00736, val_loss=0.00689]Epoch 18:  46%|████▋     | 13/28 [00:00<00:00, 91.22it/s, train_loss=0.00736, val_loss=0.00689]Epoch 18:  46%|████▋     | 13/28 [00:00<00:00, 88.19it/s, train_loss=0.00746, val_loss=0.00689]Epoch 18:  50%|█████     | 14/28 [00:00<00:00, 91.36it/s, train_loss=0.00746, val_loss=0.00689]Epoch 18:  50%|█████     | 14/28 [00:00<00:00, 88.22it/s, train_loss=0.00799, val_loss=0.00689]Epoch 18:  54%|█████▎    | 15/28 [00:00<00:00, 91.51it/s, train_loss=0.00799, val_loss=0.00689]Epoch 18:  54%|█████▎    | 15/28 [00:00<00:00, 88.17it/s, train_loss=0.00662, val_loss=0.00689]Epoch 18:  57%|█████▋    | 16/28 [00:00<00:00, 91.21it/s, train_loss=0.00662, val_loss=0.00689]Epoch 18:  57%|█████▋    | 16/28 [00:00<00:00, 88.20it/s, train_loss=0.00821, val_loss=0.00689]Epoch 18:  61%|██████    | 17/28 [00:00<00:00, 90.57it/s, train_loss=0.00821, val_loss=0.00689]Epoch 18:  61%|██████    | 17/28 [00:00<00:00, 87.43it/s, train_loss=0.0058, val_loss=0.00689] Epoch 18:  64%|██████▍   | 18/28 [00:00<00:00, 90.02it/s, train_loss=0.0058, val_loss=0.00689]Epoch 18:  64%|██████▍   | 18/28 [00:00<00:00, 87.48it/s, train_loss=0.00668, val_loss=0.00689]Epoch 18:  68%|██████▊   | 19/28 [00:00<00:00, 89.84it/s, train_loss=0.00668, val_loss=0.00689]Epoch 18:  68%|██████▊   | 19/28 [00:00<00:00, 87.54it/s, train_loss=0.00684, val_loss=0.00689]Epoch 18:  71%|███████▏  | 20/28 [00:00<00:00, 89.73it/s, train_loss=0.00684, val_loss=0.00689]Epoch 18:  71%|███████▏  | 20/28 [00:00<00:00, 87.60it/s, train_loss=0.0086, val_loss=0.00689] Epoch 18:  75%|███████▌  | 21/28 [00:00<00:00, 89.41it/s, train_loss=0.0086, val_loss=0.00689]Epoch 18:  75%|███████▌  | 21/28 [00:00<00:00, 87.61it/s, train_loss=0.00793, val_loss=0.00689]Epoch 18:  79%|███████▊  | 22/28 [00:00<00:00, 89.70it/s, train_loss=0.00793, val_loss=0.00689]Epoch 18:  79%|███████▊  | 22/28 [00:00<00:00, 87.61it/s, train_loss=0.00697, val_loss=0.00689]Epoch 18:  82%|████████▏ | 23/28 [00:00<00:00, 89.61it/s, train_loss=0.00697, val_loss=0.00689]Epoch 18:  82%|████████▏ | 23/28 [00:00<00:00, 87.65it/s, train_loss=0.00756, val_loss=0.00689]Epoch 18:  86%|████████▌ | 24/28 [00:00<00:00, 89.45it/s, train_loss=0.00756, val_loss=0.00689]Epoch 18:  86%|████████▌ | 24/28 [00:00<00:00, 88.23it/s, train_loss=0.00591, val_loss=0.00689]Epoch 18:  89%|████████▉ | 25/28 [00:00<00:00, 89.67it/s, train_loss=0.00591, val_loss=0.00689]Epoch 18:  89%|████████▉ | 25/28 [00:00<00:00, 88.22it/s, train_loss=0.0102, val_loss=0.00689] Epoch 18:  93%|█████████▎| 26/28 [00:00<00:00, 89.96it/s, train_loss=0.0102, val_loss=0.00689]Epoch 18:  93%|█████████▎| 26/28 [00:00<00:00, 88.21it/s, train_loss=0.00846, val_loss=0.00689]Epoch 18:  96%|█████████▋| 27/28 [00:00<00:00, 89.86it/s, train_loss=0.00846, val_loss=0.00689]Epoch 18:  96%|█████████▋| 27/28 [00:00<00:00, 88.21it/s, train_loss=0.0102, val_loss=0.00689] Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 89.60it/s, train_loss=0.0102, val_loss=0.00689]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 88.84it/s, train_loss=0.00522, val_loss=0.00689]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 138.57it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 169.37it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 182.68it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 186.55it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 177.19it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 179.55it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 187.82it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 197.09it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 204.58it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 211.44it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 216.92it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 222.06it/s][A
                                                                         [AEpoch 18: 100%|██████████| 28/28 [00:00<00:00, 74.04it/s, train_loss=0.00522, val_loss=0.00663]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 73.90it/s, train_loss=0.00522, val_loss=0.00663]Epoch 18:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00522, val_loss=0.00663]         Epoch 19:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00522, val_loss=0.00663]Epoch 19:   4%|▎         | 1/28 [00:00<00:00, 132.77it/s, train_loss=0.00522, val_loss=0.00663]Epoch 19:   4%|▎         | 1/28 [00:00<00:00, 82.08it/s, train_loss=0.00719, val_loss=0.00663] Epoch 19:   7%|▋         | 2/28 [00:00<00:00, 111.45it/s, train_loss=0.00719, val_loss=0.00663]Epoch 19:   7%|▋         | 2/28 [00:00<00:00, 84.90it/s, train_loss=0.011, val_loss=0.00663]   Epoch 19:  11%|█         | 3/28 [00:00<00:00, 103.00it/s, train_loss=0.011, val_loss=0.00663]Epoch 19:  11%|█         | 3/28 [00:00<00:00, 85.98it/s, train_loss=0.00799, val_loss=0.00663]Epoch 19:  14%|█▍        | 4/28 [00:00<00:00, 98.83it/s, train_loss=0.00799, val_loss=0.00663]Epoch 19:  14%|█▍        | 4/28 [00:00<00:00, 90.38it/s, train_loss=0.00836, val_loss=0.00663]Epoch 19:  18%|█▊        | 5/28 [00:00<00:00, 99.02it/s, train_loss=0.00836, val_loss=0.00663]Epoch 19:  18%|█▊        | 5/28 [00:00<00:00, 88.31it/s, train_loss=0.0054, val_loss=0.00663] Epoch 19:  21%|██▏       | 6/28 [00:00<00:00, 96.34it/s, train_loss=0.0054, val_loss=0.00663]Epoch 19:  21%|██▏       | 6/28 [00:00<00:00, 88.26it/s, train_loss=0.00965, val_loss=0.00663]Epoch 19:  25%|██▌       | 7/28 [00:00<00:00, 94.63it/s, train_loss=0.00965, val_loss=0.00663]Epoch 19:  25%|██▌       | 7/28 [00:00<00:00, 88.36it/s, train_loss=0.00844, val_loss=0.00663]Epoch 19:  29%|██▊       | 8/28 [00:00<00:00, 94.09it/s, train_loss=0.00844, val_loss=0.00663]Epoch 19:  29%|██▊       | 8/28 [00:00<00:00, 88.47it/s, train_loss=0.00842, val_loss=0.00663]Epoch 19:  32%|███▏      | 9/28 [00:00<00:00, 92.94it/s, train_loss=0.00842, val_loss=0.00663]Epoch 19:  32%|███▏      | 9/28 [00:00<00:00, 88.46it/s, train_loss=0.00598, val_loss=0.00663]Epoch 19:  36%|███▌      | 10/28 [00:00<00:00, 93.10it/s, train_loss=0.00598, val_loss=0.00663]Epoch 19:  36%|███▌      | 10/28 [00:00<00:00, 88.41it/s, train_loss=0.00594, val_loss=0.00663]Epoch 19:  39%|███▉      | 11/28 [00:00<00:00, 92.60it/s, train_loss=0.00594, val_loss=0.00663]Epoch 19:  39%|███▉      | 11/28 [00:00<00:00, 88.45it/s, train_loss=0.00893, val_loss=0.00663]Epoch 19:  43%|████▎     | 12/28 [00:00<00:00, 91.79it/s, train_loss=0.00893, val_loss=0.00663]Epoch 19:  43%|████▎     | 12/28 [00:00<00:00, 88.39it/s, train_loss=0.00619, val_loss=0.00663]Epoch 19:  46%|████▋     | 13/28 [00:00<00:00, 91.85it/s, train_loss=0.00619, val_loss=0.00663]Epoch 19:  46%|████▋     | 13/28 [00:00<00:00, 88.37it/s, train_loss=0.00602, val_loss=0.00663]Epoch 19:  50%|█████     | 14/28 [00:00<00:00, 91.61it/s, train_loss=0.00602, val_loss=0.00663]Epoch 19:  50%|█████     | 14/28 [00:00<00:00, 88.36it/s, train_loss=0.00619, val_loss=0.00663]Epoch 19:  54%|█████▎    | 15/28 [00:00<00:00, 91.38it/s, train_loss=0.00619, val_loss=0.00663]Epoch 19:  54%|█████▎    | 15/28 [00:00<00:00, 88.41it/s, train_loss=0.00514, val_loss=0.00663]Epoch 19:  57%|█████▋    | 16/28 [00:00<00:00, 90.74it/s, train_loss=0.00514, val_loss=0.00663]Epoch 19:  57%|█████▋    | 16/28 [00:00<00:00, 87.44it/s, train_loss=0.00691, val_loss=0.00663]Epoch 19:  61%|██████    | 17/28 [00:00<00:00, 90.26it/s, train_loss=0.00691, val_loss=0.00663]Epoch 19:  61%|██████    | 17/28 [00:00<00:00, 87.48it/s, train_loss=0.00597, val_loss=0.00663]Epoch 19:  64%|██████▍   | 18/28 [00:00<00:00, 90.17it/s, train_loss=0.00597, val_loss=0.00663]Epoch 19:  64%|██████▍   | 18/28 [00:00<00:00, 87.54it/s, train_loss=0.00758, val_loss=0.00663]Epoch 19:  68%|██████▊   | 19/28 [00:00<00:00, 90.06it/s, train_loss=0.00758, val_loss=0.00663]Epoch 19:  68%|██████▊   | 19/28 [00:00<00:00, 87.63it/s, train_loss=0.0064, val_loss=0.00663] Epoch 19:  71%|███████▏  | 20/28 [00:00<00:00, 89.61it/s, train_loss=0.0064, val_loss=0.00663]Epoch 19:  71%|███████▏  | 20/28 [00:00<00:00, 87.69it/s, train_loss=0.00708, val_loss=0.00663]Epoch 19:  75%|███████▌  | 21/28 [00:00<00:00, 89.91it/s, train_loss=0.00708, val_loss=0.00663]Epoch 19:  75%|███████▌  | 21/28 [00:00<00:00, 87.69it/s, train_loss=0.00665, val_loss=0.00663]Epoch 19:  79%|███████▊  | 22/28 [00:00<00:00, 89.76it/s, train_loss=0.00665, val_loss=0.00663]Epoch 19:  79%|███████▊  | 22/28 [00:00<00:00, 87.72it/s, train_loss=0.00804, val_loss=0.00663]Epoch 19:  82%|████████▏ | 23/28 [00:00<00:00, 89.63it/s, train_loss=0.00804, val_loss=0.00663]Epoch 19:  82%|████████▏ | 23/28 [00:00<00:00, 88.44it/s, train_loss=0.00678, val_loss=0.00663]Epoch 19:  86%|████████▌ | 24/28 [00:00<00:00, 90.03it/s, train_loss=0.00678, val_loss=0.00663]Epoch 19:  86%|████████▌ | 24/28 [00:00<00:00, 88.46it/s, train_loss=0.00635, val_loss=0.00663]Epoch 19:  89%|████████▉ | 25/28 [00:00<00:00, 90.22it/s, train_loss=0.00635, val_loss=0.00663]Epoch 19:  89%|████████▉ | 25/28 [00:00<00:00, 88.45it/s, train_loss=0.00773, val_loss=0.00663]Epoch 19:  93%|█████████▎| 26/28 [00:00<00:00, 90.18it/s, train_loss=0.00773, val_loss=0.00663]Epoch 19:  93%|█████████▎| 26/28 [00:00<00:00, 88.43it/s, train_loss=0.0068, val_loss=0.00663] Epoch 19:  96%|█████████▋| 27/28 [00:00<00:00, 89.84it/s, train_loss=0.0068, val_loss=0.00663]Epoch 19:  96%|█████████▋| 27/28 [00:00<00:00, 88.44it/s, train_loss=0.00526, val_loss=0.00663]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 90.00it/s, train_loss=0.00526, val_loss=0.00663]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 88.50it/s, train_loss=0.0075, val_loss=0.00663] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 142.69it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 152.90it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 170.78it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 182.38it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 188.88it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 193.59it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 197.11it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 200.15it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 203.48it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 205.50it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 207.10it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 209.36it/s][A
                                                                         [AEpoch 19: 100%|██████████| 28/28 [00:00<00:00, 73.39it/s, train_loss=0.0075, val_loss=0.00636]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 73.27it/s, train_loss=0.0075, val_loss=0.00636]Epoch 19:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0075, val_loss=0.00636]         Epoch 20:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0075, val_loss=0.00636]Epoch 20:   4%|▎         | 1/28 [00:00<00:00, 161.37it/s, train_loss=0.0075, val_loss=0.00636]Epoch 20:   4%|▎         | 1/28 [00:00<00:00, 90.22it/s, train_loss=0.00714, val_loss=0.00636]Epoch 20:   7%|▋         | 2/28 [00:00<00:00, 109.95it/s, train_loss=0.00714, val_loss=0.00636]Epoch 20:   7%|▋         | 2/28 [00:00<00:00, 86.68it/s, train_loss=0.00996, val_loss=0.00636] Epoch 20:  11%|█         | 3/28 [00:00<00:00, 101.93it/s, train_loss=0.00996, val_loss=0.00636]Epoch 20:  11%|█         | 3/28 [00:00<00:00, 86.65it/s, train_loss=0.00698, val_loss=0.00636] Epoch 20:  14%|█▍        | 4/28 [00:00<00:00, 97.76it/s, train_loss=0.00698, val_loss=0.00636]Epoch 20:  14%|█▍        | 4/28 [00:00<00:00, 86.86it/s, train_loss=0.00755, val_loss=0.00636]Epoch 20:  18%|█▊        | 5/28 [00:00<00:00, 95.43it/s, train_loss=0.00755, val_loss=0.00636]Epoch 20:  18%|█▊        | 5/28 [00:00<00:00, 89.64it/s, train_loss=0.00673, val_loss=0.00636]Epoch 20:  21%|██▏       | 6/28 [00:00<00:00, 95.83it/s, train_loss=0.00673, val_loss=0.00636]Epoch 20:  21%|██▏       | 6/28 [00:00<00:00, 88.05it/s, train_loss=0.00866, val_loss=0.00636]Epoch 20:  25%|██▌       | 7/28 [00:00<00:00, 93.85it/s, train_loss=0.00866, val_loss=0.00636]Epoch 20:  25%|██▌       | 7/28 [00:00<00:00, 88.12it/s, train_loss=0.00444, val_loss=0.00636]Epoch 20:  29%|██▊       | 8/28 [00:00<00:00, 93.24it/s, train_loss=0.00444, val_loss=0.00636]Epoch 20:  29%|██▊       | 8/28 [00:00<00:00, 88.19it/s, train_loss=0.00701, val_loss=0.00636]Epoch 20:  32%|███▏      | 9/28 [00:00<00:00, 92.76it/s, train_loss=0.00701, val_loss=0.00636]Epoch 20:  32%|███▏      | 9/28 [00:00<00:00, 89.87it/s, train_loss=0.00713, val_loss=0.00636]Epoch 20:  36%|███▌      | 10/28 [00:00<00:00, 93.51it/s, train_loss=0.00713, val_loss=0.00636]Epoch 20:  36%|███▌      | 10/28 [00:00<00:00, 88.83it/s, train_loss=0.00592, val_loss=0.00636]Epoch 20:  39%|███▉      | 11/28 [00:00<00:00, 92.43it/s, train_loss=0.00592, val_loss=0.00636]Epoch 20:  39%|███▉      | 11/28 [00:00<00:00, 88.86it/s, train_loss=0.00545, val_loss=0.00636]Epoch 20:  43%|████▎     | 12/28 [00:00<00:00, 92.07it/s, train_loss=0.00545, val_loss=0.00636]Epoch 20:  43%|████▎     | 12/28 [00:00<00:00, 88.86it/s, train_loss=0.00586, val_loss=0.00636]Epoch 20:  46%|████▋     | 13/28 [00:00<00:00, 91.81it/s, train_loss=0.00586, val_loss=0.00636]Epoch 20:  46%|████▋     | 13/28 [00:00<00:00, 90.03it/s, train_loss=0.00783, val_loss=0.00636]Epoch 20:  50%|█████     | 14/28 [00:00<00:00, 92.47it/s, train_loss=0.00783, val_loss=0.00636]Epoch 20:  50%|█████     | 14/28 [00:00<00:00, 89.35it/s, train_loss=0.00696, val_loss=0.00636]Epoch 20:  54%|█████▎    | 15/28 [00:00<00:00, 91.98it/s, train_loss=0.00696, val_loss=0.00636]Epoch 20:  54%|█████▎    | 15/28 [00:00<00:00, 89.31it/s, train_loss=0.0105, val_loss=0.00636] Epoch 20:  57%|█████▋    | 16/28 [00:00<00:00, 91.78it/s, train_loss=0.0105, val_loss=0.00636]Epoch 20:  57%|█████▋    | 16/28 [00:00<00:00, 89.26it/s, train_loss=0.00626, val_loss=0.00636]Epoch 20:  61%|██████    | 17/28 [00:00<00:00, 91.55it/s, train_loss=0.00626, val_loss=0.00636]Epoch 20:  61%|██████    | 17/28 [00:00<00:00, 90.17it/s, train_loss=0.00637, val_loss=0.00636]Epoch 20:  64%|██████▍   | 18/28 [00:00<00:00, 92.09it/s, train_loss=0.00637, val_loss=0.00636]Epoch 20:  64%|██████▍   | 18/28 [00:00<00:00, 89.56it/s, train_loss=0.00508, val_loss=0.00636]Epoch 20:  68%|██████▊   | 19/28 [00:00<00:00, 91.74it/s, train_loss=0.00508, val_loss=0.00636]Epoch 20:  68%|██████▊   | 19/28 [00:00<00:00, 89.49it/s, train_loss=0.00531, val_loss=0.00636]Epoch 20:  71%|███████▏  | 20/28 [00:00<00:00, 91.54it/s, train_loss=0.00531, val_loss=0.00636]Epoch 20:  71%|███████▏  | 20/28 [00:00<00:00, 89.45it/s, train_loss=0.00796, val_loss=0.00636]Epoch 20:  75%|███████▌  | 21/28 [00:00<00:00, 91.42it/s, train_loss=0.00796, val_loss=0.00636]Epoch 20:  75%|███████▌  | 21/28 [00:00<00:00, 89.46it/s, train_loss=0.00692, val_loss=0.00636]Epoch 20:  79%|███████▊  | 22/28 [00:00<00:00, 91.14it/s, train_loss=0.00692, val_loss=0.00636]Epoch 20:  79%|███████▊  | 22/28 [00:00<00:00, 89.39it/s, train_loss=0.00695, val_loss=0.00636]Epoch 20:  82%|████████▏ | 23/28 [00:00<00:00, 91.18it/s, train_loss=0.00695, val_loss=0.00636]Epoch 20:  82%|████████▏ | 23/28 [00:00<00:00, 89.33it/s, train_loss=0.00539, val_loss=0.00636]Epoch 20:  86%|████████▌ | 24/28 [00:00<00:00, 91.04it/s, train_loss=0.00539, val_loss=0.00636]Epoch 20:  86%|████████▌ | 24/28 [00:00<00:00, 89.30it/s, train_loss=0.00795, val_loss=0.00636]Epoch 20:  89%|████████▉ | 25/28 [00:00<00:00, 91.01it/s, train_loss=0.00795, val_loss=0.00636]Epoch 20:  89%|████████▉ | 25/28 [00:00<00:00, 89.29it/s, train_loss=0.0066, val_loss=0.00636] Epoch 20:  93%|█████████▎| 26/28 [00:00<00:00, 90.72it/s, train_loss=0.0066, val_loss=0.00636]Epoch 20:  93%|█████████▎| 26/28 [00:00<00:00, 89.27it/s, train_loss=0.00534, val_loss=0.00636]Epoch 20:  96%|█████████▋| 27/28 [00:00<00:00, 90.67it/s, train_loss=0.00534, val_loss=0.00636]Epoch 20:  96%|█████████▋| 27/28 [00:00<00:00, 89.24it/s, train_loss=0.00562, val_loss=0.00636]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 90.63it/s, train_loss=0.00562, val_loss=0.00636]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 89.94it/s, train_loss=0.00703, val_loss=0.00636]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 164.64it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 194.17it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 208.69it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 216.24it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 220.47it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 223.00it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 225.24it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 226.66it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 226.76it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 227.04it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 227.75it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 228.27it/s][A
                                                                         [AEpoch 20: 100%|██████████| 28/28 [00:00<00:00, 75.09it/s, train_loss=0.00703, val_loss=0.00614]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 74.88it/s, train_loss=0.00703, val_loss=0.00614]Epoch 20:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00703, val_loss=0.00614]         Epoch 21:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00703, val_loss=0.00614]Epoch 21:   4%|▎         | 1/28 [00:00<00:00, 130.75it/s, train_loss=0.00703, val_loss=0.00614]Epoch 21:   4%|▎         | 1/28 [00:00<00:00, 81.21it/s, train_loss=0.0069, val_loss=0.00614]  Epoch 21:   7%|▋         | 2/28 [00:00<00:00, 107.96it/s, train_loss=0.0069, val_loss=0.00614]Epoch 21:   7%|▋         | 2/28 [00:00<00:00, 83.97it/s, train_loss=0.00667, val_loss=0.00614]Epoch 21:  11%|█         | 3/28 [00:00<00:00, 100.84it/s, train_loss=0.00667, val_loss=0.00614]Epoch 21:  11%|█         | 3/28 [00:00<00:00, 85.09it/s, train_loss=0.00673, val_loss=0.00614] Epoch 21:  14%|█▍        | 4/28 [00:00<00:00, 96.29it/s, train_loss=0.00673, val_loss=0.00614]Epoch 21:  14%|█▍        | 4/28 [00:00<00:00, 88.90it/s, train_loss=0.00479, val_loss=0.00614]Epoch 21:  18%|█▊        | 5/28 [00:00<00:00, 96.89it/s, train_loss=0.00479, val_loss=0.00614]Epoch 21:  18%|█▊        | 5/28 [00:00<00:00, 87.31it/s, train_loss=0.00565, val_loss=0.00614]Epoch 21:  21%|██▏       | 6/28 [00:00<00:00, 94.56it/s, train_loss=0.00565, val_loss=0.00614]Epoch 21:  21%|██▏       | 6/28 [00:00<00:00, 87.46it/s, train_loss=0.0078, val_loss=0.00614] Epoch 21:  25%|██▌       | 7/28 [00:00<00:00, 93.59it/s, train_loss=0.0078, val_loss=0.00614]Epoch 21:  25%|██▌       | 7/28 [00:00<00:00, 87.58it/s, train_loss=0.00489, val_loss=0.00614]Epoch 21:  29%|██▊       | 8/28 [00:00<00:00, 92.78it/s, train_loss=0.00489, val_loss=0.00614]Epoch 21:  29%|██▊       | 8/28 [00:00<00:00, 87.83it/s, train_loss=0.00774, val_loss=0.00614]Epoch 21:  32%|███▏      | 9/28 [00:00<00:00, 91.91it/s, train_loss=0.00774, val_loss=0.00614]Epoch 21:  32%|███▏      | 9/28 [00:00<00:00, 87.87it/s, train_loss=0.00854, val_loss=0.00614]Epoch 21:  36%|███▌      | 10/28 [00:00<00:00, 91.10it/s, train_loss=0.00854, val_loss=0.00614]Epoch 21:  36%|███▌      | 10/28 [00:00<00:00, 86.15it/s, train_loss=0.00751, val_loss=0.00614]Epoch 21:  39%|███▉      | 11/28 [00:00<00:00, 90.41it/s, train_loss=0.00751, val_loss=0.00614]Epoch 21:  39%|███▉      | 11/28 [00:00<00:00, 86.39it/s, train_loss=0.00597, val_loss=0.00614]Epoch 21:  43%|████▎     | 12/28 [00:00<00:00, 90.06it/s, train_loss=0.00597, val_loss=0.00614]Epoch 21:  43%|████▎     | 12/28 [00:00<00:00, 85.60it/s, train_loss=0.00694, val_loss=0.00614]Epoch 21:  46%|████▋     | 13/28 [00:00<00:00, 89.07it/s, train_loss=0.00694, val_loss=0.00614]Epoch 21:  46%|████▋     | 13/28 [00:00<00:00, 85.81it/s, train_loss=0.00574, val_loss=0.00614]Epoch 21:  50%|█████     | 14/28 [00:00<00:00, 88.97it/s, train_loss=0.00574, val_loss=0.00614]Epoch 21:  50%|█████     | 14/28 [00:00<00:00, 86.00it/s, train_loss=0.00749, val_loss=0.00614]Epoch 21:  54%|█████▎    | 15/28 [00:00<00:00, 89.09it/s, train_loss=0.00749, val_loss=0.00614]Epoch 21:  54%|█████▎    | 15/28 [00:00<00:00, 87.19it/s, train_loss=0.00728, val_loss=0.00614]Epoch 21:  57%|█████▋    | 16/28 [00:00<00:00, 89.85it/s, train_loss=0.00728, val_loss=0.00614]Epoch 21:  57%|█████▋    | 16/28 [00:00<00:00, 86.74it/s, train_loss=0.00736, val_loss=0.00614]Epoch 21:  61%|██████    | 17/28 [00:00<00:00, 89.39it/s, train_loss=0.00736, val_loss=0.00614]Epoch 21:  61%|██████    | 17/28 [00:00<00:00, 86.81it/s, train_loss=0.0067, val_loss=0.00614] Epoch 21:  64%|██████▍   | 18/28 [00:00<00:00, 89.26it/s, train_loss=0.0067, val_loss=0.00614]Epoch 21:  64%|██████▍   | 18/28 [00:00<00:00, 86.90it/s, train_loss=0.00742, val_loss=0.00614]Epoch 21:  68%|██████▊   | 19/28 [00:00<00:00, 89.32it/s, train_loss=0.00742, val_loss=0.00614]Epoch 21:  68%|██████▊   | 19/28 [00:00<00:00, 87.82it/s, train_loss=0.00809, val_loss=0.00614]Epoch 21:  71%|███████▏  | 20/28 [00:00<00:00, 89.98it/s, train_loss=0.00809, val_loss=0.00614]Epoch 21:  71%|███████▏  | 20/28 [00:00<00:00, 87.40it/s, train_loss=0.00694, val_loss=0.00614]Epoch 21:  75%|███████▌  | 21/28 [00:00<00:00, 89.53it/s, train_loss=0.00694, val_loss=0.00614]Epoch 21:  75%|███████▌  | 21/28 [00:00<00:00, 87.46it/s, train_loss=0.00692, val_loss=0.00614]Epoch 21:  79%|███████▊  | 22/28 [00:00<00:00, 89.64it/s, train_loss=0.00692, val_loss=0.00614]Epoch 21:  79%|███████▊  | 22/28 [00:00<00:00, 87.52it/s, train_loss=0.00501, val_loss=0.00614]Epoch 21:  82%|████████▏ | 23/28 [00:00<00:00, 89.59it/s, train_loss=0.00501, val_loss=0.00614]Epoch 21:  82%|████████▏ | 23/28 [00:00<00:00, 87.62it/s, train_loss=0.0055, val_loss=0.00614] Epoch 21:  86%|████████▌ | 24/28 [00:00<00:00, 89.29it/s, train_loss=0.0055, val_loss=0.00614]Epoch 21:  86%|████████▌ | 24/28 [00:00<00:00, 87.66it/s, train_loss=0.00501, val_loss=0.00614]Epoch 21:  89%|████████▉ | 25/28 [00:00<00:00, 89.51it/s, train_loss=0.00501, val_loss=0.00614]Epoch 21:  89%|████████▉ | 25/28 [00:00<00:00, 87.66it/s, train_loss=0.0073, val_loss=0.00614] Epoch 21:  93%|█████████▎| 26/28 [00:00<00:00, 89.43it/s, train_loss=0.0073, val_loss=0.00614]Epoch 21:  93%|█████████▎| 26/28 [00:00<00:00, 87.70it/s, train_loss=0.00723, val_loss=0.00614]Epoch 21:  96%|█████████▋| 27/28 [00:00<00:00, 89.39it/s, train_loss=0.00723, val_loss=0.00614]Epoch 21:  96%|█████████▋| 27/28 [00:00<00:00, 88.22it/s, train_loss=0.00538, val_loss=0.00614]Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 89.62it/s, train_loss=0.00538, val_loss=0.00614]Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 88.93it/s, train_loss=0.00698, val_loss=0.00614]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 171.44it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 204.97it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 220.24it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 227.85it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 231.54it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 233.22it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 235.56it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 237.30it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 238.41it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 239.10it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 239.50it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 240.60it/s][A
                                                                         [AEpoch 21: 100%|██████████| 28/28 [00:00<00:00, 75.03it/s, train_loss=0.00698, val_loss=0.00586]Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 74.85it/s, train_loss=0.00698, val_loss=0.00586]Epoch 21:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00698, val_loss=0.00586]         Epoch 22:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00698, val_loss=0.00586]Epoch 22:   4%|▎         | 1/28 [00:00<00:00, 137.69it/s, train_loss=0.00698, val_loss=0.00586]Epoch 22:   4%|▎         | 1/28 [00:00<00:00, 81.82it/s, train_loss=0.0066, val_loss=0.00586]  Epoch 22:   7%|▋         | 2/28 [00:00<00:00, 111.77it/s, train_loss=0.0066, val_loss=0.00586]Epoch 22:   7%|▋         | 2/28 [00:00<00:00, 84.86it/s, train_loss=0.00564, val_loss=0.00586]Epoch 22:  11%|█         | 3/28 [00:00<00:00, 102.74it/s, train_loss=0.00564, val_loss=0.00586]Epoch 22:  11%|█         | 3/28 [00:00<00:00, 86.04it/s, train_loss=0.00622, val_loss=0.00586] Epoch 22:  14%|█▍        | 4/28 [00:00<00:00, 99.67it/s, train_loss=0.00622, val_loss=0.00586]Epoch 22:  14%|█▍        | 4/28 [00:00<00:00, 90.12it/s, train_loss=0.00774, val_loss=0.00586]Epoch 22:  18%|█▊        | 5/28 [00:00<00:00, 99.06it/s, train_loss=0.00774, val_loss=0.00586]Epoch 22:  18%|█▊        | 5/28 [00:00<00:00, 88.20it/s, train_loss=0.00909, val_loss=0.00586]Epoch 22:  21%|██▏       | 6/28 [00:00<00:00, 96.61it/s, train_loss=0.00909, val_loss=0.00586]Epoch 22:  21%|██▏       | 6/28 [00:00<00:00, 88.26it/s, train_loss=0.00526, val_loss=0.00586]Epoch 22:  25%|██▌       | 7/28 [00:00<00:00, 95.29it/s, train_loss=0.00526, val_loss=0.00586]Epoch 22:  25%|██▌       | 7/28 [00:00<00:00, 88.33it/s, train_loss=0.00568, val_loss=0.00586]Epoch 22:  29%|██▊       | 8/28 [00:00<00:00, 94.58it/s, train_loss=0.00568, val_loss=0.00586]Epoch 22:  29%|██▊       | 8/28 [00:00<00:00, 88.54it/s, train_loss=0.00675, val_loss=0.00586]Epoch 22:  32%|███▏      | 9/28 [00:00<00:00, 93.11it/s, train_loss=0.00675, val_loss=0.00586]Epoch 22:  32%|███▏      | 9/28 [00:00<00:00, 88.50it/s, train_loss=0.00625, val_loss=0.00586]Epoch 22:  36%|███▌      | 10/28 [00:00<00:00, 93.31it/s, train_loss=0.00625, val_loss=0.00586]Epoch 22:  36%|███▌      | 10/28 [00:00<00:00, 88.44it/s, train_loss=0.00593, val_loss=0.00586]Epoch 22:  39%|███▉      | 11/28 [00:00<00:00, 92.85it/s, train_loss=0.00593, val_loss=0.00586]Epoch 22:  39%|███▉      | 11/28 [00:00<00:00, 88.41it/s, train_loss=0.00693, val_loss=0.00586]Epoch 22:  43%|████▎     | 12/28 [00:00<00:00, 92.15it/s, train_loss=0.00693, val_loss=0.00586]Epoch 22:  43%|████▎     | 12/28 [00:00<00:00, 89.66it/s, train_loss=0.00521, val_loss=0.00586]Epoch 22:  46%|████▋     | 13/28 [00:00<00:00, 92.73it/s, train_loss=0.00521, val_loss=0.00586]Epoch 22:  46%|████▋     | 13/28 [00:00<00:00, 89.59it/s, train_loss=0.00633, val_loss=0.00586]Epoch 22:  50%|█████     | 14/28 [00:00<00:00, 92.92it/s, train_loss=0.00633, val_loss=0.00586]Epoch 22:  50%|█████     | 14/28 [00:00<00:00, 89.50it/s, train_loss=0.00706, val_loss=0.00586]Epoch 22:  54%|█████▎    | 15/28 [00:00<00:00, 92.56it/s, train_loss=0.00706, val_loss=0.00586]Epoch 22:  54%|█████▎    | 15/28 [00:00<00:00, 89.46it/s, train_loss=0.00508, val_loss=0.00586]Epoch 22:  57%|█████▋    | 16/28 [00:00<00:00, 92.05it/s, train_loss=0.00508, val_loss=0.00586]Epoch 22:  57%|█████▋    | 16/28 [00:00<00:00, 89.38it/s, train_loss=0.00745, val_loss=0.00586]Epoch 22:  61%|██████    | 17/28 [00:00<00:00, 92.05it/s, train_loss=0.00745, val_loss=0.00586]Epoch 22:  61%|██████    | 17/28 [00:00<00:00, 89.31it/s, train_loss=0.00711, val_loss=0.00586]Epoch 22:  64%|██████▍   | 18/28 [00:00<00:00, 91.87it/s, train_loss=0.00711, val_loss=0.00586]Epoch 22:  64%|██████▍   | 18/28 [00:00<00:00, 89.24it/s, train_loss=0.0052, val_loss=0.00586] Epoch 22:  68%|██████▊   | 19/28 [00:00<00:00, 91.60it/s, train_loss=0.0052, val_loss=0.00586]Epoch 22:  68%|██████▊   | 19/28 [00:00<00:00, 89.24it/s, train_loss=0.00454, val_loss=0.00586]Epoch 22:  71%|███████▏  | 20/28 [00:00<00:00, 91.14it/s, train_loss=0.00454, val_loss=0.00586]Epoch 22:  71%|███████▏  | 20/28 [00:00<00:00, 88.48it/s, train_loss=0.00663, val_loss=0.00586]Epoch 22:  75%|███████▌  | 21/28 [00:00<00:00, 90.60it/s, train_loss=0.00663, val_loss=0.00586]Epoch 22:  75%|███████▌  | 21/28 [00:00<00:00, 88.45it/s, train_loss=0.00447, val_loss=0.00586]Epoch 22:  79%|███████▊  | 22/28 [00:00<00:00, 90.51it/s, train_loss=0.00447, val_loss=0.00586]Epoch 22:  79%|███████▊  | 22/28 [00:00<00:00, 88.45it/s, train_loss=0.00436, val_loss=0.00586]Epoch 22:  82%|████████▏ | 23/28 [00:00<00:00, 90.53it/s, train_loss=0.00436, val_loss=0.00586]Epoch 22:  82%|████████▏ | 23/28 [00:00<00:00, 88.45it/s, train_loss=0.00828, val_loss=0.00586]Epoch 22:  86%|████████▌ | 24/28 [00:00<00:00, 90.18it/s, train_loss=0.00828, val_loss=0.00586]Epoch 22:  86%|████████▌ | 24/28 [00:00<00:00, 88.42it/s, train_loss=0.00672, val_loss=0.00586]Epoch 22:  89%|████████▉ | 25/28 [00:00<00:00, 90.36it/s, train_loss=0.00672, val_loss=0.00586]Epoch 22:  89%|████████▉ | 25/28 [00:00<00:00, 88.41it/s, train_loss=0.00811, val_loss=0.00586]Epoch 22:  93%|█████████▎| 26/28 [00:00<00:00, 90.26it/s, train_loss=0.00811, val_loss=0.00586]Epoch 22:  93%|█████████▎| 26/28 [00:00<00:00, 88.40it/s, train_loss=0.00716, val_loss=0.00586]Epoch 22:  96%|█████████▋| 27/28 [00:00<00:00, 90.09it/s, train_loss=0.00716, val_loss=0.00586]Epoch 22:  96%|█████████▋| 27/28 [00:00<00:00, 88.94it/s, train_loss=0.00815, val_loss=0.00586]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 90.38it/s, train_loss=0.00815, val_loss=0.00586]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 88.96it/s, train_loss=0.0057, val_loss=0.00586] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 177.26it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 169.13it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 160.32it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 174.68it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 186.51it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 193.97it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 198.73it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 202.13it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 206.03it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 209.15it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 211.74it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 214.44it/s][A
                                                                         [AEpoch 22: 100%|██████████| 28/28 [00:00<00:00, 73.90it/s, train_loss=0.0057, val_loss=0.00571]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 73.72it/s, train_loss=0.0057, val_loss=0.00571]Epoch 22:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0057, val_loss=0.00571]         Epoch 23:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0057, val_loss=0.00571]Epoch 23:   4%|▎         | 1/28 [00:00<00:00, 142.75it/s, train_loss=0.0057, val_loss=0.00571]Epoch 23:   4%|▎         | 1/28 [00:00<00:00, 72.73it/s, train_loss=0.00576, val_loss=0.00571]Epoch 23:   7%|▋         | 2/28 [00:00<00:00, 98.17it/s, train_loss=0.00576, val_loss=0.00571]Epoch 23:   7%|▋         | 2/28 [00:00<00:00, 86.27it/s, train_loss=0.00576, val_loss=0.00571]Epoch 23:  11%|█         | 3/28 [00:00<00:00, 101.83it/s, train_loss=0.00576, val_loss=0.00571]Epoch 23:  11%|█         | 3/28 [00:00<00:00, 86.85it/s, train_loss=0.0059, val_loss=0.00571]  Epoch 23:  14%|█▍        | 4/28 [00:00<00:00, 99.44it/s, train_loss=0.0059, val_loss=0.00571]Epoch 23:  14%|█▍        | 4/28 [00:00<00:00, 87.17it/s, train_loss=0.00517, val_loss=0.00571]Epoch 23:  18%|█▊        | 5/28 [00:00<00:00, 96.87it/s, train_loss=0.00517, val_loss=0.00571]Epoch 23:  18%|█▊        | 5/28 [00:00<00:00, 87.40it/s, train_loss=0.00661, val_loss=0.00571]Epoch 23:  21%|██▏       | 6/28 [00:00<00:00, 95.78it/s, train_loss=0.00661, val_loss=0.00571]Epoch 23:  21%|██▏       | 6/28 [00:00<00:00, 89.81it/s, train_loss=0.00634, val_loss=0.00571]Epoch 23:  25%|██▌       | 7/28 [00:00<00:00, 95.87it/s, train_loss=0.00634, val_loss=0.00571]Epoch 23:  25%|██▌       | 7/28 [00:00<00:00, 89.58it/s, train_loss=0.0055, val_loss=0.00571] Epoch 23:  29%|██▊       | 8/28 [00:00<00:00, 95.78it/s, train_loss=0.0055, val_loss=0.00571]Epoch 23:  29%|██▊       | 8/28 [00:00<00:00, 89.45it/s, train_loss=0.00596, val_loss=0.00571]Epoch 23:  32%|███▏      | 9/28 [00:00<00:00, 94.89it/s, train_loss=0.00596, val_loss=0.00571]Epoch 23:  32%|███▏      | 9/28 [00:00<00:00, 89.35it/s, train_loss=0.00597, val_loss=0.00571]Epoch 23:  36%|███▌      | 10/28 [00:00<00:00, 93.47it/s, train_loss=0.00597, val_loss=0.00571]Epoch 23:  36%|███▌      | 10/28 [00:00<00:00, 89.49it/s, train_loss=0.00719, val_loss=0.00571]Epoch 23:  39%|███▉      | 11/28 [00:00<00:00, 93.85it/s, train_loss=0.00719, val_loss=0.00571]Epoch 23:  39%|███▉      | 11/28 [00:00<00:00, 89.37it/s, train_loss=0.00664, val_loss=0.00571]Epoch 23:  43%|████▎     | 12/28 [00:00<00:00, 93.43it/s, train_loss=0.00664, val_loss=0.00571]Epoch 23:  43%|████▎     | 12/28 [00:00<00:00, 89.26it/s, train_loss=0.00635, val_loss=0.00571]Epoch 23:  46%|████▋     | 13/28 [00:00<00:00, 92.89it/s, train_loss=0.00635, val_loss=0.00571]Epoch 23:  46%|████▋     | 13/28 [00:00<00:00, 89.27it/s, train_loss=0.00671, val_loss=0.00571]Epoch 23:  50%|█████     | 14/28 [00:00<00:00, 92.14it/s, train_loss=0.00671, val_loss=0.00571]Epoch 23:  50%|█████     | 14/28 [00:00<00:00, 88.55it/s, train_loss=0.0066, val_loss=0.00571] Epoch 23:  54%|█████▎    | 15/28 [00:00<00:00, 91.64it/s, train_loss=0.0066, val_loss=0.00571]Epoch 23:  54%|█████▎    | 15/28 [00:00<00:00, 88.49it/s, train_loss=0.00722, val_loss=0.00571]Epoch 23:  57%|█████▋    | 16/28 [00:00<00:00, 91.37it/s, train_loss=0.00722, val_loss=0.00571]Epoch 23:  57%|█████▋    | 16/28 [00:00<00:00, 88.48it/s, train_loss=0.00774, val_loss=0.00571]Epoch 23:  61%|██████    | 17/28 [00:00<00:00, 91.15it/s, train_loss=0.00774, val_loss=0.00571]Epoch 23:  61%|██████    | 17/28 [00:00<00:00, 89.36it/s, train_loss=0.00479, val_loss=0.00571]Epoch 23:  64%|██████▍   | 18/28 [00:00<00:00, 91.63it/s, train_loss=0.00479, val_loss=0.00571]Epoch 23:  64%|██████▍   | 18/28 [00:00<00:00, 88.86it/s, train_loss=0.00652, val_loss=0.00571]Epoch 23:  68%|██████▊   | 19/28 [00:00<00:00, 91.27it/s, train_loss=0.00652, val_loss=0.00571]Epoch 23:  68%|██████▊   | 19/28 [00:00<00:00, 88.83it/s, train_loss=0.00448, val_loss=0.00571]Epoch 23:  71%|███████▏  | 20/28 [00:00<00:00, 91.10it/s, train_loss=0.00448, val_loss=0.00571]Epoch 23:  71%|███████▏  | 20/28 [00:00<00:00, 88.85it/s, train_loss=0.00731, val_loss=0.00571]Epoch 23:  75%|███████▌  | 21/28 [00:00<00:00, 91.03it/s, train_loss=0.00731, val_loss=0.00571]Epoch 23:  75%|███████▌  | 21/28 [00:00<00:00, 88.80it/s, train_loss=0.00524, val_loss=0.00571]Epoch 23:  79%|███████▊  | 22/28 [00:00<00:00, 90.50it/s, train_loss=0.00524, val_loss=0.00571]Epoch 23:  79%|███████▊  | 22/28 [00:00<00:00, 88.77it/s, train_loss=0.00636, val_loss=0.00571]Epoch 23:  82%|████████▏ | 23/28 [00:00<00:00, 90.66it/s, train_loss=0.00636, val_loss=0.00571]Epoch 23:  82%|████████▏ | 23/28 [00:00<00:00, 88.73it/s, train_loss=0.00814, val_loss=0.00571]Epoch 23:  86%|████████▌ | 24/28 [00:00<00:00, 90.50it/s, train_loss=0.00814, val_loss=0.00571]Epoch 23:  86%|████████▌ | 24/28 [00:00<00:00, 88.74it/s, train_loss=0.00742, val_loss=0.00571]Epoch 23:  89%|████████▉ | 25/28 [00:00<00:00, 90.60it/s, train_loss=0.00742, val_loss=0.00571]Epoch 23:  89%|████████▉ | 25/28 [00:00<00:00, 89.25it/s, train_loss=0.00613, val_loss=0.00571]Epoch 23:  93%|█████████▎| 26/28 [00:00<00:00, 90.88it/s, train_loss=0.00613, val_loss=0.00571]Epoch 23:  93%|█████████▎| 26/28 [00:00<00:00, 89.22it/s, train_loss=0.00445, val_loss=0.00571]Epoch 23:  96%|█████████▋| 27/28 [00:00<00:00, 90.96it/s, train_loss=0.00445, val_loss=0.00571]Epoch 23:  96%|█████████▋| 27/28 [00:00<00:00, 89.18it/s, train_loss=0.00682, val_loss=0.00571]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 90.85it/s, train_loss=0.00682, val_loss=0.00571]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 89.88it/s, train_loss=0.00626, val_loss=0.00571]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 192.21it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 220.07it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 228.63it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 232.37it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 235.78it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 237.27it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 237.77it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 238.15it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 237.95it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 225.49it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 212.05it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 214.28it/s][A
                                                                         [AEpoch 23: 100%|██████████| 28/28 [00:00<00:00, 74.63it/s, train_loss=0.00626, val_loss=0.00559]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 74.47it/s, train_loss=0.00626, val_loss=0.00559]Epoch 23:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00626, val_loss=0.00559]         Epoch 24:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00626, val_loss=0.00559]Epoch 24:   4%|▎         | 1/28 [00:00<00:00, 132.62it/s, train_loss=0.00626, val_loss=0.00559]Epoch 24:   4%|▎         | 1/28 [00:00<00:00, 78.03it/s, train_loss=0.0076, val_loss=0.00559]  Epoch 24:   7%|▋         | 2/28 [00:00<00:00, 107.83it/s, train_loss=0.0076, val_loss=0.00559]Epoch 24:   7%|▋         | 2/28 [00:00<00:00, 81.94it/s, train_loss=0.00516, val_loss=0.00559]Epoch 24:  11%|█         | 3/28 [00:00<00:00, 99.64it/s, train_loss=0.00516, val_loss=0.00559]Epoch 24:  11%|█         | 3/28 [00:00<00:00, 83.66it/s, train_loss=0.00766, val_loss=0.00559]Epoch 24:  14%|█▍        | 4/28 [00:00<00:00, 96.18it/s, train_loss=0.00766, val_loss=0.00559]Epoch 24:  14%|█▍        | 4/28 [00:00<00:00, 87.18it/s, train_loss=0.0049, val_loss=0.00559] Epoch 24:  18%|█▊        | 5/28 [00:00<00:00, 94.01it/s, train_loss=0.0049, val_loss=0.00559]Epoch 24:  18%|█▊        | 5/28 [00:00<00:00, 85.21it/s, train_loss=0.00574, val_loss=0.00559]Epoch 24:  21%|██▏       | 6/28 [00:00<00:00, 93.16it/s, train_loss=0.00574, val_loss=0.00559]Epoch 24:  21%|██▏       | 6/28 [00:00<00:00, 85.73it/s, train_loss=0.0051, val_loss=0.00559] Epoch 24:  25%|██▌       | 7/28 [00:00<00:00, 92.41it/s, train_loss=0.0051, val_loss=0.00559]Epoch 24:  25%|██▌       | 7/28 [00:00<00:00, 86.10it/s, train_loss=0.0049, val_loss=0.00559]Epoch 24:  29%|██▊       | 8/28 [00:00<00:00, 91.81it/s, train_loss=0.0049, val_loss=0.00559]Epoch 24:  29%|██▊       | 8/28 [00:00<00:00, 88.19it/s, train_loss=0.00648, val_loss=0.00559]Epoch 24:  32%|███▏      | 9/28 [00:00<00:00, 92.62it/s, train_loss=0.00648, val_loss=0.00559]Epoch 24:  32%|███▏      | 9/28 [00:00<00:00, 87.68it/s, train_loss=0.00503, val_loss=0.00559]Epoch 24:  36%|███▌      | 10/28 [00:00<00:00, 92.61it/s, train_loss=0.00503, val_loss=0.00559]Epoch 24:  36%|███▌      | 10/28 [00:00<00:00, 87.79it/s, train_loss=0.00496, val_loss=0.00559]Epoch 24:  39%|███▉      | 11/28 [00:00<00:00, 92.22it/s, train_loss=0.00496, val_loss=0.00559]Epoch 24:  39%|███▉      | 11/28 [00:00<00:00, 87.88it/s, train_loss=0.00623, val_loss=0.00559]Epoch 24:  43%|████▎     | 12/28 [00:00<00:00, 91.83it/s, train_loss=0.00623, val_loss=0.00559]Epoch 24:  43%|████▎     | 12/28 [00:00<00:00, 89.25it/s, train_loss=0.0052, val_loss=0.00559] Epoch 24:  46%|████▋     | 13/28 [00:00<00:00, 92.22it/s, train_loss=0.0052, val_loss=0.00559]Epoch 24:  46%|████▋     | 13/28 [00:00<00:00, 88.48it/s, train_loss=0.00527, val_loss=0.00559]Epoch 24:  50%|█████     | 14/28 [00:00<00:00, 91.84it/s, train_loss=0.00527, val_loss=0.00559]Epoch 24:  50%|█████     | 14/28 [00:00<00:00, 88.50it/s, train_loss=0.00433, val_loss=0.00559]Epoch 24:  54%|█████▎    | 15/28 [00:00<00:00, 91.64it/s, train_loss=0.00433, val_loss=0.00559]Epoch 24:  54%|█████▎    | 15/28 [00:00<00:00, 88.51it/s, train_loss=0.00497, val_loss=0.00559]Epoch 24:  57%|█████▋    | 16/28 [00:00<00:00, 91.46it/s, train_loss=0.00497, val_loss=0.00559]Epoch 24:  57%|█████▋    | 16/28 [00:00<00:00, 88.50it/s, train_loss=0.00865, val_loss=0.00559]Epoch 24:  61%|██████    | 17/28 [00:00<00:00, 90.74it/s, train_loss=0.00865, val_loss=0.00559]Epoch 24:  61%|██████    | 17/28 [00:00<00:00, 88.52it/s, train_loss=0.00564, val_loss=0.00559]Epoch 24:  64%|██████▍   | 18/28 [00:00<00:00, 91.11it/s, train_loss=0.00564, val_loss=0.00559]Epoch 24:  64%|██████▍   | 18/28 [00:00<00:00, 88.49it/s, train_loss=0.00562, val_loss=0.00559]Epoch 24:  68%|██████▊   | 19/28 [00:00<00:00, 90.86it/s, train_loss=0.00562, val_loss=0.00559]Epoch 24:  68%|██████▊   | 19/28 [00:00<00:00, 88.50it/s, train_loss=0.00765, val_loss=0.00559]Epoch 24:  71%|███████▏  | 20/28 [00:00<00:00, 90.40it/s, train_loss=0.00765, val_loss=0.00559]Epoch 24:  71%|███████▏  | 20/28 [00:00<00:00, 88.53it/s, train_loss=0.00566, val_loss=0.00559]Epoch 24:  75%|███████▌  | 21/28 [00:00<00:00, 90.69it/s, train_loss=0.00566, val_loss=0.00559]Epoch 24:  75%|███████▌  | 21/28 [00:00<00:00, 88.51it/s, train_loss=0.00664, val_loss=0.00559]Epoch 24:  79%|███████▊  | 22/28 [00:00<00:00, 90.58it/s, train_loss=0.00664, val_loss=0.00559]Epoch 24:  79%|███████▊  | 22/28 [00:00<00:00, 88.47it/s, train_loss=0.00684, val_loss=0.00559]Epoch 24:  82%|████████▏ | 23/28 [00:00<00:00, 90.39it/s, train_loss=0.00684, val_loss=0.00559]Epoch 24:  82%|████████▏ | 23/28 [00:00<00:00, 88.48it/s, train_loss=0.00794, val_loss=0.00559]Epoch 24:  86%|████████▌ | 24/28 [00:00<00:00, 89.96it/s, train_loss=0.00794, val_loss=0.00559]Epoch 24:  86%|████████▌ | 24/28 [00:00<00:00, 88.56it/s, train_loss=0.00572, val_loss=0.00559]Epoch 24:  89%|████████▉ | 25/28 [00:00<00:00, 90.32it/s, train_loss=0.00572, val_loss=0.00559]Epoch 24:  89%|████████▉ | 25/28 [00:00<00:00, 88.55it/s, train_loss=0.0064, val_loss=0.00559] Epoch 24:  93%|█████████▎| 26/28 [00:00<00:00, 90.25it/s, train_loss=0.0064, val_loss=0.00559]Epoch 24:  93%|█████████▎| 26/28 [00:00<00:00, 88.53it/s, train_loss=0.00731, val_loss=0.00559]Epoch 24:  96%|█████████▋| 27/28 [00:00<00:00, 90.16it/s, train_loss=0.00731, val_loss=0.00559]Epoch 24:  96%|█████████▋| 27/28 [00:00<00:00, 88.52it/s, train_loss=0.00528, val_loss=0.00559]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 89.84it/s, train_loss=0.00528, val_loss=0.00559]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 88.03it/s, train_loss=0.00639, val_loss=0.00559]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 191.06it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 226.30it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 238.78it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 245.84it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 249.12it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 248.75it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 248.59it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 248.50it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 249.12it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 249.88it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 249.12it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 249.91it/s][A
                                                                         [AEpoch 24: 100%|██████████| 28/28 [00:00<00:00, 74.83it/s, train_loss=0.00639, val_loss=0.00542]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 74.65it/s, train_loss=0.00639, val_loss=0.00542]Epoch 24:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00639, val_loss=0.00542]         Epoch 25:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00639, val_loss=0.00542]Epoch 25:   4%|▎         | 1/28 [00:00<00:00, 128.59it/s, train_loss=0.00639, val_loss=0.00542]Epoch 25:   4%|▎         | 1/28 [00:00<00:00, 79.27it/s, train_loss=0.00474, val_loss=0.00542] Epoch 25:   7%|▋         | 2/28 [00:00<00:00, 110.69it/s, train_loss=0.00474, val_loss=0.00542]Epoch 25:   7%|▋         | 2/28 [00:00<00:00, 83.36it/s, train_loss=0.00574, val_loss=0.00542] Epoch 25:  11%|█         | 3/28 [00:00<00:00, 99.27it/s, train_loss=0.00574, val_loss=0.00542]Epoch 25:  11%|█         | 3/28 [00:00<00:00, 84.94it/s, train_loss=0.00622, val_loss=0.00542]Epoch 25:  14%|█▍        | 4/28 [00:00<00:00, 97.05it/s, train_loss=0.00622, val_loss=0.00542]Epoch 25:  14%|█▍        | 4/28 [00:00<00:00, 89.60it/s, train_loss=0.0053, val_loss=0.00542] Epoch 25:  18%|█▊        | 5/28 [00:00<00:00, 97.33it/s, train_loss=0.0053, val_loss=0.00542]Epoch 25:  18%|█▊        | 5/28 [00:00<00:00, 88.42it/s, train_loss=0.00691, val_loss=0.00542]Epoch 25:  21%|██▏       | 6/28 [00:00<00:00, 96.44it/s, train_loss=0.00691, val_loss=0.00542]Epoch 25:  21%|██▏       | 6/28 [00:00<00:00, 88.35it/s, train_loss=0.00654, val_loss=0.00542]Epoch 25:  25%|██▌       | 7/28 [00:00<00:00, 95.11it/s, train_loss=0.00654, val_loss=0.00542]Epoch 25:  25%|██▌       | 7/28 [00:00<00:00, 88.37it/s, train_loss=0.00495, val_loss=0.00542]Epoch 25:  29%|██▊       | 8/28 [00:00<00:00, 94.14it/s, train_loss=0.00495, val_loss=0.00542]Epoch 25:  29%|██▊       | 8/28 [00:00<00:00, 90.48it/s, train_loss=0.0063, val_loss=0.00542] Epoch 25:  32%|███▏      | 9/28 [00:00<00:00, 94.39it/s, train_loss=0.0063, val_loss=0.00542]Epoch 25:  32%|███▏      | 9/28 [00:00<00:00, 89.72it/s, train_loss=0.00654, val_loss=0.00542]Epoch 25:  36%|███▌      | 10/28 [00:00<00:00, 94.40it/s, train_loss=0.00654, val_loss=0.00542]Epoch 25:  36%|███▌      | 10/28 [00:00<00:00, 89.62it/s, train_loss=0.00702, val_loss=0.00542]Epoch 25:  39%|███▉      | 11/28 [00:00<00:00, 94.16it/s, train_loss=0.00702, val_loss=0.00542]Epoch 25:  39%|███▉      | 11/28 [00:00<00:00, 89.56it/s, train_loss=0.00508, val_loss=0.00542]Epoch 25:  43%|████▎     | 12/28 [00:00<00:00, 93.65it/s, train_loss=0.00508, val_loss=0.00542]Epoch 25:  43%|████▎     | 12/28 [00:00<00:00, 89.57it/s, train_loss=0.00669, val_loss=0.00542]Epoch 25:  46%|████▋     | 13/28 [00:00<00:00, 92.59it/s, train_loss=0.00669, val_loss=0.00542]Epoch 25:  46%|████▋     | 13/28 [00:00<00:00, 89.45it/s, train_loss=0.00686, val_loss=0.00542]Epoch 25:  50%|█████     | 14/28 [00:00<00:00, 92.82it/s, train_loss=0.00686, val_loss=0.00542]Epoch 25:  50%|█████     | 14/28 [00:00<00:00, 89.34it/s, train_loss=0.00667, val_loss=0.00542]Epoch 25:  54%|█████▎    | 15/28 [00:00<00:00, 90.98it/s, train_loss=0.00667, val_loss=0.00542]Epoch 25:  54%|█████▎    | 15/28 [00:00<00:00, 88.22it/s, train_loss=0.00775, val_loss=0.00542]Epoch 25:  57%|█████▋    | 16/28 [00:00<00:00, 90.42it/s, train_loss=0.00775, val_loss=0.00542]Epoch 25:  57%|█████▋    | 16/28 [00:00<00:00, 87.34it/s, train_loss=0.00567, val_loss=0.00542]Epoch 25:  61%|██████    | 17/28 [00:00<00:00, 90.03it/s, train_loss=0.00567, val_loss=0.00542]Epoch 25:  61%|██████    | 17/28 [00:00<00:00, 87.42it/s, train_loss=0.00663, val_loss=0.00542]Epoch 25:  64%|██████▍   | 18/28 [00:00<00:00, 89.99it/s, train_loss=0.00663, val_loss=0.00542]Epoch 25:  64%|██████▍   | 18/28 [00:00<00:00, 87.44it/s, train_loss=0.005, val_loss=0.00542]  Epoch 25:  68%|██████▊   | 19/28 [00:00<00:00, 89.87it/s, train_loss=0.005, val_loss=0.00542]Epoch 25:  68%|██████▊   | 19/28 [00:00<00:00, 87.47it/s, train_loss=0.00607, val_loss=0.00542]Epoch 25:  71%|███████▏  | 20/28 [00:00<00:00, 89.28it/s, train_loss=0.00607, val_loss=0.00542]Epoch 25:  71%|███████▏  | 20/28 [00:00<00:00, 87.51it/s, train_loss=0.00585, val_loss=0.00542]Epoch 25:  75%|███████▌  | 21/28 [00:00<00:00, 89.61it/s, train_loss=0.00585, val_loss=0.00542]Epoch 25:  75%|███████▌  | 21/28 [00:00<00:00, 87.56it/s, train_loss=0.00722, val_loss=0.00542]Epoch 25:  79%|███████▊  | 22/28 [00:00<00:00, 89.60it/s, train_loss=0.00722, val_loss=0.00542]Epoch 25:  79%|███████▊  | 22/28 [00:00<00:00, 87.61it/s, train_loss=0.00541, val_loss=0.00542]Epoch 25:  82%|████████▏ | 23/28 [00:00<00:00, 89.43it/s, train_loss=0.00541, val_loss=0.00542]Epoch 25:  82%|████████▏ | 23/28 [00:00<00:00, 88.29it/s, train_loss=0.00588, val_loss=0.00542]Epoch 25:  86%|████████▌ | 24/28 [00:00<00:00, 89.81it/s, train_loss=0.00588, val_loss=0.00542]Epoch 25:  86%|████████▌ | 24/28 [00:00<00:00, 88.31it/s, train_loss=0.00472, val_loss=0.00542]Epoch 25:  89%|████████▉ | 25/28 [00:00<00:00, 90.11it/s, train_loss=0.00472, val_loss=0.00542]Epoch 25:  89%|████████▉ | 25/28 [00:00<00:00, 88.32it/s, train_loss=0.00604, val_loss=0.00542]Epoch 25:  93%|█████████▎| 26/28 [00:00<00:00, 90.05it/s, train_loss=0.00604, val_loss=0.00542]Epoch 25:  93%|█████████▎| 26/28 [00:00<00:00, 88.33it/s, train_loss=0.0048, val_loss=0.00542] Epoch 25:  96%|█████████▋| 27/28 [00:00<00:00, 89.87it/s, train_loss=0.0048, val_loss=0.00542]Epoch 25:  96%|█████████▋| 27/28 [00:00<00:00, 88.93it/s, train_loss=0.00621, val_loss=0.00542]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 90.23it/s, train_loss=0.00621, val_loss=0.00542]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 88.99it/s, train_loss=0.00502, val_loss=0.00542]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 219.28it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 254.62it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 140.82it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 157.60it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 172.01it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 183.90it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 193.25it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 201.48it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 207.70it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 212.37it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 216.43it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 220.32it/s][A
                                                                         [AEpoch 25: 100%|██████████| 28/28 [00:00<00:00, 74.45it/s, train_loss=0.00502, val_loss=0.00529]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 74.29it/s, train_loss=0.00502, val_loss=0.00529]Epoch 25:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00502, val_loss=0.00529]         Epoch 26:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00502, val_loss=0.00529]Epoch 26:   4%|▎         | 1/28 [00:00<00:00, 149.08it/s, train_loss=0.00502, val_loss=0.00529]Epoch 26:   4%|▎         | 1/28 [00:00<00:00, 73.33it/s, train_loss=0.00687, val_loss=0.00529] Epoch 26:   7%|▋         | 2/28 [00:00<00:00, 103.80it/s, train_loss=0.00687, val_loss=0.00529]Epoch 26:   7%|▋         | 2/28 [00:00<00:00, 80.65it/s, train_loss=0.00597, val_loss=0.00529] Epoch 26:  11%|█         | 3/28 [00:00<00:00, 94.98it/s, train_loss=0.00597, val_loss=0.00529]Epoch 26:  11%|█         | 3/28 [00:00<00:00, 80.10it/s, train_loss=0.00654, val_loss=0.00529]Epoch 26:  14%|█▍        | 4/28 [00:00<00:00, 92.70it/s, train_loss=0.00654, val_loss=0.00529]Epoch 26:  14%|█▍        | 4/28 [00:00<00:00, 81.92it/s, train_loss=0.00501, val_loss=0.00529]Epoch 26:  18%|█▊        | 5/28 [00:00<00:00, 91.83it/s, train_loss=0.00501, val_loss=0.00529]Epoch 26:  18%|█▊        | 5/28 [00:00<00:00, 83.05it/s, train_loss=0.0045, val_loss=0.00529] Epoch 26:  21%|██▏       | 6/28 [00:00<00:00, 91.07it/s, train_loss=0.0045, val_loss=0.00529]Epoch 26:  21%|██▏       | 6/28 [00:00<00:00, 85.97it/s, train_loss=0.00512, val_loss=0.00529]Epoch 26:  25%|██▌       | 7/28 [00:00<00:00, 91.38it/s, train_loss=0.00512, val_loss=0.00529]Epoch 26:  25%|██▌       | 7/28 [00:00<00:00, 85.01it/s, train_loss=0.00583, val_loss=0.00529]Epoch 26:  29%|██▊       | 8/28 [00:00<00:00, 90.84it/s, train_loss=0.00583, val_loss=0.00529]Epoch 26:  29%|██▊       | 8/28 [00:00<00:00, 85.45it/s, train_loss=0.00415, val_loss=0.00529]Epoch 26:  32%|███▏      | 9/28 [00:00<00:00, 90.59it/s, train_loss=0.00415, val_loss=0.00529]Epoch 26:  32%|███▏      | 9/28 [00:00<00:00, 85.80it/s, train_loss=0.00562, val_loss=0.00529]Epoch 26:  36%|███▌      | 10/28 [00:00<00:00, 90.36it/s, train_loss=0.00562, val_loss=0.00529]Epoch 26:  36%|███▌      | 10/28 [00:00<00:00, 86.08it/s, train_loss=0.00747, val_loss=0.00529]Epoch 26:  39%|███▉      | 11/28 [00:00<00:00, 89.57it/s, train_loss=0.00747, val_loss=0.00529]Epoch 26:  39%|███▉      | 11/28 [00:00<00:00, 86.35it/s, train_loss=0.00713, val_loss=0.00529]Epoch 26:  43%|████▎     | 12/28 [00:00<00:00, 90.17it/s, train_loss=0.00713, val_loss=0.00529]Epoch 26:  43%|████▎     | 12/28 [00:00<00:00, 86.49it/s, train_loss=0.00563, val_loss=0.00529]Epoch 26:  46%|████▋     | 13/28 [00:00<00:00, 90.30it/s, train_loss=0.00563, val_loss=0.00529]Epoch 26:  46%|████▋     | 13/28 [00:00<00:00, 86.65it/s, train_loss=0.00594, val_loss=0.00529]Epoch 26:  50%|█████     | 14/28 [00:00<00:00, 90.03it/s, train_loss=0.00594, val_loss=0.00529]Epoch 26:  50%|█████     | 14/28 [00:00<00:00, 87.78it/s, train_loss=0.00463, val_loss=0.00529]Epoch 26:  54%|█████▎    | 15/28 [00:00<00:00, 90.45it/s, train_loss=0.00463, val_loss=0.00529]Epoch 26:  54%|█████▎    | 15/28 [00:00<00:00, 87.83it/s, train_loss=0.0068, val_loss=0.00529] Epoch 26:  57%|█████▋    | 16/28 [00:00<00:00, 90.80it/s, train_loss=0.0068, val_loss=0.00529]Epoch 26:  57%|█████▋    | 16/28 [00:00<00:00, 87.83it/s, train_loss=0.00594, val_loss=0.00529]Epoch 26:  61%|██████    | 17/28 [00:00<00:00, 90.62it/s, train_loss=0.00594, val_loss=0.00529]Epoch 26:  61%|██████    | 17/28 [00:00<00:00, 87.86it/s, train_loss=0.00709, val_loss=0.00529]Epoch 26:  64%|██████▍   | 18/28 [00:00<00:00, 90.38it/s, train_loss=0.00709, val_loss=0.00529]Epoch 26:  64%|██████▍   | 18/28 [00:00<00:00, 88.66it/s, train_loss=0.00678, val_loss=0.00529]Epoch 26:  68%|██████▊   | 19/28 [00:00<00:00, 90.69it/s, train_loss=0.00678, val_loss=0.00529]Epoch 26:  68%|██████▊   | 19/28 [00:00<00:00, 88.64it/s, train_loss=0.00708, val_loss=0.00529]Epoch 26:  71%|███████▏  | 20/28 [00:00<00:00, 91.00it/s, train_loss=0.00708, val_loss=0.00529]Epoch 26:  71%|███████▏  | 20/28 [00:00<00:00, 88.60it/s, train_loss=0.00565, val_loss=0.00529]Epoch 26:  75%|███████▌  | 21/28 [00:00<00:00, 90.84it/s, train_loss=0.00565, val_loss=0.00529]Epoch 26:  75%|███████▌  | 21/28 [00:00<00:00, 88.58it/s, train_loss=0.00539, val_loss=0.00529]Epoch 26:  79%|███████▊  | 22/28 [00:00<00:00, 90.58it/s, train_loss=0.00539, val_loss=0.00529]Epoch 26:  79%|███████▊  | 22/28 [00:00<00:00, 89.24it/s, train_loss=0.00562, val_loss=0.00529]Epoch 26:  82%|████████▏ | 23/28 [00:00<00:00, 90.87it/s, train_loss=0.00562, val_loss=0.00529]Epoch 26:  82%|████████▏ | 23/28 [00:00<00:00, 89.21it/s, train_loss=0.00633, val_loss=0.00529]Epoch 26:  86%|████████▌ | 24/28 [00:00<00:00, 91.09it/s, train_loss=0.00633, val_loss=0.00529]Epoch 26:  86%|████████▌ | 24/28 [00:00<00:00, 89.16it/s, train_loss=0.00485, val_loss=0.00529]Epoch 26:  89%|████████▉ | 25/28 [00:00<00:00, 90.96it/s, train_loss=0.00485, val_loss=0.00529]Epoch 26:  89%|████████▉ | 25/28 [00:00<00:00, 89.13it/s, train_loss=0.00573, val_loss=0.00529]Epoch 26:  93%|█████████▎| 26/28 [00:00<00:00, 90.74it/s, train_loss=0.00573, val_loss=0.00529]Epoch 26:  93%|█████████▎| 26/28 [00:00<00:00, 89.66it/s, train_loss=0.00581, val_loss=0.00529]Epoch 26:  96%|█████████▋| 27/28 [00:00<00:00, 91.04it/s, train_loss=0.00581, val_loss=0.00529]Epoch 26:  96%|█████████▋| 27/28 [00:00<00:00, 89.61it/s, train_loss=0.00482, val_loss=0.00529]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 91.23it/s, train_loss=0.00482, val_loss=0.00529]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 89.62it/s, train_loss=0.00483, val_loss=0.00529]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 128.94it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 159.20it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 174.31it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 190.97it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 205.34it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 214.52it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 224.64it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 233.03it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 239.36it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 243.94it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 247.62it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 250.73it/s][A
                                                                         [AEpoch 26: 100%|██████████| 28/28 [00:00<00:00, 75.77it/s, train_loss=0.00483, val_loss=0.00523]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 75.62it/s, train_loss=0.00483, val_loss=0.00523]Epoch 26:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00483, val_loss=0.00523]         Epoch 27:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00483, val_loss=0.00523]Epoch 27:   4%|▎         | 1/28 [00:00<00:00, 153.58it/s, train_loss=0.00483, val_loss=0.00523]Epoch 27:   4%|▎         | 1/28 [00:00<00:00, 73.42it/s, train_loss=0.00554, val_loss=0.00523] Epoch 27:   7%|▋         | 2/28 [00:00<00:00, 99.23it/s, train_loss=0.00554, val_loss=0.00523]Epoch 27:   7%|▋         | 2/28 [00:00<00:00, 80.56it/s, train_loss=0.005, val_loss=0.00523]  Epoch 27:  11%|█         | 3/28 [00:00<00:00, 98.29it/s, train_loss=0.005, val_loss=0.00523]Epoch 27:  11%|█         | 3/28 [00:00<00:00, 82.72it/s, train_loss=0.00542, val_loss=0.00523]Epoch 27:  14%|█▍        | 4/28 [00:00<00:00, 95.51it/s, train_loss=0.00542, val_loss=0.00523]Epoch 27:  14%|█▍        | 4/28 [00:00<00:00, 83.90it/s, train_loss=0.00484, val_loss=0.00523]Epoch 27:  18%|█▊        | 5/28 [00:00<00:00, 93.94it/s, train_loss=0.00484, val_loss=0.00523]Epoch 27:  18%|█▊        | 5/28 [00:00<00:00, 84.72it/s, train_loss=0.00575, val_loss=0.00523]Epoch 27:  21%|██▏       | 6/28 [00:00<00:00, 91.70it/s, train_loss=0.00575, val_loss=0.00523]Epoch 27:  21%|██▏       | 6/28 [00:00<00:00, 82.99it/s, train_loss=0.00557, val_loss=0.00523]Epoch 27:  25%|██▌       | 7/28 [00:00<00:00, 89.70it/s, train_loss=0.00557, val_loss=0.00523]Epoch 27:  25%|██▌       | 7/28 [00:00<00:00, 83.68it/s, train_loss=0.00658, val_loss=0.00523]Epoch 27:  29%|██▊       | 8/28 [00:00<00:00, 89.37it/s, train_loss=0.00658, val_loss=0.00523]Epoch 27:  29%|██▊       | 8/28 [00:00<00:00, 84.28it/s, train_loss=0.0058, val_loss=0.00523] Epoch 27:  32%|███▏      | 9/28 [00:00<00:00, 89.37it/s, train_loss=0.0058, val_loss=0.00523]Epoch 27:  32%|███▏      | 9/28 [00:00<00:00, 86.32it/s, train_loss=0.0064, val_loss=0.00523]Epoch 27:  36%|███▌      | 10/28 [00:00<00:00, 90.36it/s, train_loss=0.0064, val_loss=0.00523]Epoch 27:  36%|███▌      | 10/28 [00:00<00:00, 86.09it/s, train_loss=0.00852, val_loss=0.00523]Epoch 27:  39%|███▉      | 11/28 [00:00<00:00, 90.20it/s, train_loss=0.00852, val_loss=0.00523]Epoch 27:  39%|███▉      | 11/28 [00:00<00:00, 86.34it/s, train_loss=0.00583, val_loss=0.00523]Epoch 27:  43%|████▎     | 12/28 [00:00<00:00, 90.13it/s, train_loss=0.00583, val_loss=0.00523]Epoch 27:  43%|████▎     | 12/28 [00:00<00:00, 86.58it/s, train_loss=0.00539, val_loss=0.00523]Epoch 27:  46%|████▋     | 13/28 [00:00<00:00, 90.14it/s, train_loss=0.00539, val_loss=0.00523]Epoch 27:  46%|████▋     | 13/28 [00:00<00:00, 87.92it/s, train_loss=0.00476, val_loss=0.00523]Epoch 27:  50%|█████     | 14/28 [00:00<00:00, 90.76it/s, train_loss=0.00476, val_loss=0.00523]Epoch 27:  50%|█████     | 14/28 [00:00<00:00, 87.30it/s, train_loss=0.00647, val_loss=0.00523]Epoch 27:  54%|█████▎    | 15/28 [00:00<00:00, 90.24it/s, train_loss=0.00647, val_loss=0.00523]Epoch 27:  54%|█████▎    | 15/28 [00:00<00:00, 87.42it/s, train_loss=0.00655, val_loss=0.00523]Epoch 27:  57%|█████▋    | 16/28 [00:00<00:00, 90.45it/s, train_loss=0.00655, val_loss=0.00523]Epoch 27:  57%|█████▋    | 16/28 [00:00<00:00, 87.48it/s, train_loss=0.00699, val_loss=0.00523]Epoch 27:  61%|██████    | 17/28 [00:00<00:00, 90.25it/s, train_loss=0.00699, val_loss=0.00523]Epoch 27:  61%|██████    | 17/28 [00:00<00:00, 87.55it/s, train_loss=0.0083, val_loss=0.00523] Epoch 27:  64%|██████▍   | 18/28 [00:00<00:00, 89.70it/s, train_loss=0.0083, val_loss=0.00523]Epoch 27:  64%|██████▍   | 18/28 [00:00<00:00, 87.63it/s, train_loss=0.0048, val_loss=0.00523]Epoch 27:  68%|██████▊   | 19/28 [00:00<00:00, 89.82it/s, train_loss=0.0048, val_loss=0.00523]Epoch 27:  68%|██████▊   | 19/28 [00:00<00:00, 87.65it/s, train_loss=0.00639, val_loss=0.00523]Epoch 27:  71%|███████▏  | 20/28 [00:00<00:00, 89.79it/s, train_loss=0.00639, val_loss=0.00523]Epoch 27:  71%|███████▏  | 20/28 [00:00<00:00, 87.72it/s, train_loss=0.00433, val_loss=0.00523]Epoch 27:  75%|███████▌  | 21/28 [00:00<00:00, 89.60it/s, train_loss=0.00433, val_loss=0.00523]Epoch 27:  75%|███████▌  | 21/28 [00:00<00:00, 88.41it/s, train_loss=0.00499, val_loss=0.00523]Epoch 27:  79%|███████▊  | 22/28 [00:00<00:00, 90.20it/s, train_loss=0.00499, val_loss=0.00523]Epoch 27:  79%|███████▊  | 22/28 [00:00<00:00, 88.42it/s, train_loss=0.00452, val_loss=0.00523]Epoch 27:  82%|████████▏ | 23/28 [00:00<00:00, 90.45it/s, train_loss=0.00452, val_loss=0.00523]Epoch 27:  82%|████████▏ | 23/28 [00:00<00:00, 88.39it/s, train_loss=0.0049, val_loss=0.00523] Epoch 27:  86%|████████▌ | 24/28 [00:00<00:00, 90.32it/s, train_loss=0.0049, val_loss=0.00523]Epoch 27:  86%|████████▌ | 24/28 [00:00<00:00, 88.38it/s, train_loss=0.00539, val_loss=0.00523]Epoch 27:  89%|████████▉ | 25/28 [00:00<00:00, 90.26it/s, train_loss=0.00539, val_loss=0.00523]Epoch 27:  89%|████████▉ | 25/28 [00:00<00:00, 88.97it/s, train_loss=0.00515, val_loss=0.00523]Epoch 27:  93%|█████████▎| 26/28 [00:00<00:00, 90.51it/s, train_loss=0.00515, val_loss=0.00523]Epoch 27:  93%|█████████▎| 26/28 [00:00<00:00, 88.93it/s, train_loss=0.00543, val_loss=0.00523]Epoch 27:  96%|█████████▋| 27/28 [00:00<00:00, 90.64it/s, train_loss=0.00543, val_loss=0.00523]Epoch 27:  96%|█████████▋| 27/28 [00:00<00:00, 88.88it/s, train_loss=0.0063, val_loss=0.00523] Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 90.52it/s, train_loss=0.0063, val_loss=0.00523]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 89.59it/s, train_loss=0.00497, val_loss=0.00523]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 151.59it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 163.36it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 180.70it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 190.58it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 196.48it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 200.62it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 202.01it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 201.64it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 204.23it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 210.09it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 216.74it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 222.27it/s][A
                                                                         [AEpoch 27: 100%|██████████| 28/28 [00:00<00:00, 74.83it/s, train_loss=0.00497, val_loss=0.00511]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 74.67it/s, train_loss=0.00497, val_loss=0.00511]Epoch 27:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00497, val_loss=0.00511]         Epoch 28:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00497, val_loss=0.00511]Epoch 28:   4%|▎         | 1/28 [00:00<00:00, 144.75it/s, train_loss=0.00497, val_loss=0.00511]Epoch 28:   4%|▎         | 1/28 [00:00<00:00, 88.76it/s, train_loss=0.00565, val_loss=0.00511] Epoch 28:   7%|▋         | 2/28 [00:00<00:00, 117.85it/s, train_loss=0.00565, val_loss=0.00511]Epoch 28:   7%|▋         | 2/28 [00:00<00:00, 88.21it/s, train_loss=0.00615, val_loss=0.00511] Epoch 28:  11%|█         | 3/28 [00:00<00:00, 106.64it/s, train_loss=0.00615, val_loss=0.00511]Epoch 28:  11%|█         | 3/28 [00:00<00:00, 87.86it/s, train_loss=0.00458, val_loss=0.00511] Epoch 28:  14%|█▍        | 4/28 [00:00<00:00, 100.63it/s, train_loss=0.00458, val_loss=0.00511]Epoch 28:  14%|█▍        | 4/28 [00:00<00:00, 87.86it/s, train_loss=0.00754, val_loss=0.00511] Epoch 28:  18%|█▊        | 5/28 [00:00<00:00, 96.36it/s, train_loss=0.00754, val_loss=0.00511]Epoch 28:  18%|█▊        | 5/28 [00:00<00:00, 88.73it/s, train_loss=0.00698, val_loss=0.00511]Epoch 28:  21%|██▏       | 6/28 [00:00<00:00, 96.05it/s, train_loss=0.00698, val_loss=0.00511]Epoch 28:  21%|██▏       | 6/28 [00:00<00:00, 88.69it/s, train_loss=0.00474, val_loss=0.00511]Epoch 28:  25%|██▌       | 7/28 [00:00<00:00, 95.68it/s, train_loss=0.00474, val_loss=0.00511]Epoch 28:  25%|██▌       | 7/28 [00:00<00:00, 88.62it/s, train_loss=0.00583, val_loss=0.00511]Epoch 28:  29%|██▊       | 8/28 [00:00<00:00, 94.67it/s, train_loss=0.00583, val_loss=0.00511]Epoch 28:  29%|██▊       | 8/28 [00:00<00:00, 88.69it/s, train_loss=0.00571, val_loss=0.00511]Epoch 28:  32%|███▏      | 9/28 [00:00<00:00, 92.70it/s, train_loss=0.00571, val_loss=0.00511]Epoch 28:  32%|███▏      | 9/28 [00:00<00:00, 87.10it/s, train_loss=0.00655, val_loss=0.00511]Epoch 28:  36%|███▌      | 10/28 [00:00<00:00, 91.68it/s, train_loss=0.00655, val_loss=0.00511]Epoch 28:  36%|███▌      | 10/28 [00:00<00:00, 87.29it/s, train_loss=0.00562, val_loss=0.00511]Epoch 28:  39%|███▉      | 11/28 [00:00<00:00, 91.43it/s, train_loss=0.00562, val_loss=0.00511]Epoch 28:  39%|███▉      | 11/28 [00:00<00:00, 87.49it/s, train_loss=0.00525, val_loss=0.00511]Epoch 28:  43%|████▎     | 12/28 [00:00<00:00, 91.30it/s, train_loss=0.00525, val_loss=0.00511]Epoch 28:  43%|████▎     | 12/28 [00:00<00:00, 87.77it/s, train_loss=0.00632, val_loss=0.00511]Epoch 28:  46%|████▋     | 13/28 [00:00<00:00, 90.78it/s, train_loss=0.00632, val_loss=0.00511]Epoch 28:  46%|████▋     | 13/28 [00:00<00:00, 87.86it/s, train_loss=0.00534, val_loss=0.00511]Epoch 28:  50%|█████     | 14/28 [00:00<00:00, 91.21it/s, train_loss=0.00534, val_loss=0.00511]Epoch 28:  50%|█████     | 14/28 [00:00<00:00, 87.90it/s, train_loss=0.00537, val_loss=0.00511]Epoch 28:  54%|█████▎    | 15/28 [00:00<00:00, 90.94it/s, train_loss=0.00537, val_loss=0.00511]Epoch 28:  54%|█████▎    | 15/28 [00:00<00:00, 87.98it/s, train_loss=0.00567, val_loss=0.00511]Epoch 28:  57%|█████▋    | 16/28 [00:00<00:00, 90.24it/s, train_loss=0.00567, val_loss=0.00511]Epoch 28:  57%|█████▋    | 16/28 [00:00<00:00, 88.02it/s, train_loss=0.00579, val_loss=0.00511]Epoch 28:  61%|██████    | 17/28 [00:00<00:00, 90.55it/s, train_loss=0.00579, val_loss=0.00511]Epoch 28:  61%|██████    | 17/28 [00:00<00:00, 88.03it/s, train_loss=0.00578, val_loss=0.00511]Epoch 28:  64%|██████▍   | 18/28 [00:00<00:00, 90.74it/s, train_loss=0.00578, val_loss=0.00511]Epoch 28:  64%|██████▍   | 18/28 [00:00<00:00, 88.04it/s, train_loss=0.00645, val_loss=0.00511]Epoch 28:  68%|██████▊   | 19/28 [00:00<00:00, 90.54it/s, train_loss=0.00645, val_loss=0.00511]Epoch 28:  68%|██████▊   | 19/28 [00:00<00:00, 88.08it/s, train_loss=0.00699, val_loss=0.00511]Epoch 28:  71%|███████▏  | 20/28 [00:00<00:00, 89.92it/s, train_loss=0.00699, val_loss=0.00511]Epoch 28:  71%|███████▏  | 20/28 [00:00<00:00, 87.64it/s, train_loss=0.0052, val_loss=0.00511] Epoch 28:  75%|███████▌  | 21/28 [00:00<00:00, 89.89it/s, train_loss=0.0052, val_loss=0.00511]Epoch 28:  75%|███████▌  | 21/28 [00:00<00:00, 87.68it/s, train_loss=0.0046, val_loss=0.00511]Epoch 28:  79%|███████▊  | 22/28 [00:00<00:00, 89.82it/s, train_loss=0.0046, val_loss=0.00511]Epoch 28:  79%|███████▊  | 22/28 [00:00<00:00, 87.72it/s, train_loss=0.00571, val_loss=0.00511]Epoch 28:  82%|████████▏ | 23/28 [00:00<00:00, 89.75it/s, train_loss=0.00571, val_loss=0.00511]Epoch 28:  82%|████████▏ | 23/28 [00:00<00:00, 87.80it/s, train_loss=0.00542, val_loss=0.00511]Epoch 28:  86%|████████▌ | 24/28 [00:00<00:00, 89.35it/s, train_loss=0.00542, val_loss=0.00511]Epoch 28:  86%|████████▌ | 24/28 [00:00<00:00, 87.84it/s, train_loss=0.0063, val_loss=0.00511] Epoch 28:  89%|████████▉ | 25/28 [00:00<00:00, 89.68it/s, train_loss=0.0063, val_loss=0.00511]Epoch 28:  89%|████████▉ | 25/28 [00:00<00:00, 87.87it/s, train_loss=0.00442, val_loss=0.00511]Epoch 28:  93%|█████████▎| 26/28 [00:00<00:00, 89.60it/s, train_loss=0.00442, val_loss=0.00511]Epoch 28:  93%|█████████▎| 26/28 [00:00<00:00, 87.92it/s, train_loss=0.00474, val_loss=0.00511]Epoch 28:  96%|█████████▋| 27/28 [00:00<00:00, 89.34it/s, train_loss=0.00474, val_loss=0.00511]Epoch 28:  96%|█████████▋| 27/28 [00:00<00:00, 87.98it/s, train_loss=0.00509, val_loss=0.00511]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 89.50it/s, train_loss=0.00509, val_loss=0.00511]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 88.09it/s, train_loss=0.00432, val_loss=0.00511]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 145.43it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 175.34it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 184.84it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 191.97it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 198.70it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 203.89it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 207.82it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 210.61it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 211.71it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 212.83it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 212.05it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 212.84it/s][A
                                                                         [AEpoch 28: 100%|██████████| 28/28 [00:00<00:00, 72.84it/s, train_loss=0.00432, val_loss=0.00503]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 72.64it/s, train_loss=0.00432, val_loss=0.00503]Epoch 28:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00432, val_loss=0.00503]         Epoch 29:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00432, val_loss=0.00503]Epoch 29:   4%|▎         | 1/28 [00:00<00:00, 160.19it/s, train_loss=0.00432, val_loss=0.00503]Epoch 29:   4%|▎         | 1/28 [00:00<00:00, 90.38it/s, train_loss=0.00475, val_loss=0.00503] Epoch 29:   7%|▋         | 2/28 [00:00<00:00, 117.32it/s, train_loss=0.00475, val_loss=0.00503]Epoch 29:   7%|▋         | 2/28 [00:00<00:00, 89.12it/s, train_loss=0.00495, val_loss=0.00503] Epoch 29:  11%|█         | 3/28 [00:00<00:00, 107.67it/s, train_loss=0.00495, val_loss=0.00503]Epoch 29:  11%|█         | 3/28 [00:00<00:00, 88.52it/s, train_loss=0.00714, val_loss=0.00503] Epoch 29:  14%|█▍        | 4/28 [00:00<00:00, 101.53it/s, train_loss=0.00714, val_loss=0.00503]Epoch 29:  14%|█▍        | 4/28 [00:00<00:00, 88.49it/s, train_loss=0.00525, val_loss=0.00503] Epoch 29:  18%|█▊        | 5/28 [00:00<00:00, 97.30it/s, train_loss=0.00525, val_loss=0.00503]Epoch 29:  18%|█▊        | 5/28 [00:00<00:00, 91.05it/s, train_loss=0.00563, val_loss=0.00503]Epoch 29:  21%|██▏       | 6/28 [00:00<00:00, 97.95it/s, train_loss=0.00563, val_loss=0.00503]Epoch 29:  21%|██▏       | 6/28 [00:00<00:00, 90.68it/s, train_loss=0.00497, val_loss=0.00503]Epoch 29:  25%|██▌       | 7/28 [00:00<00:00, 97.38it/s, train_loss=0.00497, val_loss=0.00503]Epoch 29:  25%|██▌       | 7/28 [00:00<00:00, 90.34it/s, train_loss=0.00582, val_loss=0.00503]Epoch 29:  29%|██▊       | 8/28 [00:00<00:00, 96.25it/s, train_loss=0.00582, val_loss=0.00503]Epoch 29:  29%|██▊       | 8/28 [00:00<00:00, 90.18it/s, train_loss=0.00702, val_loss=0.00503]Epoch 29:  32%|███▏      | 9/28 [00:00<00:00, 94.77it/s, train_loss=0.00702, val_loss=0.00503]Epoch 29:  32%|███▏      | 9/28 [00:00<00:00, 90.08it/s, train_loss=0.00512, val_loss=0.00503]Epoch 29:  36%|███▌      | 10/28 [00:00<00:00, 94.06it/s, train_loss=0.00512, val_loss=0.00503]Epoch 29:  36%|███▌      | 10/28 [00:00<00:00, 88.11it/s, train_loss=0.00578, val_loss=0.00503]Epoch 29:  39%|███▉      | 11/28 [00:00<00:00, 92.37it/s, train_loss=0.00578, val_loss=0.00503]Epoch 29:  39%|███▉      | 11/28 [00:00<00:00, 88.18it/s, train_loss=0.0058, val_loss=0.00503] Epoch 29:  43%|████▎     | 12/28 [00:00<00:00, 92.02it/s, train_loss=0.0058, val_loss=0.00503]Epoch 29:  43%|████▎     | 12/28 [00:00<00:00, 88.30it/s, train_loss=0.00407, val_loss=0.00503]Epoch 29:  46%|████▋     | 13/28 [00:00<00:00, 91.35it/s, train_loss=0.00407, val_loss=0.00503]Epoch 29:  46%|████▋     | 13/28 [00:00<00:00, 88.34it/s, train_loss=0.00735, val_loss=0.00503]Epoch 29:  50%|█████     | 14/28 [00:00<00:00, 91.54it/s, train_loss=0.00735, val_loss=0.00503]Epoch 29:  50%|█████     | 14/28 [00:00<00:00, 88.40it/s, train_loss=0.00517, val_loss=0.00503]Epoch 29:  54%|█████▎    | 15/28 [00:00<00:00, 91.32it/s, train_loss=0.00517, val_loss=0.00503]Epoch 29:  54%|█████▎    | 15/28 [00:00<00:00, 88.46it/s, train_loss=0.00617, val_loss=0.00503]Epoch 29:  57%|█████▋    | 16/28 [00:00<00:00, 90.74it/s, train_loss=0.00617, val_loss=0.00503]Epoch 29:  57%|█████▋    | 16/28 [00:00<00:00, 88.56it/s, train_loss=0.00485, val_loss=0.00503]Epoch 29:  61%|██████    | 17/28 [00:00<00:00, 91.12it/s, train_loss=0.00485, val_loss=0.00503]Epoch 29:  61%|██████    | 17/28 [00:00<00:00, 88.61it/s, train_loss=0.00506, val_loss=0.00503]Epoch 29:  64%|██████▍   | 18/28 [00:00<00:00, 91.16it/s, train_loss=0.00506, val_loss=0.00503]Epoch 29:  64%|██████▍   | 18/28 [00:00<00:00, 88.59it/s, train_loss=0.00591, val_loss=0.00503]Epoch 29:  68%|██████▊   | 19/28 [00:00<00:00, 90.92it/s, train_loss=0.00591, val_loss=0.00503]Epoch 29:  68%|██████▊   | 19/28 [00:00<00:00, 88.63it/s, train_loss=0.0052, val_loss=0.00503] Epoch 29:  71%|███████▏  | 20/28 [00:00<00:00, 90.63it/s, train_loss=0.0052, val_loss=0.00503]Epoch 29:  71%|███████▏  | 20/28 [00:00<00:00, 88.83it/s, train_loss=0.00524, val_loss=0.00503]Epoch 29:  75%|███████▌  | 21/28 [00:00<00:00, 91.07it/s, train_loss=0.00524, val_loss=0.00503]Epoch 29:  75%|███████▌  | 21/28 [00:00<00:00, 88.83it/s, train_loss=0.00679, val_loss=0.00503]Epoch 29:  79%|███████▊  | 22/28 [00:00<00:00, 91.00it/s, train_loss=0.00679, val_loss=0.00503]Epoch 29:  79%|███████▊  | 22/28 [00:00<00:00, 88.81it/s, train_loss=0.00626, val_loss=0.00503]Epoch 29:  82%|████████▏ | 23/28 [00:00<00:00, 90.87it/s, train_loss=0.00626, val_loss=0.00503]Epoch 29:  82%|████████▏ | 23/28 [00:00<00:00, 88.90it/s, train_loss=0.00631, val_loss=0.00503]Epoch 29:  86%|████████▌ | 24/28 [00:00<00:00, 90.58it/s, train_loss=0.00631, val_loss=0.00503]Epoch 29:  86%|████████▌ | 24/28 [00:00<00:00, 88.46it/s, train_loss=0.00522, val_loss=0.00503]Epoch 29:  89%|████████▉ | 25/28 [00:00<00:00, 90.24it/s, train_loss=0.00522, val_loss=0.00503]Epoch 29:  89%|████████▉ | 25/28 [00:00<00:00, 88.48it/s, train_loss=0.0049, val_loss=0.00503] Epoch 29:  93%|█████████▎| 26/28 [00:00<00:00, 90.23it/s, train_loss=0.0049, val_loss=0.00503]Epoch 29:  93%|█████████▎| 26/28 [00:00<00:00, 88.49it/s, train_loss=0.00532, val_loss=0.00503]Epoch 29:  96%|█████████▋| 27/28 [00:00<00:00, 90.19it/s, train_loss=0.00532, val_loss=0.00503]Epoch 29:  96%|█████████▋| 27/28 [00:00<00:00, 88.51it/s, train_loss=0.00514, val_loss=0.00503]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 89.94it/s, train_loss=0.00514, val_loss=0.00503]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 88.57it/s, train_loss=0.00593, val_loss=0.00503]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 159.92it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 190.33it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 203.24it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 208.97it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 212.15it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 215.75it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 217.11it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 217.82it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 219.72it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 220.39it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 221.44it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 221.95it/s][A
                                                                         [AEpoch 29: 100%|██████████| 28/28 [00:00<00:00, 73.56it/s, train_loss=0.00593, val_loss=0.00497]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 73.36it/s, train_loss=0.00593, val_loss=0.00497]Epoch 29:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00593, val_loss=0.00497]         Epoch 30:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00593, val_loss=0.00497]Epoch 30:   4%|▎         | 1/28 [00:00<00:00, 139.33it/s, train_loss=0.00593, val_loss=0.00497]Epoch 30:   4%|▎         | 1/28 [00:00<00:00, 73.26it/s, train_loss=0.00546, val_loss=0.00497] Epoch 30:   7%|▋         | 2/28 [00:00<00:00, 100.67it/s, train_loss=0.00546, val_loss=0.00497]Epoch 30:   7%|▋         | 2/28 [00:00<00:00, 79.07it/s, train_loss=0.00716, val_loss=0.00497] Epoch 30:  11%|█         | 3/28 [00:00<00:00, 97.22it/s, train_loss=0.00716, val_loss=0.00497]Epoch 30:  11%|█         | 3/28 [00:00<00:00, 81.42it/s, train_loss=0.00631, val_loss=0.00497]Epoch 30:  14%|█▍        | 4/28 [00:00<00:00, 94.70it/s, train_loss=0.00631, val_loss=0.00497]Epoch 30:  14%|█▍        | 4/28 [00:00<00:00, 82.93it/s, train_loss=0.00494, val_loss=0.00497]Epoch 30:  18%|█▊        | 5/28 [00:00<00:00, 92.76it/s, train_loss=0.00494, val_loss=0.00497]Epoch 30:  18%|█▊        | 5/28 [00:00<00:00, 86.16it/s, train_loss=0.0057, val_loss=0.00497] Epoch 30:  21%|██▏       | 6/28 [00:00<00:00, 93.29it/s, train_loss=0.0057, val_loss=0.00497]Epoch 30:  21%|██▏       | 6/28 [00:00<00:00, 86.42it/s, train_loss=0.00596, val_loss=0.00497]Epoch 30:  25%|██▌       | 7/28 [00:00<00:00, 93.43it/s, train_loss=0.00596, val_loss=0.00497]Epoch 30:  25%|██▌       | 7/28 [00:00<00:00, 86.55it/s, train_loss=0.00497, val_loss=0.00497]Epoch 30:  29%|██▊       | 8/28 [00:00<00:00, 92.77it/s, train_loss=0.00497, val_loss=0.00497]Epoch 30:  29%|██▊       | 8/28 [00:00<00:00, 86.66it/s, train_loss=0.00603, val_loss=0.00497]Epoch 30:  32%|███▏      | 9/28 [00:00<00:00, 91.96it/s, train_loss=0.00603, val_loss=0.00497]Epoch 30:  32%|███▏      | 9/28 [00:00<00:00, 87.77it/s, train_loss=0.00546, val_loss=0.00497]Epoch 30:  36%|███▌      | 10/28 [00:00<00:00, 91.94it/s, train_loss=0.00546, val_loss=0.00497]Epoch 30:  36%|███▌      | 10/28 [00:00<00:00, 87.71it/s, train_loss=0.00412, val_loss=0.00497]Epoch 30:  39%|███▉      | 11/28 [00:00<00:00, 91.91it/s, train_loss=0.00412, val_loss=0.00497]Epoch 30:  39%|███▉      | 11/28 [00:00<00:00, 87.66it/s, train_loss=0.00425, val_loss=0.00497]Epoch 30:  43%|████▎     | 12/28 [00:00<00:00, 91.56it/s, train_loss=0.00425, val_loss=0.00497]Epoch 30:  43%|████▎     | 12/28 [00:00<00:00, 87.64it/s, train_loss=0.00481, val_loss=0.00497]Epoch 30:  46%|████▋     | 13/28 [00:00<00:00, 91.04it/s, train_loss=0.00481, val_loss=0.00497]Epoch 30:  46%|████▋     | 13/28 [00:00<00:00, 88.54it/s, train_loss=0.00579, val_loss=0.00497]Epoch 30:  50%|█████     | 14/28 [00:00<00:00, 91.39it/s, train_loss=0.00579, val_loss=0.00497]Epoch 30:  50%|█████     | 14/28 [00:00<00:00, 88.44it/s, train_loss=0.00482, val_loss=0.00497]Epoch 30:  54%|█████▎    | 15/28 [00:00<00:00, 91.42it/s, train_loss=0.00482, val_loss=0.00497]Epoch 30:  54%|█████▎    | 15/28 [00:00<00:00, 88.33it/s, train_loss=0.0068, val_loss=0.00497] Epoch 30:  57%|█████▋    | 16/28 [00:00<00:00, 91.20it/s, train_loss=0.0068, val_loss=0.00497]Epoch 30:  57%|█████▋    | 16/28 [00:00<00:00, 88.28it/s, train_loss=0.00628, val_loss=0.00497]Epoch 30:  61%|██████    | 17/28 [00:00<00:00, 90.87it/s, train_loss=0.00628, val_loss=0.00497]Epoch 30:  61%|██████    | 17/28 [00:00<00:00, 88.95it/s, train_loss=0.00746, val_loss=0.00497]Epoch 30:  64%|██████▍   | 18/28 [00:00<00:00, 91.14it/s, train_loss=0.00746, val_loss=0.00497]Epoch 30:  64%|██████▍   | 18/28 [00:00<00:00, 88.83it/s, train_loss=0.00541, val_loss=0.00497]Epoch 30:  68%|██████▊   | 19/28 [00:00<00:00, 91.16it/s, train_loss=0.00541, val_loss=0.00497]Epoch 30:  68%|██████▊   | 19/28 [00:00<00:00, 88.74it/s, train_loss=0.00697, val_loss=0.00497]Epoch 30:  71%|███████▏  | 20/28 [00:00<00:00, 90.91it/s, train_loss=0.00697, val_loss=0.00497]Epoch 30:  71%|███████▏  | 20/28 [00:00<00:00, 88.71it/s, train_loss=0.00521, val_loss=0.00497]Epoch 30:  75%|███████▌  | 21/28 [00:00<00:00, 90.72it/s, train_loss=0.00521, val_loss=0.00497]Epoch 30:  75%|███████▌  | 21/28 [00:00<00:00, 89.21it/s, train_loss=0.00625, val_loss=0.00497]Epoch 30:  79%|███████▊  | 22/28 [00:00<00:00, 91.20it/s, train_loss=0.00625, val_loss=0.00497]Epoch 30:  79%|███████▊  | 22/28 [00:00<00:00, 89.08it/s, train_loss=0.00463, val_loss=0.00497]Epoch 30:  82%|████████▏ | 23/28 [00:00<00:00, 91.14it/s, train_loss=0.00463, val_loss=0.00497]Epoch 30:  82%|████████▏ | 23/28 [00:00<00:00, 88.96it/s, train_loss=0.00462, val_loss=0.00497]Epoch 30:  86%|████████▌ | 24/28 [00:00<00:00, 90.90it/s, train_loss=0.00462, val_loss=0.00497]Epoch 30:  86%|████████▌ | 24/28 [00:00<00:00, 88.88it/s, train_loss=0.00465, val_loss=0.00497]Epoch 30:  89%|████████▉ | 25/28 [00:00<00:00, 90.75it/s, train_loss=0.00465, val_loss=0.00497]Epoch 30:  89%|████████▉ | 25/28 [00:00<00:00, 89.14it/s, train_loss=0.00531, val_loss=0.00497]Epoch 30:  93%|█████████▎| 26/28 [00:00<00:00, 90.57it/s, train_loss=0.00531, val_loss=0.00497]Epoch 30:  93%|█████████▎| 26/28 [00:00<00:00, 89.06it/s, train_loss=0.00478, val_loss=0.00497]Epoch 30:  96%|█████████▋| 27/28 [00:00<00:00, 90.43it/s, train_loss=0.00478, val_loss=0.00497]Epoch 30:  96%|█████████▋| 27/28 [00:00<00:00, 88.30it/s, train_loss=0.00573, val_loss=0.00497]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 89.89it/s, train_loss=0.00573, val_loss=0.00497]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 88.33it/s, train_loss=0.00684, val_loss=0.00497]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 164.88it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 197.05it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 209.44it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 211.93it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 211.49it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 214.47it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 217.96it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 217.68it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 217.71it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 219.15it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 220.02it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 221.21it/s][A
                                                                         [AEpoch 30: 100%|██████████| 28/28 [00:00<00:00, 73.52it/s, train_loss=0.00684, val_loss=0.00492]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 73.31it/s, train_loss=0.00684, val_loss=0.00492]Epoch 30:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00684, val_loss=0.00492]         Epoch 31:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00684, val_loss=0.00492]Epoch 31:   4%|▎         | 1/28 [00:00<00:00, 125.80it/s, train_loss=0.00684, val_loss=0.00492]Epoch 31:   4%|▎         | 1/28 [00:00<00:00, 77.01it/s, train_loss=0.00497, val_loss=0.00492] Epoch 31:   7%|▋         | 2/28 [00:00<00:00, 105.73it/s, train_loss=0.00497, val_loss=0.00492]Epoch 31:   7%|▋         | 2/28 [00:00<00:00, 81.41it/s, train_loss=0.00613, val_loss=0.00492] Epoch 31:  11%|█         | 3/28 [00:00<00:00, 98.31it/s, train_loss=0.00613, val_loss=0.00492]Epoch 31:  11%|█         | 3/28 [00:00<00:00, 83.06it/s, train_loss=0.00561, val_loss=0.00492]Epoch 31:  14%|█▍        | 4/28 [00:00<00:00, 95.00it/s, train_loss=0.00561, val_loss=0.00492]Epoch 31:  14%|█▍        | 4/28 [00:00<00:00, 85.56it/s, train_loss=0.0056, val_loss=0.00492] Epoch 31:  18%|█▊        | 5/28 [00:00<00:00, 94.56it/s, train_loss=0.0056, val_loss=0.00492]Epoch 31:  18%|█▊        | 5/28 [00:00<00:00, 85.25it/s, train_loss=0.00449, val_loss=0.00492]Epoch 31:  21%|██▏       | 6/28 [00:00<00:00, 93.37it/s, train_loss=0.00449, val_loss=0.00492]Epoch 31:  21%|██▏       | 6/28 [00:00<00:00, 85.57it/s, train_loss=0.00816, val_loss=0.00492]Epoch 31:  25%|██▌       | 7/28 [00:00<00:00, 92.44it/s, train_loss=0.00816, val_loss=0.00492]Epoch 31:  25%|██▌       | 7/28 [00:00<00:00, 85.88it/s, train_loss=0.00671, val_loss=0.00492]Epoch 31:  29%|██▊       | 8/28 [00:00<00:00, 91.80it/s, train_loss=0.00671, val_loss=0.00492]Epoch 31:  29%|██▊       | 8/28 [00:00<00:00, 87.75it/s, train_loss=0.00469, val_loss=0.00492]Epoch 31:  32%|███▏      | 9/28 [00:00<00:00, 92.66it/s, train_loss=0.00469, val_loss=0.00492]Epoch 31:  32%|███▏      | 9/28 [00:00<00:00, 86.84it/s, train_loss=0.00512, val_loss=0.00492]Epoch 31:  36%|███▌      | 10/28 [00:00<00:00, 91.51it/s, train_loss=0.00512, val_loss=0.00492]Epoch 31:  36%|███▌      | 10/28 [00:00<00:00, 86.96it/s, train_loss=0.0044, val_loss=0.00492] Epoch 31:  39%|███▉      | 11/28 [00:00<00:00, 91.21it/s, train_loss=0.0044, val_loss=0.00492]Epoch 31:  39%|███▉      | 11/28 [00:00<00:00, 87.01it/s, train_loss=0.00507, val_loss=0.00492]Epoch 31:  43%|████▎     | 12/28 [00:00<00:00, 90.83it/s, train_loss=0.00507, val_loss=0.00492]Epoch 31:  43%|████▎     | 12/28 [00:00<00:00, 88.23it/s, train_loss=0.00623, val_loss=0.00492]Epoch 31:  46%|████▋     | 13/28 [00:00<00:00, 91.28it/s, train_loss=0.00623, val_loss=0.00492]Epoch 31:  46%|████▋     | 13/28 [00:00<00:00, 87.43it/s, train_loss=0.00621, val_loss=0.00492]Epoch 31:  50%|█████     | 14/28 [00:00<00:00, 90.56it/s, train_loss=0.00621, val_loss=0.00492]Epoch 31:  50%|█████     | 14/28 [00:00<00:00, 87.47it/s, train_loss=0.0075, val_loss=0.00492] Epoch 31:  54%|█████▎    | 15/28 [00:00<00:00, 90.49it/s, train_loss=0.0075, val_loss=0.00492]Epoch 31:  54%|█████▎    | 15/28 [00:00<00:00, 87.46it/s, train_loss=0.00562, val_loss=0.00492]Epoch 31:  57%|█████▋    | 16/28 [00:00<00:00, 90.33it/s, train_loss=0.00562, val_loss=0.00492]Epoch 31:  57%|█████▋    | 16/28 [00:00<00:00, 88.38it/s, train_loss=0.00496, val_loss=0.00492]Epoch 31:  61%|██████    | 17/28 [00:00<00:00, 90.48it/s, train_loss=0.00496, val_loss=0.00492]Epoch 31:  61%|██████    | 17/28 [00:00<00:00, 87.74it/s, train_loss=0.0058, val_loss=0.00492] Epoch 31:  64%|██████▍   | 18/28 [00:00<00:00, 90.22it/s, train_loss=0.0058, val_loss=0.00492]Epoch 31:  64%|██████▍   | 18/28 [00:00<00:00, 87.74it/s, train_loss=0.00534, val_loss=0.00492]Epoch 31:  68%|██████▊   | 19/28 [00:00<00:00, 90.07it/s, train_loss=0.00534, val_loss=0.00492]Epoch 31:  68%|██████▊   | 19/28 [00:00<00:00, 87.75it/s, train_loss=0.00523, val_loss=0.00492]Epoch 31:  71%|███████▏  | 20/28 [00:00<00:00, 89.96it/s, train_loss=0.00523, val_loss=0.00492]Epoch 31:  71%|███████▏  | 20/28 [00:00<00:00, 88.42it/s, train_loss=0.00762, val_loss=0.00492]Epoch 31:  75%|███████▌  | 21/28 [00:00<00:00, 89.65it/s, train_loss=0.00762, val_loss=0.00492]Epoch 31:  75%|███████▌  | 21/28 [00:00<00:00, 88.19it/s, train_loss=0.00506, val_loss=0.00492]Epoch 31:  79%|███████▊  | 22/28 [00:00<00:00, 90.09it/s, train_loss=0.00506, val_loss=0.00492]Epoch 31:  79%|███████▊  | 22/28 [00:00<00:00, 88.20it/s, train_loss=0.00468, val_loss=0.00492]Epoch 31:  82%|████████▏ | 23/28 [00:00<00:00, 90.02it/s, train_loss=0.00468, val_loss=0.00492]Epoch 31:  82%|████████▏ | 23/28 [00:00<00:00, 88.20it/s, train_loss=0.00624, val_loss=0.00492]Epoch 31:  86%|████████▌ | 24/28 [00:00<00:00, 90.18it/s, train_loss=0.00624, val_loss=0.00492]Epoch 31:  86%|████████▌ | 24/28 [00:00<00:00, 88.82it/s, train_loss=0.00475, val_loss=0.00492]Epoch 31:  89%|████████▉ | 25/28 [00:00<00:00, 90.52it/s, train_loss=0.00475, val_loss=0.00492]Epoch 31:  89%|████████▉ | 25/28 [00:00<00:00, 88.42it/s, train_loss=0.00526, val_loss=0.00492]Epoch 31:  93%|█████████▎| 26/28 [00:00<00:00, 90.19it/s, train_loss=0.00526, val_loss=0.00492]Epoch 31:  93%|█████████▎| 26/28 [00:00<00:00, 88.41it/s, train_loss=0.00525, val_loss=0.00492]Epoch 31:  96%|█████████▋| 27/28 [00:00<00:00, 90.13it/s, train_loss=0.00525, val_loss=0.00492]Epoch 31:  96%|█████████▋| 27/28 [00:00<00:00, 88.40it/s, train_loss=0.00374, val_loss=0.00492]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 90.03it/s, train_loss=0.00374, val_loss=0.00492]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 88.47it/s, train_loss=0.00455, val_loss=0.00492]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 179.83it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 210.11it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 223.13it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 230.84it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 235.37it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 238.29it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 241.86it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 240.96it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 239.72it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 239.51it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 239.90it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 241.18it/s][A
                                                                         [AEpoch 31: 100%|██████████| 28/28 [00:00<00:00, 74.69it/s, train_loss=0.00455, val_loss=0.00487]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 74.52it/s, train_loss=0.00455, val_loss=0.00487]Epoch 31:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00455, val_loss=0.00487]         Epoch 32:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00455, val_loss=0.00487]Epoch 32:   4%|▎         | 1/28 [00:00<00:00, 130.43it/s, train_loss=0.00455, val_loss=0.00487]Epoch 32:   4%|▎         | 1/28 [00:00<00:00, 73.87it/s, train_loss=0.0042, val_loss=0.00487]  Epoch 32:   7%|▋         | 2/28 [00:00<00:00, 102.48it/s, train_loss=0.0042, val_loss=0.00487]Epoch 32:   7%|▋         | 2/28 [00:00<00:00, 80.12it/s, train_loss=0.00432, val_loss=0.00487]Epoch 32:  11%|█         | 3/28 [00:00<00:00, 97.87it/s, train_loss=0.00432, val_loss=0.00487]Epoch 32:  11%|█         | 3/28 [00:00<00:00, 82.31it/s, train_loss=0.00477, val_loss=0.00487]Epoch 32:  14%|█▍        | 4/28 [00:00<00:00, 94.76it/s, train_loss=0.00477, val_loss=0.00487]Epoch 32:  14%|█▍        | 4/28 [00:00<00:00, 86.25it/s, train_loss=0.00558, val_loss=0.00487]Epoch 32:  18%|█▊        | 5/28 [00:00<00:00, 94.41it/s, train_loss=0.00558, val_loss=0.00487]Epoch 32:  18%|█▊        | 5/28 [00:00<00:00, 84.79it/s, train_loss=0.00701, val_loss=0.00487]Epoch 32:  21%|██▏       | 6/28 [00:00<00:00, 92.39it/s, train_loss=0.00701, val_loss=0.00487]Epoch 32:  21%|██▏       | 6/28 [00:00<00:00, 85.38it/s, train_loss=0.0049, val_loss=0.00487] Epoch 32:  25%|██▌       | 7/28 [00:00<00:00, 92.48it/s, train_loss=0.0049, val_loss=0.00487]Epoch 32:  25%|██▌       | 7/28 [00:00<00:00, 85.78it/s, train_loss=0.00514, val_loss=0.00487]Epoch 32:  29%|██▊       | 8/28 [00:00<00:00, 91.98it/s, train_loss=0.00514, val_loss=0.00487]Epoch 32:  29%|██▊       | 8/28 [00:00<00:00, 87.74it/s, train_loss=0.00508, val_loss=0.00487]Epoch 32:  32%|███▏      | 9/28 [00:00<00:00, 92.50it/s, train_loss=0.00508, val_loss=0.00487]Epoch 32:  32%|███▏      | 9/28 [00:00<00:00, 86.81it/s, train_loss=0.00647, val_loss=0.00487]Epoch 32:  36%|███▌      | 10/28 [00:00<00:00, 91.53it/s, train_loss=0.00647, val_loss=0.00487]Epoch 32:  36%|███▌      | 10/28 [00:00<00:00, 86.94it/s, train_loss=0.008, val_loss=0.00487]  Epoch 32:  39%|███▉      | 11/28 [00:00<00:00, 91.33it/s, train_loss=0.008, val_loss=0.00487]Epoch 32:  39%|███▉      | 11/28 [00:00<00:00, 87.02it/s, train_loss=0.00596, val_loss=0.00487]Epoch 32:  43%|████▎     | 12/28 [00:00<00:00, 91.05it/s, train_loss=0.00596, val_loss=0.00487]Epoch 32:  43%|████▎     | 12/28 [00:00<00:00, 88.29it/s, train_loss=0.00495, val_loss=0.00487]Epoch 32:  46%|████▋     | 13/28 [00:00<00:00, 91.46it/s, train_loss=0.00495, val_loss=0.00487]Epoch 32:  46%|████▋     | 13/28 [00:00<00:00, 87.54it/s, train_loss=0.00545, val_loss=0.00487]Epoch 32:  50%|█████     | 14/28 [00:00<00:00, 90.82it/s, train_loss=0.00545, val_loss=0.00487]Epoch 32:  50%|█████     | 14/28 [00:00<00:00, 87.55it/s, train_loss=0.00604, val_loss=0.00487]Epoch 32:  54%|█████▎    | 15/28 [00:00<00:00, 90.62it/s, train_loss=0.00604, val_loss=0.00487]Epoch 32:  54%|█████▎    | 15/28 [00:00<00:00, 87.59it/s, train_loss=0.00538, val_loss=0.00487]Epoch 32:  57%|█████▋    | 16/28 [00:00<00:00, 90.43it/s, train_loss=0.00538, val_loss=0.00487]Epoch 32:  57%|█████▋    | 16/28 [00:00<00:00, 87.65it/s, train_loss=0.0052, val_loss=0.00487] Epoch 32:  61%|██████    | 17/28 [00:00<00:00, 89.93it/s, train_loss=0.0052, val_loss=0.00487]Epoch 32:  61%|██████    | 17/28 [00:00<00:00, 87.71it/s, train_loss=0.0053, val_loss=0.00487]Epoch 32:  64%|██████▍   | 18/28 [00:00<00:00, 90.18it/s, train_loss=0.0053, val_loss=0.00487]Epoch 32:  64%|██████▍   | 18/28 [00:00<00:00, 87.74it/s, train_loss=0.00575, val_loss=0.00487]Epoch 32:  68%|██████▊   | 19/28 [00:00<00:00, 90.14it/s, train_loss=0.00575, val_loss=0.00487]Epoch 32:  68%|██████▊   | 19/28 [00:00<00:00, 87.78it/s, train_loss=0.00585, val_loss=0.00487]Epoch 32:  71%|███████▏  | 20/28 [00:00<00:00, 89.84it/s, train_loss=0.00585, val_loss=0.00487]Epoch 32:  71%|███████▏  | 20/28 [00:00<00:00, 87.78it/s, train_loss=0.00422, val_loss=0.00487]Epoch 32:  75%|███████▌  | 21/28 [00:00<00:00, 89.86it/s, train_loss=0.00422, val_loss=0.00487]Epoch 32:  75%|███████▌  | 21/28 [00:00<00:00, 87.79it/s, train_loss=0.00414, val_loss=0.00487]Epoch 32:  79%|███████▊  | 22/28 [00:00<00:00, 89.82it/s, train_loss=0.00414, val_loss=0.00487]Epoch 32:  79%|███████▊  | 22/28 [00:00<00:00, 87.74it/s, train_loss=0.00611, val_loss=0.00487]Epoch 32:  82%|████████▏ | 23/28 [00:00<00:00, 89.66it/s, train_loss=0.00611, val_loss=0.00487]Epoch 32:  82%|████████▏ | 23/28 [00:00<00:00, 87.77it/s, train_loss=0.00718, val_loss=0.00487]Epoch 32:  86%|████████▌ | 24/28 [00:00<00:00, 89.26it/s, train_loss=0.00718, val_loss=0.00487]Epoch 32:  86%|████████▌ | 24/28 [00:00<00:00, 87.16it/s, train_loss=0.00361, val_loss=0.00487]Epoch 32:  89%|████████▉ | 25/28 [00:00<00:00, 88.86it/s, train_loss=0.00361, val_loss=0.00487]Epoch 32:  89%|████████▉ | 25/28 [00:00<00:00, 87.22it/s, train_loss=0.00796, val_loss=0.00487]Epoch 32:  93%|█████████▎| 26/28 [00:00<00:00, 89.07it/s, train_loss=0.00796, val_loss=0.00487]Epoch 32:  93%|█████████▎| 26/28 [00:00<00:00, 87.26it/s, train_loss=0.00476, val_loss=0.00487]Epoch 32:  96%|█████████▋| 27/28 [00:00<00:00, 89.05it/s, train_loss=0.00476, val_loss=0.00487]Epoch 32:  96%|█████████▋| 27/28 [00:00<00:00, 87.33it/s, train_loss=0.00462, val_loss=0.00487]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 88.74it/s, train_loss=0.00462, val_loss=0.00487]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 87.42it/s, train_loss=0.00386, val_loss=0.00487]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 194.28it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 226.73it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 240.10it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 247.58it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 251.50it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 249.04it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 246.23it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 244.81it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 245.49it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 246.11it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 246.15it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 247.10it/s][A
                                                                         [AEpoch 32: 100%|██████████| 28/28 [00:00<00:00, 74.36it/s, train_loss=0.00386, val_loss=0.00484]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 74.19it/s, train_loss=0.00386, val_loss=0.00484]Epoch 32:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00386, val_loss=0.00484]         Epoch 33:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00386, val_loss=0.00484]Epoch 33:   4%|▎         | 1/28 [00:00<00:00, 135.89it/s, train_loss=0.00386, val_loss=0.00484]Epoch 33:   4%|▎         | 1/28 [00:00<00:00, 79.52it/s, train_loss=0.00527, val_loss=0.00484] Epoch 33:   7%|▋         | 2/28 [00:00<00:00, 109.29it/s, train_loss=0.00527, val_loss=0.00484]Epoch 33:   7%|▋         | 2/28 [00:00<00:00, 83.48it/s, train_loss=0.00512, val_loss=0.00484] Epoch 33:  11%|█         | 3/28 [00:00<00:00, 101.16it/s, train_loss=0.00512, val_loss=0.00484]Epoch 33:  11%|█         | 3/28 [00:00<00:00, 85.02it/s, train_loss=0.00416, val_loss=0.00484] Epoch 33:  14%|█▍        | 4/28 [00:00<00:00, 97.11it/s, train_loss=0.00416, val_loss=0.00484]Epoch 33:  14%|█▍        | 4/28 [00:00<00:00, 89.28it/s, train_loss=0.00619, val_loss=0.00484]Epoch 33:  18%|█▊        | 5/28 [00:00<00:00, 97.18it/s, train_loss=0.00619, val_loss=0.00484]Epoch 33:  18%|█▊        | 5/28 [00:00<00:00, 88.08it/s, train_loss=0.00446, val_loss=0.00484]Epoch 33:  21%|██▏       | 6/28 [00:00<00:00, 95.97it/s, train_loss=0.00446, val_loss=0.00484]Epoch 33:  21%|██▏       | 6/28 [00:00<00:00, 88.18it/s, train_loss=0.00637, val_loss=0.00484]Epoch 33:  25%|██▌       | 7/28 [00:00<00:00, 94.74it/s, train_loss=0.00637, val_loss=0.00484]Epoch 33:  25%|██▌       | 7/28 [00:00<00:00, 88.32it/s, train_loss=0.00717, val_loss=0.00484]Epoch 33:  29%|██▊       | 8/28 [00:00<00:00, 94.22it/s, train_loss=0.00717, val_loss=0.00484]Epoch 33:  29%|██▊       | 8/28 [00:00<00:00, 90.41it/s, train_loss=0.00439, val_loss=0.00484]Epoch 33:  32%|███▏      | 9/28 [00:00<00:00, 94.98it/s, train_loss=0.00439, val_loss=0.00484]Epoch 33:  32%|███▏      | 9/28 [00:00<00:00, 89.06it/s, train_loss=0.00522, val_loss=0.00484]Epoch 33:  36%|███▌      | 10/28 [00:00<00:00, 93.91it/s, train_loss=0.00522, val_loss=0.00484]Epoch 33:  36%|███▌      | 10/28 [00:00<00:00, 89.00it/s, train_loss=0.00549, val_loss=0.00484]Epoch 33:  39%|███▉      | 11/28 [00:00<00:00, 93.48it/s, train_loss=0.00549, val_loss=0.00484]Epoch 33:  39%|███▉      | 11/28 [00:00<00:00, 88.91it/s, train_loss=0.00673, val_loss=0.00484]Epoch 33:  43%|████▎     | 12/28 [00:00<00:00, 92.94it/s, train_loss=0.00673, val_loss=0.00484]Epoch 33:  43%|████▎     | 12/28 [00:00<00:00, 88.93it/s, train_loss=0.00456, val_loss=0.00484]Epoch 33:  46%|████▋     | 13/28 [00:00<00:00, 92.06it/s, train_loss=0.00456, val_loss=0.00484]Epoch 33:  46%|████▋     | 13/28 [00:00<00:00, 88.89it/s, train_loss=0.00581, val_loss=0.00484]Epoch 33:  50%|█████     | 14/28 [00:00<00:00, 92.29it/s, train_loss=0.00581, val_loss=0.00484]Epoch 33:  50%|█████     | 14/28 [00:00<00:00, 88.81it/s, train_loss=0.00575, val_loss=0.00484]Epoch 33:  54%|█████▎    | 15/28 [00:00<00:00, 91.86it/s, train_loss=0.00575, val_loss=0.00484]Epoch 33:  54%|█████▎    | 15/28 [00:00<00:00, 88.80it/s, train_loss=0.00471, val_loss=0.00484]Epoch 33:  57%|█████▋    | 16/28 [00:00<00:00, 91.67it/s, train_loss=0.00471, val_loss=0.00484]Epoch 33:  57%|█████▋    | 16/28 [00:00<00:00, 89.59it/s, train_loss=0.00449, val_loss=0.00484]Epoch 33:  61%|██████    | 17/28 [00:00<00:00, 91.66it/s, train_loss=0.00449, val_loss=0.00484]Epoch 33:  61%|██████    | 17/28 [00:00<00:00, 89.49it/s, train_loss=0.00607, val_loss=0.00484]Epoch 33:  64%|██████▍   | 18/28 [00:00<00:00, 91.88it/s, train_loss=0.00607, val_loss=0.00484]Epoch 33:  64%|██████▍   | 18/28 [00:00<00:00, 89.44it/s, train_loss=0.00536, val_loss=0.00484]Epoch 33:  68%|██████▊   | 19/28 [00:00<00:00, 91.86it/s, train_loss=0.00536, val_loss=0.00484]Epoch 33:  68%|██████▊   | 19/28 [00:00<00:00, 89.42it/s, train_loss=0.00722, val_loss=0.00484]Epoch 33:  71%|███████▏  | 20/28 [00:00<00:00, 91.26it/s, train_loss=0.00722, val_loss=0.00484]Epoch 33:  71%|███████▏  | 20/28 [00:00<00:00, 89.37it/s, train_loss=0.00661, val_loss=0.00484]Epoch 33:  75%|███████▌  | 21/28 [00:00<00:00, 91.47it/s, train_loss=0.00661, val_loss=0.00484]Epoch 33:  75%|███████▌  | 21/28 [00:00<00:00, 89.31it/s, train_loss=0.00549, val_loss=0.00484]Epoch 33:  79%|███████▊  | 22/28 [00:00<00:00, 91.37it/s, train_loss=0.00549, val_loss=0.00484]Epoch 33:  79%|███████▊  | 22/28 [00:00<00:00, 89.25it/s, train_loss=0.00626, val_loss=0.00484]Epoch 33:  82%|████████▏ | 23/28 [00:00<00:00, 91.22it/s, train_loss=0.00626, val_loss=0.00484]Epoch 33:  82%|████████▏ | 23/28 [00:00<00:00, 89.20it/s, train_loss=0.00532, val_loss=0.00484]Epoch 33:  86%|████████▌ | 24/28 [00:00<00:00, 90.67it/s, train_loss=0.00532, val_loss=0.00484]Epoch 33:  86%|████████▌ | 24/28 [00:00<00:00, 89.20it/s, train_loss=0.00467, val_loss=0.00484]Epoch 33:  89%|████████▉ | 25/28 [00:00<00:00, 90.98it/s, train_loss=0.00467, val_loss=0.00484]Epoch 33:  89%|████████▉ | 25/28 [00:00<00:00, 89.16it/s, train_loss=0.00475, val_loss=0.00484]Epoch 33:  93%|█████████▎| 26/28 [00:00<00:00, 90.88it/s, train_loss=0.00475, val_loss=0.00484]Epoch 33:  93%|█████████▎| 26/28 [00:00<00:00, 89.13it/s, train_loss=0.00482, val_loss=0.00484]Epoch 33:  96%|█████████▋| 27/28 [00:00<00:00, 90.77it/s, train_loss=0.00482, val_loss=0.00484]Epoch 33:  96%|█████████▋| 27/28 [00:00<00:00, 89.14it/s, train_loss=0.00483, val_loss=0.00484]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 90.50it/s, train_loss=0.00483, val_loss=0.00484]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 89.33it/s, train_loss=0.00446, val_loss=0.00484]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 216.11it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 244.62it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 258.99it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 262.55it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 266.31it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 267.07it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 269.35it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 267.42it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 265.31it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 263.30it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 262.96it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 263.82it/s][A
                                                                         [AEpoch 33: 100%|██████████| 28/28 [00:00<00:00, 76.27it/s, train_loss=0.00446, val_loss=0.00483]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 76.09it/s, train_loss=0.00446, val_loss=0.00483]Epoch 33:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00446, val_loss=0.00483]         Epoch 34:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00446, val_loss=0.00483]Epoch 34:   4%|▎         | 1/28 [00:00<00:00, 125.94it/s, train_loss=0.00446, val_loss=0.00483]Epoch 34:   4%|▎         | 1/28 [00:00<00:00, 78.22it/s, train_loss=0.00626, val_loss=0.00483] Epoch 34:   7%|▋         | 2/28 [00:00<00:00, 108.63it/s, train_loss=0.00626, val_loss=0.00483]Epoch 34:   7%|▋         | 2/28 [00:00<00:00, 82.55it/s, train_loss=0.0043, val_loss=0.00483]  Epoch 34:  11%|█         | 3/28 [00:00<00:00, 100.91it/s, train_loss=0.0043, val_loss=0.00483]Epoch 34:  11%|█         | 3/28 [00:00<00:00, 84.09it/s, train_loss=0.00481, val_loss=0.00483]Epoch 34:  14%|█▍        | 4/28 [00:00<00:00, 97.13it/s, train_loss=0.00481, val_loss=0.00483]Epoch 34:  14%|█▍        | 4/28 [00:00<00:00, 88.38it/s, train_loss=0.00572, val_loss=0.00483]Epoch 34:  18%|█▊        | 5/28 [00:00<00:00, 96.02it/s, train_loss=0.00572, val_loss=0.00483]Epoch 34:  18%|█▊        | 5/28 [00:00<00:00, 86.52it/s, train_loss=0.00518, val_loss=0.00483]Epoch 34:  21%|██▏       | 6/28 [00:00<00:00, 94.35it/s, train_loss=0.00518, val_loss=0.00483]Epoch 34:  21%|██▏       | 6/28 [00:00<00:00, 86.90it/s, train_loss=0.00625, val_loss=0.00483]Epoch 34:  25%|██▌       | 7/28 [00:00<00:00, 93.68it/s, train_loss=0.00625, val_loss=0.00483]Epoch 34:  25%|██▌       | 7/28 [00:00<00:00, 87.13it/s, train_loss=0.00483, val_loss=0.00483]Epoch 34:  29%|██▊       | 8/28 [00:00<00:00, 92.87it/s, train_loss=0.00483, val_loss=0.00483]Epoch 34:  29%|██▊       | 8/28 [00:00<00:00, 87.33it/s, train_loss=0.00564, val_loss=0.00483]Epoch 34:  32%|███▏      | 9/28 [00:00<00:00, 91.64it/s, train_loss=0.00564, val_loss=0.00483]Epoch 34:  32%|███▏      | 9/28 [00:00<00:00, 87.45it/s, train_loss=0.00509, val_loss=0.00483]Epoch 34:  36%|███▌      | 10/28 [00:00<00:00, 91.90it/s, train_loss=0.00509, val_loss=0.00483]Epoch 34:  36%|███▌      | 10/28 [00:00<00:00, 87.54it/s, train_loss=0.00455, val_loss=0.00483]Epoch 34:  39%|███▉      | 11/28 [00:00<00:00, 91.34it/s, train_loss=0.00455, val_loss=0.00483]Epoch 34:  39%|███▉      | 11/28 [00:00<00:00, 87.65it/s, train_loss=0.00616, val_loss=0.00483]Epoch 34:  43%|████▎     | 12/28 [00:00<00:00, 91.58it/s, train_loss=0.00616, val_loss=0.00483]Epoch 34:  43%|████▎     | 12/28 [00:00<00:00, 88.91it/s, train_loss=0.00472, val_loss=0.00483]Epoch 34:  46%|████▋     | 13/28 [00:00<00:00, 92.07it/s, train_loss=0.00472, val_loss=0.00483]Epoch 34:  46%|████▋     | 13/28 [00:00<00:00, 88.91it/s, train_loss=0.00563, val_loss=0.00483]Epoch 34:  50%|█████     | 14/28 [00:00<00:00, 92.36it/s, train_loss=0.00563, val_loss=0.00483]Epoch 34:  50%|█████     | 14/28 [00:00<00:00, 88.88it/s, train_loss=0.00423, val_loss=0.00483]Epoch 34:  54%|█████▎    | 15/28 [00:00<00:00, 92.02it/s, train_loss=0.00423, val_loss=0.00483]Epoch 34:  54%|█████▎    | 15/28 [00:00<00:00, 88.85it/s, train_loss=0.00509, val_loss=0.00483]Epoch 34:  57%|█████▋    | 16/28 [00:00<00:00, 91.32it/s, train_loss=0.00509, val_loss=0.00483]Epoch 34:  57%|█████▋    | 16/28 [00:00<00:00, 88.88it/s, train_loss=0.00653, val_loss=0.00483]Epoch 34:  61%|██████    | 17/28 [00:00<00:00, 91.50it/s, train_loss=0.00653, val_loss=0.00483]Epoch 34:  61%|██████    | 17/28 [00:00<00:00, 88.87it/s, train_loss=0.0065, val_loss=0.00483] Epoch 34:  64%|██████▍   | 18/28 [00:00<00:00, 91.41it/s, train_loss=0.0065, val_loss=0.00483]Epoch 34:  64%|██████▍   | 18/28 [00:00<00:00, 88.79it/s, train_loss=0.00569, val_loss=0.00483]Epoch 34:  68%|██████▊   | 19/28 [00:00<00:00, 91.17it/s, train_loss=0.00569, val_loss=0.00483]Epoch 34:  68%|██████▊   | 19/28 [00:00<00:00, 88.78it/s, train_loss=0.00544, val_loss=0.00483]Epoch 34:  71%|███████▏  | 20/28 [00:00<00:00, 90.66it/s, train_loss=0.00544, val_loss=0.00483]Epoch 34:  71%|███████▏  | 20/28 [00:00<00:00, 88.03it/s, train_loss=0.00464, val_loss=0.00483]Epoch 34:  75%|███████▌  | 21/28 [00:00<00:00, 90.21it/s, train_loss=0.00464, val_loss=0.00483]Epoch 34:  75%|███████▌  | 21/28 [00:00<00:00, 88.02it/s, train_loss=0.00629, val_loss=0.00483]Epoch 34:  79%|███████▊  | 22/28 [00:00<00:00, 89.96it/s, train_loss=0.00629, val_loss=0.00483]Epoch 34:  79%|███████▊  | 22/28 [00:00<00:00, 88.06it/s, train_loss=0.00497, val_loss=0.00483]Epoch 34:  82%|████████▏ | 23/28 [00:00<00:00, 89.99it/s, train_loss=0.00497, val_loss=0.00483]Epoch 34:  82%|████████▏ | 23/28 [00:00<00:00, 88.10it/s, train_loss=0.00555, val_loss=0.00483]Epoch 34:  86%|████████▌ | 24/28 [00:00<00:00, 89.66it/s, train_loss=0.00555, val_loss=0.00483]Epoch 34:  86%|████████▌ | 24/28 [00:00<00:00, 88.11it/s, train_loss=0.0043, val_loss=0.00483] Epoch 34:  89%|████████▉ | 25/28 [00:00<00:00, 89.88it/s, train_loss=0.0043, val_loss=0.00483]Epoch 34:  89%|████████▉ | 25/28 [00:00<00:00, 88.09it/s, train_loss=0.00603, val_loss=0.00483]Epoch 34:  93%|█████████▎| 26/28 [00:00<00:00, 89.79it/s, train_loss=0.00603, val_loss=0.00483]Epoch 34:  93%|█████████▎| 26/28 [00:00<00:00, 88.11it/s, train_loss=0.00572, val_loss=0.00483]Epoch 34:  96%|█████████▋| 27/28 [00:00<00:00, 89.66it/s, train_loss=0.00572, val_loss=0.00483]Epoch 34:  96%|█████████▋| 27/28 [00:00<00:00, 88.65it/s, train_loss=0.00575, val_loss=0.00483]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 89.97it/s, train_loss=0.00575, val_loss=0.00483]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 88.69it/s, train_loss=0.00427, val_loss=0.00483]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 151.91it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 203.54it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 229.74it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 245.59it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 250.22it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 253.62it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 255.45it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 259.52it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 261.21it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 262.97it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 264.20it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 265.59it/s][A
                                                                         [AEpoch 34: 100%|██████████| 28/28 [00:00<00:00, 75.63it/s, train_loss=0.00427, val_loss=0.0048] Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 75.45it/s, train_loss=0.00427, val_loss=0.0048]Epoch 34:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00427, val_loss=0.0048]         Epoch 35:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00427, val_loss=0.0048]Epoch 35:   4%|▎         | 1/28 [00:00<00:00, 130.26it/s, train_loss=0.00427, val_loss=0.0048]Epoch 35:   4%|▎         | 1/28 [00:00<00:00, 78.82it/s, train_loss=0.00434, val_loss=0.0048] Epoch 35:   7%|▋         | 2/28 [00:00<00:00, 110.14it/s, train_loss=0.00434, val_loss=0.0048]Epoch 35:   7%|▋         | 2/28 [00:00<00:00, 83.07it/s, train_loss=0.0053, val_loss=0.0048]  Epoch 35:  11%|█         | 3/28 [00:00<00:00, 101.17it/s, train_loss=0.0053, val_loss=0.0048]Epoch 35:  11%|█         | 3/28 [00:00<00:00, 84.68it/s, train_loss=0.0052, val_loss=0.0048] Epoch 35:  14%|█▍        | 4/28 [00:00<00:00, 97.38it/s, train_loss=0.0052, val_loss=0.0048]Epoch 35:  14%|█▍        | 4/28 [00:00<00:00, 89.43it/s, train_loss=0.00549, val_loss=0.0048]Epoch 35:  18%|█▊        | 5/28 [00:00<00:00, 97.22it/s, train_loss=0.00549, val_loss=0.0048]Epoch 35:  18%|█▊        | 5/28 [00:00<00:00, 87.37it/s, train_loss=0.00802, val_loss=0.0048]Epoch 35:  21%|██▏       | 6/28 [00:00<00:00, 95.30it/s, train_loss=0.00802, val_loss=0.0048]Epoch 35:  21%|██▏       | 6/28 [00:00<00:00, 87.52it/s, train_loss=0.00672, val_loss=0.0048]Epoch 35:  25%|██▌       | 7/28 [00:00<00:00, 94.19it/s, train_loss=0.00672, val_loss=0.0048]Epoch 35:  25%|██▌       | 7/28 [00:00<00:00, 87.62it/s, train_loss=0.00483, val_loss=0.0048]Epoch 35:  29%|██▊       | 8/28 [00:00<00:00, 93.28it/s, train_loss=0.00483, val_loss=0.0048]Epoch 35:  29%|██▊       | 8/28 [00:00<00:00, 89.70it/s, train_loss=0.00545, val_loss=0.0048]Epoch 35:  32%|███▏      | 9/28 [00:00<00:00, 93.86it/s, train_loss=0.00545, val_loss=0.0048]Epoch 35:  32%|███▏      | 9/28 [00:00<00:00, 89.12it/s, train_loss=0.00536, val_loss=0.0048]Epoch 35:  36%|███▌      | 10/28 [00:00<00:00, 93.78it/s, train_loss=0.00536, val_loss=0.0048]Epoch 35:  36%|███▌      | 10/28 [00:00<00:00, 89.07it/s, train_loss=0.00453, val_loss=0.0048]Epoch 35:  39%|███▉      | 11/28 [00:00<00:00, 93.28it/s, train_loss=0.00453, val_loss=0.0048]Epoch 35:  39%|███▉      | 11/28 [00:00<00:00, 89.01it/s, train_loss=0.00439, val_loss=0.0048]Epoch 35:  43%|████▎     | 12/28 [00:00<00:00, 92.78it/s, train_loss=0.00439, val_loss=0.0048]Epoch 35:  43%|████▎     | 12/28 [00:00<00:00, 90.33it/s, train_loss=0.0043, val_loss=0.0048] Epoch 35:  46%|████▋     | 13/28 [00:00<00:00, 92.95it/s, train_loss=0.0043, val_loss=0.0048]Epoch 35:  46%|████▋     | 13/28 [00:00<00:00, 89.84it/s, train_loss=0.00438, val_loss=0.0048]Epoch 35:  50%|█████     | 14/28 [00:00<00:00, 93.20it/s, train_loss=0.00438, val_loss=0.0048]Epoch 35:  50%|█████     | 14/28 [00:00<00:00, 89.74it/s, train_loss=0.00572, val_loss=0.0048]Epoch 35:  54%|█████▎    | 15/28 [00:00<00:00, 92.99it/s, train_loss=0.00572, val_loss=0.0048]Epoch 35:  54%|█████▎    | 15/28 [00:00<00:00, 89.63it/s, train_loss=0.00736, val_loss=0.0048]Epoch 35:  57%|█████▋    | 16/28 [00:00<00:00, 92.63it/s, train_loss=0.00736, val_loss=0.0048]Epoch 35:  57%|█████▋    | 16/28 [00:00<00:00, 89.56it/s, train_loss=0.00559, val_loss=0.0048]Epoch 35:  61%|██████    | 17/28 [00:00<00:00, 91.84it/s, train_loss=0.00559, val_loss=0.0048]Epoch 35:  61%|██████    | 17/28 [00:00<00:00, 89.50it/s, train_loss=0.00421, val_loss=0.0048]Epoch 35:  64%|██████▍   | 18/28 [00:00<00:00, 92.16it/s, train_loss=0.00421, val_loss=0.0048]Epoch 35:  64%|██████▍   | 18/28 [00:00<00:00, 89.40it/s, train_loss=0.00485, val_loss=0.0048]Epoch 35:  68%|██████▊   | 19/28 [00:00<00:00, 91.80it/s, train_loss=0.00485, val_loss=0.0048]Epoch 35:  68%|██████▊   | 19/28 [00:00<00:00, 89.32it/s, train_loss=0.00382, val_loss=0.0048]Epoch 35:  71%|███████▏  | 20/28 [00:00<00:00, 91.52it/s, train_loss=0.00382, val_loss=0.0048]Epoch 35:  71%|███████▏  | 20/28 [00:00<00:00, 89.98it/s, train_loss=0.00484, val_loss=0.0048]Epoch 35:  75%|███████▌  | 21/28 [00:00<00:00, 91.78it/s, train_loss=0.00484, val_loss=0.0048]Epoch 35:  75%|███████▌  | 21/28 [00:00<00:00, 89.92it/s, train_loss=0.00663, val_loss=0.0048]Epoch 35:  79%|███████▊  | 22/28 [00:00<00:00, 91.99it/s, train_loss=0.00663, val_loss=0.0048]Epoch 35:  79%|███████▊  | 22/28 [00:00<00:00, 89.85it/s, train_loss=0.00608, val_loss=0.0048]Epoch 35:  82%|████████▏ | 23/28 [00:00<00:00, 91.83it/s, train_loss=0.00608, val_loss=0.0048]Epoch 35:  82%|████████▏ | 23/28 [00:00<00:00, 89.81it/s, train_loss=0.00458, val_loss=0.0048]Epoch 35:  86%|████████▌ | 24/28 [00:00<00:00, 91.38it/s, train_loss=0.00458, val_loss=0.0048]Epoch 35:  86%|████████▌ | 24/28 [00:00<00:00, 89.73it/s, train_loss=0.00525, val_loss=0.0048]Epoch 35:  89%|████████▉ | 25/28 [00:00<00:00, 91.47it/s, train_loss=0.00525, val_loss=0.0048]Epoch 35:  89%|████████▉ | 25/28 [00:00<00:00, 89.68it/s, train_loss=0.00693, val_loss=0.0048]Epoch 35:  93%|█████████▎| 26/28 [00:00<00:00, 91.40it/s, train_loss=0.00693, val_loss=0.0048]Epoch 35:  93%|█████████▎| 26/28 [00:00<00:00, 89.61it/s, train_loss=0.00508, val_loss=0.0048]Epoch 35:  96%|█████████▋| 27/28 [00:00<00:00, 91.27it/s, train_loss=0.00508, val_loss=0.0048]Epoch 35:  96%|█████████▋| 27/28 [00:00<00:00, 89.58it/s, train_loss=0.00756, val_loss=0.0048]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 90.80it/s, train_loss=0.00756, val_loss=0.0048]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 89.02it/s, train_loss=0.00569, val_loss=0.0048]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 119.33it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 155.11it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 174.15it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 183.00it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 185.84it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 189.17it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 197.36it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 206.52it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 214.90it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 221.56it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 226.68it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 229.55it/s][A
                                                                         [AEpoch 35: 100%|██████████| 28/28 [00:00<00:00, 74.52it/s, train_loss=0.00569, val_loss=0.00477]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 74.37it/s, train_loss=0.00569, val_loss=0.00477]Epoch 35:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00569, val_loss=0.00477]         Epoch 36:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00569, val_loss=0.00477]Epoch 36:   4%|▎         | 1/28 [00:00<00:00, 139.00it/s, train_loss=0.00569, val_loss=0.00477]Epoch 36:   4%|▎         | 1/28 [00:00<00:00, 80.38it/s, train_loss=0.00712, val_loss=0.00477] Epoch 36:   7%|▋         | 2/28 [00:00<00:00, 111.70it/s, train_loss=0.00712, val_loss=0.00477]Epoch 36:   7%|▋         | 2/28 [00:00<00:00, 83.98it/s, train_loss=0.0048, val_loss=0.00477]  Epoch 36:  11%|█         | 3/28 [00:00<00:00, 102.20it/s, train_loss=0.0048, val_loss=0.00477]Epoch 36:  11%|█         | 3/28 [00:00<00:00, 85.54it/s, train_loss=0.00498, val_loss=0.00477]Epoch 36:  14%|█▍        | 4/28 [00:00<00:00, 98.45it/s, train_loss=0.00498, val_loss=0.00477]Epoch 36:  14%|█▍        | 4/28 [00:00<00:00, 90.39it/s, train_loss=0.00415, val_loss=0.00477]Epoch 36:  18%|█▊        | 5/28 [00:00<00:00, 98.22it/s, train_loss=0.00415, val_loss=0.00477]Epoch 36:  18%|█▊        | 5/28 [00:00<00:00, 88.02it/s, train_loss=0.00512, val_loss=0.00477]Epoch 36:  21%|██▏       | 6/28 [00:00<00:00, 95.72it/s, train_loss=0.00512, val_loss=0.00477]Epoch 36:  21%|██▏       | 6/28 [00:00<00:00, 88.05it/s, train_loss=0.00386, val_loss=0.00477]Epoch 36:  25%|██▌       | 7/28 [00:00<00:00, 94.79it/s, train_loss=0.00386, val_loss=0.00477]Epoch 36:  25%|██▌       | 7/28 [00:00<00:00, 88.12it/s, train_loss=0.00543, val_loss=0.00477]Epoch 36:  29%|██▊       | 8/28 [00:00<00:00, 93.92it/s, train_loss=0.00543, val_loss=0.00477]Epoch 36:  29%|██▊       | 8/28 [00:00<00:00, 88.16it/s, train_loss=0.005, val_loss=0.00477]  Epoch 36:  32%|███▏      | 9/28 [00:00<00:00, 92.36it/s, train_loss=0.005, val_loss=0.00477]Epoch 36:  32%|███▏      | 9/28 [00:00<00:00, 88.18it/s, train_loss=0.00493, val_loss=0.00477]Epoch 36:  36%|███▌      | 10/28 [00:00<00:00, 92.88it/s, train_loss=0.00493, val_loss=0.00477]Epoch 36:  36%|███▌      | 10/28 [00:00<00:00, 88.17it/s, train_loss=0.00584, val_loss=0.00477]Epoch 36:  39%|███▉      | 11/28 [00:00<00:00, 92.43it/s, train_loss=0.00584, val_loss=0.00477]Epoch 36:  39%|███▉      | 11/28 [00:00<00:00, 88.22it/s, train_loss=0.00577, val_loss=0.00477]Epoch 36:  43%|████▎     | 12/28 [00:00<00:00, 91.80it/s, train_loss=0.00577, val_loss=0.00477]Epoch 36:  43%|████▎     | 12/28 [00:00<00:00, 89.53it/s, train_loss=0.00518, val_loss=0.00477]Epoch 36:  46%|████▋     | 13/28 [00:00<00:00, 92.36it/s, train_loss=0.00518, val_loss=0.00477]Epoch 36:  46%|████▋     | 13/28 [00:00<00:00, 89.37it/s, train_loss=0.00518, val_loss=0.00477]Epoch 36:  50%|█████     | 14/28 [00:00<00:00, 92.45it/s, train_loss=0.00518, val_loss=0.00477]Epoch 36:  50%|█████     | 14/28 [00:00<00:00, 89.30it/s, train_loss=0.00573, val_loss=0.00477]Epoch 36:  54%|█████▎    | 15/28 [00:00<00:00, 92.09it/s, train_loss=0.00573, val_loss=0.00477]Epoch 36:  54%|█████▎    | 15/28 [00:00<00:00, 89.28it/s, train_loss=0.00678, val_loss=0.00477]Epoch 36:  57%|█████▋    | 16/28 [00:00<00:00, 91.51it/s, train_loss=0.00678, val_loss=0.00477]Epoch 36:  57%|█████▋    | 16/28 [00:00<00:00, 90.07it/s, train_loss=0.00616, val_loss=0.00477]Epoch 36:  61%|██████    | 17/28 [00:00<00:00, 92.35it/s, train_loss=0.00616, val_loss=0.00477]Epoch 36:  61%|██████    | 17/28 [00:00<00:00, 89.95it/s, train_loss=0.00416, val_loss=0.00477]Epoch 36:  64%|██████▍   | 18/28 [00:00<00:00, 92.52it/s, train_loss=0.00416, val_loss=0.00477]Epoch 36:  64%|██████▍   | 18/28 [00:00<00:00, 89.85it/s, train_loss=0.00458, val_loss=0.00477]Epoch 36:  68%|██████▊   | 19/28 [00:00<00:00, 92.39it/s, train_loss=0.00458, val_loss=0.00477]Epoch 36:  68%|██████▊   | 19/28 [00:00<00:00, 89.78it/s, train_loss=0.00516, val_loss=0.00477]Epoch 36:  71%|███████▏  | 20/28 [00:00<00:00, 92.16it/s, train_loss=0.00516, val_loss=0.00477]Epoch 36:  71%|███████▏  | 20/28 [00:00<00:00, 90.52it/s, train_loss=0.00719, val_loss=0.00477]Epoch 36:  75%|███████▌  | 21/28 [00:00<00:00, 92.43it/s, train_loss=0.00719, val_loss=0.00477]Epoch 36:  75%|███████▌  | 21/28 [00:00<00:00, 90.41it/s, train_loss=0.00565, val_loss=0.00477]Epoch 36:  79%|███████▊  | 22/28 [00:00<00:00, 92.58it/s, train_loss=0.00565, val_loss=0.00477]Epoch 36:  79%|███████▊  | 22/28 [00:00<00:00, 90.31it/s, train_loss=0.00615, val_loss=0.00477]Epoch 36:  82%|████████▏ | 23/28 [00:00<00:00, 92.39it/s, train_loss=0.00615, val_loss=0.00477]Epoch 36:  82%|████████▏ | 23/28 [00:00<00:00, 90.21it/s, train_loss=0.00701, val_loss=0.00477]Epoch 36:  86%|████████▌ | 24/28 [00:00<00:00, 91.87it/s, train_loss=0.00701, val_loss=0.00477]Epoch 36:  86%|████████▌ | 24/28 [00:00<00:00, 90.12it/s, train_loss=0.00438, val_loss=0.00477]Epoch 36:  89%|████████▉ | 25/28 [00:00<00:00, 91.94it/s, train_loss=0.00438, val_loss=0.00477]Epoch 36:  89%|████████▉ | 25/28 [00:00<00:00, 90.02it/s, train_loss=0.00453, val_loss=0.00477]Epoch 36:  93%|█████████▎| 26/28 [00:00<00:00, 91.81it/s, train_loss=0.00453, val_loss=0.00477]Epoch 36:  93%|█████████▎| 26/28 [00:00<00:00, 89.93it/s, train_loss=0.00528, val_loss=0.00477]Epoch 36:  96%|█████████▋| 27/28 [00:00<00:00, 91.64it/s, train_loss=0.00528, val_loss=0.00477]Epoch 36:  96%|█████████▋| 27/28 [00:00<00:00, 89.91it/s, train_loss=0.00558, val_loss=0.00477]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 91.22it/s, train_loss=0.00558, val_loss=0.00477]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 89.62it/s, train_loss=0.00436, val_loss=0.00477]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 139.45it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 171.26it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 188.16it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 191.72it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 195.69it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 198.93it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 202.17it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 205.70it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 207.61it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 209.00it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 210.05it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 214.56it/s][A
                                                                         [AEpoch 36: 100%|██████████| 28/28 [00:00<00:00, 74.68it/s, train_loss=0.00436, val_loss=0.00477]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 74.56it/s, train_loss=0.00436, val_loss=0.00477]Epoch 36:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00436, val_loss=0.00477]         Epoch 37:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00436, val_loss=0.00477]Epoch 37:   4%|▎         | 1/28 [00:00<00:00, 151.00it/s, train_loss=0.00436, val_loss=0.00477]Epoch 37:   4%|▎         | 1/28 [00:00<00:00, 73.08it/s, train_loss=0.00449, val_loss=0.00477] Epoch 37:   7%|▋         | 2/28 [00:00<00:00, 104.12it/s, train_loss=0.00449, val_loss=0.00477]Epoch 37:   7%|▋         | 2/28 [00:00<00:00, 79.81it/s, train_loss=0.005, val_loss=0.00477]   Epoch 37:  11%|█         | 3/28 [00:00<00:00, 94.47it/s, train_loss=0.005, val_loss=0.00477]Epoch 37:  11%|█         | 3/28 [00:00<00:00, 78.03it/s, train_loss=0.00541, val_loss=0.00477]Epoch 37:  14%|█▍        | 4/28 [00:00<00:00, 90.77it/s, train_loss=0.00541, val_loss=0.00477]Epoch 37:  14%|█▍        | 4/28 [00:00<00:00, 80.17it/s, train_loss=0.00619, val_loss=0.00477]Epoch 37:  18%|█▊        | 5/28 [00:00<00:00, 90.09it/s, train_loss=0.00619, val_loss=0.00477]Epoch 37:  18%|█▊        | 5/28 [00:00<00:00, 81.66it/s, train_loss=0.00717, val_loss=0.00477]Epoch 37:  21%|██▏       | 6/28 [00:00<00:00, 89.87it/s, train_loss=0.00717, val_loss=0.00477]Epoch 37:  21%|██▏       | 6/28 [00:00<00:00, 84.85it/s, train_loss=0.00411, val_loss=0.00477]Epoch 37:  25%|██▌       | 7/28 [00:00<00:00, 90.29it/s, train_loss=0.00411, val_loss=0.00477]Epoch 37:  25%|██▌       | 7/28 [00:00<00:00, 84.02it/s, train_loss=0.00541, val_loss=0.00477]Epoch 37:  29%|██▊       | 8/28 [00:00<00:00, 89.83it/s, train_loss=0.00541, val_loss=0.00477]Epoch 37:  29%|██▊       | 8/28 [00:00<00:00, 84.60it/s, train_loss=0.00529, val_loss=0.00477]Epoch 37:  32%|███▏      | 9/28 [00:00<00:00, 89.88it/s, train_loss=0.00529, val_loss=0.00477]Epoch 37:  32%|███▏      | 9/28 [00:00<00:00, 84.97it/s, train_loss=0.004, val_loss=0.00477]  Epoch 37:  36%|███▌      | 10/28 [00:00<00:00, 89.67it/s, train_loss=0.004, val_loss=0.00477]Epoch 37:  36%|███▌      | 10/28 [00:00<00:00, 86.73it/s, train_loss=0.00606, val_loss=0.00477]Epoch 37:  39%|███▉      | 11/28 [00:00<00:00, 89.87it/s, train_loss=0.00606, val_loss=0.00477]Epoch 37:  39%|███▉      | 11/28 [00:00<00:00, 85.95it/s, train_loss=0.0063, val_loss=0.00477] Epoch 37:  43%|████▎     | 12/28 [00:00<00:00, 89.63it/s, train_loss=0.0063, val_loss=0.00477]Epoch 37:  43%|████▎     | 12/28 [00:00<00:00, 86.20it/s, train_loss=0.00544, val_loss=0.00477]Epoch 37:  46%|████▋     | 13/28 [00:00<00:00, 89.74it/s, train_loss=0.00544, val_loss=0.00477]Epoch 37:  46%|████▋     | 13/28 [00:00<00:00, 86.42it/s, train_loss=0.00421, val_loss=0.00477]Epoch 37:  50%|█████     | 14/28 [00:00<00:00, 89.61it/s, train_loss=0.00421, val_loss=0.00477]Epoch 37:  50%|█████     | 14/28 [00:00<00:00, 86.71it/s, train_loss=0.00563, val_loss=0.00477]Epoch 37:  54%|█████▎    | 15/28 [00:00<00:00, 89.18it/s, train_loss=0.00563, val_loss=0.00477]Epoch 37:  54%|█████▎    | 15/28 [00:00<00:00, 86.85it/s, train_loss=0.00713, val_loss=0.00477]Epoch 37:  57%|█████▋    | 16/28 [00:00<00:00, 89.68it/s, train_loss=0.00713, val_loss=0.00477]Epoch 37:  57%|█████▋    | 16/28 [00:00<00:00, 86.94it/s, train_loss=0.00508, val_loss=0.00477]Epoch 37:  61%|██████    | 17/28 [00:00<00:00, 89.66it/s, train_loss=0.00508, val_loss=0.00477]Epoch 37:  61%|██████    | 17/28 [00:00<00:00, 87.04it/s, train_loss=0.00591, val_loss=0.00477]Epoch 37:  64%|██████▍   | 18/28 [00:00<00:00, 89.39it/s, train_loss=0.00591, val_loss=0.00477]Epoch 37:  64%|██████▍   | 18/28 [00:00<00:00, 88.00it/s, train_loss=0.00386, val_loss=0.00477]Epoch 37:  68%|██████▊   | 19/28 [00:00<00:00, 90.09it/s, train_loss=0.00386, val_loss=0.00477]Epoch 37:  68%|██████▊   | 19/28 [00:00<00:00, 88.03it/s, train_loss=0.00646, val_loss=0.00477]Epoch 37:  71%|███████▏  | 20/28 [00:00<00:00, 90.43it/s, train_loss=0.00646, val_loss=0.00477]Epoch 37:  71%|███████▏  | 20/28 [00:00<00:00, 88.04it/s, train_loss=0.00501, val_loss=0.00477]Epoch 37:  75%|███████▌  | 21/28 [00:00<00:00, 89.94it/s, train_loss=0.00501, val_loss=0.00477]Epoch 37:  75%|███████▌  | 21/28 [00:00<00:00, 88.07it/s, train_loss=0.00419, val_loss=0.00477]Epoch 37:  79%|███████▊  | 22/28 [00:00<00:00, 90.12it/s, train_loss=0.00419, val_loss=0.00477]Epoch 37:  79%|███████▊  | 22/28 [00:00<00:00, 88.75it/s, train_loss=0.00487, val_loss=0.00477]Epoch 37:  82%|████████▏ | 23/28 [00:00<00:00, 90.38it/s, train_loss=0.00487, val_loss=0.00477]Epoch 37:  82%|████████▏ | 23/28 [00:00<00:00, 88.73it/s, train_loss=0.00564, val_loss=0.00477]Epoch 37:  86%|████████▌ | 24/28 [00:00<00:00, 90.62it/s, train_loss=0.00564, val_loss=0.00477]Epoch 37:  86%|████████▌ | 24/28 [00:00<00:00, 88.68it/s, train_loss=0.00535, val_loss=0.00477]Epoch 37:  89%|████████▉ | 25/28 [00:00<00:00, 90.52it/s, train_loss=0.00535, val_loss=0.00477]Epoch 37:  89%|████████▉ | 25/28 [00:00<00:00, 88.67it/s, train_loss=0.00461, val_loss=0.00477]Epoch 37:  93%|█████████▎| 26/28 [00:00<00:00, 90.29it/s, train_loss=0.00461, val_loss=0.00477]Epoch 37:  93%|█████████▎| 26/28 [00:00<00:00, 89.31it/s, train_loss=0.00722, val_loss=0.00477]Epoch 37:  96%|█████████▋| 27/28 [00:00<00:00, 90.69it/s, train_loss=0.00722, val_loss=0.00477]Epoch 37:  96%|█████████▋| 27/28 [00:00<00:00, 89.28it/s, train_loss=0.00438, val_loss=0.00477]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 90.89it/s, train_loss=0.00438, val_loss=0.00477]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 89.97it/s, train_loss=0.0056, val_loss=0.00477] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 152.01it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 178.33it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 190.28it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 198.72it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 204.45it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 207.96it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 210.55it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 212.98it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 214.50it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 215.12it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 215.19it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 215.02it/s][A
                                                                         [AEpoch 37: 100%|██████████| 28/28 [00:00<00:00, 74.39it/s, train_loss=0.0056, val_loss=0.00477]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 74.18it/s, train_loss=0.0056, val_loss=0.00477]Epoch 37:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0056, val_loss=0.00477]         Epoch 38:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0056, val_loss=0.00477]Epoch 38:   4%|▎         | 1/28 [00:00<00:00, 128.30it/s, train_loss=0.0056, val_loss=0.00477]Epoch 38:   4%|▎         | 1/28 [00:00<00:00, 84.66it/s, train_loss=0.0061, val_loss=0.00477] Epoch 38:   7%|▋         | 2/28 [00:00<00:00, 115.91it/s, train_loss=0.0061, val_loss=0.00477]Epoch 38:   7%|▋         | 2/28 [00:00<00:00, 86.00it/s, train_loss=0.00547, val_loss=0.00477]Epoch 38:  11%|█         | 3/28 [00:00<00:00, 104.70it/s, train_loss=0.00547, val_loss=0.00477]Epoch 38:  11%|█         | 3/28 [00:00<00:00, 86.53it/s, train_loss=0.00455, val_loss=0.00477] Epoch 38:  14%|█▍        | 4/28 [00:00<00:00, 99.44it/s, train_loss=0.00455, val_loss=0.00477]Epoch 38:  14%|█▍        | 4/28 [00:00<00:00, 86.97it/s, train_loss=0.00478, val_loss=0.00477]Epoch 38:  18%|█▊        | 5/28 [00:00<00:00, 95.11it/s, train_loss=0.00478, val_loss=0.00477]Epoch 38:  18%|█▊        | 5/28 [00:00<00:00, 87.80it/s, train_loss=0.00577, val_loss=0.00477]Epoch 38:  21%|██▏       | 6/28 [00:00<00:00, 96.20it/s, train_loss=0.00577, val_loss=0.00477]Epoch 38:  21%|██▏       | 6/28 [00:00<00:00, 87.87it/s, train_loss=0.00579, val_loss=0.00477]Epoch 38:  25%|██▌       | 7/28 [00:00<00:00, 94.86it/s, train_loss=0.00579, val_loss=0.00477]Epoch 38:  25%|██▌       | 7/28 [00:00<00:00, 87.96it/s, train_loss=0.00519, val_loss=0.00477]Epoch 38:  29%|██▊       | 8/28 [00:00<00:00, 93.76it/s, train_loss=0.00519, val_loss=0.00477]Epoch 38:  29%|██▊       | 8/28 [00:00<00:00, 88.03it/s, train_loss=0.00632, val_loss=0.00477]Epoch 38:  32%|███▏      | 9/28 [00:00<00:00, 92.21it/s, train_loss=0.00632, val_loss=0.00477]Epoch 38:  32%|███▏      | 9/28 [00:00<00:00, 86.51it/s, train_loss=0.0042, val_loss=0.00477] Epoch 38:  36%|███▌      | 10/28 [00:00<00:00, 91.21it/s, train_loss=0.0042, val_loss=0.00477]Epoch 38:  36%|███▌      | 10/28 [00:00<00:00, 86.66it/s, train_loss=0.00658, val_loss=0.00477]Epoch 38:  39%|███▉      | 11/28 [00:00<00:00, 90.90it/s, train_loss=0.00658, val_loss=0.00477]Epoch 38:  39%|███▉      | 11/28 [00:00<00:00, 86.87it/s, train_loss=0.00495, val_loss=0.00477]Epoch 38:  43%|████▎     | 12/28 [00:00<00:00, 90.83it/s, train_loss=0.00495, val_loss=0.00477]Epoch 38:  43%|████▎     | 12/28 [00:00<00:00, 86.99it/s, train_loss=0.0034, val_loss=0.00477] Epoch 38:  46%|████▋     | 13/28 [00:00<00:00, 89.89it/s, train_loss=0.0034, val_loss=0.00477]Epoch 38:  46%|████▋     | 13/28 [00:00<00:00, 87.08it/s, train_loss=0.00642, val_loss=0.00477]Epoch 38:  50%|█████     | 14/28 [00:00<00:00, 90.40it/s, train_loss=0.00642, val_loss=0.00477]Epoch 38:  50%|█████     | 14/28 [00:00<00:00, 87.17it/s, train_loss=0.00555, val_loss=0.00477]Epoch 38:  54%|█████▎    | 15/28 [00:00<00:00, 90.22it/s, train_loss=0.00555, val_loss=0.00477]Epoch 38:  54%|█████▎    | 15/28 [00:00<00:00, 87.29it/s, train_loss=0.00535, val_loss=0.00477]Epoch 38:  57%|█████▋    | 16/28 [00:00<00:00, 89.99it/s, train_loss=0.00535, val_loss=0.00477]Epoch 38:  57%|█████▋    | 16/28 [00:00<00:00, 88.25it/s, train_loss=0.0049, val_loss=0.00477] Epoch 38:  61%|██████    | 17/28 [00:00<00:00, 90.45it/s, train_loss=0.0049, val_loss=0.00477]Epoch 38:  61%|██████    | 17/28 [00:00<00:00, 88.23it/s, train_loss=0.00464, val_loss=0.00477]Epoch 38:  64%|██████▍   | 18/28 [00:00<00:00, 90.32it/s, train_loss=0.00464, val_loss=0.00477]Epoch 38:  64%|██████▍   | 18/28 [00:00<00:00, 88.22it/s, train_loss=0.00639, val_loss=0.00477]Epoch 38:  68%|██████▊   | 19/28 [00:00<00:00, 90.60it/s, train_loss=0.00639, val_loss=0.00477]Epoch 38:  68%|██████▊   | 19/28 [00:00<00:00, 88.25it/s, train_loss=0.00489, val_loss=0.00477]Epoch 38:  71%|███████▏  | 20/28 [00:00<00:00, 90.39it/s, train_loss=0.00489, val_loss=0.00477]Epoch 38:  71%|███████▏  | 20/28 [00:00<00:00, 88.98it/s, train_loss=0.00481, val_loss=0.00477]Epoch 38:  75%|███████▌  | 21/28 [00:00<00:00, 90.86it/s, train_loss=0.00481, val_loss=0.00477]Epoch 38:  75%|███████▌  | 21/28 [00:00<00:00, 88.97it/s, train_loss=0.00507, val_loss=0.00477]Epoch 38:  79%|███████▊  | 22/28 [00:00<00:00, 91.06it/s, train_loss=0.00507, val_loss=0.00477]Epoch 38:  79%|███████▊  | 22/28 [00:00<00:00, 88.93it/s, train_loss=0.00564, val_loss=0.00477]Epoch 38:  82%|████████▏ | 23/28 [00:00<00:00, 90.97it/s, train_loss=0.00564, val_loss=0.00477]Epoch 38:  82%|████████▏ | 23/28 [00:00<00:00, 88.93it/s, train_loss=0.00452, val_loss=0.00477]Epoch 38:  86%|████████▌ | 24/28 [00:00<00:00, 90.57it/s, train_loss=0.00452, val_loss=0.00477]Epoch 38:  86%|████████▌ | 24/28 [00:00<00:00, 88.89it/s, train_loss=0.00602, val_loss=0.00477]Epoch 38:  89%|████████▉ | 25/28 [00:00<00:00, 90.66it/s, train_loss=0.00602, val_loss=0.00477]Epoch 38:  89%|████████▉ | 25/28 [00:00<00:00, 88.88it/s, train_loss=0.0052, val_loss=0.00477] Epoch 38:  93%|█████████▎| 26/28 [00:00<00:00, 90.64it/s, train_loss=0.0052, val_loss=0.00477]Epoch 38:  93%|█████████▎| 26/28 [00:00<00:00, 88.85it/s, train_loss=0.00691, val_loss=0.00477]Epoch 38:  96%|█████████▋| 27/28 [00:00<00:00, 90.49it/s, train_loss=0.00691, val_loss=0.00477]Epoch 38:  96%|█████████▋| 27/28 [00:00<00:00, 88.85it/s, train_loss=0.00536, val_loss=0.00477]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 90.16it/s, train_loss=0.00536, val_loss=0.00477]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 89.01it/s, train_loss=0.00524, val_loss=0.00477]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 160.67it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 194.47it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 207.09it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 216.48it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 222.41it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 155.00it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 162.70it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 169.20it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 174.79it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 178.81it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 181.80it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 185.70it/s][A
                                                                         [AEpoch 38: 100%|██████████| 28/28 [00:00<00:00, 72.32it/s, train_loss=0.00524, val_loss=0.00476]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 72.13it/s, train_loss=0.00524, val_loss=0.00476]Epoch 38:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00524, val_loss=0.00476]         Epoch 39:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00524, val_loss=0.00476]Epoch 39:   4%|▎         | 1/28 [00:00<00:00, 134.53it/s, train_loss=0.00524, val_loss=0.00476]Epoch 39:   4%|▎         | 1/28 [00:00<00:00, 73.97it/s, train_loss=0.00575, val_loss=0.00476] Epoch 39:   7%|▋         | 2/28 [00:00<00:00, 102.68it/s, train_loss=0.00575, val_loss=0.00476]Epoch 39:   7%|▋         | 2/28 [00:00<00:00, 80.37it/s, train_loss=0.0047, val_loss=0.00476]  Epoch 39:  11%|█         | 3/28 [00:00<00:00, 97.70it/s, train_loss=0.0047, val_loss=0.00476]Epoch 39:  11%|█         | 3/28 [00:00<00:00, 82.61it/s, train_loss=0.00432, val_loss=0.00476]Epoch 39:  14%|█▍        | 4/28 [00:00<00:00, 96.08it/s, train_loss=0.00432, val_loss=0.00476]Epoch 39:  14%|█▍        | 4/28 [00:00<00:00, 83.88it/s, train_loss=0.00503, val_loss=0.00476]Epoch 39:  18%|█▊        | 5/28 [00:00<00:00, 92.29it/s, train_loss=0.00503, val_loss=0.00476]Epoch 39:  18%|█▊        | 5/28 [00:00<00:00, 85.56it/s, train_loss=0.00567, val_loss=0.00476]Epoch 39:  21%|██▏       | 6/28 [00:00<00:00, 93.81it/s, train_loss=0.00567, val_loss=0.00476]Epoch 39:  21%|██▏       | 6/28 [00:00<00:00, 86.01it/s, train_loss=0.00506, val_loss=0.00476]Epoch 39:  25%|██▌       | 7/28 [00:00<00:00, 93.24it/s, train_loss=0.00506, val_loss=0.00476]Epoch 39:  25%|██▌       | 7/28 [00:00<00:00, 86.25it/s, train_loss=0.00575, val_loss=0.00476]Epoch 39:  29%|██▊       | 8/28 [00:00<00:00, 92.43it/s, train_loss=0.00575, val_loss=0.00476]Epoch 39:  29%|██▊       | 8/28 [00:00<00:00, 86.55it/s, train_loss=0.00472, val_loss=0.00476]Epoch 39:  32%|███▏      | 9/28 [00:00<00:00, 90.71it/s, train_loss=0.00472, val_loss=0.00476]Epoch 39:  32%|███▏      | 9/28 [00:00<00:00, 85.26it/s, train_loss=0.00512, val_loss=0.00476]Epoch 39:  36%|███▌      | 10/28 [00:00<00:00, 89.99it/s, train_loss=0.00512, val_loss=0.00476]Epoch 39:  36%|███▌      | 10/28 [00:00<00:00, 85.62it/s, train_loss=0.00435, val_loss=0.00476]Epoch 39:  39%|███▉      | 11/28 [00:00<00:00, 89.88it/s, train_loss=0.00435, val_loss=0.00476]Epoch 39:  39%|███▉      | 11/28 [00:00<00:00, 85.88it/s, train_loss=0.00669, val_loss=0.00476]Epoch 39:  43%|████▎     | 12/28 [00:00<00:00, 89.78it/s, train_loss=0.00669, val_loss=0.00476]Epoch 39:  43%|████▎     | 12/28 [00:00<00:00, 86.24it/s, train_loss=0.004, val_loss=0.00476]  Epoch 39:  46%|████▋     | 13/28 [00:00<00:00, 88.89it/s, train_loss=0.004, val_loss=0.00476]Epoch 39:  46%|████▋     | 13/28 [00:00<00:00, 86.41it/s, train_loss=0.00496, val_loss=0.00476]Epoch 39:  50%|█████     | 14/28 [00:00<00:00, 89.72it/s, train_loss=0.00496, val_loss=0.00476]Epoch 39:  50%|█████     | 14/28 [00:00<00:00, 86.51it/s, train_loss=0.00616, val_loss=0.00476]Epoch 39:  54%|█████▎    | 15/28 [00:00<00:00, 89.64it/s, train_loss=0.00616, val_loss=0.00476]Epoch 39:  54%|█████▎    | 15/28 [00:00<00:00, 86.66it/s, train_loss=0.00446, val_loss=0.00476]Epoch 39:  57%|█████▋    | 16/28 [00:00<00:00, 89.38it/s, train_loss=0.00446, val_loss=0.00476]Epoch 39:  57%|█████▋    | 16/28 [00:00<00:00, 87.76it/s, train_loss=0.00603, val_loss=0.00476]Epoch 39:  61%|██████    | 17/28 [00:00<00:00, 89.96it/s, train_loss=0.00603, val_loss=0.00476]Epoch 39:  61%|██████    | 17/28 [00:00<00:00, 87.79it/s, train_loss=0.00482, val_loss=0.00476]Epoch 39:  64%|██████▍   | 18/28 [00:00<00:00, 90.31it/s, train_loss=0.00482, val_loss=0.00476]Epoch 39:  64%|██████▍   | 18/28 [00:00<00:00, 87.79it/s, train_loss=0.00469, val_loss=0.00476]Epoch 39:  68%|██████▊   | 19/28 [00:00<00:00, 89.76it/s, train_loss=0.00469, val_loss=0.00476]Epoch 39:  68%|██████▊   | 19/28 [00:00<00:00, 87.80it/s, train_loss=0.00572, val_loss=0.00476]Epoch 39:  71%|███████▏  | 20/28 [00:00<00:00, 89.89it/s, train_loss=0.00572, val_loss=0.00476]Epoch 39:  71%|███████▏  | 20/28 [00:00<00:00, 88.60it/s, train_loss=0.00522, val_loss=0.00476]Epoch 39:  75%|███████▌  | 21/28 [00:00<00:00, 90.32it/s, train_loss=0.00522, val_loss=0.00476]Epoch 39:  75%|███████▌  | 21/28 [00:00<00:00, 88.59it/s, train_loss=0.00629, val_loss=0.00476]Epoch 39:  79%|███████▊  | 22/28 [00:00<00:00, 90.66it/s, train_loss=0.00629, val_loss=0.00476]Epoch 39:  79%|███████▊  | 22/28 [00:00<00:00, 88.56it/s, train_loss=0.00723, val_loss=0.00476]Epoch 39:  82%|████████▏ | 23/28 [00:00<00:00, 90.72it/s, train_loss=0.00723, val_loss=0.00476]Epoch 39:  82%|████████▏ | 23/28 [00:00<00:00, 88.55it/s, train_loss=0.00466, val_loss=0.00476]Epoch 39:  86%|████████▌ | 24/28 [00:00<00:00, 90.48it/s, train_loss=0.00466, val_loss=0.00476]Epoch 39:  86%|████████▌ | 24/28 [00:00<00:00, 89.18it/s, train_loss=0.00734, val_loss=0.00476]Epoch 39:  89%|████████▉ | 25/28 [00:00<00:00, 90.73it/s, train_loss=0.00734, val_loss=0.00476]Epoch 39:  89%|████████▉ | 25/28 [00:00<00:00, 89.16it/s, train_loss=0.00555, val_loss=0.00476]Epoch 39:  93%|█████████▎| 26/28 [00:00<00:00, 91.00it/s, train_loss=0.00555, val_loss=0.00476]Epoch 39:  93%|█████████▎| 26/28 [00:00<00:00, 89.13it/s, train_loss=0.00466, val_loss=0.00476]Epoch 39:  96%|█████████▋| 27/28 [00:00<00:00, 90.86it/s, train_loss=0.00466, val_loss=0.00476]Epoch 39:  96%|█████████▋| 27/28 [00:00<00:00, 89.11it/s, train_loss=0.00541, val_loss=0.00476]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 90.31it/s, train_loss=0.00541, val_loss=0.00476]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 89.18it/s, train_loss=0.00527, val_loss=0.00476]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|▊         | 1/12 [00:00<00:00, 165.25it/s][A
Validation DataLoader 0:  17%|█▋        | 2/12 [00:00<00:00, 198.45it/s][A
Validation DataLoader 0:  25%|██▌       | 3/12 [00:00<00:00, 215.03it/s][A
Validation DataLoader 0:  33%|███▎      | 4/12 [00:00<00:00, 225.20it/s][A
Validation DataLoader 0:  42%|████▏     | 5/12 [00:00<00:00, 229.83it/s][A
Validation DataLoader 0:  50%|█████     | 6/12 [00:00<00:00, 229.85it/s][A
Validation DataLoader 0:  58%|█████▊    | 7/12 [00:00<00:00, 229.94it/s][A
Validation DataLoader 0:  67%|██████▋   | 8/12 [00:00<00:00, 230.79it/s][A
Validation DataLoader 0:  75%|███████▌  | 9/12 [00:00<00:00, 232.84it/s][A
Validation DataLoader 0:  83%|████████▎ | 10/12 [00:00<00:00, 233.82it/s][A
Validation DataLoader 0:  92%|█████████▏| 11/12 [00:00<00:00, 234.47it/s][A
Validation DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 235.57it/s][A
                                                                         [AEpoch 39: 100%|██████████| 28/28 [00:00<00:00, 75.12it/s, train_loss=0.00527, val_loss=0.00476]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 74.94it/s, train_loss=0.00527, val_loss=0.00476]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 73.92it/s, train_loss=0.00527, val_loss=0.00476]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▎         | 1/27 [00:00<00:00, 178.90it/s]Predicting DataLoader 0:   7%|▋         | 2/27 [00:00<00:00, 155.15it/s]Predicting DataLoader 0:  11%|█         | 3/27 [00:00<00:00, 151.65it/s]Predicting DataLoader 0:  15%|█▍        | 4/27 [00:00<00:00, 143.35it/s]Predicting DataLoader 0:  19%|█▊        | 5/27 [00:00<00:00, 138.09it/s]Predicting DataLoader 0:  22%|██▏       | 6/27 [00:00<00:00, 138.95it/s]Predicting DataLoader 0:  26%|██▌       | 7/27 [00:00<00:00, 136.97it/s]Predicting DataLoader 0:  30%|██▉       | 8/27 [00:00<00:00, 135.62it/s]Predicting DataLoader 0:  33%|███▎      | 9/27 [00:00<00:00, 135.53it/s]Predicting DataLoader 0:  37%|███▋      | 10/27 [00:00<00:00, 135.81it/s]Predicting DataLoader 0:  41%|████      | 11/27 [00:00<00:00, 137.22it/s]Predicting DataLoader 0:  44%|████▍     | 12/27 [00:00<00:00, 138.45it/s]Predicting DataLoader 0:  48%|████▊     | 13/27 [00:00<00:00, 138.29it/s]Predicting DataLoader 0:  52%|█████▏    | 14/27 [00:00<00:00, 137.73it/s]Predicting DataLoader 0:  56%|█████▌    | 15/27 [00:00<00:00, 137.37it/s]Predicting DataLoader 0:  59%|█████▉    | 16/27 [00:00<00:00, 135.84it/s]Predicting DataLoader 0:  63%|██████▎   | 17/27 [00:00<00:00, 136.13it/s]Predicting DataLoader 0:  67%|██████▋   | 18/27 [00:00<00:00, 134.44it/s]Predicting DataLoader 0:  70%|███████   | 19/27 [00:00<00:00, 134.16it/s]Predicting DataLoader 0:  74%|███████▍  | 20/27 [00:00<00:00, 134.79it/s]Predicting DataLoader 0:  78%|███████▊  | 21/27 [00:00<00:00, 135.44it/s]Predicting DataLoader 0:  81%|████████▏ | 22/27 [00:00<00:00, 134.04it/s]Predicting DataLoader 0:  85%|████████▌ | 23/27 [00:00<00:00, 133.91it/s]Predicting DataLoader 0:  89%|████████▉ | 24/27 [00:00<00:00, 133.51it/s]Predicting DataLoader 0:  93%|█████████▎| 25/27 [00:00<00:00, 133.97it/s]Predicting DataLoader 0:  96%|█████████▋| 26/27 [00:00<00:00, 132.86it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 132.94it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 131.81it/s][I 2025-08-18 01:51:37,286] A new study created in memory with name: no-name-fbb5db85-f3fa-432a-b21d-8e19365dbfc0
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 7, Horizon length: 30
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.43it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.19it/s] [I 2025-08-18 01:52:04,605] Trial 0 finished with value: 53.3965000582583 and parameters: {'hidden_dim': 92, 'n_rnn_layers': 4, 'dropout': 0.24548141205991708}. Best is trial 0 with value: 53.3965000582583.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.31163140581806653 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.09it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.24it/s][I 2025-08-18 01:52:24,043] Trial 1 finished with value: 27.961923173854714 and parameters: {'hidden_dim': 104, 'n_rnn_layers': 1, 'dropout': 0.31163140581806653}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.19it/s] [I 2025-08-18 01:52:49,732] Trial 2 finished with value: 28.53668602926581 and parameters: {'hidden_dim': 80, 'n_rnn_layers': 3, 'dropout': 0.1671001269563276}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.97it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.54it/s] [I 2025-08-18 01:53:10,472] Trial 3 finished with value: 28.98808981785539 and parameters: {'hidden_dim': 27, 'n_rnn_layers': 4, 'dropout': 0.4675681419649184}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1663910344385352 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.73it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.10it/s][I 2025-08-18 01:53:26,465] Trial 4 finished with value: 43.48162248246895 and parameters: {'hidden_dim': 41, 'n_rnn_layers': 1, 'dropout': 0.1663910344385352}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0982121707608909 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.24it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.47it/s][I 2025-08-18 01:53:41,606] Trial 5 finished with value: 41.97374020063929 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 1, 'dropout': 0.0982121707608909}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.52it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.73it/s][I 2025-08-18 01:53:59,647] Trial 6 finished with value: 36.824020543470766 and parameters: {'hidden_dim': 44, 'n_rnn_layers': 2, 'dropout': 0.2520916789979307}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0861112320884786 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.26it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.22it/s][I 2025-08-18 01:54:14,774] Trial 7 finished with value: 57.76300777183167 and parameters: {'hidden_dim': 38, 'n_rnn_layers': 1, 'dropout': 0.0861112320884786}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3175218314829063 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.88it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.86it/s][I 2025-08-18 01:54:33,375] Trial 8 finished with value: 64.10158542210088 and parameters: {'hidden_dim': 113, 'n_rnn_layers': 1, 'dropout': 0.3175218314829063}. Best is trial 1 with value: 27.961923173854714.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1175401575391622 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.50it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.32it/s][I 2025-08-18 01:54:52,742] Trial 9 finished with value: 20.845392857749896 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 1, 'dropout': 0.1175401575391622}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.81it/s] [I 2025-08-18 01:55:07,988] Trial 10 finished with value: 31.483972893681777 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 2, 'dropout': 0.003894465374644468}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.52it/s][I 2025-08-18 01:55:35,357] Trial 11 finished with value: 35.983288912598965 and parameters: {'hidden_dim': 65, 'n_rnn_layers': 2, 'dropout': 0.3970995256580969}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.18it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.74it/s] [I 2025-08-18 01:56:04,083] Trial 12 finished with value: 47.8090424587074 and parameters: {'hidden_dim': 62, 'n_rnn_layers': 3, 'dropout': 0.33166476092192765}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2007790488917478 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s][I 2025-08-18 01:56:22,227] Trial 13 finished with value: 38.07187205838656 and parameters: {'hidden_dim': 124, 'n_rnn_layers': 1, 'dropout': 0.2007790488917478}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.95it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s][I 2025-08-18 01:56:47,344] Trial 14 finished with value: 42.09613508034614 and parameters: {'hidden_dim': 62, 'n_rnn_layers': 2, 'dropout': 0.35140658600952324}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.08877549389623587 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.85it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.64it/s] [I 2025-08-18 01:57:03,928] Trial 15 finished with value: 25.143940312021098 and parameters: {'hidden_dim': 90, 'n_rnn_layers': 1, 'dropout': 0.08877549389623587}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.30it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.09it/s][I 2025-08-18 01:57:32,090] Trial 16 finished with value: 25.633272695664484 and parameters: {'hidden_dim': 76, 'n_rnn_layers': 3, 'dropout': 0.0002770298130440052}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.44it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.54it/s][I 2025-08-18 01:57:55,578] Trial 17 finished with value: 42.82637214651388 and parameters: {'hidden_dim': 55, 'n_rnn_layers': 2, 'dropout': 0.08677240939987885}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06220259766150132 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.21it/s][I 2025-08-18 01:58:09,405] Trial 18 finished with value: 26.839176002099922 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 1, 'dropout': 0.06220259766150132}. Best is trial 9 with value: 20.845392857749896.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.46it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.50it/s] [I 2025-08-18 01:58:25,029] Trial 19 finished with value: 45.06723391852855 and parameters: {'hidden_dim': 32, 'n_rnn_layers': 2, 'dropout': 0.13328773571937694}. Best is trial 9 with value: 20.845392857749896.
[I 2025-08-18 01:58:25,030] A new study created in memory with name: no-name-c651bcd8-4300-4b74-a118-405f49d3570c
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 60, 'n_rnn_layers': 1, 'dropout': 0.1175401575391622}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.76it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.99it/s] [I 2025-08-18 01:58:54,142] Trial 0 finished with value: 21.87292444293572 and parameters: {'hidden_dim': 107, 'n_rnn_layers': 4, 'dropout': 0.18312572268698085}. Best is trial 0 with value: 21.87292444293572.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.85it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 34.36it/s][I 2025-08-18 01:59:29,047] Trial 1 finished with value: 42.97942581543406 and parameters: {'hidden_dim': 96, 'n_rnn_layers': 2, 'dropout': 0.4167811377129182}. Best is trial 0 with value: 21.87292444293572.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3254231459094033 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.85it/s][I 2025-08-18 01:59:58,725] Trial 2 finished with value: 25.265135196990574 and parameters: {'hidden_dim': 128, 'n_rnn_layers': 1, 'dropout': 0.3254231459094033}. Best is trial 0 with value: 21.87292444293572.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45550951783246263 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.62it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.05it/s][I 2025-08-18 02:00:10,070] Trial 3 finished with value: 41.07900390480037 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 1, 'dropout': 0.45550951783246263}. Best is trial 0 with value: 21.87292444293572.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.26it/s][I 2025-08-18 02:00:25,529] Trial 4 finished with value: 44.04567166987119 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 2, 'dropout': 0.020322457268943994}. Best is trial 0 with value: 21.87292444293572.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.81it/s][I 2025-08-18 02:00:48,877] Trial 5 finished with value: 41.81750932681327 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 4, 'dropout': 0.36476773863420336}. Best is trial 0 with value: 21.87292444293572.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.73it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.46it/s][I 2025-08-18 02:01:05,593] Trial 6 finished with value: 21.787113481097983 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 2, 'dropout': 0.34071024054550064}. Best is trial 6 with value: 21.787113481097983.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.55it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.73it/s][I 2025-08-18 02:01:22,067] Trial 7 finished with value: 27.043168646536564 and parameters: {'hidden_dim': 119, 'n_rnn_layers': 3, 'dropout': 0.07479596583357284}. Best is trial 6 with value: 21.787113481097983.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.37it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.40it/s] [I 2025-08-18 02:01:33,532] Trial 8 finished with value: 21.234768347175482 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 3, 'dropout': 0.09323824490232974}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13759193559573024 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.98it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.48it/s][I 2025-08-18 02:01:42,637] Trial 9 finished with value: 33.18182801161229 and parameters: {'hidden_dim': 40, 'n_rnn_layers': 1, 'dropout': 0.13759193559573024}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.55it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.55it/s][I 2025-08-18 02:01:52,290] Trial 10 finished with value: 40.651029602515955 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 3, 'dropout': 0.232212409691218}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.20it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.37it/s] [I 2025-08-18 02:02:07,848] Trial 11 finished with value: 25.506367287173177 and parameters: {'hidden_dim': 69, 'n_rnn_layers': 3, 'dropout': 0.292666164174665}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.59it/s][I 2025-08-18 02:02:21,676] Trial 12 finished with value: 43.53113724303714 and parameters: {'hidden_dim': 62, 'n_rnn_layers': 2, 'dropout': 0.23886120433931127}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.83it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.51it/s] [I 2025-08-18 02:02:31,820] Trial 13 finished with value: 22.441334921649506 and parameters: {'hidden_dim': 33, 'n_rnn_layers': 3, 'dropout': 0.12172639964822823}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.35it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.68it/s][I 2025-08-18 02:02:47,486] Trial 14 finished with value: 28.490052427592445 and parameters: {'hidden_dim': 69, 'n_rnn_layers': 2, 'dropout': 0.0314311534592433}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.02it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.47it/s] [I 2025-08-18 02:03:00,775] Trial 15 finished with value: 21.671030169923693 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 4, 'dropout': 0.3783241984501362}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.03it/s][I 2025-08-18 02:03:13,780] Trial 16 finished with value: 80.27406691197776 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 4, 'dropout': 0.49360374548792846}. Best is trial 8 with value: 21.234768347175482.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.24it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.47it/s][I 2025-08-18 02:03:26,385] Trial 17 finished with value: 21.057561575130382 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 4, 'dropout': 0.3981472420879551}. Best is trial 17 with value: 21.057561575130382.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.82it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.93it/s][I 2025-08-18 02:03:38,197] Trial 18 finished with value: 44.13254313801924 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.1598618130241016}. Best is trial 17 with value: 21.057561575130382.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.43it/s][I 2025-08-18 02:03:49,038] Trial 19 finished with value: 48.80731265185189 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 3, 'dropout': 0.27229532043068944}. Best is trial 17 with value: 21.057561575130382.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 15.6 K | train
6 | V               | Linear           | 24     | train
-------------------------------------------------------------
15.7 K    Trainable params
0         Non-trainable params
15.7 K    Total params
0.063     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 23, 'n_rnn_layers': 4, 'dropout': 0.3981472420879551}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 207.33it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 213.49it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/28 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s] Epoch 0:   4%|▎         | 1/28 [00:00<00:00, 85.34it/s]Epoch 0:   4%|▎         | 1/28 [00:00<00:00, 79.61it/s, train_loss=0.180]Epoch 0:   7%|▋         | 2/28 [00:00<00:00, 87.22it/s, train_loss=0.180]Epoch 0:   7%|▋         | 2/28 [00:00<00:00, 84.12it/s, train_loss=0.165]Epoch 0:  11%|█         | 3/28 [00:00<00:00, 92.40it/s, train_loss=0.165]Epoch 0:  11%|█         | 3/28 [00:00<00:00, 88.65it/s, train_loss=0.187]Epoch 0:  14%|█▍        | 4/28 [00:00<00:00, 90.81it/s, train_loss=0.187]Epoch 0:  14%|█▍        | 4/28 [00:00<00:00, 89.12it/s, train_loss=0.145]Epoch 0:  18%|█▊        | 5/28 [00:00<00:00, 93.60it/s, train_loss=0.145]Epoch 0:  18%|█▊        | 5/28 [00:00<00:00, 91.02it/s, train_loss=0.163]Epoch 0:  21%|██▏       | 6/28 [00:00<00:00, 92.31it/s, train_loss=0.163]Epoch 0:  21%|██▏       | 6/28 [00:00<00:00, 90.92it/s, train_loss=0.182]Epoch 0:  25%|██▌       | 7/28 [00:00<00:00, 93.80it/s, train_loss=0.182]Epoch 0:  25%|██▌       | 7/28 [00:00<00:00, 91.71it/s, train_loss=0.171]Epoch 0:  29%|██▊       | 8/28 [00:00<00:00, 92.82it/s, train_loss=0.171]Epoch 0:  29%|██▊       | 8/28 [00:00<00:00, 91.52it/s, train_loss=0.170]Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 93.40it/s, train_loss=0.170]Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 92.00it/s, train_loss=0.190]Epoch 0:  36%|███▌      | 10/28 [00:00<00:00, 92.52it/s, train_loss=0.190]Epoch 0:  36%|███▌      | 10/28 [00:00<00:00, 91.89it/s, train_loss=0.158]Epoch 0:  39%|███▉      | 11/28 [00:00<00:00, 93.91it/s, train_loss=0.158]Epoch 0:  39%|███▉      | 11/28 [00:00<00:00, 92.53it/s, train_loss=0.154]Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 94.19it/s, train_loss=0.154]Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 91.93it/s, train_loss=0.119]Epoch 0:  46%|████▋     | 13/28 [00:00<00:00, 93.34it/s, train_loss=0.119]Epoch 0:  46%|████▋     | 13/28 [00:00<00:00, 92.37it/s, train_loss=0.156]Epoch 0:  50%|█████     | 14/28 [00:00<00:00, 93.83it/s, train_loss=0.156]Epoch 0:  50%|█████     | 14/28 [00:00<00:00, 91.84it/s, train_loss=0.143]Epoch 0:  54%|█████▎    | 15/28 [00:00<00:00, 93.05it/s, train_loss=0.143]Epoch 0:  54%|█████▎    | 15/28 [00:00<00:00, 92.15it/s, train_loss=0.160]Epoch 0:  57%|█████▋    | 16/28 [00:00<00:00, 92.40it/s, train_loss=0.160]Epoch 0:  57%|█████▋    | 16/28 [00:00<00:00, 91.98it/s, train_loss=0.141]Epoch 0:  61%|██████    | 17/28 [00:00<00:00, 93.19it/s, train_loss=0.141]Epoch 0:  61%|██████    | 17/28 [00:00<00:00, 92.36it/s, train_loss=0.131]Epoch 0:  64%|██████▍   | 18/28 [00:00<00:00, 92.98it/s, train_loss=0.131]Epoch 0:  64%|██████▍   | 18/28 [00:00<00:00, 92.25it/s, train_loss=0.136]Epoch 0:  68%|██████▊   | 19/28 [00:00<00:00, 93.33it/s, train_loss=0.136]Epoch 0:  68%|██████▊   | 19/28 [00:00<00:00, 92.55it/s, train_loss=0.142]Epoch 0:  71%|███████▏  | 20/28 [00:00<00:00, 93.10it/s, train_loss=0.142]Epoch 0:  71%|███████▏  | 20/28 [00:00<00:00, 92.41it/s, train_loss=0.165]Epoch 0:  75%|███████▌  | 21/28 [00:00<00:00, 93.35it/s, train_loss=0.165]Epoch 0:  75%|███████▌  | 21/28 [00:00<00:00, 92.65it/s, train_loss=0.142]Epoch 0:  79%|███████▊  | 22/28 [00:00<00:00, 93.13it/s, train_loss=0.142]Epoch 0:  79%|███████▊  | 22/28 [00:00<00:00, 92.49it/s, train_loss=0.137]Epoch 0:  82%|████████▏ | 23/28 [00:00<00:00, 93.24it/s, train_loss=0.137]Epoch 0:  82%|████████▏ | 23/28 [00:00<00:00, 92.72it/s, train_loss=0.138]Epoch 0:  86%|████████▌ | 24/28 [00:00<00:00, 93.06it/s, train_loss=0.138]Epoch 0:  86%|████████▌ | 24/28 [00:00<00:00, 92.56it/s, train_loss=0.125]Epoch 0:  89%|████████▉ | 25/28 [00:00<00:00, 93.32it/s, train_loss=0.125]Epoch 0:  89%|████████▉ | 25/28 [00:00<00:00, 92.73it/s, train_loss=0.127]Epoch 0:  93%|█████████▎| 26/28 [00:00<00:00, 93.05it/s, train_loss=0.127]Epoch 0:  93%|█████████▎| 26/28 [00:00<00:00, 92.60it/s, train_loss=0.122]Epoch 0:  96%|█████████▋| 27/28 [00:00<00:00, 93.29it/s, train_loss=0.122]Epoch 0:  96%|█████████▋| 27/28 [00:00<00:00, 92.76it/s, train_loss=0.140]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 93.45it/s, train_loss=0.140]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 93.19it/s, train_loss=0.142]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 127.03it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 143.73it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 151.91it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 154.77it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 157.80it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 158.49it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 159.85it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 162.83it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 167.40it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 171.23it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 174.20it/s][A
                                                                         [AEpoch 0: 100%|██████████| 28/28 [00:00<00:00, 75.69it/s, train_loss=0.142, val_loss=0.152]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 75.55it/s, train_loss=0.142, val_loss=0.152]Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.142, val_loss=0.152]         Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.142, val_loss=0.152]Epoch 1:   4%|▎         | 1/28 [00:00<00:00, 91.91it/s, train_loss=0.142, val_loss=0.152]Epoch 1:   4%|▎         | 1/28 [00:00<00:00, 86.87it/s, train_loss=0.109, val_loss=0.152]Epoch 1:   7%|▋         | 2/28 [00:00<00:00, 98.43it/s, train_loss=0.109, val_loss=0.152]Epoch 1:   7%|▋         | 2/28 [00:00<00:00, 92.26it/s, train_loss=0.128, val_loss=0.152]Epoch 1:  11%|█         | 3/28 [00:00<00:00, 95.08it/s, train_loss=0.128, val_loss=0.152]Epoch 1:  11%|█         | 3/28 [00:00<00:00, 91.20it/s, train_loss=0.146, val_loss=0.152]Epoch 1:  14%|█▍        | 4/28 [00:00<00:00, 96.04it/s, train_loss=0.146, val_loss=0.152]Epoch 1:  14%|█▍        | 4/28 [00:00<00:00, 92.79it/s, train_loss=0.124, val_loss=0.152]Epoch 1:  18%|█▊        | 5/28 [00:00<00:00, 94.38it/s, train_loss=0.124, val_loss=0.152]Epoch 1:  18%|█▊        | 5/28 [00:00<00:00, 92.08it/s, train_loss=0.118, val_loss=0.152]Epoch 1:  21%|██▏       | 6/28 [00:00<00:00, 95.15it/s, train_loss=0.118, val_loss=0.152]Epoch 1:  21%|██▏       | 6/28 [00:00<00:00, 92.98it/s, train_loss=0.117, val_loss=0.152]Epoch 1:  25%|██▌       | 7/28 [00:00<00:00, 94.08it/s, train_loss=0.117, val_loss=0.152]Epoch 1:  25%|██▌       | 7/28 [00:00<00:00, 92.39it/s, train_loss=0.107, val_loss=0.152]Epoch 1:  29%|██▊       | 8/28 [00:00<00:00, 94.73it/s, train_loss=0.107, val_loss=0.152]Epoch 1:  29%|██▊       | 8/28 [00:00<00:00, 93.00it/s, train_loss=0.115, val_loss=0.152]Epoch 1:  32%|███▏      | 9/28 [00:00<00:00, 93.81it/s, train_loss=0.115, val_loss=0.152]Epoch 1:  32%|███▏      | 9/28 [00:00<00:00, 92.58it/s, train_loss=0.138, val_loss=0.152]Epoch 1:  36%|███▌      | 10/28 [00:00<00:00, 94.58it/s, train_loss=0.138, val_loss=0.152]Epoch 1:  36%|███▌      | 10/28 [00:00<00:00, 93.08it/s, train_loss=0.105, val_loss=0.152]Epoch 1:  39%|███▉      | 11/28 [00:00<00:00, 93.89it/s, train_loss=0.105, val_loss=0.152]Epoch 1:  39%|███▉      | 11/28 [00:00<00:00, 92.74it/s, train_loss=0.112, val_loss=0.152]Epoch 1:  43%|████▎     | 12/28 [00:00<00:00, 94.18it/s, train_loss=0.112, val_loss=0.152]Epoch 1:  43%|████▎     | 12/28 [00:00<00:00, 93.03it/s, train_loss=0.109, val_loss=0.152]Epoch 1:  46%|████▋     | 13/28 [00:00<00:00, 92.85it/s, train_loss=0.109, val_loss=0.152]Epoch 1:  46%|████▋     | 13/28 [00:00<00:00, 92.27it/s, train_loss=0.104, val_loss=0.152]Epoch 1:  50%|█████     | 14/28 [00:00<00:00, 93.56it/s, train_loss=0.104, val_loss=0.152]Epoch 1:  50%|█████     | 14/28 [00:00<00:00, 92.50it/s, train_loss=0.121, val_loss=0.152]Epoch 1:  54%|█████▎    | 15/28 [00:00<00:00, 92.90it/s, train_loss=0.121, val_loss=0.152]Epoch 1:  54%|█████▎    | 15/28 [00:00<00:00, 92.37it/s, train_loss=0.0854, val_loss=0.152]Epoch 1:  57%|█████▋    | 16/28 [00:00<00:00, 83.72it/s, train_loss=0.0854, val_loss=0.152]Epoch 1:  57%|█████▋    | 16/28 [00:00<00:00, 83.23it/s, train_loss=0.0858, val_loss=0.152]Epoch 1:  61%|██████    | 17/28 [00:00<00:00, 84.58it/s, train_loss=0.0858, val_loss=0.152]Epoch 1:  61%|██████    | 17/28 [00:00<00:00, 83.91it/s, train_loss=0.0682, val_loss=0.152]Epoch 1:  64%|██████▍   | 18/28 [00:00<00:00, 84.91it/s, train_loss=0.0682, val_loss=0.152]Epoch 1:  64%|██████▍   | 18/28 [00:00<00:00, 84.13it/s, train_loss=0.102, val_loss=0.152] Epoch 1:  68%|██████▊   | 19/28 [00:00<00:00, 85.47it/s, train_loss=0.102, val_loss=0.152]Epoch 1:  68%|██████▊   | 19/28 [00:00<00:00, 84.84it/s, train_loss=0.0913, val_loss=0.152]Epoch 1:  71%|███████▏  | 20/28 [00:00<00:00, 85.97it/s, train_loss=0.0913, val_loss=0.152]Epoch 1:  71%|███████▏  | 20/28 [00:00<00:00, 84.70it/s, train_loss=0.0816, val_loss=0.152]Epoch 1:  75%|███████▌  | 21/28 [00:00<00:00, 85.74it/s, train_loss=0.0816, val_loss=0.152]Epoch 1:  75%|███████▌  | 21/28 [00:00<00:00, 85.15it/s, train_loss=0.0823, val_loss=0.152]Epoch 1:  79%|███████▊  | 22/28 [00:00<00:00, 85.88it/s, train_loss=0.0823, val_loss=0.152]Epoch 1:  79%|███████▊  | 22/28 [00:00<00:00, 85.21it/s, train_loss=0.0756, val_loss=0.152]Epoch 1:  82%|████████▏ | 23/28 [00:00<00:00, 86.20it/s, train_loss=0.0756, val_loss=0.152]Epoch 1:  82%|████████▏ | 23/28 [00:00<00:00, 85.62it/s, train_loss=0.0918, val_loss=0.152]Epoch 1:  86%|████████▌ | 24/28 [00:00<00:00, 86.21it/s, train_loss=0.0918, val_loss=0.152]Epoch 1:  86%|████████▌ | 24/28 [00:00<00:00, 85.68it/s, train_loss=0.0693, val_loss=0.152]Epoch 1:  89%|████████▉ | 25/28 [00:00<00:00, 86.62it/s, train_loss=0.0693, val_loss=0.152]Epoch 1:  89%|████████▉ | 25/28 [00:00<00:00, 86.09it/s, train_loss=0.0685, val_loss=0.152]Epoch 1:  93%|█████████▎| 26/28 [00:00<00:00, 86.75it/s, train_loss=0.0685, val_loss=0.152]Epoch 1:  93%|█████████▎| 26/28 [00:00<00:00, 86.10it/s, train_loss=0.0688, val_loss=0.152]Epoch 1:  96%|█████████▋| 27/28 [00:00<00:00, 86.98it/s, train_loss=0.0688, val_loss=0.152]Epoch 1:  96%|█████████▋| 27/28 [00:00<00:00, 86.48it/s, train_loss=0.0517, val_loss=0.152]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 87.39it/s, train_loss=0.0517, val_loss=0.152]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 87.18it/s, train_loss=0.078, val_loss=0.152] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 100.34it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 127.95it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 141.67it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 145.92it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 150.39it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 152.50it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 155.23it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 156.03it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 157.25it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 158.43it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 160.00it/s][A
                                                                         [AEpoch 1: 100%|██████████| 28/28 [00:00<00:00, 70.33it/s, train_loss=0.078, val_loss=0.0672]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 70.15it/s, train_loss=0.078, val_loss=0.0672]Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.078, val_loss=0.0672]         Epoch 2:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.078, val_loss=0.0672]Epoch 2:   4%|▎         | 1/28 [00:00<00:00, 93.69it/s, train_loss=0.078, val_loss=0.0672]Epoch 2:   4%|▎         | 1/28 [00:00<00:00, 73.28it/s, train_loss=0.0378, val_loss=0.0672]Epoch 2:   7%|▋         | 2/28 [00:00<00:00, 83.99it/s, train_loss=0.0378, val_loss=0.0672]Epoch 2:   7%|▋         | 2/28 [00:00<00:00, 81.51it/s, train_loss=0.0566, val_loss=0.0672]Epoch 2:  11%|█         | 3/28 [00:00<00:00, 91.92it/s, train_loss=0.0566, val_loss=0.0672]Epoch 2:  11%|█         | 3/28 [00:00<00:00, 86.97it/s, train_loss=0.0302, val_loss=0.0672]Epoch 2:  14%|█▍        | 4/28 [00:00<00:00, 90.09it/s, train_loss=0.0302, val_loss=0.0672]Epoch 2:  14%|█▍        | 4/28 [00:00<00:00, 86.91it/s, train_loss=0.0547, val_loss=0.0672]Epoch 2:  18%|█▊        | 5/28 [00:00<00:00, 91.39it/s, train_loss=0.0547, val_loss=0.0672]Epoch 2:  18%|█▊        | 5/28 [00:00<00:00, 88.67it/s, train_loss=0.036, val_loss=0.0672] Epoch 2:  21%|██▏       | 6/28 [00:00<00:00, 91.76it/s, train_loss=0.036, val_loss=0.0672]Epoch 2:  21%|██▏       | 6/28 [00:00<00:00, 87.68it/s, train_loss=0.0226, val_loss=0.0672]Epoch 2:  25%|██▌       | 7/28 [00:00<00:00, 90.76it/s, train_loss=0.0226, val_loss=0.0672]Epoch 2:  25%|██▌       | 7/28 [00:00<00:00, 88.72it/s, train_loss=0.0198, val_loss=0.0672]Epoch 2:  29%|██▊       | 8/28 [00:00<00:00, 91.04it/s, train_loss=0.0198, val_loss=0.0672]Epoch 2:  29%|██▊       | 8/28 [00:00<00:00, 88.10it/s, train_loss=0.0232, val_loss=0.0672]Epoch 2:  32%|███▏      | 9/28 [00:00<00:00, 90.11it/s, train_loss=0.0232, val_loss=0.0672]Epoch 2:  32%|███▏      | 9/28 [00:00<00:00, 88.54it/s, train_loss=0.035, val_loss=0.0672] Epoch 2:  36%|███▌      | 10/28 [00:00<00:00, 90.62it/s, train_loss=0.035, val_loss=0.0672]Epoch 2:  36%|███▌      | 10/28 [00:00<00:00, 87.94it/s, train_loss=0.0233, val_loss=0.0672]Epoch 2:  39%|███▉      | 11/28 [00:00<00:00, 89.57it/s, train_loss=0.0233, val_loss=0.0672]Epoch 2:  39%|███▉      | 11/28 [00:00<00:00, 88.36it/s, train_loss=0.0247, val_loss=0.0672]Epoch 2:  43%|████▎     | 12/28 [00:00<00:00, 89.99it/s, train_loss=0.0247, val_loss=0.0672]Epoch 2:  43%|████▎     | 12/28 [00:00<00:00, 87.90it/s, train_loss=0.0294, val_loss=0.0672]Epoch 2:  46%|████▋     | 13/28 [00:00<00:00, 89.44it/s, train_loss=0.0294, val_loss=0.0672]Epoch 2:  46%|████▋     | 13/28 [00:00<00:00, 88.28it/s, train_loss=0.0408, val_loss=0.0672]Epoch 2:  50%|█████     | 14/28 [00:00<00:00, 90.04it/s, train_loss=0.0408, val_loss=0.0672]Epoch 2:  50%|█████     | 14/28 [00:00<00:00, 87.78it/s, train_loss=0.0328, val_loss=0.0672]Epoch 2:  54%|█████▎    | 15/28 [00:00<00:00, 89.23it/s, train_loss=0.0328, val_loss=0.0672]Epoch 2:  54%|█████▎    | 15/28 [00:00<00:00, 88.21it/s, train_loss=0.0288, val_loss=0.0672]Epoch 2:  57%|█████▋    | 16/28 [00:00<00:00, 89.53it/s, train_loss=0.0288, val_loss=0.0672]Epoch 2:  57%|█████▋    | 16/28 [00:00<00:00, 88.02it/s, train_loss=0.0271, val_loss=0.0672]Epoch 2:  61%|██████    | 17/28 [00:00<00:00, 89.39it/s, train_loss=0.0271, val_loss=0.0672]Epoch 2:  61%|██████    | 17/28 [00:00<00:00, 88.54it/s, train_loss=0.0223, val_loss=0.0672]Epoch 2:  64%|██████▍   | 18/28 [00:00<00:00, 89.80it/s, train_loss=0.0223, val_loss=0.0672]Epoch 2:  64%|██████▍   | 18/28 [00:00<00:00, 88.16it/s, train_loss=0.032, val_loss=0.0672] Epoch 2:  68%|██████▊   | 19/28 [00:00<00:00, 89.38it/s, train_loss=0.032, val_loss=0.0672]Epoch 2:  68%|██████▊   | 19/28 [00:00<00:00, 88.57it/s, train_loss=0.0391, val_loss=0.0672]Epoch 2:  71%|███████▏  | 20/28 [00:00<00:00, 89.61it/s, train_loss=0.0391, val_loss=0.0672]Epoch 2:  71%|███████▏  | 20/28 [00:00<00:00, 88.26it/s, train_loss=0.0307, val_loss=0.0672]Epoch 2:  75%|███████▌  | 21/28 [00:00<00:00, 89.36it/s, train_loss=0.0307, val_loss=0.0672]Epoch 2:  75%|███████▌  | 21/28 [00:00<00:00, 88.63it/s, train_loss=0.0199, val_loss=0.0672]Epoch 2:  79%|███████▊  | 22/28 [00:00<00:00, 89.77it/s, train_loss=0.0199, val_loss=0.0672]Epoch 2:  79%|███████▊  | 22/28 [00:00<00:00, 88.40it/s, train_loss=0.0206, val_loss=0.0672]Epoch 2:  82%|████████▏ | 23/28 [00:00<00:00, 89.53it/s, train_loss=0.0206, val_loss=0.0672]Epoch 2:  82%|████████▏ | 23/28 [00:00<00:00, 88.86it/s, train_loss=0.0193, val_loss=0.0672]Epoch 2:  86%|████████▌ | 24/28 [00:00<00:00, 90.00it/s, train_loss=0.0193, val_loss=0.0672]Epoch 2:  86%|████████▌ | 24/28 [00:00<00:00, 89.33it/s, train_loss=0.0239, val_loss=0.0672]Epoch 2:  89%|████████▉ | 25/28 [00:00<00:00, 90.32it/s, train_loss=0.0239, val_loss=0.0672]Epoch 2:  89%|████████▉ | 25/28 [00:00<00:00, 89.50it/s, train_loss=0.0314, val_loss=0.0672]Epoch 2:  93%|█████████▎| 26/28 [00:00<00:00, 90.50it/s, train_loss=0.0314, val_loss=0.0672]Epoch 2:  93%|█████████▎| 26/28 [00:00<00:00, 89.88it/s, train_loss=0.023, val_loss=0.0672] Epoch 2:  96%|█████████▋| 27/28 [00:00<00:00, 90.85it/s, train_loss=0.023, val_loss=0.0672]Epoch 2:  96%|█████████▋| 27/28 [00:00<00:00, 89.62it/s, train_loss=0.0258, val_loss=0.0672]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 90.41it/s, train_loss=0.0258, val_loss=0.0672]Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 90.21it/s, train_loss=0.0199, val_loss=0.0672]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 141.97it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 163.88it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 174.60it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 179.87it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 178.93it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 181.24it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 174.94it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 172.49it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 172.49it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 172.69it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 172.94it/s][A
                                                                         [AEpoch 2: 100%|██████████| 28/28 [00:00<00:00, 72.98it/s, train_loss=0.0199, val_loss=0.0347]Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 72.78it/s, train_loss=0.0199, val_loss=0.0347]Epoch 2:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0199, val_loss=0.0347]         Epoch 3:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0199, val_loss=0.0347]Epoch 3:   4%|▎         | 1/28 [00:00<00:00, 94.14it/s, train_loss=0.0199, val_loss=0.0347]Epoch 3:   4%|▎         | 1/28 [00:00<00:00, 83.06it/s, train_loss=0.0262, val_loss=0.0347]Epoch 3:   7%|▋         | 2/28 [00:00<00:00, 98.51it/s, train_loss=0.0262, val_loss=0.0347]Epoch 3:   7%|▋         | 2/28 [00:00<00:00, 90.55it/s, train_loss=0.0125, val_loss=0.0347]Epoch 3:  11%|█         | 3/28 [00:00<00:00, 98.77it/s, train_loss=0.0125, val_loss=0.0347]Epoch 3:  11%|█         | 3/28 [00:00<00:00, 87.56it/s, train_loss=0.023, val_loss=0.0347] Epoch 3:  14%|█▍        | 4/28 [00:00<00:00, 92.86it/s, train_loss=0.023, val_loss=0.0347]Epoch 3:  14%|█▍        | 4/28 [00:00<00:00, 89.52it/s, train_loss=0.0204, val_loss=0.0347]Epoch 3:  18%|█▊        | 5/28 [00:00<00:00, 94.20it/s, train_loss=0.0204, val_loss=0.0347]Epoch 3:  18%|█▊        | 5/28 [00:00<00:00, 87.93it/s, train_loss=0.0141, val_loss=0.0347]Epoch 3:  21%|██▏       | 6/28 [00:00<00:00, 91.66it/s, train_loss=0.0141, val_loss=0.0347]Epoch 3:  21%|██▏       | 6/28 [00:00<00:00, 89.00it/s, train_loss=0.0261, val_loss=0.0347]Epoch 3:  25%|██▌       | 7/28 [00:00<00:00, 92.66it/s, train_loss=0.0261, val_loss=0.0347]Epoch 3:  25%|██▌       | 7/28 [00:00<00:00, 87.69it/s, train_loss=0.0303, val_loss=0.0347]Epoch 3:  29%|██▊       | 8/28 [00:00<00:00, 90.41it/s, train_loss=0.0303, val_loss=0.0347]Epoch 3:  29%|██▊       | 8/28 [00:00<00:00, 88.40it/s, train_loss=0.0209, val_loss=0.0347]Epoch 3:  32%|███▏      | 9/28 [00:00<00:00, 90.75it/s, train_loss=0.0209, val_loss=0.0347]Epoch 3:  32%|███▏      | 9/28 [00:00<00:00, 88.18it/s, train_loss=0.0453, val_loss=0.0347]Epoch 3:  36%|███▌      | 10/28 [00:00<00:00, 90.44it/s, train_loss=0.0453, val_loss=0.0347]Epoch 3:  36%|███▌      | 10/28 [00:00<00:00, 88.97it/s, train_loss=0.0284, val_loss=0.0347]Epoch 3:  39%|███▉      | 11/28 [00:00<00:00, 89.35it/s, train_loss=0.0284, val_loss=0.0347]Epoch 3:  39%|███▉      | 11/28 [00:00<00:00, 87.91it/s, train_loss=0.0246, val_loss=0.0347]Epoch 3:  43%|████▎     | 12/28 [00:00<00:00, 88.22it/s, train_loss=0.0246, val_loss=0.0347]Epoch 3:  43%|████▎     | 12/28 [00:00<00:00, 87.38it/s, train_loss=0.0356, val_loss=0.0347]Epoch 3:  46%|████▋     | 13/28 [00:00<00:00, 86.80it/s, train_loss=0.0356, val_loss=0.0347]Epoch 3:  46%|████▋     | 13/28 [00:00<00:00, 86.30it/s, train_loss=0.024, val_loss=0.0347] Epoch 3:  50%|█████     | 14/28 [00:00<00:00, 86.63it/s, train_loss=0.024, val_loss=0.0347]Epoch 3:  50%|█████     | 14/28 [00:00<00:00, 84.91it/s, train_loss=0.032, val_loss=0.0347]Epoch 3:  54%|█████▎    | 15/28 [00:00<00:00, 84.65it/s, train_loss=0.032, val_loss=0.0347]Epoch 3:  54%|█████▎    | 15/28 [00:00<00:00, 84.19it/s, train_loss=0.0287, val_loss=0.0347]Epoch 3:  57%|█████▋    | 16/28 [00:00<00:00, 84.44it/s, train_loss=0.0287, val_loss=0.0347]Epoch 3:  57%|█████▋    | 16/28 [00:00<00:00, 83.53it/s, train_loss=0.0283, val_loss=0.0347]Epoch 3:  61%|██████    | 17/28 [00:00<00:00, 83.66it/s, train_loss=0.0283, val_loss=0.0347]Epoch 3:  61%|██████    | 17/28 [00:00<00:00, 83.26it/s, train_loss=0.0254, val_loss=0.0347]Epoch 3:  64%|██████▍   | 18/28 [00:00<00:00, 83.77it/s, train_loss=0.0254, val_loss=0.0347]Epoch 3:  64%|██████▍   | 18/28 [00:00<00:00, 83.38it/s, train_loss=0.025, val_loss=0.0347] Epoch 3:  68%|██████▊   | 19/28 [00:00<00:00, 83.48it/s, train_loss=0.025, val_loss=0.0347]Epoch 3:  68%|██████▊   | 19/28 [00:00<00:00, 82.27it/s, train_loss=0.018, val_loss=0.0347]Epoch 3:  71%|███████▏  | 20/28 [00:00<00:00, 82.84it/s, train_loss=0.018, val_loss=0.0347]Epoch 3:  71%|███████▏  | 20/28 [00:00<00:00, 82.32it/s, train_loss=0.0195, val_loss=0.0347]Epoch 3:  75%|███████▌  | 21/28 [00:00<00:00, 83.36it/s, train_loss=0.0195, val_loss=0.0347]Epoch 3:  75%|███████▌  | 21/28 [00:00<00:00, 82.20it/s, train_loss=0.0232, val_loss=0.0347]Epoch 3:  79%|███████▊  | 22/28 [00:00<00:00, 82.89it/s, train_loss=0.0232, val_loss=0.0347]Epoch 3:  79%|███████▊  | 22/28 [00:00<00:00, 82.42it/s, train_loss=0.0208, val_loss=0.0347]Epoch 3:  82%|████████▏ | 23/28 [00:00<00:00, 83.56it/s, train_loss=0.0208, val_loss=0.0347]Epoch 3:  82%|████████▏ | 23/28 [00:00<00:00, 83.07it/s, train_loss=0.0267, val_loss=0.0347]Epoch 3:  86%|████████▌ | 24/28 [00:00<00:00, 83.98it/s, train_loss=0.0267, val_loss=0.0347]Epoch 3:  86%|████████▌ | 24/28 [00:00<00:00, 83.21it/s, train_loss=0.0296, val_loss=0.0347]Epoch 3:  89%|████████▉ | 25/28 [00:00<00:00, 84.18it/s, train_loss=0.0296, val_loss=0.0347]Epoch 3:  89%|████████▉ | 25/28 [00:00<00:00, 83.66it/s, train_loss=0.0195, val_loss=0.0347]Epoch 3:  93%|█████████▎| 26/28 [00:00<00:00, 84.64it/s, train_loss=0.0195, val_loss=0.0347]Epoch 3:  93%|█████████▎| 26/28 [00:00<00:00, 83.68it/s, train_loss=0.0274, val_loss=0.0347]Epoch 3:  96%|█████████▋| 27/28 [00:00<00:00, 84.57it/s, train_loss=0.0274, val_loss=0.0347]Epoch 3:  96%|█████████▋| 27/28 [00:00<00:00, 84.09it/s, train_loss=0.0178, val_loss=0.0347]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 85.22it/s, train_loss=0.0178, val_loss=0.0347]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 85.04it/s, train_loss=0.0336, val_loss=0.0347]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 136.00it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 155.54it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 162.21it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 167.15it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 170.25it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 171.40it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 173.52it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 173.56it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 174.03it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 173.74it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 174.34it/s][A
                                                                         [AEpoch 3: 100%|██████████| 28/28 [00:00<00:00, 70.09it/s, train_loss=0.0336, val_loss=0.0333]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 69.91it/s, train_loss=0.0336, val_loss=0.0333]Epoch 3:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0336, val_loss=0.0333]         Epoch 4:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0336, val_loss=0.0333]Epoch 4:   4%|▎         | 1/28 [00:00<00:00, 91.02it/s, train_loss=0.0336, val_loss=0.0333]Epoch 4:   4%|▎         | 1/28 [00:00<00:00, 84.02it/s, train_loss=0.0208, val_loss=0.0333]Epoch 4:   7%|▋         | 2/28 [00:00<00:00, 91.38it/s, train_loss=0.0208, val_loss=0.0333]Epoch 4:   7%|▋         | 2/28 [00:00<00:00, 87.63it/s, train_loss=0.0268, val_loss=0.0333]Epoch 4:  11%|█         | 3/28 [00:00<00:00, 93.59it/s, train_loss=0.0268, val_loss=0.0333]Epoch 4:  11%|█         | 3/28 [00:00<00:00, 89.06it/s, train_loss=0.0267, val_loss=0.0333]Epoch 4:  14%|█▍        | 4/28 [00:00<00:00, 90.96it/s, train_loss=0.0267, val_loss=0.0333]Epoch 4:  14%|█▍        | 4/28 [00:00<00:00, 88.55it/s, train_loss=0.0252, val_loss=0.0333]Epoch 4:  18%|█▊        | 5/28 [00:00<00:00, 92.71it/s, train_loss=0.0252, val_loss=0.0333]Epoch 4:  18%|█▊        | 5/28 [00:00<00:00, 89.74it/s, train_loss=0.0242, val_loss=0.0333]Epoch 4:  21%|██▏       | 6/28 [00:00<00:00, 93.20it/s, train_loss=0.0242, val_loss=0.0333]Epoch 4:  21%|██▏       | 6/28 [00:00<00:00, 88.83it/s, train_loss=0.0287, val_loss=0.0333]Epoch 4:  25%|██▌       | 7/28 [00:00<00:00, 91.94it/s, train_loss=0.0287, val_loss=0.0333]Epoch 4:  25%|██▌       | 7/28 [00:00<00:00, 89.87it/s, train_loss=0.0204, val_loss=0.0333]Epoch 4:  29%|██▊       | 8/28 [00:00<00:00, 92.39it/s, train_loss=0.0204, val_loss=0.0333]Epoch 4:  29%|██▊       | 8/28 [00:00<00:00, 88.93it/s, train_loss=0.0243, val_loss=0.0333]Epoch 4:  32%|███▏      | 9/28 [00:00<00:00, 91.21it/s, train_loss=0.0243, val_loss=0.0333]Epoch 4:  32%|███▏      | 9/28 [00:00<00:00, 89.56it/s, train_loss=0.0168, val_loss=0.0333]Epoch 4:  36%|███▌      | 10/28 [00:00<00:00, 90.99it/s, train_loss=0.0168, val_loss=0.0333]Epoch 4:  36%|███▌      | 10/28 [00:00<00:00, 89.17it/s, train_loss=0.0139, val_loss=0.0333]Epoch 4:  39%|███▉      | 11/28 [00:00<00:00, 91.20it/s, train_loss=0.0139, val_loss=0.0333]Epoch 4:  39%|███▉      | 11/28 [00:00<00:00, 89.84it/s, train_loss=0.0264, val_loss=0.0333]Epoch 4:  43%|████▎     | 12/28 [00:00<00:00, 90.65it/s, train_loss=0.0264, val_loss=0.0333]Epoch 4:  43%|████▎     | 12/28 [00:00<00:00, 89.29it/s, train_loss=0.0139, val_loss=0.0333]Epoch 4:  46%|████▋     | 13/28 [00:00<00:00, 90.49it/s, train_loss=0.0139, val_loss=0.0333]Epoch 4:  46%|████▋     | 13/28 [00:00<00:00, 89.51it/s, train_loss=0.0419, val_loss=0.0333]Epoch 4:  50%|█████     | 14/28 [00:00<00:00, 90.21it/s, train_loss=0.0419, val_loss=0.0333]Epoch 4:  50%|█████     | 14/28 [00:00<00:00, 89.23it/s, train_loss=0.0304, val_loss=0.0333]Epoch 4:  54%|█████▎    | 15/28 [00:00<00:00, 90.70it/s, train_loss=0.0304, val_loss=0.0333]Epoch 4:  54%|█████▎    | 15/28 [00:00<00:00, 89.71it/s, train_loss=0.0287, val_loss=0.0333]Epoch 4:  57%|█████▋    | 16/28 [00:00<00:00, 90.60it/s, train_loss=0.0287, val_loss=0.0333]Epoch 4:  57%|█████▋    | 16/28 [00:00<00:00, 89.40it/s, train_loss=0.026, val_loss=0.0333] Epoch 4:  61%|██████    | 17/28 [00:00<00:00, 90.71it/s, train_loss=0.026, val_loss=0.0333]Epoch 4:  61%|██████    | 17/28 [00:00<00:00, 89.83it/s, train_loss=0.029, val_loss=0.0333]Epoch 4:  64%|██████▍   | 18/28 [00:00<00:00, 90.52it/s, train_loss=0.029, val_loss=0.0333]Epoch 4:  64%|██████▍   | 18/28 [00:00<00:00, 89.56it/s, train_loss=0.0217, val_loss=0.0333]Epoch 4:  68%|██████▊   | 19/28 [00:00<00:00, 90.66it/s, train_loss=0.0217, val_loss=0.0333]Epoch 4:  68%|██████▊   | 19/28 [00:00<00:00, 89.92it/s, train_loss=0.0245, val_loss=0.0333]Epoch 4:  71%|███████▏  | 20/28 [00:00<00:00, 90.46it/s, train_loss=0.0245, val_loss=0.0333]Epoch 4:  71%|███████▏  | 20/28 [00:00<00:00, 89.67it/s, train_loss=0.0203, val_loss=0.0333]Epoch 4:  75%|███████▌  | 21/28 [00:00<00:00, 90.63it/s, train_loss=0.0203, val_loss=0.0333]Epoch 4:  75%|███████▌  | 21/28 [00:00<00:00, 89.96it/s, train_loss=0.0177, val_loss=0.0333]Epoch 4:  79%|███████▊  | 22/28 [00:00<00:00, 90.46it/s, train_loss=0.0177, val_loss=0.0333]Epoch 4:  79%|███████▊  | 22/28 [00:00<00:00, 89.73it/s, train_loss=0.0201, val_loss=0.0333]Epoch 4:  82%|████████▏ | 23/28 [00:00<00:00, 90.61it/s, train_loss=0.0201, val_loss=0.0333]Epoch 4:  82%|████████▏ | 23/28 [00:00<00:00, 89.96it/s, train_loss=0.0187, val_loss=0.0333]Epoch 4:  86%|████████▌ | 24/28 [00:00<00:00, 90.28it/s, train_loss=0.0187, val_loss=0.0333]Epoch 4:  86%|████████▌ | 24/28 [00:00<00:00, 89.78it/s, train_loss=0.0263, val_loss=0.0333]Epoch 4:  89%|████████▉ | 25/28 [00:00<00:00, 90.54it/s, train_loss=0.0263, val_loss=0.0333]Epoch 4:  89%|████████▉ | 25/28 [00:00<00:00, 89.98it/s, train_loss=0.028, val_loss=0.0333] Epoch 4:  93%|█████████▎| 26/28 [00:00<00:00, 90.46it/s, train_loss=0.028, val_loss=0.0333]Epoch 4:  93%|█████████▎| 26/28 [00:00<00:00, 89.80it/s, train_loss=0.0237, val_loss=0.0333]Epoch 4:  96%|█████████▋| 27/28 [00:00<00:00, 90.67it/s, train_loss=0.0237, val_loss=0.0333]Epoch 4:  96%|█████████▋| 27/28 [00:00<00:00, 90.12it/s, train_loss=0.0151, val_loss=0.0333]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 91.24it/s, train_loss=0.0151, val_loss=0.0333]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 91.05it/s, train_loss=0.0116, val_loss=0.0333]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 158.96it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 175.44it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 181.29it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 184.26it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 185.90it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 185.24it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 186.08it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 185.92it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 184.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 184.27it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 184.44it/s][A
                                                                         [AEpoch 4: 100%|██████████| 28/28 [00:00<00:00, 74.99it/s, train_loss=0.0116, val_loss=0.0323]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 74.81it/s, train_loss=0.0116, val_loss=0.0323]Epoch 4:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0116, val_loss=0.0323]         Epoch 5:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0116, val_loss=0.0323]Epoch 5:   4%|▎         | 1/28 [00:00<00:00, 90.75it/s, train_loss=0.0116, val_loss=0.0323]Epoch 5:   4%|▎         | 1/28 [00:00<00:00, 84.78it/s, train_loss=0.018, val_loss=0.0323] Epoch 5:   7%|▋         | 2/28 [00:00<00:00, 94.81it/s, train_loss=0.018, val_loss=0.0323]Epoch 5:   7%|▋         | 2/28 [00:00<00:00, 83.41it/s, train_loss=0.0248, val_loss=0.0323]Epoch 5:  11%|█         | 3/28 [00:00<00:00, 90.23it/s, train_loss=0.0248, val_loss=0.0323]Epoch 5:  11%|█         | 3/28 [00:00<00:00, 86.05it/s, train_loss=0.0177, val_loss=0.0323]Epoch 5:  14%|█▍        | 4/28 [00:00<00:00, 88.40it/s, train_loss=0.0177, val_loss=0.0323]Epoch 5:  14%|█▍        | 4/28 [00:00<00:00, 86.24it/s, train_loss=0.0255, val_loss=0.0323]Epoch 5:  18%|█▊        | 5/28 [00:00<00:00, 90.27it/s, train_loss=0.0255, val_loss=0.0323]Epoch 5:  18%|█▊        | 5/28 [00:00<00:00, 87.70it/s, train_loss=0.0328, val_loss=0.0323]Epoch 5:  21%|██▏       | 6/28 [00:00<00:00, 89.08it/s, train_loss=0.0328, val_loss=0.0323]Epoch 5:  21%|██▏       | 6/28 [00:00<00:00, 87.39it/s, train_loss=0.0287, val_loss=0.0323]Epoch 5:  25%|██▌       | 7/28 [00:00<00:00, 90.10it/s, train_loss=0.0287, val_loss=0.0323]Epoch 5:  25%|██▌       | 7/28 [00:00<00:00, 88.17it/s, train_loss=0.022, val_loss=0.0323] Epoch 5:  29%|██▊       | 8/28 [00:00<00:00, 89.02it/s, train_loss=0.022, val_loss=0.0323]Epoch 5:  29%|██▊       | 8/28 [00:00<00:00, 87.82it/s, train_loss=0.0198, val_loss=0.0323]Epoch 5:  32%|███▏      | 9/28 [00:00<00:00, 90.08it/s, train_loss=0.0198, val_loss=0.0323]Epoch 5:  32%|███▏      | 9/28 [00:00<00:00, 88.43it/s, train_loss=0.0238, val_loss=0.0323]Epoch 5:  36%|███▌      | 10/28 [00:00<00:00, 90.59it/s, train_loss=0.0238, val_loss=0.0323]Epoch 5:  36%|███▌      | 10/28 [00:00<00:00, 88.02it/s, train_loss=0.0136, val_loss=0.0323]Epoch 5:  39%|███▉      | 11/28 [00:00<00:00, 90.02it/s, train_loss=0.0136, val_loss=0.0323]Epoch 5:  39%|███▉      | 11/28 [00:00<00:00, 88.69it/s, train_loss=0.0233, val_loss=0.0323]Epoch 5:  43%|████▎     | 12/28 [00:00<00:00, 90.52it/s, train_loss=0.0233, val_loss=0.0323]Epoch 5:  43%|████▎     | 12/28 [00:00<00:00, 88.17it/s, train_loss=0.0175, val_loss=0.0323]Epoch 5:  46%|████▋     | 13/28 [00:00<00:00, 89.87it/s, train_loss=0.0175, val_loss=0.0323]Epoch 5:  46%|████▋     | 13/28 [00:00<00:00, 88.80it/s, train_loss=0.0215, val_loss=0.0323]Epoch 5:  50%|█████     | 14/28 [00:00<00:00, 90.10it/s, train_loss=0.0215, val_loss=0.0323]Epoch 5:  50%|█████     | 14/28 [00:00<00:00, 88.47it/s, train_loss=0.0256, val_loss=0.0323]Epoch 5:  54%|█████▎    | 15/28 [00:00<00:00, 90.05it/s, train_loss=0.0256, val_loss=0.0323]Epoch 5:  54%|█████▎    | 15/28 [00:00<00:00, 89.06it/s, train_loss=0.0251, val_loss=0.0323]Epoch 5:  57%|█████▋    | 16/28 [00:00<00:00, 90.44it/s, train_loss=0.0251, val_loss=0.0323]Epoch 5:  57%|█████▋    | 16/28 [00:00<00:00, 88.65it/s, train_loss=0.0133, val_loss=0.0323]Epoch 5:  61%|██████    | 17/28 [00:00<00:00, 89.78it/s, train_loss=0.0133, val_loss=0.0323]Epoch 5:  61%|██████    | 17/28 [00:00<00:00, 88.92it/s, train_loss=0.0186, val_loss=0.0323]Epoch 5:  64%|██████▍   | 18/28 [00:00<00:00, 89.72it/s, train_loss=0.0186, val_loss=0.0323]Epoch 5:  64%|██████▍   | 18/28 [00:00<00:00, 88.77it/s, train_loss=0.0205, val_loss=0.0323]Epoch 5:  68%|██████▊   | 19/28 [00:00<00:00, 89.94it/s, train_loss=0.0205, val_loss=0.0323]Epoch 5:  68%|██████▊   | 19/28 [00:00<00:00, 89.19it/s, train_loss=0.0229, val_loss=0.0323]Epoch 5:  71%|███████▏  | 20/28 [00:00<00:00, 89.92it/s, train_loss=0.0229, val_loss=0.0323]Epoch 5:  71%|███████▏  | 20/28 [00:00<00:00, 88.99it/s, train_loss=0.0219, val_loss=0.0323]Epoch 5:  75%|███████▌  | 21/28 [00:00<00:00, 89.92it/s, train_loss=0.0219, val_loss=0.0323]Epoch 5:  75%|███████▌  | 21/28 [00:00<00:00, 89.21it/s, train_loss=0.024, val_loss=0.0323] Epoch 5:  79%|███████▊  | 22/28 [00:00<00:00, 89.66it/s, train_loss=0.024, val_loss=0.0323]Epoch 5:  79%|███████▊  | 22/28 [00:00<00:00, 89.03it/s, train_loss=0.0251, val_loss=0.0323]Epoch 5:  82%|████████▏ | 23/28 [00:00<00:00, 89.96it/s, train_loss=0.0251, val_loss=0.0323]Epoch 5:  82%|████████▏ | 23/28 [00:00<00:00, 89.36it/s, train_loss=0.0201, val_loss=0.0323]Epoch 5:  86%|████████▌ | 24/28 [00:00<00:00, 89.60it/s, train_loss=0.0201, val_loss=0.0323]Epoch 5:  86%|████████▌ | 24/28 [00:00<00:00, 89.18it/s, train_loss=0.0264, val_loss=0.0323]Epoch 5:  89%|████████▉ | 25/28 [00:00<00:00, 90.00it/s, train_loss=0.0264, val_loss=0.0323]Epoch 5:  89%|████████▉ | 25/28 [00:00<00:00, 89.43it/s, train_loss=0.0304, val_loss=0.0323]Epoch 5:  93%|█████████▎| 26/28 [00:00<00:00, 89.83it/s, train_loss=0.0304, val_loss=0.0323]Epoch 5:  93%|█████████▎| 26/28 [00:00<00:00, 89.25it/s, train_loss=0.0242, val_loss=0.0323]Epoch 5:  96%|█████████▋| 27/28 [00:00<00:00, 89.98it/s, train_loss=0.0242, val_loss=0.0323]Epoch 5:  96%|█████████▋| 27/28 [00:00<00:00, 89.41it/s, train_loss=0.0274, val_loss=0.0323]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 90.15it/s, train_loss=0.0274, val_loss=0.0323]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 89.86it/s, train_loss=0.00794, val_loss=0.0323]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 191.92it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 201.57it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 210.00it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 208.59it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 208.79it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 208.62it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 206.68it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 206.05it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 205.04it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 201.59it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 200.12it/s][A
                                                                         [AEpoch 5: 100%|██████████| 28/28 [00:00<00:00, 75.23it/s, train_loss=0.00794, val_loss=0.0298]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 75.08it/s, train_loss=0.00794, val_loss=0.0298]Epoch 5:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00794, val_loss=0.0298]         Epoch 6:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00794, val_loss=0.0298]Epoch 6:   4%|▎         | 1/28 [00:00<00:00, 90.03it/s, train_loss=0.00794, val_loss=0.0298]Epoch 6:   4%|▎         | 1/28 [00:00<00:00, 84.61it/s, train_loss=0.0238, val_loss=0.0298] Epoch 6:   7%|▋         | 2/28 [00:00<00:00, 94.93it/s, train_loss=0.0238, val_loss=0.0298]Epoch 6:   7%|▋         | 2/28 [00:00<00:00, 83.36it/s, train_loss=0.0255, val_loss=0.0298]Epoch 6:  11%|█         | 3/28 [00:00<00:00, 90.69it/s, train_loss=0.0255, val_loss=0.0298]Epoch 6:  11%|█         | 3/28 [00:00<00:00, 86.46it/s, train_loss=0.0161, val_loss=0.0298]Epoch 6:  14%|█▍        | 4/28 [00:00<00:00, 89.63it/s, train_loss=0.0161, val_loss=0.0298]Epoch 6:  14%|█▍        | 4/28 [00:00<00:00, 86.29it/s, train_loss=0.0157, val_loss=0.0298]Epoch 6:  18%|█▊        | 5/28 [00:00<00:00, 90.58it/s, train_loss=0.0157, val_loss=0.0298]Epoch 6:  18%|█▊        | 5/28 [00:00<00:00, 87.89it/s, train_loss=0.0224, val_loss=0.0298]Epoch 6:  21%|██▏       | 6/28 [00:00<00:00, 89.79it/s, train_loss=0.0224, val_loss=0.0298]Epoch 6:  21%|██▏       | 6/28 [00:00<00:00, 87.57it/s, train_loss=0.0222, val_loss=0.0298]Epoch 6:  25%|██▌       | 7/28 [00:00<00:00, 90.66it/s, train_loss=0.0222, val_loss=0.0298]Epoch 6:  25%|██▌       | 7/28 [00:00<00:00, 88.51it/s, train_loss=0.019, val_loss=0.0298] Epoch 6:  29%|██▊       | 8/28 [00:00<00:00, 89.72it/s, train_loss=0.019, val_loss=0.0298]Epoch 6:  29%|██▊       | 8/28 [00:00<00:00, 88.22it/s, train_loss=0.0173, val_loss=0.0298]Epoch 6:  32%|███▏      | 9/28 [00:00<00:00, 90.57it/s, train_loss=0.0173, val_loss=0.0298]Epoch 6:  32%|███▏      | 9/28 [00:00<00:00, 88.84it/s, train_loss=0.0267, val_loss=0.0298]Epoch 6:  36%|███▌      | 10/28 [00:00<00:00, 90.10it/s, train_loss=0.0267, val_loss=0.0298]Epoch 6:  36%|███▌      | 10/28 [00:00<00:00, 88.53it/s, train_loss=0.0241, val_loss=0.0298]Epoch 6:  39%|███▉      | 11/28 [00:00<00:00, 90.39it/s, train_loss=0.0241, val_loss=0.0298]Epoch 6:  39%|███▉      | 11/28 [00:00<00:00, 89.00it/s, train_loss=0.0196, val_loss=0.0298]Epoch 6:  43%|████▎     | 12/28 [00:00<00:00, 89.79it/s, train_loss=0.0196, val_loss=0.0298]Epoch 6:  43%|████▎     | 12/28 [00:00<00:00, 88.76it/s, train_loss=0.0219, val_loss=0.0298]Epoch 6:  46%|████▋     | 13/28 [00:00<00:00, 90.31it/s, train_loss=0.0219, val_loss=0.0298]Epoch 6:  46%|████▋     | 13/28 [00:00<00:00, 89.19it/s, train_loss=0.0287, val_loss=0.0298]Epoch 6:  50%|█████     | 14/28 [00:00<00:00, 90.01it/s, train_loss=0.0287, val_loss=0.0298]Epoch 6:  50%|█████     | 14/28 [00:00<00:00, 89.02it/s, train_loss=0.0176, val_loss=0.0298]Epoch 6:  54%|█████▎    | 15/28 [00:00<00:00, 90.48it/s, train_loss=0.0176, val_loss=0.0298]Epoch 6:  54%|█████▎    | 15/28 [00:00<00:00, 89.52it/s, train_loss=0.0124, val_loss=0.0298]Epoch 6:  57%|█████▋    | 16/28 [00:00<00:00, 90.45it/s, train_loss=0.0124, val_loss=0.0298]Epoch 6:  57%|█████▋    | 16/28 [00:00<00:00, 89.13it/s, train_loss=0.0176, val_loss=0.0298]Epoch 6:  61%|██████    | 17/28 [00:00<00:00, 90.30it/s, train_loss=0.0176, val_loss=0.0298]Epoch 6:  61%|██████    | 17/28 [00:00<00:00, 89.40it/s, train_loss=0.029, val_loss=0.0298] Epoch 6:  64%|██████▍   | 18/28 [00:00<00:00, 90.24it/s, train_loss=0.029, val_loss=0.0298]Epoch 6:  64%|██████▍   | 18/28 [00:00<00:00, 89.23it/s, train_loss=0.0174, val_loss=0.0298]Epoch 6:  68%|██████▊   | 19/28 [00:00<00:00, 90.48it/s, train_loss=0.0174, val_loss=0.0298]Epoch 6:  68%|██████▊   | 19/28 [00:00<00:00, 89.65it/s, train_loss=0.0233, val_loss=0.0298]Epoch 6:  71%|███████▏  | 20/28 [00:00<00:00, 90.58it/s, train_loss=0.0233, val_loss=0.0298]Epoch 6:  71%|███████▏  | 20/28 [00:00<00:00, 89.33it/s, train_loss=0.0113, val_loss=0.0298]Epoch 6:  75%|███████▌  | 21/28 [00:00<00:00, 90.28it/s, train_loss=0.0113, val_loss=0.0298]Epoch 6:  75%|███████▌  | 21/28 [00:00<00:00, 89.51it/s, train_loss=0.0364, val_loss=0.0298]Epoch 6:  79%|███████▊  | 22/28 [00:00<00:00, 90.14it/s, train_loss=0.0364, val_loss=0.0298]Epoch 6:  79%|███████▊  | 22/28 [00:00<00:00, 89.36it/s, train_loss=0.0237, val_loss=0.0298]Epoch 6:  82%|████████▏ | 23/28 [00:00<00:00, 90.32it/s, train_loss=0.0237, val_loss=0.0298]Epoch 6:  82%|████████▏ | 23/28 [00:00<00:00, 89.65it/s, train_loss=0.0224, val_loss=0.0298]Epoch 6:  86%|████████▌ | 24/28 [00:00<00:00, 90.26it/s, train_loss=0.0224, val_loss=0.0298]Epoch 6:  86%|████████▌ | 24/28 [00:00<00:00, 89.48it/s, train_loss=0.0217, val_loss=0.0298]Epoch 6:  89%|████████▉ | 25/28 [00:00<00:00, 90.33it/s, train_loss=0.0217, val_loss=0.0298]Epoch 6:  89%|████████▉ | 25/28 [00:00<00:00, 89.73it/s, train_loss=0.0153, val_loss=0.0298]Epoch 6:  93%|█████████▎| 26/28 [00:00<00:00, 90.21it/s, train_loss=0.0153, val_loss=0.0298]Epoch 6:  93%|█████████▎| 26/28 [00:00<00:00, 89.60it/s, train_loss=0.0116, val_loss=0.0298]Epoch 6:  96%|█████████▋| 27/28 [00:00<00:00, 90.36it/s, train_loss=0.0116, val_loss=0.0298]Epoch 6:  96%|█████████▋| 27/28 [00:00<00:00, 89.78it/s, train_loss=0.0164, val_loss=0.0298]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 90.51it/s, train_loss=0.0164, val_loss=0.0298]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 90.24it/s, train_loss=0.0116, val_loss=0.0298]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 126.09it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 141.84it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 150.92it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 153.16it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 155.66it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 155.84it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 159.83it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 163.92it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 167.85it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 171.42it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 175.52it/s][A
                                                                         [AEpoch 6: 100%|██████████| 28/28 [00:00<00:00, 73.45it/s, train_loss=0.0116, val_loss=0.0207]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 73.32it/s, train_loss=0.0116, val_loss=0.0207]Epoch 6:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0116, val_loss=0.0207]         Epoch 7:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0116, val_loss=0.0207]Epoch 7:   4%|▎         | 1/28 [00:00<00:00, 91.63it/s, train_loss=0.0116, val_loss=0.0207]Epoch 7:   4%|▎         | 1/28 [00:00<00:00, 79.46it/s, train_loss=0.0131, val_loss=0.0207]Epoch 7:   7%|▋         | 2/28 [00:00<00:00, 91.29it/s, train_loss=0.0131, val_loss=0.0207]Epoch 7:   7%|▋         | 2/28 [00:00<00:00, 85.36it/s, train_loss=0.0165, val_loss=0.0207]Epoch 7:  11%|█         | 3/28 [00:00<00:00, 89.50it/s, train_loss=0.0165, val_loss=0.0207]Epoch 7:  11%|█         | 3/28 [00:00<00:00, 86.03it/s, train_loss=0.0167, val_loss=0.0207]Epoch 7:  14%|█▍        | 4/28 [00:00<00:00, 91.59it/s, train_loss=0.0167, val_loss=0.0207]Epoch 7:  14%|█▍        | 4/28 [00:00<00:00, 87.98it/s, train_loss=0.0178, val_loss=0.0207]Epoch 7:  18%|█▊        | 5/28 [00:00<00:00, 90.20it/s, train_loss=0.0178, val_loss=0.0207]Epoch 7:  18%|█▊        | 5/28 [00:00<00:00, 87.48it/s, train_loss=0.0228, val_loss=0.0207]Epoch 7:  21%|██▏       | 6/28 [00:00<00:00, 90.66it/s, train_loss=0.0228, val_loss=0.0207]Epoch 7:  21%|██▏       | 6/28 [00:00<00:00, 88.50it/s, train_loss=0.0174, val_loss=0.0207]Epoch 7:  25%|██▌       | 7/28 [00:00<00:00, 89.19it/s, train_loss=0.0174, val_loss=0.0207]Epoch 7:  25%|██▌       | 7/28 [00:00<00:00, 88.31it/s, train_loss=0.0258, val_loss=0.0207]Epoch 7:  29%|██▊       | 8/28 [00:00<00:00, 91.20it/s, train_loss=0.0258, val_loss=0.0207]Epoch 7:  29%|██▊       | 8/28 [00:00<00:00, 89.28it/s, train_loss=0.0147, val_loss=0.0207]Epoch 7:  32%|███▏      | 9/28 [00:00<00:00, 90.67it/s, train_loss=0.0147, val_loss=0.0207]Epoch 7:  32%|███▏      | 9/28 [00:00<00:00, 88.89it/s, train_loss=0.0285, val_loss=0.0207]Epoch 7:  36%|███▌      | 10/28 [00:00<00:00, 90.88it/s, train_loss=0.0285, val_loss=0.0207]Epoch 7:  36%|███▌      | 10/28 [00:00<00:00, 89.52it/s, train_loss=0.0169, val_loss=0.0207]Epoch 7:  39%|███▉      | 11/28 [00:00<00:00, 90.41it/s, train_loss=0.0169, val_loss=0.0207]Epoch 7:  39%|███▉      | 11/28 [00:00<00:00, 89.18it/s, train_loss=0.0162, val_loss=0.0207]Epoch 7:  43%|████▎     | 12/28 [00:00<00:00, 90.91it/s, train_loss=0.0162, val_loss=0.0207]Epoch 7:  43%|████▎     | 12/28 [00:00<00:00, 89.66it/s, train_loss=0.0151, val_loss=0.0207]Epoch 7:  46%|████▋     | 13/28 [00:00<00:00, 90.41it/s, train_loss=0.0151, val_loss=0.0207]Epoch 7:  46%|████▋     | 13/28 [00:00<00:00, 89.45it/s, train_loss=0.014, val_loss=0.0207] Epoch 7:  50%|█████     | 14/28 [00:00<00:00, 90.68it/s, train_loss=0.014, val_loss=0.0207]Epoch 7:  50%|█████     | 14/28 [00:00<00:00, 89.78it/s, train_loss=0.0167, val_loss=0.0207]Epoch 7:  54%|█████▎    | 15/28 [00:00<00:00, 90.38it/s, train_loss=0.0167, val_loss=0.0207]Epoch 7:  54%|█████▎    | 15/28 [00:00<00:00, 89.56it/s, train_loss=0.0184, val_loss=0.0207]Epoch 7:  57%|█████▋    | 16/28 [00:00<00:00, 90.81it/s, train_loss=0.0184, val_loss=0.0207]Epoch 7:  57%|█████▋    | 16/28 [00:00<00:00, 89.97it/s, train_loss=0.0193, val_loss=0.0207]Epoch 7:  61%|██████    | 17/28 [00:00<00:00, 90.57it/s, train_loss=0.0193, val_loss=0.0207]Epoch 7:  61%|██████    | 17/28 [00:00<00:00, 89.82it/s, train_loss=0.0136, val_loss=0.0207]Epoch 7:  64%|██████▍   | 18/28 [00:00<00:00, 91.11it/s, train_loss=0.0136, val_loss=0.0207]Epoch 7:  64%|██████▍   | 18/28 [00:00<00:00, 90.28it/s, train_loss=0.0205, val_loss=0.0207]Epoch 7:  68%|██████▊   | 19/28 [00:00<00:00, 90.91it/s, train_loss=0.0205, val_loss=0.0207]Epoch 7:  68%|██████▊   | 19/28 [00:00<00:00, 90.01it/s, train_loss=0.0134, val_loss=0.0207]Epoch 7:  71%|███████▏  | 20/28 [00:00<00:00, 91.07it/s, train_loss=0.0134, val_loss=0.0207]Epoch 7:  71%|███████▏  | 20/28 [00:00<00:00, 90.37it/s, train_loss=0.0182, val_loss=0.0207]Epoch 7:  75%|███████▌  | 21/28 [00:00<00:00, 90.80it/s, train_loss=0.0182, val_loss=0.0207]Epoch 7:  75%|███████▌  | 21/28 [00:00<00:00, 90.14it/s, train_loss=0.0128, val_loss=0.0207]Epoch 7:  79%|███████▊  | 22/28 [00:00<00:00, 91.10it/s, train_loss=0.0128, val_loss=0.0207]Epoch 7:  79%|███████▊  | 22/28 [00:00<00:00, 90.42it/s, train_loss=0.0149, val_loss=0.0207]Epoch 7:  82%|████████▏ | 23/28 [00:00<00:00, 91.03it/s, train_loss=0.0149, val_loss=0.0207]Epoch 7:  82%|████████▏ | 23/28 [00:00<00:00, 90.24it/s, train_loss=0.012, val_loss=0.0207] Epoch 7:  86%|████████▌ | 24/28 [00:00<00:00, 91.21it/s, train_loss=0.012, val_loss=0.0207]Epoch 7:  86%|████████▌ | 24/28 [00:00<00:00, 90.54it/s, train_loss=0.0145, val_loss=0.0207]Epoch 7:  89%|████████▉ | 25/28 [00:00<00:00, 91.15it/s, train_loss=0.0145, val_loss=0.0207]Epoch 7:  89%|████████▉ | 25/28 [00:00<00:00, 90.35it/s, train_loss=0.0177, val_loss=0.0207]Epoch 7:  93%|█████████▎| 26/28 [00:00<00:00, 91.18it/s, train_loss=0.0177, val_loss=0.0207]Epoch 7:  93%|█████████▎| 26/28 [00:00<00:00, 90.59it/s, train_loss=0.0136, val_loss=0.0207]Epoch 7:  96%|█████████▋| 27/28 [00:00<00:00, 91.12it/s, train_loss=0.0136, val_loss=0.0207]Epoch 7:  96%|█████████▋| 27/28 [00:00<00:00, 90.47it/s, train_loss=0.014, val_loss=0.0207] Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 91.50it/s, train_loss=0.014, val_loss=0.0207]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 91.03it/s, train_loss=0.00704, val_loss=0.0207]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 129.34it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 149.67it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 155.65it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 160.12it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 160.59it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 162.37it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 162.57it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 163.42it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 163.29it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 163.74it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 163.41it/s][A
                                                                         [AEpoch 7: 100%|██████████| 28/28 [00:00<00:00, 73.07it/s, train_loss=0.00704, val_loss=0.0133]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 72.86it/s, train_loss=0.00704, val_loss=0.0133]Epoch 7:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00704, val_loss=0.0133]         Epoch 8:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00704, val_loss=0.0133]Epoch 8:   4%|▎         | 1/28 [00:00<00:00, 90.89it/s, train_loss=0.00704, val_loss=0.0133]Epoch 8:   4%|▎         | 1/28 [00:00<00:00, 86.24it/s, train_loss=0.0137, val_loss=0.0133] Epoch 8:   7%|▋         | 2/28 [00:00<00:00, 96.91it/s, train_loss=0.0137, val_loss=0.0133]Epoch 8:   7%|▋         | 2/28 [00:00<00:00, 84.01it/s, train_loss=0.0164, val_loss=0.0133]Epoch 8:  11%|█         | 3/28 [00:00<00:00, 91.49it/s, train_loss=0.0164, val_loss=0.0133]Epoch 8:  11%|█         | 3/28 [00:00<00:00, 87.43it/s, train_loss=0.0107, val_loss=0.0133]Epoch 8:  14%|█▍        | 4/28 [00:00<00:00, 90.66it/s, train_loss=0.0107, val_loss=0.0133]Epoch 8:  14%|█▍        | 4/28 [00:00<00:00, 87.68it/s, train_loss=0.0129, val_loss=0.0133]Epoch 8:  18%|█▊        | 5/28 [00:00<00:00, 92.02it/s, train_loss=0.0129, val_loss=0.0133]Epoch 8:  18%|█▊        | 5/28 [00:00<00:00, 89.23it/s, train_loss=0.0112, val_loss=0.0133]Epoch 8:  21%|██▏       | 6/28 [00:00<00:00, 91.02it/s, train_loss=0.0112, val_loss=0.0133]Epoch 8:  21%|██▏       | 6/28 [00:00<00:00, 88.85it/s, train_loss=0.0166, val_loss=0.0133]Epoch 8:  25%|██▌       | 7/28 [00:00<00:00, 91.27it/s, train_loss=0.0166, val_loss=0.0133]Epoch 8:  25%|██▌       | 7/28 [00:00<00:00, 89.51it/s, train_loss=0.0158, val_loss=0.0133]Epoch 8:  29%|██▊       | 8/28 [00:00<00:00, 90.80it/s, train_loss=0.0158, val_loss=0.0133]Epoch 8:  29%|██▊       | 8/28 [00:00<00:00, 89.37it/s, train_loss=0.0108, val_loss=0.0133]Epoch 8:  32%|███▏      | 9/28 [00:00<00:00, 91.68it/s, train_loss=0.0108, val_loss=0.0133]Epoch 8:  32%|███▏      | 9/28 [00:00<00:00, 90.02it/s, train_loss=0.0129, val_loss=0.0133]Epoch 8:  36%|███▌      | 10/28 [00:00<00:00, 90.88it/s, train_loss=0.0129, val_loss=0.0133]Epoch 8:  36%|███▌      | 10/28 [00:00<00:00, 89.74it/s, train_loss=0.00921, val_loss=0.0133]Epoch 8:  39%|███▉      | 11/28 [00:00<00:00, 91.45it/s, train_loss=0.00921, val_loss=0.0133]Epoch 8:  39%|███▉      | 11/28 [00:00<00:00, 90.20it/s, train_loss=0.0142, val_loss=0.0133] Epoch 8:  43%|████▎     | 12/28 [00:00<00:00, 91.02it/s, train_loss=0.0142, val_loss=0.0133]Epoch 8:  43%|████▎     | 12/28 [00:00<00:00, 90.06it/s, train_loss=0.0135, val_loss=0.0133]Epoch 8:  46%|████▋     | 13/28 [00:00<00:00, 91.51it/s, train_loss=0.0135, val_loss=0.0133]Epoch 8:  46%|████▋     | 13/28 [00:00<00:00, 90.53it/s, train_loss=0.0115, val_loss=0.0133]Epoch 8:  50%|█████     | 14/28 [00:00<00:00, 91.14it/s, train_loss=0.0115, val_loss=0.0133]Epoch 8:  50%|█████     | 14/28 [00:00<00:00, 90.30it/s, train_loss=0.0144, val_loss=0.0133]Epoch 8:  54%|█████▎    | 15/28 [00:00<00:00, 91.48it/s, train_loss=0.0144, val_loss=0.0133]Epoch 8:  54%|█████▎    | 15/28 [00:00<00:00, 90.62it/s, train_loss=0.0147, val_loss=0.0133]Epoch 8:  57%|█████▋    | 16/28 [00:00<00:00, 91.05it/s, train_loss=0.0147, val_loss=0.0133]Epoch 8:  57%|█████▋    | 16/28 [00:00<00:00, 90.38it/s, train_loss=0.0101, val_loss=0.0133]Epoch 8:  61%|██████    | 17/28 [00:00<00:00, 91.44it/s, train_loss=0.0101, val_loss=0.0133]Epoch 8:  61%|██████    | 17/28 [00:00<00:00, 90.66it/s, train_loss=0.016, val_loss=0.0133] Epoch 8:  64%|██████▍   | 18/28 [00:00<00:00, 90.93it/s, train_loss=0.016, val_loss=0.0133]Epoch 8:  64%|██████▍   | 18/28 [00:00<00:00, 90.42it/s, train_loss=0.0144, val_loss=0.0133]Epoch 8:  68%|██████▊   | 19/28 [00:00<00:00, 91.36it/s, train_loss=0.0144, val_loss=0.0133]Epoch 8:  68%|██████▊   | 19/28 [00:00<00:00, 90.66it/s, train_loss=0.0109, val_loss=0.0133]Epoch 8:  71%|███████▏  | 20/28 [00:00<00:00, 91.17it/s, train_loss=0.0109, val_loss=0.0133]Epoch 8:  71%|███████▏  | 20/28 [00:00<00:00, 90.54it/s, train_loss=0.0155, val_loss=0.0133]Epoch 8:  75%|███████▌  | 21/28 [00:00<00:00, 91.64it/s, train_loss=0.0155, val_loss=0.0133]Epoch 8:  75%|███████▌  | 21/28 [00:00<00:00, 90.96it/s, train_loss=0.0104, val_loss=0.0133]Epoch 8:  79%|███████▊  | 22/28 [00:00<00:00, 91.70it/s, train_loss=0.0104, val_loss=0.0133]Epoch 8:  79%|███████▊  | 22/28 [00:00<00:00, 90.72it/s, train_loss=0.0122, val_loss=0.0133]Epoch 8:  82%|████████▏ | 23/28 [00:00<00:00, 91.69it/s, train_loss=0.0122, val_loss=0.0133]Epoch 8:  82%|████████▏ | 23/28 [00:00<00:00, 91.09it/s, train_loss=0.0106, val_loss=0.0133]Epoch 8:  86%|████████▌ | 24/28 [00:00<00:00, 91.88it/s, train_loss=0.0106, val_loss=0.0133]Epoch 8:  86%|████████▌ | 24/28 [00:00<00:00, 90.85it/s, train_loss=0.00961, val_loss=0.0133]Epoch 8:  89%|████████▉ | 25/28 [00:00<00:00, 91.63it/s, train_loss=0.00961, val_loss=0.0133]Epoch 8:  89%|████████▉ | 25/28 [00:00<00:00, 91.08it/s, train_loss=0.0115, val_loss=0.0133] Epoch 8:  93%|█████████▎| 26/28 [00:00<00:00, 91.61it/s, train_loss=0.0115, val_loss=0.0133]Epoch 8:  93%|█████████▎| 26/28 [00:00<00:00, 90.96it/s, train_loss=0.0109, val_loss=0.0133]Epoch 8:  96%|█████████▋| 27/28 [00:00<00:00, 91.73it/s, train_loss=0.0109, val_loss=0.0133]Epoch 8:  96%|█████████▋| 27/28 [00:00<00:00, 91.21it/s, train_loss=0.0145, val_loss=0.0133]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 92.07it/s, train_loss=0.0145, val_loss=0.0133]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 91.84it/s, train_loss=0.00791, val_loss=0.0133]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 142.84it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 158.91it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 167.11it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 169.03it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 171.47it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 172.07it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 173.13it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 173.35it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 173.58it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 172.95it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 173.21it/s][A
                                                                         [AEpoch 8: 100%|██████████| 28/28 [00:00<00:00, 74.33it/s, train_loss=0.00791, val_loss=0.0129]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 74.14it/s, train_loss=0.00791, val_loss=0.0129]Epoch 8:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00791, val_loss=0.0129]         Epoch 9:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00791, val_loss=0.0129]Epoch 9:   4%|▎         | 1/28 [00:00<00:00, 84.84it/s, train_loss=0.00791, val_loss=0.0129]Epoch 9:   4%|▎         | 1/28 [00:00<00:00, 78.61it/s, train_loss=0.0141, val_loss=0.0129] Epoch 9:   7%|▋         | 2/28 [00:00<00:00, 92.86it/s, train_loss=0.0141, val_loss=0.0129]Epoch 9:   7%|▋         | 2/28 [00:00<00:00, 83.00it/s, train_loss=0.0139, val_loss=0.0129]Epoch 9:  11%|█         | 3/28 [00:00<00:00, 87.21it/s, train_loss=0.0139, val_loss=0.0129]Epoch 9:  11%|█         | 3/28 [00:00<00:00, 84.75it/s, train_loss=0.00918, val_loss=0.0129]Epoch 9:  14%|█▍        | 4/28 [00:00<00:00, 88.35it/s, train_loss=0.00918, val_loss=0.0129]Epoch 9:  14%|█▍        | 4/28 [00:00<00:00, 86.83it/s, train_loss=0.0199, val_loss=0.0129] Epoch 9:  18%|█▊        | 5/28 [00:00<00:00, 91.77it/s, train_loss=0.0199, val_loss=0.0129]Epoch 9:  18%|█▊        | 5/28 [00:00<00:00, 89.18it/s, train_loss=0.0119, val_loss=0.0129]Epoch 9:  21%|██▏       | 6/28 [00:00<00:00, 90.71it/s, train_loss=0.0119, val_loss=0.0129]Epoch 9:  21%|██▏       | 6/28 [00:00<00:00, 89.80it/s, train_loss=0.0157, val_loss=0.0129]Epoch 9:  25%|██▌       | 7/28 [00:00<00:00, 92.94it/s, train_loss=0.0157, val_loss=0.0129]Epoch 9:  25%|██▌       | 7/28 [00:00<00:00, 91.16it/s, train_loss=0.012, val_loss=0.0129] Epoch 9:  29%|██▊       | 8/28 [00:00<00:00, 92.00it/s, train_loss=0.012, val_loss=0.0129]Epoch 9:  29%|██▊       | 8/28 [00:00<00:00, 91.27it/s, train_loss=0.0105, val_loss=0.0129]Epoch 9:  32%|███▏      | 9/28 [00:00<00:00, 93.56it/s, train_loss=0.0105, val_loss=0.0129]Epoch 9:  32%|███▏      | 9/28 [00:00<00:00, 92.00it/s, train_loss=0.0125, val_loss=0.0129]Epoch 9:  36%|███▌      | 10/28 [00:00<00:00, 92.44it/s, train_loss=0.0125, val_loss=0.0129]Epoch 9:  36%|███▌      | 10/28 [00:00<00:00, 91.86it/s, train_loss=0.0108, val_loss=0.0129]Epoch 9:  39%|███▉      | 11/28 [00:00<00:00, 93.94it/s, train_loss=0.0108, val_loss=0.0129]Epoch 9:  39%|███▉      | 11/28 [00:00<00:00, 92.62it/s, train_loss=0.00982, val_loss=0.0129]Epoch 9:  43%|████▎     | 12/28 [00:00<00:00, 93.36it/s, train_loss=0.00982, val_loss=0.0129]Epoch 9:  43%|████▎     | 12/28 [00:00<00:00, 92.83it/s, train_loss=0.0114, val_loss=0.0129] Epoch 9:  46%|████▋     | 13/28 [00:00<00:00, 94.48it/s, train_loss=0.0114, val_loss=0.0129]Epoch 9:  46%|████▋     | 13/28 [00:00<00:00, 93.35it/s, train_loss=0.00909, val_loss=0.0129]Epoch 9:  50%|█████     | 14/28 [00:00<00:00, 93.81it/s, train_loss=0.00909, val_loss=0.0129]Epoch 9:  50%|█████     | 14/28 [00:00<00:00, 93.32it/s, train_loss=0.00858, val_loss=0.0129]Epoch 9:  54%|█████▎    | 15/28 [00:00<00:00, 94.67it/s, train_loss=0.00858, val_loss=0.0129]Epoch 9:  54%|█████▎    | 15/28 [00:00<00:00, 93.62it/s, train_loss=0.00978, val_loss=0.0129]Epoch 9:  57%|█████▋    | 16/28 [00:00<00:00, 94.00it/s, train_loss=0.00978, val_loss=0.0129]Epoch 9:  57%|█████▋    | 16/28 [00:00<00:00, 93.58it/s, train_loss=0.00936, val_loss=0.0129]Epoch 9:  61%|██████    | 17/28 [00:00<00:00, 94.78it/s, train_loss=0.00936, val_loss=0.0129]Epoch 9:  61%|██████    | 17/28 [00:00<00:00, 93.90it/s, train_loss=0.0129, val_loss=0.0129] Epoch 9:  64%|██████▍   | 18/28 [00:00<00:00, 94.17it/s, train_loss=0.0129, val_loss=0.0129]Epoch 9:  64%|██████▍   | 18/28 [00:00<00:00, 93.76it/s, train_loss=0.00883, val_loss=0.0129]Epoch 9:  68%|██████▊   | 19/28 [00:00<00:00, 94.86it/s, train_loss=0.00883, val_loss=0.0129]Epoch 9:  68%|██████▊   | 19/28 [00:00<00:00, 94.06it/s, train_loss=0.00923, val_loss=0.0129]Epoch 9:  71%|███████▏  | 20/28 [00:00<00:00, 94.34it/s, train_loss=0.00923, val_loss=0.0129]Epoch 9:  71%|███████▏  | 20/28 [00:00<00:00, 93.96it/s, train_loss=0.0118, val_loss=0.0129] Epoch 9:  75%|███████▌  | 21/28 [00:00<00:00, 94.88it/s, train_loss=0.0118, val_loss=0.0129]Epoch 9:  75%|███████▌  | 21/28 [00:00<00:00, 94.16it/s, train_loss=0.00943, val_loss=0.0129]Epoch 9:  79%|███████▊  | 22/28 [00:00<00:00, 94.37it/s, train_loss=0.00943, val_loss=0.0129]Epoch 9:  79%|███████▊  | 22/28 [00:00<00:00, 94.01it/s, train_loss=0.0113, val_loss=0.0129] Epoch 9:  82%|████████▏ | 23/28 [00:00<00:00, 94.82it/s, train_loss=0.0113, val_loss=0.0129]Epoch 9:  82%|████████▏ | 23/28 [00:00<00:00, 94.20it/s, train_loss=0.00848, val_loss=0.0129]Epoch 9:  86%|████████▌ | 24/28 [00:00<00:00, 94.45it/s, train_loss=0.00848, val_loss=0.0129]Epoch 9:  86%|████████▌ | 24/28 [00:00<00:00, 94.14it/s, train_loss=0.0102, val_loss=0.0129] Epoch 9:  89%|████████▉ | 25/28 [00:00<00:00, 95.01it/s, train_loss=0.0102, val_loss=0.0129]Epoch 9:  89%|████████▉ | 25/28 [00:00<00:00, 94.40it/s, train_loss=0.00862, val_loss=0.0129]Epoch 9:  93%|█████████▎| 26/28 [00:00<00:00, 94.74it/s, train_loss=0.00862, val_loss=0.0129]Epoch 9:  93%|█████████▎| 26/28 [00:00<00:00, 94.46it/s, train_loss=0.00962, val_loss=0.0129]Epoch 9:  96%|█████████▋| 27/28 [00:00<00:00, 95.20it/s, train_loss=0.00962, val_loss=0.0129]Epoch 9:  96%|█████████▋| 27/28 [00:00<00:00, 94.59it/s, train_loss=0.0112, val_loss=0.0129] Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 95.24it/s, train_loss=0.0112, val_loss=0.0129]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 95.02it/s, train_loss=0.00817, val_loss=0.0129]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 143.99it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 162.36it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 168.25it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 171.51it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 171.80it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 173.02it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 172.83it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 173.66it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 173.15it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 173.21it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 172.61it/s][A
                                                                         [AEpoch 9: 100%|██████████| 28/28 [00:00<00:00, 76.38it/s, train_loss=0.00817, val_loss=0.00995]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 76.18it/s, train_loss=0.00817, val_loss=0.00995]Epoch 9:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00817, val_loss=0.00995]         Epoch 10:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00817, val_loss=0.00995]Epoch 10:   4%|▎         | 1/28 [00:00<00:00, 86.14it/s, train_loss=0.00817, val_loss=0.00995]Epoch 10:   4%|▎         | 1/28 [00:00<00:00, 79.60it/s, train_loss=0.00959, val_loss=0.00995]Epoch 10:   7%|▋         | 2/28 [00:00<00:00, 84.96it/s, train_loss=0.00959, val_loss=0.00995]Epoch 10:   7%|▋         | 2/28 [00:00<00:00, 81.79it/s, train_loss=0.0108, val_loss=0.00995] Epoch 10:  11%|█         | 3/28 [00:00<00:00, 87.90it/s, train_loss=0.0108, val_loss=0.00995]Epoch 10:  11%|█         | 3/28 [00:00<00:00, 83.20it/s, train_loss=0.00969, val_loss=0.00995]Epoch 10:  14%|█▍        | 4/28 [00:00<00:00, 88.21it/s, train_loss=0.00969, val_loss=0.00995]Epoch 10:  14%|█▍        | 4/28 [00:00<00:00, 85.61it/s, train_loss=0.00998, val_loss=0.00995]Epoch 10:  18%|█▊        | 5/28 [00:00<00:00, 87.93it/s, train_loss=0.00998, val_loss=0.00995]Epoch 10:  18%|█▊        | 5/28 [00:00<00:00, 86.63it/s, train_loss=0.0101, val_loss=0.00995] Epoch 10:  21%|██▏       | 6/28 [00:00<00:00, 90.52it/s, train_loss=0.0101, val_loss=0.00995]Epoch 10:  21%|██▏       | 6/28 [00:00<00:00, 88.41it/s, train_loss=0.0135, val_loss=0.00995]Epoch 10:  25%|██▌       | 7/28 [00:00<00:00, 89.55it/s, train_loss=0.0135, val_loss=0.00995]Epoch 10:  25%|██▌       | 7/28 [00:00<00:00, 88.62it/s, train_loss=0.0104, val_loss=0.00995]Epoch 10:  29%|██▊       | 8/28 [00:00<00:00, 91.85it/s, train_loss=0.0104, val_loss=0.00995]Epoch 10:  29%|██▊       | 8/28 [00:00<00:00, 90.13it/s, train_loss=0.00864, val_loss=0.00995]Epoch 10:  32%|███▏      | 9/28 [00:00<00:00, 91.54it/s, train_loss=0.00864, val_loss=0.00995]Epoch 10:  32%|███▏      | 9/28 [00:00<00:00, 90.74it/s, train_loss=0.00924, val_loss=0.00995]Epoch 10:  36%|███▌      | 10/28 [00:00<00:00, 92.95it/s, train_loss=0.00924, val_loss=0.00995]Epoch 10:  36%|███▌      | 10/28 [00:00<00:00, 91.55it/s, train_loss=0.0109, val_loss=0.00995] Epoch 10:  39%|███▉      | 11/28 [00:00<00:00, 92.57it/s, train_loss=0.0109, val_loss=0.00995]Epoch 10:  39%|███▉      | 11/28 [00:00<00:00, 91.93it/s, train_loss=0.00992, val_loss=0.00995]Epoch 10:  43%|████▎     | 12/28 [00:00<00:00, 93.76it/s, train_loss=0.00992, val_loss=0.00995]Epoch 10:  43%|████▎     | 12/28 [00:00<00:00, 92.45it/s, train_loss=0.013, val_loss=0.00995]  Epoch 10:  46%|████▋     | 13/28 [00:00<00:00, 93.17it/s, train_loss=0.013, val_loss=0.00995]Epoch 10:  46%|████▋     | 13/28 [00:00<00:00, 92.71it/s, train_loss=0.00808, val_loss=0.00995]Epoch 10:  50%|█████     | 14/28 [00:00<00:00, 94.23it/s, train_loss=0.00808, val_loss=0.00995]Epoch 10:  50%|█████     | 14/28 [00:00<00:00, 93.10it/s, train_loss=0.0114, val_loss=0.00995] Epoch 10:  54%|█████▎    | 15/28 [00:00<00:00, 93.68it/s, train_loss=0.0114, val_loss=0.00995]Epoch 10:  54%|█████▎    | 15/28 [00:00<00:00, 93.28it/s, train_loss=0.0101, val_loss=0.00995]Epoch 10:  57%|█████▋    | 16/28 [00:00<00:00, 94.55it/s, train_loss=0.0101, val_loss=0.00995]Epoch 10:  57%|█████▋    | 16/28 [00:00<00:00, 93.59it/s, train_loss=0.00946, val_loss=0.00995]Epoch 10:  61%|██████    | 17/28 [00:00<00:00, 93.99it/s, train_loss=0.00946, val_loss=0.00995]Epoch 10:  61%|██████    | 17/28 [00:00<00:00, 93.57it/s, train_loss=0.0118, val_loss=0.00995] Epoch 10:  64%|██████▍   | 18/28 [00:00<00:00, 94.66it/s, train_loss=0.0118, val_loss=0.00995]Epoch 10:  64%|██████▍   | 18/28 [00:00<00:00, 93.86it/s, train_loss=0.0104, val_loss=0.00995]Epoch 10:  68%|██████▊   | 19/28 [00:00<00:00, 94.13it/s, train_loss=0.0104, val_loss=0.00995]Epoch 10:  68%|██████▊   | 19/28 [00:00<00:00, 93.75it/s, train_loss=0.00957, val_loss=0.00995]Epoch 10:  71%|███████▏  | 20/28 [00:00<00:00, 94.75it/s, train_loss=0.00957, val_loss=0.00995]Epoch 10:  71%|███████▏  | 20/28 [00:00<00:00, 94.05it/s, train_loss=0.00685, val_loss=0.00995]Epoch 10:  75%|███████▌  | 21/28 [00:00<00:00, 94.31it/s, train_loss=0.00685, val_loss=0.00995]Epoch 10:  75%|███████▌  | 21/28 [00:00<00:00, 93.92it/s, train_loss=0.00781, val_loss=0.00995]Epoch 10:  79%|███████▊  | 22/28 [00:00<00:00, 94.84it/s, train_loss=0.00781, val_loss=0.00995]Epoch 10:  79%|███████▊  | 22/28 [00:00<00:00, 94.17it/s, train_loss=0.00759, val_loss=0.00995]Epoch 10:  82%|████████▏ | 23/28 [00:00<00:00, 94.39it/s, train_loss=0.00759, val_loss=0.00995]Epoch 10:  82%|████████▏ | 23/28 [00:00<00:00, 94.02it/s, train_loss=0.00647, val_loss=0.00995]Epoch 10:  86%|████████▌ | 24/28 [00:00<00:00, 94.92it/s, train_loss=0.00647, val_loss=0.00995]Epoch 10:  86%|████████▌ | 24/28 [00:00<00:00, 94.30it/s, train_loss=0.00923, val_loss=0.00995]Epoch 10:  89%|████████▉ | 25/28 [00:00<00:00, 94.58it/s, train_loss=0.00923, val_loss=0.00995]Epoch 10:  89%|████████▉ | 25/28 [00:00<00:00, 94.26it/s, train_loss=0.00859, val_loss=0.00995]Epoch 10:  93%|█████████▎| 26/28 [00:00<00:00, 94.96it/s, train_loss=0.00859, val_loss=0.00995]Epoch 10:  93%|█████████▎| 26/28 [00:00<00:00, 94.38it/s, train_loss=0.0141, val_loss=0.00995] Epoch 10:  96%|█████████▋| 27/28 [00:00<00:00, 94.76it/s, train_loss=0.0141, val_loss=0.00995]Epoch 10:  96%|█████████▋| 27/28 [00:00<00:00, 94.49it/s, train_loss=0.00941, val_loss=0.00995]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 95.56it/s, train_loss=0.00941, val_loss=0.00995]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 95.36it/s, train_loss=0.00274, val_loss=0.00995]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 159.70it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 178.00it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 181.83it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 185.23it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 185.38it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 187.02it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 186.48it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 187.35it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 186.88it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 185.60it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 182.68it/s][A
                                                                         [AEpoch 10: 100%|██████████| 28/28 [00:00<00:00, 77.71it/s, train_loss=0.00274, val_loss=0.00892]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 77.52it/s, train_loss=0.00274, val_loss=0.00892]Epoch 10:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00274, val_loss=0.00892]         Epoch 11:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00274, val_loss=0.00892]Epoch 11:   4%|▎         | 1/28 [00:00<00:00, 87.17it/s, train_loss=0.00274, val_loss=0.00892]Epoch 11:   4%|▎         | 1/28 [00:00<00:00, 81.30it/s, train_loss=0.00676, val_loss=0.00892]Epoch 11:   7%|▋         | 2/28 [00:00<00:00, 87.29it/s, train_loss=0.00676, val_loss=0.00892]Epoch 11:   7%|▋         | 2/28 [00:00<00:00, 84.39it/s, train_loss=0.00798, val_loss=0.00892]Epoch 11:  11%|█         | 3/28 [00:00<00:00, 91.81it/s, train_loss=0.00798, val_loss=0.00892]Epoch 11:  11%|█         | 3/28 [00:00<00:00, 87.88it/s, train_loss=0.00835, val_loss=0.00892]Epoch 11:  14%|█▍        | 4/28 [00:00<00:00, 89.52it/s, train_loss=0.00835, val_loss=0.00892]Epoch 11:  14%|█▍        | 4/28 [00:00<00:00, 87.80it/s, train_loss=0.00956, val_loss=0.00892]Epoch 11:  18%|█▊        | 5/28 [00:00<00:00, 92.05it/s, train_loss=0.00956, val_loss=0.00892]Epoch 11:  18%|█▊        | 5/28 [00:00<00:00, 89.53it/s, train_loss=0.0106, val_loss=0.00892] Epoch 11:  21%|██▏       | 6/28 [00:00<00:00, 90.48it/s, train_loss=0.0106, val_loss=0.00892]Epoch 11:  21%|██▏       | 6/28 [00:00<00:00, 89.32it/s, train_loss=0.0112, val_loss=0.00892]Epoch 11:  25%|██▌       | 7/28 [00:00<00:00, 92.47it/s, train_loss=0.0112, val_loss=0.00892]Epoch 11:  25%|██▌       | 7/28 [00:00<00:00, 90.57it/s, train_loss=0.0116, val_loss=0.00892]Epoch 11:  29%|██▊       | 8/28 [00:00<00:00, 91.18it/s, train_loss=0.0116, val_loss=0.00892]Epoch 11:  29%|██▊       | 8/28 [00:00<00:00, 90.28it/s, train_loss=0.00992, val_loss=0.00892]Epoch 11:  32%|███▏      | 9/28 [00:00<00:00, 92.49it/s, train_loss=0.00992, val_loss=0.00892]Epoch 11:  32%|███▏      | 9/28 [00:00<00:00, 90.95it/s, train_loss=0.00894, val_loss=0.00892]Epoch 11:  36%|███▌      | 10/28 [00:00<00:00, 91.22it/s, train_loss=0.00894, val_loss=0.00892]Epoch 11:  36%|███▌      | 10/28 [00:00<00:00, 90.62it/s, train_loss=0.00733, val_loss=0.00892]Epoch 11:  39%|███▉      | 11/28 [00:00<00:00, 92.41it/s, train_loss=0.00733, val_loss=0.00892]Epoch 11:  39%|███▉      | 11/28 [00:00<00:00, 91.34it/s, train_loss=0.00778, val_loss=0.00892]Epoch 11:  43%|████▎     | 12/28 [00:00<00:00, 91.91it/s, train_loss=0.00778, val_loss=0.00892]Epoch 11:  43%|████▎     | 12/28 [00:00<00:00, 91.40it/s, train_loss=0.00849, val_loss=0.00892]Epoch 11:  46%|████▋     | 13/28 [00:00<00:00, 93.13it/s, train_loss=0.00849, val_loss=0.00892]Epoch 11:  46%|████▋     | 13/28 [00:00<00:00, 92.10it/s, train_loss=0.00717, val_loss=0.00892]Epoch 11:  50%|█████     | 14/28 [00:00<00:00, 92.46it/s, train_loss=0.00717, val_loss=0.00892]Epoch 11:  50%|█████     | 14/28 [00:00<00:00, 92.01it/s, train_loss=0.0123, val_loss=0.00892] Epoch 11:  54%|█████▎    | 15/28 [00:00<00:00, 93.35it/s, train_loss=0.0123, val_loss=0.00892]Epoch 11:  54%|█████▎    | 15/28 [00:00<00:00, 92.41it/s, train_loss=0.00813, val_loss=0.00892]Epoch 11:  57%|█████▋    | 16/28 [00:00<00:00, 92.90it/s, train_loss=0.00813, val_loss=0.00892]Epoch 11:  57%|█████▋    | 16/28 [00:00<00:00, 92.39it/s, train_loss=0.00629, val_loss=0.00892]Epoch 11:  61%|██████    | 17/28 [00:00<00:00, 93.67it/s, train_loss=0.00629, val_loss=0.00892]Epoch 11:  61%|██████    | 17/28 [00:00<00:00, 92.82it/s, train_loss=0.00888, val_loss=0.00892]Epoch 11:  64%|██████▍   | 18/28 [00:00<00:00, 93.13it/s, train_loss=0.00888, val_loss=0.00892]Epoch 11:  64%|██████▍   | 18/28 [00:00<00:00, 92.72it/s, train_loss=0.0105, val_loss=0.00892] Epoch 11:  68%|██████▊   | 19/28 [00:00<00:00, 93.82it/s, train_loss=0.0105, val_loss=0.00892]Epoch 11:  68%|██████▊   | 19/28 [00:00<00:00, 93.07it/s, train_loss=0.0122, val_loss=0.00892]Epoch 11:  71%|███████▏  | 20/28 [00:00<00:00, 93.39it/s, train_loss=0.0122, val_loss=0.00892]Epoch 11:  71%|███████▏  | 20/28 [00:00<00:00, 92.97it/s, train_loss=0.00879, val_loss=0.00892]Epoch 11:  75%|███████▌  | 21/28 [00:00<00:00, 93.94it/s, train_loss=0.00879, val_loss=0.00892]Epoch 11:  75%|███████▌  | 21/28 [00:00<00:00, 93.25it/s, train_loss=0.0098, val_loss=0.00892] Epoch 11:  79%|███████▊  | 22/28 [00:00<00:00, 93.50it/s, train_loss=0.0098, val_loss=0.00892]Epoch 11:  79%|███████▊  | 22/28 [00:00<00:00, 93.16it/s, train_loss=0.00691, val_loss=0.00892]Epoch 11:  82%|████████▏ | 23/28 [00:00<00:00, 93.98it/s, train_loss=0.00691, val_loss=0.00892]Epoch 11:  82%|████████▏ | 23/28 [00:00<00:00, 93.38it/s, train_loss=0.00905, val_loss=0.00892]Epoch 11:  86%|████████▌ | 24/28 [00:00<00:00, 93.55it/s, train_loss=0.00905, val_loss=0.00892]Epoch 11:  86%|████████▌ | 24/28 [00:00<00:00, 93.21it/s, train_loss=0.00974, val_loss=0.00892]Epoch 11:  89%|████████▉ | 25/28 [00:00<00:00, 94.06it/s, train_loss=0.00974, val_loss=0.00892]Epoch 11:  89%|████████▉ | 25/28 [00:00<00:00, 93.45it/s, train_loss=0.00973, val_loss=0.00892]Epoch 11:  93%|█████████▎| 26/28 [00:00<00:00, 93.72it/s, train_loss=0.00973, val_loss=0.00892]Epoch 11:  93%|█████████▎| 26/28 [00:00<00:00, 93.43it/s, train_loss=0.00744, val_loss=0.00892]Epoch 11:  96%|█████████▋| 27/28 [00:00<00:00, 94.17it/s, train_loss=0.00744, val_loss=0.00892]Epoch 11:  96%|█████████▋| 27/28 [00:00<00:00, 93.62it/s, train_loss=0.00828, val_loss=0.00892]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 94.15it/s, train_loss=0.00828, val_loss=0.00892]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 93.85it/s, train_loss=0.00433, val_loss=0.00892]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 191.21it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 193.40it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 197.62it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 200.05it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 196.22it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 196.52it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 195.31it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 194.71it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 193.45it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 193.20it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 192.53it/s][A
                                                                         [AEpoch 11: 100%|██████████| 28/28 [00:00<00:00, 77.53it/s, train_loss=0.00433, val_loss=0.00789]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 77.36it/s, train_loss=0.00433, val_loss=0.00789]Epoch 11:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00433, val_loss=0.00789]         Epoch 12:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00433, val_loss=0.00789]Epoch 12:   4%|▎         | 1/28 [00:00<00:00, 88.50it/s, train_loss=0.00433, val_loss=0.00789]Epoch 12:   4%|▎         | 1/28 [00:00<00:00, 82.65it/s, train_loss=0.00871, val_loss=0.00789]Epoch 12:   7%|▋         | 2/28 [00:00<00:00, 88.49it/s, train_loss=0.00871, val_loss=0.00789]Epoch 12:   7%|▋         | 2/28 [00:00<00:00, 85.70it/s, train_loss=0.00687, val_loss=0.00789]Epoch 12:  11%|█         | 3/28 [00:00<00:00, 92.24it/s, train_loss=0.00687, val_loss=0.00789]Epoch 12:  11%|█         | 3/28 [00:00<00:00, 88.42it/s, train_loss=0.00812, val_loss=0.00789]Epoch 12:  14%|█▍        | 4/28 [00:00<00:00, 90.06it/s, train_loss=0.00812, val_loss=0.00789]Epoch 12:  14%|█▍        | 4/28 [00:00<00:00, 88.42it/s, train_loss=0.00741, val_loss=0.00789]Epoch 12:  18%|█▊        | 5/28 [00:00<00:00, 92.73it/s, train_loss=0.00741, val_loss=0.00789]Epoch 12:  18%|█▊        | 5/28 [00:00<00:00, 88.06it/s, train_loss=0.00905, val_loss=0.00789]Epoch 12:  21%|██▏       | 6/28 [00:00<00:00, 89.85it/s, train_loss=0.00905, val_loss=0.00789]Epoch 12:  21%|██▏       | 6/28 [00:00<00:00, 88.66it/s, train_loss=0.0105, val_loss=0.00789] Epoch 12:  25%|██▌       | 7/28 [00:00<00:00, 89.80it/s, train_loss=0.0105, val_loss=0.00789]Epoch 12:  25%|██▌       | 7/28 [00:00<00:00, 88.84it/s, train_loss=0.00892, val_loss=0.00789]Epoch 12:  29%|██▊       | 8/28 [00:00<00:00, 91.36it/s, train_loss=0.00892, val_loss=0.00789]Epoch 12:  29%|██▊       | 8/28 [00:00<00:00, 89.77it/s, train_loss=0.00738, val_loss=0.00789]Epoch 12:  32%|███▏      | 9/28 [00:00<00:00, 90.38it/s, train_loss=0.00738, val_loss=0.00789]Epoch 12:  32%|███▏      | 9/28 [00:00<00:00, 89.57it/s, train_loss=0.00665, val_loss=0.00789]Epoch 12:  36%|███▌      | 10/28 [00:00<00:00, 91.70it/s, train_loss=0.00665, val_loss=0.00789]Epoch 12:  36%|███▌      | 10/28 [00:00<00:00, 90.38it/s, train_loss=0.0086, val_loss=0.00789] Epoch 12:  39%|███▉      | 11/28 [00:00<00:00, 90.79it/s, train_loss=0.0086, val_loss=0.00789]Epoch 12:  39%|███▉      | 11/28 [00:00<00:00, 90.14it/s, train_loss=0.00823, val_loss=0.00789]Epoch 12:  43%|████▎     | 12/28 [00:00<00:00, 92.01it/s, train_loss=0.00823, val_loss=0.00789]Epoch 12:  43%|████▎     | 12/28 [00:00<00:00, 90.77it/s, train_loss=0.00906, val_loss=0.00789]Epoch 12:  46%|████▋     | 13/28 [00:00<00:00, 91.38it/s, train_loss=0.00906, val_loss=0.00789]Epoch 12:  46%|████▋     | 13/28 [00:00<00:00, 90.87it/s, train_loss=0.00822, val_loss=0.00789]Epoch 12:  50%|█████     | 14/28 [00:00<00:00, 92.62it/s, train_loss=0.00822, val_loss=0.00789]Epoch 12:  50%|█████     | 14/28 [00:00<00:00, 91.54it/s, train_loss=0.00758, val_loss=0.00789]Epoch 12:  54%|█████▎    | 15/28 [00:00<00:00, 92.19it/s, train_loss=0.00758, val_loss=0.00789]Epoch 12:  54%|█████▎    | 15/28 [00:00<00:00, 91.72it/s, train_loss=0.00828, val_loss=0.00789]Epoch 12:  57%|█████▋    | 16/28 [00:00<00:00, 93.06it/s, train_loss=0.00828, val_loss=0.00789]Epoch 12:  57%|█████▋    | 16/28 [00:00<00:00, 92.14it/s, train_loss=0.00758, val_loss=0.00789]Epoch 12:  61%|██████    | 17/28 [00:00<00:00, 92.65it/s, train_loss=0.00758, val_loss=0.00789]Epoch 12:  61%|██████    | 17/28 [00:00<00:00, 92.15it/s, train_loss=0.00759, val_loss=0.00789]Epoch 12:  64%|██████▍   | 18/28 [00:00<00:00, 93.35it/s, train_loss=0.00759, val_loss=0.00789]Epoch 12:  64%|██████▍   | 18/28 [00:00<00:00, 92.58it/s, train_loss=0.00656, val_loss=0.00789]Epoch 12:  68%|██████▊   | 19/28 [00:00<00:00, 92.96it/s, train_loss=0.00656, val_loss=0.00789]Epoch 12:  68%|██████▊   | 19/28 [00:00<00:00, 92.55it/s, train_loss=0.00879, val_loss=0.00789]Epoch 12:  71%|███████▏  | 20/28 [00:00<00:00, 93.42it/s, train_loss=0.00879, val_loss=0.00789]Epoch 12:  71%|███████▏  | 20/28 [00:00<00:00, 92.73it/s, train_loss=0.008, val_loss=0.00789]  Epoch 12:  75%|███████▌  | 21/28 [00:00<00:00, 93.00it/s, train_loss=0.008, val_loss=0.00789]Epoch 12:  75%|███████▌  | 21/28 [00:00<00:00, 92.62it/s, train_loss=0.0075, val_loss=0.00789]Epoch 12:  79%|███████▊  | 22/28 [00:00<00:00, 93.58it/s, train_loss=0.0075, val_loss=0.00789]Epoch 12:  79%|███████▊  | 22/28 [00:00<00:00, 92.90it/s, train_loss=0.010, val_loss=0.00789] Epoch 12:  82%|████████▏ | 23/28 [00:00<00:00, 93.17it/s, train_loss=0.010, val_loss=0.00789]Epoch 12:  82%|████████▏ | 23/28 [00:00<00:00, 92.78it/s, train_loss=0.00734, val_loss=0.00789]Epoch 12:  86%|████████▌ | 24/28 [00:00<00:00, 93.61it/s, train_loss=0.00734, val_loss=0.00789]Epoch 12:  86%|████████▌ | 24/28 [00:00<00:00, 93.03it/s, train_loss=0.00922, val_loss=0.00789]Epoch 12:  89%|████████▉ | 25/28 [00:00<00:00, 92.92it/s, train_loss=0.00922, val_loss=0.00789]Epoch 12:  89%|████████▉ | 25/28 [00:00<00:00, 92.62it/s, train_loss=0.00816, val_loss=0.00789]Epoch 12:  93%|█████████▎| 26/28 [00:00<00:00, 93.43it/s, train_loss=0.00816, val_loss=0.00789]Epoch 12:  93%|█████████▎| 26/28 [00:00<00:00, 92.88it/s, train_loss=0.00694, val_loss=0.00789]Epoch 12:  96%|█████████▋| 27/28 [00:00<00:00, 93.10it/s, train_loss=0.00694, val_loss=0.00789]Epoch 12:  96%|█████████▋| 27/28 [00:00<00:00, 92.77it/s, train_loss=0.00715, val_loss=0.00789]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 93.59it/s, train_loss=0.00715, val_loss=0.00789]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 93.32it/s, train_loss=0.00345, val_loss=0.00789]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 123.09it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 137.24it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 145.57it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 146.61it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 149.75it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 156.49it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 162.47it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 165.82it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 169.76it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 173.23it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 174.62it/s][A
                                                                         [AEpoch 12: 100%|██████████| 28/28 [00:00<00:00, 75.71it/s, train_loss=0.00345, val_loss=0.00715]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 75.57it/s, train_loss=0.00345, val_loss=0.00715]Epoch 12:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00345, val_loss=0.00715]         Epoch 13:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00345, val_loss=0.00715]Epoch 13:   4%|▎         | 1/28 [00:00<00:00, 90.34it/s, train_loss=0.00345, val_loss=0.00715]Epoch 13:   4%|▎         | 1/28 [00:00<00:00, 84.82it/s, train_loss=0.00798, val_loss=0.00715]Epoch 13:   7%|▋         | 2/28 [00:00<00:00, 90.35it/s, train_loss=0.00798, val_loss=0.00715]Epoch 13:   7%|▋         | 2/28 [00:00<00:00, 87.50it/s, train_loss=0.0065, val_loss=0.00715] Epoch 13:  11%|█         | 3/28 [00:00<00:00, 94.23it/s, train_loss=0.0065, val_loss=0.00715]Epoch 13:  11%|█         | 3/28 [00:00<00:00, 89.74it/s, train_loss=0.00625, val_loss=0.00715]Epoch 13:  14%|█▍        | 4/28 [00:00<00:00, 91.17it/s, train_loss=0.00625, val_loss=0.00715]Epoch 13:  14%|█▍        | 4/28 [00:00<00:00, 89.57it/s, train_loss=0.00788, val_loss=0.00715]Epoch 13:  18%|█▊        | 5/28 [00:00<00:00, 93.71it/s, train_loss=0.00788, val_loss=0.00715]Epoch 13:  18%|█▊        | 5/28 [00:00<00:00, 90.95it/s, train_loss=0.0082, val_loss=0.00715] Epoch 13:  21%|██▏       | 6/28 [00:00<00:00, 92.13it/s, train_loss=0.0082, val_loss=0.00715]Epoch 13:  21%|██▏       | 6/28 [00:00<00:00, 91.07it/s, train_loss=0.00662, val_loss=0.00715]Epoch 13:  25%|██▌       | 7/28 [00:00<00:00, 94.13it/s, train_loss=0.00662, val_loss=0.00715]Epoch 13:  25%|██▌       | 7/28 [00:00<00:00, 92.03it/s, train_loss=0.010, val_loss=0.00715]  Epoch 13:  29%|██▊       | 8/28 [00:00<00:00, 92.94it/s, train_loss=0.010, val_loss=0.00715]Epoch 13:  29%|██▊       | 8/28 [00:00<00:00, 91.88it/s, train_loss=0.0064, val_loss=0.00715]Epoch 13:  32%|███▏      | 9/28 [00:00<00:00, 94.20it/s, train_loss=0.0064, val_loss=0.00715]Epoch 13:  32%|███▏      | 9/28 [00:00<00:00, 92.43it/s, train_loss=0.00687, val_loss=0.00715]Epoch 13:  36%|███▌      | 10/28 [00:00<00:00, 92.95it/s, train_loss=0.00687, val_loss=0.00715]Epoch 13:  36%|███▌      | 10/28 [00:00<00:00, 92.19it/s, train_loss=0.00752, val_loss=0.00715]Epoch 13:  39%|███▉      | 11/28 [00:00<00:00, 94.02it/s, train_loss=0.00752, val_loss=0.00715]Epoch 13:  39%|███▉      | 11/28 [00:00<00:00, 92.71it/s, train_loss=0.00788, val_loss=0.00715]Epoch 13:  43%|████▎     | 12/28 [00:00<00:00, 93.13it/s, train_loss=0.00788, val_loss=0.00715]Epoch 13:  43%|████▎     | 12/28 [00:00<00:00, 92.50it/s, train_loss=0.00891, val_loss=0.00715]Epoch 13:  46%|████▋     | 13/28 [00:00<00:00, 93.97it/s, train_loss=0.00891, val_loss=0.00715]Epoch 13:  46%|████▋     | 13/28 [00:00<00:00, 92.87it/s, train_loss=0.00821, val_loss=0.00715]Epoch 13:  50%|█████     | 14/28 [00:00<00:00, 93.23it/s, train_loss=0.00821, val_loss=0.00715]Epoch 13:  50%|█████     | 14/28 [00:00<00:00, 92.60it/s, train_loss=0.00691, val_loss=0.00715]Epoch 13:  54%|█████▎    | 15/28 [00:00<00:00, 93.96it/s, train_loss=0.00691, val_loss=0.00715]Epoch 13:  54%|█████▎    | 15/28 [00:00<00:00, 92.92it/s, train_loss=0.0068, val_loss=0.00715] Epoch 13:  57%|█████▋    | 16/28 [00:00<00:00, 93.57it/s, train_loss=0.0068, val_loss=0.00715]Epoch 13:  57%|█████▋    | 16/28 [00:00<00:00, 93.00it/s, train_loss=0.00587, val_loss=0.00715]Epoch 13:  61%|██████    | 17/28 [00:00<00:00, 94.32it/s, train_loss=0.00587, val_loss=0.00715]Epoch 13:  61%|██████    | 17/28 [00:00<00:00, 93.38it/s, train_loss=0.00744, val_loss=0.00715]Epoch 13:  64%|██████▍   | 18/28 [00:00<00:00, 93.84it/s, train_loss=0.00744, val_loss=0.00715]Epoch 13:  64%|██████▍   | 18/28 [00:00<00:00, 93.36it/s, train_loss=0.00704, val_loss=0.00715]Epoch 13:  68%|██████▊   | 19/28 [00:00<00:00, 94.31it/s, train_loss=0.00704, val_loss=0.00715]Epoch 13:  68%|██████▊   | 19/28 [00:00<00:00, 93.46it/s, train_loss=0.00879, val_loss=0.00715]Epoch 13:  71%|███████▏  | 20/28 [00:00<00:00, 93.76it/s, train_loss=0.00879, val_loss=0.00715]Epoch 13:  71%|███████▏  | 20/28 [00:00<00:00, 93.33it/s, train_loss=0.0082, val_loss=0.00715] Epoch 13:  75%|███████▌  | 21/28 [00:00<00:00, 94.20it/s, train_loss=0.0082, val_loss=0.00715]Epoch 13:  75%|███████▌  | 21/28 [00:00<00:00, 93.42it/s, train_loss=0.00702, val_loss=0.00715]Epoch 13:  79%|███████▊  | 22/28 [00:00<00:00, 93.67it/s, train_loss=0.00702, val_loss=0.00715]Epoch 13:  79%|███████▊  | 22/28 [00:00<00:00, 93.27it/s, train_loss=0.00619, val_loss=0.00715]Epoch 13:  82%|████████▏ | 23/28 [00:00<00:00, 94.16it/s, train_loss=0.00619, val_loss=0.00715]Epoch 13:  82%|████████▏ | 23/28 [00:00<00:00, 93.50it/s, train_loss=0.00783, val_loss=0.00715]Epoch 13:  86%|████████▌ | 24/28 [00:00<00:00, 93.55it/s, train_loss=0.00783, val_loss=0.00715]Epoch 13:  86%|████████▌ | 24/28 [00:00<00:00, 93.18it/s, train_loss=0.00913, val_loss=0.00715]Epoch 13:  89%|████████▉ | 25/28 [00:00<00:00, 94.02it/s, train_loss=0.00913, val_loss=0.00715]Epoch 13:  89%|████████▉ | 25/28 [00:00<00:00, 93.39it/s, train_loss=0.00765, val_loss=0.00715]Epoch 13:  93%|█████████▎| 26/28 [00:00<00:00, 93.62it/s, train_loss=0.00765, val_loss=0.00715]Epoch 13:  93%|█████████▎| 26/28 [00:00<00:00, 93.26it/s, train_loss=0.00625, val_loss=0.00715]Epoch 13:  96%|█████████▋| 27/28 [00:00<00:00, 94.06it/s, train_loss=0.00625, val_loss=0.00715]Epoch 13:  96%|█████████▋| 27/28 [00:00<00:00, 93.45it/s, train_loss=0.00707, val_loss=0.00715]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 93.99it/s, train_loss=0.00707, val_loss=0.00715]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 93.72it/s, train_loss=0.00189, val_loss=0.00715]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 122.07it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 141.36it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 146.36it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 151.91it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 153.30it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 155.55it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 156.00it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 157.38it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 157.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 157.96it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 160.19it/s][A
                                                                         [AEpoch 13: 100%|██████████| 28/28 [00:00<00:00, 74.98it/s, train_loss=0.00189, val_loss=0.00658]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 74.86it/s, train_loss=0.00189, val_loss=0.00658]Epoch 13:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00189, val_loss=0.00658]         Epoch 14:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00189, val_loss=0.00658]Epoch 14:   4%|▎         | 1/28 [00:00<00:00, 90.61it/s, train_loss=0.00189, val_loss=0.00658]Epoch 14:   4%|▎         | 1/28 [00:00<00:00, 85.79it/s, train_loss=0.0071, val_loss=0.00658] Epoch 14:   7%|▋         | 2/28 [00:00<00:00, 94.66it/s, train_loss=0.0071, val_loss=0.00658]Epoch 14:   7%|▋         | 2/28 [00:00<00:00, 86.78it/s, train_loss=0.00872, val_loss=0.00658]Epoch 14:  11%|█         | 3/28 [00:00<00:00, 92.03it/s, train_loss=0.00872, val_loss=0.00658]Epoch 14:  11%|█         | 3/28 [00:00<00:00, 88.31it/s, train_loss=0.00904, val_loss=0.00658]Epoch 14:  14%|█▍        | 4/28 [00:00<00:00, 90.43it/s, train_loss=0.00904, val_loss=0.00658]Epoch 14:  14%|█▍        | 4/28 [00:00<00:00, 88.91it/s, train_loss=0.00854, val_loss=0.00658]Epoch 14:  18%|█▊        | 5/28 [00:00<00:00, 93.29it/s, train_loss=0.00854, val_loss=0.00658]Epoch 14:  18%|█▊        | 5/28 [00:00<00:00, 90.37it/s, train_loss=0.00856, val_loss=0.00658]Epoch 14:  21%|██▏       | 6/28 [00:00<00:00, 91.49it/s, train_loss=0.00856, val_loss=0.00658]Epoch 14:  21%|██▏       | 6/28 [00:00<00:00, 90.32it/s, train_loss=0.00574, val_loss=0.00658]Epoch 14:  25%|██▌       | 7/28 [00:00<00:00, 93.40it/s, train_loss=0.00574, val_loss=0.00658]Epoch 14:  25%|██▌       | 7/28 [00:00<00:00, 91.10it/s, train_loss=0.00823, val_loss=0.00658]Epoch 14:  29%|██▊       | 8/28 [00:00<00:00, 91.95it/s, train_loss=0.00823, val_loss=0.00658]Epoch 14:  29%|██▊       | 8/28 [00:00<00:00, 90.96it/s, train_loss=0.00838, val_loss=0.00658]Epoch 14:  32%|███▏      | 9/28 [00:00<00:00, 93.33it/s, train_loss=0.00838, val_loss=0.00658]Epoch 14:  32%|███▏      | 9/28 [00:00<00:00, 91.68it/s, train_loss=0.00656, val_loss=0.00658]Epoch 14:  36%|███▌      | 10/28 [00:00<00:00, 92.20it/s, train_loss=0.00656, val_loss=0.00658]Epoch 14:  36%|███▌      | 10/28 [00:00<00:00, 91.50it/s, train_loss=0.00628, val_loss=0.00658]Epoch 14:  39%|███▉      | 11/28 [00:00<00:00, 93.41it/s, train_loss=0.00628, val_loss=0.00658]Epoch 14:  39%|███▉      | 11/28 [00:00<00:00, 92.05it/s, train_loss=0.00452, val_loss=0.00658]Epoch 14:  43%|████▎     | 12/28 [00:00<00:00, 92.74it/s, train_loss=0.00452, val_loss=0.00658]Epoch 14:  43%|████▎     | 12/28 [00:00<00:00, 92.08it/s, train_loss=0.00647, val_loss=0.00658]Epoch 14:  46%|████▋     | 13/28 [00:00<00:00, 93.70it/s, train_loss=0.00647, val_loss=0.00658]Epoch 14:  46%|████▋     | 13/28 [00:00<00:00, 92.53it/s, train_loss=0.00824, val_loss=0.00658]Epoch 14:  50%|█████     | 14/28 [00:00<00:00, 92.95it/s, train_loss=0.00824, val_loss=0.00658]Epoch 14:  50%|█████     | 14/28 [00:00<00:00, 92.34it/s, train_loss=0.00785, val_loss=0.00658]Epoch 14:  54%|█████▎    | 15/28 [00:00<00:00, 93.63it/s, train_loss=0.00785, val_loss=0.00658]Epoch 14:  54%|█████▎    | 15/28 [00:00<00:00, 92.63it/s, train_loss=0.00583, val_loss=0.00658]Epoch 14:  57%|█████▋    | 16/28 [00:00<00:00, 92.98it/s, train_loss=0.00583, val_loss=0.00658]Epoch 14:  57%|█████▋    | 16/28 [00:00<00:00, 92.42it/s, train_loss=0.00702, val_loss=0.00658]Epoch 14:  61%|██████    | 17/28 [00:00<00:00, 93.67it/s, train_loss=0.00702, val_loss=0.00658]Epoch 14:  61%|██████    | 17/28 [00:00<00:00, 92.74it/s, train_loss=0.0076, val_loss=0.00658] Epoch 14:  64%|██████▍   | 18/28 [00:00<00:00, 92.97it/s, train_loss=0.0076, val_loss=0.00658]Epoch 14:  64%|██████▍   | 18/28 [00:00<00:00, 92.50it/s, train_loss=0.00553, val_loss=0.00658]Epoch 14:  68%|██████▊   | 19/28 [00:00<00:00, 93.83it/s, train_loss=0.00553, val_loss=0.00658]Epoch 14:  68%|██████▊   | 19/28 [00:00<00:00, 92.99it/s, train_loss=0.00696, val_loss=0.00658]Epoch 14:  71%|███████▏  | 20/28 [00:00<00:00, 93.44it/s, train_loss=0.00696, val_loss=0.00658]Epoch 14:  71%|███████▏  | 20/28 [00:00<00:00, 93.04it/s, train_loss=0.00662, val_loss=0.00658]Epoch 14:  75%|███████▌  | 21/28 [00:00<00:00, 93.99it/s, train_loss=0.00662, val_loss=0.00658]Epoch 14:  75%|███████▌  | 21/28 [00:00<00:00, 93.25it/s, train_loss=0.00658, val_loss=0.00658]Epoch 14:  79%|███████▊  | 22/28 [00:00<00:00, 93.66it/s, train_loss=0.00658, val_loss=0.00658]Epoch 14:  79%|███████▊  | 22/28 [00:00<00:00, 93.30it/s, train_loss=0.00765, val_loss=0.00658]Epoch 14:  82%|████████▏ | 23/28 [00:00<00:00, 89.12it/s, train_loss=0.00765, val_loss=0.00658]Epoch 14:  82%|████████▏ | 23/28 [00:00<00:00, 88.81it/s, train_loss=0.00667, val_loss=0.00658]Epoch 14:  86%|████████▌ | 24/28 [00:00<00:00, 89.18it/s, train_loss=0.00667, val_loss=0.00658]Epoch 14:  86%|████████▌ | 24/28 [00:00<00:00, 88.90it/s, train_loss=0.0077, val_loss=0.00658] Epoch 14:  89%|████████▉ | 25/28 [00:00<00:00, 89.73it/s, train_loss=0.0077, val_loss=0.00658]Epoch 14:  89%|████████▉ | 25/28 [00:00<00:00, 89.18it/s, train_loss=0.00555, val_loss=0.00658]Epoch 14:  93%|█████████▎| 26/28 [00:00<00:00, 89.51it/s, train_loss=0.00555, val_loss=0.00658]Epoch 14:  93%|█████████▎| 26/28 [00:00<00:00, 89.21it/s, train_loss=0.00628, val_loss=0.00658]Epoch 14:  96%|█████████▋| 27/28 [00:00<00:00, 90.08it/s, train_loss=0.00628, val_loss=0.00658]Epoch 14:  96%|█████████▋| 27/28 [00:00<00:00, 89.55it/s, train_loss=0.00699, val_loss=0.00658]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 90.22it/s, train_loss=0.00699, val_loss=0.00658]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 89.99it/s, train_loss=0.00326, val_loss=0.00658]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 127.51it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 147.49it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 151.13it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 156.18it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 157.39it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 159.82it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 159.92it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 161.11it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 160.28it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 161.01it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 160.97it/s][A
                                                                         [AEpoch 14: 100%|██████████| 28/28 [00:00<00:00, 72.20it/s, train_loss=0.00326, val_loss=0.00621]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 71.99it/s, train_loss=0.00326, val_loss=0.00621]Epoch 14:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00326, val_loss=0.00621]         Epoch 15:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00326, val_loss=0.00621]Epoch 15:   4%|▎         | 1/28 [00:00<00:00, 68.96it/s, train_loss=0.00326, val_loss=0.00621]Epoch 15:   4%|▎         | 1/28 [00:00<00:00, 65.96it/s, train_loss=0.00667, val_loss=0.00621]Epoch 15:   7%|▋         | 2/28 [00:00<00:00, 84.66it/s, train_loss=0.00667, val_loss=0.00621]Epoch 15:   7%|▋         | 2/28 [00:00<00:00, 79.52it/s, train_loss=0.00806, val_loss=0.00621]Epoch 15:  11%|█         | 3/28 [00:00<00:00, 82.82it/s, train_loss=0.00806, val_loss=0.00621]Epoch 15:  11%|█         | 3/28 [00:00<00:00, 81.11it/s, train_loss=0.00596, val_loss=0.00621]Epoch 15:  14%|█▍        | 4/28 [00:00<00:00, 87.67it/s, train_loss=0.00596, val_loss=0.00621]Epoch 15:  14%|█▍        | 4/28 [00:00<00:00, 84.65it/s, train_loss=0.00567, val_loss=0.00621]Epoch 15:  18%|█▊        | 5/28 [00:00<00:00, 86.38it/s, train_loss=0.00567, val_loss=0.00621]Epoch 15:  18%|█▊        | 5/28 [00:00<00:00, 85.31it/s, train_loss=0.00785, val_loss=0.00621]Epoch 15:  21%|██▏       | 6/28 [00:00<00:00, 89.11it/s, train_loss=0.00785, val_loss=0.00621]Epoch 15:  21%|██▏       | 6/28 [00:00<00:00, 87.03it/s, train_loss=0.00647, val_loss=0.00621]Epoch 15:  25%|██▌       | 7/28 [00:00<00:00, 88.04it/s, train_loss=0.00647, val_loss=0.00621]Epoch 15:  25%|██▌       | 7/28 [00:00<00:00, 87.14it/s, train_loss=0.00735, val_loss=0.00621]Epoch 15:  29%|██▊       | 8/28 [00:00<00:00, 90.04it/s, train_loss=0.00735, val_loss=0.00621]Epoch 15:  29%|██▊       | 8/28 [00:00<00:00, 88.31it/s, train_loss=0.0057, val_loss=0.00621] Epoch 15:  32%|███▏      | 9/28 [00:00<00:00, 89.43it/s, train_loss=0.0057, val_loss=0.00621]Epoch 15:  32%|███▏      | 9/28 [00:00<00:00, 88.53it/s, train_loss=0.00597, val_loss=0.00621]Epoch 15:  36%|███▌      | 10/28 [00:00<00:00, 90.98it/s, train_loss=0.00597, val_loss=0.00621]Epoch 15:  36%|███▌      | 10/28 [00:00<00:00, 89.50it/s, train_loss=0.00728, val_loss=0.00621]Epoch 15:  39%|███▉      | 11/28 [00:00<00:00, 90.06it/s, train_loss=0.00728, val_loss=0.00621]Epoch 15:  39%|███▉      | 11/28 [00:00<00:00, 89.51it/s, train_loss=0.00674, val_loss=0.00621]Epoch 15:  43%|████▎     | 12/28 [00:00<00:00, 91.45it/s, train_loss=0.00674, val_loss=0.00621]Epoch 15:  43%|████▎     | 12/28 [00:00<00:00, 90.19it/s, train_loss=0.00713, val_loss=0.00621]Epoch 15:  46%|████▋     | 13/28 [00:00<00:00, 90.99it/s, train_loss=0.00713, val_loss=0.00621]Epoch 15:  46%|████▋     | 13/28 [00:00<00:00, 90.39it/s, train_loss=0.0063, val_loss=0.00621] Epoch 15:  50%|█████     | 14/28 [00:00<00:00, 92.04it/s, train_loss=0.0063, val_loss=0.00621]Epoch 15:  50%|█████     | 14/28 [00:00<00:00, 90.92it/s, train_loss=0.00741, val_loss=0.00621]Epoch 15:  54%|█████▎    | 15/28 [00:00<00:00, 91.56it/s, train_loss=0.00741, val_loss=0.00621]Epoch 15:  54%|█████▎    | 15/28 [00:00<00:00, 91.06it/s, train_loss=0.00673, val_loss=0.00621]Epoch 15:  57%|█████▋    | 16/28 [00:00<00:00, 92.42it/s, train_loss=0.00673, val_loss=0.00621]Epoch 15:  57%|█████▋    | 16/28 [00:00<00:00, 91.49it/s, train_loss=0.00754, val_loss=0.00621]Epoch 15:  61%|██████    | 17/28 [00:00<00:00, 92.02it/s, train_loss=0.00754, val_loss=0.00621]Epoch 15:  61%|██████    | 17/28 [00:00<00:00, 91.55it/s, train_loss=0.0059, val_loss=0.00621] Epoch 15:  64%|██████▍   | 18/28 [00:00<00:00, 92.71it/s, train_loss=0.0059, val_loss=0.00621]Epoch 15:  64%|██████▍   | 18/28 [00:00<00:00, 91.87it/s, train_loss=0.00497, val_loss=0.00621]Epoch 15:  68%|██████▊   | 19/28 [00:00<00:00, 92.27it/s, train_loss=0.00497, val_loss=0.00621]Epoch 15:  68%|██████▊   | 19/28 [00:00<00:00, 91.78it/s, train_loss=0.00582, val_loss=0.00621]Epoch 15:  71%|███████▏  | 20/28 [00:00<00:00, 92.86it/s, train_loss=0.00582, val_loss=0.00621]Epoch 15:  71%|███████▏  | 20/28 [00:00<00:00, 92.04it/s, train_loss=0.00698, val_loss=0.00621]Epoch 15:  75%|███████▌  | 21/28 [00:00<00:00, 92.38it/s, train_loss=0.00698, val_loss=0.00621]Epoch 15:  75%|███████▌  | 21/28 [00:00<00:00, 91.98it/s, train_loss=0.00913, val_loss=0.00621]Epoch 15:  79%|███████▊  | 22/28 [00:00<00:00, 93.09it/s, train_loss=0.00913, val_loss=0.00621]Epoch 15:  79%|███████▊  | 22/28 [00:00<00:00, 92.42it/s, train_loss=0.00706, val_loss=0.00621]Epoch 15:  82%|████████▏ | 23/28 [00:00<00:00, 92.91it/s, train_loss=0.00706, val_loss=0.00621]Epoch 15:  82%|████████▏ | 23/28 [00:00<00:00, 92.55it/s, train_loss=0.00637, val_loss=0.00621]Epoch 15:  86%|████████▌ | 24/28 [00:00<00:00, 93.43it/s, train_loss=0.00637, val_loss=0.00621]Epoch 15:  86%|████████▌ | 24/28 [00:00<00:00, 92.80it/s, train_loss=0.00596, val_loss=0.00621]Epoch 15:  89%|████████▉ | 25/28 [00:00<00:00, 93.15it/s, train_loss=0.00596, val_loss=0.00621]Epoch 15:  89%|████████▉ | 25/28 [00:00<00:00, 92.83it/s, train_loss=0.00638, val_loss=0.00621]Epoch 15:  93%|█████████▎| 26/28 [00:00<00:00, 93.59it/s, train_loss=0.00638, val_loss=0.00621]Epoch 15:  93%|█████████▎| 26/28 [00:00<00:00, 92.97it/s, train_loss=0.00546, val_loss=0.00621]Epoch 15:  96%|█████████▋| 27/28 [00:00<00:00, 93.23it/s, train_loss=0.00546, val_loss=0.00621]Epoch 15:  96%|█████████▋| 27/28 [00:00<00:00, 92.90it/s, train_loss=0.0063, val_loss=0.00621] Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 93.69it/s, train_loss=0.0063, val_loss=0.00621]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 93.46it/s, train_loss=0.0153, val_loss=0.00621]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 142.29it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 156.98it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 164.49it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 165.61it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 167.16it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 167.47it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 168.65it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 168.25it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 169.02it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 167.73it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 168.28it/s][A
                                                                         [AEpoch 15: 100%|██████████| 28/28 [00:00<00:00, 75.18it/s, train_loss=0.0153, val_loss=0.00579]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 74.99it/s, train_loss=0.0153, val_loss=0.00579]Epoch 15:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0153, val_loss=0.00579]         Epoch 16:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0153, val_loss=0.00579]Epoch 16:   4%|▎         | 1/28 [00:00<00:00, 84.11it/s, train_loss=0.0153, val_loss=0.00579]Epoch 16:   4%|▎         | 1/28 [00:00<00:00, 77.92it/s, train_loss=0.00531, val_loss=0.00579]Epoch 16:   7%|▋         | 2/28 [00:00<00:00, 88.02it/s, train_loss=0.00531, val_loss=0.00579]Epoch 16:   7%|▋         | 2/28 [00:00<00:00, 80.86it/s, train_loss=0.00773, val_loss=0.00579]Epoch 16:  11%|█         | 3/28 [00:00<00:00, 87.10it/s, train_loss=0.00773, val_loss=0.00579]Epoch 16:  11%|█         | 3/28 [00:00<00:00, 83.38it/s, train_loss=0.0051, val_loss=0.00579] Epoch 16:  14%|█▍        | 4/28 [00:00<00:00, 85.97it/s, train_loss=0.0051, val_loss=0.00579]Epoch 16:  14%|█▍        | 4/28 [00:00<00:00, 84.56it/s, train_loss=0.00553, val_loss=0.00579]Epoch 16:  18%|█▊        | 5/28 [00:00<00:00, 89.81it/s, train_loss=0.00553, val_loss=0.00579]Epoch 16:  18%|█▊        | 5/28 [00:00<00:00, 87.32it/s, train_loss=0.00604, val_loss=0.00579]Epoch 16:  21%|██▏       | 6/28 [00:00<00:00, 89.06it/s, train_loss=0.00604, val_loss=0.00579]Epoch 16:  21%|██▏       | 6/28 [00:00<00:00, 87.95it/s, train_loss=0.00615, val_loss=0.00579]Epoch 16:  25%|██▌       | 7/28 [00:00<00:00, 91.15it/s, train_loss=0.00615, val_loss=0.00579]Epoch 16:  25%|██▌       | 7/28 [00:00<00:00, 89.16it/s, train_loss=0.00545, val_loss=0.00579]Epoch 16:  29%|██▊       | 8/28 [00:00<00:00, 90.15it/s, train_loss=0.00545, val_loss=0.00579]Epoch 16:  29%|██▊       | 8/28 [00:00<00:00, 89.24it/s, train_loss=0.00724, val_loss=0.00579]Epoch 16:  32%|███▏      | 9/28 [00:00<00:00, 91.71it/s, train_loss=0.00724, val_loss=0.00579]Epoch 16:  32%|███▏      | 9/28 [00:00<00:00, 89.99it/s, train_loss=0.00615, val_loss=0.00579]Epoch 16:  36%|███▌      | 10/28 [00:00<00:00, 90.91it/s, train_loss=0.00615, val_loss=0.00579]Epoch 16:  36%|███▌      | 10/28 [00:00<00:00, 90.08it/s, train_loss=0.00653, val_loss=0.00579]Epoch 16:  39%|███▉      | 11/28 [00:00<00:00, 92.25it/s, train_loss=0.00653, val_loss=0.00579]Epoch 16:  39%|███▉      | 11/28 [00:00<00:00, 90.81it/s, train_loss=0.00769, val_loss=0.00579]Epoch 16:  43%|████▎     | 12/28 [00:00<00:00, 91.34it/s, train_loss=0.00769, val_loss=0.00579]Epoch 16:  43%|████▎     | 12/28 [00:00<00:00, 90.26it/s, train_loss=0.00731, val_loss=0.00579]Epoch 16:  46%|████▋     | 13/28 [00:00<00:00, 91.33it/s, train_loss=0.00731, val_loss=0.00579]Epoch 16:  46%|████▋     | 13/28 [00:00<00:00, 89.95it/s, train_loss=0.00531, val_loss=0.00579]Epoch 16:  50%|█████     | 14/28 [00:00<00:00, 91.10it/s, train_loss=0.00531, val_loss=0.00579]Epoch 16:  50%|█████     | 14/28 [00:00<00:00, 90.13it/s, train_loss=0.00637, val_loss=0.00579]Epoch 16:  54%|█████▎    | 15/28 [00:00<00:00, 91.62it/s, train_loss=0.00637, val_loss=0.00579]Epoch 16:  54%|█████▎    | 15/28 [00:00<00:00, 90.74it/s, train_loss=0.00651, val_loss=0.00579]Epoch 16:  57%|█████▋    | 16/28 [00:00<00:00, 92.16it/s, train_loss=0.00651, val_loss=0.00579]Epoch 16:  57%|█████▋    | 16/28 [00:00<00:00, 86.73it/s, train_loss=0.00659, val_loss=0.00579]Epoch 16:  61%|██████    | 17/28 [00:00<00:00, 84.47it/s, train_loss=0.00659, val_loss=0.00579]Epoch 16:  61%|██████    | 17/28 [00:00<00:00, 76.83it/s, train_loss=0.00602, val_loss=0.00579]Epoch 16:  64%|██████▍   | 18/28 [00:00<00:00, 78.42it/s, train_loss=0.00602, val_loss=0.00579]Epoch 16:  64%|██████▍   | 18/28 [00:00<00:00, 72.33it/s, train_loss=0.00917, val_loss=0.00579]Epoch 16:  68%|██████▊   | 19/28 [00:00<00:00, 73.24it/s, train_loss=0.00917, val_loss=0.00579]Epoch 16:  68%|██████▊   | 19/28 [00:00<00:00, 72.99it/s, train_loss=0.00626, val_loss=0.00579]Epoch 16:  71%|███████▏  | 20/28 [00:00<00:00, 74.26it/s, train_loss=0.00626, val_loss=0.00579]Epoch 16:  71%|███████▏  | 20/28 [00:00<00:00, 73.72it/s, train_loss=0.00552, val_loss=0.00579]Epoch 16:  75%|███████▌  | 21/28 [00:00<00:00, 74.73it/s, train_loss=0.00552, val_loss=0.00579]Epoch 16:  75%|███████▌  | 21/28 [00:00<00:00, 74.50it/s, train_loss=0.00594, val_loss=0.00579]Epoch 16:  79%|███████▊  | 22/28 [00:00<00:00, 75.69it/s, train_loss=0.00594, val_loss=0.00579]Epoch 16:  79%|███████▊  | 22/28 [00:00<00:00, 75.17it/s, train_loss=0.00634, val_loss=0.00579]Epoch 16:  82%|████████▏ | 23/28 [00:00<00:00, 76.07it/s, train_loss=0.00634, val_loss=0.00579]Epoch 16:  82%|████████▏ | 23/28 [00:00<00:00, 75.63it/s, train_loss=0.00608, val_loss=0.00579]Epoch 16:  86%|████████▌ | 24/28 [00:00<00:00, 76.89it/s, train_loss=0.00608, val_loss=0.00579]Epoch 16:  86%|████████▌ | 24/28 [00:00<00:00, 76.37it/s, train_loss=0.00579, val_loss=0.00579]Epoch 16:  89%|████████▉ | 25/28 [00:00<00:00, 77.33it/s, train_loss=0.00579, val_loss=0.00579]Epoch 16:  89%|████████▉ | 25/28 [00:00<00:00, 76.64it/s, train_loss=0.00744, val_loss=0.00579]Epoch 16:  93%|█████████▎| 26/28 [00:00<00:00, 77.66it/s, train_loss=0.00744, val_loss=0.00579]Epoch 16:  93%|█████████▎| 26/28 [00:00<00:00, 77.20it/s, train_loss=0.00546, val_loss=0.00579]Epoch 16:  96%|█████████▋| 27/28 [00:00<00:00, 78.01it/s, train_loss=0.00546, val_loss=0.00579]Epoch 16:  96%|█████████▋| 27/28 [00:00<00:00, 77.53it/s, train_loss=0.00668, val_loss=0.00579]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 78.76it/s, train_loss=0.00668, val_loss=0.00579]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 78.40it/s, train_loss=0.00418, val_loss=0.00579]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 137.46it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 158.09it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 165.97it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 171.11it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 174.53it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 174.43it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 175.72it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 175.41it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 175.82it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 175.57it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 175.99it/s][A
                                                                         [AEpoch 16: 100%|██████████| 28/28 [00:00<00:00, 65.58it/s, train_loss=0.00418, val_loss=0.0055] Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 65.44it/s, train_loss=0.00418, val_loss=0.0055]Epoch 16:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00418, val_loss=0.0055]         Epoch 17:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00418, val_loss=0.0055]Epoch 17:   4%|▎         | 1/28 [00:00<00:00, 93.50it/s, train_loss=0.00418, val_loss=0.0055]Epoch 17:   4%|▎         | 1/28 [00:00<00:00, 85.57it/s, train_loss=0.00666, val_loss=0.0055]Epoch 17:   7%|▋         | 2/28 [00:00<00:00, 93.56it/s, train_loss=0.00666, val_loss=0.0055]Epoch 17:   7%|▋         | 2/28 [00:00<00:00, 86.60it/s, train_loss=0.00731, val_loss=0.0055]Epoch 17:  11%|█         | 3/28 [00:00<00:00, 95.06it/s, train_loss=0.00731, val_loss=0.0055]Epoch 17:  11%|█         | 3/28 [00:00<00:00, 89.03it/s, train_loss=0.00866, val_loss=0.0055]Epoch 17:  14%|█▍        | 4/28 [00:00<00:00, 91.76it/s, train_loss=0.00866, val_loss=0.0055]Epoch 17:  14%|█▍        | 4/28 [00:00<00:00, 88.44it/s, train_loss=0.00517, val_loss=0.0055]Epoch 17:  18%|█▊        | 5/28 [00:00<00:00, 92.82it/s, train_loss=0.00517, val_loss=0.0055]Epoch 17:  18%|█▊        | 5/28 [00:00<00:00, 89.52it/s, train_loss=0.00496, val_loss=0.0055]Epoch 17:  21%|██▏       | 6/28 [00:00<00:00, 90.89it/s, train_loss=0.00496, val_loss=0.0055]Epoch 17:  21%|██▏       | 6/28 [00:00<00:00, 89.03it/s, train_loss=0.00531, val_loss=0.0055]Epoch 17:  25%|██▌       | 7/28 [00:00<00:00, 92.00it/s, train_loss=0.00531, val_loss=0.0055]Epoch 17:  25%|██▌       | 7/28 [00:00<00:00, 89.72it/s, train_loss=0.00543, val_loss=0.0055]Epoch 17:  29%|██▊       | 8/28 [00:00<00:00, 91.30it/s, train_loss=0.00543, val_loss=0.0055]Epoch 17:  29%|██▊       | 8/28 [00:00<00:00, 89.43it/s, train_loss=0.00591, val_loss=0.0055]Epoch 17:  32%|███▏      | 9/28 [00:00<00:00, 92.12it/s, train_loss=0.00591, val_loss=0.0055]Epoch 17:  32%|███▏      | 9/28 [00:00<00:00, 90.38it/s, train_loss=0.00455, val_loss=0.0055]Epoch 17:  36%|███▌      | 10/28 [00:00<00:00, 92.28it/s, train_loss=0.00455, val_loss=0.0055]Epoch 17:  36%|███▌      | 10/28 [00:00<00:00, 89.74it/s, train_loss=0.00706, val_loss=0.0055]Epoch 17:  39%|███▉      | 11/28 [00:00<00:00, 91.49it/s, train_loss=0.00706, val_loss=0.0055]Epoch 17:  39%|███▉      | 11/28 [00:00<00:00, 90.15it/s, train_loss=0.00606, val_loss=0.0055]Epoch 17:  43%|████▎     | 12/28 [00:00<00:00, 91.10it/s, train_loss=0.00606, val_loss=0.0055]Epoch 17:  43%|████▎     | 12/28 [00:00<00:00, 89.82it/s, train_loss=0.00582, val_loss=0.0055]Epoch 17:  46%|████▋     | 13/28 [00:00<00:00, 91.56it/s, train_loss=0.00582, val_loss=0.0055]Epoch 17:  46%|████▋     | 13/28 [00:00<00:00, 90.31it/s, train_loss=0.00577, val_loss=0.0055]Epoch 17:  50%|█████     | 14/28 [00:00<00:00, 91.14it/s, train_loss=0.00577, val_loss=0.0055]Epoch 17:  50%|█████     | 14/28 [00:00<00:00, 89.93it/s, train_loss=0.00564, val_loss=0.0055]Epoch 17:  54%|█████▎    | 15/28 [00:00<00:00, 91.40it/s, train_loss=0.00564, val_loss=0.0055]Epoch 17:  54%|█████▎    | 15/28 [00:00<00:00, 90.30it/s, train_loss=0.00504, val_loss=0.0055]Epoch 17:  57%|█████▋    | 16/28 [00:00<00:00, 90.91it/s, train_loss=0.00504, val_loss=0.0055]Epoch 17:  57%|█████▋    | 16/28 [00:00<00:00, 90.03it/s, train_loss=0.00726, val_loss=0.0055]Epoch 17:  61%|██████    | 17/28 [00:00<00:00, 91.35it/s, train_loss=0.00726, val_loss=0.0055]Epoch 17:  61%|██████    | 17/28 [00:00<00:00, 90.41it/s, train_loss=0.00711, val_loss=0.0055]Epoch 17:  64%|██████▍   | 18/28 [00:00<00:00, 91.09it/s, train_loss=0.00711, val_loss=0.0055]Epoch 17:  64%|██████▍   | 18/28 [00:00<00:00, 90.12it/s, train_loss=0.00606, val_loss=0.0055]Epoch 17:  68%|██████▊   | 19/28 [00:00<00:00, 91.18it/s, train_loss=0.00606, val_loss=0.0055]Epoch 17:  68%|██████▊   | 19/28 [00:00<00:00, 89.81it/s, train_loss=0.0074, val_loss=0.0055] Epoch 17:  71%|███████▏  | 20/28 [00:00<00:00, 90.05it/s, train_loss=0.0074, val_loss=0.0055]Epoch 17:  71%|███████▏  | 20/28 [00:00<00:00, 89.64it/s, train_loss=0.00533, val_loss=0.0055]Epoch 17:  75%|███████▌  | 21/28 [00:00<00:00, 90.76it/s, train_loss=0.00533, val_loss=0.0055]Epoch 17:  75%|███████▌  | 21/28 [00:00<00:00, 90.05it/s, train_loss=0.00573, val_loss=0.0055]Epoch 17:  79%|███████▊  | 22/28 [00:00<00:00, 90.18it/s, train_loss=0.00573, val_loss=0.0055]Epoch 17:  79%|███████▊  | 22/28 [00:00<00:00, 89.81it/s, train_loss=0.00531, val_loss=0.0055]Epoch 17:  82%|████████▏ | 23/28 [00:00<00:00, 90.76it/s, train_loss=0.00531, val_loss=0.0055]Epoch 17:  82%|████████▏ | 23/28 [00:00<00:00, 90.07it/s, train_loss=0.00478, val_loss=0.0055]Epoch 17:  86%|████████▌ | 24/28 [00:00<00:00, 90.19it/s, train_loss=0.00478, val_loss=0.0055]Epoch 17:  86%|████████▌ | 24/28 [00:00<00:00, 89.85it/s, train_loss=0.00553, val_loss=0.0055]Epoch 17:  89%|████████▉ | 25/28 [00:00<00:00, 90.74it/s, train_loss=0.00553, val_loss=0.0055]Epoch 17:  89%|████████▉ | 25/28 [00:00<00:00, 90.14it/s, train_loss=0.0061, val_loss=0.0055] Epoch 17:  93%|█████████▎| 26/28 [00:00<00:00, 90.44it/s, train_loss=0.0061, val_loss=0.0055]Epoch 17:  93%|█████████▎| 26/28 [00:00<00:00, 90.03it/s, train_loss=0.00583, val_loss=0.0055]Epoch 17:  96%|█████████▋| 27/28 [00:00<00:00, 90.92it/s, train_loss=0.00583, val_loss=0.0055]Epoch 17:  96%|█████████▋| 27/28 [00:00<00:00, 90.33it/s, train_loss=0.00504, val_loss=0.0055]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 91.30it/s, train_loss=0.00504, val_loss=0.0055]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 91.11it/s, train_loss=0.00474, val_loss=0.0055]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 149.24it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 164.40it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 164.88it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 167.45it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 166.59it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 166.96it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 165.95it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 165.97it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 165.59it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 164.14it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 164.64it/s][A
                                                                         [AEpoch 17: 100%|██████████| 28/28 [00:00<00:00, 73.30it/s, train_loss=0.00474, val_loss=0.00534]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 73.12it/s, train_loss=0.00474, val_loss=0.00534]Epoch 17:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00474, val_loss=0.00534]         Epoch 18:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00474, val_loss=0.00534]Epoch 18:   4%|▎         | 1/28 [00:00<00:00, 79.37it/s, train_loss=0.00474, val_loss=0.00534]Epoch 18:   4%|▎         | 1/28 [00:00<00:00, 74.36it/s, train_loss=0.00524, val_loss=0.00534]Epoch 18:   7%|▋         | 2/28 [00:00<00:00, 85.48it/s, train_loss=0.00524, val_loss=0.00534]Epoch 18:   7%|▋         | 2/28 [00:00<00:00, 81.01it/s, train_loss=0.00717, val_loss=0.00534]Epoch 18:  11%|█         | 3/28 [00:00<00:00, 83.67it/s, train_loss=0.00717, val_loss=0.00534]Epoch 18:  11%|█         | 3/28 [00:00<00:00, 81.49it/s, train_loss=0.00648, val_loss=0.00534]Epoch 18:  14%|█▍        | 4/28 [00:00<00:00, 85.18it/s, train_loss=0.00648, val_loss=0.00534]Epoch 18:  14%|█▍        | 4/28 [00:00<00:00, 83.01it/s, train_loss=0.00773, val_loss=0.00534]Epoch 18:  18%|█▊        | 5/28 [00:00<00:00, 85.26it/s, train_loss=0.00773, val_loss=0.00534]Epoch 18:  18%|█▊        | 5/28 [00:00<00:00, 83.93it/s, train_loss=0.00615, val_loss=0.00534]Epoch 18:  21%|██▏       | 6/28 [00:00<00:00, 86.75it/s, train_loss=0.00615, val_loss=0.00534]Epoch 18:  21%|██▏       | 6/28 [00:00<00:00, 84.88it/s, train_loss=0.00667, val_loss=0.00534]Epoch 18:  25%|██▌       | 7/28 [00:00<00:00, 86.57it/s, train_loss=0.00667, val_loss=0.00534]Epoch 18:  25%|██▌       | 7/28 [00:00<00:00, 85.55it/s, train_loss=0.0058, val_loss=0.00534] Epoch 18:  29%|██▊       | 8/28 [00:00<00:00, 87.66it/s, train_loss=0.0058, val_loss=0.00534]Epoch 18:  29%|██▊       | 8/28 [00:00<00:00, 86.16it/s, train_loss=0.00526, val_loss=0.00534]Epoch 18:  32%|███▏      | 9/28 [00:00<00:00, 87.20it/s, train_loss=0.00526, val_loss=0.00534]Epoch 18:  32%|███▏      | 9/28 [00:00<00:00, 86.40it/s, train_loss=0.00505, val_loss=0.00534]Epoch 18:  36%|███▌      | 10/28 [00:00<00:00, 88.29it/s, train_loss=0.00505, val_loss=0.00534]Epoch 18:  36%|███▌      | 10/28 [00:00<00:00, 87.01it/s, train_loss=0.00596, val_loss=0.00534]Epoch 18:  39%|███▉      | 11/28 [00:00<00:00, 88.77it/s, train_loss=0.00596, val_loss=0.00534]Epoch 18:  39%|███▉      | 11/28 [00:00<00:00, 86.82it/s, train_loss=0.00463, val_loss=0.00534]Epoch 18:  43%|████▎     | 12/28 [00:00<00:00, 88.49it/s, train_loss=0.00463, val_loss=0.00534]Epoch 18:  43%|████▎     | 12/28 [00:00<00:00, 87.40it/s, train_loss=0.00594, val_loss=0.00534]Epoch 18:  46%|████▋     | 13/28 [00:00<00:00, 88.46it/s, train_loss=0.00594, val_loss=0.00534]Epoch 18:  46%|████▋     | 13/28 [00:00<00:00, 87.41it/s, train_loss=0.0064, val_loss=0.00534] Epoch 18:  50%|█████     | 14/28 [00:00<00:00, 88.89it/s, train_loss=0.0064, val_loss=0.00534]Epoch 18:  50%|█████     | 14/28 [00:00<00:00, 87.88it/s, train_loss=0.0039, val_loss=0.00534]Epoch 18:  54%|█████▎    | 15/28 [00:00<00:00, 88.76it/s, train_loss=0.0039, val_loss=0.00534]Epoch 18:  54%|█████▎    | 15/28 [00:00<00:00, 87.80it/s, train_loss=0.00562, val_loss=0.00534]Epoch 18:  57%|█████▋    | 16/28 [00:00<00:00, 89.14it/s, train_loss=0.00562, val_loss=0.00534]Epoch 18:  57%|█████▋    | 16/28 [00:00<00:00, 88.24it/s, train_loss=0.00543, val_loss=0.00534]Epoch 18:  61%|██████    | 17/28 [00:00<00:00, 89.09it/s, train_loss=0.00543, val_loss=0.00534]Epoch 18:  61%|██████    | 17/28 [00:00<00:00, 88.09it/s, train_loss=0.00492, val_loss=0.00534]Epoch 18:  64%|██████▍   | 18/28 [00:00<00:00, 89.35it/s, train_loss=0.00492, val_loss=0.00534]Epoch 18:  64%|██████▍   | 18/28 [00:00<00:00, 88.50it/s, train_loss=0.00614, val_loss=0.00534]Epoch 18:  68%|██████▊   | 19/28 [00:00<00:00, 89.16it/s, train_loss=0.00614, val_loss=0.00534]Epoch 18:  68%|██████▊   | 19/28 [00:00<00:00, 88.35it/s, train_loss=0.00564, val_loss=0.00534]Epoch 18:  71%|███████▏  | 20/28 [00:00<00:00, 89.44it/s, train_loss=0.00564, val_loss=0.00534]Epoch 18:  71%|███████▏  | 20/28 [00:00<00:00, 88.67it/s, train_loss=0.00592, val_loss=0.00534]Epoch 18:  75%|███████▌  | 21/28 [00:00<00:00, 89.22it/s, train_loss=0.00592, val_loss=0.00534]Epoch 18:  75%|███████▌  | 21/28 [00:00<00:00, 88.51it/s, train_loss=0.00555, val_loss=0.00534]Epoch 18:  79%|███████▊  | 22/28 [00:00<00:00, 89.44it/s, train_loss=0.00555, val_loss=0.00534]Epoch 18:  79%|███████▊  | 22/28 [00:00<00:00, 88.78it/s, train_loss=0.0058, val_loss=0.00534] Epoch 18:  82%|████████▏ | 23/28 [00:00<00:00, 89.29it/s, train_loss=0.0058, val_loss=0.00534]Epoch 18:  82%|████████▏ | 23/28 [00:00<00:00, 88.65it/s, train_loss=0.00481, val_loss=0.00534]Epoch 18:  86%|████████▌ | 24/28 [00:00<00:00, 89.53it/s, train_loss=0.00481, val_loss=0.00534]Epoch 18:  86%|████████▌ | 24/28 [00:00<00:00, 88.87it/s, train_loss=0.00492, val_loss=0.00534]Epoch 18:  89%|████████▉ | 25/28 [00:00<00:00, 89.39it/s, train_loss=0.00492, val_loss=0.00534]Epoch 18:  89%|████████▉ | 25/28 [00:00<00:00, 88.81it/s, train_loss=0.00553, val_loss=0.00534]Epoch 18:  93%|█████████▎| 26/28 [00:00<00:00, 89.64it/s, train_loss=0.00553, val_loss=0.00534]Epoch 18:  93%|█████████▎| 26/28 [00:00<00:00, 89.02it/s, train_loss=0.00678, val_loss=0.00534]Epoch 18:  96%|█████████▋| 27/28 [00:00<00:00, 89.45it/s, train_loss=0.00678, val_loss=0.00534]Epoch 18:  96%|█████████▋| 27/28 [00:00<00:00, 88.90it/s, train_loss=0.00497, val_loss=0.00534]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 89.93it/s, train_loss=0.00497, val_loss=0.00534]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 89.66it/s, train_loss=0.0233, val_loss=0.00534] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 185.13it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 198.15it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 208.80it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 201.22it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 191.66it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 195.96it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 195.39it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 195.76it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 197.97it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 197.63it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 197.92it/s][A
                                                                         [AEpoch 18: 100%|██████████| 28/28 [00:00<00:00, 74.94it/s, train_loss=0.0233, val_loss=0.00503]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 74.79it/s, train_loss=0.0233, val_loss=0.00503]Epoch 18:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0233, val_loss=0.00503]         Epoch 19:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0233, val_loss=0.00503]Epoch 19:   4%|▎         | 1/28 [00:00<00:00, 86.52it/s, train_loss=0.0233, val_loss=0.00503]Epoch 19:   4%|▎         | 1/28 [00:00<00:00, 80.39it/s, train_loss=0.0054, val_loss=0.00503]Epoch 19:   7%|▋         | 2/28 [00:00<00:00, 89.62it/s, train_loss=0.0054, val_loss=0.00503]Epoch 19:   7%|▋         | 2/28 [00:00<00:00, 84.00it/s, train_loss=0.00582, val_loss=0.00503]Epoch 19:  11%|█         | 3/28 [00:00<00:00, 92.16it/s, train_loss=0.00582, val_loss=0.00503]Epoch 19:  11%|█         | 3/28 [00:00<00:00, 87.42it/s, train_loss=0.00614, val_loss=0.00503]Epoch 19:  14%|█▍        | 4/28 [00:00<00:00, 90.86it/s, train_loss=0.00614, val_loss=0.00503]Epoch 19:  14%|█▍        | 4/28 [00:00<00:00, 86.93it/s, train_loss=0.00475, val_loss=0.00503]Epoch 19:  18%|█▊        | 5/28 [00:00<00:00, 91.36it/s, train_loss=0.00475, val_loss=0.00503]Epoch 19:  18%|█▊        | 5/28 [00:00<00:00, 88.42it/s, train_loss=0.00493, val_loss=0.00503]Epoch 19:  21%|██▏       | 6/28 [00:00<00:00, 90.07it/s, train_loss=0.00493, val_loss=0.00503]Epoch 19:  21%|██▏       | 6/28 [00:00<00:00, 88.09it/s, train_loss=0.00584, val_loss=0.00503]Epoch 19:  25%|██▌       | 7/28 [00:00<00:00, 90.93it/s, train_loss=0.00584, val_loss=0.00503]Epoch 19:  25%|██▌       | 7/28 [00:00<00:00, 88.84it/s, train_loss=0.00595, val_loss=0.00503]Epoch 19:  29%|██▊       | 8/28 [00:00<00:00, 90.24it/s, train_loss=0.00595, val_loss=0.00503]Epoch 19:  29%|██▊       | 8/28 [00:00<00:00, 88.52it/s, train_loss=0.00468, val_loss=0.00503]Epoch 19:  32%|███▏      | 9/28 [00:00<00:00, 90.94it/s, train_loss=0.00468, val_loss=0.00503]Epoch 19:  32%|███▏      | 9/28 [00:00<00:00, 89.18it/s, train_loss=0.00436, val_loss=0.00503]Epoch 19:  36%|███▌      | 10/28 [00:00<00:00, 90.30it/s, train_loss=0.00436, val_loss=0.00503]Epoch 19:  36%|███▌      | 10/28 [00:00<00:00, 88.95it/s, train_loss=0.00491, val_loss=0.00503]Epoch 19:  39%|███▉      | 11/28 [00:00<00:00, 90.76it/s, train_loss=0.00491, val_loss=0.00503]Epoch 19:  39%|███▉      | 11/28 [00:00<00:00, 89.34it/s, train_loss=0.00481, val_loss=0.00503]Epoch 19:  43%|████▎     | 12/28 [00:00<00:00, 90.18it/s, train_loss=0.00481, val_loss=0.00503]Epoch 19:  43%|████▎     | 12/28 [00:00<00:00, 89.09it/s, train_loss=0.00614, val_loss=0.00503]Epoch 19:  46%|████▋     | 13/28 [00:00<00:00, 91.00it/s, train_loss=0.00614, val_loss=0.00503]Epoch 19:  46%|████▋     | 13/28 [00:00<00:00, 89.80it/s, train_loss=0.00664, val_loss=0.00503]Epoch 19:  50%|█████     | 14/28 [00:00<00:00, 91.36it/s, train_loss=0.00664, val_loss=0.00503]Epoch 19:  50%|█████     | 14/28 [00:00<00:00, 89.28it/s, train_loss=0.00505, val_loss=0.00503]Epoch 19:  54%|█████▎    | 15/28 [00:00<00:00, 90.57it/s, train_loss=0.00505, val_loss=0.00503]Epoch 19:  54%|█████▎    | 15/28 [00:00<00:00, 89.61it/s, train_loss=0.00599, val_loss=0.00503]Epoch 19:  57%|█████▋    | 16/28 [00:00<00:00, 90.91it/s, train_loss=0.00599, val_loss=0.00503]Epoch 19:  57%|█████▋    | 16/28 [00:00<00:00, 89.00it/s, train_loss=0.00473, val_loss=0.00503]Epoch 19:  61%|██████    | 17/28 [00:00<00:00, 90.18it/s, train_loss=0.00473, val_loss=0.00503]Epoch 19:  61%|██████    | 17/28 [00:00<00:00, 89.28it/s, train_loss=0.00536, val_loss=0.00503]Epoch 19:  64%|██████▍   | 18/28 [00:00<00:00, 90.37it/s, train_loss=0.00536, val_loss=0.00503]Epoch 19:  64%|██████▍   | 18/28 [00:00<00:00, 88.95it/s, train_loss=0.00637, val_loss=0.00503]Epoch 19:  68%|██████▊   | 19/28 [00:00<00:00, 89.94it/s, train_loss=0.00637, val_loss=0.00503]Epoch 19:  68%|██████▊   | 19/28 [00:00<00:00, 89.13it/s, train_loss=0.00719, val_loss=0.00503]Epoch 19:  71%|███████▏  | 20/28 [00:00<00:00, 89.84it/s, train_loss=0.00719, val_loss=0.00503]Epoch 19:  71%|███████▏  | 20/28 [00:00<00:00, 89.01it/s, train_loss=0.00636, val_loss=0.00503]Epoch 19:  75%|███████▌  | 21/28 [00:00<00:00, 90.04it/s, train_loss=0.00636, val_loss=0.00503]Epoch 19:  75%|███████▌  | 21/28 [00:00<00:00, 89.29it/s, train_loss=0.00505, val_loss=0.00503]Epoch 19:  79%|███████▊  | 22/28 [00:00<00:00, 89.86it/s, train_loss=0.00505, val_loss=0.00503]Epoch 19:  79%|███████▊  | 22/28 [00:00<00:00, 89.13it/s, train_loss=0.00457, val_loss=0.00503]Epoch 19:  82%|████████▏ | 23/28 [00:00<00:00, 90.07it/s, train_loss=0.00457, val_loss=0.00503]Epoch 19:  82%|████████▏ | 23/28 [00:00<00:00, 89.38it/s, train_loss=0.00624, val_loss=0.00503]Epoch 19:  86%|████████▌ | 24/28 [00:00<00:00, 89.86it/s, train_loss=0.00624, val_loss=0.00503]Epoch 19:  86%|████████▌ | 24/28 [00:00<00:00, 89.22it/s, train_loss=0.00468, val_loss=0.00503]Epoch 19:  89%|████████▉ | 25/28 [00:00<00:00, 90.07it/s, train_loss=0.00468, val_loss=0.00503]Epoch 19:  89%|████████▉ | 25/28 [00:00<00:00, 89.43it/s, train_loss=0.00578, val_loss=0.00503]Epoch 19:  93%|█████████▎| 26/28 [00:00<00:00, 89.86it/s, train_loss=0.00578, val_loss=0.00503]Epoch 19:  93%|█████████▎| 26/28 [00:00<00:00, 89.27it/s, train_loss=0.00529, val_loss=0.00503]Epoch 19:  96%|█████████▋| 27/28 [00:00<00:00, 90.04it/s, train_loss=0.00529, val_loss=0.00503]Epoch 19:  96%|█████████▋| 27/28 [00:00<00:00, 89.47it/s, train_loss=0.00422, val_loss=0.00503]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 90.30it/s, train_loss=0.00422, val_loss=0.00503]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 90.03it/s, train_loss=0.0304, val_loss=0.00503] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 125.75it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 141.60it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 149.22it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 154.84it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 163.86it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 170.80it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 175.47it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 178.74it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 181.42it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 184.08it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 185.95it/s][A
                                                                         [AEpoch 19: 100%|██████████| 28/28 [00:00<00:00, 74.28it/s, train_loss=0.0304, val_loss=0.00489]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 74.14it/s, train_loss=0.0304, val_loss=0.00489]Epoch 19:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0304, val_loss=0.00489]         Epoch 20:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0304, val_loss=0.00489]Epoch 20:   4%|▎         | 1/28 [00:00<00:00, 88.98it/s, train_loss=0.0304, val_loss=0.00489]Epoch 20:   4%|▎         | 1/28 [00:00<00:00, 83.17it/s, train_loss=0.00523, val_loss=0.00489]Epoch 20:   7%|▋         | 2/28 [00:00<00:00, 99.40it/s, train_loss=0.00523, val_loss=0.00489]Epoch 20:   7%|▋         | 2/28 [00:00<00:00, 91.31it/s, train_loss=0.00483, val_loss=0.00489]Epoch 20:  11%|█         | 3/28 [00:00<00:00, 95.80it/s, train_loss=0.00483, val_loss=0.00489]Epoch 20:  11%|█         | 3/28 [00:00<00:00, 90.27it/s, train_loss=0.00577, val_loss=0.00489]Epoch 20:  14%|█▍        | 4/28 [00:00<00:00, 95.60it/s, train_loss=0.00577, val_loss=0.00489]Epoch 20:  14%|█▍        | 4/28 [00:00<00:00, 91.51it/s, train_loss=0.00635, val_loss=0.00489]Epoch 20:  18%|█▊        | 5/28 [00:00<00:00, 93.62it/s, train_loss=0.00635, val_loss=0.00489]Epoch 20:  18%|█▊        | 5/28 [00:00<00:00, 90.30it/s, train_loss=0.00472, val_loss=0.00489]Epoch 20:  21%|██▏       | 6/28 [00:00<00:00, 93.82it/s, train_loss=0.00472, val_loss=0.00489]Epoch 20:  21%|██▏       | 6/28 [00:00<00:00, 91.16it/s, train_loss=0.00526, val_loss=0.00489]Epoch 20:  25%|██▌       | 7/28 [00:00<00:00, 92.18it/s, train_loss=0.00526, val_loss=0.00489]Epoch 20:  25%|██▌       | 7/28 [00:00<00:00, 90.28it/s, train_loss=0.00736, val_loss=0.00489]Epoch 20:  29%|██▊       | 8/28 [00:00<00:00, 92.83it/s, train_loss=0.00736, val_loss=0.00489]Epoch 20:  29%|██▊       | 8/28 [00:00<00:00, 90.88it/s, train_loss=0.0049, val_loss=0.00489] Epoch 20:  32%|███▏      | 9/28 [00:00<00:00, 91.94it/s, train_loss=0.0049, val_loss=0.00489]Epoch 20:  32%|███▏      | 9/28 [00:00<00:00, 90.34it/s, train_loss=0.00392, val_loss=0.00489]Epoch 20:  36%|███▌      | 10/28 [00:00<00:00, 92.34it/s, train_loss=0.00392, val_loss=0.00489]Epoch 20:  36%|███▌      | 10/28 [00:00<00:00, 90.74it/s, train_loss=0.00557, val_loss=0.00489]Epoch 20:  39%|███▉      | 11/28 [00:00<00:00, 91.76it/s, train_loss=0.00557, val_loss=0.00489]Epoch 20:  39%|███▉      | 11/28 [00:00<00:00, 90.39it/s, train_loss=0.00581, val_loss=0.00489]Epoch 20:  43%|████▎     | 12/28 [00:00<00:00, 92.12it/s, train_loss=0.00581, val_loss=0.00489]Epoch 20:  43%|████▎     | 12/28 [00:00<00:00, 90.69it/s, train_loss=0.00543, val_loss=0.00489]Epoch 20:  46%|████▋     | 13/28 [00:00<00:00, 91.47it/s, train_loss=0.00543, val_loss=0.00489]Epoch 20:  46%|████▋     | 13/28 [00:00<00:00, 90.34it/s, train_loss=0.00592, val_loss=0.00489]Epoch 20:  50%|█████     | 14/28 [00:00<00:00, 91.74it/s, train_loss=0.00592, val_loss=0.00489]Epoch 20:  50%|█████     | 14/28 [00:00<00:00, 90.61it/s, train_loss=0.00467, val_loss=0.00489]Epoch 20:  54%|█████▎    | 15/28 [00:00<00:00, 91.23it/s, train_loss=0.00467, val_loss=0.00489]Epoch 20:  54%|█████▎    | 15/28 [00:00<00:00, 90.28it/s, train_loss=0.00473, val_loss=0.00489]Epoch 20:  57%|█████▋    | 16/28 [00:00<00:00, 91.74it/s, train_loss=0.00473, val_loss=0.00489]Epoch 20:  57%|█████▋    | 16/28 [00:00<00:00, 90.76it/s, train_loss=0.00561, val_loss=0.00489]Epoch 20:  61%|██████    | 17/28 [00:00<00:00, 91.84it/s, train_loss=0.00561, val_loss=0.00489]Epoch 20:  61%|██████    | 17/28 [00:00<00:00, 90.22it/s, train_loss=0.00614, val_loss=0.00489]Epoch 20:  64%|██████▍   | 18/28 [00:00<00:00, 91.10it/s, train_loss=0.00614, val_loss=0.00489]Epoch 20:  64%|██████▍   | 18/28 [00:00<00:00, 90.33it/s, train_loss=0.00507, val_loss=0.00489]Epoch 20:  68%|██████▊   | 19/28 [00:00<00:00, 91.25it/s, train_loss=0.00507, val_loss=0.00489]Epoch 20:  68%|██████▊   | 19/28 [00:00<00:00, 89.86it/s, train_loss=0.00431, val_loss=0.00489]Epoch 20:  71%|███████▏  | 20/28 [00:00<00:00, 90.87it/s, train_loss=0.00431, val_loss=0.00489]Epoch 20:  71%|███████▏  | 20/28 [00:00<00:00, 90.09it/s, train_loss=0.005, val_loss=0.00489]  Epoch 20:  75%|███████▌  | 21/28 [00:00<00:00, 91.00it/s, train_loss=0.005, val_loss=0.00489]Epoch 20:  75%|███████▌  | 21/28 [00:00<00:00, 89.74it/s, train_loss=0.00639, val_loss=0.00489]Epoch 20:  79%|███████▊  | 22/28 [00:00<00:00, 90.64it/s, train_loss=0.00639, val_loss=0.00489]Epoch 20:  79%|███████▊  | 22/28 [00:00<00:00, 89.90it/s, train_loss=0.00473, val_loss=0.00489]Epoch 20:  82%|████████▏ | 23/28 [00:00<00:00, 90.45it/s, train_loss=0.00473, val_loss=0.00489]Epoch 20:  82%|████████▏ | 23/28 [00:00<00:00, 89.78it/s, train_loss=0.00412, val_loss=0.00489]Epoch 20:  86%|████████▌ | 24/28 [00:00<00:00, 90.66it/s, train_loss=0.00412, val_loss=0.00489]Epoch 20:  86%|████████▌ | 24/28 [00:00<00:00, 90.00it/s, train_loss=0.00509, val_loss=0.00489]Epoch 20:  89%|████████▉ | 25/28 [00:00<00:00, 90.40it/s, train_loss=0.00509, val_loss=0.00489]Epoch 20:  89%|████████▉ | 25/28 [00:00<00:00, 89.83it/s, train_loss=0.00449, val_loss=0.00489]Epoch 20:  93%|█████████▎| 26/28 [00:00<00:00, 90.64it/s, train_loss=0.00449, val_loss=0.00489]Epoch 20:  93%|█████████▎| 26/28 [00:00<00:00, 90.01it/s, train_loss=0.00475, val_loss=0.00489]Epoch 20:  96%|█████████▋| 27/28 [00:00<00:00, 90.52it/s, train_loss=0.00475, val_loss=0.00489]Epoch 20:  96%|█████████▋| 27/28 [00:00<00:00, 89.84it/s, train_loss=0.00536, val_loss=0.00489]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 90.90it/s, train_loss=0.00536, val_loss=0.00489]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 90.63it/s, train_loss=0.00709, val_loss=0.00489]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 121.69it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 141.68it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 151.02it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 155.53it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 159.38it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 159.48it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 160.88it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 160.78it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 161.37it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 161.49it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 163.92it/s][A
                                                                         [AEpoch 20: 100%|██████████| 28/28 [00:00<00:00, 73.19it/s, train_loss=0.00709, val_loss=0.00479]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 73.07it/s, train_loss=0.00709, val_loss=0.00479]Epoch 20:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00709, val_loss=0.00479]         Epoch 21:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00709, val_loss=0.00479]Epoch 21:   4%|▎         | 1/28 [00:00<00:00, 94.40it/s, train_loss=0.00709, val_loss=0.00479]Epoch 21:   4%|▎         | 1/28 [00:00<00:00, 87.89it/s, train_loss=0.00615, val_loss=0.00479]Epoch 21:   7%|▋         | 2/28 [00:00<00:00, 102.28it/s, train_loss=0.00615, val_loss=0.00479]Epoch 21:   7%|▋         | 2/28 [00:00<00:00, 84.73it/s, train_loss=0.00491, val_loss=0.00479] Epoch 21:  11%|█         | 3/28 [00:00<00:00, 89.30it/s, train_loss=0.00491, val_loss=0.00479]Epoch 21:  11%|█         | 3/28 [00:00<00:00, 86.75it/s, train_loss=0.00457, val_loss=0.00479]Epoch 21:  14%|█▍        | 4/28 [00:00<00:00, 93.35it/s, train_loss=0.00457, val_loss=0.00479]Epoch 21:  14%|█▍        | 4/28 [00:00<00:00, 85.50it/s, train_loss=0.00595, val_loss=0.00479]Epoch 21:  18%|█▊        | 5/28 [00:00<00:00, 87.85it/s, train_loss=0.00595, val_loss=0.00479]Epoch 21:  18%|█▊        | 5/28 [00:00<00:00, 86.39it/s, train_loss=0.00484, val_loss=0.00479]Epoch 21:  21%|██▏       | 6/28 [00:00<00:00, 90.73it/s, train_loss=0.00484, val_loss=0.00479]Epoch 21:  21%|██▏       | 6/28 [00:00<00:00, 88.46it/s, train_loss=0.00561, val_loss=0.00479]Epoch 21:  25%|██▌       | 7/28 [00:00<00:00, 90.05it/s, train_loss=0.00561, val_loss=0.00479]Epoch 21:  25%|██▌       | 7/28 [00:00<00:00, 88.35it/s, train_loss=0.00496, val_loss=0.00479]Epoch 21:  29%|██▊       | 8/28 [00:00<00:00, 91.19it/s, train_loss=0.00496, val_loss=0.00479]Epoch 21:  29%|██▊       | 8/28 [00:00<00:00, 89.18it/s, train_loss=0.00532, val_loss=0.00479]Epoch 21:  32%|███▏      | 9/28 [00:00<00:00, 90.61it/s, train_loss=0.00532, val_loss=0.00479]Epoch 21:  32%|███▏      | 9/28 [00:00<00:00, 88.75it/s, train_loss=0.00656, val_loss=0.00479]Epoch 21:  36%|███▌      | 10/28 [00:00<00:00, 90.87it/s, train_loss=0.00656, val_loss=0.00479]Epoch 21:  36%|███▌      | 10/28 [00:00<00:00, 89.33it/s, train_loss=0.00524, val_loss=0.00479]Epoch 21:  39%|███▉      | 11/28 [00:00<00:00, 90.23it/s, train_loss=0.00524, val_loss=0.00479]Epoch 21:  39%|███▉      | 11/28 [00:00<00:00, 89.02it/s, train_loss=0.00475, val_loss=0.00479]Epoch 21:  43%|████▎     | 12/28 [00:00<00:00, 90.80it/s, train_loss=0.00475, val_loss=0.00479]Epoch 21:  43%|████▎     | 12/28 [00:00<00:00, 89.43it/s, train_loss=0.00474, val_loss=0.00479]Epoch 21:  46%|████▋     | 13/28 [00:00<00:00, 90.24it/s, train_loss=0.00474, val_loss=0.00479]Epoch 21:  46%|████▋     | 13/28 [00:00<00:00, 89.28it/s, train_loss=0.00565, val_loss=0.00479]Epoch 21:  50%|█████     | 14/28 [00:00<00:00, 90.82it/s, train_loss=0.00565, val_loss=0.00479]Epoch 21:  50%|█████     | 14/28 [00:00<00:00, 89.65it/s, train_loss=0.00577, val_loss=0.00479]Epoch 21:  54%|█████▎    | 15/28 [00:00<00:00, 90.33it/s, train_loss=0.00577, val_loss=0.00479]Epoch 21:  54%|█████▎    | 15/28 [00:00<00:00, 89.37it/s, train_loss=0.00461, val_loss=0.00479]Epoch 21:  57%|█████▋    | 16/28 [00:00<00:00, 90.72it/s, train_loss=0.00461, val_loss=0.00479]Epoch 21:  57%|█████▋    | 16/28 [00:00<00:00, 89.73it/s, train_loss=0.00579, val_loss=0.00479]Epoch 21:  61%|██████    | 17/28 [00:00<00:00, 90.48it/s, train_loss=0.00579, val_loss=0.00479]Epoch 21:  61%|██████    | 17/28 [00:00<00:00, 89.35it/s, train_loss=0.00477, val_loss=0.00479]Epoch 21:  64%|██████▍   | 18/28 [00:00<00:00, 90.50it/s, train_loss=0.00477, val_loss=0.00479]Epoch 21:  64%|██████▍   | 18/28 [00:00<00:00, 89.68it/s, train_loss=0.00503, val_loss=0.00479]Epoch 21:  68%|██████▊   | 19/28 [00:00<00:00, 90.41it/s, train_loss=0.00503, val_loss=0.00479]Epoch 21:  68%|██████▊   | 19/28 [00:00<00:00, 89.40it/s, train_loss=0.00497, val_loss=0.00479]Epoch 21:  71%|███████▏  | 20/28 [00:00<00:00, 90.48it/s, train_loss=0.00497, val_loss=0.00479]Epoch 21:  71%|███████▏  | 20/28 [00:00<00:00, 89.79it/s, train_loss=0.00447, val_loss=0.00479]Epoch 21:  75%|███████▌  | 21/28 [00:00<00:00, 90.43it/s, train_loss=0.00447, val_loss=0.00479]Epoch 21:  75%|███████▌  | 21/28 [00:00<00:00, 89.24it/s, train_loss=0.00458, val_loss=0.00479]Epoch 21:  79%|███████▊  | 22/28 [00:00<00:00, 90.08it/s, train_loss=0.00458, val_loss=0.00479]Epoch 21:  79%|███████▊  | 22/28 [00:00<00:00, 89.40it/s, train_loss=0.00525, val_loss=0.00479]Epoch 21:  82%|████████▏ | 23/28 [00:00<00:00, 90.03it/s, train_loss=0.00525, val_loss=0.00479]Epoch 21:  82%|████████▏ | 23/28 [00:00<00:00, 89.23it/s, train_loss=0.00527, val_loss=0.00479]Epoch 21:  86%|████████▌ | 24/28 [00:00<00:00, 90.24it/s, train_loss=0.00527, val_loss=0.00479]Epoch 21:  86%|████████▌ | 24/28 [00:00<00:00, 89.57it/s, train_loss=0.00416, val_loss=0.00479]Epoch 21:  89%|████████▉ | 25/28 [00:00<00:00, 90.33it/s, train_loss=0.00416, val_loss=0.00479]Epoch 21:  89%|████████▉ | 25/28 [00:00<00:00, 89.28it/s, train_loss=0.00464, val_loss=0.00479]Epoch 21:  93%|█████████▎| 26/28 [00:00<00:00, 90.11it/s, train_loss=0.00464, val_loss=0.00479]Epoch 21:  93%|█████████▎| 26/28 [00:00<00:00, 89.54it/s, train_loss=0.00461, val_loss=0.00479]Epoch 21:  96%|█████████▋| 27/28 [00:00<00:00, 90.33it/s, train_loss=0.00461, val_loss=0.00479]Epoch 21:  96%|█████████▋| 27/28 [00:00<00:00, 89.27it/s, train_loss=0.0048, val_loss=0.00479] Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 90.29it/s, train_loss=0.0048, val_loss=0.00479]Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 89.82it/s, train_loss=0.00351, val_loss=0.00479]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 126.23it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 145.91it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 149.90it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 154.15it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 156.89it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 158.81it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 160.10it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 161.47it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 162.31it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 163.10it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 164.08it/s][A
                                                                         [AEpoch 21: 100%|██████████| 28/28 [00:00<00:00, 72.26it/s, train_loss=0.00351, val_loss=0.00455]Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 72.07it/s, train_loss=0.00351, val_loss=0.00455]Epoch 21:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00351, val_loss=0.00455]         Epoch 22:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00351, val_loss=0.00455]Epoch 22:   4%|▎         | 1/28 [00:00<00:00, 96.24it/s, train_loss=0.00351, val_loss=0.00455]Epoch 22:   4%|▎         | 1/28 [00:00<00:00, 80.58it/s, train_loss=0.00513, val_loss=0.00455]Epoch 22:   7%|▋         | 2/28 [00:00<00:00, 94.53it/s, train_loss=0.00513, val_loss=0.00455]Epoch 22:   7%|▋         | 2/28 [00:00<00:00, 87.18it/s, train_loss=0.0044, val_loss=0.00455] Epoch 22:  11%|█         | 3/28 [00:00<00:00, 95.34it/s, train_loss=0.0044, val_loss=0.00455]Epoch 22:  11%|█         | 3/28 [00:00<00:00, 86.92it/s, train_loss=0.00576, val_loss=0.00455]Epoch 22:  14%|█▍        | 4/28 [00:00<00:00, 92.95it/s, train_loss=0.00576, val_loss=0.00455]Epoch 22:  14%|█▍        | 4/28 [00:00<00:00, 89.40it/s, train_loss=0.00473, val_loss=0.00455]Epoch 22:  18%|█▊        | 5/28 [00:00<00:00, 93.15it/s, train_loss=0.00473, val_loss=0.00455]Epoch 22:  18%|█▊        | 5/28 [00:00<00:00, 88.67it/s, train_loss=0.00545, val_loss=0.00455]Epoch 22:  21%|██▏       | 6/28 [00:00<00:00, 92.17it/s, train_loss=0.00545, val_loss=0.00455]Epoch 22:  21%|██▏       | 6/28 [00:00<00:00, 89.58it/s, train_loss=0.0055, val_loss=0.00455] Epoch 22:  25%|██▌       | 7/28 [00:00<00:00, 92.19it/s, train_loss=0.0055, val_loss=0.00455]Epoch 22:  25%|██▌       | 7/28 [00:00<00:00, 89.12it/s, train_loss=0.00654, val_loss=0.00455]Epoch 22:  29%|██▊       | 8/28 [00:00<00:00, 91.99it/s, train_loss=0.00654, val_loss=0.00455]Epoch 22:  29%|██▊       | 8/28 [00:00<00:00, 90.04it/s, train_loss=0.0042, val_loss=0.00455] Epoch 22:  32%|███▏      | 9/28 [00:00<00:00, 92.47it/s, train_loss=0.0042, val_loss=0.00455]Epoch 22:  32%|███▏      | 9/28 [00:00<00:00, 89.18it/s, train_loss=0.00471, val_loss=0.00455]Epoch 22:  36%|███▌      | 10/28 [00:00<00:00, 91.38it/s, train_loss=0.00471, val_loss=0.00455]Epoch 22:  36%|███▌      | 10/28 [00:00<00:00, 89.86it/s, train_loss=0.00494, val_loss=0.00455]Epoch 22:  39%|███▉      | 11/28 [00:00<00:00, 91.71it/s, train_loss=0.00494, val_loss=0.00455]Epoch 22:  39%|███▉      | 11/28 [00:00<00:00, 89.18it/s, train_loss=0.00447, val_loss=0.00455]Epoch 22:  43%|████▎     | 12/28 [00:00<00:00, 90.98it/s, train_loss=0.00447, val_loss=0.00455]Epoch 22:  43%|████▎     | 12/28 [00:00<00:00, 89.68it/s, train_loss=0.00513, val_loss=0.00455]Epoch 22:  46%|████▋     | 13/28 [00:00<00:00, 91.00it/s, train_loss=0.00513, val_loss=0.00455]Epoch 22:  46%|████▋     | 13/28 [00:00<00:00, 89.38it/s, train_loss=0.00391, val_loss=0.00455]Epoch 22:  50%|█████     | 14/28 [00:00<00:00, 90.84it/s, train_loss=0.00391, val_loss=0.00455]Epoch 22:  50%|█████     | 14/28 [00:00<00:00, 89.80it/s, train_loss=0.00447, val_loss=0.00455]Epoch 22:  54%|█████▎    | 15/28 [00:00<00:00, 90.87it/s, train_loss=0.00447, val_loss=0.00455]Epoch 22:  54%|█████▎    | 15/28 [00:00<00:00, 89.50it/s, train_loss=0.00444, val_loss=0.00455]Epoch 22:  57%|█████▋    | 16/28 [00:00<00:00, 90.76it/s, train_loss=0.00444, val_loss=0.00455]Epoch 22:  57%|█████▋    | 16/28 [00:00<00:00, 89.80it/s, train_loss=0.00584, val_loss=0.00455]Epoch 22:  61%|██████    | 17/28 [00:00<00:00, 90.79it/s, train_loss=0.00584, val_loss=0.00455]Epoch 22:  61%|██████    | 17/28 [00:00<00:00, 89.59it/s, train_loss=0.00529, val_loss=0.00455]Epoch 22:  64%|██████▍   | 18/28 [00:00<00:00, 90.66it/s, train_loss=0.00529, val_loss=0.00455]Epoch 22:  64%|██████▍   | 18/28 [00:00<00:00, 89.86it/s, train_loss=0.00516, val_loss=0.00455]Epoch 22:  68%|██████▊   | 19/28 [00:00<00:00, 90.37it/s, train_loss=0.00516, val_loss=0.00455]Epoch 22:  68%|██████▊   | 19/28 [00:00<00:00, 89.64it/s, train_loss=0.00561, val_loss=0.00455]Epoch 22:  71%|███████▏  | 20/28 [00:00<00:00, 90.67it/s, train_loss=0.00561, val_loss=0.00455]Epoch 22:  71%|███████▏  | 20/28 [00:00<00:00, 89.84it/s, train_loss=0.00498, val_loss=0.00455]Epoch 22:  75%|███████▌  | 21/28 [00:00<00:00, 90.46it/s, train_loss=0.00498, val_loss=0.00455]Epoch 22:  75%|███████▌  | 21/28 [00:00<00:00, 89.67it/s, train_loss=0.00492, val_loss=0.00455]Epoch 22:  79%|███████▊  | 22/28 [00:00<00:00, 90.74it/s, train_loss=0.00492, val_loss=0.00455]Epoch 22:  79%|███████▊  | 22/28 [00:00<00:00, 90.06it/s, train_loss=0.00566, val_loss=0.00455]Epoch 22:  82%|████████▏ | 23/28 [00:00<00:00, 90.93it/s, train_loss=0.00566, val_loss=0.00455]Epoch 22:  82%|████████▏ | 23/28 [00:00<00:00, 89.65it/s, train_loss=0.00446, val_loss=0.00455]Epoch 22:  86%|████████▌ | 24/28 [00:00<00:00, 90.49it/s, train_loss=0.00446, val_loss=0.00455]Epoch 22:  86%|████████▌ | 24/28 [00:00<00:00, 89.88it/s, train_loss=0.00423, val_loss=0.00455]Epoch 22:  89%|████████▉ | 25/28 [00:00<00:00, 90.56it/s, train_loss=0.00423, val_loss=0.00455]Epoch 22:  89%|████████▉ | 25/28 [00:00<00:00, 89.61it/s, train_loss=0.00399, val_loss=0.00455]Epoch 22:  93%|█████████▎| 26/28 [00:00<00:00, 90.38it/s, train_loss=0.00399, val_loss=0.00455]Epoch 22:  93%|█████████▎| 26/28 [00:00<00:00, 89.78it/s, train_loss=0.00521, val_loss=0.00455]Epoch 22:  96%|█████████▋| 27/28 [00:00<00:00, 90.24it/s, train_loss=0.00521, val_loss=0.00455]Epoch 22:  96%|█████████▋| 27/28 [00:00<00:00, 89.66it/s, train_loss=0.00493, val_loss=0.00455]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 90.66it/s, train_loss=0.00493, val_loss=0.00455]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 90.41it/s, train_loss=0.0058, val_loss=0.00455] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 138.16it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 162.74it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 170.53it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 160.79it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 166.17it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 169.32it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 169.95it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 171.53it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 173.89it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 175.68it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 176.81it/s][A
                                                                         [AEpoch 22: 100%|██████████| 28/28 [00:00<00:00, 73.10it/s, train_loss=0.0058, val_loss=0.00447]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 72.91it/s, train_loss=0.0058, val_loss=0.00447]Epoch 22:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0058, val_loss=0.00447]         Epoch 23:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0058, val_loss=0.00447]Epoch 23:   4%|▎         | 1/28 [00:00<00:00, 105.12it/s, train_loss=0.0058, val_loss=0.00447]Epoch 23:   4%|▎         | 1/28 [00:00<00:00, 88.35it/s, train_loss=0.00463, val_loss=0.00447]Epoch 23:   7%|▋         | 2/28 [00:00<00:00, 96.91it/s, train_loss=0.00463, val_loss=0.00447]Epoch 23:   7%|▋         | 2/28 [00:00<00:00, 84.00it/s, train_loss=0.00476, val_loss=0.00447]Epoch 23:  11%|█         | 3/28 [00:00<00:00, 88.13it/s, train_loss=0.00476, val_loss=0.00447]Epoch 23:  11%|█         | 3/28 [00:00<00:00, 83.26it/s, train_loss=0.00548, val_loss=0.00447]Epoch 23:  14%|█▍        | 4/28 [00:00<00:00, 86.92it/s, train_loss=0.00548, val_loss=0.00447]Epoch 23:  14%|█▍        | 4/28 [00:00<00:00, 84.42it/s, train_loss=0.00528, val_loss=0.00447]Epoch 23:  18%|█▊        | 5/28 [00:00<00:00, 89.94it/s, train_loss=0.00528, val_loss=0.00447]Epoch 23:  18%|█▊        | 5/28 [00:00<00:00, 87.14it/s, train_loss=0.00345, val_loss=0.00447]Epoch 23:  21%|██▏       | 6/28 [00:00<00:00, 90.72it/s, train_loss=0.00345, val_loss=0.00447]Epoch 23:  21%|██▏       | 6/28 [00:00<00:00, 86.47it/s, train_loss=0.00459, val_loss=0.00447]Epoch 23:  25%|██▌       | 7/28 [00:00<00:00, 90.26it/s, train_loss=0.00459, val_loss=0.00447]Epoch 23:  25%|██▌       | 7/28 [00:00<00:00, 88.25it/s, train_loss=0.00398, val_loss=0.00447]Epoch 23:  29%|██▊       | 8/28 [00:00<00:00, 91.05it/s, train_loss=0.00398, val_loss=0.00447]Epoch 23:  29%|██▊       | 8/28 [00:00<00:00, 87.32it/s, train_loss=0.00546, val_loss=0.00447]Epoch 23:  32%|███▏      | 9/28 [00:00<00:00, 90.07it/s, train_loss=0.00546, val_loss=0.00447]Epoch 23:  32%|███▏      | 9/28 [00:00<00:00, 88.45it/s, train_loss=0.00408, val_loss=0.00447]Epoch 23:  36%|███▌      | 10/28 [00:00<00:00, 89.99it/s, train_loss=0.00408, val_loss=0.00447]Epoch 23:  36%|███▌      | 10/28 [00:00<00:00, 87.87it/s, train_loss=0.00619, val_loss=0.00447]Epoch 23:  39%|███▉      | 11/28 [00:00<00:00, 90.16it/s, train_loss=0.00619, val_loss=0.00447]Epoch 23:  39%|███▉      | 11/28 [00:00<00:00, 88.73it/s, train_loss=0.0047, val_loss=0.00447] Epoch 23:  43%|████▎     | 12/28 [00:00<00:00, 90.01it/s, train_loss=0.0047, val_loss=0.00447]Epoch 23:  43%|████▎     | 12/28 [00:00<00:00, 88.20it/s, train_loss=0.0059, val_loss=0.00447]Epoch 23:  46%|████▋     | 13/28 [00:00<00:00, 90.10it/s, train_loss=0.0059, val_loss=0.00447]Epoch 23:  46%|████▋     | 13/28 [00:00<00:00, 88.89it/s, train_loss=0.00389, val_loss=0.00447]Epoch 23:  50%|█████     | 14/28 [00:00<00:00, 90.14it/s, train_loss=0.00389, val_loss=0.00447]Epoch 23:  50%|█████     | 14/28 [00:00<00:00, 88.36it/s, train_loss=0.00451, val_loss=0.00447]Epoch 23:  54%|█████▎    | 15/28 [00:00<00:00, 89.92it/s, train_loss=0.00451, val_loss=0.00447]Epoch 23:  54%|█████▎    | 15/28 [00:00<00:00, 88.89it/s, train_loss=0.00548, val_loss=0.00447]Epoch 23:  57%|█████▋    | 16/28 [00:00<00:00, 90.04it/s, train_loss=0.00548, val_loss=0.00447]Epoch 23:  57%|█████▋    | 16/28 [00:00<00:00, 88.47it/s, train_loss=0.00443, val_loss=0.00447]Epoch 23:  61%|██████    | 17/28 [00:00<00:00, 89.64it/s, train_loss=0.00443, val_loss=0.00447]Epoch 23:  61%|██████    | 17/28 [00:00<00:00, 88.74it/s, train_loss=0.00511, val_loss=0.00447]Epoch 23:  64%|██████▍   | 18/28 [00:00<00:00, 89.37it/s, train_loss=0.00511, val_loss=0.00447]Epoch 23:  64%|██████▍   | 18/28 [00:00<00:00, 88.68it/s, train_loss=0.00544, val_loss=0.00447]Epoch 23:  68%|██████▊   | 19/28 [00:00<00:00, 89.86it/s, train_loss=0.00544, val_loss=0.00447]Epoch 23:  68%|██████▊   | 19/28 [00:00<00:00, 89.09it/s, train_loss=0.00425, val_loss=0.00447]Epoch 23:  71%|███████▏  | 20/28 [00:00<00:00, 89.61it/s, train_loss=0.00425, val_loss=0.00447]Epoch 23:  71%|███████▏  | 20/28 [00:00<00:00, 88.91it/s, train_loss=0.00586, val_loss=0.00447]Epoch 23:  75%|███████▌  | 21/28 [00:00<00:00, 89.94it/s, train_loss=0.00586, val_loss=0.00447]Epoch 23:  75%|███████▌  | 21/28 [00:00<00:00, 89.16it/s, train_loss=0.00467, val_loss=0.00447]Epoch 23:  79%|███████▊  | 22/28 [00:00<00:00, 89.71it/s, train_loss=0.00467, val_loss=0.00447]Epoch 23:  79%|███████▊  | 22/28 [00:00<00:00, 89.05it/s, train_loss=0.00532, val_loss=0.00447]Epoch 23:  82%|████████▏ | 23/28 [00:00<00:00, 90.01it/s, train_loss=0.00532, val_loss=0.00447]Epoch 23:  82%|████████▏ | 23/28 [00:00<00:00, 89.31it/s, train_loss=0.00583, val_loss=0.00447]Epoch 23:  86%|████████▌ | 24/28 [00:00<00:00, 89.93it/s, train_loss=0.00583, val_loss=0.00447]Epoch 23:  86%|████████▌ | 24/28 [00:00<00:00, 89.19it/s, train_loss=0.00439, val_loss=0.00447]Epoch 23:  89%|████████▉ | 25/28 [00:00<00:00, 90.08it/s, train_loss=0.00439, val_loss=0.00447]Epoch 23:  89%|████████▉ | 25/28 [00:00<00:00, 89.49it/s, train_loss=0.00531, val_loss=0.00447]Epoch 23:  93%|█████████▎| 26/28 [00:00<00:00, 90.21it/s, train_loss=0.00531, val_loss=0.00447]Epoch 23:  93%|█████████▎| 26/28 [00:00<00:00, 89.29it/s, train_loss=0.00434, val_loss=0.00447]Epoch 23:  96%|█████████▋| 27/28 [00:00<00:00, 90.04it/s, train_loss=0.00434, val_loss=0.00447]Epoch 23:  96%|█████████▋| 27/28 [00:00<00:00, 89.49it/s, train_loss=0.00427, val_loss=0.00447]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 90.36it/s, train_loss=0.00427, val_loss=0.00447]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 90.14it/s, train_loss=0.00467, val_loss=0.00447]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 146.37it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 164.98it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 168.82it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 173.73it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 177.62it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 178.77it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 179.90it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 178.36it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 178.52it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 177.96it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 178.52it/s][A
                                                                         [AEpoch 23: 100%|██████████| 28/28 [00:00<00:00, 73.84it/s, train_loss=0.00467, val_loss=0.0044] Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 73.65it/s, train_loss=0.00467, val_loss=0.0044]Epoch 23:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00467, val_loss=0.0044]         Epoch 24:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00467, val_loss=0.0044]Epoch 24:   4%|▎         | 1/28 [00:00<00:00, 91.25it/s, train_loss=0.00467, val_loss=0.0044]Epoch 24:   4%|▎         | 1/28 [00:00<00:00, 84.17it/s, train_loss=0.00415, val_loss=0.0044]Epoch 24:   7%|▋         | 2/28 [00:00<00:00, 92.28it/s, train_loss=0.00415, val_loss=0.0044]Epoch 24:   7%|▋         | 2/28 [00:00<00:00, 88.71it/s, train_loss=0.00477, val_loss=0.0044]Epoch 24:  11%|█         | 3/28 [00:00<00:00, 94.05it/s, train_loss=0.00477, val_loss=0.0044]Epoch 24:  11%|█         | 3/28 [00:00<00:00, 89.49it/s, train_loss=0.00541, val_loss=0.0044]Epoch 24:  14%|█▍        | 4/28 [00:00<00:00, 91.71it/s, train_loss=0.00541, val_loss=0.0044]Epoch 24:  14%|█▍        | 4/28 [00:00<00:00, 88.94it/s, train_loss=0.00564, val_loss=0.0044]Epoch 24:  18%|█▊        | 5/28 [00:00<00:00, 92.87it/s, train_loss=0.00564, val_loss=0.0044]Epoch 24:  18%|█▊        | 5/28 [00:00<00:00, 90.03it/s, train_loss=0.00383, val_loss=0.0044]Epoch 24:  21%|██▏       | 6/28 [00:00<00:00, 91.44it/s, train_loss=0.00383, val_loss=0.0044]Epoch 24:  21%|██▏       | 6/28 [00:00<00:00, 89.42it/s, train_loss=0.00456, val_loss=0.0044]Epoch 24:  25%|██▌       | 7/28 [00:00<00:00, 92.76it/s, train_loss=0.00456, val_loss=0.0044]Epoch 24:  25%|██▌       | 7/28 [00:00<00:00, 90.61it/s, train_loss=0.00495, val_loss=0.0044]Epoch 24:  29%|██▊       | 8/28 [00:00<00:00, 92.00it/s, train_loss=0.00495, val_loss=0.0044]Epoch 24:  29%|██▊       | 8/28 [00:00<00:00, 89.78it/s, train_loss=0.00476, val_loss=0.0044]Epoch 24:  32%|███▏      | 9/28 [00:00<00:00, 92.19it/s, train_loss=0.00476, val_loss=0.0044]Epoch 24:  32%|███▏      | 9/28 [00:00<00:00, 90.57it/s, train_loss=0.00414, val_loss=0.0044]Epoch 24:  36%|███▌      | 10/28 [00:00<00:00, 92.61it/s, train_loss=0.00414, val_loss=0.0044]Epoch 24:  36%|███▌      | 10/28 [00:00<00:00, 89.87it/s, train_loss=0.00507, val_loss=0.0044]Epoch 24:  39%|███▉      | 11/28 [00:00<00:00, 91.76it/s, train_loss=0.00507, val_loss=0.0044]Epoch 24:  39%|███▉      | 11/28 [00:00<00:00, 90.33it/s, train_loss=0.0042, val_loss=0.0044] Epoch 24:  43%|████▎     | 12/28 [00:00<00:00, 91.06it/s, train_loss=0.0042, val_loss=0.0044]Epoch 24:  43%|████▎     | 12/28 [00:00<00:00, 89.89it/s, train_loss=0.00458, val_loss=0.0044]Epoch 24:  46%|████▋     | 13/28 [00:00<00:00, 91.49it/s, train_loss=0.00458, val_loss=0.0044]Epoch 24:  46%|████▋     | 13/28 [00:00<00:00, 90.35it/s, train_loss=0.00517, val_loss=0.0044]Epoch 24:  50%|█████     | 14/28 [00:00<00:00, 91.25it/s, train_loss=0.00517, val_loss=0.0044]Epoch 24:  50%|█████     | 14/28 [00:00<00:00, 89.99it/s, train_loss=0.00392, val_loss=0.0044]Epoch 24:  54%|█████▎    | 15/28 [00:00<00:00, 91.37it/s, train_loss=0.00392, val_loss=0.0044]Epoch 24:  54%|█████▎    | 15/28 [00:00<00:00, 90.38it/s, train_loss=0.00465, val_loss=0.0044]Epoch 24:  57%|█████▋    | 16/28 [00:00<00:00, 91.14it/s, train_loss=0.00465, val_loss=0.0044]Epoch 24:  57%|█████▋    | 16/28 [00:00<00:00, 90.08it/s, train_loss=0.00524, val_loss=0.0044]Epoch 24:  61%|██████    | 17/28 [00:00<00:00, 91.29it/s, train_loss=0.00524, val_loss=0.0044]Epoch 24:  61%|██████    | 17/28 [00:00<00:00, 90.38it/s, train_loss=0.00491, val_loss=0.0044]Epoch 24:  64%|██████▍   | 18/28 [00:00<00:00, 90.98it/s, train_loss=0.00491, val_loss=0.0044]Epoch 24:  64%|██████▍   | 18/28 [00:00<00:00, 90.15it/s, train_loss=0.00449, val_loss=0.0044]Epoch 24:  68%|██████▊   | 19/28 [00:00<00:00, 91.20it/s, train_loss=0.00449, val_loss=0.0044]Epoch 24:  68%|██████▊   | 19/28 [00:00<00:00, 90.37it/s, train_loss=0.00405, val_loss=0.0044]Epoch 24:  71%|███████▏  | 20/28 [00:00<00:00, 90.78it/s, train_loss=0.00405, val_loss=0.0044]Epoch 24:  71%|███████▏  | 20/28 [00:00<00:00, 90.17it/s, train_loss=0.00493, val_loss=0.0044]Epoch 24:  75%|███████▌  | 21/28 [00:00<00:00, 91.20it/s, train_loss=0.00493, val_loss=0.0044]Epoch 24:  75%|███████▌  | 21/28 [00:00<00:00, 90.47it/s, train_loss=0.00541, val_loss=0.0044]Epoch 24:  79%|███████▊  | 22/28 [00:00<00:00, 91.03it/s, train_loss=0.00541, val_loss=0.0044]Epoch 24:  79%|███████▊  | 22/28 [00:00<00:00, 90.23it/s, train_loss=0.0043, val_loss=0.0044] Epoch 24:  82%|████████▏ | 23/28 [00:00<00:00, 91.21it/s, train_loss=0.0043, val_loss=0.0044]Epoch 24:  82%|████████▏ | 23/28 [00:00<00:00, 90.51it/s, train_loss=0.00478, val_loss=0.0044]Epoch 24:  86%|████████▌ | 24/28 [00:00<00:00, 90.98it/s, train_loss=0.00478, val_loss=0.0044]Epoch 24:  86%|████████▌ | 24/28 [00:00<00:00, 90.30it/s, train_loss=0.0048, val_loss=0.0044] Epoch 24:  89%|████████▉ | 25/28 [00:00<00:00, 91.16it/s, train_loss=0.0048, val_loss=0.0044]Epoch 24:  89%|████████▉ | 25/28 [00:00<00:00, 90.54it/s, train_loss=0.0047, val_loss=0.0044]Epoch 24:  93%|█████████▎| 26/28 [00:00<00:00, 90.88it/s, train_loss=0.0047, val_loss=0.0044]Epoch 24:  93%|█████████▎| 26/28 [00:00<00:00, 90.33it/s, train_loss=0.00553, val_loss=0.0044]Epoch 24:  96%|█████████▋| 27/28 [00:00<00:00, 91.19it/s, train_loss=0.00553, val_loss=0.0044]Epoch 24:  96%|█████████▋| 27/28 [00:00<00:00, 90.64it/s, train_loss=0.00459, val_loss=0.0044]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 91.64it/s, train_loss=0.00459, val_loss=0.0044]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 91.45it/s, train_loss=0.00298, val_loss=0.0044]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 158.11it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 176.91it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 183.13it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 185.73it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 187.68it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 186.95it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 187.58it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 188.12it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 186.65it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 186.57it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 187.33it/s][A
                                                                         [AEpoch 24: 100%|██████████| 28/28 [00:00<00:00, 75.42it/s, train_loss=0.00298, val_loss=0.00429]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 75.25it/s, train_loss=0.00298, val_loss=0.00429]Epoch 24:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00429]         Epoch 25:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00429]Epoch 25:   4%|▎         | 1/28 [00:00<00:00, 90.00it/s, train_loss=0.00298, val_loss=0.00429]Epoch 25:   4%|▎         | 1/28 [00:00<00:00, 83.78it/s, train_loss=0.00526, val_loss=0.00429]Epoch 25:   7%|▋         | 2/28 [00:00<00:00, 97.22it/s, train_loss=0.00526, val_loss=0.00429]Epoch 25:   7%|▋         | 2/28 [00:00<00:00, 89.41it/s, train_loss=0.00401, val_loss=0.00429]Epoch 25:  11%|█         | 3/28 [00:00<00:00, 91.98it/s, train_loss=0.00401, val_loss=0.00429]Epoch 25:  11%|█         | 3/28 [00:00<00:00, 89.69it/s, train_loss=0.00405, val_loss=0.00429]Epoch 25:  14%|█▍        | 4/28 [00:00<00:00, 94.44it/s, train_loss=0.00405, val_loss=0.00429]Epoch 25:  14%|█▍        | 4/28 [00:00<00:00, 90.78it/s, train_loss=0.00454, val_loss=0.00429]Epoch 25:  18%|█▊        | 5/28 [00:00<00:00, 92.79it/s, train_loss=0.00454, val_loss=0.00429]Epoch 25:  18%|█▊        | 5/28 [00:00<00:00, 90.85it/s, train_loss=0.00492, val_loss=0.00429]Epoch 25:  21%|██▏       | 6/28 [00:00<00:00, 94.48it/s, train_loss=0.00492, val_loss=0.00429]Epoch 25:  21%|██▏       | 6/28 [00:00<00:00, 91.57it/s, train_loss=0.00475, val_loss=0.00429]Epoch 25:  25%|██▌       | 7/28 [00:00<00:00, 92.94it/s, train_loss=0.00475, val_loss=0.00429]Epoch 25:  25%|██▌       | 7/28 [00:00<00:00, 90.78it/s, train_loss=0.0049, val_loss=0.00429] Epoch 25:  29%|██▊       | 8/28 [00:00<00:00, 93.17it/s, train_loss=0.0049, val_loss=0.00429]Epoch 25:  29%|██▊       | 8/28 [00:00<00:00, 91.25it/s, train_loss=0.00546, val_loss=0.00429]Epoch 25:  32%|███▏      | 9/28 [00:00<00:00, 92.10it/s, train_loss=0.00546, val_loss=0.00429]Epoch 25:  32%|███▏      | 9/28 [00:00<00:00, 90.66it/s, train_loss=0.00438, val_loss=0.00429]Epoch 25:  36%|███▌      | 10/28 [00:00<00:00, 92.62it/s, train_loss=0.00438, val_loss=0.00429]Epoch 25:  36%|███▌      | 10/28 [00:00<00:00, 90.99it/s, train_loss=0.00429, val_loss=0.00429]Epoch 25:  39%|███▉      | 11/28 [00:00<00:00, 91.98it/s, train_loss=0.00429, val_loss=0.00429]Epoch 25:  39%|███▉      | 11/28 [00:00<00:00, 90.56it/s, train_loss=0.00456, val_loss=0.00429]Epoch 25:  43%|████▎     | 12/28 [00:00<00:00, 92.47it/s, train_loss=0.00456, val_loss=0.00429]Epoch 25:  43%|████▎     | 12/28 [00:00<00:00, 91.10it/s, train_loss=0.00527, val_loss=0.00429]Epoch 25:  46%|████▋     | 13/28 [00:00<00:00, 92.38it/s, train_loss=0.00527, val_loss=0.00429]Epoch 25:  46%|████▋     | 13/28 [00:00<00:00, 90.57it/s, train_loss=0.00474, val_loss=0.00429]Epoch 25:  50%|█████     | 14/28 [00:00<00:00, 92.18it/s, train_loss=0.00474, val_loss=0.00429]Epoch 25:  50%|█████     | 14/28 [00:00<00:00, 91.04it/s, train_loss=0.00464, val_loss=0.00429]Epoch 25:  54%|█████▎    | 15/28 [00:00<00:00, 91.96it/s, train_loss=0.00464, val_loss=0.00429]Epoch 25:  54%|█████▎    | 15/28 [00:00<00:00, 90.68it/s, train_loss=0.00512, val_loss=0.00429]Epoch 25:  57%|█████▋    | 16/28 [00:00<00:00, 91.98it/s, train_loss=0.00512, val_loss=0.00429]Epoch 25:  57%|█████▋    | 16/28 [00:00<00:00, 91.03it/s, train_loss=0.00458, val_loss=0.00429]Epoch 25:  61%|██████    | 17/28 [00:00<00:00, 90.58it/s, train_loss=0.00458, val_loss=0.00429]Epoch 25:  61%|██████    | 17/28 [00:00<00:00, 90.19it/s, train_loss=0.00499, val_loss=0.00429]Epoch 25:  64%|██████▍   | 18/28 [00:00<00:00, 91.45it/s, train_loss=0.00499, val_loss=0.00429]Epoch 25:  64%|██████▍   | 18/28 [00:00<00:00, 90.65it/s, train_loss=0.00466, val_loss=0.00429]Epoch 25:  68%|██████▊   | 19/28 [00:00<00:00, 91.23it/s, train_loss=0.00466, val_loss=0.00429]Epoch 25:  68%|██████▊   | 19/28 [00:00<00:00, 90.49it/s, train_loss=0.00437, val_loss=0.00429]Epoch 25:  71%|███████▏  | 20/28 [00:00<00:00, 91.60it/s, train_loss=0.00437, val_loss=0.00429]Epoch 25:  71%|███████▏  | 20/28 [00:00<00:00, 90.81it/s, train_loss=0.00506, val_loss=0.00429]Epoch 25:  75%|███████▌  | 21/28 [00:00<00:00, 91.32it/s, train_loss=0.00506, val_loss=0.00429]Epoch 25:  75%|███████▌  | 21/28 [00:00<00:00, 90.56it/s, train_loss=0.00495, val_loss=0.00429]Epoch 25:  79%|███████▊  | 22/28 [00:00<00:00, 91.55it/s, train_loss=0.00495, val_loss=0.00429]Epoch 25:  79%|███████▊  | 22/28 [00:00<00:00, 90.84it/s, train_loss=0.00412, val_loss=0.00429]Epoch 25:  82%|████████▏ | 23/28 [00:00<00:00, 91.32it/s, train_loss=0.00412, val_loss=0.00429]Epoch 25:  82%|████████▏ | 23/28 [00:00<00:00, 90.61it/s, train_loss=0.00496, val_loss=0.00429]Epoch 25:  86%|████████▌ | 24/28 [00:00<00:00, 91.36it/s, train_loss=0.00496, val_loss=0.00429]Epoch 25:  86%|████████▌ | 24/28 [00:00<00:00, 90.77it/s, train_loss=0.00413, val_loss=0.00429]Epoch 25:  89%|████████▉ | 25/28 [00:00<00:00, 91.02it/s, train_loss=0.00413, val_loss=0.00429]Epoch 25:  89%|████████▉ | 25/28 [00:00<00:00, 90.58it/s, train_loss=0.00404, val_loss=0.00429]Epoch 25:  93%|█████████▎| 26/28 [00:00<00:00, 91.21it/s, train_loss=0.00404, val_loss=0.00429]Epoch 25:  93%|█████████▎| 26/28 [00:00<00:00, 90.64it/s, train_loss=0.00419, val_loss=0.00429]Epoch 25:  96%|█████████▋| 27/28 [00:00<00:00, 90.88it/s, train_loss=0.00419, val_loss=0.00429]Epoch 25:  96%|█████████▋| 27/28 [00:00<00:00, 90.53it/s, train_loss=0.00364, val_loss=0.00429]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 91.47it/s, train_loss=0.00364, val_loss=0.00429]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 91.15it/s, train_loss=0.0036, val_loss=0.00429] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 184.00it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 184.60it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 190.87it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 195.47it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 196.09it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 197.83it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 198.35it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 198.49it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 198.49it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 198.25it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 198.55it/s][A
                                                                         [AEpoch 25: 100%|██████████| 28/28 [00:00<00:00, 75.97it/s, train_loss=0.0036, val_loss=0.00424]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 75.80it/s, train_loss=0.0036, val_loss=0.00424]Epoch 25:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0036, val_loss=0.00424]         Epoch 26:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0036, val_loss=0.00424]Epoch 26:   4%|▎         | 1/28 [00:00<00:00, 91.22it/s, train_loss=0.0036, val_loss=0.00424]Epoch 26:   4%|▎         | 1/28 [00:00<00:00, 84.90it/s, train_loss=0.00456, val_loss=0.00424]Epoch 26:   7%|▋         | 2/28 [00:00<00:00, 99.35it/s, train_loss=0.00456, val_loss=0.00424]Epoch 26:   7%|▋         | 2/28 [00:00<00:00, 91.08it/s, train_loss=0.00457, val_loss=0.00424]Epoch 26:  11%|█         | 3/28 [00:00<00:00, 94.68it/s, train_loss=0.00457, val_loss=0.00424]Epoch 26:  11%|█         | 3/28 [00:00<00:00, 90.00it/s, train_loss=0.00446, val_loss=0.00424]Epoch 26:  14%|█▍        | 4/28 [00:00<00:00, 95.36it/s, train_loss=0.00446, val_loss=0.00424]Epoch 26:  14%|█▍        | 4/28 [00:00<00:00, 91.33it/s, train_loss=0.00517, val_loss=0.00424]Epoch 26:  18%|█▊        | 5/28 [00:00<00:00, 93.67it/s, train_loss=0.00517, val_loss=0.00424]Epoch 26:  18%|█▊        | 5/28 [00:00<00:00, 90.35it/s, train_loss=0.00619, val_loss=0.00424]Epoch 26:  21%|██▏       | 6/28 [00:00<00:00, 94.07it/s, train_loss=0.00619, val_loss=0.00424]Epoch 26:  21%|██▏       | 6/28 [00:00<00:00, 91.46it/s, train_loss=0.00576, val_loss=0.00424]Epoch 26:  25%|██▌       | 7/28 [00:00<00:00, 93.04it/s, train_loss=0.00576, val_loss=0.00424]Epoch 26:  25%|██▌       | 7/28 [00:00<00:00, 90.61it/s, train_loss=0.00497, val_loss=0.00424]Epoch 26:  29%|██▊       | 8/28 [00:00<00:00, 93.31it/s, train_loss=0.00497, val_loss=0.00424]Epoch 26:  29%|██▊       | 8/28 [00:00<00:00, 91.16it/s, train_loss=0.00433, val_loss=0.00424]Epoch 26:  32%|███▏      | 9/28 [00:00<00:00, 92.47it/s, train_loss=0.00433, val_loss=0.00424]Epoch 26:  32%|███▏      | 9/28 [00:00<00:00, 90.62it/s, train_loss=0.00483, val_loss=0.00424]Epoch 26:  36%|███▌      | 10/28 [00:00<00:00, 92.75it/s, train_loss=0.00483, val_loss=0.00424]Epoch 26:  36%|███▌      | 10/28 [00:00<00:00, 91.22it/s, train_loss=0.00393, val_loss=0.00424]Epoch 26:  39%|███▉      | 11/28 [00:00<00:00, 92.13it/s, train_loss=0.00393, val_loss=0.00424]Epoch 26:  39%|███▉      | 11/28 [00:00<00:00, 90.66it/s, train_loss=0.00412, val_loss=0.00424]Epoch 26:  43%|████▎     | 12/28 [00:00<00:00, 92.33it/s, train_loss=0.00412, val_loss=0.00424]Epoch 26:  43%|████▎     | 12/28 [00:00<00:00, 90.96it/s, train_loss=0.00385, val_loss=0.00424]Epoch 26:  46%|████▋     | 13/28 [00:00<00:00, 92.42it/s, train_loss=0.00385, val_loss=0.00424]Epoch 26:  46%|████▋     | 13/28 [00:00<00:00, 90.48it/s, train_loss=0.00452, val_loss=0.00424]Epoch 26:  50%|█████     | 14/28 [00:00<00:00, 91.90it/s, train_loss=0.00452, val_loss=0.00424]Epoch 26:  50%|█████     | 14/28 [00:00<00:00, 90.87it/s, train_loss=0.00446, val_loss=0.00424]Epoch 26:  54%|█████▎    | 15/28 [00:00<00:00, 91.86it/s, train_loss=0.00446, val_loss=0.00424]Epoch 26:  54%|█████▎    | 15/28 [00:00<00:00, 90.25it/s, train_loss=0.00374, val_loss=0.00424]Epoch 26:  57%|█████▋    | 16/28 [00:00<00:00, 91.46it/s, train_loss=0.00374, val_loss=0.00424]Epoch 26:  57%|█████▋    | 16/28 [00:00<00:00, 90.53it/s, train_loss=0.0041, val_loss=0.00424] Epoch 26:  61%|██████    | 17/28 [00:00<00:00, 91.22it/s, train_loss=0.0041, val_loss=0.00424]Epoch 26:  61%|██████    | 17/28 [00:00<00:00, 90.26it/s, train_loss=0.00506, val_loss=0.00424]Epoch 26:  64%|██████▍   | 18/28 [00:00<00:00, 91.46it/s, train_loss=0.00506, val_loss=0.00424]Epoch 26:  64%|██████▍   | 18/28 [00:00<00:00, 90.59it/s, train_loss=0.00463, val_loss=0.00424]Epoch 26:  68%|██████▊   | 19/28 [00:00<00:00, 91.26it/s, train_loss=0.00463, val_loss=0.00424]Epoch 26:  68%|██████▊   | 19/28 [00:00<00:00, 90.31it/s, train_loss=0.00488, val_loss=0.00424]Epoch 26:  71%|███████▏  | 20/28 [00:00<00:00, 91.37it/s, train_loss=0.00488, val_loss=0.00424]Epoch 26:  71%|███████▏  | 20/28 [00:00<00:00, 90.62it/s, train_loss=0.0046, val_loss=0.00424] Epoch 26:  75%|███████▌  | 21/28 [00:00<00:00, 91.14it/s, train_loss=0.0046, val_loss=0.00424]Epoch 26:  75%|███████▌  | 21/28 [00:00<00:00, 90.37it/s, train_loss=0.00387, val_loss=0.00424]Epoch 26:  79%|███████▊  | 22/28 [00:00<00:00, 91.28it/s, train_loss=0.00387, val_loss=0.00424]Epoch 26:  79%|███████▊  | 22/28 [00:00<00:00, 90.58it/s, train_loss=0.0043, val_loss=0.00424] Epoch 26:  82%|████████▏ | 23/28 [00:00<00:00, 91.07it/s, train_loss=0.0043, val_loss=0.00424]Epoch 26:  82%|████████▏ | 23/28 [00:00<00:00, 90.40it/s, train_loss=0.00442, val_loss=0.00424]Epoch 26:  86%|████████▌ | 24/28 [00:00<00:00, 91.29it/s, train_loss=0.00442, val_loss=0.00424]Epoch 26:  86%|████████▌ | 24/28 [00:00<00:00, 90.66it/s, train_loss=0.00367, val_loss=0.00424]Epoch 26:  89%|████████▉ | 25/28 [00:00<00:00, 91.11it/s, train_loss=0.00367, val_loss=0.00424]Epoch 26:  89%|████████▉ | 25/28 [00:00<00:00, 90.46it/s, train_loss=0.00477, val_loss=0.00424]Epoch 26:  93%|█████████▎| 26/28 [00:00<00:00, 91.29it/s, train_loss=0.00477, val_loss=0.00424]Epoch 26:  93%|█████████▎| 26/28 [00:00<00:00, 90.70it/s, train_loss=0.00487, val_loss=0.00424]Epoch 26:  96%|█████████▋| 27/28 [00:00<00:00, 91.07it/s, train_loss=0.00487, val_loss=0.00424]Epoch 26:  96%|█████████▋| 27/28 [00:00<00:00, 90.51it/s, train_loss=0.00426, val_loss=0.00424]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 91.47it/s, train_loss=0.00426, val_loss=0.00424]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 91.15it/s, train_loss=0.00605, val_loss=0.00424]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 118.07it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 127.24it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 134.48it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 146.27it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 158.08it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 165.38it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 170.83it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 177.06it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 181.04it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 182.66it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 184.81it/s][A
                                                                         [AEpoch 26: 100%|██████████| 28/28 [00:00<00:00, 74.88it/s, train_loss=0.00605, val_loss=0.00418]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 74.74it/s, train_loss=0.00605, val_loss=0.00418]Epoch 26:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00605, val_loss=0.00418]         Epoch 27:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00605, val_loss=0.00418]Epoch 27:   4%|▎         | 1/28 [00:00<00:00, 91.40it/s, train_loss=0.00605, val_loss=0.00418]Epoch 27:   4%|▎         | 1/28 [00:00<00:00, 85.15it/s, train_loss=0.00469, val_loss=0.00418]Epoch 27:   7%|▋         | 2/28 [00:00<00:00, 99.12it/s, train_loss=0.00469, val_loss=0.00418]Epoch 27:   7%|▋         | 2/28 [00:00<00:00, 83.33it/s, train_loss=0.0043, val_loss=0.00418] Epoch 27:  11%|█         | 3/28 [00:00<00:00, 87.35it/s, train_loss=0.0043, val_loss=0.00418]Epoch 27:  11%|█         | 3/28 [00:00<00:00, 85.14it/s, train_loss=0.00522, val_loss=0.00418]Epoch 27:  14%|█▍        | 4/28 [00:00<00:00, 89.17it/s, train_loss=0.00522, val_loss=0.00418]Epoch 27:  14%|█▍        | 4/28 [00:00<00:00, 83.53it/s, train_loss=0.0045, val_loss=0.00418] Epoch 27:  18%|█▊        | 5/28 [00:00<00:00, 87.58it/s, train_loss=0.0045, val_loss=0.00418]Epoch 27:  18%|█▊        | 5/28 [00:00<00:00, 85.18it/s, train_loss=0.00427, val_loss=0.00418]Epoch 27:  21%|██▏       | 6/28 [00:00<00:00, 87.23it/s, train_loss=0.00427, val_loss=0.00418]Epoch 27:  21%|██▏       | 6/28 [00:00<00:00, 85.47it/s, train_loss=0.00417, val_loss=0.00418]Epoch 27:  25%|██▌       | 7/28 [00:00<00:00, 88.99it/s, train_loss=0.00417, val_loss=0.00418]Epoch 27:  25%|██▌       | 7/28 [00:00<00:00, 86.79it/s, train_loss=0.00396, val_loss=0.00418]Epoch 27:  29%|██▊       | 8/28 [00:00<00:00, 88.62it/s, train_loss=0.00396, val_loss=0.00418]Epoch 27:  29%|██▊       | 8/28 [00:00<00:00, 86.78it/s, train_loss=0.00463, val_loss=0.00418]Epoch 27:  32%|███▏      | 9/28 [00:00<00:00, 89.40it/s, train_loss=0.00463, val_loss=0.00418]Epoch 27:  32%|███▏      | 9/28 [00:00<00:00, 87.65it/s, train_loss=0.00481, val_loss=0.00418]Epoch 27:  36%|███▌      | 10/28 [00:00<00:00, 88.99it/s, train_loss=0.00481, val_loss=0.00418]Epoch 27:  36%|███▌      | 10/28 [00:00<00:00, 87.55it/s, train_loss=0.00436, val_loss=0.00418]Epoch 27:  39%|███▉      | 11/28 [00:00<00:00, 89.64it/s, train_loss=0.00436, val_loss=0.00418]Epoch 27:  39%|███▉      | 11/28 [00:00<00:00, 88.19it/s, train_loss=0.00451, val_loss=0.00418]Epoch 27:  43%|████▎     | 12/28 [00:00<00:00, 89.30it/s, train_loss=0.00451, val_loss=0.00418]Epoch 27:  43%|████▎     | 12/28 [00:00<00:00, 88.05it/s, train_loss=0.00488, val_loss=0.00418]Epoch 27:  46%|████▋     | 13/28 [00:00<00:00, 89.68it/s, train_loss=0.00488, val_loss=0.00418]Epoch 27:  46%|████▋     | 13/28 [00:00<00:00, 88.49it/s, train_loss=0.00461, val_loss=0.00418]Epoch 27:  50%|█████     | 14/28 [00:00<00:00, 89.25it/s, train_loss=0.00461, val_loss=0.00418]Epoch 27:  50%|█████     | 14/28 [00:00<00:00, 88.33it/s, train_loss=0.00483, val_loss=0.00418]Epoch 27:  54%|█████▎    | 15/28 [00:00<00:00, 89.66it/s, train_loss=0.00483, val_loss=0.00418]Epoch 27:  54%|█████▎    | 15/28 [00:00<00:00, 88.77it/s, train_loss=0.00427, val_loss=0.00418]Epoch 27:  57%|█████▋    | 16/28 [00:00<00:00, 89.56it/s, train_loss=0.00427, val_loss=0.00418]Epoch 27:  57%|█████▋    | 16/28 [00:00<00:00, 88.61it/s, train_loss=0.0048, val_loss=0.00418] Epoch 27:  61%|██████    | 17/28 [00:00<00:00, 89.93it/s, train_loss=0.0048, val_loss=0.00418]Epoch 27:  61%|██████    | 17/28 [00:00<00:00, 89.08it/s, train_loss=0.00435, val_loss=0.00418]Epoch 27:  64%|██████▍   | 18/28 [00:00<00:00, 89.72it/s, train_loss=0.00435, val_loss=0.00418]Epoch 27:  64%|██████▍   | 18/28 [00:00<00:00, 88.88it/s, train_loss=0.00397, val_loss=0.00418]Epoch 27:  68%|██████▊   | 19/28 [00:00<00:00, 90.12it/s, train_loss=0.00397, val_loss=0.00418]Epoch 27:  68%|██████▊   | 19/28 [00:00<00:00, 89.31it/s, train_loss=0.00392, val_loss=0.00418]Epoch 27:  71%|███████▏  | 20/28 [00:00<00:00, 90.13it/s, train_loss=0.00392, val_loss=0.00418]Epoch 27:  71%|███████▏  | 20/28 [00:00<00:00, 89.13it/s, train_loss=0.00463, val_loss=0.00418]Epoch 27:  75%|███████▌  | 21/28 [00:00<00:00, 90.24it/s, train_loss=0.00463, val_loss=0.00418]Epoch 27:  75%|███████▌  | 21/28 [00:00<00:00, 89.54it/s, train_loss=0.00537, val_loss=0.00418]Epoch 27:  79%|███████▊  | 22/28 [00:00<00:00, 90.47it/s, train_loss=0.00537, val_loss=0.00418]Epoch 27:  79%|███████▊  | 22/28 [00:00<00:00, 89.23it/s, train_loss=0.00507, val_loss=0.00418]Epoch 27:  82%|████████▏ | 23/28 [00:00<00:00, 86.33it/s, train_loss=0.00507, val_loss=0.00418]Epoch 27:  82%|████████▏ | 23/28 [00:00<00:00, 85.73it/s, train_loss=0.00466, val_loss=0.00418]Epoch 27:  86%|████████▌ | 24/28 [00:00<00:00, 86.72it/s, train_loss=0.00466, val_loss=0.00418]Epoch 27:  86%|████████▌ | 24/28 [00:00<00:00, 86.10it/s, train_loss=0.00349, val_loss=0.00418]Epoch 27:  89%|████████▉ | 25/28 [00:00<00:00, 86.61it/s, train_loss=0.00349, val_loss=0.00418]Epoch 27:  89%|████████▉ | 25/28 [00:00<00:00, 86.12it/s, train_loss=0.00459, val_loss=0.00418]Epoch 27:  93%|█████████▎| 26/28 [00:00<00:00, 86.99it/s, train_loss=0.00459, val_loss=0.00418]Epoch 27:  93%|█████████▎| 26/28 [00:00<00:00, 86.43it/s, train_loss=0.00399, val_loss=0.00418]Epoch 27:  96%|█████████▋| 27/28 [00:00<00:00, 86.89it/s, train_loss=0.00399, val_loss=0.00418]Epoch 27:  96%|█████████▋| 27/28 [00:00<00:00, 86.44it/s, train_loss=0.00401, val_loss=0.00418]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 87.50it/s, train_loss=0.00401, val_loss=0.00418]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 87.19it/s, train_loss=0.00502, val_loss=0.00418]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 122.02it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 142.58it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 149.51it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 154.03it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 154.62it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 156.49it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 157.20it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 158.75it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 159.27it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 162.32it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 166.51it/s][A
                                                                         [AEpoch 27: 100%|██████████| 28/28 [00:00<00:00, 70.91it/s, train_loss=0.00502, val_loss=0.00412]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 70.79it/s, train_loss=0.00502, val_loss=0.00412]Epoch 27:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00502, val_loss=0.00412]         Epoch 28:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00502, val_loss=0.00412]Epoch 28:   4%|▎         | 1/28 [00:00<00:00, 96.36it/s, train_loss=0.00502, val_loss=0.00412]Epoch 28:   4%|▎         | 1/28 [00:00<00:00, 87.93it/s, train_loss=0.00425, val_loss=0.00412]Epoch 28:   7%|▋         | 2/28 [00:00<00:00, 95.20it/s, train_loss=0.00425, val_loss=0.00412]Epoch 28:   7%|▋         | 2/28 [00:00<00:00, 90.30it/s, train_loss=0.00396, val_loss=0.00412]Epoch 28:  11%|█         | 3/28 [00:00<00:00, 94.94it/s, train_loss=0.00396, val_loss=0.00412]Epoch 28:  11%|█         | 3/28 [00:00<00:00, 90.35it/s, train_loss=0.00469, val_loss=0.00412]Epoch 28:  14%|█▍        | 4/28 [00:00<00:00, 92.50it/s, train_loss=0.00469, val_loss=0.00412]Epoch 28:  14%|█▍        | 4/28 [00:00<00:00, 89.52it/s, train_loss=0.0055, val_loss=0.00412] Epoch 28:  18%|█▊        | 5/28 [00:00<00:00, 93.61it/s, train_loss=0.0055, val_loss=0.00412]Epoch 28:  18%|█▊        | 5/28 [00:00<00:00, 90.38it/s, train_loss=0.00427, val_loss=0.00412]Epoch 28:  21%|██▏       | 6/28 [00:00<00:00, 92.04it/s, train_loss=0.00427, val_loss=0.00412]Epoch 28:  21%|██▏       | 6/28 [00:00<00:00, 89.63it/s, train_loss=0.005, val_loss=0.00412]  Epoch 28:  25%|██▌       | 7/28 [00:00<00:00, 92.72it/s, train_loss=0.005, val_loss=0.00412]Epoch 28:  25%|██▌       | 7/28 [00:00<00:00, 90.50it/s, train_loss=0.00414, val_loss=0.00412]Epoch 28:  29%|██▊       | 8/28 [00:00<00:00, 91.76it/s, train_loss=0.00414, val_loss=0.00412]Epoch 28:  29%|██▊       | 8/28 [00:00<00:00, 89.87it/s, train_loss=0.00478, val_loss=0.00412]Epoch 28:  32%|███▏      | 9/28 [00:00<00:00, 92.21it/s, train_loss=0.00478, val_loss=0.00412]Epoch 28:  32%|███▏      | 9/28 [00:00<00:00, 90.52it/s, train_loss=0.00399, val_loss=0.00412]Epoch 28:  36%|███▌      | 10/28 [00:00<00:00, 91.53it/s, train_loss=0.00399, val_loss=0.00412]Epoch 28:  36%|███▌      | 10/28 [00:00<00:00, 89.99it/s, train_loss=0.00415, val_loss=0.00412]Epoch 28:  39%|███▉      | 11/28 [00:00<00:00, 91.89it/s, train_loss=0.00415, val_loss=0.00412]Epoch 28:  39%|███▉      | 11/28 [00:00<00:00, 90.46it/s, train_loss=0.0039, val_loss=0.00412] Epoch 28:  43%|████▎     | 12/28 [00:00<00:00, 91.26it/s, train_loss=0.0039, val_loss=0.00412]Epoch 28:  43%|████▎     | 12/28 [00:00<00:00, 90.10it/s, train_loss=0.00501, val_loss=0.00412]Epoch 28:  46%|████▋     | 13/28 [00:00<00:00, 91.75it/s, train_loss=0.00501, val_loss=0.00412]Epoch 28:  46%|████▋     | 13/28 [00:00<00:00, 90.61it/s, train_loss=0.00309, val_loss=0.00412]Epoch 28:  50%|█████     | 14/28 [00:00<00:00, 91.16it/s, train_loss=0.00309, val_loss=0.00412]Epoch 28:  50%|█████     | 14/28 [00:00<00:00, 90.39it/s, train_loss=0.00485, val_loss=0.00412]Epoch 28:  54%|█████▎    | 15/28 [00:00<00:00, 91.59it/s, train_loss=0.00485, val_loss=0.00412]Epoch 28:  54%|█████▎    | 15/28 [00:00<00:00, 90.62it/s, train_loss=0.00471, val_loss=0.00412]Epoch 28:  57%|█████▋    | 16/28 [00:00<00:00, 91.17it/s, train_loss=0.00471, val_loss=0.00412]Epoch 28:  57%|█████▋    | 16/28 [00:00<00:00, 90.34it/s, train_loss=0.00431, val_loss=0.00412]Epoch 28:  61%|██████    | 17/28 [00:00<00:00, 91.42it/s, train_loss=0.00431, val_loss=0.00412]Epoch 28:  61%|██████    | 17/28 [00:00<00:00, 90.57it/s, train_loss=0.00397, val_loss=0.00412]Epoch 28:  64%|██████▍   | 18/28 [00:00<00:00, 90.92it/s, train_loss=0.00397, val_loss=0.00412]Epoch 28:  64%|██████▍   | 18/28 [00:00<00:00, 90.34it/s, train_loss=0.00414, val_loss=0.00412]Epoch 28:  68%|██████▊   | 19/28 [00:00<00:00, 91.59it/s, train_loss=0.00414, val_loss=0.00412]Epoch 28:  68%|██████▊   | 19/28 [00:00<00:00, 90.72it/s, train_loss=0.00537, val_loss=0.00412]Epoch 28:  71%|███████▏  | 20/28 [00:00<00:00, 91.55it/s, train_loss=0.00537, val_loss=0.00412]Epoch 28:  71%|███████▏  | 20/28 [00:00<00:00, 90.41it/s, train_loss=0.00424, val_loss=0.00412]Epoch 28:  75%|███████▌  | 21/28 [00:00<00:00, 91.49it/s, train_loss=0.00424, val_loss=0.00412]Epoch 28:  75%|███████▌  | 21/28 [00:00<00:00, 90.74it/s, train_loss=0.00514, val_loss=0.00412]Epoch 28:  79%|███████▊  | 22/28 [00:00<00:00, 91.33it/s, train_loss=0.00514, val_loss=0.00412]Epoch 28:  79%|███████▊  | 22/28 [00:00<00:00, 90.48it/s, train_loss=0.00362, val_loss=0.00412]Epoch 28:  82%|████████▏ | 23/28 [00:00<00:00, 91.42it/s, train_loss=0.00362, val_loss=0.00412]Epoch 28:  82%|████████▏ | 23/28 [00:00<00:00, 90.76it/s, train_loss=0.00372, val_loss=0.00412]Epoch 28:  86%|████████▌ | 24/28 [00:00<00:00, 91.24it/s, train_loss=0.00372, val_loss=0.00412]Epoch 28:  86%|████████▌ | 24/28 [00:00<00:00, 90.53it/s, train_loss=0.00521, val_loss=0.00412]Epoch 28:  89%|████████▉ | 25/28 [00:00<00:00, 91.38it/s, train_loss=0.00521, val_loss=0.00412]Epoch 28:  89%|████████▉ | 25/28 [00:00<00:00, 90.75it/s, train_loss=0.00339, val_loss=0.00412]Epoch 28:  93%|█████████▎| 26/28 [00:00<00:00, 91.17it/s, train_loss=0.00339, val_loss=0.00412]Epoch 28:  93%|█████████▎| 26/28 [00:00<00:00, 90.55it/s, train_loss=0.0043, val_loss=0.00412] Epoch 28:  96%|█████████▋| 27/28 [00:00<00:00, 91.36it/s, train_loss=0.0043, val_loss=0.00412]Epoch 28:  96%|█████████▋| 27/28 [00:00<00:00, 90.78it/s, train_loss=0.00483, val_loss=0.00412]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 91.49it/s, train_loss=0.00483, val_loss=0.00412]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 91.24it/s, train_loss=0.00352, val_loss=0.00412]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 133.72it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 150.68it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 159.31it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 162.06it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 164.29it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 164.55it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 165.75it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 165.53it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 166.19it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 166.49it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 166.62it/s][A
                                                                         [AEpoch 28: 100%|██████████| 28/28 [00:00<00:00, 73.49it/s, train_loss=0.00352, val_loss=0.00403]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 73.28it/s, train_loss=0.00352, val_loss=0.00403]Epoch 28:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00352, val_loss=0.00403]         Epoch 29:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00352, val_loss=0.00403]Epoch 29:   4%|▎         | 1/28 [00:00<00:00, 90.91it/s, train_loss=0.00352, val_loss=0.00403]Epoch 29:   4%|▎         | 1/28 [00:00<00:00, 84.84it/s, train_loss=0.00466, val_loss=0.00403]Epoch 29:   7%|▋         | 2/28 [00:00<00:00, 93.53it/s, train_loss=0.00466, val_loss=0.00403]Epoch 29:   7%|▋         | 2/28 [00:00<00:00, 88.89it/s, train_loss=0.00498, val_loss=0.00403]Epoch 29:  11%|█         | 3/28 [00:00<00:00, 95.25it/s, train_loss=0.00498, val_loss=0.00403]Epoch 29:  11%|█         | 3/28 [00:00<00:00, 90.94it/s, train_loss=0.00471, val_loss=0.00403]Epoch 29:  14%|█▍        | 4/28 [00:00<00:00, 93.12it/s, train_loss=0.00471, val_loss=0.00403]Epoch 29:  14%|█▍        | 4/28 [00:00<00:00, 89.53it/s, train_loss=0.00538, val_loss=0.00403]Epoch 29:  18%|█▊        | 5/28 [00:00<00:00, 93.73it/s, train_loss=0.00538, val_loss=0.00403]Epoch 29:  18%|█▊        | 5/28 [00:00<00:00, 90.52it/s, train_loss=0.00432, val_loss=0.00403]Epoch 29:  21%|██▏       | 6/28 [00:00<00:00, 92.26it/s, train_loss=0.00432, val_loss=0.00403]Epoch 29:  21%|██▏       | 6/28 [00:00<00:00, 89.72it/s, train_loss=0.00522, val_loss=0.00403]Epoch 29:  25%|██▌       | 7/28 [00:00<00:00, 92.71it/s, train_loss=0.00522, val_loss=0.00403]Epoch 29:  25%|██▌       | 7/28 [00:00<00:00, 90.63it/s, train_loss=0.0044, val_loss=0.00403] Epoch 29:  29%|██▊       | 8/28 [00:00<00:00, 91.92it/s, train_loss=0.0044, val_loss=0.00403]Epoch 29:  29%|██▊       | 8/28 [00:00<00:00, 89.98it/s, train_loss=0.0041, val_loss=0.00403]Epoch 29:  32%|███▏      | 9/28 [00:00<00:00, 92.31it/s, train_loss=0.0041, val_loss=0.00403]Epoch 29:  32%|███▏      | 9/28 [00:00<00:00, 90.56it/s, train_loss=0.00465, val_loss=0.00403]Epoch 29:  36%|███▌      | 10/28 [00:00<00:00, 91.46it/s, train_loss=0.00465, val_loss=0.00403]Epoch 29:  36%|███▌      | 10/28 [00:00<00:00, 90.11it/s, train_loss=0.00357, val_loss=0.00403]Epoch 29:  39%|███▉      | 11/28 [00:00<00:00, 92.06it/s, train_loss=0.00357, val_loss=0.00403]Epoch 29:  39%|███▉      | 11/28 [00:00<00:00, 90.58it/s, train_loss=0.00398, val_loss=0.00403]Epoch 29:  43%|████▎     | 12/28 [00:00<00:00, 91.63it/s, train_loss=0.00398, val_loss=0.00403]Epoch 29:  43%|████▎     | 12/28 [00:00<00:00, 90.18it/s, train_loss=0.00453, val_loss=0.00403]Epoch 29:  46%|████▋     | 13/28 [00:00<00:00, 91.84it/s, train_loss=0.00453, val_loss=0.00403]Epoch 29:  46%|████▋     | 13/28 [00:00<00:00, 90.69it/s, train_loss=0.00431, val_loss=0.00403]Epoch 29:  50%|█████     | 14/28 [00:00<00:00, 91.39it/s, train_loss=0.00431, val_loss=0.00403]Epoch 29:  50%|█████     | 14/28 [00:00<00:00, 90.30it/s, train_loss=0.00457, val_loss=0.00403]Epoch 29:  54%|█████▎    | 15/28 [00:00<00:00, 90.85it/s, train_loss=0.00457, val_loss=0.00403]Epoch 29:  54%|█████▎    | 15/28 [00:00<00:00, 90.25it/s, train_loss=0.004, val_loss=0.00403]  Epoch 29:  57%|█████▋    | 16/28 [00:00<00:00, 90.66it/s, train_loss=0.004, val_loss=0.00403]Epoch 29:  57%|█████▋    | 16/28 [00:00<00:00, 90.18it/s, train_loss=0.00441, val_loss=0.00403]Epoch 29:  61%|██████    | 17/28 [00:00<00:00, 91.38it/s, train_loss=0.00441, val_loss=0.00403]Epoch 29:  61%|██████    | 17/28 [00:00<00:00, 90.47it/s, train_loss=0.00379, val_loss=0.00403]Epoch 29:  64%|██████▍   | 18/28 [00:00<00:00, 90.97it/s, train_loss=0.00379, val_loss=0.00403]Epoch 29:  64%|██████▍   | 18/28 [00:00<00:00, 90.36it/s, train_loss=0.00475, val_loss=0.00403]Epoch 29:  68%|██████▊   | 19/28 [00:00<00:00, 91.36it/s, train_loss=0.00475, val_loss=0.00403]Epoch 29:  68%|██████▊   | 19/28 [00:00<00:00, 90.50it/s, train_loss=0.00427, val_loss=0.00403]Epoch 29:  71%|███████▏  | 20/28 [00:00<00:00, 91.01it/s, train_loss=0.00427, val_loss=0.00403]Epoch 29:  71%|███████▏  | 20/28 [00:00<00:00, 90.29it/s, train_loss=0.00431, val_loss=0.00403]Epoch 29:  75%|███████▌  | 21/28 [00:00<00:00, 91.35it/s, train_loss=0.00431, val_loss=0.00403]Epoch 29:  75%|███████▌  | 21/28 [00:00<00:00, 90.66it/s, train_loss=0.00464, val_loss=0.00403]Epoch 29:  79%|███████▊  | 22/28 [00:00<00:00, 91.66it/s, train_loss=0.00464, val_loss=0.00403]Epoch 29:  79%|███████▊  | 22/28 [00:00<00:00, 90.22it/s, train_loss=0.005, val_loss=0.00403]  Epoch 29:  82%|████████▏ | 23/28 [00:00<00:00, 91.10it/s, train_loss=0.005, val_loss=0.00403]Epoch 29:  82%|████████▏ | 23/28 [00:00<00:00, 90.43it/s, train_loss=0.00419, val_loss=0.00403]Epoch 29:  86%|████████▌ | 24/28 [00:00<00:00, 90.99it/s, train_loss=0.00419, val_loss=0.00403]Epoch 29:  86%|████████▌ | 24/28 [00:00<00:00, 90.25it/s, train_loss=0.00388, val_loss=0.00403]Epoch 29:  89%|████████▉ | 25/28 [00:00<00:00, 91.06it/s, train_loss=0.00388, val_loss=0.00403]Epoch 29:  89%|████████▉ | 25/28 [00:00<00:00, 90.50it/s, train_loss=0.00399, val_loss=0.00403]Epoch 29:  93%|█████████▎| 26/28 [00:00<00:00, 90.82it/s, train_loss=0.00399, val_loss=0.00403]Epoch 29:  93%|█████████▎| 26/28 [00:00<00:00, 90.36it/s, train_loss=0.00337, val_loss=0.00403]Epoch 29:  96%|█████████▋| 27/28 [00:00<00:00, 91.08it/s, train_loss=0.00337, val_loss=0.00403]Epoch 29:  96%|█████████▋| 27/28 [00:00<00:00, 90.54it/s, train_loss=0.00372, val_loss=0.00403]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 91.37it/s, train_loss=0.00372, val_loss=0.00403]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 91.15it/s, train_loss=0.00639, val_loss=0.00403]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 140.78it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 156.06it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 164.27it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 167.76it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 166.71it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 168.44it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 168.80it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 169.38it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 168.71it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 169.02it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 169.57it/s][A
                                                                         [AEpoch 29: 100%|██████████| 28/28 [00:00<00:00, 73.78it/s, train_loss=0.00639, val_loss=0.00402]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 73.60it/s, train_loss=0.00639, val_loss=0.00402]Epoch 29:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00639, val_loss=0.00402]         Epoch 30:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00639, val_loss=0.00402]Epoch 30:   4%|▎         | 1/28 [00:00<00:00, 89.28it/s, train_loss=0.00639, val_loss=0.00402]Epoch 30:   4%|▎         | 1/28 [00:00<00:00, 82.34it/s, train_loss=0.00383, val_loss=0.00402]Epoch 30:   7%|▋         | 2/28 [00:00<00:00, 90.47it/s, train_loss=0.00383, val_loss=0.00402]Epoch 30:   7%|▋         | 2/28 [00:00<00:00, 83.25it/s, train_loss=0.00438, val_loss=0.00402]Epoch 30:  11%|█         | 3/28 [00:00<00:00, 91.39it/s, train_loss=0.00438, val_loss=0.00402]Epoch 30:  11%|█         | 3/28 [00:00<00:00, 86.58it/s, train_loss=0.00376, val_loss=0.00402]Epoch 30:  14%|█▍        | 4/28 [00:00<00:00, 90.01it/s, train_loss=0.00376, val_loss=0.00402]Epoch 30:  14%|█▍        | 4/28 [00:00<00:00, 86.53it/s, train_loss=0.00455, val_loss=0.00402]Epoch 30:  18%|█▊        | 5/28 [00:00<00:00, 91.16it/s, train_loss=0.00455, val_loss=0.00402]Epoch 30:  18%|█▊        | 5/28 [00:00<00:00, 88.17it/s, train_loss=0.00509, val_loss=0.00402]Epoch 30:  21%|██▏       | 6/28 [00:00<00:00, 90.54it/s, train_loss=0.00509, val_loss=0.00402]Epoch 30:  21%|██▏       | 6/28 [00:00<00:00, 87.83it/s, train_loss=0.00466, val_loss=0.00402]Epoch 30:  25%|██▌       | 7/28 [00:00<00:00, 91.17it/s, train_loss=0.00466, val_loss=0.00402]Epoch 30:  25%|██▌       | 7/28 [00:00<00:00, 89.05it/s, train_loss=0.00512, val_loss=0.00402]Epoch 30:  29%|██▊       | 8/28 [00:00<00:00, 90.55it/s, train_loss=0.00512, val_loss=0.00402]Epoch 30:  29%|██▊       | 8/28 [00:00<00:00, 88.58it/s, train_loss=0.00419, val_loss=0.00402]Epoch 30:  32%|███▏      | 9/28 [00:00<00:00, 91.03it/s, train_loss=0.00419, val_loss=0.00402]Epoch 30:  32%|███▏      | 9/28 [00:00<00:00, 89.43it/s, train_loss=0.00401, val_loss=0.00402]Epoch 30:  36%|███▌      | 10/28 [00:00<00:00, 90.57it/s, train_loss=0.00401, val_loss=0.00402]Epoch 30:  36%|███▌      | 10/28 [00:00<00:00, 89.02it/s, train_loss=0.00448, val_loss=0.00402]Epoch 30:  39%|███▉      | 11/28 [00:00<00:00, 90.98it/s, train_loss=0.00448, val_loss=0.00402]Epoch 30:  39%|███▉      | 11/28 [00:00<00:00, 89.64it/s, train_loss=0.00422, val_loss=0.00402]Epoch 30:  43%|████▎     | 12/28 [00:00<00:00, 90.74it/s, train_loss=0.00422, val_loss=0.00402]Epoch 30:  43%|████▎     | 12/28 [00:00<00:00, 89.27it/s, train_loss=0.00493, val_loss=0.00402]Epoch 30:  46%|████▋     | 13/28 [00:00<00:00, 90.86it/s, train_loss=0.00493, val_loss=0.00402]Epoch 30:  46%|████▋     | 13/28 [00:00<00:00, 89.71it/s, train_loss=0.00434, val_loss=0.00402]Epoch 30:  50%|█████     | 14/28 [00:00<00:00, 90.55it/s, train_loss=0.00434, val_loss=0.00402]Epoch 30:  50%|█████     | 14/28 [00:00<00:00, 89.44it/s, train_loss=0.00456, val_loss=0.00402]Epoch 30:  54%|█████▎    | 15/28 [00:00<00:00, 90.78it/s, train_loss=0.00456, val_loss=0.00402]Epoch 30:  54%|█████▎    | 15/28 [00:00<00:00, 89.78it/s, train_loss=0.0046, val_loss=0.00402] Epoch 30:  57%|█████▋    | 16/28 [00:00<00:00, 90.46it/s, train_loss=0.0046, val_loss=0.00402]Epoch 30:  57%|█████▋    | 16/28 [00:00<00:00, 89.56it/s, train_loss=0.00355, val_loss=0.00402]Epoch 30:  61%|██████    | 17/28 [00:00<00:00, 90.74it/s, train_loss=0.00355, val_loss=0.00402]Epoch 30:  61%|██████    | 17/28 [00:00<00:00, 89.86it/s, train_loss=0.00497, val_loss=0.00402]Epoch 30:  64%|██████▍   | 18/28 [00:00<00:00, 90.52it/s, train_loss=0.00497, val_loss=0.00402]Epoch 30:  64%|██████▍   | 18/28 [00:00<00:00, 89.69it/s, train_loss=0.0038, val_loss=0.00402] Epoch 30:  68%|██████▊   | 19/28 [00:00<00:00, 90.86it/s, train_loss=0.0038, val_loss=0.00402]Epoch 30:  68%|██████▊   | 19/28 [00:00<00:00, 90.05it/s, train_loss=0.00485, val_loss=0.00402]Epoch 30:  71%|███████▏  | 20/28 [00:00<00:00, 90.59it/s, train_loss=0.00485, val_loss=0.00402]Epoch 30:  71%|███████▏  | 20/28 [00:00<00:00, 89.81it/s, train_loss=0.00353, val_loss=0.00402]Epoch 30:  75%|███████▌  | 21/28 [00:00<00:00, 90.74it/s, train_loss=0.00353, val_loss=0.00402]Epoch 30:  75%|███████▌  | 21/28 [00:00<00:00, 90.08it/s, train_loss=0.00418, val_loss=0.00402]Epoch 30:  79%|███████▊  | 22/28 [00:00<00:00, 89.92it/s, train_loss=0.00418, val_loss=0.00402]Epoch 30:  79%|███████▊  | 22/28 [00:00<00:00, 89.56it/s, train_loss=0.00441, val_loss=0.00402]Epoch 30:  82%|████████▏ | 23/28 [00:00<00:00, 90.53it/s, train_loss=0.00441, val_loss=0.00402]Epoch 30:  82%|████████▏ | 23/28 [00:00<00:00, 89.89it/s, train_loss=0.00322, val_loss=0.00402]Epoch 30:  86%|████████▌ | 24/28 [00:00<00:00, 90.51it/s, train_loss=0.00322, val_loss=0.00402]Epoch 30:  86%|████████▌ | 24/28 [00:00<00:00, 89.81it/s, train_loss=0.0047, val_loss=0.00402] Epoch 30:  89%|████████▉ | 25/28 [00:00<00:00, 90.75it/s, train_loss=0.0047, val_loss=0.00402]Epoch 30:  89%|████████▉ | 25/28 [00:00<00:00, 90.13it/s, train_loss=0.00374, val_loss=0.00402]Epoch 30:  93%|█████████▎| 26/28 [00:00<00:00, 90.65it/s, train_loss=0.00374, val_loss=0.00402]Epoch 30:  93%|█████████▎| 26/28 [00:00<00:00, 89.97it/s, train_loss=0.00382, val_loss=0.00402]Epoch 30:  96%|█████████▋| 27/28 [00:00<00:00, 90.79it/s, train_loss=0.00382, val_loss=0.00402]Epoch 30:  96%|█████████▋| 27/28 [00:00<00:00, 90.22it/s, train_loss=0.00455, val_loss=0.00402]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 91.04it/s, train_loss=0.00455, val_loss=0.00402]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 90.83it/s, train_loss=0.00329, val_loss=0.00402]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 148.88it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 166.34it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 169.18it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 173.60it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 175.88it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 176.88it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 178.72it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 175.67it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 175.67it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 175.20it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 175.41it/s][A
                                                                         [AEpoch 30: 100%|██████████| 28/28 [00:00<00:00, 74.09it/s, train_loss=0.00329, val_loss=0.00398]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 73.88it/s, train_loss=0.00329, val_loss=0.00398]Epoch 30:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00329, val_loss=0.00398]         Epoch 31:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00329, val_loss=0.00398]Epoch 31:   4%|▎         | 1/28 [00:00<00:00, 93.65it/s, train_loss=0.00329, val_loss=0.00398]Epoch 31:   4%|▎         | 1/28 [00:00<00:00, 72.12it/s, train_loss=0.00387, val_loss=0.00398]Epoch 31:   7%|▋         | 2/28 [00:00<00:00, 83.96it/s, train_loss=0.00387, val_loss=0.00398]Epoch 31:   7%|▋         | 2/28 [00:00<00:00, 80.45it/s, train_loss=0.00429, val_loss=0.00398]Epoch 31:  11%|█         | 3/28 [00:00<00:00, 85.31it/s, train_loss=0.00429, val_loss=0.00398]Epoch 31:  11%|█         | 3/28 [00:00<00:00, 82.67it/s, train_loss=0.00491, val_loss=0.00398]Epoch 31:  14%|█▍        | 4/28 [00:00<00:00, 88.55it/s, train_loss=0.00491, val_loss=0.00398]Epoch 31:  14%|█▍        | 4/28 [00:00<00:00, 85.37it/s, train_loss=0.00374, val_loss=0.00398]Epoch 31:  18%|█▊        | 5/28 [00:00<00:00, 87.72it/s, train_loss=0.00374, val_loss=0.00398]Epoch 31:  18%|█▊        | 5/28 [00:00<00:00, 85.55it/s, train_loss=0.00388, val_loss=0.00398]Epoch 31:  21%|██▏       | 6/28 [00:00<00:00, 89.07it/s, train_loss=0.00388, val_loss=0.00398]Epoch 31:  21%|██▏       | 6/28 [00:00<00:00, 86.89it/s, train_loss=0.00381, val_loss=0.00398]Epoch 31:  25%|██▌       | 7/28 [00:00<00:00, 89.02it/s, train_loss=0.00381, val_loss=0.00398]Epoch 31:  25%|██▌       | 7/28 [00:00<00:00, 86.83it/s, train_loss=0.0032, val_loss=0.00398] Epoch 31:  29%|██▊       | 8/28 [00:00<00:00, 89.99it/s, train_loss=0.0032, val_loss=0.00398]Epoch 31:  29%|██▊       | 8/28 [00:00<00:00, 88.09it/s, train_loss=0.00461, val_loss=0.00398]Epoch 31:  32%|███▏      | 9/28 [00:00<00:00, 90.25it/s, train_loss=0.00461, val_loss=0.00398]Epoch 31:  32%|███▏      | 9/28 [00:00<00:00, 87.61it/s, train_loss=0.00489, val_loss=0.00398]Epoch 31:  36%|███▌      | 10/28 [00:00<00:00, 89.71it/s, train_loss=0.00489, val_loss=0.00398]Epoch 31:  36%|███▌      | 10/28 [00:00<00:00, 88.29it/s, train_loss=0.00464, val_loss=0.00398]Epoch 31:  39%|███▉      | 11/28 [00:00<00:00, 89.50it/s, train_loss=0.00464, val_loss=0.00398]Epoch 31:  39%|███▉      | 11/28 [00:00<00:00, 88.12it/s, train_loss=0.00437, val_loss=0.00398]Epoch 31:  43%|████▎     | 12/28 [00:00<00:00, 90.03it/s, train_loss=0.00437, val_loss=0.00398]Epoch 31:  43%|████▎     | 12/28 [00:00<00:00, 88.78it/s, train_loss=0.00434, val_loss=0.00398]Epoch 31:  46%|████▋     | 13/28 [00:00<00:00, 89.77it/s, train_loss=0.00434, val_loss=0.00398]Epoch 31:  46%|████▋     | 13/28 [00:00<00:00, 88.49it/s, train_loss=0.00467, val_loss=0.00398]Epoch 31:  50%|█████     | 14/28 [00:00<00:00, 90.13it/s, train_loss=0.00467, val_loss=0.00398]Epoch 31:  50%|█████     | 14/28 [00:00<00:00, 89.06it/s, train_loss=0.00366, val_loss=0.00398]Epoch 31:  54%|█████▎    | 15/28 [00:00<00:00, 89.91it/s, train_loss=0.00366, val_loss=0.00398]Epoch 31:  54%|█████▎    | 15/28 [00:00<00:00, 88.86it/s, train_loss=0.00414, val_loss=0.00398]Epoch 31:  57%|█████▋    | 16/28 [00:00<00:00, 90.22it/s, train_loss=0.00414, val_loss=0.00398]Epoch 31:  57%|█████▋    | 16/28 [00:00<00:00, 89.31it/s, train_loss=0.00436, val_loss=0.00398]Epoch 31:  61%|██████    | 17/28 [00:00<00:00, 89.99it/s, train_loss=0.00436, val_loss=0.00398]Epoch 31:  61%|██████    | 17/28 [00:00<00:00, 89.07it/s, train_loss=0.00332, val_loss=0.00398]Epoch 31:  64%|██████▍   | 18/28 [00:00<00:00, 90.25it/s, train_loss=0.00332, val_loss=0.00398]Epoch 31:  64%|██████▍   | 18/28 [00:00<00:00, 89.38it/s, train_loss=0.00379, val_loss=0.00398]Epoch 31:  68%|██████▊   | 19/28 [00:00<00:00, 90.00it/s, train_loss=0.00379, val_loss=0.00398]Epoch 31:  68%|██████▊   | 19/28 [00:00<00:00, 89.18it/s, train_loss=0.0049, val_loss=0.00398] Epoch 31:  71%|███████▏  | 20/28 [00:00<00:00, 90.32it/s, train_loss=0.0049, val_loss=0.00398]Epoch 31:  71%|███████▏  | 20/28 [00:00<00:00, 89.56it/s, train_loss=0.00362, val_loss=0.00398]Epoch 31:  75%|███████▌  | 21/28 [00:00<00:00, 90.06it/s, train_loss=0.00362, val_loss=0.00398]Epoch 31:  75%|███████▌  | 21/28 [00:00<00:00, 89.37it/s, train_loss=0.00411, val_loss=0.00398]Epoch 31:  79%|███████▊  | 22/28 [00:00<00:00, 90.36it/s, train_loss=0.00411, val_loss=0.00398]Epoch 31:  79%|███████▊  | 22/28 [00:00<00:00, 89.70it/s, train_loss=0.00432, val_loss=0.00398]Epoch 31:  82%|████████▏ | 23/28 [00:00<00:00, 90.18it/s, train_loss=0.00432, val_loss=0.00398]Epoch 31:  82%|████████▏ | 23/28 [00:00<00:00, 89.53it/s, train_loss=0.0046, val_loss=0.00398] Epoch 31:  86%|████████▌ | 24/28 [00:00<00:00, 90.43it/s, train_loss=0.0046, val_loss=0.00398]Epoch 31:  86%|████████▌ | 24/28 [00:00<00:00, 89.81it/s, train_loss=0.00434, val_loss=0.00398]Epoch 31:  89%|████████▉ | 25/28 [00:00<00:00, 90.20it/s, train_loss=0.00434, val_loss=0.00398]Epoch 31:  89%|████████▉ | 25/28 [00:00<00:00, 89.62it/s, train_loss=0.00406, val_loss=0.00398]Epoch 31:  93%|█████████▎| 26/28 [00:00<00:00, 90.53it/s, train_loss=0.00406, val_loss=0.00398]Epoch 31:  93%|█████████▎| 26/28 [00:00<00:00, 89.96it/s, train_loss=0.00419, val_loss=0.00398]Epoch 31:  96%|█████████▋| 27/28 [00:00<00:00, 90.71it/s, train_loss=0.00419, val_loss=0.00398]Epoch 31:  96%|█████████▋| 27/28 [00:00<00:00, 89.68it/s, train_loss=0.00523, val_loss=0.00398]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 90.67it/s, train_loss=0.00523, val_loss=0.00398]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 90.18it/s, train_loss=0.0217, val_loss=0.00398] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 155.11it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 171.24it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 178.92it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 179.78it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 182.40it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 183.69it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 184.36it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 184.74it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 183.28it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 183.57it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 183.73it/s][A
                                                                         [AEpoch 31: 100%|██████████| 28/28 [00:00<00:00, 74.26it/s, train_loss=0.0217, val_loss=0.00396]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 74.09it/s, train_loss=0.0217, val_loss=0.00396]Epoch 31:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0217, val_loss=0.00396]         Epoch 32:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0217, val_loss=0.00396]Epoch 32:   4%|▎         | 1/28 [00:00<00:00, 89.28it/s, train_loss=0.0217, val_loss=0.00396]Epoch 32:   4%|▎         | 1/28 [00:00<00:00, 82.49it/s, train_loss=0.00384, val_loss=0.00396]Epoch 32:   7%|▋         | 2/28 [00:00<00:00, 91.15it/s, train_loss=0.00384, val_loss=0.00396]Epoch 32:   7%|▋         | 2/28 [00:00<00:00, 80.57it/s, train_loss=0.00348, val_loss=0.00396]Epoch 32:  11%|█         | 3/28 [00:00<00:00, 87.96it/s, train_loss=0.00348, val_loss=0.00396]Epoch 32:  11%|█         | 3/28 [00:00<00:00, 83.76it/s, train_loss=0.00449, val_loss=0.00396]Epoch 32:  14%|█▍        | 4/28 [00:00<00:00, 86.53it/s, train_loss=0.00449, val_loss=0.00396]Epoch 32:  14%|█▍        | 4/28 [00:00<00:00, 84.71it/s, train_loss=0.00484, val_loss=0.00396]Epoch 32:  18%|█▊        | 5/28 [00:00<00:00, 89.19it/s, train_loss=0.00484, val_loss=0.00396]Epoch 32:  18%|█▊        | 5/28 [00:00<00:00, 86.48it/s, train_loss=0.00396, val_loss=0.00396]Epoch 32:  21%|██▏       | 6/28 [00:00<00:00, 88.90it/s, train_loss=0.00396, val_loss=0.00396]Epoch 32:  21%|██▏       | 6/28 [00:00<00:00, 86.45it/s, train_loss=0.00448, val_loss=0.00396]Epoch 32:  25%|██▌       | 7/28 [00:00<00:00, 89.78it/s, train_loss=0.00448, val_loss=0.00396]Epoch 32:  25%|██▌       | 7/28 [00:00<00:00, 87.55it/s, train_loss=0.00444, val_loss=0.00396]Epoch 32:  29%|██▊       | 8/28 [00:00<00:00, 89.06it/s, train_loss=0.00444, val_loss=0.00396]Epoch 32:  29%|██▊       | 8/28 [00:00<00:00, 87.42it/s, train_loss=0.00383, val_loss=0.00396]Epoch 32:  32%|███▏      | 9/28 [00:00<00:00, 89.72it/s, train_loss=0.00383, val_loss=0.00396]Epoch 32:  32%|███▏      | 9/28 [00:00<00:00, 88.15it/s, train_loss=0.00395, val_loss=0.00396]Epoch 32:  36%|███▌      | 10/28 [00:00<00:00, 89.40it/s, train_loss=0.00395, val_loss=0.00396]Epoch 32:  36%|███▌      | 10/28 [00:00<00:00, 87.93it/s, train_loss=0.00368, val_loss=0.00396]Epoch 32:  39%|███▉      | 11/28 [00:00<00:00, 89.71it/s, train_loss=0.00368, val_loss=0.00396]Epoch 32:  39%|███▉      | 11/28 [00:00<00:00, 88.51it/s, train_loss=0.00421, val_loss=0.00396]Epoch 32:  43%|████▎     | 12/28 [00:00<00:00, 89.46it/s, train_loss=0.00421, val_loss=0.00396]Epoch 32:  43%|████▎     | 12/28 [00:00<00:00, 88.29it/s, train_loss=0.00456, val_loss=0.00396]Epoch 32:  46%|████▋     | 13/28 [00:00<00:00, 90.06it/s, train_loss=0.00456, val_loss=0.00396]Epoch 32:  46%|████▋     | 13/28 [00:00<00:00, 88.90it/s, train_loss=0.0039, val_loss=0.00396] Epoch 32:  50%|█████     | 14/28 [00:00<00:00, 90.44it/s, train_loss=0.0039, val_loss=0.00396]Epoch 32:  50%|█████     | 14/28 [00:00<00:00, 88.58it/s, train_loss=0.00423, val_loss=0.00396]Epoch 32:  54%|█████▎    | 15/28 [00:00<00:00, 90.02it/s, train_loss=0.00423, val_loss=0.00396]Epoch 32:  54%|█████▎    | 15/28 [00:00<00:00, 88.96it/s, train_loss=0.00374, val_loss=0.00396]Epoch 32:  57%|█████▋    | 16/28 [00:00<00:00, 89.75it/s, train_loss=0.00374, val_loss=0.00396]Epoch 32:  57%|█████▋    | 16/28 [00:00<00:00, 88.80it/s, train_loss=0.00499, val_loss=0.00396]Epoch 32:  61%|██████    | 17/28 [00:00<00:00, 90.10it/s, train_loss=0.00499, val_loss=0.00396]Epoch 32:  61%|██████    | 17/28 [00:00<00:00, 89.24it/s, train_loss=0.00371, val_loss=0.00396]Epoch 32:  64%|██████▍   | 18/28 [00:00<00:00, 89.94it/s, train_loss=0.00371, val_loss=0.00396]Epoch 32:  64%|██████▍   | 18/28 [00:00<00:00, 89.03it/s, train_loss=0.00487, val_loss=0.00396]Epoch 32:  68%|██████▊   | 19/28 [00:00<00:00, 90.15it/s, train_loss=0.00487, val_loss=0.00396]Epoch 32:  68%|██████▊   | 19/28 [00:00<00:00, 89.31it/s, train_loss=0.00441, val_loss=0.00396]Epoch 32:  71%|███████▏  | 20/28 [00:00<00:00, 89.92it/s, train_loss=0.00441, val_loss=0.00396]Epoch 32:  71%|███████▏  | 20/28 [00:00<00:00, 89.14it/s, train_loss=0.00562, val_loss=0.00396]Epoch 32:  75%|███████▌  | 21/28 [00:00<00:00, 90.20it/s, train_loss=0.00562, val_loss=0.00396]Epoch 32:  75%|███████▌  | 21/28 [00:00<00:00, 89.52it/s, train_loss=0.00435, val_loss=0.00396]Epoch 32:  79%|███████▊  | 22/28 [00:00<00:00, 90.11it/s, train_loss=0.00435, val_loss=0.00396]Epoch 32:  79%|███████▊  | 22/28 [00:00<00:00, 89.34it/s, train_loss=0.00371, val_loss=0.00396]Epoch 32:  82%|████████▏ | 23/28 [00:00<00:00, 90.25it/s, train_loss=0.00371, val_loss=0.00396]Epoch 32:  82%|████████▏ | 23/28 [00:00<00:00, 89.57it/s, train_loss=0.00381, val_loss=0.00396]Epoch 32:  86%|████████▌ | 24/28 [00:00<00:00, 90.01it/s, train_loss=0.00381, val_loss=0.00396]Epoch 32:  86%|████████▌ | 24/28 [00:00<00:00, 89.44it/s, train_loss=0.00433, val_loss=0.00396]Epoch 32:  89%|████████▉ | 25/28 [00:00<00:00, 90.32it/s, train_loss=0.00433, val_loss=0.00396]Epoch 32:  89%|████████▉ | 25/28 [00:00<00:00, 89.71it/s, train_loss=0.00434, val_loss=0.00396]Epoch 32:  93%|█████████▎| 26/28 [00:00<00:00, 90.13it/s, train_loss=0.00434, val_loss=0.00396]Epoch 32:  93%|█████████▎| 26/28 [00:00<00:00, 89.54it/s, train_loss=0.00409, val_loss=0.00396]Epoch 32:  96%|█████████▋| 27/28 [00:00<00:00, 90.29it/s, train_loss=0.00409, val_loss=0.00396]Epoch 32:  96%|█████████▋| 27/28 [00:00<00:00, 89.74it/s, train_loss=0.00455, val_loss=0.00396]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 90.45it/s, train_loss=0.00455, val_loss=0.00396]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 90.30it/s, train_loss=0.0056, val_loss=0.00396] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 175.95it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 190.90it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 200.76it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 196.79it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 197.76it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 200.15it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 198.13it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 197.87it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 197.98it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 195.07it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 194.83it/s][A
                                                                         [AEpoch 32: 100%|██████████| 28/28 [00:00<00:00, 75.18it/s, train_loss=0.0056, val_loss=0.00392]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 74.98it/s, train_loss=0.0056, val_loss=0.00392]Epoch 32:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0056, val_loss=0.00392]         Epoch 33:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0056, val_loss=0.00392]Epoch 33:   4%|▎         | 1/28 [00:00<00:00, 91.60it/s, train_loss=0.0056, val_loss=0.00392]Epoch 33:   4%|▎         | 1/28 [00:00<00:00, 84.89it/s, train_loss=0.00397, val_loss=0.00392]Epoch 33:   7%|▋         | 2/28 [00:00<00:00, 92.78it/s, train_loss=0.00397, val_loss=0.00392]Epoch 33:   7%|▋         | 2/28 [00:00<00:00, 86.38it/s, train_loss=0.00459, val_loss=0.00392]Epoch 33:  11%|█         | 3/28 [00:00<00:00, 94.32it/s, train_loss=0.00459, val_loss=0.00392]Epoch 33:  11%|█         | 3/28 [00:00<00:00, 89.41it/s, train_loss=0.00391, val_loss=0.00392]Epoch 33:  14%|█▍        | 4/28 [00:00<00:00, 92.22it/s, train_loss=0.00391, val_loss=0.00392]Epoch 33:  14%|█▍        | 4/28 [00:00<00:00, 88.46it/s, train_loss=0.00398, val_loss=0.00392]Epoch 33:  18%|█▊        | 5/28 [00:00<00:00, 92.98it/s, train_loss=0.00398, val_loss=0.00392]Epoch 33:  18%|█▊        | 5/28 [00:00<00:00, 89.81it/s, train_loss=0.00438, val_loss=0.00392]Epoch 33:  21%|██▏       | 6/28 [00:00<00:00, 91.35it/s, train_loss=0.00438, val_loss=0.00392]Epoch 33:  21%|██▏       | 6/28 [00:00<00:00, 89.24it/s, train_loss=0.00421, val_loss=0.00392]Epoch 33:  25%|██▌       | 7/28 [00:00<00:00, 92.29it/s, train_loss=0.00421, val_loss=0.00392]Epoch 33:  25%|██▌       | 7/28 [00:00<00:00, 90.03it/s, train_loss=0.00422, val_loss=0.00392]Epoch 33:  29%|██▊       | 8/28 [00:00<00:00, 91.07it/s, train_loss=0.00422, val_loss=0.00392]Epoch 33:  29%|██▊       | 8/28 [00:00<00:00, 89.55it/s, train_loss=0.00426, val_loss=0.00392]Epoch 33:  32%|███▏      | 9/28 [00:00<00:00, 91.77it/s, train_loss=0.00426, val_loss=0.00392]Epoch 33:  32%|███▏      | 9/28 [00:00<00:00, 90.05it/s, train_loss=0.00441, val_loss=0.00392]Epoch 33:  36%|███▌      | 10/28 [00:00<00:00, 91.00it/s, train_loss=0.00441, val_loss=0.00392]Epoch 33:  36%|███▌      | 10/28 [00:00<00:00, 89.61it/s, train_loss=0.00641, val_loss=0.00392]Epoch 33:  39%|███▉      | 11/28 [00:00<00:00, 91.46it/s, train_loss=0.00641, val_loss=0.00392]Epoch 33:  39%|███▉      | 11/28 [00:00<00:00, 90.15it/s, train_loss=0.00478, val_loss=0.00392]Epoch 33:  43%|████▎     | 12/28 [00:00<00:00, 90.85it/s, train_loss=0.00478, val_loss=0.00392]Epoch 33:  43%|████▎     | 12/28 [00:00<00:00, 89.77it/s, train_loss=0.00438, val_loss=0.00392]Epoch 33:  46%|████▋     | 13/28 [00:00<00:00, 91.60it/s, train_loss=0.00438, val_loss=0.00392]Epoch 33:  46%|████▋     | 13/28 [00:00<00:00, 90.45it/s, train_loss=0.00375, val_loss=0.00392]Epoch 33:  50%|█████     | 14/28 [00:00<00:00, 92.04it/s, train_loss=0.00375, val_loss=0.00392]Epoch 33:  50%|█████     | 14/28 [00:00<00:00, 89.76it/s, train_loss=0.00448, val_loss=0.00392]Epoch 33:  54%|█████▎    | 15/28 [00:00<00:00, 91.16it/s, train_loss=0.00448, val_loss=0.00392]Epoch 33:  54%|█████▎    | 15/28 [00:00<00:00, 90.11it/s, train_loss=0.00422, val_loss=0.00392]Epoch 33:  57%|█████▋    | 16/28 [00:00<00:00, 90.98it/s, train_loss=0.00422, val_loss=0.00392]Epoch 33:  57%|█████▋    | 16/28 [00:00<00:00, 89.88it/s, train_loss=0.00436, val_loss=0.00392]Epoch 33:  61%|██████    | 17/28 [00:00<00:00, 91.17it/s, train_loss=0.00436, val_loss=0.00392]Epoch 33:  61%|██████    | 17/28 [00:00<00:00, 90.28it/s, train_loss=0.00429, val_loss=0.00392]Epoch 33:  64%|██████▍   | 18/28 [00:00<00:00, 90.98it/s, train_loss=0.00429, val_loss=0.00392]Epoch 33:  64%|██████▍   | 18/28 [00:00<00:00, 90.00it/s, train_loss=0.00439, val_loss=0.00392]Epoch 33:  68%|██████▊   | 19/28 [00:00<00:00, 91.13it/s, train_loss=0.00439, val_loss=0.00392]Epoch 33:  68%|██████▊   | 19/28 [00:00<00:00, 90.33it/s, train_loss=0.0041, val_loss=0.00392] Epoch 33:  71%|███████▏  | 20/28 [00:00<00:00, 90.75it/s, train_loss=0.0041, val_loss=0.00392]Epoch 33:  71%|███████▏  | 20/28 [00:00<00:00, 90.08it/s, train_loss=0.00386, val_loss=0.00392]Epoch 33:  75%|███████▌  | 21/28 [00:00<00:00, 91.06it/s, train_loss=0.00386, val_loss=0.00392]Epoch 33:  75%|███████▌  | 21/28 [00:00<00:00, 90.34it/s, train_loss=0.0038, val_loss=0.00392] Epoch 33:  79%|███████▊  | 22/28 [00:00<00:00, 90.89it/s, train_loss=0.0038, val_loss=0.00392]Epoch 33:  79%|███████▊  | 22/28 [00:00<00:00, 90.09it/s, train_loss=0.0041, val_loss=0.00392]Epoch 33:  82%|████████▏ | 23/28 [00:00<00:00, 90.89it/s, train_loss=0.0041, val_loss=0.00392]Epoch 33:  82%|████████▏ | 23/28 [00:00<00:00, 90.30it/s, train_loss=0.00393, val_loss=0.00392]Epoch 33:  86%|████████▌ | 24/28 [00:00<00:00, 90.64it/s, train_loss=0.00393, val_loss=0.00392]Epoch 33:  86%|████████▌ | 24/28 [00:00<00:00, 90.12it/s, train_loss=0.00414, val_loss=0.00392]Epoch 33:  89%|████████▉ | 25/28 [00:00<00:00, 90.85it/s, train_loss=0.00414, val_loss=0.00392]Epoch 33:  89%|████████▉ | 25/28 [00:00<00:00, 90.32it/s, train_loss=0.00408, val_loss=0.00392]Epoch 33:  93%|█████████▎| 26/28 [00:00<00:00, 90.59it/s, train_loss=0.00408, val_loss=0.00392]Epoch 33:  93%|█████████▎| 26/28 [00:00<00:00, 90.14it/s, train_loss=0.00427, val_loss=0.00392]Epoch 33:  96%|█████████▋| 27/28 [00:00<00:00, 90.85it/s, train_loss=0.00427, val_loss=0.00392]Epoch 33:  96%|█████████▋| 27/28 [00:00<00:00, 90.28it/s, train_loss=0.00406, val_loss=0.00392]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 90.84it/s, train_loss=0.00406, val_loss=0.00392]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 90.57it/s, train_loss=0.0037, val_loss=0.00392] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 115.87it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 137.64it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 155.44it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 165.48it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 173.07it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 178.86it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 181.04it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 183.92it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 186.27it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 188.18it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 189.93it/s][A
                                                                         [AEpoch 33: 100%|██████████| 28/28 [00:00<00:00, 74.83it/s, train_loss=0.0037, val_loss=0.00392]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 74.68it/s, train_loss=0.0037, val_loss=0.00392]Epoch 33:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0037, val_loss=0.00392]         Epoch 34:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0037, val_loss=0.00392]Epoch 34:   4%|▎         | 1/28 [00:00<00:00, 93.55it/s, train_loss=0.0037, val_loss=0.00392]Epoch 34:   4%|▎         | 1/28 [00:00<00:00, 87.97it/s, train_loss=0.00378, val_loss=0.00392]Epoch 34:   7%|▋         | 2/28 [00:00<00:00, 102.53it/s, train_loss=0.00378, val_loss=0.00392]Epoch 34:   7%|▋         | 2/28 [00:00<00:00, 85.87it/s, train_loss=0.00386, val_loss=0.00392] Epoch 34:  11%|█         | 3/28 [00:00<00:00, 90.02it/s, train_loss=0.00386, val_loss=0.00392]Epoch 34:  11%|█         | 3/28 [00:00<00:00, 87.84it/s, train_loss=0.00446, val_loss=0.00392]Epoch 34:  14%|█▍        | 4/28 [00:00<00:00, 94.51it/s, train_loss=0.00446, val_loss=0.00392]Epoch 34:  14%|█▍        | 4/28 [00:00<00:00, 90.71it/s, train_loss=0.00391, val_loss=0.00392]Epoch 34:  18%|█▊        | 5/28 [00:00<00:00, 93.08it/s, train_loss=0.00391, val_loss=0.00392]Epoch 34:  18%|█▊        | 5/28 [00:00<00:00, 90.20it/s, train_loss=0.00367, val_loss=0.00392]Epoch 34:  21%|██▏       | 6/28 [00:00<00:00, 93.97it/s, train_loss=0.00367, val_loss=0.00392]Epoch 34:  21%|██▏       | 6/28 [00:00<00:00, 91.15it/s, train_loss=0.00397, val_loss=0.00392]Epoch 34:  25%|██▌       | 7/28 [00:00<00:00, 92.84it/s, train_loss=0.00397, val_loss=0.00392]Epoch 34:  25%|██▌       | 7/28 [00:00<00:00, 90.30it/s, train_loss=0.00439, val_loss=0.00392]Epoch 34:  29%|██▊       | 8/28 [00:00<00:00, 92.99it/s, train_loss=0.00439, val_loss=0.00392]Epoch 34:  29%|██▊       | 8/28 [00:00<00:00, 91.10it/s, train_loss=0.0046, val_loss=0.00392] Epoch 34:  32%|███▏      | 9/28 [00:00<00:00, 92.45it/s, train_loss=0.0046, val_loss=0.00392]Epoch 34:  32%|███▏      | 9/28 [00:00<00:00, 90.46it/s, train_loss=0.00447, val_loss=0.00392]Epoch 34:  36%|███▌      | 10/28 [00:00<00:00, 92.54it/s, train_loss=0.00447, val_loss=0.00392]Epoch 34:  36%|███▌      | 10/28 [00:00<00:00, 90.87it/s, train_loss=0.00357, val_loss=0.00392]Epoch 34:  39%|███▉      | 11/28 [00:00<00:00, 91.67it/s, train_loss=0.00357, val_loss=0.00392]Epoch 34:  39%|███▉      | 11/28 [00:00<00:00, 90.44it/s, train_loss=0.00471, val_loss=0.00392]Epoch 34:  43%|████▎     | 12/28 [00:00<00:00, 92.09it/s, train_loss=0.00471, val_loss=0.00392]Epoch 34:  43%|████▎     | 12/28 [00:00<00:00, 90.76it/s, train_loss=0.00383, val_loss=0.00392]Epoch 34:  46%|████▋     | 13/28 [00:00<00:00, 91.42it/s, train_loss=0.00383, val_loss=0.00392]Epoch 34:  46%|████▋     | 13/28 [00:00<00:00, 90.42it/s, train_loss=0.00398, val_loss=0.00392]Epoch 34:  50%|█████     | 14/28 [00:00<00:00, 91.98it/s, train_loss=0.00398, val_loss=0.00392]Epoch 34:  50%|█████     | 14/28 [00:00<00:00, 90.84it/s, train_loss=0.00459, val_loss=0.00392]Epoch 34:  54%|█████▎    | 15/28 [00:00<00:00, 91.51it/s, train_loss=0.00459, val_loss=0.00392]Epoch 34:  54%|█████▎    | 15/28 [00:00<00:00, 90.46it/s, train_loss=0.00445, val_loss=0.00392]Epoch 34:  57%|█████▋    | 16/28 [00:00<00:00, 91.88it/s, train_loss=0.00445, val_loss=0.00392]Epoch 34:  57%|█████▋    | 16/28 [00:00<00:00, 90.97it/s, train_loss=0.00403, val_loss=0.00392]Epoch 34:  61%|██████    | 17/28 [00:00<00:00, 92.10it/s, train_loss=0.00403, val_loss=0.00392]Epoch 34:  61%|██████    | 17/28 [00:00<00:00, 90.48it/s, train_loss=0.00419, val_loss=0.00392]Epoch 34:  64%|██████▍   | 18/28 [00:00<00:00, 91.59it/s, train_loss=0.00419, val_loss=0.00392]Epoch 34:  64%|██████▍   | 18/28 [00:00<00:00, 90.71it/s, train_loss=0.00434, val_loss=0.00392]Epoch 34:  68%|██████▊   | 19/28 [00:00<00:00, 91.23it/s, train_loss=0.00434, val_loss=0.00392]Epoch 34:  68%|██████▊   | 19/28 [00:00<00:00, 89.84it/s, train_loss=0.00434, val_loss=0.00392]Epoch 34:  71%|███████▏  | 20/28 [00:00<00:00, 90.66it/s, train_loss=0.00434, val_loss=0.00392]Epoch 34:  71%|███████▏  | 20/28 [00:00<00:00, 89.24it/s, train_loss=0.00388, val_loss=0.00392]Epoch 34:  75%|███████▌  | 21/28 [00:00<00:00, 90.09it/s, train_loss=0.00388, val_loss=0.00392]Epoch 34:  75%|███████▌  | 21/28 [00:00<00:00, 89.38it/s, train_loss=0.00467, val_loss=0.00392]Epoch 34:  79%|███████▊  | 22/28 [00:00<00:00, 89.74it/s, train_loss=0.00467, val_loss=0.00392]Epoch 34:  79%|███████▊  | 22/28 [00:00<00:00, 89.29it/s, train_loss=0.00416, val_loss=0.00392]Epoch 34:  82%|████████▏ | 23/28 [00:00<00:00, 90.23it/s, train_loss=0.00416, val_loss=0.00392]Epoch 34:  82%|████████▏ | 23/28 [00:00<00:00, 89.59it/s, train_loss=0.00479, val_loss=0.00392]Epoch 34:  86%|████████▌ | 24/28 [00:00<00:00, 90.08it/s, train_loss=0.00479, val_loss=0.00392]Epoch 34:  86%|████████▌ | 24/28 [00:00<00:00, 89.39it/s, train_loss=0.00459, val_loss=0.00392]Epoch 34:  89%|████████▉ | 25/28 [00:00<00:00, 90.21it/s, train_loss=0.00459, val_loss=0.00392]Epoch 34:  89%|████████▉ | 25/28 [00:00<00:00, 89.59it/s, train_loss=0.00381, val_loss=0.00392]Epoch 34:  93%|█████████▎| 26/28 [00:00<00:00, 89.93it/s, train_loss=0.00381, val_loss=0.00392]Epoch 34:  93%|█████████▎| 26/28 [00:00<00:00, 89.45it/s, train_loss=0.00452, val_loss=0.00392]Epoch 34:  96%|█████████▋| 27/28 [00:00<00:00, 90.20it/s, train_loss=0.00452, val_loss=0.00392]Epoch 34:  96%|█████████▋| 27/28 [00:00<00:00, 89.64it/s, train_loss=0.00412, val_loss=0.00392]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 90.28it/s, train_loss=0.00412, val_loss=0.00392]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 90.03it/s, train_loss=0.00374, val_loss=0.00392]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 125.59it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 143.56it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 152.84it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 157.42it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 160.10it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 161.25it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 162.43it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 162.60it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 165.95it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 169.73it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 172.89it/s][A
                                                                         [AEpoch 34: 100%|██████████| 28/28 [00:00<00:00, 73.44it/s, train_loss=0.00374, val_loss=0.00391]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 73.32it/s, train_loss=0.00374, val_loss=0.00391]Epoch 34:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00391]         Epoch 35:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00391]Epoch 35:   4%|▎         | 1/28 [00:00<00:00, 91.71it/s, train_loss=0.00374, val_loss=0.00391]Epoch 35:   4%|▎         | 1/28 [00:00<00:00, 82.07it/s, train_loss=0.00415, val_loss=0.00391]Epoch 35:   7%|▋         | 2/28 [00:00<00:00, 95.29it/s, train_loss=0.00415, val_loss=0.00391]Epoch 35:   7%|▋         | 2/28 [00:00<00:00, 88.29it/s, train_loss=0.00347, val_loss=0.00391]Epoch 35:  11%|█         | 3/28 [00:00<00:00, 91.96it/s, train_loss=0.00347, val_loss=0.00391]Epoch 35:  11%|█         | 3/28 [00:00<00:00, 87.19it/s, train_loss=0.00401, val_loss=0.00391]Epoch 35:  14%|█▍        | 4/28 [00:00<00:00, 92.69it/s, train_loss=0.00401, val_loss=0.00391]Epoch 35:  14%|█▍        | 4/28 [00:00<00:00, 88.80it/s, train_loss=0.00393, val_loss=0.00391]Epoch 35:  18%|█▊        | 5/28 [00:00<00:00, 91.22it/s, train_loss=0.00393, val_loss=0.00391]Epoch 35:  18%|█▊        | 5/28 [00:00<00:00, 88.20it/s, train_loss=0.00354, val_loss=0.00391]Epoch 35:  21%|██▏       | 6/28 [00:00<00:00, 91.93it/s, train_loss=0.00354, val_loss=0.00391]Epoch 35:  21%|██▏       | 6/28 [00:00<00:00, 89.41it/s, train_loss=0.00401, val_loss=0.00391]Epoch 35:  25%|██▌       | 7/28 [00:00<00:00, 91.11it/s, train_loss=0.00401, val_loss=0.00391]Epoch 35:  25%|██▌       | 7/28 [00:00<00:00, 88.81it/s, train_loss=0.00383, val_loss=0.00391]Epoch 35:  29%|██▊       | 8/28 [00:00<00:00, 91.53it/s, train_loss=0.00383, val_loss=0.00391]Epoch 35:  29%|██▊       | 8/28 [00:00<00:00, 89.57it/s, train_loss=0.00362, val_loss=0.00391]Epoch 35:  32%|███▏      | 9/28 [00:00<00:00, 90.74it/s, train_loss=0.00362, val_loss=0.00391]Epoch 35:  32%|███▏      | 9/28 [00:00<00:00, 89.20it/s, train_loss=0.00372, val_loss=0.00391]Epoch 35:  36%|███▌      | 10/28 [00:00<00:00, 91.34it/s, train_loss=0.00372, val_loss=0.00391]Epoch 35:  36%|███▌      | 10/28 [00:00<00:00, 89.77it/s, train_loss=0.00459, val_loss=0.00391]Epoch 35:  39%|███▉      | 11/28 [00:00<00:00, 90.85it/s, train_loss=0.00459, val_loss=0.00391]Epoch 35:  39%|███▉      | 11/28 [00:00<00:00, 89.39it/s, train_loss=0.00382, val_loss=0.00391]Epoch 35:  43%|████▎     | 12/28 [00:00<00:00, 91.10it/s, train_loss=0.00382, val_loss=0.00391]Epoch 35:  43%|████▎     | 12/28 [00:00<00:00, 89.82it/s, train_loss=0.00437, val_loss=0.00391]Epoch 35:  46%|████▋     | 13/28 [00:00<00:00, 90.45it/s, train_loss=0.00437, val_loss=0.00391]Epoch 35:  46%|████▋     | 13/28 [00:00<00:00, 89.52it/s, train_loss=0.00432, val_loss=0.00391]Epoch 35:  50%|█████     | 14/28 [00:00<00:00, 91.12it/s, train_loss=0.00432, val_loss=0.00391]Epoch 35:  50%|█████     | 14/28 [00:00<00:00, 90.00it/s, train_loss=0.00397, val_loss=0.00391]Epoch 35:  54%|█████▎    | 15/28 [00:00<00:00, 90.86it/s, train_loss=0.00397, val_loss=0.00391]Epoch 35:  54%|█████▎    | 15/28 [00:00<00:00, 89.70it/s, train_loss=0.00482, val_loss=0.00391]Epoch 35:  57%|█████▋    | 16/28 [00:00<00:00, 91.00it/s, train_loss=0.00482, val_loss=0.00391]Epoch 35:  57%|█████▋    | 16/28 [00:00<00:00, 90.00it/s, train_loss=0.00407, val_loss=0.00391]Epoch 35:  61%|██████    | 17/28 [00:00<00:00, 90.61it/s, train_loss=0.00407, val_loss=0.00391]Epoch 35:  61%|██████    | 17/28 [00:00<00:00, 89.78it/s, train_loss=0.00433, val_loss=0.00391]Epoch 35:  64%|██████▍   | 18/28 [00:00<00:00, 91.08it/s, train_loss=0.00433, val_loss=0.00391]Epoch 35:  64%|██████▍   | 18/28 [00:00<00:00, 90.22it/s, train_loss=0.00437, val_loss=0.00391]Epoch 35:  68%|██████▊   | 19/28 [00:00<00:00, 91.22it/s, train_loss=0.00437, val_loss=0.00391]Epoch 35:  68%|██████▊   | 19/28 [00:00<00:00, 89.87it/s, train_loss=0.00486, val_loss=0.00391]Epoch 35:  71%|███████▏  | 20/28 [00:00<00:00, 90.93it/s, train_loss=0.00486, val_loss=0.00391]Epoch 35:  71%|███████▏  | 20/28 [00:00<00:00, 90.15it/s, train_loss=0.00413, val_loss=0.00391]Epoch 35:  75%|███████▌  | 21/28 [00:00<00:00, 90.79it/s, train_loss=0.00413, val_loss=0.00391]Epoch 35:  75%|███████▌  | 21/28 [00:00<00:00, 89.96it/s, train_loss=0.00404, val_loss=0.00391]Epoch 35:  79%|███████▊  | 22/28 [00:00<00:00, 90.93it/s, train_loss=0.00404, val_loss=0.00391]Epoch 35:  79%|███████▊  | 22/28 [00:00<00:00, 90.23it/s, train_loss=0.00442, val_loss=0.00391]Epoch 35:  82%|████████▏ | 23/28 [00:00<00:00, 90.75it/s, train_loss=0.00442, val_loss=0.00391]Epoch 35:  82%|████████▏ | 23/28 [00:00<00:00, 90.03it/s, train_loss=0.0053, val_loss=0.00391] Epoch 35:  86%|████████▌ | 24/28 [00:00<00:00, 90.95it/s, train_loss=0.0053, val_loss=0.00391]Epoch 35:  86%|████████▌ | 24/28 [00:00<00:00, 90.28it/s, train_loss=0.00346, val_loss=0.00391]Epoch 35:  89%|████████▉ | 25/28 [00:00<00:00, 90.77it/s, train_loss=0.00346, val_loss=0.00391]Epoch 35:  89%|████████▉ | 25/28 [00:00<00:00, 90.09it/s, train_loss=0.00411, val_loss=0.00391]Epoch 35:  93%|█████████▎| 26/28 [00:00<00:00, 90.94it/s, train_loss=0.00411, val_loss=0.00391]Epoch 35:  93%|█████████▎| 26/28 [00:00<00:00, 90.37it/s, train_loss=0.00425, val_loss=0.00391]Epoch 35:  96%|█████████▋| 27/28 [00:00<00:00, 91.00it/s, train_loss=0.00425, val_loss=0.00391]Epoch 35:  96%|█████████▋| 27/28 [00:00<00:00, 90.10it/s, train_loss=0.00441, val_loss=0.00391]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 91.05it/s, train_loss=0.00441, val_loss=0.00391]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 90.76it/s, train_loss=0.00301, val_loss=0.00391]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 129.70it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 149.42it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 156.40it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 160.88it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 162.15it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 163.97it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 164.67it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 159.83it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 156.30it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 157.74it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 157.81it/s][A
                                                                         [AEpoch 35: 100%|██████████| 28/28 [00:00<00:00, 71.93it/s, train_loss=0.00301, val_loss=0.00388]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 71.73it/s, train_loss=0.00301, val_loss=0.00388]Epoch 35:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00301, val_loss=0.00388]         Epoch 36:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00301, val_loss=0.00388]Epoch 36:   4%|▎         | 1/28 [00:00<00:00, 91.24it/s, train_loss=0.00301, val_loss=0.00388]Epoch 36:   4%|▎         | 1/28 [00:00<00:00, 78.04it/s, train_loss=0.00441, val_loss=0.00388]Epoch 36:   7%|▋         | 2/28 [00:00<00:00, 91.24it/s, train_loss=0.00441, val_loss=0.00388]Epoch 36:   7%|▋         | 2/28 [00:00<00:00, 84.70it/s, train_loss=0.00375, val_loss=0.00388]Epoch 36:  11%|█         | 3/28 [00:00<00:00, 91.48it/s, train_loss=0.00375, val_loss=0.00388]Epoch 36:  11%|█         | 3/28 [00:00<00:00, 84.62it/s, train_loss=0.00464, val_loss=0.00388]Epoch 36:  14%|█▍        | 4/28 [00:00<00:00, 89.77it/s, train_loss=0.00464, val_loss=0.00388]Epoch 36:  14%|█▍        | 4/28 [00:00<00:00, 86.74it/s, train_loss=0.00524, val_loss=0.00388]Epoch 36:  18%|█▊        | 5/28 [00:00<00:00, 89.00it/s, train_loss=0.00524, val_loss=0.00388]Epoch 36:  18%|█▊        | 5/28 [00:00<00:00, 86.77it/s, train_loss=0.00445, val_loss=0.00388]Epoch 36:  21%|██▏       | 6/28 [00:00<00:00, 90.58it/s, train_loss=0.00445, val_loss=0.00388]Epoch 36:  21%|██▏       | 6/28 [00:00<00:00, 88.07it/s, train_loss=0.00415, val_loss=0.00388]Epoch 36:  25%|██▌       | 7/28 [00:00<00:00, 89.57it/s, train_loss=0.00415, val_loss=0.00388]Epoch 36:  25%|██▌       | 7/28 [00:00<00:00, 88.01it/s, train_loss=0.00394, val_loss=0.00388]Epoch 36:  29%|██▊       | 8/28 [00:00<00:00, 90.63it/s, train_loss=0.00394, val_loss=0.00388]Epoch 36:  29%|██▊       | 8/28 [00:00<00:00, 88.90it/s, train_loss=0.0044, val_loss=0.00388] Epoch 36:  32%|███▏      | 9/28 [00:00<00:00, 90.02it/s, train_loss=0.0044, val_loss=0.00388]Epoch 36:  32%|███▏      | 9/28 [00:00<00:00, 88.48it/s, train_loss=0.00391, val_loss=0.00388]Epoch 36:  36%|███▌      | 10/28 [00:00<00:00, 90.49it/s, train_loss=0.00391, val_loss=0.00388]Epoch 36:  36%|███▌      | 10/28 [00:00<00:00, 89.08it/s, train_loss=0.00421, val_loss=0.00388]Epoch 36:  39%|███▉      | 11/28 [00:00<00:00, 89.93it/s, train_loss=0.00421, val_loss=0.00388]Epoch 36:  39%|███▉      | 11/28 [00:00<00:00, 88.76it/s, train_loss=0.00537, val_loss=0.00388]Epoch 36:  43%|████▎     | 12/28 [00:00<00:00, 90.49it/s, train_loss=0.00537, val_loss=0.00388]Epoch 36:  43%|████▎     | 12/28 [00:00<00:00, 89.23it/s, train_loss=0.00433, val_loss=0.00388]Epoch 36:  46%|████▋     | 13/28 [00:00<00:00, 90.31it/s, train_loss=0.00433, val_loss=0.00388]Epoch 36:  46%|████▋     | 13/28 [00:00<00:00, 89.02it/s, train_loss=0.00365, val_loss=0.00388]Epoch 36:  50%|█████     | 14/28 [00:00<00:00, 90.64it/s, train_loss=0.00365, val_loss=0.00388]Epoch 36:  50%|█████     | 14/28 [00:00<00:00, 89.61it/s, train_loss=0.00374, val_loss=0.00388]Epoch 36:  54%|█████▎    | 15/28 [00:00<00:00, 90.53it/s, train_loss=0.00374, val_loss=0.00388]Epoch 36:  54%|█████▎    | 15/28 [00:00<00:00, 89.32it/s, train_loss=0.00534, val_loss=0.00388]Epoch 36:  57%|█████▋    | 16/28 [00:00<00:00, 90.69it/s, train_loss=0.00534, val_loss=0.00388]Epoch 36:  57%|█████▋    | 16/28 [00:00<00:00, 89.78it/s, train_loss=0.00458, val_loss=0.00388]Epoch 36:  61%|██████    | 17/28 [00:00<00:00, 90.60it/s, train_loss=0.00458, val_loss=0.00388]Epoch 36:  61%|██████    | 17/28 [00:00<00:00, 89.53it/s, train_loss=0.00419, val_loss=0.00388]Epoch 36:  64%|██████▍   | 18/28 [00:00<00:00, 90.75it/s, train_loss=0.00419, val_loss=0.00388]Epoch 36:  64%|██████▍   | 18/28 [00:00<00:00, 89.91it/s, train_loss=0.00412, val_loss=0.00388]Epoch 36:  68%|██████▊   | 19/28 [00:00<00:00, 90.57it/s, train_loss=0.00412, val_loss=0.00388]Epoch 36:  68%|██████▊   | 19/28 [00:00<00:00, 89.67it/s, train_loss=0.00364, val_loss=0.00388]Epoch 36:  71%|███████▏  | 20/28 [00:00<00:00, 90.73it/s, train_loss=0.00364, val_loss=0.00388]Epoch 36:  71%|███████▏  | 20/28 [00:00<00:00, 89.97it/s, train_loss=0.00412, val_loss=0.00388]Epoch 36:  75%|███████▌  | 21/28 [00:00<00:00, 90.69it/s, train_loss=0.00412, val_loss=0.00388]Epoch 36:  75%|███████▌  | 21/28 [00:00<00:00, 89.78it/s, train_loss=0.00387, val_loss=0.00388]Epoch 36:  79%|███████▊  | 22/28 [00:00<00:00, 90.86it/s, train_loss=0.00387, val_loss=0.00388]Epoch 36:  79%|███████▊  | 22/28 [00:00<00:00, 90.18it/s, train_loss=0.00357, val_loss=0.00388]Epoch 36:  82%|████████▏ | 23/28 [00:00<00:00, 91.01it/s, train_loss=0.00357, val_loss=0.00388]Epoch 36:  82%|████████▏ | 23/28 [00:00<00:00, 89.85it/s, train_loss=0.00353, val_loss=0.00388]Epoch 36:  86%|████████▌ | 24/28 [00:00<00:00, 90.70it/s, train_loss=0.00353, val_loss=0.00388]Epoch 36:  86%|████████▌ | 24/28 [00:00<00:00, 90.03it/s, train_loss=0.00571, val_loss=0.00388]Epoch 36:  89%|████████▉ | 25/28 [00:00<00:00, 90.52it/s, train_loss=0.00571, val_loss=0.00388]Epoch 36:  89%|████████▉ | 25/28 [00:00<00:00, 89.87it/s, train_loss=0.00344, val_loss=0.00388]Epoch 36:  93%|█████████▎| 26/28 [00:00<00:00, 90.71it/s, train_loss=0.00344, val_loss=0.00388]Epoch 36:  93%|█████████▎| 26/28 [00:00<00:00, 90.10it/s, train_loss=0.0045, val_loss=0.00388] Epoch 36:  96%|█████████▋| 27/28 [00:00<00:00, 90.57it/s, train_loss=0.0045, val_loss=0.00388]Epoch 36:  96%|█████████▋| 27/28 [00:00<00:00, 89.92it/s, train_loss=0.00355, val_loss=0.00388]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 91.02it/s, train_loss=0.00355, val_loss=0.00388]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 90.77it/s, train_loss=0.00297, val_loss=0.00388]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 135.79it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 154.64it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 162.85it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 163.45it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 166.82it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 168.42it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 169.42it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 169.60it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 170.27it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 170.81it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 170.28it/s][A
                                                                         [AEpoch 36: 100%|██████████| 28/28 [00:00<00:00, 73.57it/s, train_loss=0.00297, val_loss=0.00388]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 73.38it/s, train_loss=0.00297, val_loss=0.00388]Epoch 36:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00388]         Epoch 37:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00388]Epoch 37:   4%|▎         | 1/28 [00:00<00:00, 88.12it/s, train_loss=0.00297, val_loss=0.00388]Epoch 37:   4%|▎         | 1/28 [00:00<00:00, 81.29it/s, train_loss=0.00409, val_loss=0.00388]Epoch 37:   7%|▋         | 2/28 [00:00<00:00, 89.16it/s, train_loss=0.00409, val_loss=0.00388]Epoch 37:   7%|▋         | 2/28 [00:00<00:00, 82.84it/s, train_loss=0.00397, val_loss=0.00388]Epoch 37:  11%|█         | 3/28 [00:00<00:00, 90.47it/s, train_loss=0.00397, val_loss=0.00388]Epoch 37:  11%|█         | 3/28 [00:00<00:00, 86.09it/s, train_loss=0.0041, val_loss=0.00388] Epoch 37:  14%|█▍        | 4/28 [00:00<00:00, 90.18it/s, train_loss=0.0041, val_loss=0.00388]Epoch 37:  14%|█▍        | 4/28 [00:00<00:00, 86.33it/s, train_loss=0.0041, val_loss=0.00388]Epoch 37:  18%|█▊        | 5/28 [00:00<00:00, 91.14it/s, train_loss=0.0041, val_loss=0.00388]Epoch 37:  18%|█▊        | 5/28 [00:00<00:00, 88.45it/s, train_loss=0.00463, val_loss=0.00388]Epoch 37:  21%|██▏       | 6/28 [00:00<00:00, 91.00it/s, train_loss=0.00463, val_loss=0.00388]Epoch 37:  21%|██▏       | 6/28 [00:00<00:00, 87.83it/s, train_loss=0.0041, val_loss=0.00388] Epoch 37:  25%|██▌       | 7/28 [00:00<00:00, 91.13it/s, train_loss=0.0041, val_loss=0.00388]Epoch 37:  25%|██▌       | 7/28 [00:00<00:00, 89.01it/s, train_loss=0.00426, val_loss=0.00388]Epoch 37:  29%|██▊       | 8/28 [00:00<00:00, 91.19it/s, train_loss=0.00426, val_loss=0.00388]Epoch 37:  29%|██▊       | 8/28 [00:00<00:00, 88.30it/s, train_loss=0.00442, val_loss=0.00388]Epoch 37:  32%|███▏      | 9/28 [00:00<00:00, 90.47it/s, train_loss=0.00442, val_loss=0.00388]Epoch 37:  32%|███▏      | 9/28 [00:00<00:00, 88.91it/s, train_loss=0.00469, val_loss=0.00388]Epoch 37:  36%|███▌      | 10/28 [00:00<00:00, 90.27it/s, train_loss=0.00469, val_loss=0.00388]Epoch 37:  36%|███▌      | 10/28 [00:00<00:00, 88.59it/s, train_loss=0.00416, val_loss=0.00388]Epoch 37:  39%|███▉      | 11/28 [00:00<00:00, 90.70it/s, train_loss=0.00416, val_loss=0.00388]Epoch 37:  39%|███▉      | 11/28 [00:00<00:00, 89.40it/s, train_loss=0.00462, val_loss=0.00388]Epoch 37:  43%|████▎     | 12/28 [00:00<00:00, 90.93it/s, train_loss=0.00462, val_loss=0.00388]Epoch 37:  43%|████▎     | 12/28 [00:00<00:00, 88.84it/s, train_loss=0.00421, val_loss=0.00388]Epoch 37:  46%|████▋     | 13/28 [00:00<00:00, 90.40it/s, train_loss=0.00421, val_loss=0.00388]Epoch 37:  46%|████▋     | 13/28 [00:00<00:00, 89.17it/s, train_loss=0.00404, val_loss=0.00388]Epoch 37:  50%|█████     | 14/28 [00:00<00:00, 90.00it/s, train_loss=0.00404, val_loss=0.00388]Epoch 37:  50%|█████     | 14/28 [00:00<00:00, 88.95it/s, train_loss=0.00504, val_loss=0.00388]Epoch 37:  54%|█████▎    | 15/28 [00:00<00:00, 90.30it/s, train_loss=0.00504, val_loss=0.00388]Epoch 37:  54%|█████▎    | 15/28 [00:00<00:00, 89.34it/s, train_loss=0.00405, val_loss=0.00388]Epoch 37:  57%|█████▋    | 16/28 [00:00<00:00, 90.05it/s, train_loss=0.00405, val_loss=0.00388]Epoch 37:  57%|█████▋    | 16/28 [00:00<00:00, 89.07it/s, train_loss=0.0045, val_loss=0.00388] Epoch 37:  61%|██████    | 17/28 [00:00<00:00, 90.31it/s, train_loss=0.0045, val_loss=0.00388]Epoch 37:  61%|██████    | 17/28 [00:00<00:00, 89.40it/s, train_loss=0.00361, val_loss=0.00388]Epoch 37:  64%|██████▍   | 18/28 [00:00<00:00, 89.96it/s, train_loss=0.00361, val_loss=0.00388]Epoch 37:  64%|██████▍   | 18/28 [00:00<00:00, 89.20it/s, train_loss=0.00373, val_loss=0.00388]Epoch 37:  68%|██████▊   | 19/28 [00:00<00:00, 90.28it/s, train_loss=0.00373, val_loss=0.00388]Epoch 37:  68%|██████▊   | 19/28 [00:00<00:00, 89.47it/s, train_loss=0.00353, val_loss=0.00388]Epoch 37:  71%|███████▏  | 20/28 [00:00<00:00, 90.04it/s, train_loss=0.00353, val_loss=0.00388]Epoch 37:  71%|███████▏  | 20/28 [00:00<00:00, 89.31it/s, train_loss=0.00438, val_loss=0.00388]Epoch 37:  75%|███████▌  | 21/28 [00:00<00:00, 90.28it/s, train_loss=0.00438, val_loss=0.00388]Epoch 37:  75%|███████▌  | 21/28 [00:00<00:00, 89.52it/s, train_loss=0.00379, val_loss=0.00388]Epoch 37:  79%|███████▊  | 22/28 [00:00<00:00, 90.03it/s, train_loss=0.00379, val_loss=0.00388]Epoch 37:  79%|███████▊  | 22/28 [00:00<00:00, 89.38it/s, train_loss=0.00394, val_loss=0.00388]Epoch 37:  82%|████████▏ | 23/28 [00:00<00:00, 90.44it/s, train_loss=0.00394, val_loss=0.00388]Epoch 37:  82%|████████▏ | 23/28 [00:00<00:00, 89.79it/s, train_loss=0.00476, val_loss=0.00388]Epoch 37:  86%|████████▌ | 24/28 [00:00<00:00, 90.60it/s, train_loss=0.00476, val_loss=0.00388]Epoch 37:  86%|████████▌ | 24/28 [00:00<00:00, 89.48it/s, train_loss=0.00442, val_loss=0.00388]Epoch 37:  89%|████████▉ | 25/28 [00:00<00:00, 90.31it/s, train_loss=0.00442, val_loss=0.00388]Epoch 37:  89%|████████▉ | 25/28 [00:00<00:00, 89.73it/s, train_loss=0.00407, val_loss=0.00388]Epoch 37:  93%|█████████▎| 26/28 [00:00<00:00, 90.59it/s, train_loss=0.00407, val_loss=0.00388]Epoch 37:  93%|█████████▎| 26/28 [00:00<00:00, 89.33it/s, train_loss=0.00389, val_loss=0.00388]Epoch 37:  96%|█████████▋| 27/28 [00:00<00:00, 90.05it/s, train_loss=0.00389, val_loss=0.00388]Epoch 37:  96%|█████████▋| 27/28 [00:00<00:00, 89.50it/s, train_loss=0.00387, val_loss=0.00388]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 90.31it/s, train_loss=0.00387, val_loss=0.00388]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 90.09it/s, train_loss=0.00231, val_loss=0.00388]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 142.68it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 158.98it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 167.73it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 172.10it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 173.77it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 175.75it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 176.47it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 177.46it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 177.82it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 177.18it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 177.63it/s][A
                                                                         [AEpoch 37: 100%|██████████| 28/28 [00:00<00:00, 73.30it/s, train_loss=0.00231, val_loss=0.00387]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 73.12it/s, train_loss=0.00231, val_loss=0.00387]Epoch 37:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.00387]         Epoch 38:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.00387]Epoch 38:   4%|▎         | 1/28 [00:00<00:00, 87.36it/s, train_loss=0.00231, val_loss=0.00387]Epoch 38:   4%|▎         | 1/28 [00:00<00:00, 81.05it/s, train_loss=0.00449, val_loss=0.00387]Epoch 38:   7%|▋         | 2/28 [00:00<00:00, 94.54it/s, train_loss=0.00449, val_loss=0.00387]Epoch 38:   7%|▋         | 2/28 [00:00<00:00, 87.75it/s, train_loss=0.00375, val_loss=0.00387]Epoch 38:  11%|█         | 3/28 [00:00<00:00, 90.38it/s, train_loss=0.00375, val_loss=0.00387]Epoch 38:  11%|█         | 3/28 [00:00<00:00, 87.67it/s, train_loss=0.00369, val_loss=0.00387]Epoch 38:  14%|█▍        | 4/28 [00:00<00:00, 92.45it/s, train_loss=0.00369, val_loss=0.00387]Epoch 38:  14%|█▍        | 4/28 [00:00<00:00, 89.26it/s, train_loss=0.00403, val_loss=0.00387]Epoch 38:  18%|█▊        | 5/28 [00:00<00:00, 90.66it/s, train_loss=0.00403, val_loss=0.00387]Epoch 38:  18%|█▊        | 5/28 [00:00<00:00, 88.54it/s, train_loss=0.00423, val_loss=0.00387]Epoch 38:  21%|██▏       | 6/28 [00:00<00:00, 91.54it/s, train_loss=0.00423, val_loss=0.00387]Epoch 38:  21%|██▏       | 6/28 [00:00<00:00, 89.34it/s, train_loss=0.00451, val_loss=0.00387]Epoch 38:  25%|██▌       | 7/28 [00:00<00:00, 90.65it/s, train_loss=0.00451, val_loss=0.00387]Epoch 38:  25%|██▌       | 7/28 [00:00<00:00, 89.00it/s, train_loss=0.0042, val_loss=0.00387] Epoch 38:  29%|██▊       | 8/28 [00:00<00:00, 91.58it/s, train_loss=0.0042, val_loss=0.00387]Epoch 38:  29%|██▊       | 8/28 [00:00<00:00, 89.68it/s, train_loss=0.00416, val_loss=0.00387]Epoch 38:  32%|███▏      | 9/28 [00:00<00:00, 91.42it/s, train_loss=0.00416, val_loss=0.00387]Epoch 38:  32%|███▏      | 9/28 [00:00<00:00, 89.28it/s, train_loss=0.0042, val_loss=0.00387] Epoch 38:  36%|███▌      | 10/28 [00:00<00:00, 91.62it/s, train_loss=0.0042, val_loss=0.00387]Epoch 38:  36%|███▌      | 10/28 [00:00<00:00, 90.14it/s, train_loss=0.00433, val_loss=0.00387]Epoch 38:  39%|███▉      | 11/28 [00:00<00:00, 92.20it/s, train_loss=0.00433, val_loss=0.00387]Epoch 38:  39%|███▉      | 11/28 [00:00<00:00, 89.45it/s, train_loss=0.00373, val_loss=0.00387]Epoch 38:  43%|████▎     | 12/28 [00:00<00:00, 91.20it/s, train_loss=0.00373, val_loss=0.00387]Epoch 38:  43%|████▎     | 12/28 [00:00<00:00, 89.86it/s, train_loss=0.00404, val_loss=0.00387]Epoch 38:  46%|████▋     | 13/28 [00:00<00:00, 91.01it/s, train_loss=0.00404, val_loss=0.00387]Epoch 38:  46%|████▋     | 13/28 [00:00<00:00, 89.56it/s, train_loss=0.00325, val_loss=0.00387]Epoch 38:  50%|█████     | 14/28 [00:00<00:00, 91.19it/s, train_loss=0.00325, val_loss=0.00387]Epoch 38:  50%|█████     | 14/28 [00:00<00:00, 90.14it/s, train_loss=0.00339, val_loss=0.00387]Epoch 38:  54%|█████▎    | 15/28 [00:00<00:00, 91.46it/s, train_loss=0.00339, val_loss=0.00387]Epoch 38:  54%|█████▎    | 15/28 [00:00<00:00, 89.64it/s, train_loss=0.00435, val_loss=0.00387]Epoch 38:  57%|█████▋    | 16/28 [00:00<00:00, 90.92it/s, train_loss=0.00435, val_loss=0.00387]Epoch 38:  57%|█████▋    | 16/28 [00:00<00:00, 89.92it/s, train_loss=0.00432, val_loss=0.00387]Epoch 38:  61%|██████    | 17/28 [00:00<00:00, 90.83it/s, train_loss=0.00432, val_loss=0.00387]Epoch 38:  61%|██████    | 17/28 [00:00<00:00, 89.70it/s, train_loss=0.00385, val_loss=0.00387]Epoch 38:  64%|██████▍   | 18/28 [00:00<00:00, 90.94it/s, train_loss=0.00385, val_loss=0.00387]Epoch 38:  64%|██████▍   | 18/28 [00:00<00:00, 90.02it/s, train_loss=0.00389, val_loss=0.00387]Epoch 38:  68%|██████▊   | 19/28 [00:00<00:00, 90.76it/s, train_loss=0.00389, val_loss=0.00387]Epoch 38:  68%|██████▊   | 19/28 [00:00<00:00, 89.84it/s, train_loss=0.00511, val_loss=0.00387]Epoch 38:  71%|███████▏  | 20/28 [00:00<00:00, 90.92it/s, train_loss=0.00511, val_loss=0.00387]Epoch 38:  71%|███████▏  | 20/28 [00:00<00:00, 90.19it/s, train_loss=0.0044, val_loss=0.00387] Epoch 38:  75%|███████▌  | 21/28 [00:00<00:00, 90.78it/s, train_loss=0.0044, val_loss=0.00387]Epoch 38:  75%|███████▌  | 21/28 [00:00<00:00, 89.95it/s, train_loss=0.00414, val_loss=0.00387]Epoch 38:  79%|███████▊  | 22/28 [00:00<00:00, 90.90it/s, train_loss=0.00414, val_loss=0.00387]Epoch 38:  79%|███████▊  | 22/28 [00:00<00:00, 90.18it/s, train_loss=0.00404, val_loss=0.00387]Epoch 38:  82%|████████▏ | 23/28 [00:00<00:00, 90.66it/s, train_loss=0.00404, val_loss=0.00387]Epoch 38:  82%|████████▏ | 23/28 [00:00<00:00, 90.01it/s, train_loss=0.00361, val_loss=0.00387]Epoch 38:  86%|████████▌ | 24/28 [00:00<00:00, 90.90it/s, train_loss=0.00361, val_loss=0.00387]Epoch 38:  86%|████████▌ | 24/28 [00:00<00:00, 90.27it/s, train_loss=0.00431, val_loss=0.00387]Epoch 38:  89%|████████▉ | 25/28 [00:00<00:00, 90.68it/s, train_loss=0.00431, val_loss=0.00387]Epoch 38:  89%|████████▉ | 25/28 [00:00<00:00, 90.08it/s, train_loss=0.00465, val_loss=0.00387]Epoch 38:  93%|█████████▎| 26/28 [00:00<00:00, 91.00it/s, train_loss=0.00465, val_loss=0.00387]Epoch 38:  93%|█████████▎| 26/28 [00:00<00:00, 90.42it/s, train_loss=0.00429, val_loss=0.00387]Epoch 38:  96%|█████████▋| 27/28 [00:00<00:00, 91.21it/s, train_loss=0.00429, val_loss=0.00387]Epoch 38:  96%|█████████▋| 27/28 [00:00<00:00, 90.09it/s, train_loss=0.00497, val_loss=0.00387]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 91.11it/s, train_loss=0.00497, val_loss=0.00387]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 90.64it/s, train_loss=0.00393, val_loss=0.00387]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 143.30it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 163.01it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 171.48it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 171.73it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 174.49it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 176.59it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 178.22it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 179.38it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 179.18it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 179.90it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 180.98it/s][A
                                                                         [AEpoch 38: 100%|██████████| 28/28 [00:00<00:00, 74.37it/s, train_loss=0.00393, val_loss=0.00387]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 74.20it/s, train_loss=0.00393, val_loss=0.00387]Epoch 38:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00393, val_loss=0.00387]         Epoch 39:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00393, val_loss=0.00387]Epoch 39:   4%|▎         | 1/28 [00:00<00:00, 89.00it/s, train_loss=0.00393, val_loss=0.00387]Epoch 39:   4%|▎         | 1/28 [00:00<00:00, 83.09it/s, train_loss=0.00416, val_loss=0.00387]Epoch 39:   7%|▋         | 2/28 [00:00<00:00, 97.09it/s, train_loss=0.00416, val_loss=0.00387]Epoch 39:   7%|▋         | 2/28 [00:00<00:00, 89.67it/s, train_loss=0.00413, val_loss=0.00387]Epoch 39:  11%|█         | 3/28 [00:00<00:00, 91.73it/s, train_loss=0.00413, val_loss=0.00387]Epoch 39:  11%|█         | 3/28 [00:00<00:00, 89.42it/s, train_loss=0.00451, val_loss=0.00387]Epoch 39:  14%|█▍        | 4/28 [00:00<00:00, 94.49it/s, train_loss=0.00451, val_loss=0.00387]Epoch 39:  14%|█▍        | 4/28 [00:00<00:00, 91.04it/s, train_loss=0.00426, val_loss=0.00387]Epoch 39:  18%|█▊        | 5/28 [00:00<00:00, 92.71it/s, train_loss=0.00426, val_loss=0.00387]Epoch 39:  18%|█▊        | 5/28 [00:00<00:00, 90.36it/s, train_loss=0.00377, val_loss=0.00387]Epoch 39:  21%|██▏       | 6/28 [00:00<00:00, 93.76it/s, train_loss=0.00377, val_loss=0.00387]Epoch 39:  21%|██▏       | 6/28 [00:00<00:00, 91.06it/s, train_loss=0.00437, val_loss=0.00387]Epoch 39:  25%|██▌       | 7/28 [00:00<00:00, 92.22it/s, train_loss=0.00437, val_loss=0.00387]Epoch 39:  25%|██▌       | 7/28 [00:00<00:00, 90.40it/s, train_loss=0.00375, val_loss=0.00387]Epoch 39:  29%|██▊       | 8/28 [00:00<00:00, 92.92it/s, train_loss=0.00375, val_loss=0.00387]Epoch 39:  29%|██▊       | 8/28 [00:00<00:00, 90.85it/s, train_loss=0.004, val_loss=0.00387]  Epoch 39:  32%|███▏      | 9/28 [00:00<00:00, 91.83it/s, train_loss=0.004, val_loss=0.00387]Epoch 39:  32%|███▏      | 9/28 [00:00<00:00, 90.39it/s, train_loss=0.00375, val_loss=0.00387]Epoch 39:  36%|███▌      | 10/28 [00:00<00:00, 92.67it/s, train_loss=0.00375, val_loss=0.00387]Epoch 39:  36%|███▌      | 10/28 [00:00<00:00, 91.08it/s, train_loss=0.00407, val_loss=0.00387]Epoch 39:  39%|███▉      | 11/28 [00:00<00:00, 92.78it/s, train_loss=0.00407, val_loss=0.00387]Epoch 39:  39%|███▉      | 11/28 [00:00<00:00, 90.35it/s, train_loss=0.00403, val_loss=0.00387]Epoch 39:  43%|████▎     | 12/28 [00:00<00:00, 92.04it/s, train_loss=0.00403, val_loss=0.00387]Epoch 39:  43%|████▎     | 12/28 [00:00<00:00, 90.70it/s, train_loss=0.00501, val_loss=0.00387]Epoch 39:  46%|████▋     | 13/28 [00:00<00:00, 91.66it/s, train_loss=0.00501, val_loss=0.00387]Epoch 39:  46%|████▋     | 13/28 [00:00<00:00, 90.34it/s, train_loss=0.00392, val_loss=0.00387]Epoch 39:  50%|█████     | 14/28 [00:00<00:00, 91.74it/s, train_loss=0.00392, val_loss=0.00387]Epoch 39:  50%|█████     | 14/28 [00:00<00:00, 90.75it/s, train_loss=0.00527, val_loss=0.00387]Epoch 39:  54%|█████▎    | 15/28 [00:00<00:00, 91.83it/s, train_loss=0.00527, val_loss=0.00387]Epoch 39:  54%|█████▎    | 15/28 [00:00<00:00, 90.12it/s, train_loss=0.00438, val_loss=0.00387]Epoch 39:  57%|█████▋    | 16/28 [00:00<00:00, 90.96it/s, train_loss=0.00438, val_loss=0.00387]Epoch 39:  57%|█████▋    | 16/28 [00:00<00:00, 90.03it/s, train_loss=0.0047, val_loss=0.00387] Epoch 39:  61%|██████    | 17/28 [00:00<00:00, 90.64it/s, train_loss=0.0047, val_loss=0.00387]Epoch 39:  61%|██████    | 17/28 [00:00<00:00, 90.13it/s, train_loss=0.00422, val_loss=0.00387]Epoch 39:  64%|██████▍   | 18/28 [00:00<00:00, 91.33it/s, train_loss=0.00422, val_loss=0.00387]Epoch 39:  64%|██████▍   | 18/28 [00:00<00:00, 90.45it/s, train_loss=0.00365, val_loss=0.00387]Epoch 39:  68%|██████▊   | 19/28 [00:00<00:00, 91.06it/s, train_loss=0.00365, val_loss=0.00387]Epoch 39:  68%|██████▊   | 19/28 [00:00<00:00, 90.17it/s, train_loss=0.00356, val_loss=0.00387]Epoch 39:  71%|███████▏  | 20/28 [00:00<00:00, 91.22it/s, train_loss=0.00356, val_loss=0.00387]Epoch 39:  71%|███████▏  | 20/28 [00:00<00:00, 90.42it/s, train_loss=0.00429, val_loss=0.00387]Epoch 39:  75%|███████▌  | 21/28 [00:00<00:00, 90.95it/s, train_loss=0.00429, val_loss=0.00387]Epoch 39:  75%|███████▌  | 21/28 [00:00<00:00, 90.22it/s, train_loss=0.00418, val_loss=0.00387]Epoch 39:  79%|███████▊  | 22/28 [00:00<00:00, 91.20it/s, train_loss=0.00418, val_loss=0.00387]Epoch 39:  79%|███████▊  | 22/28 [00:00<00:00, 90.53it/s, train_loss=0.00461, val_loss=0.00387]Epoch 39:  82%|████████▏ | 23/28 [00:00<00:00, 90.99it/s, train_loss=0.00461, val_loss=0.00387]Epoch 39:  82%|████████▏ | 23/28 [00:00<00:00, 90.32it/s, train_loss=0.00302, val_loss=0.00387]Epoch 39:  86%|████████▌ | 24/28 [00:00<00:00, 91.18it/s, train_loss=0.00302, val_loss=0.00387]Epoch 39:  86%|████████▌ | 24/28 [00:00<00:00, 90.51it/s, train_loss=0.00454, val_loss=0.00387]Epoch 39:  89%|████████▉ | 25/28 [00:00<00:00, 90.93it/s, train_loss=0.00454, val_loss=0.00387]Epoch 39:  89%|████████▉ | 25/28 [00:00<00:00, 90.34it/s, train_loss=0.00402, val_loss=0.00387]Epoch 39:  93%|█████████▎| 26/28 [00:00<00:00, 91.20it/s, train_loss=0.00402, val_loss=0.00387]Epoch 39:  93%|█████████▎| 26/28 [00:00<00:00, 90.58it/s, train_loss=0.00355, val_loss=0.00387]Epoch 39:  96%|█████████▋| 27/28 [00:00<00:00, 91.00it/s, train_loss=0.00355, val_loss=0.00387]Epoch 39:  96%|█████████▋| 27/28 [00:00<00:00, 90.40it/s, train_loss=0.00395, val_loss=0.00387]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 91.55it/s, train_loss=0.00395, val_loss=0.00387]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 90.90it/s, train_loss=0.00479, val_loss=0.00387]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 174.66it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 188.28it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 193.91it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 198.50it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 198.62it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 198.96it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 198.25it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 197.82it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 197.11it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 194.47it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 193.99it/s][A
                                                                         [AEpoch 39: 100%|██████████| 28/28 [00:00<00:00, 75.36it/s, train_loss=0.00479, val_loss=0.00387]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 75.20it/s, train_loss=0.00479, val_loss=0.00387]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 74.88it/s, train_loss=0.00479, val_loss=0.00387]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▎         | 1/27 [00:00<00:00, 85.49it/s]Predicting DataLoader 0:   7%|▋         | 2/27 [00:00<00:00, 79.79it/s]Predicting DataLoader 0:  11%|█         | 3/27 [00:00<00:00, 77.98it/s]Predicting DataLoader 0:  15%|█▍        | 4/27 [00:00<00:00, 77.23it/s]Predicting DataLoader 0:  19%|█▊        | 5/27 [00:00<00:00, 76.42it/s]Predicting DataLoader 0:  22%|██▏       | 6/27 [00:00<00:00, 75.99it/s]Predicting DataLoader 0:  26%|██▌       | 7/27 [00:00<00:00, 75.77it/s]Predicting DataLoader 0:  30%|██▉       | 8/27 [00:00<00:00, 75.66it/s]Predicting DataLoader 0:  33%|███▎      | 9/27 [00:00<00:00, 74.48it/s]Predicting DataLoader 0:  37%|███▋      | 10/27 [00:00<00:00, 74.25it/s]Predicting DataLoader 0:  41%|████      | 11/27 [00:00<00:00, 73.93it/s]Predicting DataLoader 0:  44%|████▍     | 12/27 [00:00<00:00, 73.68it/s]Predicting DataLoader 0:  48%|████▊     | 13/27 [00:00<00:00, 73.54it/s]Predicting DataLoader 0:  52%|█████▏    | 14/27 [00:00<00:00, 73.45it/s]Predicting DataLoader 0:  56%|█████▌    | 15/27 [00:00<00:00, 73.46it/s]Predicting DataLoader 0:  59%|█████▉    | 16/27 [00:00<00:00, 73.53it/s]Predicting DataLoader 0:  63%|██████▎   | 17/27 [00:00<00:00, 73.60it/s]Predicting DataLoader 0:  67%|██████▋   | 18/27 [00:00<00:00, 73.64it/s]Predicting DataLoader 0:  70%|███████   | 19/27 [00:00<00:00, 73.19it/s]Predicting DataLoader 0:  74%|███████▍  | 20/27 [00:00<00:00, 73.08it/s]Predicting DataLoader 0:  78%|███████▊  | 21/27 [00:00<00:00, 72.96it/s]Predicting DataLoader 0:  81%|████████▏ | 22/27 [00:00<00:00, 72.91it/s]Predicting DataLoader 0:  85%|████████▌ | 23/27 [00:00<00:00, 72.93it/s]Predicting DataLoader 0:  89%|████████▉ | 24/27 [00:00<00:00, 73.04it/s]Predicting DataLoader 0:  93%|█████████▎| 25/27 [00:00<00:00, 73.16it/s]Predicting DataLoader 0:  96%|█████████▋| 26/27 [00:00<00:00, 73.21it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 73.62it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 73.45it/s][I 2025-08-18 02:04:04,784] A new study created in memory with name: no-name-c8eb0dbb-ef02-46d5-a344-912e89ec6a1b
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23537284419156973 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 32, Horizon length: 1
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 426.60it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 319.32it/s][I 2025-08-18 02:04:13,821] Trial 0 finished with value: 18.36642238526888 and parameters: {'hidden_dim': 45, 'n_rnn_layers': 1, 'dropout': 0.23537284419156973}. Best is trial 0 with value: 18.36642238526888.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 306.74it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.63it/s][I 2025-08-18 02:04:29,894] Trial 1 finished with value: 20.25918614221825 and parameters: {'hidden_dim': 55, 'n_rnn_layers': 4, 'dropout': 0.3202092564917566}. Best is trial 0 with value: 18.36642238526888.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 324.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 248.32it/s][I 2025-08-18 02:04:38,768] Trial 2 finished with value: 19.429185061805175 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 2, 'dropout': 0.015409767622513337}. Best is trial 0 with value: 18.36642238526888.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 499.50it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.04it/s][I 2025-08-18 02:04:47,188] Trial 3 finished with value: 20.428398873408614 and parameters: {'hidden_dim': 18, 'n_rnn_layers': 2, 'dropout': 0.005664597967554197}. Best is trial 0 with value: 18.36642238526888.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 370.03it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 289.40it/s][I 2025-08-18 02:05:03,629] Trial 4 finished with value: 23.043429503372206 and parameters: {'hidden_dim': 97, 'n_rnn_layers': 3, 'dropout': 0.4522814052103375}. Best is trial 0 with value: 18.36642238526888.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 423.54it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 316.31it/s][I 2025-08-18 02:05:17,507] Trial 5 finished with value: 18.850588573458904 and parameters: {'hidden_dim': 67, 'n_rnn_layers': 2, 'dropout': 0.41641482371939054}. Best is trial 0 with value: 18.36642238526888.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 373.36it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.18it/s][I 2025-08-18 02:05:27,358] Trial 6 finished with value: 18.31666030428904 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 2, 'dropout': 0.08258518624272948}. Best is trial 6 with value: 18.31666030428904.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 435.91it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 335.79it/s][I 2025-08-18 02:05:36,757] Trial 7 finished with value: 20.96082123775252 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 3, 'dropout': 0.21207063520000574}. Best is trial 6 with value: 18.31666030428904.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2542944390771201 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 460.96it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.81it/s][I 2025-08-18 02:05:46,609] Trial 8 finished with value: 18.13476959410233 and parameters: {'hidden_dim': 93, 'n_rnn_layers': 1, 'dropout': 0.2542944390771201}. Best is trial 8 with value: 18.13476959410233.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 310.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 245.12it/s][I 2025-08-18 02:05:57,612] Trial 9 finished with value: 22.035389845289945 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 4, 'dropout': 0.23031222757401515}. Best is trial 8 with value: 18.13476959410233.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3559781208392033 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 399.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.13it/s][I 2025-08-18 02:06:07,841] Trial 10 finished with value: 19.40620868720209 and parameters: {'hidden_dim': 112, 'n_rnn_layers': 1, 'dropout': 0.3559781208392033}. Best is trial 8 with value: 18.13476959410233.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11104936775443533 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 500.63it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 358.18it/s][I 2025-08-18 02:06:16,148] Trial 11 finished with value: 15.947163583849134 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 1, 'dropout': 0.11104936775443533}. Best is trial 11 with value: 15.947163583849134.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13768484830871475 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 448.44it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 270.67it/s][I 2025-08-18 02:06:24,663] Trial 12 finished with value: 16.30831742268241 and parameters: {'hidden_dim': 78, 'n_rnn_layers': 1, 'dropout': 0.13768484830871475}. Best is trial 11 with value: 15.947163583849134.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12821716601944447 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 428.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 304.58it/s][I 2025-08-18 02:06:33,287] Trial 13 finished with value: 13.934189321789198 and parameters: {'hidden_dim': 69, 'n_rnn_layers': 1, 'dropout': 0.12821716601944447}. Best is trial 13 with value: 13.934189321789198.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12393611849940689 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 528.32it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 391.37it/s][I 2025-08-18 02:06:42,094] Trial 14 finished with value: 15.196335585492646 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 1, 'dropout': 0.12393611849940689}. Best is trial 13 with value: 13.934189321789198.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16154572112325488 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 426.42it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 311.13it/s][I 2025-08-18 02:06:51,934] Trial 15 finished with value: 17.39339852668507 and parameters: {'hidden_dim': 52, 'n_rnn_layers': 1, 'dropout': 0.16154572112325488}. Best is trial 13 with value: 13.934189321789198.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 294.48it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 230.20it/s][I 2025-08-18 02:07:09,256] Trial 16 finished with value: 22.74378221289215 and parameters: {'hidden_dim': 66, 'n_rnn_layers': 3, 'dropout': 0.06607908657099067}. Best is trial 13 with value: 13.934189321789198.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 553.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 393.91it/s][I 2025-08-18 02:07:18,924] Trial 17 finished with value: 22.991029165050943 and parameters: {'hidden_dim': 38, 'n_rnn_layers': 2, 'dropout': 0.1742337283736302}. Best is trial 13 with value: 13.934189321789198.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2944439118616067 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 505.83it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 368.57it/s][I 2025-08-18 02:07:29,197] Trial 18 finished with value: 18.510337578632083 and parameters: {'hidden_dim': 54, 'n_rnn_layers': 1, 'dropout': 0.2944439118616067}. Best is trial 13 with value: 13.934189321789198.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 393.57it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.87it/s][I 2025-08-18 02:07:52,227] Trial 19 finished with value: 23.5587133101276 and parameters: {'hidden_dim': 123, 'n_rnn_layers': 2, 'dropout': 0.0501913282526818}. Best is trial 13 with value: 13.934189321789198.
[I 2025-08-18 02:07:52,228] A new study created in memory with name: no-name-0e169e6b-8965-47dc-b4b0-d3fd0e5ac172
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 69, 'n_rnn_layers': 1, 'dropout': 0.12821716601944447}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 305.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.27it/s][I 2025-08-18 02:08:06,427] Trial 0 finished with value: 26.087839112049277 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 4, 'dropout': 0.3750899056087893}. Best is trial 0 with value: 26.087839112049277.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 394.16it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 238.86it/s][I 2025-08-18 02:08:33,901] Trial 1 finished with value: 24.37463449534222 and parameters: {'hidden_dim': 128, 'n_rnn_layers': 4, 'dropout': 0.2494654310448784}. Best is trial 1 with value: 24.37463449534222.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 391.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.02it/s][I 2025-08-18 02:08:49,409] Trial 2 finished with value: 21.251639307680797 and parameters: {'hidden_dim': 107, 'n_rnn_layers': 2, 'dropout': 0.09558601063732364}. Best is trial 2 with value: 21.251639307680797.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 356.11it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 278.17it/s][I 2025-08-18 02:09:00,733] Trial 3 finished with value: 12.84295733570356 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 4, 'dropout': 0.23649956879535167}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 299.74it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.56it/s][I 2025-08-18 02:09:14,516] Trial 4 finished with value: 21.470190357687766 and parameters: {'hidden_dim': 61, 'n_rnn_layers': 4, 'dropout': 0.09166406596495069}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 355.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.21it/s][I 2025-08-18 02:09:30,808] Trial 5 finished with value: 26.298706688766604 and parameters: {'hidden_dim': 125, 'n_rnn_layers': 4, 'dropout': 0.021815681457595493}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 392.06it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 308.13it/s][I 2025-08-18 02:09:43,221] Trial 6 finished with value: 24.63278134269456 and parameters: {'hidden_dim': 63, 'n_rnn_layers': 3, 'dropout': 0.05489734981542921}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 355.63it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.61it/s][I 2025-08-18 02:09:54,109] Trial 7 finished with value: 16.894111993683314 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.18579495501491827}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 281.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.44it/s][I 2025-08-18 02:10:05,150] Trial 8 finished with value: 16.260678588484392 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 3, 'dropout': 0.1221517251319631}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 507.60it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 343.74it/s][I 2025-08-18 02:10:23,126] Trial 9 finished with value: 18.248080507240285 and parameters: {'hidden_dim': 103, 'n_rnn_layers': 3, 'dropout': 0.3220672442265394}. Best is trial 3 with value: 12.84295733570356.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.488263412887018 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 485.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 352.17it/s][I 2025-08-18 02:10:30,699] Trial 10 finished with value: 12.530275282125865 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 1, 'dropout': 0.488263412887018}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49282879829861964 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 401.68it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 294.17it/s][I 2025-08-18 02:10:37,978] Trial 11 finished with value: 16.276086172857784 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 1, 'dropout': 0.49282879829861964}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45234607569829854 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 633.48it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.38it/s][I 2025-08-18 02:10:45,792] Trial 12 finished with value: 17.668059527316213 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 1, 'dropout': 0.45234607569829854}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 451.73it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 341.83it/s][I 2025-08-18 02:10:55,060] Trial 13 finished with value: 17.34216496884036 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 2, 'dropout': 0.2803424045529325}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 366.12it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.29it/s][I 2025-08-18 02:11:03,854] Trial 14 finished with value: 18.813483057896516 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 2, 'dropout': 0.3711993975912709}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19547716172433588 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 375.60it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.56it/s][I 2025-08-18 02:11:12,757] Trial 15 finished with value: 15.196335585492646 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 1, 'dropout': 0.19547716172433588}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 499.56it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 343.29it/s][I 2025-08-18 02:11:22,476] Trial 16 finished with value: 21.03224564067684 and parameters: {'hidden_dim': 44, 'n_rnn_layers': 2, 'dropout': 0.41000449686847934}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 381.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 296.10it/s][I 2025-08-18 02:11:32,878] Trial 17 finished with value: 18.794162606482562 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 3, 'dropout': 0.19813719329013002}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30447759053263757 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 401.37it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.74it/s][I 2025-08-18 02:11:39,435] Trial 18 finished with value: 12.576465967251545 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.30447759053263757}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4984309271361862 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 404.15it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.29it/s][I 2025-08-18 02:11:46,199] Trial 19 finished with value: 12.576465967251545 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.4984309271361862}. Best is trial 10 with value: 12.530275282125865.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.488263412887018 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 3.7 K  | train
6 | V               | Linear           | 30     | train
-------------------------------------------------------------
3.7 K     Trainable params
0         Non-trainable params
3.7 K     Total params
0.015     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 29, 'n_rnn_layers': 1, 'dropout': 0.488263412887018}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 313.87it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 312.77it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/28 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s] Epoch 0:   4%|▎         | 1/28 [00:00<00:00, 142.65it/s]Epoch 0:   4%|▎         | 1/28 [00:00<00:00, 118.87it/s, train_loss=0.0798]Epoch 0:   7%|▋         | 2/28 [00:00<00:00, 150.02it/s, train_loss=0.0798]Epoch 0:   7%|▋         | 2/28 [00:00<00:00, 133.67it/s, train_loss=0.0707]Epoch 0:  11%|█         | 3/28 [00:00<00:00, 150.87it/s, train_loss=0.0707]Epoch 0:  11%|█         | 3/28 [00:00<00:00, 133.72it/s, train_loss=0.087] Epoch 0:  14%|█▍        | 4/28 [00:00<00:00, 145.61it/s, train_loss=0.087]Epoch 0:  14%|█▍        | 4/28 [00:00<00:00, 137.18it/s, train_loss=0.0717]Epoch 0:  18%|█▊        | 5/28 [00:00<00:00, 148.85it/s, train_loss=0.0717]Epoch 0:  18%|█▊        | 5/28 [00:00<00:00, 132.74it/s, train_loss=0.102] Epoch 0:  21%|██▏       | 6/28 [00:00<00:00, 139.59it/s, train_loss=0.102]Epoch 0:  21%|██▏       | 6/28 [00:00<00:00, 134.92it/s, train_loss=0.0694]Epoch 0:  25%|██▌       | 7/28 [00:00<00:00, 142.33it/s, train_loss=0.0694]Epoch 0:  25%|██▌       | 7/28 [00:00<00:00, 132.69it/s, train_loss=0.0633]Epoch 0:  29%|██▊       | 8/28 [00:00<00:00, 137.91it/s, train_loss=0.0633]Epoch 0:  29%|██▊       | 8/28 [00:00<00:00, 134.25it/s, train_loss=0.0862]Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 139.97it/s, train_loss=0.0862]Epoch 0:  32%|███▏      | 9/28 [00:00<00:00, 132.68it/s, train_loss=0.060] Epoch 0:  36%|███▌      | 10/28 [00:00<00:00, 136.78it/s, train_loss=0.060]Epoch 0:  36%|███▌      | 10/28 [00:00<00:00, 133.97it/s, train_loss=0.072]Epoch 0:  39%|███▉      | 11/28 [00:00<00:00, 139.41it/s, train_loss=0.072]Epoch 0:  39%|███▉      | 11/28 [00:00<00:00, 132.85it/s, train_loss=0.0638]Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 137.10it/s, train_loss=0.0638]Epoch 0:  43%|████▎     | 12/28 [00:00<00:00, 134.50it/s, train_loss=0.043] Epoch 0:  46%|████▋     | 13/28 [00:00<00:00, 138.86it/s, train_loss=0.043]Epoch 0:  46%|████▋     | 13/28 [00:00<00:00, 136.27it/s, train_loss=0.0633]Epoch 0:  50%|█████     | 14/28 [00:00<00:00, 140.62it/s, train_loss=0.0633]Epoch 0:  50%|█████     | 14/28 [00:00<00:00, 135.68it/s, train_loss=0.068] Epoch 0:  54%|█████▎    | 15/28 [00:00<00:00, 138.32it/s, train_loss=0.068]Epoch 0:  54%|█████▎    | 15/28 [00:00<00:00, 136.26it/s, train_loss=0.0658]Epoch 0:  57%|█████▋    | 16/28 [00:00<00:00, 139.74it/s, train_loss=0.0658]Epoch 0:  57%|█████▋    | 16/28 [00:00<00:00, 135.12it/s, train_loss=0.0632]Epoch 0:  61%|██████    | 17/28 [00:00<00:00, 137.69it/s, train_loss=0.0632]Epoch 0:  61%|██████    | 17/28 [00:00<00:00, 135.97it/s, train_loss=0.0611]Epoch 0:  64%|██████▍   | 18/28 [00:00<00:00, 139.00it/s, train_loss=0.0611]Epoch 0:  64%|██████▍   | 18/28 [00:00<00:00, 137.27it/s, train_loss=0.0542]Epoch 0:  68%|██████▊   | 19/28 [00:00<00:00, 138.61it/s, train_loss=0.0542]Epoch 0:  68%|██████▊   | 19/28 [00:00<00:00, 137.14it/s, train_loss=0.0672]Epoch 0:  71%|███████▏  | 20/28 [00:00<00:00, 139.63it/s, train_loss=0.0672]Epoch 0:  71%|███████▏  | 20/28 [00:00<00:00, 138.02it/s, train_loss=0.0769]Epoch 0:  75%|███████▌  | 21/28 [00:00<00:00, 140.83it/s, train_loss=0.0769]Epoch 0:  75%|███████▌  | 21/28 [00:00<00:00, 139.10it/s, train_loss=0.0883]Epoch 0:  79%|███████▊  | 22/28 [00:00<00:00, 141.66it/s, train_loss=0.0883]Epoch 0:  79%|███████▊  | 22/28 [00:00<00:00, 139.52it/s, train_loss=0.0688]Epoch 0:  82%|████████▏ | 23/28 [00:00<00:00, 141.47it/s, train_loss=0.0688]Epoch 0:  82%|████████▏ | 23/28 [00:00<00:00, 140.12it/s, train_loss=0.0696]Epoch 0:  86%|████████▌ | 24/28 [00:00<00:00, 142.43it/s, train_loss=0.0696]Epoch 0:  86%|████████▌ | 24/28 [00:00<00:00, 139.11it/s, train_loss=0.0602]Epoch 0:  89%|████████▉ | 25/28 [00:00<00:00, 140.63it/s, train_loss=0.0602]Epoch 0:  89%|████████▉ | 25/28 [00:00<00:00, 139.39it/s, train_loss=0.0709]Epoch 0:  93%|█████████▎| 26/28 [00:00<00:00, 140.99it/s, train_loss=0.0709]Epoch 0:  93%|█████████▎| 26/28 [00:00<00:00, 139.74it/s, train_loss=0.0664]Epoch 0:  96%|█████████▋| 27/28 [00:00<00:00, 141.46it/s, train_loss=0.0664]Epoch 0:  96%|█████████▋| 27/28 [00:00<00:00, 139.53it/s, train_loss=0.0797]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 141.24it/s, train_loss=0.0797]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 140.06it/s, train_loss=0.0615]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 154.43it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 185.78it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 203.78it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 213.63it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 220.44it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 225.43it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 228.62it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 236.92it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 247.37it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 256.34it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 263.22it/s][A
                                                                         [AEpoch 0: 100%|██████████| 28/28 [00:00<00:00, 112.69it/s, train_loss=0.0615, val_loss=0.0778]Epoch 0: 100%|██████████| 28/28 [00:00<00:00, 112.42it/s, train_loss=0.0615, val_loss=0.0778]Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0615, val_loss=0.0778]          Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0615, val_loss=0.0778]Epoch 1:   4%|▎         | 1/28 [00:00<00:00, 194.36it/s, train_loss=0.0615, val_loss=0.0778]Epoch 1:   4%|▎         | 1/28 [00:00<00:00, 149.78it/s, train_loss=0.0642, val_loss=0.0778]Epoch 1:   7%|▋         | 2/28 [00:00<00:00, 174.88it/s, train_loss=0.0642, val_loss=0.0778]Epoch 1:   7%|▋         | 2/28 [00:00<00:00, 147.76it/s, train_loss=0.0614, val_loss=0.0778]Epoch 1:  11%|█         | 3/28 [00:00<00:00, 166.07it/s, train_loss=0.0614, val_loss=0.0778]Epoch 1:  11%|█         | 3/28 [00:00<00:00, 152.49it/s, train_loss=0.0559, val_loss=0.0778]Epoch 1:  14%|█▍        | 4/28 [00:00<00:00, 166.44it/s, train_loss=0.0559, val_loss=0.0778]Epoch 1:  14%|█▍        | 4/28 [00:00<00:00, 154.48it/s, train_loss=0.0515, val_loss=0.0778]Epoch 1:  18%|█▊        | 5/28 [00:00<00:00, 162.22it/s, train_loss=0.0515, val_loss=0.0778]Epoch 1:  18%|█▊        | 5/28 [00:00<00:00, 153.29it/s, train_loss=0.0746, val_loss=0.0778]Epoch 1:  21%|██▏       | 6/28 [00:00<00:00, 161.72it/s, train_loss=0.0746, val_loss=0.0778]Epoch 1:  21%|██▏       | 6/28 [00:00<00:00, 154.74it/s, train_loss=0.0626, val_loss=0.0778]Epoch 1:  25%|██▌       | 7/28 [00:00<00:00, 162.43it/s, train_loss=0.0626, val_loss=0.0778]Epoch 1:  25%|██▌       | 7/28 [00:00<00:00, 155.87it/s, train_loss=0.044, val_loss=0.0778] Epoch 1:  29%|██▊       | 8/28 [00:00<00:00, 160.19it/s, train_loss=0.044, val_loss=0.0778]Epoch 1:  29%|██▊       | 8/28 [00:00<00:00, 155.00it/s, train_loss=0.0743, val_loss=0.0778]Epoch 1:  32%|███▏      | 9/28 [00:00<00:00, 160.27it/s, train_loss=0.0743, val_loss=0.0778]Epoch 1:  32%|███▏      | 9/28 [00:00<00:00, 155.85it/s, train_loss=0.0333, val_loss=0.0778]Epoch 1:  36%|███▌      | 10/28 [00:00<00:00, 161.39it/s, train_loss=0.0333, val_loss=0.0778]Epoch 1:  36%|███▌      | 10/28 [00:00<00:00, 156.64it/s, train_loss=0.0527, val_loss=0.0778]Epoch 1:  39%|███▉      | 11/28 [00:00<00:00, 161.42it/s, train_loss=0.0527, val_loss=0.0778]Epoch 1:  39%|███▉      | 11/28 [00:00<00:00, 156.03it/s, train_loss=0.0556, val_loss=0.0778]Epoch 1:  43%|████▎     | 12/28 [00:00<00:00, 159.12it/s, train_loss=0.0556, val_loss=0.0778]Epoch 1:  43%|████▎     | 12/28 [00:00<00:00, 155.50it/s, train_loss=0.033, val_loss=0.0778] Epoch 1:  46%|████▋     | 13/28 [00:00<00:00, 159.01it/s, train_loss=0.033, val_loss=0.0778]Epoch 1:  46%|████▋     | 13/28 [00:00<00:00, 151.86it/s, train_loss=0.0503, val_loss=0.0778]Epoch 1:  50%|█████     | 14/28 [00:00<00:00, 154.34it/s, train_loss=0.0503, val_loss=0.0778]Epoch 1:  50%|█████     | 14/28 [00:00<00:00, 151.65it/s, train_loss=0.0392, val_loss=0.0778]Epoch 1:  54%|█████▎    | 15/28 [00:00<00:00, 154.74it/s, train_loss=0.0392, val_loss=0.0778]Epoch 1:  54%|█████▎    | 15/28 [00:00<00:00, 149.13it/s, train_loss=0.0468, val_loss=0.0778]Epoch 1:  57%|█████▋    | 16/28 [00:00<00:00, 151.32it/s, train_loss=0.0468, val_loss=0.0778]Epoch 1:  57%|█████▋    | 16/28 [00:00<00:00, 149.06it/s, train_loss=0.027, val_loss=0.0778] Epoch 1:  61%|██████    | 17/28 [00:00<00:00, 151.70it/s, train_loss=0.027, val_loss=0.0778]Epoch 1:  61%|██████    | 17/28 [00:00<00:00, 147.12it/s, train_loss=0.0465, val_loss=0.0778]Epoch 1:  64%|██████▍   | 18/28 [00:00<00:00, 149.71it/s, train_loss=0.0465, val_loss=0.0778]Epoch 1:  64%|██████▍   | 18/28 [00:00<00:00, 147.78it/s, train_loss=0.0492, val_loss=0.0778]Epoch 1:  68%|██████▊   | 19/28 [00:00<00:00, 150.69it/s, train_loss=0.0492, val_loss=0.0778]Epoch 1:  68%|██████▊   | 19/28 [00:00<00:00, 148.57it/s, train_loss=0.0458, val_loss=0.0778]Epoch 1:  71%|███████▏  | 20/28 [00:00<00:00, 150.72it/s, train_loss=0.0458, val_loss=0.0778]Epoch 1:  71%|███████▏  | 20/28 [00:00<00:00, 148.48it/s, train_loss=0.020, val_loss=0.0778] Epoch 1:  75%|███████▌  | 21/28 [00:00<00:00, 150.63it/s, train_loss=0.020, val_loss=0.0778]Epoch 1:  75%|███████▌  | 21/28 [00:00<00:00, 148.98it/s, train_loss=0.0419, val_loss=0.0778]Epoch 1:  79%|███████▊  | 22/28 [00:00<00:00, 151.57it/s, train_loss=0.0419, val_loss=0.0778]Epoch 1:  79%|███████▊  | 22/28 [00:00<00:00, 149.70it/s, train_loss=0.0512, val_loss=0.0778]Epoch 1:  82%|████████▏ | 23/28 [00:00<00:00, 152.18it/s, train_loss=0.0512, val_loss=0.0778]Epoch 1:  82%|████████▏ | 23/28 [00:00<00:00, 149.72it/s, train_loss=0.052, val_loss=0.0778] Epoch 1:  86%|████████▌ | 24/28 [00:00<00:00, 151.58it/s, train_loss=0.052, val_loss=0.0778]Epoch 1:  86%|████████▌ | 24/28 [00:00<00:00, 150.09it/s, train_loss=0.0298, val_loss=0.0778]Epoch 1:  89%|████████▉ | 25/28 [00:00<00:00, 152.20it/s, train_loss=0.0298, val_loss=0.0778]Epoch 1:  89%|████████▉ | 25/28 [00:00<00:00, 148.63it/s, train_loss=0.0363, val_loss=0.0778]Epoch 1:  93%|█████████▎| 26/28 [00:00<00:00, 149.97it/s, train_loss=0.0363, val_loss=0.0778]Epoch 1:  93%|█████████▎| 26/28 [00:00<00:00, 148.58it/s, train_loss=0.0241, val_loss=0.0778]Epoch 1:  96%|█████████▋| 27/28 [00:00<00:00, 150.32it/s, train_loss=0.0241, val_loss=0.0778]Epoch 1:  96%|█████████▋| 27/28 [00:00<00:00, 148.84it/s, train_loss=0.0398, val_loss=0.0778]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 150.79it/s, train_loss=0.0398, val_loss=0.0778]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 148.04it/s, train_loss=0.0248, val_loss=0.0778]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 166.99it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 198.98it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 207.57it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 214.73it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 218.75it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 221.00it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 223.81it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 225.14it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 227.31it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 228.06it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 229.24it/s][A
                                                                         [AEpoch 1: 100%|██████████| 28/28 [00:00<00:00, 114.12it/s, train_loss=0.0248, val_loss=0.0417]Epoch 1: 100%|██████████| 28/28 [00:00<00:00, 113.64it/s, train_loss=0.0248, val_loss=0.0417]Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0248, val_loss=0.0417]          Epoch 2:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0248, val_loss=0.0417]Epoch 2:   4%|▎         | 1/28 [00:00<00:00, 180.03it/s, train_loss=0.0248, val_loss=0.0417]Epoch 2:   4%|▎         | 1/28 [00:00<00:00, 136.59it/s, train_loss=0.0335, val_loss=0.0417]Epoch 2:   7%|▋         | 2/28 [00:00<00:00, 166.07it/s, train_loss=0.0335, val_loss=0.0417]Epoch 2:   7%|▋         | 2/28 [00:00<00:00, 146.81it/s, train_loss=0.0171, val_loss=0.0417]Epoch 2:  11%|█         | 3/28 [00:00<00:00, 167.90it/s, train_loss=0.0171, val_loss=0.0417]Epoch 2:  11%|█         | 3/28 [00:00<00:00, 152.79it/s, train_loss=0.0248, val_loss=0.0417]Epoch 2:  14%|█▍        | 4/28 [00:00<00:00, 163.17it/s, train_loss=0.0248, val_loss=0.0417]Epoch 2:  14%|█▍        | 4/28 [00:00<00:00, 151.11it/s, train_loss=0.0193, val_loss=0.0417]Epoch 2:  18%|█▊        | 5/28 [00:00<00:00, 160.23it/s, train_loss=0.0193, val_loss=0.0417]Epoch 2:  18%|█▊        | 5/28 [00:00<00:00, 152.55it/s, train_loss=0.024, val_loss=0.0417] Epoch 2:  21%|██▏       | 6/28 [00:00<00:00, 162.14it/s, train_loss=0.024, val_loss=0.0417]Epoch 2:  21%|██▏       | 6/28 [00:00<00:00, 154.69it/s, train_loss=0.0206, val_loss=0.0417]Epoch 2:  25%|██▌       | 7/28 [00:00<00:00, 162.10it/s, train_loss=0.0206, val_loss=0.0417]Epoch 2:  25%|██▌       | 7/28 [00:00<00:00, 154.13it/s, train_loss=0.030, val_loss=0.0417] Epoch 2:  29%|██▊       | 8/28 [00:00<00:00, 158.90it/s, train_loss=0.030, val_loss=0.0417]Epoch 2:  29%|██▊       | 8/28 [00:00<00:00, 153.98it/s, train_loss=0.0315, val_loss=0.0417]Epoch 2:  32%|███▏      | 9/28 [00:00<00:00, 159.14it/s, train_loss=0.0315, val_loss=0.0417]Epoch 2:  32%|███▏      | 9/28 [00:00<00:00, 149.14it/s, train_loss=0.0206, val_loss=0.0417]Epoch 2:  36%|███▌      | 10/28 [00:00<00:00, 152.71it/s, train_loss=0.0206, val_loss=0.0417]Epoch 2:  36%|███▌      | 10/28 [00:00<00:00, 149.15it/s, train_loss=0.0295, val_loss=0.0417]Epoch 2:  39%|███▉      | 11/28 [00:00<00:00, 153.72it/s, train_loss=0.0295, val_loss=0.0417]Epoch 2:  39%|███▉      | 11/28 [00:00<00:00, 145.98it/s, train_loss=0.0229, val_loss=0.0417]Epoch 2:  43%|████▎     | 12/28 [00:00<00:00, 149.01it/s, train_loss=0.0229, val_loss=0.0417]Epoch 2:  43%|████▎     | 12/28 [00:00<00:00, 146.23it/s, train_loss=0.0116, val_loss=0.0417]Epoch 2:  46%|████▋     | 13/28 [00:00<00:00, 149.94it/s, train_loss=0.0116, val_loss=0.0417]Epoch 2:  46%|████▋     | 13/28 [00:00<00:00, 144.07it/s, train_loss=0.0229, val_loss=0.0417]Epoch 2:  50%|█████     | 14/28 [00:00<00:00, 146.89it/s, train_loss=0.0229, val_loss=0.0417]Epoch 2:  50%|█████     | 14/28 [00:00<00:00, 144.43it/s, train_loss=0.0161, val_loss=0.0417]Epoch 2:  54%|█████▎    | 15/28 [00:00<00:00, 147.82it/s, train_loss=0.0161, val_loss=0.0417]Epoch 2:  54%|█████▎    | 15/28 [00:00<00:00, 142.80it/s, train_loss=0.0297, val_loss=0.0417]Epoch 2:  57%|█████▋    | 16/28 [00:00<00:00, 145.26it/s, train_loss=0.0297, val_loss=0.0417]Epoch 2:  57%|█████▋    | 16/28 [00:00<00:00, 143.19it/s, train_loss=0.0214, val_loss=0.0417]Epoch 2:  61%|██████    | 17/28 [00:00<00:00, 145.46it/s, train_loss=0.0214, val_loss=0.0417]Epoch 2:  61%|██████    | 17/28 [00:00<00:00, 141.81it/s, train_loss=0.0246, val_loss=0.0417]Epoch 2:  64%|██████▍   | 18/28 [00:00<00:00, 144.04it/s, train_loss=0.0246, val_loss=0.0417]Epoch 2:  64%|██████▍   | 18/28 [00:00<00:00, 142.14it/s, train_loss=0.0246, val_loss=0.0417]Epoch 2:  68%|██████▊   | 19/28 [00:00<00:00, 144.84it/s, train_loss=0.0246, val_loss=0.0417]Epoch 2:  68%|██████▊   | 19/28 [00:00<00:00, 140.99it/s, train_loss=0.0338, val_loss=0.0417]Epoch 2:  71%|███████▏  | 20/28 [00:00<00:00, 142.57it/s, train_loss=0.0338, val_loss=0.0417]Epoch 2:  71%|███████▏  | 20/28 [00:00<00:00, 140.49it/s, train_loss=0.0193, val_loss=0.0417]Epoch 2:  75%|███████▌  | 21/28 [00:00<00:00, 142.34it/s, train_loss=0.0193, val_loss=0.0417]Epoch 2:  75%|███████▌  | 21/28 [00:00<00:00, 140.11it/s, train_loss=0.0151, val_loss=0.0417]Epoch 2:  79%|███████▊  | 22/28 [00:00<00:00, 142.22it/s, train_loss=0.0151, val_loss=0.0417]Epoch 2:  79%|███████▊  | 22/28 [00:00<00:00, 140.70it/s, train_loss=0.0302, val_loss=0.0417]Epoch 2:  82%|████████▏ | 23/28 [00:00<00:00, 143.18it/s, train_loss=0.0302, val_loss=0.0417]Epoch 2:  82%|████████▏ | 23/28 [00:00<00:00, 139.75it/s, train_loss=0.0152, val_loss=0.0417]Epoch 2:  86%|████████▌ | 24/28 [00:00<00:00, 141.36it/s, train_loss=0.0152, val_loss=0.0417]Epoch 2:  86%|████████▌ | 24/28 [00:00<00:00, 140.11it/s, train_loss=0.0279, val_loss=0.0417]Epoch 2:  89%|████████▉ | 25/28 [00:00<00:00, 142.20it/s, train_loss=0.0279, val_loss=0.0417]Epoch 2:  89%|████████▉ | 25/28 [00:00<00:00, 140.80it/s, train_loss=0.0174, val_loss=0.0417]Epoch 2:  93%|█████████▎| 26/28 [00:00<00:00, 142.68it/s, train_loss=0.0174, val_loss=0.0417]Epoch 2:  93%|█████████▎| 26/28 [00:00<00:00, 140.48it/s, train_loss=0.0152, val_loss=0.0417]Epoch 2:  96%|█████████▋| 27/28 [00:00<00:00, 142.14it/s, train_loss=0.0152, val_loss=0.0417]Epoch 2:  96%|█████████▋| 27/28 [00:00<00:00, 140.89it/s, train_loss=0.0228, val_loss=0.0417]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 142.47it/s, train_loss=0.0228, val_loss=0.0417]Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 140.24it/s, train_loss=0.0243, val_loss=0.0417]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 153.90it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 189.46it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 206.80it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 215.58it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 221.80it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 218.53it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 219.75it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 222.00it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 224.42it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 225.06it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 226.53it/s][A
                                                                         [AEpoch 2: 100%|██████████| 28/28 [00:00<00:00, 108.81it/s, train_loss=0.0243, val_loss=0.0288]Epoch 2: 100%|██████████| 28/28 [00:00<00:00, 108.37it/s, train_loss=0.0243, val_loss=0.0288]Epoch 2:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0243, val_loss=0.0288]          Epoch 3:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0243, val_loss=0.0288]Epoch 3:   4%|▎         | 1/28 [00:00<00:00, 155.78it/s, train_loss=0.0243, val_loss=0.0288]Epoch 3:   4%|▎         | 1/28 [00:00<00:00, 127.35it/s, train_loss=0.013, val_loss=0.0288] Epoch 3:   7%|▋         | 2/28 [00:00<00:00, 157.94it/s, train_loss=0.013, val_loss=0.0288]Epoch 3:   7%|▋         | 2/28 [00:00<00:00, 140.40it/s, train_loss=0.020, val_loss=0.0288]Epoch 3:  11%|█         | 3/28 [00:00<00:00, 160.55it/s, train_loss=0.020, val_loss=0.0288]Epoch 3:  11%|█         | 3/28 [00:00<00:00, 133.33it/s, train_loss=0.0167, val_loss=0.0288]Epoch 3:  14%|█▍        | 4/28 [00:00<00:00, 144.70it/s, train_loss=0.0167, val_loss=0.0288]Epoch 3:  14%|█▍        | 4/28 [00:00<00:00, 136.91it/s, train_loss=0.0329, val_loss=0.0288]Epoch 3:  18%|█▊        | 5/28 [00:00<00:00, 148.61it/s, train_loss=0.0329, val_loss=0.0288]Epoch 3:  18%|█▊        | 5/28 [00:00<00:00, 133.36it/s, train_loss=0.021, val_loss=0.0288] Epoch 3:  21%|██▏       | 6/28 [00:00<00:00, 141.39it/s, train_loss=0.021, val_loss=0.0288]Epoch 3:  21%|██▏       | 6/28 [00:00<00:00, 136.14it/s, train_loss=0.0155, val_loss=0.0288]Epoch 3:  25%|██▌       | 7/28 [00:00<00:00, 142.29it/s, train_loss=0.0155, val_loss=0.0288]Epoch 3:  25%|██▌       | 7/28 [00:00<00:00, 132.38it/s, train_loss=0.0149, val_loss=0.0288]Epoch 3:  29%|██▊       | 8/28 [00:00<00:00, 136.43it/s, train_loss=0.0149, val_loss=0.0288]Epoch 3:  29%|██▊       | 8/28 [00:00<00:00, 132.99it/s, train_loss=0.0096, val_loss=0.0288]Epoch 3:  32%|███▏      | 9/28 [00:00<00:00, 137.94it/s, train_loss=0.0096, val_loss=0.0288]Epoch 3:  32%|███▏      | 9/28 [00:00<00:00, 130.56it/s, train_loss=0.0176, val_loss=0.0288]Epoch 3:  36%|███▌      | 10/28 [00:00<00:00, 133.70it/s, train_loss=0.0176, val_loss=0.0288]Epoch 3:  36%|███▌      | 10/28 [00:00<00:00, 131.01it/s, train_loss=0.0147, val_loss=0.0288]Epoch 3:  39%|███▉      | 11/28 [00:00<00:00, 135.20it/s, train_loss=0.0147, val_loss=0.0288]Epoch 3:  39%|███▉      | 11/28 [00:00<00:00, 129.21it/s, train_loss=0.0198, val_loss=0.0288]Epoch 3:  43%|████▎     | 12/28 [00:00<00:00, 131.85it/s, train_loss=0.0198, val_loss=0.0288]Epoch 3:  43%|████▎     | 12/28 [00:00<00:00, 129.73it/s, train_loss=0.0182, val_loss=0.0288]Epoch 3:  46%|████▋     | 13/28 [00:00<00:00, 133.28it/s, train_loss=0.0182, val_loss=0.0288]Epoch 3:  46%|████▋     | 13/28 [00:00<00:00, 128.41it/s, train_loss=0.0111, val_loss=0.0288]Epoch 3:  50%|█████     | 14/28 [00:00<00:00, 130.74it/s, train_loss=0.0111, val_loss=0.0288]Epoch 3:  50%|█████     | 14/28 [00:00<00:00, 128.93it/s, train_loss=0.0171, val_loss=0.0288]Epoch 3:  54%|█████▎    | 15/28 [00:00<00:00, 131.92it/s, train_loss=0.0171, val_loss=0.0288]Epoch 3:  54%|█████▎    | 15/28 [00:00<00:00, 127.66it/s, train_loss=0.0199, val_loss=0.0288]Epoch 3:  57%|█████▋    | 16/28 [00:00<00:00, 129.83it/s, train_loss=0.0199, val_loss=0.0288]Epoch 3:  57%|█████▋    | 16/28 [00:00<00:00, 128.19it/s, train_loss=0.0176, val_loss=0.0288]Epoch 3:  61%|██████    | 17/28 [00:00<00:00, 130.67it/s, train_loss=0.0176, val_loss=0.0288]Epoch 3:  61%|██████    | 17/28 [00:00<00:00, 127.35it/s, train_loss=0.0256, val_loss=0.0288]Epoch 3:  64%|██████▍   | 18/28 [00:00<00:00, 129.24it/s, train_loss=0.0256, val_loss=0.0288]Epoch 3:  64%|██████▍   | 18/28 [00:00<00:00, 127.81it/s, train_loss=0.0196, val_loss=0.0288]Epoch 3:  68%|██████▊   | 19/28 [00:00<00:00, 130.10it/s, train_loss=0.0196, val_loss=0.0288]Epoch 3:  68%|██████▊   | 19/28 [00:00<00:00, 126.98it/s, train_loss=0.0138, val_loss=0.0288]Epoch 3:  71%|███████▏  | 20/28 [00:00<00:00, 128.61it/s, train_loss=0.0138, val_loss=0.0288]Epoch 3:  71%|███████▏  | 20/28 [00:00<00:00, 127.36it/s, train_loss=0.0207, val_loss=0.0288]Epoch 3:  75%|███████▌  | 21/28 [00:00<00:00, 129.83it/s, train_loss=0.0207, val_loss=0.0288]Epoch 3:  75%|███████▌  | 21/28 [00:00<00:00, 126.89it/s, train_loss=0.0187, val_loss=0.0288]Epoch 3:  79%|███████▊  | 22/28 [00:00<00:00, 128.74it/s, train_loss=0.0187, val_loss=0.0288]Epoch 3:  79%|███████▊  | 22/28 [00:00<00:00, 127.56it/s, train_loss=0.0125, val_loss=0.0288]Epoch 3:  82%|████████▏ | 23/28 [00:00<00:00, 129.63it/s, train_loss=0.0125, val_loss=0.0288]Epoch 3:  82%|████████▏ | 23/28 [00:00<00:00, 128.34it/s, train_loss=0.0203, val_loss=0.0288]Epoch 3:  86%|████████▌ | 24/28 [00:00<00:00, 130.08it/s, train_loss=0.0203, val_loss=0.0288]Epoch 3:  86%|████████▌ | 24/28 [00:00<00:00, 128.35it/s, train_loss=0.0176, val_loss=0.0288]Epoch 3:  89%|████████▉ | 25/28 [00:00<00:00, 129.96it/s, train_loss=0.0176, val_loss=0.0288]Epoch 3:  89%|████████▉ | 25/28 [00:00<00:00, 128.89it/s, train_loss=0.0246, val_loss=0.0288]Epoch 3:  93%|█████████▎| 26/28 [00:00<00:00, 130.66it/s, train_loss=0.0246, val_loss=0.0288]Epoch 3:  93%|█████████▎| 26/28 [00:00<00:00, 127.99it/s, train_loss=0.0221, val_loss=0.0288]Epoch 3:  96%|█████████▋| 27/28 [00:00<00:00, 129.48it/s, train_loss=0.0221, val_loss=0.0288]Epoch 3:  96%|█████████▋| 27/28 [00:00<00:00, 128.51it/s, train_loss=0.0194, val_loss=0.0288]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 130.27it/s, train_loss=0.0194, val_loss=0.0288]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 129.37it/s, train_loss=0.00877, val_loss=0.0288]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 170.97it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 195.07it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 204.96it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 214.55it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 216.53it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 218.83it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 219.07it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 219.01it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 220.31it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 219.39it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 220.95it/s][A
                                                                         [AEpoch 3: 100%|██████████| 28/28 [00:00<00:00, 101.98it/s, train_loss=0.00877, val_loss=0.0218]Epoch 3: 100%|██████████| 28/28 [00:00<00:00, 101.58it/s, train_loss=0.00877, val_loss=0.0218]Epoch 3:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00877, val_loss=0.0218]          Epoch 4:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00877, val_loss=0.0218]Epoch 4:   4%|▎         | 1/28 [00:00<00:00, 145.42it/s, train_loss=0.00877, val_loss=0.0218]Epoch 4:   4%|▎         | 1/28 [00:00<00:00, 121.78it/s, train_loss=0.0169, val_loss=0.0218] Epoch 4:   7%|▋         | 2/28 [00:00<00:00, 144.58it/s, train_loss=0.0169, val_loss=0.0218]Epoch 4:   7%|▋         | 2/28 [00:00<00:00, 129.59it/s, train_loss=0.0103, val_loss=0.0218]Epoch 4:  11%|█         | 3/28 [00:00<00:00, 145.61it/s, train_loss=0.0103, val_loss=0.0218]Epoch 4:  11%|█         | 3/28 [00:00<00:00, 123.96it/s, train_loss=0.0106, val_loss=0.0218]Epoch 4:  14%|█▍        | 4/28 [00:00<00:00, 132.37it/s, train_loss=0.0106, val_loss=0.0218]Epoch 4:  14%|█▍        | 4/28 [00:00<00:00, 126.10it/s, train_loss=0.0157, val_loss=0.0218]Epoch 4:  18%|█▊        | 5/28 [00:00<00:00, 136.87it/s, train_loss=0.0157, val_loss=0.0218]Epoch 4:  18%|█▊        | 5/28 [00:00<00:00, 124.31it/s, train_loss=0.011, val_loss=0.0218] Epoch 4:  21%|██▏       | 6/28 [00:00<00:00, 131.28it/s, train_loss=0.011, val_loss=0.0218]Epoch 4:  21%|██▏       | 6/28 [00:00<00:00, 127.00it/s, train_loss=0.0166, val_loss=0.0218]Epoch 4:  25%|██▌       | 7/28 [00:00<00:00, 133.79it/s, train_loss=0.0166, val_loss=0.0218]Epoch 4:  25%|██▌       | 7/28 [00:00<00:00, 129.74it/s, train_loss=0.0167, val_loss=0.0218]Epoch 4:  29%|██▊       | 8/28 [00:00<00:00, 134.95it/s, train_loss=0.0167, val_loss=0.0218]Epoch 4:  29%|██▊       | 8/28 [00:00<00:00, 129.52it/s, train_loss=0.0163, val_loss=0.0218]Epoch 4:  32%|███▏      | 9/28 [00:00<00:00, 133.90it/s, train_loss=0.0163, val_loss=0.0218]Epoch 4:  32%|███▏      | 9/28 [00:00<00:00, 130.68it/s, train_loss=0.0114, val_loss=0.0218]Epoch 4:  36%|███▌      | 10/28 [00:00<00:00, 135.53it/s, train_loss=0.0114, val_loss=0.0218]Epoch 4:  36%|███▌      | 10/28 [00:00<00:00, 128.75it/s, train_loss=0.016, val_loss=0.0218] Epoch 4:  39%|███▉      | 11/28 [00:00<00:00, 131.99it/s, train_loss=0.016, val_loss=0.0218]Epoch 4:  39%|███▉      | 11/28 [00:00<00:00, 129.56it/s, train_loss=0.0166, val_loss=0.0218]Epoch 4:  43%|████▎     | 12/28 [00:00<00:00, 133.62it/s, train_loss=0.0166, val_loss=0.0218]Epoch 4:  43%|████▎     | 12/28 [00:00<00:00, 128.07it/s, train_loss=0.0216, val_loss=0.0218]Epoch 4:  46%|████▋     | 13/28 [00:00<00:00, 130.71it/s, train_loss=0.0216, val_loss=0.0218]Epoch 4:  46%|████▋     | 13/28 [00:00<00:00, 128.80it/s, train_loss=0.0132, val_loss=0.0218]Epoch 4:  50%|█████     | 14/28 [00:00<00:00, 131.79it/s, train_loss=0.0132, val_loss=0.0218]Epoch 4:  50%|█████     | 14/28 [00:00<00:00, 127.47it/s, train_loss=0.0144, val_loss=0.0218]Epoch 4:  54%|█████▎    | 15/28 [00:00<00:00, 129.69it/s, train_loss=0.0144, val_loss=0.0218]Epoch 4:  54%|█████▎    | 15/28 [00:00<00:00, 128.01it/s, train_loss=0.014, val_loss=0.0218] Epoch 4:  57%|█████▋    | 16/28 [00:00<00:00, 130.90it/s, train_loss=0.014, val_loss=0.0218]Epoch 4:  57%|█████▋    | 16/28 [00:00<00:00, 126.97it/s, train_loss=0.0152, val_loss=0.0218]Epoch 4:  61%|██████    | 17/28 [00:00<00:00, 128.39it/s, train_loss=0.0152, val_loss=0.0218]Epoch 4:  61%|██████    | 17/28 [00:00<00:00, 126.82it/s, train_loss=0.0133, val_loss=0.0218]Epoch 4:  64%|██████▍   | 18/28 [00:00<00:00, 129.01it/s, train_loss=0.0133, val_loss=0.0218]Epoch 4:  64%|██████▍   | 18/28 [00:00<00:00, 126.95it/s, train_loss=0.0132, val_loss=0.0218]Epoch 4:  68%|██████▊   | 19/28 [00:00<00:00, 128.84it/s, train_loss=0.0132, val_loss=0.0218]Epoch 4:  68%|██████▊   | 19/28 [00:00<00:00, 127.50it/s, train_loss=0.0084, val_loss=0.0218]Epoch 4:  71%|███████▏  | 20/28 [00:00<00:00, 129.66it/s, train_loss=0.0084, val_loss=0.0218]Epoch 4:  71%|███████▏  | 20/28 [00:00<00:00, 126.73it/s, train_loss=0.00877, val_loss=0.0218]Epoch 4:  75%|███████▌  | 21/28 [00:00<00:00, 128.30it/s, train_loss=0.00877, val_loss=0.0218]Epoch 4:  75%|███████▌  | 21/28 [00:00<00:00, 127.10it/s, train_loss=0.0124, val_loss=0.0218] Epoch 4:  79%|███████▊  | 22/28 [00:00<00:00, 129.19it/s, train_loss=0.0124, val_loss=0.0218]Epoch 4:  79%|███████▊  | 22/28 [00:00<00:00, 126.54it/s, train_loss=0.0117, val_loss=0.0218]Epoch 4:  82%|████████▏ | 23/28 [00:00<00:00, 128.18it/s, train_loss=0.0117, val_loss=0.0218]Epoch 4:  82%|████████▏ | 23/28 [00:00<00:00, 127.02it/s, train_loss=0.012, val_loss=0.0218] Epoch 4:  86%|████████▌ | 24/28 [00:00<00:00, 128.53it/s, train_loss=0.012, val_loss=0.0218]Epoch 4:  86%|████████▌ | 24/28 [00:00<00:00, 126.58it/s, train_loss=0.0135, val_loss=0.0218]Epoch 4:  89%|████████▉ | 25/28 [00:00<00:00, 127.95it/s, train_loss=0.0135, val_loss=0.0218]Epoch 4:  89%|████████▉ | 25/28 [00:00<00:00, 126.92it/s, train_loss=0.00997, val_loss=0.0218]Epoch 4:  93%|█████████▎| 26/28 [00:00<00:00, 128.78it/s, train_loss=0.00997, val_loss=0.0218]Epoch 4:  93%|█████████▎| 26/28 [00:00<00:00, 126.44it/s, train_loss=0.00963, val_loss=0.0218]Epoch 4:  96%|█████████▋| 27/28 [00:00<00:00, 127.84it/s, train_loss=0.00963, val_loss=0.0218]Epoch 4:  96%|█████████▋| 27/28 [00:00<00:00, 126.93it/s, train_loss=0.00567, val_loss=0.0218]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 128.69it/s, train_loss=0.00567, val_loss=0.0218]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 126.52it/s, train_loss=0.00971, val_loss=0.0218]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 174.92it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 199.16it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 213.29it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 215.44it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 219.70it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 221.00it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 221.46it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 224.30it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 224.31it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 225.02it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 226.43it/s][A
                                                                         [AEpoch 4: 100%|██████████| 28/28 [00:00<00:00, 100.95it/s, train_loss=0.00971, val_loss=0.0113]Epoch 4: 100%|██████████| 28/28 [00:00<00:00, 100.59it/s, train_loss=0.00971, val_loss=0.0113]Epoch 4:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00971, val_loss=0.0113]          Epoch 5:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00971, val_loss=0.0113]Epoch 5:   4%|▎         | 1/28 [00:00<00:00, 142.66it/s, train_loss=0.00971, val_loss=0.0113]Epoch 5:   4%|▎         | 1/28 [00:00<00:00, 116.66it/s, train_loss=0.0132, val_loss=0.0113] Epoch 5:   7%|▋         | 2/28 [00:00<00:00, 145.43it/s, train_loss=0.0132, val_loss=0.0113]Epoch 5:   7%|▋         | 2/28 [00:00<00:00, 114.29it/s, train_loss=0.00853, val_loss=0.0113]Epoch 5:  11%|█         | 3/28 [00:00<00:00, 128.64it/s, train_loss=0.00853, val_loss=0.0113]Epoch 5:  11%|█         | 3/28 [00:00<00:00, 121.03it/s, train_loss=0.00632, val_loss=0.0113]Epoch 5:  14%|█▍        | 4/28 [00:00<00:00, 133.26it/s, train_loss=0.00632, val_loss=0.0113]Epoch 5:  14%|█▍        | 4/28 [00:00<00:00, 118.59it/s, train_loss=0.0111, val_loss=0.0113] Epoch 5:  18%|█▊        | 5/28 [00:00<00:00, 126.04it/s, train_loss=0.0111, val_loss=0.0113]Epoch 5:  18%|█▊        | 5/28 [00:00<00:00, 121.48it/s, train_loss=0.00901, val_loss=0.0113]Epoch 5:  21%|██▏       | 6/28 [00:00<00:00, 128.62it/s, train_loss=0.00901, val_loss=0.0113]Epoch 5:  21%|██▏       | 6/28 [00:00<00:00, 120.13it/s, train_loss=0.0126, val_loss=0.0113] Epoch 5:  25%|██▌       | 7/28 [00:00<00:00, 126.80it/s, train_loss=0.0126, val_loss=0.0113]Epoch 5:  25%|██▌       | 7/28 [00:00<00:00, 123.26it/s, train_loss=0.00744, val_loss=0.0113]Epoch 5:  29%|██▊       | 8/28 [00:00<00:00, 131.37it/s, train_loss=0.00744, val_loss=0.0113]Epoch 5:  29%|██▊       | 8/28 [00:00<00:00, 123.18it/s, train_loss=0.00815, val_loss=0.0113]Epoch 5:  32%|███▏      | 9/28 [00:00<00:00, 128.41it/s, train_loss=0.00815, val_loss=0.0113]Epoch 5:  32%|███▏      | 9/28 [00:00<00:00, 125.62it/s, train_loss=0.009, val_loss=0.0113]  Epoch 5:  36%|███▌      | 10/28 [00:00<00:00, 131.58it/s, train_loss=0.009, val_loss=0.0113]Epoch 5:  36%|███▌      | 10/28 [00:00<00:00, 125.03it/s, train_loss=0.011, val_loss=0.0113]Epoch 5:  39%|███▉      | 11/28 [00:00<00:00, 129.55it/s, train_loss=0.011, val_loss=0.0113]Epoch 5:  39%|███▉      | 11/28 [00:00<00:00, 127.18it/s, train_loss=0.00903, val_loss=0.0113]Epoch 5:  43%|████▎     | 12/28 [00:00<00:00, 132.10it/s, train_loss=0.00903, val_loss=0.0113]Epoch 5:  43%|████▎     | 12/28 [00:00<00:00, 126.68it/s, train_loss=0.0112, val_loss=0.0113] Epoch 5:  46%|████▋     | 13/28 [00:00<00:00, 130.24it/s, train_loss=0.0112, val_loss=0.0113]Epoch 5:  46%|████▋     | 13/28 [00:00<00:00, 128.21it/s, train_loss=0.0104, val_loss=0.0113]Epoch 5:  50%|█████     | 14/28 [00:00<00:00, 132.08it/s, train_loss=0.0104, val_loss=0.0113]Epoch 5:  50%|█████     | 14/28 [00:00<00:00, 127.50it/s, train_loss=0.00546, val_loss=0.0113]Epoch 5:  54%|█████▎    | 15/28 [00:00<00:00, 130.52it/s, train_loss=0.00546, val_loss=0.0113]Epoch 5:  54%|█████▎    | 15/28 [00:00<00:00, 128.70it/s, train_loss=0.00604, val_loss=0.0113]Epoch 5:  57%|█████▋    | 16/28 [00:00<00:00, 132.06it/s, train_loss=0.00604, val_loss=0.0113]Epoch 5:  57%|█████▋    | 16/28 [00:00<00:00, 128.28it/s, train_loss=0.0105, val_loss=0.0113] Epoch 5:  61%|██████    | 17/28 [00:00<00:00, 130.85it/s, train_loss=0.0105, val_loss=0.0113]Epoch 5:  61%|██████    | 17/28 [00:00<00:00, 129.28it/s, train_loss=0.00779, val_loss=0.0113]Epoch 5:  64%|██████▍   | 18/28 [00:00<00:00, 132.24it/s, train_loss=0.00779, val_loss=0.0113]Epoch 5:  64%|██████▍   | 18/28 [00:00<00:00, 128.90it/s, train_loss=0.010, val_loss=0.0113]  Epoch 5:  68%|██████▊   | 19/28 [00:00<00:00, 131.14it/s, train_loss=0.010, val_loss=0.0113]Epoch 5:  68%|██████▊   | 19/28 [00:00<00:00, 129.73it/s, train_loss=0.0089, val_loss=0.0113]Epoch 5:  71%|███████▏  | 20/28 [00:00<00:00, 132.30it/s, train_loss=0.0089, val_loss=0.0113]Epoch 5:  71%|███████▏  | 20/28 [00:00<00:00, 129.39it/s, train_loss=0.00985, val_loss=0.0113]Epoch 5:  75%|███████▌  | 21/28 [00:00<00:00, 131.27it/s, train_loss=0.00985, val_loss=0.0113]Epoch 5:  75%|███████▌  | 21/28 [00:00<00:00, 129.91it/s, train_loss=0.00684, val_loss=0.0113]Epoch 5:  79%|███████▊  | 22/28 [00:00<00:00, 132.16it/s, train_loss=0.00684, val_loss=0.0113]Epoch 5:  79%|███████▊  | 22/28 [00:00<00:00, 129.64it/s, train_loss=0.0058, val_loss=0.0113] Epoch 5:  82%|████████▏ | 23/28 [00:00<00:00, 131.57it/s, train_loss=0.0058, val_loss=0.0113]Epoch 5:  82%|████████▏ | 23/28 [00:00<00:00, 130.39it/s, train_loss=0.00607, val_loss=0.0113]Epoch 5:  86%|████████▌ | 24/28 [00:00<00:00, 132.22it/s, train_loss=0.00607, val_loss=0.0113]Epoch 5:  86%|████████▌ | 24/28 [00:00<00:00, 130.04it/s, train_loss=0.00877, val_loss=0.0113]Epoch 5:  89%|████████▉ | 25/28 [00:00<00:00, 131.85it/s, train_loss=0.00877, val_loss=0.0113]Epoch 5:  89%|████████▉ | 25/28 [00:00<00:00, 130.68it/s, train_loss=0.00906, val_loss=0.0113]Epoch 5:  93%|█████████▎| 26/28 [00:00<00:00, 132.46it/s, train_loss=0.00906, val_loss=0.0113]Epoch 5:  93%|█████████▎| 26/28 [00:00<00:00, 130.31it/s, train_loss=0.00705, val_loss=0.0113]Epoch 5:  96%|█████████▋| 27/28 [00:00<00:00, 132.15it/s, train_loss=0.00705, val_loss=0.0113]Epoch 5:  96%|█████████▋| 27/28 [00:00<00:00, 131.13it/s, train_loss=0.00728, val_loss=0.0113]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 133.34it/s, train_loss=0.00728, val_loss=0.0113]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 130.97it/s, train_loss=0.00863, val_loss=0.0113]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 235.29it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 263.54it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 266.23it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 271.39it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 273.53it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 274.22it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 275.34it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 276.15it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 274.17it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 273.94it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 273.59it/s][A
                                                                         [AEpoch 5: 100%|██████████| 28/28 [00:00<00:00, 107.49it/s, train_loss=0.00863, val_loss=0.00852]Epoch 5: 100%|██████████| 28/28 [00:00<00:00, 107.15it/s, train_loss=0.00863, val_loss=0.00852]Epoch 5:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00863, val_loss=0.00852]          Epoch 6:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00863, val_loss=0.00852]Epoch 6:   4%|▎         | 1/28 [00:00<00:00, 157.35it/s, train_loss=0.00863, val_loss=0.00852]Epoch 6:   4%|▎         | 1/28 [00:00<00:00, 125.41it/s, train_loss=0.00858, val_loss=0.00852]Epoch 6:   7%|▋         | 2/28 [00:00<00:00, 156.97it/s, train_loss=0.00858, val_loss=0.00852]Epoch 6:   7%|▋         | 2/28 [00:00<00:00, 121.90it/s, train_loss=0.00795, val_loss=0.00852]Epoch 6:  11%|█         | 3/28 [00:00<00:00, 137.29it/s, train_loss=0.00795, val_loss=0.00852]Epoch 6:  11%|█         | 3/28 [00:00<00:00, 128.34it/s, train_loss=0.00737, val_loss=0.00852]Epoch 6:  14%|█▍        | 4/28 [00:00<00:00, 141.45it/s, train_loss=0.00737, val_loss=0.00852]Epoch 6:  14%|█▍        | 4/28 [00:00<00:00, 124.17it/s, train_loss=0.00611, val_loss=0.00852]Epoch 6:  18%|█▊        | 5/28 [00:00<00:00, 133.24it/s, train_loss=0.00611, val_loss=0.00852]Epoch 6:  18%|█▊        | 5/28 [00:00<00:00, 127.89it/s, train_loss=0.00885, val_loss=0.00852]Epoch 6:  21%|██▏       | 6/28 [00:00<00:00, 136.75it/s, train_loss=0.00885, val_loss=0.00852]Epoch 6:  21%|██▏       | 6/28 [00:00<00:00, 127.15it/s, train_loss=0.00536, val_loss=0.00852]Epoch 6:  25%|██▌       | 7/28 [00:00<00:00, 132.21it/s, train_loss=0.00536, val_loss=0.00852]Epoch 6:  25%|██▌       | 7/28 [00:00<00:00, 128.39it/s, train_loss=0.00612, val_loss=0.00852]Epoch 6:  29%|██▊       | 8/28 [00:00<00:00, 133.75it/s, train_loss=0.00612, val_loss=0.00852]Epoch 6:  29%|██▊       | 8/28 [00:00<00:00, 128.98it/s, train_loss=0.00728, val_loss=0.00852]Epoch 6:  32%|███▏      | 9/28 [00:00<00:00, 133.99it/s, train_loss=0.00728, val_loss=0.00852]Epoch 6:  32%|███▏      | 9/28 [00:00<00:00, 130.83it/s, train_loss=0.00793, val_loss=0.00852]Epoch 6:  36%|███▌      | 10/28 [00:00<00:00, 133.89it/s, train_loss=0.00793, val_loss=0.00852]Epoch 6:  36%|███▌      | 10/28 [00:00<00:00, 130.21it/s, train_loss=0.00715, val_loss=0.00852]Epoch 6:  39%|███▉      | 11/28 [00:00<00:00, 134.78it/s, train_loss=0.00715, val_loss=0.00852]Epoch 6:  39%|███▉      | 11/28 [00:00<00:00, 132.17it/s, train_loss=0.00697, val_loss=0.00852]Epoch 6:  43%|████▎     | 12/28 [00:00<00:00, 137.40it/s, train_loss=0.00697, val_loss=0.00852]Epoch 6:  43%|████▎     | 12/28 [00:00<00:00, 134.47it/s, train_loss=0.00616, val_loss=0.00852]Epoch 6:  46%|████▋     | 13/28 [00:00<00:00, 138.42it/s, train_loss=0.00616, val_loss=0.00852]Epoch 6:  46%|████▋     | 13/28 [00:00<00:00, 135.24it/s, train_loss=0.0067, val_loss=0.00852] Epoch 6:  50%|█████     | 14/28 [00:00<00:00, 138.99it/s, train_loss=0.0067, val_loss=0.00852]Epoch 6:  50%|█████     | 14/28 [00:00<00:00, 136.72it/s, train_loss=0.00906, val_loss=0.00852]Epoch 6:  54%|█████▎    | 15/28 [00:00<00:00, 140.72it/s, train_loss=0.00906, val_loss=0.00852]Epoch 6:  54%|█████▎    | 15/28 [00:00<00:00, 138.33it/s, train_loss=0.00523, val_loss=0.00852]Epoch 6:  57%|█████▋    | 16/28 [00:00<00:00, 141.95it/s, train_loss=0.00523, val_loss=0.00852]Epoch 6:  57%|█████▋    | 16/28 [00:00<00:00, 139.06it/s, train_loss=0.00537, val_loss=0.00852]Epoch 6:  61%|██████    | 17/28 [00:00<00:00, 141.94it/s, train_loss=0.00537, val_loss=0.00852]Epoch 6:  61%|██████    | 17/28 [00:00<00:00, 139.97it/s, train_loss=0.00718, val_loss=0.00852]Epoch 6:  64%|██████▍   | 18/28 [00:00<00:00, 143.06it/s, train_loss=0.00718, val_loss=0.00852]Epoch 6:  64%|██████▍   | 18/28 [00:00<00:00, 138.46it/s, train_loss=0.00647, val_loss=0.00852]Epoch 6:  68%|██████▊   | 19/28 [00:00<00:00, 140.59it/s, train_loss=0.00647, val_loss=0.00852]Epoch 6:  68%|██████▊   | 19/28 [00:00<00:00, 138.93it/s, train_loss=0.00728, val_loss=0.00852]Epoch 6:  71%|███████▏  | 20/28 [00:00<00:00, 141.50it/s, train_loss=0.00728, val_loss=0.00852]Epoch 6:  71%|███████▏  | 20/28 [00:00<00:00, 139.72it/s, train_loss=0.00993, val_loss=0.00852]Epoch 6:  75%|███████▌  | 21/28 [00:00<00:00, 141.66it/s, train_loss=0.00993, val_loss=0.00852]Epoch 6:  75%|███████▌  | 21/28 [00:00<00:00, 139.65it/s, train_loss=0.00452, val_loss=0.00852]Epoch 6:  79%|███████▊  | 22/28 [00:00<00:00, 141.73it/s, train_loss=0.00452, val_loss=0.00852]Epoch 6:  79%|███████▊  | 22/28 [00:00<00:00, 140.24it/s, train_loss=0.00526, val_loss=0.00852]Epoch 6:  82%|████████▏ | 23/28 [00:00<00:00, 142.66it/s, train_loss=0.00526, val_loss=0.00852]Epoch 6:  82%|████████▏ | 23/28 [00:00<00:00, 139.33it/s, train_loss=0.00717, val_loss=0.00852]Epoch 6:  86%|████████▌ | 24/28 [00:00<00:00, 140.97it/s, train_loss=0.00717, val_loss=0.00852]Epoch 6:  86%|████████▌ | 24/28 [00:00<00:00, 139.61it/s, train_loss=0.00786, val_loss=0.00852]Epoch 6:  89%|████████▉ | 25/28 [00:00<00:00, 141.66it/s, train_loss=0.00786, val_loss=0.00852]Epoch 6:  89%|████████▉ | 25/28 [00:00<00:00, 138.88it/s, train_loss=0.00679, val_loss=0.00852]Epoch 6:  93%|█████████▎| 26/28 [00:00<00:00, 140.35it/s, train_loss=0.00679, val_loss=0.00852]Epoch 6:  93%|█████████▎| 26/28 [00:00<00:00, 139.19it/s, train_loss=0.00654, val_loss=0.00852]Epoch 6:  96%|█████████▋| 27/28 [00:00<00:00, 140.77it/s, train_loss=0.00654, val_loss=0.00852]Epoch 6:  96%|█████████▋| 27/28 [00:00<00:00, 138.42it/s, train_loss=0.00515, val_loss=0.00852]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 139.65it/s, train_loss=0.00515, val_loss=0.00852]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 138.54it/s, train_loss=0.00543, val_loss=0.00852]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 249.14it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 279.41it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 292.72it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 297.23it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 297.70it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 300.92it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 302.27it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 303.38it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 302.31it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 301.97it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 301.13it/s][A
                                                                         [AEpoch 6: 100%|██████████| 28/28 [00:00<00:00, 114.20it/s, train_loss=0.00543, val_loss=0.00722]Epoch 6: 100%|██████████| 28/28 [00:00<00:00, 113.82it/s, train_loss=0.00543, val_loss=0.00722]Epoch 6:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00543, val_loss=0.00722]          Epoch 7:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00543, val_loss=0.00722]Epoch 7:   4%|▎         | 1/28 [00:00<00:00, 166.05it/s, train_loss=0.00543, val_loss=0.00722]Epoch 7:   4%|▎         | 1/28 [00:00<00:00, 112.12it/s, train_loss=0.00978, val_loss=0.00722]Epoch 7:   7%|▋         | 2/28 [00:00<00:00, 141.76it/s, train_loss=0.00978, val_loss=0.00722]Epoch 7:   7%|▋         | 2/28 [00:00<00:00, 127.18it/s, train_loss=0.00613, val_loss=0.00722]Epoch 7:  11%|█         | 3/28 [00:00<00:00, 146.50it/s, train_loss=0.00613, val_loss=0.00722]Epoch 7:  11%|█         | 3/28 [00:00<00:00, 125.46it/s, train_loss=0.00613, val_loss=0.00722]Epoch 7:  14%|█▍        | 4/28 [00:00<00:00, 136.26it/s, train_loss=0.00613, val_loss=0.00722]Epoch 7:  14%|█▍        | 4/28 [00:00<00:00, 128.93it/s, train_loss=0.00557, val_loss=0.00722]Epoch 7:  18%|█▊        | 5/28 [00:00<00:00, 139.42it/s, train_loss=0.00557, val_loss=0.00722]Epoch 7:  18%|█▊        | 5/28 [00:00<00:00, 127.69it/s, train_loss=0.00752, val_loss=0.00722]Epoch 7:  21%|██▏       | 6/28 [00:00<00:00, 134.28it/s, train_loss=0.00752, val_loss=0.00722]Epoch 7:  21%|██▏       | 6/28 [00:00<00:00, 129.71it/s, train_loss=0.00444, val_loss=0.00722]Epoch 7:  25%|██▌       | 7/28 [00:00<00:00, 136.72it/s, train_loss=0.00444, val_loss=0.00722]Epoch 7:  25%|██▌       | 7/28 [00:00<00:00, 128.70it/s, train_loss=0.00476, val_loss=0.00722]Epoch 7:  29%|██▊       | 8/28 [00:00<00:00, 133.42it/s, train_loss=0.00476, val_loss=0.00722]Epoch 7:  29%|██▊       | 8/28 [00:00<00:00, 129.83it/s, train_loss=0.00688, val_loss=0.00722]Epoch 7:  32%|███▏      | 9/28 [00:00<00:00, 134.49it/s, train_loss=0.00688, val_loss=0.00722]Epoch 7:  32%|███▏      | 9/28 [00:00<00:00, 129.97it/s, train_loss=0.00646, val_loss=0.00722]Epoch 7:  36%|███▌      | 10/28 [00:00<00:00, 134.87it/s, train_loss=0.00646, val_loss=0.00722]Epoch 7:  36%|███▌      | 10/28 [00:00<00:00, 131.96it/s, train_loss=0.00648, val_loss=0.00722]Epoch 7:  39%|███▉      | 11/28 [00:00<00:00, 137.30it/s, train_loss=0.00648, val_loss=0.00722]Epoch 7:  39%|███▉      | 11/28 [00:00<00:00, 130.92it/s, train_loss=0.00539, val_loss=0.00722]Epoch 7:  43%|████▎     | 12/28 [00:00<00:00, 134.66it/s, train_loss=0.00539, val_loss=0.00722]Epoch 7:  43%|████▎     | 12/28 [00:00<00:00, 132.16it/s, train_loss=0.00533, val_loss=0.00722]Epoch 7:  46%|████▋     | 13/28 [00:00<00:00, 135.76it/s, train_loss=0.00533, val_loss=0.00722]Epoch 7:  46%|████▋     | 13/28 [00:00<00:00, 131.38it/s, train_loss=0.0069, val_loss=0.00722] Epoch 7:  50%|█████     | 14/28 [00:00<00:00, 135.32it/s, train_loss=0.0069, val_loss=0.00722]Epoch 7:  50%|█████     | 14/28 [00:00<00:00, 133.20it/s, train_loss=0.00477, val_loss=0.00722]Epoch 7:  54%|█████▎    | 15/28 [00:00<00:00, 137.38it/s, train_loss=0.00477, val_loss=0.00722]Epoch 7:  54%|█████▎    | 15/28 [00:00<00:00, 135.00it/s, train_loss=0.00447, val_loss=0.00722]Epoch 7:  57%|█████▋    | 16/28 [00:00<00:00, 138.31it/s, train_loss=0.00447, val_loss=0.00722]Epoch 7:  57%|█████▋    | 16/28 [00:00<00:00, 135.58it/s, train_loss=0.00682, val_loss=0.00722]Epoch 7:  61%|██████    | 17/28 [00:00<00:00, 138.67it/s, train_loss=0.00682, val_loss=0.00722]Epoch 7:  61%|██████    | 17/28 [00:00<00:00, 136.77it/s, train_loss=0.0052, val_loss=0.00722] Epoch 7:  64%|██████▍   | 18/28 [00:00<00:00, 140.15it/s, train_loss=0.0052, val_loss=0.00722]Epoch 7:  64%|██████▍   | 18/28 [00:00<00:00, 138.09it/s, train_loss=0.0062, val_loss=0.00722]Epoch 7:  68%|██████▊   | 19/28 [00:00<00:00, 141.17it/s, train_loss=0.0062, val_loss=0.00722]Epoch 7:  68%|██████▊   | 19/28 [00:00<00:00, 138.65it/s, train_loss=0.00598, val_loss=0.00722]Epoch 7:  71%|███████▏  | 20/28 [00:00<00:00, 141.11it/s, train_loss=0.00598, val_loss=0.00722]Epoch 7:  71%|███████▏  | 20/28 [00:00<00:00, 139.45it/s, train_loss=0.00731, val_loss=0.00722]Epoch 7:  75%|███████▌  | 21/28 [00:00<00:00, 142.09it/s, train_loss=0.00731, val_loss=0.00722]Epoch 7:  75%|███████▌  | 21/28 [00:00<00:00, 138.35it/s, train_loss=0.0078, val_loss=0.00722] Epoch 7:  79%|███████▊  | 22/28 [00:00<00:00, 140.38it/s, train_loss=0.0078, val_loss=0.00722]Epoch 7:  79%|███████▊  | 22/28 [00:00<00:00, 138.94it/s, train_loss=0.0046, val_loss=0.00722]Epoch 7:  82%|████████▏ | 23/28 [00:00<00:00, 141.20it/s, train_loss=0.0046, val_loss=0.00722]Epoch 7:  82%|████████▏ | 23/28 [00:00<00:00, 139.66it/s, train_loss=0.00589, val_loss=0.00722]Epoch 7:  86%|████████▌ | 24/28 [00:00<00:00, 141.86it/s, train_loss=0.00589, val_loss=0.00722]Epoch 7:  86%|████████▌ | 24/28 [00:00<00:00, 138.84it/s, train_loss=0.00461, val_loss=0.00722]Epoch 7:  89%|████████▉ | 25/28 [00:00<00:00, 140.59it/s, train_loss=0.00461, val_loss=0.00722]Epoch 7:  89%|████████▉ | 25/28 [00:00<00:00, 139.22it/s, train_loss=0.00669, val_loss=0.00722]Epoch 7:  93%|█████████▎| 26/28 [00:00<00:00, 141.28it/s, train_loss=0.00669, val_loss=0.00722]Epoch 7:  93%|█████████▎| 26/28 [00:00<00:00, 138.53it/s, train_loss=0.00611, val_loss=0.00722]Epoch 7:  96%|█████████▋| 27/28 [00:00<00:00, 140.11it/s, train_loss=0.00611, val_loss=0.00722]Epoch 7:  96%|█████████▋| 27/28 [00:00<00:00, 138.86it/s, train_loss=0.00729, val_loss=0.00722]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 140.79it/s, train_loss=0.00729, val_loss=0.00722]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 138.42it/s, train_loss=0.0033, val_loss=0.00722] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 153.85it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 185.86it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 197.70it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 206.07it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 208.78it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 217.77it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 228.55it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 235.92it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 243.81it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 249.61it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 254.88it/s][A
                                                                         [AEpoch 7: 100%|██████████| 28/28 [00:00<00:00, 111.05it/s, train_loss=0.0033, val_loss=0.00631]Epoch 7: 100%|██████████| 28/28 [00:00<00:00, 110.74it/s, train_loss=0.0033, val_loss=0.00631]Epoch 7:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0033, val_loss=0.00631]          Epoch 8:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0033, val_loss=0.00631]Epoch 8:   4%|▎         | 1/28 [00:00<00:00, 163.66it/s, train_loss=0.0033, val_loss=0.00631]Epoch 8:   4%|▎         | 1/28 [00:00<00:00, 129.15it/s, train_loss=0.00601, val_loss=0.00631]Epoch 8:   7%|▋         | 2/28 [00:00<00:00, 157.01it/s, train_loss=0.00601, val_loss=0.00631]Epoch 8:   7%|▋         | 2/28 [00:00<00:00, 139.15it/s, train_loss=0.00636, val_loss=0.00631]Epoch 8:  11%|█         | 3/28 [00:00<00:00, 158.85it/s, train_loss=0.00636, val_loss=0.00631]Epoch 8:  11%|█         | 3/28 [00:00<00:00, 131.36it/s, train_loss=0.0053, val_loss=0.00631] Epoch 8:  14%|█▍        | 4/28 [00:00<00:00, 143.68it/s, train_loss=0.0053, val_loss=0.00631]Epoch 8:  14%|█▍        | 4/28 [00:00<00:00, 135.59it/s, train_loss=0.00438, val_loss=0.00631]Epoch 8:  18%|█▊        | 5/28 [00:00<00:00, 146.95it/s, train_loss=0.00438, val_loss=0.00631]Epoch 8:  18%|█▊        | 5/28 [00:00<00:00, 132.60it/s, train_loss=0.00475, val_loss=0.00631]Epoch 8:  21%|██▏       | 6/28 [00:00<00:00, 140.80it/s, train_loss=0.00475, val_loss=0.00631]Epoch 8:  21%|██▏       | 6/28 [00:00<00:00, 135.52it/s, train_loss=0.00605, val_loss=0.00631]Epoch 8:  25%|██▌       | 7/28 [00:00<00:00, 143.28it/s, train_loss=0.00605, val_loss=0.00631]Epoch 8:  25%|██▌       | 7/28 [00:00<00:00, 132.87it/s, train_loss=0.00665, val_loss=0.00631]Epoch 8:  29%|██▊       | 8/28 [00:00<00:00, 138.41it/s, train_loss=0.00665, val_loss=0.00631]Epoch 8:  29%|██▊       | 8/28 [00:00<00:00, 134.65it/s, train_loss=0.00532, val_loss=0.00631]Epoch 8:  32%|███▏      | 9/28 [00:00<00:00, 140.56it/s, train_loss=0.00532, val_loss=0.00631]Epoch 8:  32%|███▏      | 9/28 [00:00<00:00, 132.81it/s, train_loss=0.00707, val_loss=0.00631]Epoch 8:  36%|███▌      | 10/28 [00:00<00:00, 136.41it/s, train_loss=0.00707, val_loss=0.00631]Epoch 8:  36%|███▌      | 10/28 [00:00<00:00, 133.29it/s, train_loss=0.00854, val_loss=0.00631]Epoch 8:  39%|███▉      | 11/28 [00:00<00:00, 136.86it/s, train_loss=0.00854, val_loss=0.00631]Epoch 8:  39%|███▉      | 11/28 [00:00<00:00, 133.09it/s, train_loss=0.00694, val_loss=0.00631]Epoch 8:  43%|████▎     | 12/28 [00:00<00:00, 136.91it/s, train_loss=0.00694, val_loss=0.00631]Epoch 8:  43%|████▎     | 12/28 [00:00<00:00, 134.25it/s, train_loss=0.00571, val_loss=0.00631]Epoch 8:  46%|████▋     | 13/28 [00:00<00:00, 138.54it/s, train_loss=0.00571, val_loss=0.00631]Epoch 8:  46%|████▋     | 13/28 [00:00<00:00, 133.34it/s, train_loss=0.00525, val_loss=0.00631]Epoch 8:  50%|█████     | 14/28 [00:00<00:00, 136.17it/s, train_loss=0.00525, val_loss=0.00631]Epoch 8:  50%|█████     | 14/28 [00:00<00:00, 134.14it/s, train_loss=0.00418, val_loss=0.00631]Epoch 8:  54%|█████▎    | 15/28 [00:00<00:00, 136.75it/s, train_loss=0.00418, val_loss=0.00631]Epoch 8:  54%|█████▎    | 15/28 [00:00<00:00, 133.23it/s, train_loss=0.00704, val_loss=0.00631]Epoch 8:  57%|█████▋    | 16/28 [00:00<00:00, 135.82it/s, train_loss=0.00704, val_loss=0.00631]Epoch 8:  57%|█████▋    | 16/28 [00:00<00:00, 133.92it/s, train_loss=0.00576, val_loss=0.00631]Epoch 8:  61%|██████    | 17/28 [00:00<00:00, 137.47it/s, train_loss=0.00576, val_loss=0.00631]Epoch 8:  61%|██████    | 17/28 [00:00<00:00, 133.12it/s, train_loss=0.00601, val_loss=0.00631]Epoch 8:  64%|██████▍   | 18/28 [00:00<00:00, 135.76it/s, train_loss=0.00601, val_loss=0.00631]Epoch 8:  64%|██████▍   | 18/28 [00:00<00:00, 134.12it/s, train_loss=0.0046, val_loss=0.00631] Epoch 8:  68%|██████▊   | 19/28 [00:00<00:00, 137.16it/s, train_loss=0.0046, val_loss=0.00631]Epoch 8:  68%|██████▊   | 19/28 [00:00<00:00, 133.33it/s, train_loss=0.00546, val_loss=0.00631]Epoch 8:  71%|███████▏  | 20/28 [00:00<00:00, 135.77it/s, train_loss=0.00546, val_loss=0.00631]Epoch 8:  71%|███████▏  | 20/28 [00:00<00:00, 134.22it/s, train_loss=0.00453, val_loss=0.00631]Epoch 8:  75%|███████▌  | 21/28 [00:00<00:00, 136.88it/s, train_loss=0.00453, val_loss=0.00631]Epoch 8:  75%|███████▌  | 21/28 [00:00<00:00, 133.40it/s, train_loss=0.00511, val_loss=0.00631]Epoch 8:  79%|███████▊  | 22/28 [00:00<00:00, 134.93it/s, train_loss=0.00511, val_loss=0.00631]Epoch 8:  79%|███████▊  | 22/28 [00:00<00:00, 133.59it/s, train_loss=0.00427, val_loss=0.00631]Epoch 8:  82%|████████▏ | 23/28 [00:00<00:00, 135.61it/s, train_loss=0.00427, val_loss=0.00631]Epoch 8:  82%|████████▏ | 23/28 [00:00<00:00, 133.45it/s, train_loss=0.00499, val_loss=0.00631]Epoch 8:  86%|████████▌ | 24/28 [00:00<00:00, 135.41it/s, train_loss=0.00499, val_loss=0.00631]Epoch 8:  86%|████████▌ | 24/28 [00:00<00:00, 134.09it/s, train_loss=0.00493, val_loss=0.00631]Epoch 8:  89%|████████▉ | 25/28 [00:00<00:00, 135.83it/s, train_loss=0.00493, val_loss=0.00631]Epoch 8:  89%|████████▉ | 25/28 [00:00<00:00, 133.55it/s, train_loss=0.00402, val_loss=0.00631]Epoch 8:  93%|█████████▎| 26/28 [00:00<00:00, 135.29it/s, train_loss=0.00402, val_loss=0.00631]Epoch 8:  93%|█████████▎| 26/28 [00:00<00:00, 134.09it/s, train_loss=0.00568, val_loss=0.00631]Epoch 8:  96%|█████████▋| 27/28 [00:00<00:00, 136.03it/s, train_loss=0.00568, val_loss=0.00631]Epoch 8:  96%|█████████▋| 27/28 [00:00<00:00, 133.46it/s, train_loss=0.00434, val_loss=0.00631]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 134.96it/s, train_loss=0.00434, val_loss=0.00631]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 134.00it/s, train_loss=0.00646, val_loss=0.00631]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 159.86it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 186.58it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 202.12it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 210.41it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 215.67it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 219.77it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 220.85it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 222.51it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 221.26it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 221.58it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 221.20it/s][A
                                                                         [AEpoch 8: 100%|██████████| 28/28 [00:00<00:00, 105.63it/s, train_loss=0.00646, val_loss=0.00576]Epoch 8: 100%|██████████| 28/28 [00:00<00:00, 105.37it/s, train_loss=0.00646, val_loss=0.00576]Epoch 8:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00646, val_loss=0.00576]          Epoch 9:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00646, val_loss=0.00576]Epoch 9:   4%|▎         | 1/28 [00:00<00:00, 158.91it/s, train_loss=0.00646, val_loss=0.00576]Epoch 9:   4%|▎         | 1/28 [00:00<00:00, 129.94it/s, train_loss=0.00577, val_loss=0.00576]Epoch 9:   7%|▋         | 2/28 [00:00<00:00, 154.67it/s, train_loss=0.00577, val_loss=0.00576]Epoch 9:   7%|▋         | 2/28 [00:00<00:00, 138.94it/s, train_loss=0.00505, val_loss=0.00576]Epoch 9:  11%|█         | 3/28 [00:00<00:00, 156.36it/s, train_loss=0.00505, val_loss=0.00576]Epoch 9:  11%|█         | 3/28 [00:00<00:00, 143.32it/s, train_loss=0.00506, val_loss=0.00576]Epoch 9:  14%|█▍        | 4/28 [00:00<00:00, 150.37it/s, train_loss=0.00506, val_loss=0.00576]Epoch 9:  14%|█▍        | 4/28 [00:00<00:00, 140.93it/s, train_loss=0.00481, val_loss=0.00576]Epoch 9:  18%|█▊        | 5/28 [00:00<00:00, 147.77it/s, train_loss=0.00481, val_loss=0.00576]Epoch 9:  18%|█▊        | 5/28 [00:00<00:00, 141.62it/s, train_loss=0.00675, val_loss=0.00576]Epoch 9:  21%|██▏       | 6/28 [00:00<00:00, 149.20it/s, train_loss=0.00675, val_loss=0.00576]Epoch 9:  21%|██▏       | 6/28 [00:00<00:00, 142.83it/s, train_loss=0.00698, val_loss=0.00576]Epoch 9:  25%|██▌       | 7/28 [00:00<00:00, 146.67it/s, train_loss=0.00698, val_loss=0.00576]Epoch 9:  25%|██▌       | 7/28 [00:00<00:00, 142.77it/s, train_loss=0.00487, val_loss=0.00576]Epoch 9:  29%|██▊       | 8/28 [00:00<00:00, 146.87it/s, train_loss=0.00487, val_loss=0.00576]Epoch 9:  29%|██▊       | 8/28 [00:00<00:00, 143.14it/s, train_loss=0.00451, val_loss=0.00576]Epoch 9:  32%|███▏      | 9/28 [00:00<00:00, 147.84it/s, train_loss=0.00451, val_loss=0.00576]Epoch 9:  32%|███▏      | 9/28 [00:00<00:00, 143.65it/s, train_loss=0.00546, val_loss=0.00576]Epoch 9:  36%|███▌      | 10/28 [00:00<00:00, 146.29it/s, train_loss=0.00546, val_loss=0.00576]Epoch 9:  36%|███▌      | 10/28 [00:00<00:00, 143.50it/s, train_loss=0.00491, val_loss=0.00576]Epoch 9:  39%|███▉      | 11/28 [00:00<00:00, 146.25it/s, train_loss=0.00491, val_loss=0.00576]Epoch 9:  39%|███▉      | 11/28 [00:00<00:00, 143.37it/s, train_loss=0.0051, val_loss=0.00576] Epoch 9:  43%|████▎     | 12/28 [00:00<00:00, 146.79it/s, train_loss=0.0051, val_loss=0.00576]Epoch 9:  43%|████▎     | 12/28 [00:00<00:00, 143.71it/s, train_loss=0.00558, val_loss=0.00576]Epoch 9:  46%|████▋     | 13/28 [00:00<00:00, 145.34it/s, train_loss=0.00558, val_loss=0.00576]Epoch 9:  46%|████▋     | 13/28 [00:00<00:00, 143.19it/s, train_loss=0.00527, val_loss=0.00576]Epoch 9:  50%|█████     | 14/28 [00:00<00:00, 145.13it/s, train_loss=0.00527, val_loss=0.00576]Epoch 9:  50%|█████     | 14/28 [00:00<00:00, 142.94it/s, train_loss=0.00349, val_loss=0.00576]Epoch 9:  54%|█████▎    | 15/28 [00:00<00:00, 145.53it/s, train_loss=0.00349, val_loss=0.00576]Epoch 9:  54%|█████▎    | 15/28 [00:00<00:00, 140.80it/s, train_loss=0.00455, val_loss=0.00576]Epoch 9:  57%|█████▋    | 16/28 [00:00<00:00, 142.22it/s, train_loss=0.00455, val_loss=0.00576]Epoch 9:  57%|█████▋    | 16/28 [00:00<00:00, 140.29it/s, train_loss=0.0058, val_loss=0.00576] Epoch 9:  61%|██████    | 17/28 [00:00<00:00, 142.77it/s, train_loss=0.0058, val_loss=0.00576]Epoch 9:  61%|██████    | 17/28 [00:00<00:00, 138.92it/s, train_loss=0.00432, val_loss=0.00576]Epoch 9:  64%|██████▍   | 18/28 [00:00<00:00, 140.73it/s, train_loss=0.00432, val_loss=0.00576]Epoch 9:  64%|██████▍   | 18/28 [00:00<00:00, 139.16it/s, train_loss=0.00438, val_loss=0.00576]Epoch 9:  68%|██████▊   | 19/28 [00:00<00:00, 141.96it/s, train_loss=0.00438, val_loss=0.00576]Epoch 9:  68%|██████▊   | 19/28 [00:00<00:00, 138.03it/s, train_loss=0.00578, val_loss=0.00576]Epoch 9:  71%|███████▏  | 20/28 [00:00<00:00, 140.13it/s, train_loss=0.00578, val_loss=0.00576]Epoch 9:  71%|███████▏  | 20/28 [00:00<00:00, 138.66it/s, train_loss=0.0051, val_loss=0.00576] Epoch 9:  75%|███████▌  | 21/28 [00:00<00:00, 141.01it/s, train_loss=0.0051, val_loss=0.00576]Epoch 9:  75%|███████▌  | 21/28 [00:00<00:00, 137.42it/s, train_loss=0.00407, val_loss=0.00576]Epoch 9:  79%|███████▊  | 22/28 [00:00<00:00, 139.31it/s, train_loss=0.00407, val_loss=0.00576]Epoch 9:  79%|███████▊  | 22/28 [00:00<00:00, 137.93it/s, train_loss=0.00593, val_loss=0.00576]Epoch 9:  82%|████████▏ | 23/28 [00:00<00:00, 140.23it/s, train_loss=0.00593, val_loss=0.00576]Epoch 9:  82%|████████▏ | 23/28 [00:00<00:00, 136.99it/s, train_loss=0.00443, val_loss=0.00576]Epoch 9:  86%|████████▌ | 24/28 [00:00<00:00, 138.76it/s, train_loss=0.00443, val_loss=0.00576]Epoch 9:  86%|████████▌ | 24/28 [00:00<00:00, 137.53it/s, train_loss=0.00361, val_loss=0.00576]Epoch 9:  89%|████████▉ | 25/28 [00:00<00:00, 139.61it/s, train_loss=0.00361, val_loss=0.00576]Epoch 9:  89%|████████▉ | 25/28 [00:00<00:00, 136.58it/s, train_loss=0.00529, val_loss=0.00576]Epoch 9:  93%|█████████▎| 26/28 [00:00<00:00, 137.69it/s, train_loss=0.00529, val_loss=0.00576]Epoch 9:  93%|█████████▎| 26/28 [00:00<00:00, 136.67it/s, train_loss=0.00388, val_loss=0.00576]Epoch 9:  96%|█████████▋| 27/28 [00:00<00:00, 137.98it/s, train_loss=0.00388, val_loss=0.00576]Epoch 9:  96%|█████████▋| 27/28 [00:00<00:00, 136.39it/s, train_loss=0.00457, val_loss=0.00576]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 138.04it/s, train_loss=0.00457, val_loss=0.00576]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 137.06it/s, train_loss=0.0045, val_loss=0.00576] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 132.74it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 164.58it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 185.15it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 196.42it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 203.13it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 203.70it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 207.70it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 211.04it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 212.47it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 214.84it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 213.45it/s][A
                                                                         [AEpoch 9: 100%|██████████| 28/28 [00:00<00:00, 106.12it/s, train_loss=0.0045, val_loss=0.00535]Epoch 9: 100%|██████████| 28/28 [00:00<00:00, 105.71it/s, train_loss=0.0045, val_loss=0.00535]Epoch 9:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0045, val_loss=0.00535]          Epoch 10:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0045, val_loss=0.00535]Epoch 10:   4%|▎         | 1/28 [00:00<00:00, 158.60it/s, train_loss=0.0045, val_loss=0.00535]Epoch 10:   4%|▎         | 1/28 [00:00<00:00, 126.65it/s, train_loss=0.00602, val_loss=0.00535]Epoch 10:   7%|▋         | 2/28 [00:00<00:00, 162.98it/s, train_loss=0.00602, val_loss=0.00535]Epoch 10:   7%|▋         | 2/28 [00:00<00:00, 123.61it/s, train_loss=0.00467, val_loss=0.00535]Epoch 10:  11%|█         | 3/28 [00:00<00:00, 142.72it/s, train_loss=0.00467, val_loss=0.00535]Epoch 10:  11%|█         | 3/28 [00:00<00:00, 132.48it/s, train_loss=0.00438, val_loss=0.00535]Epoch 10:  14%|█▍        | 4/28 [00:00<00:00, 147.65it/s, train_loss=0.00438, val_loss=0.00535]Epoch 10:  14%|█▍        | 4/28 [00:00<00:00, 129.28it/s, train_loss=0.00488, val_loss=0.00535]Epoch 10:  18%|█▊        | 5/28 [00:00<00:00, 138.39it/s, train_loss=0.00488, val_loss=0.00535]Epoch 10:  18%|█▊        | 5/28 [00:00<00:00, 132.81it/s, train_loss=0.00533, val_loss=0.00535]Epoch 10:  21%|██▏       | 6/28 [00:00<00:00, 141.61it/s, train_loss=0.00533, val_loss=0.00535]Epoch 10:  21%|██▏       | 6/28 [00:00<00:00, 136.49it/s, train_loss=0.00502, val_loss=0.00535]Epoch 10:  25%|██▌       | 7/28 [00:00<00:00, 143.48it/s, train_loss=0.00502, val_loss=0.00535]Epoch 10:  25%|██▌       | 7/28 [00:00<00:00, 136.44it/s, train_loss=0.00495, val_loss=0.00535]Epoch 10:  29%|██▊       | 8/28 [00:00<00:00, 142.38it/s, train_loss=0.00495, val_loss=0.00535]Epoch 10:  29%|██▊       | 8/28 [00:00<00:00, 138.19it/s, train_loss=0.00431, val_loss=0.00535]Epoch 10:  32%|███▏      | 9/28 [00:00<00:00, 144.66it/s, train_loss=0.00431, val_loss=0.00535]Epoch 10:  32%|███▏      | 9/28 [00:00<00:00, 135.77it/s, train_loss=0.00428, val_loss=0.00535]Epoch 10:  36%|███▌      | 10/28 [00:00<00:00, 139.93it/s, train_loss=0.00428, val_loss=0.00535]Epoch 10:  36%|███▌      | 10/28 [00:00<00:00, 136.91it/s, train_loss=0.00584, val_loss=0.00535]Epoch 10:  39%|███▉      | 11/28 [00:00<00:00, 141.71it/s, train_loss=0.00584, val_loss=0.00535]Epoch 10:  39%|███▉      | 11/28 [00:00<00:00, 135.44it/s, train_loss=0.00542, val_loss=0.00535]Epoch 10:  43%|████▎     | 12/28 [00:00<00:00, 138.97it/s, train_loss=0.00542, val_loss=0.00535]Epoch 10:  43%|████▎     | 12/28 [00:00<00:00, 136.41it/s, train_loss=0.00468, val_loss=0.00535]Epoch 10:  46%|████▋     | 13/28 [00:00<00:00, 140.36it/s, train_loss=0.00468, val_loss=0.00535]Epoch 10:  46%|████▋     | 13/28 [00:00<00:00, 135.09it/s, train_loss=0.00516, val_loss=0.00535]Epoch 10:  50%|█████     | 14/28 [00:00<00:00, 137.82it/s, train_loss=0.00516, val_loss=0.00535]Epoch 10:  50%|█████     | 14/28 [00:00<00:00, 135.84it/s, train_loss=0.00305, val_loss=0.00535]Epoch 10:  54%|█████▎    | 15/28 [00:00<00:00, 139.03it/s, train_loss=0.00305, val_loss=0.00535]Epoch 10:  54%|█████▎    | 15/28 [00:00<00:00, 134.88it/s, train_loss=0.00508, val_loss=0.00535]Epoch 10:  57%|█████▋    | 16/28 [00:00<00:00, 137.35it/s, train_loss=0.00508, val_loss=0.00535]Epoch 10:  57%|█████▋    | 16/28 [00:00<00:00, 135.52it/s, train_loss=0.00433, val_loss=0.00535]Epoch 10:  61%|██████    | 17/28 [00:00<00:00, 138.62it/s, train_loss=0.00433, val_loss=0.00535]Epoch 10:  61%|██████    | 17/28 [00:00<00:00, 134.74it/s, train_loss=0.00496, val_loss=0.00535]Epoch 10:  64%|██████▍   | 18/28 [00:00<00:00, 137.23it/s, train_loss=0.00496, val_loss=0.00535]Epoch 10:  64%|██████▍   | 18/28 [00:00<00:00, 135.45it/s, train_loss=0.00449, val_loss=0.00535]Epoch 10:  68%|██████▊   | 19/28 [00:00<00:00, 137.85it/s, train_loss=0.00449, val_loss=0.00535]Epoch 10:  68%|██████▊   | 19/28 [00:00<00:00, 134.71it/s, train_loss=0.00408, val_loss=0.00535]Epoch 10:  71%|███████▏  | 20/28 [00:00<00:00, 136.94it/s, train_loss=0.00408, val_loss=0.00535]Epoch 10:  71%|███████▏  | 20/28 [00:00<00:00, 135.46it/s, train_loss=0.00378, val_loss=0.00535]Epoch 10:  75%|███████▌  | 21/28 [00:00<00:00, 137.95it/s, train_loss=0.00378, val_loss=0.00535]Epoch 10:  75%|███████▌  | 21/28 [00:00<00:00, 134.71it/s, train_loss=0.0038, val_loss=0.00535] Epoch 10:  79%|███████▊  | 22/28 [00:00<00:00, 136.49it/s, train_loss=0.0038, val_loss=0.00535]Epoch 10:  79%|███████▊  | 22/28 [00:00<00:00, 135.19it/s, train_loss=0.00308, val_loss=0.00535]Epoch 10:  82%|████████▏ | 23/28 [00:00<00:00, 137.49it/s, train_loss=0.00308, val_loss=0.00535]Epoch 10:  82%|████████▏ | 23/28 [00:00<00:00, 134.54it/s, train_loss=0.0032, val_loss=0.00535] Epoch 10:  86%|████████▌ | 24/28 [00:00<00:00, 136.22it/s, train_loss=0.0032, val_loss=0.00535]Epoch 10:  86%|████████▌ | 24/28 [00:00<00:00, 135.01it/s, train_loss=0.00575, val_loss=0.00535]Epoch 10:  89%|████████▉ | 25/28 [00:00<00:00, 137.20it/s, train_loss=0.00575, val_loss=0.00535]Epoch 10:  89%|████████▉ | 25/28 [00:00<00:00, 134.30it/s, train_loss=0.00571, val_loss=0.00535]Epoch 10:  93%|█████████▎| 26/28 [00:00<00:00, 135.94it/s, train_loss=0.00571, val_loss=0.00535]Epoch 10:  93%|█████████▎| 26/28 [00:00<00:00, 134.82it/s, train_loss=0.00389, val_loss=0.00535]Epoch 10:  96%|█████████▋| 27/28 [00:00<00:00, 136.77it/s, train_loss=0.00389, val_loss=0.00535]Epoch 10:  96%|█████████▋| 27/28 [00:00<00:00, 134.21it/s, train_loss=0.00422, val_loss=0.00535]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 135.85it/s, train_loss=0.00422, val_loss=0.00535]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 134.90it/s, train_loss=0.00561, val_loss=0.00535]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 179.60it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 212.32it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 223.54it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 231.44it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 235.44it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 237.98it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 240.14it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 240.90it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 242.32it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 242.88it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 243.65it/s][A
                                                                         [AEpoch 10: 100%|██████████| 28/28 [00:00<00:00, 107.67it/s, train_loss=0.00561, val_loss=0.00492]Epoch 10: 100%|██████████| 28/28 [00:00<00:00, 107.24it/s, train_loss=0.00561, val_loss=0.00492]Epoch 10:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00561, val_loss=0.00492]          Epoch 11:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00561, val_loss=0.00492]Epoch 11:   4%|▎         | 1/28 [00:00<00:00, 158.05it/s, train_loss=0.00561, val_loss=0.00492]Epoch 11:   4%|▎         | 1/28 [00:00<00:00, 99.78it/s, train_loss=0.00463, val_loss=0.00492] Epoch 11:   7%|▋         | 2/28 [00:00<00:00, 127.65it/s, train_loss=0.00463, val_loss=0.00492]Epoch 11:   7%|▋         | 2/28 [00:00<00:00, 116.69it/s, train_loss=0.00429, val_loss=0.00492]Epoch 11:  11%|█         | 3/28 [00:00<00:00, 135.13it/s, train_loss=0.00429, val_loss=0.00492]Epoch 11:  11%|█         | 3/28 [00:00<00:00, 125.31it/s, train_loss=0.00403, val_loss=0.00492]Epoch 11:  14%|█▍        | 4/28 [00:00<00:00, 136.71it/s, train_loss=0.00403, val_loss=0.00492]Epoch 11:  14%|█▍        | 4/28 [00:00<00:00, 129.66it/s, train_loss=0.00344, val_loss=0.00492]Epoch 11:  18%|█▊        | 5/28 [00:00<00:00, 140.57it/s, train_loss=0.00344, val_loss=0.00492]Epoch 11:  18%|█▊        | 5/28 [00:00<00:00, 134.17it/s, train_loss=0.00413, val_loss=0.00492]Epoch 11:  21%|██▏       | 6/28 [00:00<00:00, 145.02it/s, train_loss=0.00413, val_loss=0.00492]Epoch 11:  21%|██▏       | 6/28 [00:00<00:00, 138.66it/s, train_loss=0.00433, val_loss=0.00492]Epoch 11:  25%|██▌       | 7/28 [00:00<00:00, 146.16it/s, train_loss=0.00433, val_loss=0.00492]Epoch 11:  25%|██▌       | 7/28 [00:00<00:00, 139.51it/s, train_loss=0.00395, val_loss=0.00492]Epoch 11:  29%|██▊       | 8/28 [00:00<00:00, 145.88it/s, train_loss=0.00395, val_loss=0.00492]Epoch 11:  29%|██▊       | 8/28 [00:00<00:00, 141.71it/s, train_loss=0.00355, val_loss=0.00492]Epoch 11:  32%|███▏      | 9/28 [00:00<00:00, 148.35it/s, train_loss=0.00355, val_loss=0.00492]Epoch 11:  32%|███▏      | 9/28 [00:00<00:00, 144.05it/s, train_loss=0.00444, val_loss=0.00492]Epoch 11:  36%|███▌      | 10/28 [00:00<00:00, 149.75it/s, train_loss=0.00444, val_loss=0.00492]Epoch 11:  36%|███▌      | 10/28 [00:00<00:00, 144.56it/s, train_loss=0.00325, val_loss=0.00492]Epoch 11:  39%|███▉      | 11/28 [00:00<00:00, 148.59it/s, train_loss=0.00325, val_loss=0.00492]Epoch 11:  39%|███▉      | 11/28 [00:00<00:00, 145.28it/s, train_loss=0.00312, val_loss=0.00492]Epoch 11:  43%|████▎     | 12/28 [00:00<00:00, 149.63it/s, train_loss=0.00312, val_loss=0.00492]Epoch 11:  43%|████▎     | 12/28 [00:00<00:00, 142.61it/s, train_loss=0.00365, val_loss=0.00492]Epoch 11:  46%|████▋     | 13/28 [00:00<00:00, 145.80it/s, train_loss=0.00365, val_loss=0.00492]Epoch 11:  46%|████▋     | 13/28 [00:00<00:00, 143.11it/s, train_loss=0.00503, val_loss=0.00492]Epoch 11:  50%|█████     | 14/28 [00:00<00:00, 146.63it/s, train_loss=0.00503, val_loss=0.00492]Epoch 11:  50%|█████     | 14/28 [00:00<00:00, 141.24it/s, train_loss=0.00521, val_loss=0.00492]Epoch 11:  54%|█████▎    | 15/28 [00:00<00:00, 143.81it/s, train_loss=0.00521, val_loss=0.00492]Epoch 11:  54%|█████▎    | 15/28 [00:00<00:00, 141.67it/s, train_loss=0.00364, val_loss=0.00492]Epoch 11:  57%|█████▋    | 16/28 [00:00<00:00, 144.72it/s, train_loss=0.00364, val_loss=0.00492]Epoch 11:  57%|█████▋    | 16/28 [00:00<00:00, 140.27it/s, train_loss=0.00449, val_loss=0.00492]Epoch 11:  61%|██████    | 17/28 [00:00<00:00, 142.40it/s, train_loss=0.00449, val_loss=0.00492]Epoch 11:  61%|██████    | 17/28 [00:00<00:00, 140.63it/s, train_loss=0.00459, val_loss=0.00492]Epoch 11:  64%|██████▍   | 18/28 [00:00<00:00, 143.33it/s, train_loss=0.00459, val_loss=0.00492]Epoch 11:  64%|██████▍   | 18/28 [00:00<00:00, 139.52it/s, train_loss=0.00482, val_loss=0.00492]Epoch 11:  68%|██████▊   | 19/28 [00:00<00:00, 141.67it/s, train_loss=0.00482, val_loss=0.00492]Epoch 11:  68%|██████▊   | 19/28 [00:00<00:00, 139.93it/s, train_loss=0.00389, val_loss=0.00492]Epoch 11:  71%|███████▏  | 20/28 [00:00<00:00, 142.38it/s, train_loss=0.00389, val_loss=0.00492]Epoch 11:  71%|███████▏  | 20/28 [00:00<00:00, 138.95it/s, train_loss=0.00529, val_loss=0.00492]Epoch 11:  75%|███████▌  | 21/28 [00:00<00:00, 140.62it/s, train_loss=0.00529, val_loss=0.00492]Epoch 11:  75%|███████▌  | 21/28 [00:00<00:00, 139.20it/s, train_loss=0.00388, val_loss=0.00492]Epoch 11:  79%|███████▊  | 22/28 [00:00<00:00, 140.87it/s, train_loss=0.00388, val_loss=0.00492]Epoch 11:  79%|███████▊  | 22/28 [00:00<00:00, 138.32it/s, train_loss=0.00443, val_loss=0.00492]Epoch 11:  82%|████████▏ | 23/28 [00:00<00:00, 139.99it/s, train_loss=0.00443, val_loss=0.00492]Epoch 11:  82%|████████▏ | 23/28 [00:00<00:00, 138.59it/s, train_loss=0.0058, val_loss=0.00492] Epoch 11:  86%|████████▌ | 24/28 [00:00<00:00, 141.00it/s, train_loss=0.0058, val_loss=0.00492]Epoch 11:  86%|████████▌ | 24/28 [00:00<00:00, 137.74it/s, train_loss=0.00504, val_loss=0.00492]Epoch 11:  89%|████████▉ | 25/28 [00:00<00:00, 139.44it/s, train_loss=0.00504, val_loss=0.00492]Epoch 11:  89%|████████▉ | 25/28 [00:00<00:00, 138.25it/s, train_loss=0.00453, val_loss=0.00492]Epoch 11:  93%|█████████▎| 26/28 [00:00<00:00, 140.26it/s, train_loss=0.00453, val_loss=0.00492]Epoch 11:  93%|█████████▎| 26/28 [00:00<00:00, 137.40it/s, train_loss=0.00457, val_loss=0.00492]Epoch 11:  96%|█████████▋| 27/28 [00:00<00:00, 138.76it/s, train_loss=0.00457, val_loss=0.00492]Epoch 11:  96%|█████████▋| 27/28 [00:00<00:00, 137.63it/s, train_loss=0.00404, val_loss=0.00492]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 139.63it/s, train_loss=0.00404, val_loss=0.00492]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 137.08it/s, train_loss=0.00541, val_loss=0.00492]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 183.83it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 219.16it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 234.45it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 242.05it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 247.50it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 250.82it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 253.07it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 248.63it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 248.72it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 249.71it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 250.47it/s][A
                                                                         [AEpoch 11: 100%|██████████| 28/28 [00:00<00:00, 109.75it/s, train_loss=0.00541, val_loss=0.00468]Epoch 11: 100%|██████████| 28/28 [00:00<00:00, 109.34it/s, train_loss=0.00541, val_loss=0.00468]Epoch 11:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00541, val_loss=0.00468]          Epoch 12:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00541, val_loss=0.00468]Epoch 12:   4%|▎         | 1/28 [00:00<00:00, 156.88it/s, train_loss=0.00541, val_loss=0.00468]Epoch 12:   4%|▎         | 1/28 [00:00<00:00, 126.35it/s, train_loss=0.00346, val_loss=0.00468]Epoch 12:   7%|▋         | 2/28 [00:00<00:00, 157.61it/s, train_loss=0.00346, val_loss=0.00468]Epoch 12:   7%|▋         | 2/28 [00:00<00:00, 123.71it/s, train_loss=0.00413, val_loss=0.00468]Epoch 12:  11%|█         | 3/28 [00:00<00:00, 139.36it/s, train_loss=0.00413, val_loss=0.00468]Epoch 12:  11%|█         | 3/28 [00:00<00:00, 130.12it/s, train_loss=0.0036, val_loss=0.00468] Epoch 12:  14%|█▍        | 4/28 [00:00<00:00, 140.70it/s, train_loss=0.0036, val_loss=0.00468]Epoch 12:  14%|█▍        | 4/28 [00:00<00:00, 128.01it/s, train_loss=0.00388, val_loss=0.00468]Epoch 12:  18%|█▊        | 5/28 [00:00<00:00, 137.01it/s, train_loss=0.00388, val_loss=0.00468]Epoch 12:  18%|█▊        | 5/28 [00:00<00:00, 131.14it/s, train_loss=0.00471, val_loss=0.00468]Epoch 12:  21%|██▏       | 6/28 [00:00<00:00, 140.42it/s, train_loss=0.00471, val_loss=0.00468]Epoch 12:  21%|██▏       | 6/28 [00:00<00:00, 129.55it/s, train_loss=0.00501, val_loss=0.00468]Epoch 12:  25%|██▌       | 7/28 [00:00<00:00, 136.86it/s, train_loss=0.00501, val_loss=0.00468]Epoch 12:  25%|██▌       | 7/28 [00:00<00:00, 132.54it/s, train_loss=0.00382, val_loss=0.00468]Epoch 12:  29%|██▊       | 8/28 [00:00<00:00, 139.89it/s, train_loss=0.00382, val_loss=0.00468]Epoch 12:  29%|██▊       | 8/28 [00:00<00:00, 135.68it/s, train_loss=0.00254, val_loss=0.00468]Epoch 12:  32%|███▏      | 9/28 [00:00<00:00, 140.79it/s, train_loss=0.00254, val_loss=0.00468]Epoch 12:  32%|███▏      | 9/28 [00:00<00:00, 136.83it/s, train_loss=0.00409, val_loss=0.00468]Epoch 12:  36%|███▌      | 10/28 [00:00<00:00, 140.77it/s, train_loss=0.00409, val_loss=0.00468]Epoch 12:  36%|███▌      | 10/28 [00:00<00:00, 137.36it/s, train_loss=0.00436, val_loss=0.00468]Epoch 12:  39%|███▉      | 11/28 [00:00<00:00, 142.95it/s, train_loss=0.00436, val_loss=0.00468]Epoch 12:  39%|███▉      | 11/28 [00:00<00:00, 135.63it/s, train_loss=0.00301, val_loss=0.00468]Epoch 12:  43%|████▎     | 12/28 [00:00<00:00, 139.47it/s, train_loss=0.00301, val_loss=0.00468]Epoch 12:  43%|████▎     | 12/28 [00:00<00:00, 136.78it/s, train_loss=0.00383, val_loss=0.00468]Epoch 12:  46%|████▋     | 13/28 [00:00<00:00, 140.91it/s, train_loss=0.00383, val_loss=0.00468]Epoch 12:  46%|████▋     | 13/28 [00:00<00:00, 135.14it/s, train_loss=0.00362, val_loss=0.00468]Epoch 12:  50%|█████     | 14/28 [00:00<00:00, 138.20it/s, train_loss=0.00362, val_loss=0.00468]Epoch 12:  50%|█████     | 14/28 [00:00<00:00, 135.98it/s, train_loss=0.00476, val_loss=0.00468]Epoch 12:  54%|█████▎    | 15/28 [00:00<00:00, 139.46it/s, train_loss=0.00476, val_loss=0.00468]Epoch 12:  54%|█████▎    | 15/28 [00:00<00:00, 134.98it/s, train_loss=0.00428, val_loss=0.00468]Epoch 12:  57%|█████▋    | 16/28 [00:00<00:00, 137.76it/s, train_loss=0.00428, val_loss=0.00468]Epoch 12:  57%|█████▋    | 16/28 [00:00<00:00, 135.85it/s, train_loss=0.0028, val_loss=0.00468] Epoch 12:  61%|██████    | 17/28 [00:00<00:00, 138.89it/s, train_loss=0.0028, val_loss=0.00468]Epoch 12:  61%|██████    | 17/28 [00:00<00:00, 134.83it/s, train_loss=0.00403, val_loss=0.00468]Epoch 12:  64%|██████▍   | 18/28 [00:00<00:00, 137.15it/s, train_loss=0.00403, val_loss=0.00468]Epoch 12:  64%|██████▍   | 18/28 [00:00<00:00, 135.51it/s, train_loss=0.00432, val_loss=0.00468]Epoch 12:  68%|██████▊   | 19/28 [00:00<00:00, 138.07it/s, train_loss=0.00432, val_loss=0.00468]Epoch 12:  68%|██████▊   | 19/28 [00:00<00:00, 134.26it/s, train_loss=0.00526, val_loss=0.00468]Epoch 12:  71%|███████▏  | 20/28 [00:00<00:00, 136.06it/s, train_loss=0.00526, val_loss=0.00468]Epoch 12:  71%|███████▏  | 20/28 [00:00<00:00, 134.73it/s, train_loss=0.00349, val_loss=0.00468]Epoch 12:  75%|███████▌  | 21/28 [00:00<00:00, 136.50it/s, train_loss=0.00349, val_loss=0.00468]Epoch 12:  75%|███████▌  | 21/28 [00:00<00:00, 134.05it/s, train_loss=0.00314, val_loss=0.00468]Epoch 12:  79%|███████▊  | 22/28 [00:00<00:00, 135.83it/s, train_loss=0.00314, val_loss=0.00468]Epoch 12:  79%|███████▊  | 22/28 [00:00<00:00, 134.51it/s, train_loss=0.00497, val_loss=0.00468]Epoch 12:  82%|████████▏ | 23/28 [00:00<00:00, 136.68it/s, train_loss=0.00497, val_loss=0.00468]Epoch 12:  82%|████████▏ | 23/28 [00:00<00:00, 133.89it/s, train_loss=0.00519, val_loss=0.00468]Epoch 12:  86%|████████▌ | 24/28 [00:00<00:00, 135.43it/s, train_loss=0.00519, val_loss=0.00468]Epoch 12:  86%|████████▌ | 24/28 [00:00<00:00, 134.25it/s, train_loss=0.00462, val_loss=0.00468]Epoch 12:  89%|████████▉ | 25/28 [00:00<00:00, 135.88it/s, train_loss=0.00462, val_loss=0.00468]Epoch 12:  89%|████████▉ | 25/28 [00:00<00:00, 133.70it/s, train_loss=0.00396, val_loss=0.00468]Epoch 12:  93%|█████████▎| 26/28 [00:00<00:00, 135.61it/s, train_loss=0.00396, val_loss=0.00468]Epoch 12:  93%|█████████▎| 26/28 [00:00<00:00, 134.41it/s, train_loss=0.00373, val_loss=0.00468]Epoch 12:  96%|█████████▋| 27/28 [00:00<00:00, 136.65it/s, train_loss=0.00373, val_loss=0.00468]Epoch 12:  96%|█████████▋| 27/28 [00:00<00:00, 135.34it/s, train_loss=0.00466, val_loss=0.00468]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 137.16it/s, train_loss=0.00466, val_loss=0.00468]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 135.77it/s, train_loss=0.00432, val_loss=0.00468]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 202.83it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 232.42it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 247.07it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 251.90it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 256.60it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 259.81it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 258.99it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 260.11it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 260.89it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 261.64it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 262.59it/s][A
                                                                         [AEpoch 12: 100%|██████████| 28/28 [00:00<00:00, 110.03it/s, train_loss=0.00432, val_loss=0.00437]Epoch 12: 100%|██████████| 28/28 [00:00<00:00, 109.65it/s, train_loss=0.00432, val_loss=0.00437]Epoch 12:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00432, val_loss=0.00437]          Epoch 13:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00432, val_loss=0.00437]Epoch 13:   4%|▎         | 1/28 [00:00<00:00, 159.61it/s, train_loss=0.00432, val_loss=0.00437]Epoch 13:   4%|▎         | 1/28 [00:00<00:00, 129.65it/s, train_loss=0.00405, val_loss=0.00437]Epoch 13:   7%|▋         | 2/28 [00:00<00:00, 159.07it/s, train_loss=0.00405, val_loss=0.00437]Epoch 13:   7%|▋         | 2/28 [00:00<00:00, 139.77it/s, train_loss=0.00429, val_loss=0.00437]Epoch 13:  11%|█         | 3/28 [00:00<00:00, 154.67it/s, train_loss=0.00429, val_loss=0.00437]Epoch 13:  11%|█         | 3/28 [00:00<00:00, 143.10it/s, train_loss=0.00451, val_loss=0.00437]Epoch 13:  14%|█▍        | 4/28 [00:00<00:00, 154.13it/s, train_loss=0.00451, val_loss=0.00437]Epoch 13:  14%|█▍        | 4/28 [00:00<00:00, 144.18it/s, train_loss=0.00323, val_loss=0.00437]Epoch 13:  18%|█▊        | 5/28 [00:00<00:00, 151.44it/s, train_loss=0.00323, val_loss=0.00437]Epoch 13:  18%|█▊        | 5/28 [00:00<00:00, 144.02it/s, train_loss=0.00382, val_loss=0.00437]Epoch 13:  21%|██▏       | 6/28 [00:00<00:00, 151.09it/s, train_loss=0.00382, val_loss=0.00437]Epoch 13:  21%|██▏       | 6/28 [00:00<00:00, 145.06it/s, train_loss=0.00399, val_loss=0.00437]Epoch 13:  25%|██▌       | 7/28 [00:00<00:00, 149.78it/s, train_loss=0.00399, val_loss=0.00437]Epoch 13:  25%|██▌       | 7/28 [00:00<00:00, 144.58it/s, train_loss=0.00421, val_loss=0.00437]Epoch 13:  29%|██▊       | 8/28 [00:00<00:00, 149.60it/s, train_loss=0.00421, val_loss=0.00437]Epoch 13:  29%|██▊       | 8/28 [00:00<00:00, 144.88it/s, train_loss=0.00445, val_loss=0.00437]Epoch 13:  32%|███▏      | 9/28 [00:00<00:00, 148.37it/s, train_loss=0.00445, val_loss=0.00437]Epoch 13:  32%|███▏      | 9/28 [00:00<00:00, 144.42it/s, train_loss=0.00527, val_loss=0.00437]Epoch 13:  36%|███▌      | 10/28 [00:00<00:00, 149.44it/s, train_loss=0.00527, val_loss=0.00437]Epoch 13:  36%|███▌      | 10/28 [00:00<00:00, 145.95it/s, train_loss=0.00307, val_loss=0.00437]Epoch 13:  39%|███▉      | 11/28 [00:00<00:00, 150.19it/s, train_loss=0.00307, val_loss=0.00437]Epoch 13:  39%|███▉      | 11/28 [00:00<00:00, 145.44it/s, train_loss=0.00366, val_loss=0.00437]Epoch 13:  43%|████▎     | 12/28 [00:00<00:00, 149.45it/s, train_loss=0.00366, val_loss=0.00437]Epoch 13:  43%|████▎     | 12/28 [00:00<00:00, 146.23it/s, train_loss=0.00343, val_loss=0.00437]Epoch 13:  46%|████▋     | 13/28 [00:00<00:00, 150.16it/s, train_loss=0.00343, val_loss=0.00437]Epoch 13:  46%|████▋     | 13/28 [00:00<00:00, 145.71it/s, train_loss=0.00363, val_loss=0.00437]Epoch 13:  50%|█████     | 14/28 [00:00<00:00, 149.16it/s, train_loss=0.00363, val_loss=0.00437]Epoch 13:  50%|█████     | 14/28 [00:00<00:00, 146.56it/s, train_loss=0.00421, val_loss=0.00437]Epoch 13:  54%|█████▎    | 15/28 [00:00<00:00, 150.20it/s, train_loss=0.00421, val_loss=0.00437]Epoch 13:  54%|█████▎    | 15/28 [00:00<00:00, 147.63it/s, train_loss=0.00411, val_loss=0.00437]Epoch 13:  57%|█████▋    | 16/28 [00:00<00:00, 149.72it/s, train_loss=0.00411, val_loss=0.00437]Epoch 13:  57%|█████▋    | 16/28 [00:00<00:00, 147.53it/s, train_loss=0.00276, val_loss=0.00437]Epoch 13:  61%|██████    | 17/28 [00:00<00:00, 150.17it/s, train_loss=0.00276, val_loss=0.00437]Epoch 13:  61%|██████    | 17/28 [00:00<00:00, 147.89it/s, train_loss=0.00389, val_loss=0.00437]Epoch 13:  64%|██████▍   | 18/28 [00:00<00:00, 149.86it/s, train_loss=0.00389, val_loss=0.00437]Epoch 13:  64%|██████▍   | 18/28 [00:00<00:00, 147.90it/s, train_loss=0.00409, val_loss=0.00437]Epoch 13:  68%|██████▊   | 19/28 [00:00<00:00, 150.19it/s, train_loss=0.00409, val_loss=0.00437]Epoch 13:  68%|██████▊   | 19/28 [00:00<00:00, 148.26it/s, train_loss=0.00398, val_loss=0.00437]Epoch 13:  71%|███████▏  | 20/28 [00:00<00:00, 150.41it/s, train_loss=0.00398, val_loss=0.00437]Epoch 13:  71%|███████▏  | 20/28 [00:00<00:00, 147.91it/s, train_loss=0.00364, val_loss=0.00437]Epoch 13:  75%|███████▌  | 21/28 [00:00<00:00, 149.92it/s, train_loss=0.00364, val_loss=0.00437]Epoch 13:  75%|███████▌  | 21/28 [00:00<00:00, 148.16it/s, train_loss=0.00351, val_loss=0.00437]Epoch 13:  79%|███████▊  | 22/28 [00:00<00:00, 149.95it/s, train_loss=0.00351, val_loss=0.00437]Epoch 13:  79%|███████▊  | 22/28 [00:00<00:00, 147.78it/s, train_loss=0.00332, val_loss=0.00437]Epoch 13:  82%|████████▏ | 23/28 [00:00<00:00, 149.40it/s, train_loss=0.00332, val_loss=0.00437]Epoch 13:  82%|████████▏ | 23/28 [00:00<00:00, 147.77it/s, train_loss=0.00354, val_loss=0.00437]Epoch 13:  86%|████████▌ | 24/28 [00:00<00:00, 149.18it/s, train_loss=0.00354, val_loss=0.00437]Epoch 13:  86%|████████▌ | 24/28 [00:00<00:00, 147.57it/s, train_loss=0.0039, val_loss=0.00437] Epoch 13:  89%|████████▉ | 25/28 [00:00<00:00, 149.15it/s, train_loss=0.0039, val_loss=0.00437]Epoch 13:  89%|████████▉ | 25/28 [00:00<00:00, 147.71it/s, train_loss=0.00419, val_loss=0.00437]Epoch 13:  93%|█████████▎| 26/28 [00:00<00:00, 149.17it/s, train_loss=0.00419, val_loss=0.00437]Epoch 13:  93%|█████████▎| 26/28 [00:00<00:00, 147.38it/s, train_loss=0.00335, val_loss=0.00437]Epoch 13:  96%|█████████▋| 27/28 [00:00<00:00, 148.81it/s, train_loss=0.00335, val_loss=0.00437]Epoch 13:  96%|█████████▋| 27/28 [00:00<00:00, 147.50it/s, train_loss=0.00409, val_loss=0.00437]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 149.74it/s, train_loss=0.00409, val_loss=0.00437]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 147.38it/s, train_loss=0.00365, val_loss=0.00437]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 244.69it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 271.78it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 283.70it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 284.80it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 287.55it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 289.35it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 286.85it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 286.33it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 282.13it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 280.89it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 278.28it/s][A
                                                                         [AEpoch 13: 100%|██████████| 28/28 [00:00<00:00, 118.87it/s, train_loss=0.00365, val_loss=0.00431]Epoch 13: 100%|██████████| 28/28 [00:00<00:00, 118.46it/s, train_loss=0.00365, val_loss=0.00431]Epoch 13:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00365, val_loss=0.00431]          Epoch 14:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00365, val_loss=0.00431]Epoch 14:   4%|▎         | 1/28 [00:00<00:00, 163.40it/s, train_loss=0.00365, val_loss=0.00431]Epoch 14:   4%|▎         | 1/28 [00:00<00:00, 128.37it/s, train_loss=0.00413, val_loss=0.00431]Epoch 14:   7%|▋         | 2/28 [00:00<00:00, 160.62it/s, train_loss=0.00413, val_loss=0.00431]Epoch 14:   7%|▋         | 2/28 [00:00<00:00, 131.05it/s, train_loss=0.00314, val_loss=0.00431]Epoch 14:  11%|█         | 3/28 [00:00<00:00, 148.91it/s, train_loss=0.00314, val_loss=0.00431]Epoch 14:  11%|█         | 3/28 [00:00<00:00, 137.59it/s, train_loss=0.00412, val_loss=0.00431]Epoch 14:  14%|█▍        | 4/28 [00:00<00:00, 149.70it/s, train_loss=0.00412, val_loss=0.00431]Epoch 14:  14%|█▍        | 4/28 [00:00<00:00, 138.22it/s, train_loss=0.00358, val_loss=0.00431]Epoch 14:  18%|█▊        | 5/28 [00:00<00:00, 147.87it/s, train_loss=0.00358, val_loss=0.00431]Epoch 14:  18%|█▊        | 5/28 [00:00<00:00, 141.00it/s, train_loss=0.00377, val_loss=0.00431]Epoch 14:  21%|██▏       | 6/28 [00:00<00:00, 148.58it/s, train_loss=0.00377, val_loss=0.00431]Epoch 14:  21%|██▏       | 6/28 [00:00<00:00, 140.89it/s, train_loss=0.00356, val_loss=0.00431]Epoch 14:  25%|██▌       | 7/28 [00:00<00:00, 146.94it/s, train_loss=0.00356, val_loss=0.00431]Epoch 14:  25%|██▌       | 7/28 [00:00<00:00, 141.86it/s, train_loss=0.00345, val_loss=0.00431]Epoch 14:  29%|██▊       | 8/28 [00:00<00:00, 145.94it/s, train_loss=0.00345, val_loss=0.00431]Epoch 14:  29%|██▊       | 8/28 [00:00<00:00, 141.98it/s, train_loss=0.0039, val_loss=0.00431] Epoch 14:  32%|███▏      | 9/28 [00:00<00:00, 146.23it/s, train_loss=0.0039, val_loss=0.00431]Epoch 14:  32%|███▏      | 9/28 [00:00<00:00, 142.46it/s, train_loss=0.00347, val_loss=0.00431]Epoch 14:  36%|███▌      | 10/28 [00:00<00:00, 146.50it/s, train_loss=0.00347, val_loss=0.00431]Epoch 14:  36%|███▌      | 10/28 [00:00<00:00, 142.51it/s, train_loss=0.00365, val_loss=0.00431]Epoch 14:  39%|███▉      | 11/28 [00:00<00:00, 145.92it/s, train_loss=0.00365, val_loss=0.00431]Epoch 14:  39%|███▉      | 11/28 [00:00<00:00, 142.86it/s, train_loss=0.00355, val_loss=0.00431]Epoch 14:  43%|████▎     | 12/28 [00:00<00:00, 146.15it/s, train_loss=0.00355, val_loss=0.00431]Epoch 14:  43%|████▎     | 12/28 [00:00<00:00, 142.88it/s, train_loss=0.00387, val_loss=0.00431]Epoch 14:  46%|████▋     | 13/28 [00:00<00:00, 146.29it/s, train_loss=0.00387, val_loss=0.00431]Epoch 14:  46%|████▋     | 13/28 [00:00<00:00, 143.57it/s, train_loss=0.00404, val_loss=0.00431]Epoch 14:  50%|█████     | 14/28 [00:00<00:00, 146.43it/s, train_loss=0.00404, val_loss=0.00431]Epoch 14:  50%|█████     | 14/28 [00:00<00:00, 143.13it/s, train_loss=0.00338, val_loss=0.00431]Epoch 14:  54%|█████▎    | 15/28 [00:00<00:00, 145.85it/s, train_loss=0.00338, val_loss=0.00431]Epoch 14:  54%|█████▎    | 15/28 [00:00<00:00, 143.60it/s, train_loss=0.00385, val_loss=0.00431]Epoch 14:  57%|█████▋    | 16/28 [00:00<00:00, 146.06it/s, train_loss=0.00385, val_loss=0.00431]Epoch 14:  57%|█████▋    | 16/28 [00:00<00:00, 143.14it/s, train_loss=0.00351, val_loss=0.00431]Epoch 14:  61%|██████    | 17/28 [00:00<00:00, 145.49it/s, train_loss=0.00351, val_loss=0.00431]Epoch 14:  61%|██████    | 17/28 [00:00<00:00, 143.47it/s, train_loss=0.00326, val_loss=0.00431]Epoch 14:  64%|██████▍   | 18/28 [00:00<00:00, 146.26it/s, train_loss=0.00326, val_loss=0.00431]Epoch 14:  64%|██████▍   | 18/28 [00:00<00:00, 143.21it/s, train_loss=0.00421, val_loss=0.00431]Epoch 14:  68%|██████▊   | 19/28 [00:00<00:00, 145.12it/s, train_loss=0.00421, val_loss=0.00431]Epoch 14:  68%|██████▊   | 19/28 [00:00<00:00, 143.42it/s, train_loss=0.00291, val_loss=0.00431]Epoch 14:  71%|███████▏  | 20/28 [00:00<00:00, 145.21it/s, train_loss=0.00291, val_loss=0.00431]Epoch 14:  71%|███████▏  | 20/28 [00:00<00:00, 143.40it/s, train_loss=0.00434, val_loss=0.00431]Epoch 14:  75%|███████▌  | 21/28 [00:00<00:00, 145.55it/s, train_loss=0.00434, val_loss=0.00431]Epoch 14:  75%|███████▌  | 21/28 [00:00<00:00, 143.87it/s, train_loss=0.00378, val_loss=0.00431]Epoch 14:  79%|███████▊  | 22/28 [00:00<00:00, 146.04it/s, train_loss=0.00378, val_loss=0.00431]Epoch 14:  79%|███████▊  | 22/28 [00:00<00:00, 143.78it/s, train_loss=0.00243, val_loss=0.00431]Epoch 14:  82%|████████▏ | 23/28 [00:00<00:00, 145.80it/s, train_loss=0.00243, val_loss=0.00431]Epoch 14:  82%|████████▏ | 23/28 [00:00<00:00, 144.17it/s, train_loss=0.00375, val_loss=0.00431]Epoch 14:  86%|████████▌ | 24/28 [00:00<00:00, 145.99it/s, train_loss=0.00375, val_loss=0.00431]Epoch 14:  86%|████████▌ | 24/28 [00:00<00:00, 144.05it/s, train_loss=0.00332, val_loss=0.00431]Epoch 14:  89%|████████▉ | 25/28 [00:00<00:00, 145.75it/s, train_loss=0.00332, val_loss=0.00431]Epoch 14:  89%|████████▉ | 25/28 [00:00<00:00, 144.38it/s, train_loss=0.00401, val_loss=0.00431]Epoch 14:  93%|█████████▎| 26/28 [00:00<00:00, 145.88it/s, train_loss=0.00401, val_loss=0.00431]Epoch 14:  93%|█████████▎| 26/28 [00:00<00:00, 144.21it/s, train_loss=0.00443, val_loss=0.00431]Epoch 14:  96%|█████████▋| 27/28 [00:00<00:00, 145.69it/s, train_loss=0.00443, val_loss=0.00431]Epoch 14:  96%|█████████▋| 27/28 [00:00<00:00, 144.29it/s, train_loss=0.00385, val_loss=0.00431]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 145.86it/s, train_loss=0.00385, val_loss=0.00431]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 144.15it/s, train_loss=0.0044, val_loss=0.00431] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 171.28it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 225.46it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 249.65it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 264.94it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 274.02it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 280.53it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 285.33it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 288.96it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 290.06it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 289.87it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 290.17it/s][A
                                                                         [AEpoch 14: 100%|██████████| 28/28 [00:00<00:00, 117.10it/s, train_loss=0.0044, val_loss=0.00403]Epoch 14: 100%|██████████| 28/28 [00:00<00:00, 116.72it/s, train_loss=0.0044, val_loss=0.00403]Epoch 14:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0044, val_loss=0.00403]          Epoch 15:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.0044, val_loss=0.00403]Epoch 15:   4%|▎         | 1/28 [00:00<00:00, 170.92it/s, train_loss=0.0044, val_loss=0.00403]Epoch 15:   4%|▎         | 1/28 [00:00<00:00, 135.41it/s, train_loss=0.0028, val_loss=0.00403]Epoch 15:   7%|▋         | 2/28 [00:00<00:00, 167.09it/s, train_loss=0.0028, val_loss=0.00403]Epoch 15:   7%|▋         | 2/28 [00:00<00:00, 133.80it/s, train_loss=0.00348, val_loss=0.00403]Epoch 15:  11%|█         | 3/28 [00:00<00:00, 150.09it/s, train_loss=0.00348, val_loss=0.00403]Epoch 15:  11%|█         | 3/28 [00:00<00:00, 137.47it/s, train_loss=0.00482, val_loss=0.00403]Epoch 15:  14%|█▍        | 4/28 [00:00<00:00, 151.03it/s, train_loss=0.00482, val_loss=0.00403]Epoch 15:  14%|█▍        | 4/28 [00:00<00:00, 141.80it/s, train_loss=0.00268, val_loss=0.00403]Epoch 15:  18%|█▊        | 5/28 [00:00<00:00, 150.39it/s, train_loss=0.00268, val_loss=0.00403]Epoch 15:  18%|█▊        | 5/28 [00:00<00:00, 143.14it/s, train_loss=0.00362, val_loss=0.00403]Epoch 15:  21%|██▏       | 6/28 [00:00<00:00, 151.01it/s, train_loss=0.00362, val_loss=0.00403]Epoch 15:  21%|██▏       | 6/28 [00:00<00:00, 144.54it/s, train_loss=0.0029, val_loss=0.00403] Epoch 15:  25%|██▌       | 7/28 [00:00<00:00, 150.22it/s, train_loss=0.0029, val_loss=0.00403]Epoch 15:  25%|██▌       | 7/28 [00:00<00:00, 144.85it/s, train_loss=0.00341, val_loss=0.00403]Epoch 15:  29%|██▊       | 8/28 [00:00<00:00, 150.25it/s, train_loss=0.00341, val_loss=0.00403]Epoch 15:  29%|██▊       | 8/28 [00:00<00:00, 145.54it/s, train_loss=0.00369, val_loss=0.00403]Epoch 15:  32%|███▏      | 9/28 [00:00<00:00, 148.94it/s, train_loss=0.00369, val_loss=0.00403]Epoch 15:  32%|███▏      | 9/28 [00:00<00:00, 145.41it/s, train_loss=0.00464, val_loss=0.00403]Epoch 15:  36%|███▌      | 10/28 [00:00<00:00, 148.89it/s, train_loss=0.00464, val_loss=0.00403]Epoch 15:  36%|███▌      | 10/28 [00:00<00:00, 145.44it/s, train_loss=0.00363, val_loss=0.00403]Epoch 15:  39%|███▉      | 11/28 [00:00<00:00, 148.66it/s, train_loss=0.00363, val_loss=0.00403]Epoch 15:  39%|███▉      | 11/28 [00:00<00:00, 145.06it/s, train_loss=0.00396, val_loss=0.00403]Epoch 15:  43%|████▎     | 12/28 [00:00<00:00, 148.01it/s, train_loss=0.00396, val_loss=0.00403]Epoch 15:  43%|████▎     | 12/28 [00:00<00:00, 145.04it/s, train_loss=0.00372, val_loss=0.00403]Epoch 15:  46%|████▋     | 13/28 [00:00<00:00, 147.72it/s, train_loss=0.00372, val_loss=0.00403]Epoch 15:  46%|████▋     | 13/28 [00:00<00:00, 144.86it/s, train_loss=0.00399, val_loss=0.00403]Epoch 15:  50%|█████     | 14/28 [00:00<00:00, 147.58it/s, train_loss=0.00399, val_loss=0.00403]Epoch 15:  50%|█████     | 14/28 [00:00<00:00, 145.05it/s, train_loss=0.00429, val_loss=0.00403]Epoch 15:  54%|█████▎    | 15/28 [00:00<00:00, 148.30it/s, train_loss=0.00429, val_loss=0.00403]Epoch 15:  54%|█████▎    | 15/28 [00:00<00:00, 144.69it/s, train_loss=0.0032, val_loss=0.00403] Epoch 15:  57%|█████▋    | 16/28 [00:00<00:00, 147.86it/s, train_loss=0.0032, val_loss=0.00403]Epoch 15:  57%|█████▋    | 16/28 [00:00<00:00, 145.50it/s, train_loss=0.00378, val_loss=0.00403]Epoch 15:  61%|██████    | 17/28 [00:00<00:00, 149.02it/s, train_loss=0.00378, val_loss=0.00403]Epoch 15:  61%|██████    | 17/28 [00:00<00:00, 146.57it/s, train_loss=0.00292, val_loss=0.00403]Epoch 15:  64%|██████▍   | 18/28 [00:00<00:00, 149.03it/s, train_loss=0.00292, val_loss=0.00403]Epoch 15:  64%|██████▍   | 18/28 [00:00<00:00, 147.00it/s, train_loss=0.00351, val_loss=0.00403]Epoch 15:  68%|██████▊   | 19/28 [00:00<00:00, 149.43it/s, train_loss=0.00351, val_loss=0.00403]Epoch 15:  68%|██████▊   | 19/28 [00:00<00:00, 147.38it/s, train_loss=0.00289, val_loss=0.00403]Epoch 15:  71%|███████▏  | 20/28 [00:00<00:00, 149.55it/s, train_loss=0.00289, val_loss=0.00403]Epoch 15:  71%|███████▏  | 20/28 [00:00<00:00, 147.26it/s, train_loss=0.00331, val_loss=0.00403]Epoch 15:  75%|███████▌  | 21/28 [00:00<00:00, 149.30it/s, train_loss=0.00331, val_loss=0.00403]Epoch 15:  75%|███████▌  | 21/28 [00:00<00:00, 147.60it/s, train_loss=0.00361, val_loss=0.00403]Epoch 15:  79%|███████▊  | 22/28 [00:00<00:00, 149.54it/s, train_loss=0.00361, val_loss=0.00403]Epoch 15:  79%|███████▊  | 22/28 [00:00<00:00, 147.02it/s, train_loss=0.00343, val_loss=0.00403]Epoch 15:  82%|████████▏ | 23/28 [00:00<00:00, 148.81it/s, train_loss=0.00343, val_loss=0.00403]Epoch 15:  82%|████████▏ | 23/28 [00:00<00:00, 147.13it/s, train_loss=0.00258, val_loss=0.00403]Epoch 15:  86%|████████▌ | 24/28 [00:00<00:00, 148.89it/s, train_loss=0.00258, val_loss=0.00403]Epoch 15:  86%|████████▌ | 24/28 [00:00<00:00, 146.84it/s, train_loss=0.00326, val_loss=0.00403]Epoch 15:  89%|████████▉ | 25/28 [00:00<00:00, 148.49it/s, train_loss=0.00326, val_loss=0.00403]Epoch 15:  89%|████████▉ | 25/28 [00:00<00:00, 147.08it/s, train_loss=0.00305, val_loss=0.00403]Epoch 15:  93%|█████████▎| 26/28 [00:00<00:00, 148.67it/s, train_loss=0.00305, val_loss=0.00403]Epoch 15:  93%|█████████▎| 26/28 [00:00<00:00, 146.60it/s, train_loss=0.00414, val_loss=0.00403]Epoch 15:  96%|█████████▋| 27/28 [00:00<00:00, 148.15it/s, train_loss=0.00414, val_loss=0.00403]Epoch 15:  96%|█████████▋| 27/28 [00:00<00:00, 146.83it/s, train_loss=0.00349, val_loss=0.00403]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 148.18it/s, train_loss=0.00349, val_loss=0.00403]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 146.79it/s, train_loss=0.00197, val_loss=0.00403]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 155.45it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 179.08it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 193.81it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 199.88it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 206.10it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 207.91it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 217.01it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 227.12it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 234.24it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 240.92it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 247.11it/s][A
                                                                         [AEpoch 15: 100%|██████████| 28/28 [00:00<00:00, 115.55it/s, train_loss=0.00197, val_loss=0.00389]Epoch 15: 100%|██████████| 28/28 [00:00<00:00, 115.23it/s, train_loss=0.00197, val_loss=0.00389]Epoch 15:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00197, val_loss=0.00389]          Epoch 16:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00197, val_loss=0.00389]Epoch 16:   4%|▎         | 1/28 [00:00<00:00, 155.89it/s, train_loss=0.00197, val_loss=0.00389]Epoch 16:   4%|▎         | 1/28 [00:00<00:00, 126.13it/s, train_loss=0.00362, val_loss=0.00389]Epoch 16:   7%|▋         | 2/28 [00:00<00:00, 153.61it/s, train_loss=0.00362, val_loss=0.00389]Epoch 16:   7%|▋         | 2/28 [00:00<00:00, 136.79it/s, train_loss=0.00289, val_loss=0.00389]Epoch 16:  11%|█         | 3/28 [00:00<00:00, 151.79it/s, train_loss=0.00289, val_loss=0.00389]Epoch 16:  11%|█         | 3/28 [00:00<00:00, 138.35it/s, train_loss=0.00358, val_loss=0.00389]Epoch 16:  14%|█▍        | 4/28 [00:00<00:00, 150.48it/s, train_loss=0.00358, val_loss=0.00389]Epoch 16:  14%|█▍        | 4/28 [00:00<00:00, 142.08it/s, train_loss=0.00386, val_loss=0.00389]Epoch 16:  18%|█▊        | 5/28 [00:00<00:00, 151.09it/s, train_loss=0.00386, val_loss=0.00389]Epoch 16:  18%|█▊        | 5/28 [00:00<00:00, 140.58it/s, train_loss=0.00373, val_loss=0.00389]Epoch 16:  21%|██▏       | 6/28 [00:00<00:00, 147.82it/s, train_loss=0.00373, val_loss=0.00389]Epoch 16:  21%|██▏       | 6/28 [00:00<00:00, 141.97it/s, train_loss=0.00331, val_loss=0.00389]Epoch 16:  25%|██▌       | 7/28 [00:00<00:00, 147.81it/s, train_loss=0.00331, val_loss=0.00389]Epoch 16:  25%|██▌       | 7/28 [00:00<00:00, 140.97it/s, train_loss=0.00396, val_loss=0.00389]Epoch 16:  29%|██▊       | 8/28 [00:00<00:00, 146.30it/s, train_loss=0.00396, val_loss=0.00389]Epoch 16:  29%|██▊       | 8/28 [00:00<00:00, 141.77it/s, train_loss=0.00249, val_loss=0.00389]Epoch 16:  32%|███▏      | 9/28 [00:00<00:00, 146.98it/s, train_loss=0.00249, val_loss=0.00389]Epoch 16:  32%|███▏      | 9/28 [00:00<00:00, 141.67it/s, train_loss=0.00325, val_loss=0.00389]Epoch 16:  36%|███▌      | 10/28 [00:00<00:00, 146.18it/s, train_loss=0.00325, val_loss=0.00389]Epoch 16:  36%|███▌      | 10/28 [00:00<00:00, 142.53it/s, train_loss=0.00244, val_loss=0.00389]Epoch 16:  39%|███▉      | 11/28 [00:00<00:00, 146.24it/s, train_loss=0.00244, val_loss=0.00389]Epoch 16:  39%|███▉      | 11/28 [00:00<00:00, 142.24it/s, train_loss=0.00321, val_loss=0.00389]Epoch 16:  43%|████▎     | 12/28 [00:00<00:00, 145.55it/s, train_loss=0.00321, val_loss=0.00389]Epoch 16:  43%|████▎     | 12/28 [00:00<00:00, 142.68it/s, train_loss=0.00276, val_loss=0.00389]Epoch 16:  46%|████▋     | 13/28 [00:00<00:00, 145.84it/s, train_loss=0.00276, val_loss=0.00389]Epoch 16:  46%|████▋     | 13/28 [00:00<00:00, 142.63it/s, train_loss=0.00344, val_loss=0.00389]Epoch 16:  50%|█████     | 14/28 [00:00<00:00, 145.43it/s, train_loss=0.00344, val_loss=0.00389]Epoch 16:  50%|█████     | 14/28 [00:00<00:00, 142.91it/s, train_loss=0.00288, val_loss=0.00389]Epoch 16:  54%|█████▎    | 15/28 [00:00<00:00, 145.43it/s, train_loss=0.00288, val_loss=0.00389]Epoch 16:  54%|█████▎    | 15/28 [00:00<00:00, 142.91it/s, train_loss=0.00337, val_loss=0.00389]Epoch 16:  57%|█████▋    | 16/28 [00:00<00:00, 145.15it/s, train_loss=0.00337, val_loss=0.00389]Epoch 16:  57%|█████▋    | 16/28 [00:00<00:00, 143.03it/s, train_loss=0.00305, val_loss=0.00389]Epoch 16:  61%|██████    | 17/28 [00:00<00:00, 145.70it/s, train_loss=0.00305, val_loss=0.00389]Epoch 16:  61%|██████    | 17/28 [00:00<00:00, 142.86it/s, train_loss=0.00325, val_loss=0.00389]Epoch 16:  64%|██████▍   | 18/28 [00:00<00:00, 145.57it/s, train_loss=0.00325, val_loss=0.00389]Epoch 16:  64%|██████▍   | 18/28 [00:00<00:00, 143.62it/s, train_loss=0.00436, val_loss=0.00389]Epoch 16:  68%|██████▊   | 19/28 [00:00<00:00, 146.76it/s, train_loss=0.00436, val_loss=0.00389]Epoch 16:  68%|██████▊   | 19/28 [00:00<00:00, 144.60it/s, train_loss=0.00333, val_loss=0.00389]Epoch 16:  71%|███████▏  | 20/28 [00:00<00:00, 146.80it/s, train_loss=0.00333, val_loss=0.00389]Epoch 16:  71%|███████▏  | 20/28 [00:00<00:00, 144.89it/s, train_loss=0.00419, val_loss=0.00389]Epoch 16:  75%|███████▌  | 21/28 [00:00<00:00, 147.24it/s, train_loss=0.00419, val_loss=0.00389]Epoch 16:  75%|███████▌  | 21/28 [00:00<00:00, 145.35it/s, train_loss=0.0042, val_loss=0.00389] Epoch 16:  79%|███████▊  | 22/28 [00:00<00:00, 147.48it/s, train_loss=0.0042, val_loss=0.00389]Epoch 16:  79%|███████▊  | 22/28 [00:00<00:00, 145.08it/s, train_loss=0.00373, val_loss=0.00389]Epoch 16:  82%|████████▏ | 23/28 [00:00<00:00, 147.08it/s, train_loss=0.00373, val_loss=0.00389]Epoch 16:  82%|████████▏ | 23/28 [00:00<00:00, 145.49it/s, train_loss=0.00379, val_loss=0.00389]Epoch 16:  86%|████████▌ | 24/28 [00:00<00:00, 147.32it/s, train_loss=0.00379, val_loss=0.00389]Epoch 16:  86%|████████▌ | 24/28 [00:00<00:00, 145.12it/s, train_loss=0.00273, val_loss=0.00389]Epoch 16:  89%|████████▉ | 25/28 [00:00<00:00, 146.85it/s, train_loss=0.00273, val_loss=0.00389]Epoch 16:  89%|████████▉ | 25/28 [00:00<00:00, 145.30it/s, train_loss=0.00363, val_loss=0.00389]Epoch 16:  93%|█████████▎| 26/28 [00:00<00:00, 146.61it/s, train_loss=0.00363, val_loss=0.00389]Epoch 16:  93%|█████████▎| 26/28 [00:00<00:00, 145.28it/s, train_loss=0.00304, val_loss=0.00389]Epoch 16:  96%|█████████▋| 27/28 [00:00<00:00, 146.88it/s, train_loss=0.00304, val_loss=0.00389]Epoch 16:  96%|█████████▋| 27/28 [00:00<00:00, 145.56it/s, train_loss=0.00275, val_loss=0.00389]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 146.95it/s, train_loss=0.00275, val_loss=0.00389]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 145.54it/s, train_loss=0.00343, val_loss=0.00389]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 160.28it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 187.10it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 202.61it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 208.90it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 213.70it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 214.39it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 217.11it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 218.01it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 219.76it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 218.56it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 218.83it/s][A
                                                                         [AEpoch 16: 100%|██████████| 28/28 [00:00<00:00, 111.82it/s, train_loss=0.00343, val_loss=0.00385]Epoch 16: 100%|██████████| 28/28 [00:00<00:00, 111.54it/s, train_loss=0.00343, val_loss=0.00385]Epoch 16:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00343, val_loss=0.00385]          Epoch 17:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00343, val_loss=0.00385]Epoch 17:   4%|▎         | 1/28 [00:00<00:00, 163.78it/s, train_loss=0.00343, val_loss=0.00385]Epoch 17:   4%|▎         | 1/28 [00:00<00:00, 132.01it/s, train_loss=0.00349, val_loss=0.00385]Epoch 17:   7%|▋         | 2/28 [00:00<00:00, 162.06it/s, train_loss=0.00349, val_loss=0.00385]Epoch 17:   7%|▋         | 2/28 [00:00<00:00, 141.68it/s, train_loss=0.00335, val_loss=0.00385]Epoch 17:  11%|█         | 3/28 [00:00<00:00, 158.59it/s, train_loss=0.00335, val_loss=0.00385]Epoch 17:  11%|█         | 3/28 [00:00<00:00, 140.53it/s, train_loss=0.00322, val_loss=0.00385]Epoch 17:  14%|█▍        | 4/28 [00:00<00:00, 152.68it/s, train_loss=0.00322, val_loss=0.00385]Epoch 17:  14%|█▍        | 4/28 [00:00<00:00, 143.22it/s, train_loss=0.00299, val_loss=0.00385]Epoch 17:  18%|█▊        | 5/28 [00:00<00:00, 152.22it/s, train_loss=0.00299, val_loss=0.00385]Epoch 17:  18%|█▊        | 5/28 [00:00<00:00, 140.76it/s, train_loss=0.00361, val_loss=0.00385]Epoch 17:  21%|██▏       | 6/28 [00:00<00:00, 148.39it/s, train_loss=0.00361, val_loss=0.00385]Epoch 17:  21%|██▏       | 6/28 [00:00<00:00, 142.28it/s, train_loss=0.00265, val_loss=0.00385]Epoch 17:  25%|██▌       | 7/28 [00:00<00:00, 148.90it/s, train_loss=0.00265, val_loss=0.00385]Epoch 17:  25%|██▌       | 7/28 [00:00<00:00, 142.10it/s, train_loss=0.00337, val_loss=0.00385]Epoch 17:  29%|██▊       | 8/28 [00:00<00:00, 147.43it/s, train_loss=0.00337, val_loss=0.00385]Epoch 17:  29%|██▊       | 8/28 [00:00<00:00, 142.90it/s, train_loss=0.00314, val_loss=0.00385]Epoch 17:  32%|███▏      | 9/28 [00:00<00:00, 147.64it/s, train_loss=0.00314, val_loss=0.00385]Epoch 17:  32%|███▏      | 9/28 [00:00<00:00, 142.14it/s, train_loss=0.00282, val_loss=0.00385]Epoch 17:  36%|███▌      | 10/28 [00:00<00:00, 146.21it/s, train_loss=0.00282, val_loss=0.00385]Epoch 17:  36%|███▌      | 10/28 [00:00<00:00, 142.60it/s, train_loss=0.00387, val_loss=0.00385]Epoch 17:  39%|███▉      | 11/28 [00:00<00:00, 146.30it/s, train_loss=0.00387, val_loss=0.00385]Epoch 17:  39%|███▉      | 11/28 [00:00<00:00, 142.59it/s, train_loss=0.00379, val_loss=0.00385]Epoch 17:  43%|████▎     | 12/28 [00:00<00:00, 145.88it/s, train_loss=0.00379, val_loss=0.00385]Epoch 17:  43%|████▎     | 12/28 [00:00<00:00, 142.95it/s, train_loss=0.00344, val_loss=0.00385]Epoch 17:  46%|████▋     | 13/28 [00:00<00:00, 146.12it/s, train_loss=0.00344, val_loss=0.00385]Epoch 17:  46%|████▋     | 13/28 [00:00<00:00, 142.94it/s, train_loss=0.00321, val_loss=0.00385]Epoch 17:  50%|█████     | 14/28 [00:00<00:00, 146.11it/s, train_loss=0.00321, val_loss=0.00385]Epoch 17:  50%|█████     | 14/28 [00:00<00:00, 143.57it/s, train_loss=0.00322, val_loss=0.00385]Epoch 17:  54%|█████▎    | 15/28 [00:00<00:00, 146.62it/s, train_loss=0.00322, val_loss=0.00385]Epoch 17:  54%|█████▎    | 15/28 [00:00<00:00, 143.03it/s, train_loss=0.00319, val_loss=0.00385]Epoch 17:  57%|█████▋    | 16/28 [00:00<00:00, 145.81it/s, train_loss=0.00319, val_loss=0.00385]Epoch 17:  57%|█████▋    | 16/28 [00:00<00:00, 143.61it/s, train_loss=0.00342, val_loss=0.00385]Epoch 17:  61%|██████    | 17/28 [00:00<00:00, 145.99it/s, train_loss=0.00342, val_loss=0.00385]Epoch 17:  61%|██████    | 17/28 [00:00<00:00, 143.34it/s, train_loss=0.003, val_loss=0.00385]  Epoch 17:  64%|██████▍   | 18/28 [00:00<00:00, 145.54it/s, train_loss=0.003, val_loss=0.00385]Epoch 17:  64%|██████▍   | 18/28 [00:00<00:00, 143.57it/s, train_loss=0.00312, val_loss=0.00385]Epoch 17:  68%|██████▊   | 19/28 [00:00<00:00, 146.10it/s, train_loss=0.00312, val_loss=0.00385]Epoch 17:  68%|██████▊   | 19/28 [00:00<00:00, 143.16it/s, train_loss=0.00351, val_loss=0.00385]Epoch 17:  71%|███████▏  | 20/28 [00:00<00:00, 145.51it/s, train_loss=0.00351, val_loss=0.00385]Epoch 17:  71%|███████▏  | 20/28 [00:00<00:00, 143.65it/s, train_loss=0.00327, val_loss=0.00385]Epoch 17:  75%|███████▌  | 21/28 [00:00<00:00, 145.91it/s, train_loss=0.00327, val_loss=0.00385]Epoch 17:  75%|███████▌  | 21/28 [00:00<00:00, 143.40it/s, train_loss=0.0031, val_loss=0.00385] Epoch 17:  79%|███████▊  | 22/28 [00:00<00:00, 145.53it/s, train_loss=0.0031, val_loss=0.00385]Epoch 17:  79%|███████▊  | 22/28 [00:00<00:00, 143.81it/s, train_loss=0.00354, val_loss=0.00385]Epoch 17:  82%|████████▏ | 23/28 [00:00<00:00, 145.71it/s, train_loss=0.00354, val_loss=0.00385]Epoch 17:  82%|████████▏ | 23/28 [00:00<00:00, 143.50it/s, train_loss=0.00282, val_loss=0.00385]Epoch 17:  86%|████████▌ | 24/28 [00:00<00:00, 145.26it/s, train_loss=0.00282, val_loss=0.00385]Epoch 17:  86%|████████▌ | 24/28 [00:00<00:00, 143.68it/s, train_loss=0.00362, val_loss=0.00385]Epoch 17:  89%|████████▉ | 25/28 [00:00<00:00, 145.11it/s, train_loss=0.00362, val_loss=0.00385]Epoch 17:  89%|████████▉ | 25/28 [00:00<00:00, 143.41it/s, train_loss=0.00326, val_loss=0.00385]Epoch 17:  93%|█████████▎| 26/28 [00:00<00:00, 144.65it/s, train_loss=0.00326, val_loss=0.00385]Epoch 17:  93%|█████████▎| 26/28 [00:00<00:00, 143.25it/s, train_loss=0.00299, val_loss=0.00385]Epoch 17:  96%|█████████▋| 27/28 [00:00<00:00, 144.56it/s, train_loss=0.00299, val_loss=0.00385]Epoch 17:  96%|█████████▋| 27/28 [00:00<00:00, 143.37it/s, train_loss=0.00288, val_loss=0.00385]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 144.91it/s, train_loss=0.00288, val_loss=0.00385]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 143.72it/s, train_loss=0.00288, val_loss=0.00385]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 161.35it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 187.69it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 199.43it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 206.46it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 208.64it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 211.59it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 213.34it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 213.82it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 210.02it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 209.75it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 210.46it/s][A
                                                                         [AEpoch 17: 100%|██████████| 28/28 [00:00<00:00, 109.66it/s, train_loss=0.00288, val_loss=0.00378]Epoch 17: 100%|██████████| 28/28 [00:00<00:00, 109.23it/s, train_loss=0.00288, val_loss=0.00378]Epoch 17:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00288, val_loss=0.00378]          Epoch 18:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00288, val_loss=0.00378]Epoch 18:   4%|▎         | 1/28 [00:00<00:00, 129.15it/s, train_loss=0.00288, val_loss=0.00378]Epoch 18:   4%|▎         | 1/28 [00:00<00:00, 107.44it/s, train_loss=0.00356, val_loss=0.00378]Epoch 18:   7%|▋         | 2/28 [00:00<00:00, 139.11it/s, train_loss=0.00356, val_loss=0.00378]Epoch 18:   7%|▋         | 2/28 [00:00<00:00, 125.32it/s, train_loss=0.00282, val_loss=0.00378]Epoch 18:  11%|█         | 3/28 [00:00<00:00, 141.09it/s, train_loss=0.00282, val_loss=0.00378]Epoch 18:  11%|█         | 3/28 [00:00<00:00, 130.79it/s, train_loss=0.0029, val_loss=0.00378] Epoch 18:  14%|█▍        | 4/28 [00:00<00:00, 142.28it/s, train_loss=0.0029, val_loss=0.00378]Epoch 18:  14%|█▍        | 4/28 [00:00<00:00, 134.85it/s, train_loss=0.0025, val_loss=0.00378]Epoch 18:  18%|█▊        | 5/28 [00:00<00:00, 142.24it/s, train_loss=0.0025, val_loss=0.00378]Epoch 18:  18%|█▊        | 5/28 [00:00<00:00, 136.42it/s, train_loss=0.0031, val_loss=0.00378]Epoch 18:  21%|██▏       | 6/28 [00:00<00:00, 143.24it/s, train_loss=0.0031, val_loss=0.00378]Epoch 18:  21%|██▏       | 6/28 [00:00<00:00, 138.15it/s, train_loss=0.00304, val_loss=0.00378]Epoch 18:  25%|██▌       | 7/28 [00:00<00:00, 143.94it/s, train_loss=0.00304, val_loss=0.00378]Epoch 18:  25%|██▌       | 7/28 [00:00<00:00, 139.26it/s, train_loss=0.00355, val_loss=0.00378]Epoch 18:  29%|██▊       | 8/28 [00:00<00:00, 144.68it/s, train_loss=0.00355, val_loss=0.00378]Epoch 18:  29%|██▊       | 8/28 [00:00<00:00, 140.19it/s, train_loss=0.00344, val_loss=0.00378]Epoch 18:  32%|███▏      | 9/28 [00:00<00:00, 144.59it/s, train_loss=0.00344, val_loss=0.00378]Epoch 18:  32%|███▏      | 9/28 [00:00<00:00, 140.89it/s, train_loss=0.00306, val_loss=0.00378]Epoch 18:  36%|███▌      | 10/28 [00:00<00:00, 123.62it/s, train_loss=0.00306, val_loss=0.00378]Epoch 18:  36%|███▌      | 10/28 [00:00<00:00, 121.22it/s, train_loss=0.00293, val_loss=0.00378]Epoch 18:  39%|███▉      | 11/28 [00:00<00:00, 125.04it/s, train_loss=0.00293, val_loss=0.00378]Epoch 18:  39%|███▉      | 11/28 [00:00<00:00, 122.85it/s, train_loss=0.00312, val_loss=0.00378]Epoch 18:  43%|████▎     | 12/28 [00:00<00:00, 126.54it/s, train_loss=0.00312, val_loss=0.00378]Epoch 18:  43%|████▎     | 12/28 [00:00<00:00, 124.42it/s, train_loss=0.00309, val_loss=0.00378]Epoch 18:  46%|████▋     | 13/28 [00:00<00:00, 127.42it/s, train_loss=0.00309, val_loss=0.00378]Epoch 18:  46%|████▋     | 13/28 [00:00<00:00, 125.59it/s, train_loss=0.0048, val_loss=0.00378] Epoch 18:  50%|█████     | 14/28 [00:00<00:00, 128.54it/s, train_loss=0.0048, val_loss=0.00378]Epoch 18:  50%|█████     | 14/28 [00:00<00:00, 126.49it/s, train_loss=0.00288, val_loss=0.00378]Epoch 18:  54%|█████▎    | 15/28 [00:00<00:00, 128.88it/s, train_loss=0.00288, val_loss=0.00378]Epoch 18:  54%|█████▎    | 15/28 [00:00<00:00, 127.09it/s, train_loss=0.00413, val_loss=0.00378]Epoch 18:  57%|█████▋    | 16/28 [00:00<00:00, 129.58it/s, train_loss=0.00413, val_loss=0.00378]Epoch 18:  57%|█████▋    | 16/28 [00:00<00:00, 127.89it/s, train_loss=0.00293, val_loss=0.00378]Epoch 18:  61%|██████    | 17/28 [00:00<00:00, 129.80it/s, train_loss=0.00293, val_loss=0.00378]Epoch 18:  61%|██████    | 17/28 [00:00<00:00, 128.21it/s, train_loss=0.00359, val_loss=0.00378]Epoch 18:  64%|██████▍   | 18/28 [00:00<00:00, 130.35it/s, train_loss=0.00359, val_loss=0.00378]Epoch 18:  64%|██████▍   | 18/28 [00:00<00:00, 128.92it/s, train_loss=0.00309, val_loss=0.00378]Epoch 18:  68%|██████▊   | 19/28 [00:00<00:00, 130.54it/s, train_loss=0.00309, val_loss=0.00378]Epoch 18:  68%|██████▊   | 19/28 [00:00<00:00, 129.14it/s, train_loss=0.00275, val_loss=0.00378]Epoch 18:  71%|███████▏  | 20/28 [00:00<00:00, 131.18it/s, train_loss=0.00275, val_loss=0.00378]Epoch 18:  71%|███████▏  | 20/28 [00:00<00:00, 129.76it/s, train_loss=0.00279, val_loss=0.00378]Epoch 18:  75%|███████▌  | 21/28 [00:00<00:00, 131.52it/s, train_loss=0.00279, val_loss=0.00378]Epoch 18:  75%|███████▌  | 21/28 [00:00<00:00, 130.17it/s, train_loss=0.00317, val_loss=0.00378]Epoch 18:  79%|███████▊  | 22/28 [00:00<00:00, 132.38it/s, train_loss=0.00317, val_loss=0.00378]Epoch 18:  79%|███████▊  | 22/28 [00:00<00:00, 130.98it/s, train_loss=0.00376, val_loss=0.00378]Epoch 18:  82%|████████▏ | 23/28 [00:00<00:00, 132.84it/s, train_loss=0.00376, val_loss=0.00378]Epoch 18:  82%|████████▏ | 23/28 [00:00<00:00, 131.68it/s, train_loss=0.00275, val_loss=0.00378]Epoch 18:  86%|████████▌ | 24/28 [00:00<00:00, 133.44it/s, train_loss=0.00275, val_loss=0.00378]Epoch 18:  86%|████████▌ | 24/28 [00:00<00:00, 132.18it/s, train_loss=0.00273, val_loss=0.00378]Epoch 18:  89%|████████▉ | 25/28 [00:00<00:00, 133.67it/s, train_loss=0.00273, val_loss=0.00378]Epoch 18:  89%|████████▉ | 25/28 [00:00<00:00, 132.54it/s, train_loss=0.00272, val_loss=0.00378]Epoch 18:  93%|█████████▎| 26/28 [00:00<00:00, 134.22it/s, train_loss=0.00272, val_loss=0.00378]Epoch 18:  93%|█████████▎| 26/28 [00:00<00:00, 133.06it/s, train_loss=0.0034, val_loss=0.00378] Epoch 18:  96%|█████████▋| 27/28 [00:00<00:00, 134.57it/s, train_loss=0.0034, val_loss=0.00378]Epoch 18:  96%|█████████▋| 27/28 [00:00<00:00, 133.43it/s, train_loss=0.00256, val_loss=0.00378]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 135.14it/s, train_loss=0.00256, val_loss=0.00378]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 134.08it/s, train_loss=0.00253, val_loss=0.00378]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 183.17it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 207.27it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 218.81it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 223.26it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 226.23it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 227.55it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 228.56it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 228.40it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 228.39it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 228.24it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 228.85it/s][A
                                                                         [AEpoch 18: 100%|██████████| 28/28 [00:00<00:00, 105.75it/s, train_loss=0.00253, val_loss=0.00366]Epoch 18: 100%|██████████| 28/28 [00:00<00:00, 105.36it/s, train_loss=0.00253, val_loss=0.00366]Epoch 18:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00253, val_loss=0.00366]          Epoch 19:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00253, val_loss=0.00366]Epoch 19:   4%|▎         | 1/28 [00:00<00:00, 148.11it/s, train_loss=0.00253, val_loss=0.00366]Epoch 19:   4%|▎         | 1/28 [00:00<00:00, 121.42it/s, train_loss=0.00291, val_loss=0.00366]Epoch 19:   7%|▋         | 2/28 [00:00<00:00, 146.14it/s, train_loss=0.00291, val_loss=0.00366]Epoch 19:   7%|▋         | 2/28 [00:00<00:00, 130.49it/s, train_loss=0.00279, val_loss=0.00366]Epoch 19:  11%|█         | 3/28 [00:00<00:00, 142.56it/s, train_loss=0.00279, val_loss=0.00366]Epoch 19:  11%|█         | 3/28 [00:00<00:00, 132.37it/s, train_loss=0.00327, val_loss=0.00366]Epoch 19:  14%|█▍        | 4/28 [00:00<00:00, 142.18it/s, train_loss=0.00327, val_loss=0.00366]Epoch 19:  14%|█▍        | 4/28 [00:00<00:00, 134.74it/s, train_loss=0.00264, val_loss=0.00366]Epoch 19:  18%|█▊        | 5/28 [00:00<00:00, 143.41it/s, train_loss=0.00264, val_loss=0.00366]Epoch 19:  18%|█▊        | 5/28 [00:00<00:00, 137.01it/s, train_loss=0.00341, val_loss=0.00366]Epoch 19:  21%|██▏       | 6/28 [00:00<00:00, 144.83it/s, train_loss=0.00341, val_loss=0.00366]Epoch 19:  21%|██▏       | 6/28 [00:00<00:00, 139.58it/s, train_loss=0.00253, val_loss=0.00366]Epoch 19:  25%|██▌       | 7/28 [00:00<00:00, 145.23it/s, train_loss=0.00253, val_loss=0.00366]Epoch 19:  25%|██▌       | 7/28 [00:00<00:00, 140.56it/s, train_loss=0.00325, val_loss=0.00366]Epoch 19:  29%|██▊       | 8/28 [00:00<00:00, 145.89it/s, train_loss=0.00325, val_loss=0.00366]Epoch 19:  29%|██▊       | 8/28 [00:00<00:00, 141.26it/s, train_loss=0.00324, val_loss=0.00366]Epoch 19:  32%|███▏      | 9/28 [00:00<00:00, 145.61it/s, train_loss=0.00324, val_loss=0.00366]Epoch 19:  32%|███▏      | 9/28 [00:00<00:00, 141.76it/s, train_loss=0.00347, val_loss=0.00366]Epoch 19:  36%|███▌      | 10/28 [00:00<00:00, 145.88it/s, train_loss=0.00347, val_loss=0.00366]Epoch 19:  36%|███▌      | 10/28 [00:00<00:00, 142.29it/s, train_loss=0.00298, val_loss=0.00366]Epoch 19:  39%|███▉      | 11/28 [00:00<00:00, 145.50it/s, train_loss=0.00298, val_loss=0.00366]Epoch 19:  39%|███▉      | 11/28 [00:00<00:00, 142.38it/s, train_loss=0.0034, val_loss=0.00366] Epoch 19:  43%|████▎     | 12/28 [00:00<00:00, 145.71it/s, train_loss=0.0034, val_loss=0.00366]Epoch 19:  43%|████▎     | 12/28 [00:00<00:00, 142.93it/s, train_loss=0.00341, val_loss=0.00366]Epoch 19:  46%|████▋     | 13/28 [00:00<00:00, 145.50it/s, train_loss=0.00341, val_loss=0.00366]Epoch 19:  46%|████▋     | 13/28 [00:00<00:00, 142.87it/s, train_loss=0.00314, val_loss=0.00366]Epoch 19:  50%|█████     | 14/28 [00:00<00:00, 145.60it/s, train_loss=0.00314, val_loss=0.00366]Epoch 19:  50%|█████     | 14/28 [00:00<00:00, 143.26it/s, train_loss=0.00234, val_loss=0.00366]Epoch 19:  54%|█████▎    | 15/28 [00:00<00:00, 145.51it/s, train_loss=0.00234, val_loss=0.00366]Epoch 19:  54%|█████▎    | 15/28 [00:00<00:00, 143.22it/s, train_loss=0.00332, val_loss=0.00366]Epoch 19:  57%|█████▋    | 16/28 [00:00<00:00, 145.51it/s, train_loss=0.00332, val_loss=0.00366]Epoch 19:  57%|█████▋    | 16/28 [00:00<00:00, 143.28it/s, train_loss=0.00338, val_loss=0.00366]Epoch 19:  61%|██████    | 17/28 [00:00<00:00, 145.02it/s, train_loss=0.00338, val_loss=0.00366]Epoch 19:  61%|██████    | 17/28 [00:00<00:00, 143.08it/s, train_loss=0.00319, val_loss=0.00366]Epoch 19:  64%|██████▍   | 18/28 [00:00<00:00, 145.07it/s, train_loss=0.00319, val_loss=0.00366]Epoch 19:  64%|██████▍   | 18/28 [00:00<00:00, 143.11it/s, train_loss=0.00313, val_loss=0.00366]Epoch 19:  68%|██████▊   | 19/28 [00:00<00:00, 145.01it/s, train_loss=0.00313, val_loss=0.00366]Epoch 19:  68%|██████▊   | 19/28 [00:00<00:00, 143.12it/s, train_loss=0.00322, val_loss=0.00366]Epoch 19:  71%|███████▏  | 20/28 [00:00<00:00, 145.58it/s, train_loss=0.00322, val_loss=0.00366]Epoch 19:  71%|███████▏  | 20/28 [00:00<00:00, 143.86it/s, train_loss=0.0028, val_loss=0.00366] Epoch 19:  75%|███████▌  | 21/28 [00:00<00:00, 145.83it/s, train_loss=0.0028, val_loss=0.00366]Epoch 19:  75%|███████▌  | 21/28 [00:00<00:00, 143.67it/s, train_loss=0.0033, val_loss=0.00366]Epoch 19:  79%|███████▊  | 22/28 [00:00<00:00, 145.71it/s, train_loss=0.0033, val_loss=0.00366]Epoch 19:  79%|███████▊  | 22/28 [00:00<00:00, 144.08it/s, train_loss=0.00332, val_loss=0.00366]Epoch 19:  82%|████████▏ | 23/28 [00:00<00:00, 145.67it/s, train_loss=0.00332, val_loss=0.00366]Epoch 19:  82%|████████▏ | 23/28 [00:00<00:00, 143.95it/s, train_loss=0.0029, val_loss=0.00366] Epoch 19:  86%|████████▌ | 24/28 [00:00<00:00, 146.22it/s, train_loss=0.0029, val_loss=0.00366]Epoch 19:  86%|████████▌ | 24/28 [00:00<00:00, 144.67it/s, train_loss=0.00277, val_loss=0.00366]Epoch 19:  89%|████████▉ | 25/28 [00:00<00:00, 147.01it/s, train_loss=0.00277, val_loss=0.00366]Epoch 19:  89%|████████▉ | 25/28 [00:00<00:00, 145.38it/s, train_loss=0.00274, val_loss=0.00366]Epoch 19:  93%|█████████▎| 26/28 [00:00<00:00, 147.18it/s, train_loss=0.00274, val_loss=0.00366]Epoch 19:  93%|█████████▎| 26/28 [00:00<00:00, 145.69it/s, train_loss=0.00311, val_loss=0.00366]Epoch 19:  96%|█████████▋| 27/28 [00:00<00:00, 147.26it/s, train_loss=0.00311, val_loss=0.00366]Epoch 19:  96%|█████████▋| 27/28 [00:00<00:00, 145.71it/s, train_loss=0.00315, val_loss=0.00366]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 147.55it/s, train_loss=0.00315, val_loss=0.00366]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 146.22it/s, train_loss=0.00231, val_loss=0.00366]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 180.39it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 210.49it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 212.31it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 222.80it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 227.70it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 233.21it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 229.80it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 227.01it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 229.28it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 231.35it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 233.25it/s][A
                                                                         [AEpoch 19: 100%|██████████| 28/28 [00:00<00:00, 113.86it/s, train_loss=0.00231, val_loss=0.00362]Epoch 19: 100%|██████████| 28/28 [00:00<00:00, 113.41it/s, train_loss=0.00231, val_loss=0.00362]Epoch 19:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.00362]          Epoch 20:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00231, val_loss=0.00362]Epoch 20:   4%|▎         | 1/28 [00:00<00:00, 148.71it/s, train_loss=0.00231, val_loss=0.00362]Epoch 20:   4%|▎         | 1/28 [00:00<00:00, 118.95it/s, train_loss=0.00286, val_loss=0.00362]Epoch 20:   7%|▋         | 2/28 [00:00<00:00, 148.97it/s, train_loss=0.00286, val_loss=0.00362]Epoch 20:   7%|▋         | 2/28 [00:00<00:00, 131.96it/s, train_loss=0.00376, val_loss=0.00362]Epoch 20:  11%|█         | 3/28 [00:00<00:00, 148.66it/s, train_loss=0.00376, val_loss=0.00362]Epoch 20:  11%|█         | 3/28 [00:00<00:00, 134.33it/s, train_loss=0.00264, val_loss=0.00362]Epoch 20:  14%|█▍        | 4/28 [00:00<00:00, 146.92it/s, train_loss=0.00264, val_loss=0.00362]Epoch 20:  14%|█▍        | 4/28 [00:00<00:00, 138.27it/s, train_loss=0.00255, val_loss=0.00362]Epoch 20:  18%|█▊        | 5/28 [00:00<00:00, 147.84it/s, train_loss=0.00255, val_loss=0.00362]Epoch 20:  18%|█▊        | 5/28 [00:00<00:00, 137.70it/s, train_loss=0.00278, val_loss=0.00362]Epoch 20:  21%|██▏       | 6/28 [00:00<00:00, 145.41it/s, train_loss=0.00278, val_loss=0.00362]Epoch 20:  21%|██▏       | 6/28 [00:00<00:00, 139.25it/s, train_loss=0.00289, val_loss=0.00362]Epoch 20:  25%|██▌       | 7/28 [00:00<00:00, 147.20it/s, train_loss=0.00289, val_loss=0.00362]Epoch 20:  25%|██▌       | 7/28 [00:00<00:00, 138.94it/s, train_loss=0.00274, val_loss=0.00362]Epoch 20:  29%|██▊       | 8/28 [00:00<00:00, 145.50it/s, train_loss=0.00274, val_loss=0.00362]Epoch 20:  29%|██▊       | 8/28 [00:00<00:00, 141.10it/s, train_loss=0.00294, val_loss=0.00362]Epoch 20:  32%|███▏      | 9/28 [00:00<00:00, 146.22it/s, train_loss=0.00294, val_loss=0.00362]Epoch 20:  32%|███▏      | 9/28 [00:00<00:00, 140.27it/s, train_loss=0.00342, val_loss=0.00362]Epoch 20:  36%|███▌      | 10/28 [00:00<00:00, 144.85it/s, train_loss=0.00342, val_loss=0.00362]Epoch 20:  36%|███▌      | 10/28 [00:00<00:00, 141.29it/s, train_loss=0.00361, val_loss=0.00362]Epoch 20:  39%|███▉      | 11/28 [00:00<00:00, 146.26it/s, train_loss=0.00361, val_loss=0.00362]Epoch 20:  39%|███▉      | 11/28 [00:00<00:00, 141.09it/s, train_loss=0.00258, val_loss=0.00362]Epoch 20:  43%|████▎     | 12/28 [00:00<00:00, 144.47it/s, train_loss=0.00258, val_loss=0.00362]Epoch 20:  43%|████▎     | 12/28 [00:00<00:00, 141.59it/s, train_loss=0.00314, val_loss=0.00362]Epoch 20:  46%|████▋     | 13/28 [00:00<00:00, 144.60it/s, train_loss=0.00314, val_loss=0.00362]Epoch 20:  46%|████▋     | 13/28 [00:00<00:00, 141.51it/s, train_loss=0.00358, val_loss=0.00362]Epoch 20:  50%|█████     | 14/28 [00:00<00:00, 144.46it/s, train_loss=0.00358, val_loss=0.00362]Epoch 20:  50%|█████     | 14/28 [00:00<00:00, 141.96it/s, train_loss=0.003, val_loss=0.00362]  Epoch 20:  54%|█████▎    | 15/28 [00:00<00:00, 145.43it/s, train_loss=0.003, val_loss=0.00362]Epoch 20:  54%|█████▎    | 15/28 [00:00<00:00, 141.62it/s, train_loss=0.00267, val_loss=0.00362]Epoch 20:  57%|█████▋    | 16/28 [00:00<00:00, 144.37it/s, train_loss=0.00267, val_loss=0.00362]Epoch 20:  57%|█████▋    | 16/28 [00:00<00:00, 142.23it/s, train_loss=0.00299, val_loss=0.00362]Epoch 20:  61%|██████    | 17/28 [00:00<00:00, 144.96it/s, train_loss=0.00299, val_loss=0.00362]Epoch 20:  61%|██████    | 17/28 [00:00<00:00, 141.84it/s, train_loss=0.00298, val_loss=0.00362]Epoch 20:  64%|██████▍   | 18/28 [00:00<00:00, 144.49it/s, train_loss=0.00298, val_loss=0.00362]Epoch 20:  64%|██████▍   | 18/28 [00:00<00:00, 142.43it/s, train_loss=0.00284, val_loss=0.00362]Epoch 20:  68%|██████▊   | 19/28 [00:00<00:00, 144.74it/s, train_loss=0.00284, val_loss=0.00362]Epoch 20:  68%|██████▊   | 19/28 [00:00<00:00, 142.02it/s, train_loss=0.00331, val_loss=0.00362]Epoch 20:  71%|███████▏  | 20/28 [00:00<00:00, 144.25it/s, train_loss=0.00331, val_loss=0.00362]Epoch 20:  71%|███████▏  | 20/28 [00:00<00:00, 142.46it/s, train_loss=0.00322, val_loss=0.00362]Epoch 20:  75%|███████▌  | 21/28 [00:00<00:00, 144.61it/s, train_loss=0.00322, val_loss=0.00362]Epoch 20:  75%|███████▌  | 21/28 [00:00<00:00, 142.09it/s, train_loss=0.00252, val_loss=0.00362]Epoch 20:  79%|███████▊  | 22/28 [00:00<00:00, 144.08it/s, train_loss=0.00252, val_loss=0.00362]Epoch 20:  79%|███████▊  | 22/28 [00:00<00:00, 142.50it/s, train_loss=0.00279, val_loss=0.00362]Epoch 20:  82%|████████▏ | 23/28 [00:00<00:00, 144.41it/s, train_loss=0.00279, val_loss=0.00362]Epoch 20:  82%|████████▏ | 23/28 [00:00<00:00, 142.34it/s, train_loss=0.00305, val_loss=0.00362]Epoch 20:  86%|████████▌ | 24/28 [00:00<00:00, 143.92it/s, train_loss=0.00305, val_loss=0.00362]Epoch 20:  86%|████████▌ | 24/28 [00:00<00:00, 142.39it/s, train_loss=0.00318, val_loss=0.00362]Epoch 20:  89%|████████▉ | 25/28 [00:00<00:00, 143.82it/s, train_loss=0.00318, val_loss=0.00362]Epoch 20:  89%|████████▉ | 25/28 [00:00<00:00, 142.47it/s, train_loss=0.00308, val_loss=0.00362]Epoch 20:  93%|█████████▎| 26/28 [00:00<00:00, 144.33it/s, train_loss=0.00308, val_loss=0.00362]Epoch 20:  93%|█████████▎| 26/28 [00:00<00:00, 143.03it/s, train_loss=0.00267, val_loss=0.00362]Epoch 20:  96%|█████████▋| 27/28 [00:00<00:00, 145.20it/s, train_loss=0.00267, val_loss=0.00362]Epoch 20:  96%|█████████▋| 27/28 [00:00<00:00, 143.68it/s, train_loss=0.00285, val_loss=0.00362]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 145.32it/s, train_loss=0.00285, val_loss=0.00362]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 144.10it/s, train_loss=0.00298, val_loss=0.00362]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 210.04it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 241.12it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 250.29it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 256.84it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 261.55it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 261.82it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 263.15it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 261.03it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 261.28it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 260.11it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 260.80it/s][A
                                                                         [AEpoch 20: 100%|██████████| 28/28 [00:00<00:00, 115.35it/s, train_loss=0.00298, val_loss=0.00351]Epoch 20: 100%|██████████| 28/28 [00:00<00:00, 114.90it/s, train_loss=0.00298, val_loss=0.00351]Epoch 20:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00351]          Epoch 21:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00298, val_loss=0.00351]Epoch 21:   4%|▎         | 1/28 [00:00<00:00, 164.13it/s, train_loss=0.00298, val_loss=0.00351]Epoch 21:   4%|▎         | 1/28 [00:00<00:00, 112.60it/s, train_loss=0.00302, val_loss=0.00351]Epoch 21:   7%|▋         | 2/28 [00:00<00:00, 143.15it/s, train_loss=0.00302, val_loss=0.00351]Epoch 21:   7%|▋         | 2/28 [00:00<00:00, 127.26it/s, train_loss=0.00329, val_loss=0.00351]Epoch 21:  11%|█         | 3/28 [00:00<00:00, 143.40it/s, train_loss=0.00329, val_loss=0.00351]Epoch 21:  11%|█         | 3/28 [00:00<00:00, 131.95it/s, train_loss=0.00269, val_loss=0.00351]Epoch 21:  14%|█▍        | 4/28 [00:00<00:00, 144.33it/s, train_loss=0.00269, val_loss=0.00351]Epoch 21:  14%|█▍        | 4/28 [00:00<00:00, 135.93it/s, train_loss=0.00323, val_loss=0.00351]Epoch 21:  18%|█▊        | 5/28 [00:00<00:00, 145.03it/s, train_loss=0.00323, val_loss=0.00351]Epoch 21:  18%|█▊        | 5/28 [00:00<00:00, 135.73it/s, train_loss=0.00287, val_loss=0.00351]Epoch 21:  21%|██▏       | 6/28 [00:00<00:00, 143.25it/s, train_loss=0.00287, val_loss=0.00351]Epoch 21:  21%|██▏       | 6/28 [00:00<00:00, 137.39it/s, train_loss=0.00285, val_loss=0.00351]Epoch 21:  25%|██▌       | 7/28 [00:00<00:00, 143.91it/s, train_loss=0.00285, val_loss=0.00351]Epoch 21:  25%|██▌       | 7/28 [00:00<00:00, 137.94it/s, train_loss=0.00278, val_loss=0.00351]Epoch 21:  29%|██▊       | 8/28 [00:00<00:00, 143.29it/s, train_loss=0.00278, val_loss=0.00351]Epoch 21:  29%|██▊       | 8/28 [00:00<00:00, 139.17it/s, train_loss=0.00356, val_loss=0.00351]Epoch 21:  32%|███▏      | 9/28 [00:00<00:00, 144.91it/s, train_loss=0.00356, val_loss=0.00351]Epoch 21:  32%|███▏      | 9/28 [00:00<00:00, 139.79it/s, train_loss=0.00275, val_loss=0.00351]Epoch 21:  36%|███▌      | 10/28 [00:00<00:00, 144.71it/s, train_loss=0.00275, val_loss=0.00351]Epoch 21:  36%|███▌      | 10/28 [00:00<00:00, 138.24it/s, train_loss=0.00283, val_loss=0.00351]Epoch 21:  39%|███▉      | 11/28 [00:00<00:00, 132.03it/s, train_loss=0.00283, val_loss=0.00351]Epoch 21:  39%|███▉      | 11/28 [00:00<00:00, 122.62it/s, train_loss=0.00323, val_loss=0.00351]Epoch 21:  43%|████▎     | 12/28 [00:00<00:00, 127.84it/s, train_loss=0.00323, val_loss=0.00351]Epoch 21:  43%|████▎     | 12/28 [00:00<00:00, 125.59it/s, train_loss=0.00248, val_loss=0.00351]Epoch 21:  46%|████▋     | 13/28 [00:00<00:00, 107.02it/s, train_loss=0.00248, val_loss=0.00351]Epoch 21:  46%|████▋     | 13/28 [00:00<00:00, 97.66it/s, train_loss=0.003, val_loss=0.00351]   Epoch 21:  50%|█████     | 14/28 [00:00<00:00, 94.26it/s, train_loss=0.003, val_loss=0.00351]Epoch 21:  50%|█████     | 14/28 [00:00<00:00, 93.21it/s, train_loss=0.00246, val_loss=0.00351]Epoch 21:  54%|█████▎    | 15/28 [00:00<00:00, 96.47it/s, train_loss=0.00246, val_loss=0.00351]Epoch 21:  54%|█████▎    | 15/28 [00:00<00:00, 95.40it/s, train_loss=0.00247, val_loss=0.00351]Epoch 21:  57%|█████▋    | 16/28 [00:00<00:00, 98.88it/s, train_loss=0.00247, val_loss=0.00351]Epoch 21:  57%|█████▋    | 16/28 [00:00<00:00, 97.76it/s, train_loss=0.00364, val_loss=0.00351]Epoch 21:  61%|██████    | 17/28 [00:00<00:00, 101.19it/s, train_loss=0.00364, val_loss=0.00351]Epoch 21:  61%|██████    | 17/28 [00:00<00:00, 98.81it/s, train_loss=0.0035, val_loss=0.00351]  Epoch 21:  64%|██████▍   | 18/28 [00:00<00:00, 101.84it/s, train_loss=0.0035, val_loss=0.00351]Epoch 21:  64%|██████▍   | 18/28 [00:00<00:00, 100.79it/s, train_loss=0.0028, val_loss=0.00351]Epoch 21:  68%|██████▊   | 19/28 [00:00<00:00, 104.03it/s, train_loss=0.0028, val_loss=0.00351]Epoch 21:  68%|██████▊   | 19/28 [00:00<00:00, 101.71it/s, train_loss=0.00317, val_loss=0.00351]Epoch 21:  71%|███████▏  | 20/28 [00:00<00:00, 104.05it/s, train_loss=0.00317, val_loss=0.00351]Epoch 21:  71%|███████▏  | 20/28 [00:00<00:00, 103.32it/s, train_loss=0.00308, val_loss=0.00351]Epoch 21:  75%|███████▌  | 21/28 [00:00<00:00, 104.79it/s, train_loss=0.00308, val_loss=0.00351]Epoch 21:  75%|███████▌  | 21/28 [00:00<00:00, 104.06it/s, train_loss=0.00221, val_loss=0.00351]Epoch 21:  79%|███████▊  | 22/28 [00:00<00:00, 106.41it/s, train_loss=0.00221, val_loss=0.00351]Epoch 21:  79%|███████▊  | 22/28 [00:00<00:00, 105.55it/s, train_loss=0.00288, val_loss=0.00351]Epoch 21:  82%|████████▏ | 23/28 [00:00<00:00, 108.06it/s, train_loss=0.00288, val_loss=0.00351]Epoch 21:  82%|████████▏ | 23/28 [00:00<00:00, 106.06it/s, train_loss=0.00229, val_loss=0.00351]Epoch 21:  86%|████████▌ | 24/28 [00:00<00:00, 107.86it/s, train_loss=0.00229, val_loss=0.00351]Epoch 21:  86%|████████▌ | 24/28 [00:00<00:00, 107.09it/s, train_loss=0.00306, val_loss=0.00351]Epoch 21:  89%|████████▉ | 25/28 [00:00<00:00, 109.16it/s, train_loss=0.00306, val_loss=0.00351]Epoch 21:  89%|████████▉ | 25/28 [00:00<00:00, 107.76it/s, train_loss=0.00292, val_loss=0.00351]Epoch 21:  93%|█████████▎| 26/28 [00:00<00:00, 109.69it/s, train_loss=0.00292, val_loss=0.00351]Epoch 21:  93%|█████████▎| 26/28 [00:00<00:00, 108.93it/s, train_loss=0.00269, val_loss=0.00351]Epoch 21:  96%|█████████▋| 27/28 [00:00<00:00, 111.07it/s, train_loss=0.00269, val_loss=0.00351]Epoch 21:  96%|█████████▋| 27/28 [00:00<00:00, 109.38it/s, train_loss=0.0029, val_loss=0.00351] Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 111.06it/s, train_loss=0.0029, val_loss=0.00351]Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 110.45it/s, train_loss=0.00363, val_loss=0.00351]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 228.87it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 263.82it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 277.61it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 280.30it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 285.08it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 288.16it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 289.26it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 286.72it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 285.07it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 284.11it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 281.80it/s][A
                                                                         [AEpoch 21: 100%|██████████| 28/28 [00:00<00:00, 93.82it/s, train_loss=0.00363, val_loss=0.00349] Epoch 21: 100%|██████████| 28/28 [00:00<00:00, 93.53it/s, train_loss=0.00363, val_loss=0.00349]Epoch 21:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00363, val_loss=0.00349]         Epoch 22:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00363, val_loss=0.00349]Epoch 22:   4%|▎         | 1/28 [00:00<00:00, 166.41it/s, train_loss=0.00363, val_loss=0.00349]Epoch 22:   4%|▎         | 1/28 [00:00<00:00, 132.66it/s, train_loss=0.0027, val_loss=0.00349] Epoch 22:   7%|▋         | 2/28 [00:00<00:00, 163.62it/s, train_loss=0.0027, val_loss=0.00349]Epoch 22:   7%|▋         | 2/28 [00:00<00:00, 124.57it/s, train_loss=0.0028, val_loss=0.00349]Epoch 22:  11%|█         | 3/28 [00:00<00:00, 141.63it/s, train_loss=0.0028, val_loss=0.00349]Epoch 22:  11%|█         | 3/28 [00:00<00:00, 131.98it/s, train_loss=0.0032, val_loss=0.00349]Epoch 22:  14%|█▍        | 4/28 [00:00<00:00, 145.87it/s, train_loss=0.0032, val_loss=0.00349]Epoch 22:  14%|█▍        | 4/28 [00:00<00:00, 137.87it/s, train_loss=0.0029, val_loss=0.00349]Epoch 22:  18%|█▊        | 5/28 [00:00<00:00, 147.49it/s, train_loss=0.0029, val_loss=0.00349]Epoch 22:  18%|█▊        | 5/28 [00:00<00:00, 133.39it/s, train_loss=0.00263, val_loss=0.00349]Epoch 22:  21%|██▏       | 6/28 [00:00<00:00, 141.12it/s, train_loss=0.00263, val_loss=0.00349]Epoch 22:  21%|██▏       | 6/28 [00:00<00:00, 135.38it/s, train_loss=0.00282, val_loss=0.00349]Epoch 22:  25%|██▌       | 7/28 [00:00<00:00, 142.74it/s, train_loss=0.00282, val_loss=0.00349]Epoch 22:  25%|██▌       | 7/28 [00:00<00:00, 133.79it/s, train_loss=0.00348, val_loss=0.00349]Epoch 22:  29%|██▊       | 8/28 [00:00<00:00, 139.18it/s, train_loss=0.00348, val_loss=0.00349]Epoch 22:  29%|██▊       | 8/28 [00:00<00:00, 135.18it/s, train_loss=0.00352, val_loss=0.00349]Epoch 22:  32%|███▏      | 9/28 [00:00<00:00, 140.19it/s, train_loss=0.00352, val_loss=0.00349]Epoch 22:  32%|███▏      | 9/28 [00:00<00:00, 134.16it/s, train_loss=0.00233, val_loss=0.00349]Epoch 22:  36%|███▌      | 10/28 [00:00<00:00, 138.35it/s, train_loss=0.00233, val_loss=0.00349]Epoch 22:  36%|███▌      | 10/28 [00:00<00:00, 135.36it/s, train_loss=0.00292, val_loss=0.00349]Epoch 22:  39%|███▉      | 11/28 [00:00<00:00, 139.36it/s, train_loss=0.00292, val_loss=0.00349]Epoch 22:  39%|███▉      | 11/28 [00:00<00:00, 134.07it/s, train_loss=0.00284, val_loss=0.00349]Epoch 22:  43%|████▎     | 12/28 [00:00<00:00, 138.18it/s, train_loss=0.00284, val_loss=0.00349]Epoch 22:  43%|████▎     | 12/28 [00:00<00:00, 135.55it/s, train_loss=0.00304, val_loss=0.00349]Epoch 22:  46%|████▋     | 13/28 [00:00<00:00, 140.02it/s, train_loss=0.00304, val_loss=0.00349]Epoch 22:  46%|████▋     | 13/28 [00:00<00:00, 134.30it/s, train_loss=0.00283, val_loss=0.00349]Epoch 22:  50%|█████     | 14/28 [00:00<00:00, 137.35it/s, train_loss=0.00283, val_loss=0.00349]Epoch 22:  50%|█████     | 14/28 [00:00<00:00, 135.13it/s, train_loss=0.00279, val_loss=0.00349]Epoch 22:  54%|█████▎    | 15/28 [00:00<00:00, 138.51it/s, train_loss=0.00279, val_loss=0.00349]Epoch 22:  54%|█████▎    | 15/28 [00:00<00:00, 136.49it/s, train_loss=0.00293, val_loss=0.00349]Epoch 22:  57%|█████▋    | 16/28 [00:00<00:00, 139.56it/s, train_loss=0.00293, val_loss=0.00349]Epoch 22:  57%|█████▋    | 16/28 [00:00<00:00, 135.93it/s, train_loss=0.00274, val_loss=0.00349]Epoch 22:  61%|██████    | 17/28 [00:00<00:00, 138.56it/s, train_loss=0.00274, val_loss=0.00349]Epoch 22:  61%|██████    | 17/28 [00:00<00:00, 136.69it/s, train_loss=0.00245, val_loss=0.00349]Epoch 22:  64%|██████▍   | 18/28 [00:00<00:00, 139.47it/s, train_loss=0.00245, val_loss=0.00349]Epoch 22:  64%|██████▍   | 18/28 [00:00<00:00, 135.82it/s, train_loss=0.00287, val_loss=0.00349]Epoch 22:  68%|██████▊   | 19/28 [00:00<00:00, 137.86it/s, train_loss=0.00287, val_loss=0.00349]Epoch 22:  68%|██████▊   | 19/28 [00:00<00:00, 136.29it/s, train_loss=0.00288, val_loss=0.00349]Epoch 22:  71%|███████▏  | 20/28 [00:00<00:00, 138.74it/s, train_loss=0.00288, val_loss=0.00349]Epoch 22:  71%|███████▏  | 20/28 [00:00<00:00, 135.42it/s, train_loss=0.00288, val_loss=0.00349]Epoch 22:  75%|███████▌  | 21/28 [00:00<00:00, 137.45it/s, train_loss=0.00288, val_loss=0.00349]Epoch 22:  75%|███████▌  | 21/28 [00:00<00:00, 135.95it/s, train_loss=0.00325, val_loss=0.00349]Epoch 22:  79%|███████▊  | 22/28 [00:00<00:00, 138.10it/s, train_loss=0.00325, val_loss=0.00349]Epoch 22:  79%|███████▊  | 22/28 [00:00<00:00, 135.12it/s, train_loss=0.00264, val_loss=0.00349]Epoch 22:  82%|████████▏ | 23/28 [00:00<00:00, 136.85it/s, train_loss=0.00264, val_loss=0.00349]Epoch 22:  82%|████████▏ | 23/28 [00:00<00:00, 135.58it/s, train_loss=0.00262, val_loss=0.00349]Epoch 22:  86%|████████▌ | 24/28 [00:00<00:00, 137.07it/s, train_loss=0.00262, val_loss=0.00349]Epoch 22:  86%|████████▌ | 24/28 [00:00<00:00, 134.79it/s, train_loss=0.00285, val_loss=0.00349]Epoch 22:  89%|████████▉ | 25/28 [00:00<00:00, 136.21it/s, train_loss=0.00285, val_loss=0.00349]Epoch 22:  89%|████████▉ | 25/28 [00:00<00:00, 135.14it/s, train_loss=0.00267, val_loss=0.00349]Epoch 22:  93%|█████████▎| 26/28 [00:00<00:00, 136.58it/s, train_loss=0.00267, val_loss=0.00349]Epoch 22:  93%|█████████▎| 26/28 [00:00<00:00, 134.35it/s, train_loss=0.00333, val_loss=0.00349]Epoch 22:  96%|█████████▋| 27/28 [00:00<00:00, 135.84it/s, train_loss=0.00333, val_loss=0.00349]Epoch 22:  96%|█████████▋| 27/28 [00:00<00:00, 134.70it/s, train_loss=0.00223, val_loss=0.00349]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 136.35it/s, train_loss=0.00223, val_loss=0.00349]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 134.64it/s, train_loss=0.00248, val_loss=0.00349]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 167.43it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 222.43it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 249.89it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 259.14it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 268.47it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 275.62it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 281.29it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 282.48it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 284.85it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 286.69it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 288.78it/s][A
                                                                         [AEpoch 22: 100%|██████████| 28/28 [00:00<00:00, 110.58it/s, train_loss=0.00248, val_loss=0.00345]Epoch 22: 100%|██████████| 28/28 [00:00<00:00, 110.25it/s, train_loss=0.00248, val_loss=0.00345]Epoch 22:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00248, val_loss=0.00345]          Epoch 23:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00248, val_loss=0.00345]Epoch 23:   4%|▎         | 1/28 [00:00<00:00, 159.50it/s, train_loss=0.00248, val_loss=0.00345]Epoch 23:   4%|▎         | 1/28 [00:00<00:00, 129.03it/s, train_loss=0.00261, val_loss=0.00345]Epoch 23:   7%|▋         | 2/28 [00:00<00:00, 157.35it/s, train_loss=0.00261, val_loss=0.00345]Epoch 23:   7%|▋         | 2/28 [00:00<00:00, 139.55it/s, train_loss=0.00265, val_loss=0.00345]Epoch 23:  11%|█         | 3/28 [00:00<00:00, 157.56it/s, train_loss=0.00265, val_loss=0.00345]Epoch 23:  11%|█         | 3/28 [00:00<00:00, 133.60it/s, train_loss=0.00319, val_loss=0.00345]Epoch 23:  14%|█▍        | 4/28 [00:00<00:00, 144.02it/s, train_loss=0.00319, val_loss=0.00345]Epoch 23:  14%|█▍        | 4/28 [00:00<00:00, 136.57it/s, train_loss=0.00269, val_loss=0.00345]Epoch 23:  18%|█▊        | 5/28 [00:00<00:00, 146.17it/s, train_loss=0.00269, val_loss=0.00345]Epoch 23:  18%|█▊        | 5/28 [00:00<00:00, 132.95it/s, train_loss=0.00275, val_loss=0.00345]Epoch 23:  21%|██▏       | 6/28 [00:00<00:00, 139.89it/s, train_loss=0.00275, val_loss=0.00345]Epoch 23:  21%|██▏       | 6/28 [00:00<00:00, 135.02it/s, train_loss=0.00287, val_loss=0.00345]Epoch 23:  25%|██▌       | 7/28 [00:00<00:00, 141.53it/s, train_loss=0.00287, val_loss=0.00345]Epoch 23:  25%|██▌       | 7/28 [00:00<00:00, 132.99it/s, train_loss=0.00255, val_loss=0.00345]Epoch 23:  29%|██▊       | 8/28 [00:00<00:00, 137.86it/s, train_loss=0.00255, val_loss=0.00345]Epoch 23:  29%|██▊       | 8/28 [00:00<00:00, 134.39it/s, train_loss=0.00311, val_loss=0.00345]Epoch 23:  32%|███▏      | 9/28 [00:00<00:00, 138.65it/s, train_loss=0.00311, val_loss=0.00345]Epoch 23:  32%|███▏      | 9/28 [00:00<00:00, 132.40it/s, train_loss=0.0023, val_loss=0.00345] Epoch 23:  36%|███▌      | 10/28 [00:00<00:00, 136.37it/s, train_loss=0.0023, val_loss=0.00345]Epoch 23:  36%|███▌      | 10/28 [00:00<00:00, 133.61it/s, train_loss=0.00284, val_loss=0.00345]Epoch 23:  39%|███▉      | 11/28 [00:00<00:00, 138.09it/s, train_loss=0.00284, val_loss=0.00345]Epoch 23:  39%|███▉      | 11/28 [00:00<00:00, 132.06it/s, train_loss=0.00335, val_loss=0.00345]Epoch 23:  43%|████▎     | 12/28 [00:00<00:00, 135.59it/s, train_loss=0.00335, val_loss=0.00345]Epoch 23:  43%|████▎     | 12/28 [00:00<00:00, 133.13it/s, train_loss=0.00255, val_loss=0.00345]Epoch 23:  46%|████▋     | 13/28 [00:00<00:00, 136.39it/s, train_loss=0.00255, val_loss=0.00345]Epoch 23:  46%|████▋     | 13/28 [00:00<00:00, 131.79it/s, train_loss=0.00237, val_loss=0.00345]Epoch 23:  50%|█████     | 14/28 [00:00<00:00, 134.84it/s, train_loss=0.00237, val_loss=0.00345]Epoch 23:  50%|█████     | 14/28 [00:00<00:00, 132.75it/s, train_loss=0.003, val_loss=0.00345]  Epoch 23:  54%|█████▎    | 15/28 [00:00<00:00, 136.39it/s, train_loss=0.003, val_loss=0.00345]Epoch 23:  54%|█████▎    | 15/28 [00:00<00:00, 132.05it/s, train_loss=0.00316, val_loss=0.00345]Epoch 23:  57%|█████▋    | 16/28 [00:00<00:00, 134.83it/s, train_loss=0.00316, val_loss=0.00345]Epoch 23:  57%|█████▋    | 16/28 [00:00<00:00, 133.11it/s, train_loss=0.00324, val_loss=0.00345]Epoch 23:  61%|██████    | 17/28 [00:00<00:00, 135.92it/s, train_loss=0.00324, val_loss=0.00345]Epoch 23:  61%|██████    | 17/28 [00:00<00:00, 131.83it/s, train_loss=0.00325, val_loss=0.00345]Epoch 23:  64%|██████▍   | 18/28 [00:00<00:00, 134.20it/s, train_loss=0.00325, val_loss=0.00345]Epoch 23:  64%|██████▍   | 18/28 [00:00<00:00, 132.61it/s, train_loss=0.00314, val_loss=0.00345]Epoch 23:  68%|██████▊   | 19/28 [00:00<00:00, 135.15it/s, train_loss=0.00314, val_loss=0.00345]Epoch 23:  68%|██████▊   | 19/28 [00:00<00:00, 131.77it/s, train_loss=0.00269, val_loss=0.00345]Epoch 23:  71%|███████▏  | 20/28 [00:00<00:00, 133.89it/s, train_loss=0.00269, val_loss=0.00345]Epoch 23:  71%|███████▏  | 20/28 [00:00<00:00, 132.44it/s, train_loss=0.00271, val_loss=0.00345]Epoch 23:  75%|███████▌  | 21/28 [00:00<00:00, 134.70it/s, train_loss=0.00271, val_loss=0.00345]Epoch 23:  75%|███████▌  | 21/28 [00:00<00:00, 131.88it/s, train_loss=0.0024, val_loss=0.00345] Epoch 23:  79%|███████▊  | 22/28 [00:00<00:00, 133.63it/s, train_loss=0.0024, val_loss=0.00345]Epoch 23:  79%|███████▊  | 22/28 [00:00<00:00, 132.34it/s, train_loss=0.00257, val_loss=0.00345]Epoch 23:  82%|████████▏ | 23/28 [00:00<00:00, 133.96it/s, train_loss=0.00257, val_loss=0.00345]Epoch 23:  82%|████████▏ | 23/28 [00:00<00:00, 131.80it/s, train_loss=0.00265, val_loss=0.00345]Epoch 23:  86%|████████▌ | 24/28 [00:00<00:00, 133.34it/s, train_loss=0.00265, val_loss=0.00345]Epoch 23:  86%|████████▌ | 24/28 [00:00<00:00, 132.29it/s, train_loss=0.00273, val_loss=0.00345]Epoch 23:  89%|████████▉ | 25/28 [00:00<00:00, 134.20it/s, train_loss=0.00273, val_loss=0.00345]Epoch 23:  89%|████████▉ | 25/28 [00:00<00:00, 131.66it/s, train_loss=0.00319, val_loss=0.00345]Epoch 23:  93%|█████████▎| 26/28 [00:00<00:00, 133.16it/s, train_loss=0.00319, val_loss=0.00345]Epoch 23:  93%|█████████▎| 26/28 [00:00<00:00, 132.15it/s, train_loss=0.0026, val_loss=0.00345] Epoch 23:  96%|█████████▋| 27/28 [00:00<00:00, 133.83it/s, train_loss=0.0026, val_loss=0.00345]Epoch 23:  96%|█████████▋| 27/28 [00:00<00:00, 131.74it/s, train_loss=0.00266, val_loss=0.00345]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 133.35it/s, train_loss=0.00266, val_loss=0.00345]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 132.50it/s, train_loss=0.00296, val_loss=0.00345]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 155.52it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 181.85it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 196.68it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 197.66it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 203.09it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 205.39it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 208.32it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 214.12it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 222.64it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 230.21it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 236.44it/s][A
                                                                         [AEpoch 23: 100%|██████████| 28/28 [00:00<00:00, 105.42it/s, train_loss=0.00296, val_loss=0.00332]Epoch 23: 100%|██████████| 28/28 [00:00<00:00, 105.15it/s, train_loss=0.00296, val_loss=0.00332]Epoch 23:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00296, val_loss=0.00332]          Epoch 24:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00296, val_loss=0.00332]Epoch 24:   4%|▎         | 1/28 [00:00<00:00, 164.26it/s, train_loss=0.00296, val_loss=0.00332]Epoch 24:   4%|▎         | 1/28 [00:00<00:00, 127.88it/s, train_loss=0.00246, val_loss=0.00332]Epoch 24:   7%|▋         | 2/28 [00:00<00:00, 156.03it/s, train_loss=0.00246, val_loss=0.00332]Epoch 24:   7%|▋         | 2/28 [00:00<00:00, 138.45it/s, train_loss=0.00274, val_loss=0.00332]Epoch 24:  11%|█         | 3/28 [00:00<00:00, 157.08it/s, train_loss=0.00274, val_loss=0.00332]Epoch 24:  11%|█         | 3/28 [00:00<00:00, 131.37it/s, train_loss=0.00259, val_loss=0.00332]Epoch 24:  14%|█▍        | 4/28 [00:00<00:00, 142.47it/s, train_loss=0.00259, val_loss=0.00332]Epoch 24:  14%|█▍        | 4/28 [00:00<00:00, 134.94it/s, train_loss=0.00351, val_loss=0.00332]Epoch 24:  18%|█▊        | 5/28 [00:00<00:00, 144.58it/s, train_loss=0.00351, val_loss=0.00332]Epoch 24:  18%|█▊        | 5/28 [00:00<00:00, 132.10it/s, train_loss=0.00248, val_loss=0.00332]Epoch 24:  21%|██▏       | 6/28 [00:00<00:00, 139.06it/s, train_loss=0.00248, val_loss=0.00332]Epoch 24:  21%|██▏       | 6/28 [00:00<00:00, 134.19it/s, train_loss=0.00291, val_loss=0.00332]Epoch 24:  25%|██▌       | 7/28 [00:00<00:00, 141.11it/s, train_loss=0.00291, val_loss=0.00332]Epoch 24:  25%|██▌       | 7/28 [00:00<00:00, 132.19it/s, train_loss=0.00284, val_loss=0.00332]Epoch 24:  29%|██▊       | 8/28 [00:00<00:00, 137.22it/s, train_loss=0.00284, val_loss=0.00332]Epoch 24:  29%|██▊       | 8/28 [00:00<00:00, 133.81it/s, train_loss=0.00273, val_loss=0.00332]Epoch 24:  32%|███▏      | 9/28 [00:00<00:00, 138.98it/s, train_loss=0.00273, val_loss=0.00332]Epoch 24:  32%|███▏      | 9/28 [00:00<00:00, 132.37it/s, train_loss=0.00315, val_loss=0.00332]Epoch 24:  36%|███▌      | 10/28 [00:00<00:00, 136.40it/s, train_loss=0.00315, val_loss=0.00332]Epoch 24:  36%|███▌      | 10/28 [00:00<00:00, 133.60it/s, train_loss=0.00269, val_loss=0.00332]Epoch 24:  39%|███▉      | 11/28 [00:00<00:00, 137.84it/s, train_loss=0.00269, val_loss=0.00332]Epoch 24:  39%|███▉      | 11/28 [00:00<00:00, 132.40it/s, train_loss=0.00312, val_loss=0.00332]Epoch 24:  43%|████▎     | 12/28 [00:00<00:00, 135.84it/s, train_loss=0.00312, val_loss=0.00332]Epoch 24:  43%|████▎     | 12/28 [00:00<00:00, 133.46it/s, train_loss=0.00262, val_loss=0.00332]Epoch 24:  46%|████▋     | 13/28 [00:00<00:00, 136.97it/s, train_loss=0.00262, val_loss=0.00332]Epoch 24:  46%|████▋     | 13/28 [00:00<00:00, 132.48it/s, train_loss=0.00253, val_loss=0.00332]Epoch 24:  50%|█████     | 14/28 [00:00<00:00, 135.15it/s, train_loss=0.00253, val_loss=0.00332]Epoch 24:  50%|█████     | 14/28 [00:00<00:00, 133.25it/s, train_loss=0.00247, val_loss=0.00332]Epoch 24:  54%|█████▎    | 15/28 [00:00<00:00, 136.21it/s, train_loss=0.00247, val_loss=0.00332]Epoch 24:  54%|█████▎    | 15/28 [00:00<00:00, 132.33it/s, train_loss=0.00303, val_loss=0.00332]Epoch 24:  57%|█████▋    | 16/28 [00:00<00:00, 134.76it/s, train_loss=0.00303, val_loss=0.00332]Epoch 24:  57%|█████▋    | 16/28 [00:00<00:00, 133.06it/s, train_loss=0.00267, val_loss=0.00332]Epoch 24:  61%|██████    | 17/28 [00:00<00:00, 136.10it/s, train_loss=0.00267, val_loss=0.00332]Epoch 24:  61%|██████    | 17/28 [00:00<00:00, 132.20it/s, train_loss=0.00301, val_loss=0.00332]Epoch 24:  64%|██████▍   | 18/28 [00:00<00:00, 134.80it/s, train_loss=0.00301, val_loss=0.00332]Epoch 24:  64%|██████▍   | 18/28 [00:00<00:00, 133.14it/s, train_loss=0.00266, val_loss=0.00332]Epoch 24:  68%|██████▊   | 19/28 [00:00<00:00, 135.73it/s, train_loss=0.00266, val_loss=0.00332]Epoch 24:  68%|██████▊   | 19/28 [00:00<00:00, 132.31it/s, train_loss=0.00275, val_loss=0.00332]Epoch 24:  71%|███████▏  | 20/28 [00:00<00:00, 134.50it/s, train_loss=0.00275, val_loss=0.00332]Epoch 24:  71%|███████▏  | 20/28 [00:00<00:00, 133.08it/s, train_loss=0.00302, val_loss=0.00332]Epoch 24:  75%|███████▌  | 21/28 [00:00<00:00, 135.42it/s, train_loss=0.00302, val_loss=0.00332]Epoch 24:  75%|███████▌  | 21/28 [00:00<00:00, 132.27it/s, train_loss=0.00309, val_loss=0.00332]Epoch 24:  79%|███████▊  | 22/28 [00:00<00:00, 134.02it/s, train_loss=0.00309, val_loss=0.00332]Epoch 24:  79%|███████▊  | 22/28 [00:00<00:00, 132.82it/s, train_loss=0.00216, val_loss=0.00332]Epoch 24:  82%|████████▏ | 23/28 [00:00<00:00, 134.94it/s, train_loss=0.00216, val_loss=0.00332]Epoch 24:  82%|████████▏ | 23/28 [00:00<00:00, 133.69it/s, train_loss=0.00236, val_loss=0.00332]Epoch 24:  86%|████████▌ | 24/28 [00:00<00:00, 135.53it/s, train_loss=0.00236, val_loss=0.00332]Epoch 24:  86%|████████▌ | 24/28 [00:00<00:00, 134.09it/s, train_loss=0.00297, val_loss=0.00332]Epoch 24:  89%|████████▉ | 25/28 [00:00<00:00, 135.86it/s, train_loss=0.00297, val_loss=0.00332]Epoch 24:  89%|████████▉ | 25/28 [00:00<00:00, 134.60it/s, train_loss=0.0027, val_loss=0.00332] Epoch 24:  93%|█████████▎| 26/28 [00:00<00:00, 136.24it/s, train_loss=0.0027, val_loss=0.00332]Epoch 24:  93%|█████████▎| 26/28 [00:00<00:00, 133.43it/s, train_loss=0.00254, val_loss=0.00332]Epoch 24:  96%|█████████▋| 27/28 [00:00<00:00, 134.82it/s, train_loss=0.00254, val_loss=0.00332]Epoch 24:  96%|█████████▋| 27/28 [00:00<00:00, 133.84it/s, train_loss=0.00308, val_loss=0.00332]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 135.65it/s, train_loss=0.00308, val_loss=0.00332]Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 134.65it/s, train_loss=0.00313, val_loss=0.00332]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 157.98it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 188.70it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 204.95it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 211.01it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 216.68it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 218.89it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 221.48it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 223.80it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 224.63it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 225.98it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 226.45it/s][A
                                                                         [AEpoch 24: 100%|██████████| 28/28 [00:00<00:00, 105.66it/s, train_loss=0.00313, val_loss=0.0033] Epoch 24: 100%|██████████| 28/28 [00:00<00:00, 105.44it/s, train_loss=0.00313, val_loss=0.0033]Epoch 24:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00313, val_loss=0.0033]          Epoch 25:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00313, val_loss=0.0033]Epoch 25:   4%|▎         | 1/28 [00:00<00:00, 169.82it/s, train_loss=0.00313, val_loss=0.0033]Epoch 25:   4%|▎         | 1/28 [00:00<00:00, 134.14it/s, train_loss=0.00252, val_loss=0.0033]Epoch 25:   7%|▋         | 2/28 [00:00<00:00, 162.16it/s, train_loss=0.00252, val_loss=0.0033]Epoch 25:   7%|▋         | 2/28 [00:00<00:00, 123.52it/s, train_loss=0.00216, val_loss=0.0033]Epoch 25:  11%|█         | 3/28 [00:00<00:00, 140.88it/s, train_loss=0.00216, val_loss=0.0033]Epoch 25:  11%|█         | 3/28 [00:00<00:00, 130.95it/s, train_loss=0.00301, val_loss=0.0033]Epoch 25:  14%|█▍        | 4/28 [00:00<00:00, 144.60it/s, train_loss=0.00301, val_loss=0.0033]Epoch 25:  14%|█▍        | 4/28 [00:00<00:00, 136.55it/s, train_loss=0.0025, val_loss=0.0033] Epoch 25:  18%|█▊        | 5/28 [00:00<00:00, 145.51it/s, train_loss=0.0025, val_loss=0.0033]Epoch 25:  18%|█▊        | 5/28 [00:00<00:00, 135.45it/s, train_loss=0.00266, val_loss=0.0033]Epoch 25:  21%|██▏       | 6/28 [00:00<00:00, 143.17it/s, train_loss=0.00266, val_loss=0.0033]Epoch 25:  21%|██▏       | 6/28 [00:00<00:00, 137.71it/s, train_loss=0.00307, val_loss=0.0033]Epoch 25:  25%|██▌       | 7/28 [00:00<00:00, 144.85it/s, train_loss=0.00307, val_loss=0.0033]Epoch 25:  25%|██▌       | 7/28 [00:00<00:00, 135.11it/s, train_loss=0.00322, val_loss=0.0033]Epoch 25:  29%|██▊       | 8/28 [00:00<00:00, 140.13it/s, train_loss=0.00322, val_loss=0.0033]Epoch 25:  29%|██▊       | 8/28 [00:00<00:00, 136.48it/s, train_loss=0.00246, val_loss=0.0033]Epoch 25:  32%|███▏      | 9/28 [00:00<00:00, 141.55it/s, train_loss=0.00246, val_loss=0.0033]Epoch 25:  32%|███▏      | 9/28 [00:00<00:00, 134.05it/s, train_loss=0.00323, val_loss=0.0033]Epoch 25:  36%|███▌      | 10/28 [00:00<00:00, 137.80it/s, train_loss=0.00323, val_loss=0.0033]Epoch 25:  36%|███▌      | 10/28 [00:00<00:00, 135.13it/s, train_loss=0.00268, val_loss=0.0033]Epoch 25:  39%|███▉      | 11/28 [00:00<00:00, 139.38it/s, train_loss=0.00268, val_loss=0.0033]Epoch 25:  39%|███▉      | 11/28 [00:00<00:00, 133.46it/s, train_loss=0.00315, val_loss=0.0033]Epoch 25:  43%|████▎     | 12/28 [00:00<00:00, 136.77it/s, train_loss=0.00315, val_loss=0.0033]Epoch 25:  43%|████▎     | 12/28 [00:00<00:00, 134.45it/s, train_loss=0.00259, val_loss=0.0033]Epoch 25:  46%|████▋     | 13/28 [00:00<00:00, 137.97it/s, train_loss=0.00259, val_loss=0.0033]Epoch 25:  46%|████▋     | 13/28 [00:00<00:00, 133.47it/s, train_loss=0.00291, val_loss=0.0033]Epoch 25:  50%|█████     | 14/28 [00:00<00:00, 136.24it/s, train_loss=0.00291, val_loss=0.0033]Epoch 25:  50%|█████     | 14/28 [00:00<00:00, 134.19it/s, train_loss=0.00287, val_loss=0.0033]Epoch 25:  54%|█████▎    | 15/28 [00:00<00:00, 137.16it/s, train_loss=0.00287, val_loss=0.0033]Epoch 25:  54%|█████▎    | 15/28 [00:00<00:00, 133.06it/s, train_loss=0.00249, val_loss=0.0033]Epoch 25:  57%|█████▋    | 16/28 [00:00<00:00, 135.23it/s, train_loss=0.00249, val_loss=0.0033]Epoch 25:  57%|█████▋    | 16/28 [00:00<00:00, 133.24it/s, train_loss=0.00246, val_loss=0.0033]Epoch 25:  61%|██████    | 17/28 [00:00<00:00, 135.91it/s, train_loss=0.00246, val_loss=0.0033]Epoch 25:  61%|██████    | 17/28 [00:00<00:00, 132.75it/s, train_loss=0.00254, val_loss=0.0033]Epoch 25:  64%|██████▍   | 18/28 [00:00<00:00, 135.37it/s, train_loss=0.00254, val_loss=0.0033]Epoch 25:  64%|██████▍   | 18/28 [00:00<00:00, 133.28it/s, train_loss=0.00252, val_loss=0.0033]Epoch 25:  68%|██████▊   | 19/28 [00:00<00:00, 135.81it/s, train_loss=0.00252, val_loss=0.0033]Epoch 25:  68%|██████▊   | 19/28 [00:00<00:00, 132.80it/s, train_loss=0.0032, val_loss=0.0033] Epoch 25:  71%|███████▏  | 20/28 [00:00<00:00, 135.54it/s, train_loss=0.0032, val_loss=0.0033]Epoch 25:  71%|███████▏  | 20/28 [00:00<00:00, 133.88it/s, train_loss=0.00306, val_loss=0.0033]Epoch 25:  75%|███████▌  | 21/28 [00:00<00:00, 136.78it/s, train_loss=0.00306, val_loss=0.0033]Epoch 25:  75%|███████▌  | 21/28 [00:00<00:00, 133.15it/s, train_loss=0.00224, val_loss=0.0033]Epoch 25:  79%|███████▊  | 22/28 [00:00<00:00, 135.48it/s, train_loss=0.00224, val_loss=0.0033]Epoch 25:  79%|███████▊  | 22/28 [00:00<00:00, 133.86it/s, train_loss=0.00242, val_loss=0.0033]Epoch 25:  82%|████████▏ | 23/28 [00:00<00:00, 136.35it/s, train_loss=0.00242, val_loss=0.0033]Epoch 25:  82%|████████▏ | 23/28 [00:00<00:00, 133.09it/s, train_loss=0.00234, val_loss=0.0033]Epoch 25:  86%|████████▌ | 24/28 [00:00<00:00, 135.21it/s, train_loss=0.00234, val_loss=0.0033]Epoch 25:  86%|████████▌ | 24/28 [00:00<00:00, 133.81it/s, train_loss=0.00283, val_loss=0.0033]Epoch 25:  89%|████████▉ | 25/28 [00:00<00:00, 136.00it/s, train_loss=0.00283, val_loss=0.0033]Epoch 25:  89%|████████▉ | 25/28 [00:00<00:00, 133.03it/s, train_loss=0.00281, val_loss=0.0033]Epoch 25:  93%|█████████▎| 26/28 [00:00<00:00, 134.74it/s, train_loss=0.00281, val_loss=0.0033]Epoch 25:  93%|█████████▎| 26/28 [00:00<00:00, 133.41it/s, train_loss=0.00255, val_loss=0.0033]Epoch 25:  96%|█████████▋| 27/28 [00:00<00:00, 135.44it/s, train_loss=0.00255, val_loss=0.0033]Epoch 25:  96%|█████████▋| 27/28 [00:00<00:00, 132.95it/s, train_loss=0.00291, val_loss=0.0033]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 134.72it/s, train_loss=0.00291, val_loss=0.0033]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 133.60it/s, train_loss=0.00297, val_loss=0.0033]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 167.06it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 198.74it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 211.45it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 212.69it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 212.71it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 215.61it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 215.15it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 214.07it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 210.26it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 210.98it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 211.26it/s][A
                                                                         [AEpoch 25: 100%|██████████| 28/28 [00:00<00:00, 103.93it/s, train_loss=0.00297, val_loss=0.00332]Epoch 25: 100%|██████████| 28/28 [00:00<00:00, 103.56it/s, train_loss=0.00297, val_loss=0.00332]Epoch 25:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00332]          Epoch 26:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00332]Epoch 26:   4%|▎         | 1/28 [00:00<00:00, 134.88it/s, train_loss=0.00297, val_loss=0.00332]Epoch 26:   4%|▎         | 1/28 [00:00<00:00, 110.02it/s, train_loss=0.00223, val_loss=0.00332]Epoch 26:   7%|▋         | 2/28 [00:00<00:00, 133.27it/s, train_loss=0.00223, val_loss=0.00332]Epoch 26:   7%|▋         | 2/28 [00:00<00:00, 110.99it/s, train_loss=0.00283, val_loss=0.00332]Epoch 26:  11%|█         | 3/28 [00:00<00:00, 127.15it/s, train_loss=0.00283, val_loss=0.00332]Epoch 26:  11%|█         | 3/28 [00:00<00:00, 118.69it/s, train_loss=0.00289, val_loss=0.00332]Epoch 26:  14%|█▍        | 4/28 [00:00<00:00, 132.73it/s, train_loss=0.00289, val_loss=0.00332]Epoch 26:  14%|█▍        | 4/28 [00:00<00:00, 117.42it/s, train_loss=0.00321, val_loss=0.00332]Epoch 26:  18%|█▊        | 5/28 [00:00<00:00, 127.21it/s, train_loss=0.00321, val_loss=0.00332]Epoch 26:  18%|█▊        | 5/28 [00:00<00:00, 121.87it/s, train_loss=0.00304, val_loss=0.00332]Epoch 26:  21%|██▏       | 6/28 [00:00<00:00, 130.30it/s, train_loss=0.00304, val_loss=0.00332]Epoch 26:  21%|██▏       | 6/28 [00:00<00:00, 125.21it/s, train_loss=0.00266, val_loss=0.00332]Epoch 26:  25%|██▌       | 7/28 [00:00<00:00, 127.90it/s, train_loss=0.00266, val_loss=0.00332]Epoch 26:  25%|██▌       | 7/28 [00:00<00:00, 124.82it/s, train_loss=0.00214, val_loss=0.00332]Epoch 26:  29%|██▊       | 8/28 [00:00<00:00, 129.72it/s, train_loss=0.00214, val_loss=0.00332]Epoch 26:  29%|██▊       | 8/28 [00:00<00:00, 126.21it/s, train_loss=0.00264, val_loss=0.00332]Epoch 26:  32%|███▏      | 9/28 [00:00<00:00, 129.83it/s, train_loss=0.00264, val_loss=0.00332]Epoch 26:  32%|███▏      | 9/28 [00:00<00:00, 124.09it/s, train_loss=0.00283, val_loss=0.00332]Epoch 26:  36%|███▌      | 10/28 [00:00<00:00, 127.76it/s, train_loss=0.00283, val_loss=0.00332]Epoch 26:  36%|███▌      | 10/28 [00:00<00:00, 125.12it/s, train_loss=0.00262, val_loss=0.00332]Epoch 26:  39%|███▉      | 11/28 [00:00<00:00, 129.32it/s, train_loss=0.00262, val_loss=0.00332]Epoch 26:  39%|███▉      | 11/28 [00:00<00:00, 123.96it/s, train_loss=0.0026, val_loss=0.00332] Epoch 26:  43%|████▎     | 12/28 [00:00<00:00, 127.07it/s, train_loss=0.0026, val_loss=0.00332]Epoch 26:  43%|████▎     | 12/28 [00:00<00:00, 124.84it/s, train_loss=0.00239, val_loss=0.00332]Epoch 26:  46%|████▋     | 13/28 [00:00<00:00, 128.53it/s, train_loss=0.00239, val_loss=0.00332]Epoch 26:  46%|████▋     | 13/28 [00:00<00:00, 123.77it/s, train_loss=0.00276, val_loss=0.00332]Epoch 26:  50%|█████     | 14/28 [00:00<00:00, 126.44it/s, train_loss=0.00276, val_loss=0.00332]Epoch 26:  50%|█████     | 14/28 [00:00<00:00, 124.54it/s, train_loss=0.00261, val_loss=0.00332]Epoch 26:  54%|█████▎    | 15/28 [00:00<00:00, 127.68it/s, train_loss=0.00261, val_loss=0.00332]Epoch 26:  54%|█████▎    | 15/28 [00:00<00:00, 123.60it/s, train_loss=0.0025, val_loss=0.00332] Epoch 26:  57%|█████▋    | 16/28 [00:00<00:00, 125.94it/s, train_loss=0.0025, val_loss=0.00332]Epoch 26:  57%|█████▋    | 16/28 [00:00<00:00, 124.35it/s, train_loss=0.00269, val_loss=0.00332]Epoch 26:  61%|██████    | 17/28 [00:00<00:00, 127.16it/s, train_loss=0.00269, val_loss=0.00332]Epoch 26:  61%|██████    | 17/28 [00:00<00:00, 123.46it/s, train_loss=0.00304, val_loss=0.00332]Epoch 26:  64%|██████▍   | 18/28 [00:00<00:00, 125.44it/s, train_loss=0.00304, val_loss=0.00332]Epoch 26:  64%|██████▍   | 18/28 [00:00<00:00, 124.02it/s, train_loss=0.00232, val_loss=0.00332]Epoch 26:  68%|██████▊   | 19/28 [00:00<00:00, 126.37it/s, train_loss=0.00232, val_loss=0.00332]Epoch 26:  68%|██████▊   | 19/28 [00:00<00:00, 123.24it/s, train_loss=0.00306, val_loss=0.00332]Epoch 26:  71%|███████▏  | 20/28 [00:00<00:00, 125.00it/s, train_loss=0.00306, val_loss=0.00332]Epoch 26:  71%|███████▏  | 20/28 [00:00<00:00, 123.77it/s, train_loss=0.00269, val_loss=0.00332]Epoch 26:  75%|███████▌  | 21/28 [00:00<00:00, 125.54it/s, train_loss=0.00269, val_loss=0.00332]Epoch 26:  75%|███████▌  | 21/28 [00:00<00:00, 123.23it/s, train_loss=0.00287, val_loss=0.00332]Epoch 26:  79%|███████▊  | 22/28 [00:00<00:00, 125.20it/s, train_loss=0.00287, val_loss=0.00332]Epoch 26:  79%|███████▊  | 22/28 [00:00<00:00, 123.97it/s, train_loss=0.00242, val_loss=0.00332]Epoch 26:  82%|████████▏ | 23/28 [00:00<00:00, 126.05it/s, train_loss=0.00242, val_loss=0.00332]Epoch 26:  82%|████████▏ | 23/28 [00:00<00:00, 123.45it/s, train_loss=0.00256, val_loss=0.00332]Epoch 26:  86%|████████▌ | 24/28 [00:00<00:00, 125.11it/s, train_loss=0.00256, val_loss=0.00332]Epoch 26:  86%|████████▌ | 24/28 [00:00<00:00, 124.00it/s, train_loss=0.003, val_loss=0.00332]  Epoch 26:  89%|████████▉ | 25/28 [00:00<00:00, 126.01it/s, train_loss=0.003, val_loss=0.00332]Epoch 26:  89%|████████▉ | 25/28 [00:00<00:00, 123.54it/s, train_loss=0.0029, val_loss=0.00332]Epoch 26:  93%|█████████▎| 26/28 [00:00<00:00, 125.02it/s, train_loss=0.0029, val_loss=0.00332]Epoch 26:  93%|█████████▎| 26/28 [00:00<00:00, 124.01it/s, train_loss=0.00227, val_loss=0.00332]Epoch 26:  96%|█████████▋| 27/28 [00:00<00:00, 125.86it/s, train_loss=0.00227, val_loss=0.00332]Epoch 26:  96%|█████████▋| 27/28 [00:00<00:00, 123.57it/s, train_loss=0.00269, val_loss=0.00332]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 125.03it/s, train_loss=0.00269, val_loss=0.00332]Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 124.21it/s, train_loss=0.00227, val_loss=0.00332]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 168.89it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 200.27it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 208.50it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 213.98it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 215.32it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 216.79it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 220.16it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 220.17it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 221.75it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 221.88it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 221.90it/s][A
                                                                         [AEpoch 26: 100%|██████████| 28/28 [00:00<00:00, 98.29it/s, train_loss=0.00227, val_loss=0.00327] Epoch 26: 100%|██████████| 28/28 [00:00<00:00, 97.92it/s, train_loss=0.00227, val_loss=0.00327]Epoch 26:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00327]         Epoch 27:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00327]Epoch 27:   4%|▎         | 1/28 [00:00<00:00, 143.93it/s, train_loss=0.00227, val_loss=0.00327]Epoch 27:   4%|▎         | 1/28 [00:00<00:00, 119.43it/s, train_loss=0.00269, val_loss=0.00327]Epoch 27:   7%|▋         | 2/28 [00:00<00:00, 141.29it/s, train_loss=0.00269, val_loss=0.00327]Epoch 27:   7%|▋         | 2/28 [00:00<00:00, 126.62it/s, train_loss=0.00292, val_loss=0.00327]Epoch 27:  11%|█         | 3/28 [00:00<00:00, 141.81it/s, train_loss=0.00292, val_loss=0.00327]Epoch 27:  11%|█         | 3/28 [00:00<00:00, 121.03it/s, train_loss=0.00302, val_loss=0.00327]Epoch 27:  14%|█▍        | 4/28 [00:00<00:00, 130.00it/s, train_loss=0.00302, val_loss=0.00327]Epoch 27:  14%|█▍        | 4/28 [00:00<00:00, 123.59it/s, train_loss=0.00255, val_loss=0.00327]Epoch 27:  18%|█▊        | 5/28 [00:00<00:00, 134.32it/s, train_loss=0.00255, val_loss=0.00327]Epoch 27:  18%|█▊        | 5/28 [00:00<00:00, 121.69it/s, train_loss=0.00248, val_loss=0.00327]Epoch 27:  21%|██▏       | 6/28 [00:00<00:00, 127.64it/s, train_loss=0.00248, val_loss=0.00327]Epoch 27:  21%|██▏       | 6/28 [00:00<00:00, 123.65it/s, train_loss=0.00288, val_loss=0.00327]Epoch 27:  25%|██▌       | 7/28 [00:00<00:00, 130.31it/s, train_loss=0.00288, val_loss=0.00327]Epoch 27:  25%|██▌       | 7/28 [00:00<00:00, 126.07it/s, train_loss=0.00258, val_loss=0.00327]Epoch 27:  29%|██▊       | 8/28 [00:00<00:00, 131.55it/s, train_loss=0.00258, val_loss=0.00327]Epoch 27:  29%|██▊       | 8/28 [00:00<00:00, 126.05it/s, train_loss=0.0022, val_loss=0.00327] Epoch 27:  32%|███▏      | 9/28 [00:00<00:00, 131.05it/s, train_loss=0.0022, val_loss=0.00327]Epoch 27:  32%|███▏      | 9/28 [00:00<00:00, 127.79it/s, train_loss=0.00277, val_loss=0.00327]Epoch 27:  36%|███▌      | 10/28 [00:00<00:00, 132.74it/s, train_loss=0.00277, val_loss=0.00327]Epoch 27:  36%|███▌      | 10/28 [00:00<00:00, 126.12it/s, train_loss=0.00238, val_loss=0.00327]Epoch 27:  39%|███▉      | 11/28 [00:00<00:00, 129.74it/s, train_loss=0.00238, val_loss=0.00327]Epoch 27:  39%|███▉      | 11/28 [00:00<00:00, 127.16it/s, train_loss=0.00242, val_loss=0.00327]Epoch 27:  43%|████▎     | 12/28 [00:00<00:00, 131.37it/s, train_loss=0.00242, val_loss=0.00327]Epoch 27:  43%|████▎     | 12/28 [00:00<00:00, 125.81it/s, train_loss=0.00301, val_loss=0.00327]Epoch 27:  46%|████▋     | 13/28 [00:00<00:00, 128.62it/s, train_loss=0.00301, val_loss=0.00327]Epoch 27:  46%|████▋     | 13/28 [00:00<00:00, 126.53it/s, train_loss=0.00275, val_loss=0.00327]Epoch 27:  50%|█████     | 14/28 [00:00<00:00, 129.98it/s, train_loss=0.00275, val_loss=0.00327]Epoch 27:  50%|█████     | 14/28 [00:00<00:00, 125.38it/s, train_loss=0.00251, val_loss=0.00327]Epoch 27:  54%|█████▎    | 15/28 [00:00<00:00, 127.69it/s, train_loss=0.00251, val_loss=0.00327]Epoch 27:  54%|█████▎    | 15/28 [00:00<00:00, 125.98it/s, train_loss=0.00297, val_loss=0.00327]Epoch 27:  57%|█████▋    | 16/28 [00:00<00:00, 127.05it/s, train_loss=0.00297, val_loss=0.00327]Epoch 27:  57%|█████▋    | 16/28 [00:00<00:00, 125.55it/s, train_loss=0.00236, val_loss=0.00327]Epoch 27:  61%|██████    | 17/28 [00:00<00:00, 127.71it/s, train_loss=0.00236, val_loss=0.00327]Epoch 27:  61%|██████    | 17/28 [00:00<00:00, 126.07it/s, train_loss=0.00276, val_loss=0.00327]Epoch 27:  64%|██████▍   | 18/28 [00:00<00:00, 128.52it/s, train_loss=0.00276, val_loss=0.00327]Epoch 27:  64%|██████▍   | 18/28 [00:00<00:00, 125.06it/s, train_loss=0.00217, val_loss=0.00327]Epoch 27:  68%|██████▊   | 19/28 [00:00<00:00, 126.73it/s, train_loss=0.00217, val_loss=0.00327]Epoch 27:  68%|██████▊   | 19/28 [00:00<00:00, 125.40it/s, train_loss=0.00225, val_loss=0.00327]Epoch 27:  71%|███████▏  | 20/28 [00:00<00:00, 127.74it/s, train_loss=0.00225, val_loss=0.00327]Epoch 27:  71%|███████▏  | 20/28 [00:00<00:00, 124.67it/s, train_loss=0.00278, val_loss=0.00327]Epoch 27:  75%|███████▌  | 21/28 [00:00<00:00, 126.46it/s, train_loss=0.00278, val_loss=0.00327]Epoch 27:  75%|███████▌  | 21/28 [00:00<00:00, 125.17it/s, train_loss=0.0023, val_loss=0.00327] Epoch 27:  79%|███████▊  | 22/28 [00:00<00:00, 126.87it/s, train_loss=0.0023, val_loss=0.00327]Epoch 27:  79%|███████▊  | 22/28 [00:00<00:00, 124.54it/s, train_loss=0.00272, val_loss=0.00327]Epoch 27:  82%|████████▏ | 23/28 [00:00<00:00, 126.03it/s, train_loss=0.00272, val_loss=0.00327]Epoch 27:  82%|████████▏ | 23/28 [00:00<00:00, 124.94it/s, train_loss=0.00239, val_loss=0.00327]Epoch 27:  86%|████████▌ | 24/28 [00:00<00:00, 126.96it/s, train_loss=0.00239, val_loss=0.00327]Epoch 27:  86%|████████▌ | 24/28 [00:00<00:00, 124.37it/s, train_loss=0.00298, val_loss=0.00327]Epoch 27:  89%|████████▉ | 25/28 [00:00<00:00, 125.83it/s, train_loss=0.00298, val_loss=0.00327]Epoch 27:  89%|████████▉ | 25/28 [00:00<00:00, 124.84it/s, train_loss=0.00269, val_loss=0.00327]Epoch 27:  93%|█████████▎| 26/28 [00:00<00:00, 126.53it/s, train_loss=0.00269, val_loss=0.00327]Epoch 27:  93%|█████████▎| 26/28 [00:00<00:00, 124.15it/s, train_loss=0.00303, val_loss=0.00327]Epoch 27:  96%|█████████▋| 27/28 [00:00<00:00, 125.22it/s, train_loss=0.00303, val_loss=0.00327]Epoch 27:  96%|█████████▋| 27/28 [00:00<00:00, 124.21it/s, train_loss=0.00319, val_loss=0.00327]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 125.92it/s, train_loss=0.00319, val_loss=0.00327]Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 124.96it/s, train_loss=0.00205, val_loss=0.00327]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 149.01it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 183.31it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 199.61it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 211.50it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 215.91it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 221.48it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 222.72it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 223.89it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 225.60it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 225.91it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 227.60it/s][A
                                                                         [AEpoch 27: 100%|██████████| 28/28 [00:00<00:00, 99.79it/s, train_loss=0.00205, val_loss=0.00322] Epoch 27: 100%|██████████| 28/28 [00:00<00:00, 99.44it/s, train_loss=0.00205, val_loss=0.00322]Epoch 27:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00205, val_loss=0.00322]         Epoch 28:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00205, val_loss=0.00322]Epoch 28:   4%|▎         | 1/28 [00:00<00:00, 140.50it/s, train_loss=0.00205, val_loss=0.00322]Epoch 28:   4%|▎         | 1/28 [00:00<00:00, 114.67it/s, train_loss=0.00275, val_loss=0.00322]Epoch 28:   7%|▋         | 2/28 [00:00<00:00, 143.27it/s, train_loss=0.00275, val_loss=0.00322]Epoch 28:   7%|▋         | 2/28 [00:00<00:00, 128.96it/s, train_loss=0.00285, val_loss=0.00322]Epoch 28:  11%|█         | 3/28 [00:00<00:00, 145.78it/s, train_loss=0.00285, val_loss=0.00322]Epoch 28:  11%|█         | 3/28 [00:00<00:00, 129.40it/s, train_loss=0.00222, val_loss=0.00322]Epoch 28:  14%|█▍        | 4/28 [00:00<00:00, 140.15it/s, train_loss=0.00222, val_loss=0.00322]Epoch 28:  14%|█▍        | 4/28 [00:00<00:00, 132.75it/s, train_loss=0.00259, val_loss=0.00322]Epoch 28:  18%|█▊        | 5/28 [00:00<00:00, 143.70it/s, train_loss=0.00259, val_loss=0.00322]Epoch 28:  18%|█▊        | 5/28 [00:00<00:00, 129.26it/s, train_loss=0.00213, val_loss=0.00322]Epoch 28:  21%|██▏       | 6/28 [00:00<00:00, 136.44it/s, train_loss=0.00213, val_loss=0.00322]Epoch 28:  21%|██▏       | 6/28 [00:00<00:00, 131.28it/s, train_loss=0.00317, val_loss=0.00322]Epoch 28:  25%|██▌       | 7/28 [00:00<00:00, 137.33it/s, train_loss=0.00317, val_loss=0.00322]Epoch 28:  25%|██▌       | 7/28 [00:00<00:00, 129.58it/s, train_loss=0.00283, val_loss=0.00322]Epoch 28:  29%|██▊       | 8/28 [00:00<00:00, 136.07it/s, train_loss=0.00283, val_loss=0.00322]Epoch 28:  29%|██▊       | 8/28 [00:00<00:00, 132.02it/s, train_loss=0.00265, val_loss=0.00322]Epoch 28:  32%|███▏      | 9/28 [00:00<00:00, 138.74it/s, train_loss=0.00265, val_loss=0.00322]Epoch 28:  32%|███▏      | 9/28 [00:00<00:00, 130.48it/s, train_loss=0.00256, val_loss=0.00322]Epoch 28:  36%|███▌      | 10/28 [00:00<00:00, 134.97it/s, train_loss=0.00256, val_loss=0.00322]Epoch 28:  36%|███▌      | 10/28 [00:00<00:00, 132.07it/s, train_loss=0.00263, val_loss=0.00322]Epoch 28:  39%|███▉      | 11/28 [00:00<00:00, 137.34it/s, train_loss=0.00263, val_loss=0.00322]Epoch 28:  39%|███▉      | 11/28 [00:00<00:00, 130.26it/s, train_loss=0.0028, val_loss=0.00322] Epoch 28:  43%|████▎     | 12/28 [00:00<00:00, 134.39it/s, train_loss=0.0028, val_loss=0.00322]Epoch 28:  43%|████▎     | 12/28 [00:00<00:00, 131.94it/s, train_loss=0.00223, val_loss=0.00322]Epoch 28:  46%|████▋     | 13/28 [00:00<00:00, 136.34it/s, train_loss=0.00223, val_loss=0.00322]Epoch 28:  46%|████▋     | 13/28 [00:00<00:00, 130.44it/s, train_loss=0.0032, val_loss=0.00322] Epoch 28:  50%|█████     | 14/28 [00:00<00:00, 133.89it/s, train_loss=0.0032, val_loss=0.00322]Epoch 28:  50%|█████     | 14/28 [00:00<00:00, 131.55it/s, train_loss=0.00231, val_loss=0.00322]Epoch 28:  54%|█████▎    | 15/28 [00:00<00:00, 134.53it/s, train_loss=0.00231, val_loss=0.00322]Epoch 28:  54%|█████▎    | 15/28 [00:00<00:00, 130.02it/s, train_loss=0.00261, val_loss=0.00322]Epoch 28:  57%|█████▋    | 16/28 [00:00<00:00, 132.09it/s, train_loss=0.00261, val_loss=0.00322]Epoch 28:  57%|█████▋    | 16/28 [00:00<00:00, 130.32it/s, train_loss=0.00271, val_loss=0.00322]Epoch 28:  61%|██████    | 17/28 [00:00<00:00, 132.97it/s, train_loss=0.00271, val_loss=0.00322]Epoch 28:  61%|██████    | 17/28 [00:00<00:00, 129.09it/s, train_loss=0.00268, val_loss=0.00322]Epoch 28:  64%|██████▍   | 18/28 [00:00<00:00, 130.88it/s, train_loss=0.00268, val_loss=0.00322]Epoch 28:  64%|██████▍   | 18/28 [00:00<00:00, 129.34it/s, train_loss=0.00307, val_loss=0.00322]Epoch 28:  68%|██████▊   | 19/28 [00:00<00:00, 131.74it/s, train_loss=0.00307, val_loss=0.00322]Epoch 28:  68%|██████▊   | 19/28 [00:00<00:00, 128.30it/s, train_loss=0.00238, val_loss=0.00322]Epoch 28:  71%|███████▏  | 20/28 [00:00<00:00, 129.86it/s, train_loss=0.00238, val_loss=0.00322]Epoch 28:  71%|███████▏  | 20/28 [00:00<00:00, 128.55it/s, train_loss=0.0027, val_loss=0.00322] Epoch 28:  75%|███████▌  | 21/28 [00:00<00:00, 130.68it/s, train_loss=0.0027, val_loss=0.00322]Epoch 28:  75%|███████▌  | 21/28 [00:00<00:00, 127.58it/s, train_loss=0.00241, val_loss=0.00322]Epoch 28:  79%|███████▊  | 22/28 [00:00<00:00, 129.16it/s, train_loss=0.00241, val_loss=0.00322]Epoch 28:  79%|███████▊  | 22/28 [00:00<00:00, 127.93it/s, train_loss=0.00229, val_loss=0.00322]Epoch 28:  82%|████████▏ | 23/28 [00:00<00:00, 130.27it/s, train_loss=0.00229, val_loss=0.00322]Epoch 28:  82%|████████▏ | 23/28 [00:00<00:00, 127.59it/s, train_loss=0.00218, val_loss=0.00322]Epoch 28:  86%|████████▌ | 24/28 [00:00<00:00, 129.42it/s, train_loss=0.00218, val_loss=0.00322]Epoch 28:  86%|████████▌ | 24/28 [00:00<00:00, 128.22it/s, train_loss=0.00245, val_loss=0.00322]Epoch 28:  89%|████████▉ | 25/28 [00:00<00:00, 129.92it/s, train_loss=0.00245, val_loss=0.00322]Epoch 28:  89%|████████▉ | 25/28 [00:00<00:00, 127.80it/s, train_loss=0.0022, val_loss=0.00322] Epoch 28:  93%|█████████▎| 26/28 [00:00<00:00, 129.54it/s, train_loss=0.0022, val_loss=0.00322]Epoch 28:  93%|█████████▎| 26/28 [00:00<00:00, 128.42it/s, train_loss=0.00301, val_loss=0.00322]Epoch 28:  96%|█████████▋| 27/28 [00:00<00:00, 130.77it/s, train_loss=0.00301, val_loss=0.00322]Epoch 28:  96%|█████████▋| 27/28 [00:00<00:00, 128.05it/s, train_loss=0.00322, val_loss=0.00322]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 129.89it/s, train_loss=0.00322, val_loss=0.00322]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 129.01it/s, train_loss=0.00282, val_loss=0.00322]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 211.88it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 240.32it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 254.20it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 259.63it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 263.97it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 265.26it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 264.93it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 265.90it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 264.46it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 264.46it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 265.11it/s][A
                                                                         [AEpoch 28: 100%|██████████| 28/28 [00:00<00:00, 105.52it/s, train_loss=0.00282, val_loss=0.00321]Epoch 28: 100%|██████████| 28/28 [00:00<00:00, 105.16it/s, train_loss=0.00282, val_loss=0.00321]Epoch 28:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00282, val_loss=0.00321]          Epoch 29:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00282, val_loss=0.00321]Epoch 29:   4%|▎         | 1/28 [00:00<00:00, 155.36it/s, train_loss=0.00282, val_loss=0.00321]Epoch 29:   4%|▎         | 1/28 [00:00<00:00, 113.01it/s, train_loss=0.00268, val_loss=0.00321]Epoch 29:   7%|▋         | 2/28 [00:00<00:00, 142.86it/s, train_loss=0.00268, val_loss=0.00321]Epoch 29:   7%|▋         | 2/28 [00:00<00:00, 127.43it/s, train_loss=0.00241, val_loss=0.00321]Epoch 29:  11%|█         | 3/28 [00:00<00:00, 144.83it/s, train_loss=0.00241, val_loss=0.00321]Epoch 29:  11%|█         | 3/28 [00:00<00:00, 121.49it/s, train_loss=0.00218, val_loss=0.00321]Epoch 29:  14%|█▍        | 4/28 [00:00<00:00, 133.99it/s, train_loss=0.00218, val_loss=0.00321]Epoch 29:  14%|█▍        | 4/28 [00:00<00:00, 126.06it/s, train_loss=0.0026, val_loss=0.00321] Epoch 29:  18%|█▊        | 5/28 [00:00<00:00, 137.13it/s, train_loss=0.0026, val_loss=0.00321]Epoch 29:  18%|█▊        | 5/28 [00:00<00:00, 124.30it/s, train_loss=0.00317, val_loss=0.00321]Epoch 29:  21%|██▏       | 6/28 [00:00<00:00, 132.46it/s, train_loss=0.00317, val_loss=0.00321]Epoch 29:  21%|██▏       | 6/28 [00:00<00:00, 127.11it/s, train_loss=0.00287, val_loss=0.00321]Epoch 29:  25%|██▌       | 7/28 [00:00<00:00, 134.69it/s, train_loss=0.00287, val_loss=0.00321]Epoch 29:  25%|██▌       | 7/28 [00:00<00:00, 126.10it/s, train_loss=0.00269, val_loss=0.00321]Epoch 29:  29%|██▊       | 8/28 [00:00<00:00, 131.85it/s, train_loss=0.00269, val_loss=0.00321]Epoch 29:  29%|██▊       | 8/28 [00:00<00:00, 127.82it/s, train_loss=0.00236, val_loss=0.00321]Epoch 29:  32%|███▏      | 9/28 [00:00<00:00, 132.83it/s, train_loss=0.00236, val_loss=0.00321]Epoch 29:  32%|███▏      | 9/28 [00:00<00:00, 126.83it/s, train_loss=0.00216, val_loss=0.00321]Epoch 29:  36%|███▌      | 10/28 [00:00<00:00, 132.28it/s, train_loss=0.00216, val_loss=0.00321]Epoch 29:  36%|███▌      | 10/28 [00:00<00:00, 129.01it/s, train_loss=0.00301, val_loss=0.00321]Epoch 29:  39%|███▉      | 11/28 [00:00<00:00, 134.43it/s, train_loss=0.00301, val_loss=0.00321]Epoch 29:  39%|███▉      | 11/28 [00:00<00:00, 128.09it/s, train_loss=0.00231, val_loss=0.00321]Epoch 29:  43%|████▎     | 12/28 [00:00<00:00, 132.15it/s, train_loss=0.00231, val_loss=0.00321]Epoch 29:  43%|████▎     | 12/28 [00:00<00:00, 129.56it/s, train_loss=0.00251, val_loss=0.00321]Epoch 29:  46%|████▋     | 13/28 [00:00<00:00, 133.82it/s, train_loss=0.00251, val_loss=0.00321]Epoch 29:  46%|████▋     | 13/28 [00:00<00:00, 128.25it/s, train_loss=0.00221, val_loss=0.00321]Epoch 29:  50%|█████     | 14/28 [00:00<00:00, 132.10it/s, train_loss=0.00221, val_loss=0.00321]Epoch 29:  50%|█████     | 14/28 [00:00<00:00, 129.85it/s, train_loss=0.00254, val_loss=0.00321]Epoch 29:  54%|█████▎    | 15/28 [00:00<00:00, 133.64it/s, train_loss=0.00254, val_loss=0.00321]Epoch 29:  54%|█████▎    | 15/28 [00:00<00:00, 128.91it/s, train_loss=0.00228, val_loss=0.00321]Epoch 29:  57%|█████▋    | 16/28 [00:00<00:00, 131.91it/s, train_loss=0.00228, val_loss=0.00321]Epoch 29:  57%|█████▋    | 16/28 [00:00<00:00, 129.93it/s, train_loss=0.00242, val_loss=0.00321]Epoch 29:  61%|██████    | 17/28 [00:00<00:00, 133.27it/s, train_loss=0.00242, val_loss=0.00321]Epoch 29:  61%|██████    | 17/28 [00:00<00:00, 129.17it/s, train_loss=0.00301, val_loss=0.00321]Epoch 29:  64%|██████▍   | 18/28 [00:00<00:00, 131.76it/s, train_loss=0.00301, val_loss=0.00321]Epoch 29:  64%|██████▍   | 18/28 [00:00<00:00, 130.06it/s, train_loss=0.00253, val_loss=0.00321]Epoch 29:  68%|██████▊   | 19/28 [00:00<00:00, 132.91it/s, train_loss=0.00253, val_loss=0.00321]Epoch 29:  68%|██████▊   | 19/28 [00:00<00:00, 129.40it/s, train_loss=0.00319, val_loss=0.00321]Epoch 29:  71%|███████▏  | 20/28 [00:00<00:00, 131.59it/s, train_loss=0.00319, val_loss=0.00321]Epoch 29:  71%|███████▏  | 20/28 [00:00<00:00, 130.16it/s, train_loss=0.0024, val_loss=0.00321] Epoch 29:  75%|███████▌  | 21/28 [00:00<00:00, 132.71it/s, train_loss=0.0024, val_loss=0.00321]Epoch 29:  75%|███████▌  | 21/28 [00:00<00:00, 129.58it/s, train_loss=0.0023, val_loss=0.00321]Epoch 29:  79%|███████▊  | 22/28 [00:00<00:00, 131.54it/s, train_loss=0.0023, val_loss=0.00321]Epoch 29:  79%|███████▊  | 22/28 [00:00<00:00, 130.24it/s, train_loss=0.00242, val_loss=0.00321]Epoch 29:  82%|████████▏ | 23/28 [00:00<00:00, 132.54it/s, train_loss=0.00242, val_loss=0.00321]Epoch 29:  82%|████████▏ | 23/28 [00:00<00:00, 129.86it/s, train_loss=0.00275, val_loss=0.00321]Epoch 29:  86%|████████▌ | 24/28 [00:00<00:00, 131.78it/s, train_loss=0.00275, val_loss=0.00321]Epoch 29:  86%|████████▌ | 24/28 [00:00<00:00, 130.57it/s, train_loss=0.00278, val_loss=0.00321]Epoch 29:  89%|████████▉ | 25/28 [00:00<00:00, 132.64it/s, train_loss=0.00278, val_loss=0.00321]Epoch 29:  89%|████████▉ | 25/28 [00:00<00:00, 129.97it/s, train_loss=0.00275, val_loss=0.00321]Epoch 29:  93%|█████████▎| 26/28 [00:00<00:00, 131.42it/s, train_loss=0.00275, val_loss=0.00321]Epoch 29:  93%|█████████▎| 26/28 [00:00<00:00, 130.39it/s, train_loss=0.00296, val_loss=0.00321]Epoch 29:  96%|█████████▋| 27/28 [00:00<00:00, 131.76it/s, train_loss=0.00296, val_loss=0.00321]Epoch 29:  96%|█████████▋| 27/28 [00:00<00:00, 129.86it/s, train_loss=0.00269, val_loss=0.00321]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 131.48it/s, train_loss=0.00269, val_loss=0.00321]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 130.52it/s, train_loss=0.00302, val_loss=0.00321]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 226.41it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 262.14it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 278.17it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 279.35it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 283.12it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 285.65it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 287.51it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 286.22it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 285.80it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 285.45it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 283.33it/s][A
                                                                         [AEpoch 29: 100%|██████████| 28/28 [00:00<00:00, 108.03it/s, train_loss=0.00302, val_loss=0.00317]Epoch 29: 100%|██████████| 28/28 [00:00<00:00, 107.69it/s, train_loss=0.00302, val_loss=0.00317]Epoch 29:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00317]          Epoch 30:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00317]Epoch 30:   4%|▎         | 1/28 [00:00<00:00, 169.11it/s, train_loss=0.00302, val_loss=0.00317]Epoch 30:   4%|▎         | 1/28 [00:00<00:00, 133.47it/s, train_loss=0.00237, val_loss=0.00317]Epoch 30:   7%|▋         | 2/28 [00:00<00:00, 163.80it/s, train_loss=0.00237, val_loss=0.00317]Epoch 30:   7%|▋         | 2/28 [00:00<00:00, 122.38it/s, train_loss=0.00266, val_loss=0.00317]Epoch 30:  11%|█         | 3/28 [00:00<00:00, 138.81it/s, train_loss=0.00266, val_loss=0.00317]Epoch 30:  11%|█         | 3/28 [00:00<00:00, 128.51it/s, train_loss=0.00224, val_loss=0.00317]Epoch 30:  14%|█▍        | 4/28 [00:00<00:00, 142.32it/s, train_loss=0.00224, val_loss=0.00317]Epoch 30:  14%|█▍        | 4/28 [00:00<00:00, 133.90it/s, train_loss=0.00208, val_loss=0.00317]Epoch 30:  18%|█▊        | 5/28 [00:00<00:00, 143.26it/s, train_loss=0.00208, val_loss=0.00317]Epoch 30:  18%|█▊        | 5/28 [00:00<00:00, 135.91it/s, train_loss=0.00233, val_loss=0.00317]Epoch 30:  21%|██▏       | 6/28 [00:00<00:00, 143.80it/s, train_loss=0.00233, val_loss=0.00317]Epoch 30:  21%|██▏       | 6/28 [00:00<00:00, 138.05it/s, train_loss=0.00272, val_loss=0.00317]Epoch 30:  25%|██▌       | 7/28 [00:00<00:00, 146.29it/s, train_loss=0.00272, val_loss=0.00317]Epoch 30:  25%|██▌       | 7/28 [00:00<00:00, 134.56it/s, train_loss=0.00277, val_loss=0.00317]Epoch 30:  29%|██▊       | 8/28 [00:00<00:00, 139.74it/s, train_loss=0.00277, val_loss=0.00317]Epoch 30:  29%|██▊       | 8/28 [00:00<00:00, 135.73it/s, train_loss=0.00302, val_loss=0.00317]Epoch 30:  32%|███▏      | 9/28 [00:00<00:00, 140.74it/s, train_loss=0.00302, val_loss=0.00317]Epoch 30:  32%|███▏      | 9/28 [00:00<00:00, 133.59it/s, train_loss=0.00236, val_loss=0.00317]Epoch 30:  36%|███▌      | 10/28 [00:00<00:00, 137.86it/s, train_loss=0.00236, val_loss=0.00317]Epoch 30:  36%|███▌      | 10/28 [00:00<00:00, 134.39it/s, train_loss=0.00311, val_loss=0.00317]Epoch 30:  39%|███▉      | 11/28 [00:00<00:00, 138.27it/s, train_loss=0.00311, val_loss=0.00317]Epoch 30:  39%|███▉      | 11/28 [00:00<00:00, 133.60it/s, train_loss=0.00219, val_loss=0.00317]Epoch 30:  43%|████▎     | 12/28 [00:00<00:00, 136.98it/s, train_loss=0.00219, val_loss=0.00317]Epoch 30:  43%|████▎     | 12/28 [00:00<00:00, 134.08it/s, train_loss=0.00302, val_loss=0.00317]Epoch 30:  46%|████▋     | 13/28 [00:00<00:00, 138.42it/s, train_loss=0.00302, val_loss=0.00317]Epoch 30:  46%|████▋     | 13/28 [00:00<00:00, 133.31it/s, train_loss=0.00247, val_loss=0.00317]Epoch 30:  50%|█████     | 14/28 [00:00<00:00, 137.05it/s, train_loss=0.00247, val_loss=0.00317]Epoch 30:  50%|█████     | 14/28 [00:00<00:00, 134.89it/s, train_loss=0.00272, val_loss=0.00317]Epoch 30:  54%|█████▎    | 15/28 [00:00<00:00, 139.01it/s, train_loss=0.00272, val_loss=0.00317]Epoch 30:  54%|█████▎    | 15/28 [00:00<00:00, 133.71it/s, train_loss=0.00255, val_loss=0.00317]Epoch 30:  57%|█████▋    | 16/28 [00:00<00:00, 136.35it/s, train_loss=0.00255, val_loss=0.00317]Epoch 30:  57%|█████▋    | 16/28 [00:00<00:00, 134.38it/s, train_loss=0.00262, val_loss=0.00317]Epoch 30:  61%|██████    | 17/28 [00:00<00:00, 137.48it/s, train_loss=0.00262, val_loss=0.00317]Epoch 30:  61%|██████    | 17/28 [00:00<00:00, 135.37it/s, train_loss=0.00328, val_loss=0.00317]Epoch 30:  64%|██████▍   | 18/28 [00:00<00:00, 137.87it/s, train_loss=0.00328, val_loss=0.00317]Epoch 30:  64%|██████▍   | 18/28 [00:00<00:00, 135.16it/s, train_loss=0.0026, val_loss=0.00317] Epoch 30:  68%|██████▊   | 19/28 [00:00<00:00, 137.68it/s, train_loss=0.0026, val_loss=0.00317]Epoch 30:  68%|██████▊   | 19/28 [00:00<00:00, 135.96it/s, train_loss=0.00287, val_loss=0.00317]Epoch 30:  71%|███████▏  | 20/28 [00:00<00:00, 138.73it/s, train_loss=0.00287, val_loss=0.00317]Epoch 30:  71%|███████▏  | 20/28 [00:00<00:00, 134.89it/s, train_loss=0.00253, val_loss=0.00317]Epoch 30:  75%|███████▌  | 21/28 [00:00<00:00, 136.83it/s, train_loss=0.00253, val_loss=0.00317]Epoch 30:  75%|███████▌  | 21/28 [00:00<00:00, 135.37it/s, train_loss=0.00262, val_loss=0.00317]Epoch 30:  79%|███████▊  | 22/28 [00:00<00:00, 137.76it/s, train_loss=0.00262, val_loss=0.00317]Epoch 30:  79%|███████▊  | 22/28 [00:00<00:00, 134.70it/s, train_loss=0.00239, val_loss=0.00317]Epoch 30:  82%|████████▏ | 23/28 [00:00<00:00, 136.68it/s, train_loss=0.00239, val_loss=0.00317]Epoch 30:  82%|████████▏ | 23/28 [00:00<00:00, 135.22it/s, train_loss=0.00209, val_loss=0.00317]Epoch 30:  86%|████████▌ | 24/28 [00:00<00:00, 137.35it/s, train_loss=0.00209, val_loss=0.00317]Epoch 30:  86%|████████▌ | 24/28 [00:00<00:00, 134.52it/s, train_loss=0.00277, val_loss=0.00317]Epoch 30:  89%|████████▉ | 25/28 [00:00<00:00, 136.28it/s, train_loss=0.00277, val_loss=0.00317]Epoch 30:  89%|████████▉ | 25/28 [00:00<00:00, 135.03it/s, train_loss=0.0025, val_loss=0.00317] Epoch 30:  93%|█████████▎| 26/28 [00:00<00:00, 137.08it/s, train_loss=0.0025, val_loss=0.00317]Epoch 30:  93%|█████████▎| 26/28 [00:00<00:00, 134.41it/s, train_loss=0.00256, val_loss=0.00317]Epoch 30:  96%|█████████▋| 27/28 [00:00<00:00, 136.01it/s, train_loss=0.00256, val_loss=0.00317]Epoch 30:  96%|█████████▋| 27/28 [00:00<00:00, 134.82it/s, train_loss=0.0024, val_loss=0.00317] Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 136.77it/s, train_loss=0.0024, val_loss=0.00317]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 134.44it/s, train_loss=0.00227, val_loss=0.00317]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 147.22it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 194.74it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 223.51it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 243.44it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 257.12it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 266.29it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 272.66it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 278.22it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 282.12it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 284.73it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 286.05it/s][A
                                                                         [AEpoch 30: 100%|██████████| 28/28 [00:00<00:00, 110.39it/s, train_loss=0.00227, val_loss=0.00317]Epoch 30: 100%|██████████| 28/28 [00:00<00:00, 110.06it/s, train_loss=0.00227, val_loss=0.00317]Epoch 30:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00317]          Epoch 31:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00317]Epoch 31:   4%|▎         | 1/28 [00:00<00:00, 173.78it/s, train_loss=0.00227, val_loss=0.00317]Epoch 31:   4%|▎         | 1/28 [00:00<00:00, 135.05it/s, train_loss=0.00261, val_loss=0.00317]Epoch 31:   7%|▋         | 2/28 [00:00<00:00, 167.23it/s, train_loss=0.00261, val_loss=0.00317]Epoch 31:   7%|▋         | 2/28 [00:00<00:00, 125.57it/s, train_loss=0.00249, val_loss=0.00317]Epoch 31:  11%|█         | 3/28 [00:00<00:00, 141.34it/s, train_loss=0.00249, val_loss=0.00317]Epoch 31:  11%|█         | 3/28 [00:00<00:00, 130.19it/s, train_loss=0.00202, val_loss=0.00317]Epoch 31:  14%|█▍        | 4/28 [00:00<00:00, 144.55it/s, train_loss=0.00202, val_loss=0.00317]Epoch 31:  14%|█▍        | 4/28 [00:00<00:00, 135.75it/s, train_loss=0.00259, val_loss=0.00317]Epoch 31:  18%|█▊        | 5/28 [00:00<00:00, 145.02it/s, train_loss=0.00259, val_loss=0.00317]Epoch 31:  18%|█▊        | 5/28 [00:00<00:00, 133.96it/s, train_loss=0.00275, val_loss=0.00317]Epoch 31:  21%|██▏       | 6/28 [00:00<00:00, 142.08it/s, train_loss=0.00275, val_loss=0.00317]Epoch 31:  21%|██▏       | 6/28 [00:00<00:00, 136.55it/s, train_loss=0.00256, val_loss=0.00317]Epoch 31:  25%|██▌       | 7/28 [00:00<00:00, 144.42it/s, train_loss=0.00256, val_loss=0.00317]Epoch 31:  25%|██▌       | 7/28 [00:00<00:00, 134.08it/s, train_loss=0.002, val_loss=0.00317]  Epoch 31:  29%|██▊       | 8/28 [00:00<00:00, 138.91it/s, train_loss=0.002, val_loss=0.00317]Epoch 31:  29%|██▊       | 8/28 [00:00<00:00, 135.23it/s, train_loss=0.00237, val_loss=0.00317]Epoch 31:  32%|███▏      | 9/28 [00:00<00:00, 140.58it/s, train_loss=0.00237, val_loss=0.00317]Epoch 31:  32%|███▏      | 9/28 [00:00<00:00, 133.45it/s, train_loss=0.00237, val_loss=0.00317]Epoch 31:  36%|███▌      | 10/28 [00:00<00:00, 137.87it/s, train_loss=0.00237, val_loss=0.00317]Epoch 31:  36%|███▌      | 10/28 [00:00<00:00, 134.59it/s, train_loss=0.00236, val_loss=0.00317]Epoch 31:  39%|███▉      | 11/28 [00:00<00:00, 139.60it/s, train_loss=0.00236, val_loss=0.00317]Epoch 31:  39%|███▉      | 11/28 [00:00<00:00, 133.32it/s, train_loss=0.0026, val_loss=0.00317] Epoch 31:  43%|████▎     | 12/28 [00:00<00:00, 137.01it/s, train_loss=0.0026, val_loss=0.00317]Epoch 31:  43%|████▎     | 12/28 [00:00<00:00, 134.38it/s, train_loss=0.00272, val_loss=0.00317]Epoch 31:  46%|████▋     | 13/28 [00:00<00:00, 138.47it/s, train_loss=0.00272, val_loss=0.00317]Epoch 31:  46%|████▋     | 13/28 [00:00<00:00, 132.94it/s, train_loss=0.00274, val_loss=0.00317]Epoch 31:  50%|█████     | 14/28 [00:00<00:00, 135.90it/s, train_loss=0.00274, val_loss=0.00317]Epoch 31:  50%|█████     | 14/28 [00:00<00:00, 133.61it/s, train_loss=0.00286, val_loss=0.00317]Epoch 31:  54%|█████▎    | 15/28 [00:00<00:00, 137.57it/s, train_loss=0.00286, val_loss=0.00317]Epoch 31:  54%|█████▎    | 15/28 [00:00<00:00, 132.60it/s, train_loss=0.00262, val_loss=0.00317]Epoch 31:  57%|█████▋    | 16/28 [00:00<00:00, 135.64it/s, train_loss=0.00262, val_loss=0.00317]Epoch 31:  57%|█████▋    | 16/28 [00:00<00:00, 133.57it/s, train_loss=0.00295, val_loss=0.00317]Epoch 31:  61%|██████    | 17/28 [00:00<00:00, 136.93it/s, train_loss=0.00295, val_loss=0.00317]Epoch 31:  61%|██████    | 17/28 [00:00<00:00, 132.39it/s, train_loss=0.00265, val_loss=0.00317]Epoch 31:  64%|██████▍   | 18/28 [00:00<00:00, 134.90it/s, train_loss=0.00265, val_loss=0.00317]Epoch 31:  64%|██████▍   | 18/28 [00:00<00:00, 133.20it/s, train_loss=0.00294, val_loss=0.00317]Epoch 31:  68%|██████▊   | 19/28 [00:00<00:00, 136.16it/s, train_loss=0.00294, val_loss=0.00317]Epoch 31:  68%|██████▊   | 19/28 [00:00<00:00, 132.32it/s, train_loss=0.00289, val_loss=0.00317]Epoch 31:  71%|███████▏  | 20/28 [00:00<00:00, 134.89it/s, train_loss=0.00289, val_loss=0.00317]Epoch 31:  71%|███████▏  | 20/28 [00:00<00:00, 133.30it/s, train_loss=0.00273, val_loss=0.00317]Epoch 31:  75%|███████▌  | 21/28 [00:00<00:00, 136.06it/s, train_loss=0.00273, val_loss=0.00317]Epoch 31:  75%|███████▌  | 21/28 [00:00<00:00, 134.45it/s, train_loss=0.00276, val_loss=0.00317]Epoch 31:  79%|███████▊  | 22/28 [00:00<00:00, 137.23it/s, train_loss=0.00276, val_loss=0.00317]Epoch 31:  79%|███████▊  | 22/28 [00:00<00:00, 134.95it/s, train_loss=0.00219, val_loss=0.00317]Epoch 31:  82%|████████▏ | 23/28 [00:00<00:00, 137.22it/s, train_loss=0.00219, val_loss=0.00317]Epoch 31:  82%|████████▏ | 23/28 [00:00<00:00, 135.72it/s, train_loss=0.00237, val_loss=0.00317]Epoch 31:  86%|████████▌ | 24/28 [00:00<00:00, 138.11it/s, train_loss=0.00237, val_loss=0.00317]Epoch 31:  86%|████████▌ | 24/28 [00:00<00:00, 135.01it/s, train_loss=0.00279, val_loss=0.00317]Epoch 31:  89%|████████▉ | 25/28 [00:00<00:00, 136.67it/s, train_loss=0.00279, val_loss=0.00317]Epoch 31:  89%|████████▉ | 25/28 [00:00<00:00, 135.36it/s, train_loss=0.00229, val_loss=0.00317]Epoch 31:  93%|█████████▎| 26/28 [00:00<00:00, 137.25it/s, train_loss=0.00229, val_loss=0.00317]Epoch 31:  93%|█████████▎| 26/28 [00:00<00:00, 135.98it/s, train_loss=0.00263, val_loss=0.00317]Epoch 31:  96%|█████████▋| 27/28 [00:00<00:00, 137.61it/s, train_loss=0.00263, val_loss=0.00317]Epoch 31:  96%|█████████▋| 27/28 [00:00<00:00, 135.61it/s, train_loss=0.00271, val_loss=0.00317]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 137.48it/s, train_loss=0.00271, val_loss=0.00317]Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 136.43it/s, train_loss=0.00179, val_loss=0.00317]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 153.77it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 178.00it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 193.75it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 200.52it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 207.16it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 211.66it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 214.79it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 222.66it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 230.65it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 238.30it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 245.15it/s][A
                                                                         [AEpoch 31: 100%|██████████| 28/28 [00:00<00:00, 109.12it/s, train_loss=0.00179, val_loss=0.0032] Epoch 31: 100%|██████████| 28/28 [00:00<00:00, 108.85it/s, train_loss=0.00179, val_loss=0.0032]Epoch 31:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00179, val_loss=0.0032]          Epoch 32:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00179, val_loss=0.0032]Epoch 32:   4%|▎         | 1/28 [00:00<00:00, 174.61it/s, train_loss=0.00179, val_loss=0.0032]Epoch 32:   4%|▎         | 1/28 [00:00<00:00, 135.20it/s, train_loss=0.00252, val_loss=0.0032]Epoch 32:   7%|▋         | 2/28 [00:00<00:00, 167.19it/s, train_loss=0.00252, val_loss=0.0032]Epoch 32:   7%|▋         | 2/28 [00:00<00:00, 144.86it/s, train_loss=0.00255, val_loss=0.0032]Epoch 32:  11%|█         | 3/28 [00:00<00:00, 159.28it/s, train_loss=0.00255, val_loss=0.0032]Epoch 32:  11%|█         | 3/28 [00:00<00:00, 144.87it/s, train_loss=0.00239, val_loss=0.0032]Epoch 32:  14%|█▍        | 4/28 [00:00<00:00, 157.01it/s, train_loss=0.00239, val_loss=0.0032]Epoch 32:  14%|█▍        | 4/28 [00:00<00:00, 146.84it/s, train_loss=0.00233, val_loss=0.0032]Epoch 32:  18%|█▊        | 5/28 [00:00<00:00, 158.44it/s, train_loss=0.00233, val_loss=0.0032]Epoch 32:  18%|█▊        | 5/28 [00:00<00:00, 149.45it/s, train_loss=0.00252, val_loss=0.0032]Epoch 32:  21%|██▏       | 6/28 [00:00<00:00, 157.51it/s, train_loss=0.00252, val_loss=0.0032]Epoch 32:  21%|██▏       | 6/28 [00:00<00:00, 149.01it/s, train_loss=0.00294, val_loss=0.0032]Epoch 32:  25%|██▌       | 7/28 [00:00<00:00, 154.81it/s, train_loss=0.00294, val_loss=0.0032]Epoch 32:  25%|██▌       | 7/28 [00:00<00:00, 148.78it/s, train_loss=0.00272, val_loss=0.0032]Epoch 32:  29%|██▊       | 8/28 [00:00<00:00, 154.98it/s, train_loss=0.00272, val_loss=0.0032]Epoch 32:  29%|██▊       | 8/28 [00:00<00:00, 143.31it/s, train_loss=0.00256, val_loss=0.0032]Epoch 32:  32%|███▏      | 9/28 [00:00<00:00, 147.38it/s, train_loss=0.00256, val_loss=0.0032]Epoch 32:  32%|███▏      | 9/28 [00:00<00:00, 143.37it/s, train_loss=0.0027, val_loss=0.0032] Epoch 32:  36%|███▌      | 10/28 [00:00<00:00, 148.20it/s, train_loss=0.0027, val_loss=0.0032]Epoch 32:  36%|███▌      | 10/28 [00:00<00:00, 140.85it/s, train_loss=0.00258, val_loss=0.0032]Epoch 32:  39%|███▉      | 11/28 [00:00<00:00, 144.29it/s, train_loss=0.00258, val_loss=0.0032]Epoch 32:  39%|███▉      | 11/28 [00:00<00:00, 141.05it/s, train_loss=0.00261, val_loss=0.0032]Epoch 32:  43%|████▎     | 12/28 [00:00<00:00, 145.39it/s, train_loss=0.00261, val_loss=0.0032]Epoch 32:  43%|████▎     | 12/28 [00:00<00:00, 139.26it/s, train_loss=0.00204, val_loss=0.0032]Epoch 32:  46%|████▋     | 13/28 [00:00<00:00, 142.75it/s, train_loss=0.00204, val_loss=0.0032]Epoch 32:  46%|████▋     | 13/28 [00:00<00:00, 139.92it/s, train_loss=0.00319, val_loss=0.0032]Epoch 32:  50%|█████     | 14/28 [00:00<00:00, 143.74it/s, train_loss=0.00319, val_loss=0.0032]Epoch 32:  50%|█████     | 14/28 [00:00<00:00, 138.38it/s, train_loss=0.00228, val_loss=0.0032]Epoch 32:  54%|█████▎    | 15/28 [00:00<00:00, 141.37it/s, train_loss=0.00228, val_loss=0.0032]Epoch 32:  54%|█████▎    | 15/28 [00:00<00:00, 139.08it/s, train_loss=0.00266, val_loss=0.0032]Epoch 32:  57%|█████▋    | 16/28 [00:00<00:00, 142.07it/s, train_loss=0.00266, val_loss=0.0032]Epoch 32:  57%|█████▋    | 16/28 [00:00<00:00, 137.55it/s, train_loss=0.00225, val_loss=0.0032]Epoch 32:  61%|██████    | 17/28 [00:00<00:00, 140.34it/s, train_loss=0.00225, val_loss=0.0032]Epoch 32:  61%|██████    | 17/28 [00:00<00:00, 138.13it/s, train_loss=0.00296, val_loss=0.0032]Epoch 32:  64%|██████▍   | 18/28 [00:00<00:00, 141.65it/s, train_loss=0.00296, val_loss=0.0032]Epoch 32:  64%|██████▍   | 18/28 [00:00<00:00, 137.01it/s, train_loss=0.00239, val_loss=0.0032]Epoch 32:  68%|██████▊   | 19/28 [00:00<00:00, 139.79it/s, train_loss=0.00239, val_loss=0.0032]Epoch 32:  68%|██████▊   | 19/28 [00:00<00:00, 137.98it/s, train_loss=0.00265, val_loss=0.0032]Epoch 32:  71%|███████▏  | 20/28 [00:00<00:00, 141.00it/s, train_loss=0.00265, val_loss=0.0032]Epoch 32:  71%|███████▏  | 20/28 [00:00<00:00, 139.05it/s, train_loss=0.00256, val_loss=0.0032]Epoch 32:  75%|███████▌  | 21/28 [00:00<00:00, 141.97it/s, train_loss=0.00256, val_loss=0.0032]Epoch 32:  75%|███████▌  | 21/28 [00:00<00:00, 139.35it/s, train_loss=0.00235, val_loss=0.0032]Epoch 32:  79%|███████▊  | 22/28 [00:00<00:00, 141.63it/s, train_loss=0.00235, val_loss=0.0032]Epoch 32:  79%|███████▊  | 22/28 [00:00<00:00, 139.97it/s, train_loss=0.00224, val_loss=0.0032]Epoch 32:  82%|████████▏ | 23/28 [00:00<00:00, 142.44it/s, train_loss=0.00224, val_loss=0.0032]Epoch 32:  82%|████████▏ | 23/28 [00:00<00:00, 140.82it/s, train_loss=0.00258, val_loss=0.0032]Epoch 32:  86%|████████▌ | 24/28 [00:00<00:00, 143.23it/s, train_loss=0.00258, val_loss=0.0032]Epoch 32:  86%|████████▌ | 24/28 [00:00<00:00, 141.06it/s, train_loss=0.00258, val_loss=0.0032]Epoch 32:  89%|████████▉ | 25/28 [00:00<00:00, 143.00it/s, train_loss=0.00258, val_loss=0.0032]Epoch 32:  89%|████████▉ | 25/28 [00:00<00:00, 141.50it/s, train_loss=0.00269, val_loss=0.0032]Epoch 32:  93%|█████████▎| 26/28 [00:00<00:00, 143.69it/s, train_loss=0.00269, val_loss=0.0032]Epoch 32:  93%|█████████▎| 26/28 [00:00<00:00, 140.56it/s, train_loss=0.00276, val_loss=0.0032]Epoch 32:  96%|█████████▋| 27/28 [00:00<00:00, 142.19it/s, train_loss=0.00276, val_loss=0.0032]Epoch 32:  96%|█████████▋| 27/28 [00:00<00:00, 140.89it/s, train_loss=0.00275, val_loss=0.0032]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 142.84it/s, train_loss=0.00275, val_loss=0.0032]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 141.54it/s, train_loss=0.00175, val_loss=0.0032]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 173.33it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 203.35it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 217.89it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 222.36it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 213.93it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 216.35it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 220.20it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 223.07it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 224.73it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 223.70it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 222.87it/s][A
                                                                         [AEpoch 32: 100%|██████████| 28/28 [00:00<00:00, 109.55it/s, train_loss=0.00175, val_loss=0.00316]Epoch 32: 100%|██████████| 28/28 [00:00<00:00, 109.09it/s, train_loss=0.00175, val_loss=0.00316]Epoch 32:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00175, val_loss=0.00316]          Epoch 33:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00175, val_loss=0.00316]Epoch 33:   4%|▎         | 1/28 [00:00<00:00, 189.00it/s, train_loss=0.00175, val_loss=0.00316]Epoch 33:   4%|▎         | 1/28 [00:00<00:00, 145.39it/s, train_loss=0.00229, val_loss=0.00316]Epoch 33:   7%|▋         | 2/28 [00:00<00:00, 174.50it/s, train_loss=0.00229, val_loss=0.00316]Epoch 33:   7%|▋         | 2/28 [00:00<00:00, 135.67it/s, train_loss=0.00257, val_loss=0.00316]Epoch 33:  11%|█         | 3/28 [00:00<00:00, 155.20it/s, train_loss=0.00257, val_loss=0.00316]Epoch 33:  11%|█         | 3/28 [00:00<00:00, 142.40it/s, train_loss=0.00252, val_loss=0.00316]Epoch 33:  14%|█▍        | 4/28 [00:00<00:00, 158.73it/s, train_loss=0.00252, val_loss=0.00316]Epoch 33:  14%|█▍        | 4/28 [00:00<00:00, 135.11it/s, train_loss=0.00284, val_loss=0.00316]Epoch 33:  18%|█▊        | 5/28 [00:00<00:00, 145.23it/s, train_loss=0.00284, val_loss=0.00316]Epoch 33:  18%|█▊        | 5/28 [00:00<00:00, 138.68it/s, train_loss=0.00246, val_loss=0.00316]Epoch 33:  21%|██▏       | 6/28 [00:00<00:00, 148.41it/s, train_loss=0.00246, val_loss=0.00316]Epoch 33:  21%|██▏       | 6/28 [00:00<00:00, 134.55it/s, train_loss=0.00237, val_loss=0.00316]Epoch 33:  25%|██▌       | 7/28 [00:00<00:00, 141.27it/s, train_loss=0.00237, val_loss=0.00316]Epoch 33:  25%|██▌       | 7/28 [00:00<00:00, 136.35it/s, train_loss=0.00237, val_loss=0.00316]Epoch 33:  29%|██▊       | 8/28 [00:00<00:00, 143.58it/s, train_loss=0.00237, val_loss=0.00316]Epoch 33:  29%|██▊       | 8/28 [00:00<00:00, 133.84it/s, train_loss=0.00237, val_loss=0.00316]Epoch 33:  32%|███▏      | 9/28 [00:00<00:00, 139.08it/s, train_loss=0.00237, val_loss=0.00316]Epoch 33:  32%|███▏      | 9/28 [00:00<00:00, 135.19it/s, train_loss=0.00254, val_loss=0.00316]Epoch 33:  36%|███▌      | 10/28 [00:00<00:00, 140.76it/s, train_loss=0.00254, val_loss=0.00316]Epoch 33:  36%|███▌      | 10/28 [00:00<00:00, 133.60it/s, train_loss=0.00216, val_loss=0.00316]Epoch 33:  39%|███▉      | 11/28 [00:00<00:00, 137.82it/s, train_loss=0.00216, val_loss=0.00316]Epoch 33:  39%|███▉      | 11/28 [00:00<00:00, 134.75it/s, train_loss=0.00262, val_loss=0.00316]Epoch 33:  43%|████▎     | 12/28 [00:00<00:00, 139.34it/s, train_loss=0.00262, val_loss=0.00316]Epoch 33:  43%|████▎     | 12/28 [00:00<00:00, 133.47it/s, train_loss=0.00247, val_loss=0.00316]Epoch 33:  46%|████▋     | 13/28 [00:00<00:00, 136.98it/s, train_loss=0.00247, val_loss=0.00316]Epoch 33:  46%|████▋     | 13/28 [00:00<00:00, 134.42it/s, train_loss=0.00275, val_loss=0.00316]Epoch 33:  50%|█████     | 14/28 [00:00<00:00, 138.29it/s, train_loss=0.00275, val_loss=0.00316]Epoch 33:  50%|█████     | 14/28 [00:00<00:00, 132.99it/s, train_loss=0.00274, val_loss=0.00316]Epoch 33:  54%|█████▎    | 15/28 [00:00<00:00, 135.94it/s, train_loss=0.00274, val_loss=0.00316]Epoch 33:  54%|█████▎    | 15/28 [00:00<00:00, 133.71it/s, train_loss=0.0026, val_loss=0.00316] Epoch 33:  57%|█████▋    | 16/28 [00:00<00:00, 137.05it/s, train_loss=0.0026, val_loss=0.00316]Epoch 33:  57%|█████▋    | 16/28 [00:00<00:00, 132.69it/s, train_loss=0.00229, val_loss=0.00316]Epoch 33:  61%|██████    | 17/28 [00:00<00:00, 134.83it/s, train_loss=0.00229, val_loss=0.00316]Epoch 33:  61%|██████    | 17/28 [00:00<00:00, 133.03it/s, train_loss=0.00273, val_loss=0.00316]Epoch 33:  64%|██████▍   | 18/28 [00:00<00:00, 135.40it/s, train_loss=0.00273, val_loss=0.00316]Epoch 33:  64%|██████▍   | 18/28 [00:00<00:00, 132.32it/s, train_loss=0.00248, val_loss=0.00316]Epoch 33:  68%|██████▊   | 19/28 [00:00<00:00, 134.67it/s, train_loss=0.00248, val_loss=0.00316]Epoch 33:  68%|██████▊   | 19/28 [00:00<00:00, 132.98it/s, train_loss=0.00235, val_loss=0.00316]Epoch 33:  71%|███████▏  | 20/28 [00:00<00:00, 136.09it/s, train_loss=0.00235, val_loss=0.00316]Epoch 33:  71%|███████▏  | 20/28 [00:00<00:00, 132.30it/s, train_loss=0.00299, val_loss=0.00316]Epoch 33:  75%|███████▌  | 21/28 [00:00<00:00, 134.69it/s, train_loss=0.00299, val_loss=0.00316]Epoch 33:  75%|███████▌  | 21/28 [00:00<00:00, 133.13it/s, train_loss=0.00228, val_loss=0.00316]Epoch 33:  79%|███████▊  | 22/28 [00:00<00:00, 135.76it/s, train_loss=0.00228, val_loss=0.00316]Epoch 33:  79%|███████▊  | 22/28 [00:00<00:00, 132.27it/s, train_loss=0.00267, val_loss=0.00316]Epoch 33:  82%|████████▏ | 23/28 [00:00<00:00, 134.22it/s, train_loss=0.00267, val_loss=0.00316]Epoch 33:  82%|████████▏ | 23/28 [00:00<00:00, 132.90it/s, train_loss=0.00232, val_loss=0.00316]Epoch 33:  86%|████████▌ | 24/28 [00:00<00:00, 135.27it/s, train_loss=0.00232, val_loss=0.00316]Epoch 33:  86%|████████▌ | 24/28 [00:00<00:00, 132.25it/s, train_loss=0.00269, val_loss=0.00316]Epoch 33:  89%|████████▉ | 25/28 [00:00<00:00, 134.12it/s, train_loss=0.00269, val_loss=0.00316]Epoch 33:  89%|████████▉ | 25/28 [00:00<00:00, 132.93it/s, train_loss=0.00344, val_loss=0.00316]Epoch 33:  93%|█████████▎| 26/28 [00:00<00:00, 135.08it/s, train_loss=0.00344, val_loss=0.00316]Epoch 33:  93%|█████████▎| 26/28 [00:00<00:00, 132.23it/s, train_loss=0.00249, val_loss=0.00316]Epoch 33:  96%|█████████▋| 27/28 [00:00<00:00, 133.87it/s, train_loss=0.00249, val_loss=0.00316]Epoch 33:  96%|█████████▋| 27/28 [00:00<00:00, 132.70it/s, train_loss=0.00238, val_loss=0.00316]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 134.76it/s, train_loss=0.00238, val_loss=0.00316]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 132.27it/s, train_loss=0.00257, val_loss=0.00316]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 173.05it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 206.07it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 220.92it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 229.27it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 235.52it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 238.84it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 240.95it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 242.46it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 243.35it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 244.42it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 244.55it/s][A
                                                                         [AEpoch 33: 100%|██████████| 28/28 [00:00<00:00, 105.94it/s, train_loss=0.00257, val_loss=0.00312]Epoch 33: 100%|██████████| 28/28 [00:00<00:00, 105.56it/s, train_loss=0.00257, val_loss=0.00312]Epoch 33:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00257, val_loss=0.00312]          Epoch 34:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00257, val_loss=0.00312]Epoch 34:   4%|▎         | 1/28 [00:00<00:00, 161.19it/s, train_loss=0.00257, val_loss=0.00312]Epoch 34:   4%|▎         | 1/28 [00:00<00:00, 126.30it/s, train_loss=0.00233, val_loss=0.00312]Epoch 34:   7%|▋         | 2/28 [00:00<00:00, 152.20it/s, train_loss=0.00233, val_loss=0.00312]Epoch 34:   7%|▋         | 2/28 [00:00<00:00, 125.71it/s, train_loss=0.00291, val_loss=0.00312]Epoch 34:  11%|█         | 3/28 [00:00<00:00, 146.69it/s, train_loss=0.00291, val_loss=0.00312]Epoch 34:  11%|█         | 3/28 [00:00<00:00, 135.35it/s, train_loss=0.00239, val_loss=0.00312]Epoch 34:  14%|█▍        | 4/28 [00:00<00:00, 152.51it/s, train_loss=0.00239, val_loss=0.00312]Epoch 34:  14%|█▍        | 4/28 [00:00<00:00, 132.03it/s, train_loss=0.00276, val_loss=0.00312]Epoch 34:  18%|█▊        | 5/28 [00:00<00:00, 141.18it/s, train_loss=0.00276, val_loss=0.00312]Epoch 34:  18%|█▊        | 5/28 [00:00<00:00, 134.71it/s, train_loss=0.00267, val_loss=0.00312]Epoch 34:  21%|██▏       | 6/28 [00:00<00:00, 144.46it/s, train_loss=0.00267, val_loss=0.00312]Epoch 34:  21%|██▏       | 6/28 [00:00<00:00, 138.59it/s, train_loss=0.00281, val_loss=0.00312]Epoch 34:  25%|██▌       | 7/28 [00:00<00:00, 147.39it/s, train_loss=0.00281, val_loss=0.00312]Epoch 34:  25%|██▌       | 7/28 [00:00<00:00, 135.33it/s, train_loss=0.00215, val_loss=0.00312]Epoch 34:  29%|██▊       | 8/28 [00:00<00:00, 141.07it/s, train_loss=0.00215, val_loss=0.00312]Epoch 34:  29%|██▊       | 8/28 [00:00<00:00, 136.63it/s, train_loss=0.003, val_loss=0.00312]  Epoch 34:  32%|███▏      | 9/28 [00:00<00:00, 142.93it/s, train_loss=0.003, val_loss=0.00312]Epoch 34:  32%|███▏      | 9/28 [00:00<00:00, 133.78it/s, train_loss=0.00223, val_loss=0.00312]Epoch 34:  36%|███▌      | 10/28 [00:00<00:00, 138.25it/s, train_loss=0.00223, val_loss=0.00312]Epoch 34:  36%|███▌      | 10/28 [00:00<00:00, 134.95it/s, train_loss=0.00238, val_loss=0.00312]Epoch 34:  39%|███▉      | 11/28 [00:00<00:00, 140.01it/s, train_loss=0.00238, val_loss=0.00312]Epoch 34:  39%|███▉      | 11/28 [00:00<00:00, 133.13it/s, train_loss=0.00254, val_loss=0.00312]Epoch 34:  43%|████▎     | 12/28 [00:00<00:00, 137.36it/s, train_loss=0.00254, val_loss=0.00312]Epoch 34:  43%|████▎     | 12/28 [00:00<00:00, 134.49it/s, train_loss=0.00252, val_loss=0.00312]Epoch 34:  46%|████▋     | 13/28 [00:00<00:00, 138.79it/s, train_loss=0.00252, val_loss=0.00312]Epoch 34:  46%|████▋     | 13/28 [00:00<00:00, 132.96it/s, train_loss=0.00245, val_loss=0.00312]Epoch 34:  50%|█████     | 14/28 [00:00<00:00, 136.31it/s, train_loss=0.00245, val_loss=0.00312]Epoch 34:  50%|█████     | 14/28 [00:00<00:00, 134.06it/s, train_loss=0.00241, val_loss=0.00312]Epoch 34:  54%|█████▎    | 15/28 [00:00<00:00, 137.77it/s, train_loss=0.00241, val_loss=0.00312]Epoch 34:  54%|█████▎    | 15/28 [00:00<00:00, 135.47it/s, train_loss=0.0022, val_loss=0.00312] Epoch 34:  57%|█████▋    | 16/28 [00:00<00:00, 138.84it/s, train_loss=0.0022, val_loss=0.00312]Epoch 34:  57%|█████▋    | 16/28 [00:00<00:00, 136.09it/s, train_loss=0.00247, val_loss=0.00312]Epoch 34:  61%|██████    | 17/28 [00:00<00:00, 138.68it/s, train_loss=0.00247, val_loss=0.00312]Epoch 34:  61%|██████    | 17/28 [00:00<00:00, 136.75it/s, train_loss=0.00275, val_loss=0.00312]Epoch 34:  64%|██████▍   | 18/28 [00:00<00:00, 139.64it/s, train_loss=0.00275, val_loss=0.00312]Epoch 34:  64%|██████▍   | 18/28 [00:00<00:00, 135.34it/s, train_loss=0.00251, val_loss=0.00312]Epoch 34:  68%|██████▊   | 19/28 [00:00<00:00, 137.14it/s, train_loss=0.00251, val_loss=0.00312]Epoch 34:  68%|██████▊   | 19/28 [00:00<00:00, 135.52it/s, train_loss=0.00257, val_loss=0.00312]Epoch 34:  71%|███████▏  | 20/28 [00:00<00:00, 137.85it/s, train_loss=0.00257, val_loss=0.00312]Epoch 34:  71%|███████▏  | 20/28 [00:00<00:00, 136.12it/s, train_loss=0.00303, val_loss=0.00312]Epoch 34:  75%|███████▌  | 21/28 [00:00<00:00, 138.31it/s, train_loss=0.00303, val_loss=0.00312]Epoch 34:  75%|███████▌  | 21/28 [00:00<00:00, 135.57it/s, train_loss=0.00273, val_loss=0.00312]Epoch 34:  79%|███████▊  | 22/28 [00:00<00:00, 138.08it/s, train_loss=0.00273, val_loss=0.00312]Epoch 34:  79%|███████▊  | 22/28 [00:00<00:00, 136.47it/s, train_loss=0.00247, val_loss=0.00312]Epoch 34:  82%|████████▏ | 23/28 [00:00<00:00, 139.31it/s, train_loss=0.00247, val_loss=0.00312]Epoch 34:  82%|████████▏ | 23/28 [00:00<00:00, 137.68it/s, train_loss=0.00224, val_loss=0.00312]Epoch 34:  86%|████████▌ | 24/28 [00:00<00:00, 139.89it/s, train_loss=0.00224, val_loss=0.00312]Epoch 34:  86%|████████▌ | 24/28 [00:00<00:00, 137.65it/s, train_loss=0.0023, val_loss=0.00312] Epoch 34:  89%|████████▉ | 25/28 [00:00<00:00, 139.99it/s, train_loss=0.0023, val_loss=0.00312]Epoch 34:  89%|████████▉ | 25/28 [00:00<00:00, 138.55it/s, train_loss=0.00217, val_loss=0.00312]Epoch 34:  93%|█████████▎| 26/28 [00:00<00:00, 140.95it/s, train_loss=0.00217, val_loss=0.00312]Epoch 34:  93%|█████████▎| 26/28 [00:00<00:00, 139.50it/s, train_loss=0.00259, val_loss=0.00312]Epoch 34:  96%|█████████▋| 27/28 [00:00<00:00, 141.35it/s, train_loss=0.00259, val_loss=0.00312]Epoch 34:  96%|█████████▋| 27/28 [00:00<00:00, 139.40it/s, train_loss=0.00281, val_loss=0.00312]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 141.43it/s, train_loss=0.00281, val_loss=0.00312]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 140.26it/s, train_loss=0.00337, val_loss=0.00312]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 171.11it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 207.28it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 217.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 225.01it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 231.62it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 234.88it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 238.27it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 239.43it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 240.74it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 241.68it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 241.12it/s][A
                                                                         [AEpoch 34: 100%|██████████| 28/28 [00:00<00:00, 110.72it/s, train_loss=0.00337, val_loss=0.00313]Epoch 34: 100%|██████████| 28/28 [00:00<00:00, 110.32it/s, train_loss=0.00337, val_loss=0.00313]Epoch 34:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00337, val_loss=0.00313]          Epoch 35:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00337, val_loss=0.00313]Epoch 35:   4%|▎         | 1/28 [00:00<00:00, 156.77it/s, train_loss=0.00337, val_loss=0.00313]Epoch 35:   4%|▎         | 1/28 [00:00<00:00, 124.98it/s, train_loss=0.00291, val_loss=0.00313]Epoch 35:   7%|▋         | 2/28 [00:00<00:00, 158.27it/s, train_loss=0.00291, val_loss=0.00313]Epoch 35:   7%|▋         | 2/28 [00:00<00:00, 137.79it/s, train_loss=0.00265, val_loss=0.00313]Epoch 35:  11%|█         | 3/28 [00:00<00:00, 158.31it/s, train_loss=0.00265, val_loss=0.00313]Epoch 35:  11%|█         | 3/28 [00:00<00:00, 140.52it/s, train_loss=0.00274, val_loss=0.00313]Epoch 35:  14%|█▍        | 4/28 [00:00<00:00, 152.60it/s, train_loss=0.00274, val_loss=0.00313]Epoch 35:  14%|█▍        | 4/28 [00:00<00:00, 142.28it/s, train_loss=0.00253, val_loss=0.00313]Epoch 35:  18%|█▊        | 5/28 [00:00<00:00, 155.01it/s, train_loss=0.00253, val_loss=0.00313]Epoch 35:  18%|█▊        | 5/28 [00:00<00:00, 145.90it/s, train_loss=0.0021, val_loss=0.00313] Epoch 35:  21%|██▏       | 6/28 [00:00<00:00, 155.00it/s, train_loss=0.0021, val_loss=0.00313]Epoch 35:  21%|██▏       | 6/28 [00:00<00:00, 144.80it/s, train_loss=0.0029, val_loss=0.00313]Epoch 35:  25%|██▌       | 7/28 [00:00<00:00, 152.48it/s, train_loss=0.0029, val_loss=0.00313]Epoch 35:  25%|██▌       | 7/28 [00:00<00:00, 146.98it/s, train_loss=0.00251, val_loss=0.00313]Epoch 35:  29%|██▊       | 8/28 [00:00<00:00, 154.76it/s, train_loss=0.00251, val_loss=0.00313]Epoch 35:  29%|██▊       | 8/28 [00:00<00:00, 149.24it/s, train_loss=0.00297, val_loss=0.00313]Epoch 35:  32%|███▏      | 9/28 [00:00<00:00, 154.20it/s, train_loss=0.00297, val_loss=0.00313]Epoch 35:  32%|███▏      | 9/28 [00:00<00:00, 147.68it/s, train_loss=0.00269, val_loss=0.00313]Epoch 35:  36%|███▌      | 10/28 [00:00<00:00, 152.41it/s, train_loss=0.00269, val_loss=0.00313]Epoch 35:  36%|███▌      | 10/28 [00:00<00:00, 148.23it/s, train_loss=0.0021, val_loss=0.00313] Epoch 35:  39%|███▉      | 11/28 [00:00<00:00, 153.44it/s, train_loss=0.0021, val_loss=0.00313]Epoch 35:  39%|███▉      | 11/28 [00:00<00:00, 149.27it/s, train_loss=0.0025, val_loss=0.00313]Epoch 35:  43%|████▎     | 12/28 [00:00<00:00, 153.99it/s, train_loss=0.0025, val_loss=0.00313]Epoch 35:  43%|████▎     | 12/28 [00:00<00:00, 148.98it/s, train_loss=0.00251, val_loss=0.00313]Epoch 35:  46%|████▋     | 13/28 [00:00<00:00, 152.18it/s, train_loss=0.00251, val_loss=0.00313]Epoch 35:  46%|████▋     | 13/28 [00:00<00:00, 149.20it/s, train_loss=0.00231, val_loss=0.00313]Epoch 35:  50%|█████     | 14/28 [00:00<00:00, 148.13it/s, train_loss=0.00231, val_loss=0.00313]Epoch 35:  50%|█████     | 14/28 [00:00<00:00, 145.65it/s, train_loss=0.00261, val_loss=0.00313]Epoch 35:  54%|█████▎    | 15/28 [00:00<00:00, 148.64it/s, train_loss=0.00261, val_loss=0.00313]Epoch 35:  54%|█████▎    | 15/28 [00:00<00:00, 146.05it/s, train_loss=0.00244, val_loss=0.00313]Epoch 35:  57%|█████▋    | 16/28 [00:00<00:00, 149.60it/s, train_loss=0.00244, val_loss=0.00313]Epoch 35:  57%|█████▋    | 16/28 [00:00<00:00, 146.82it/s, train_loss=0.00239, val_loss=0.00313]Epoch 35:  61%|██████    | 17/28 [00:00<00:00, 147.26it/s, train_loss=0.00239, val_loss=0.00313]Epoch 35:  61%|██████    | 17/28 [00:00<00:00, 145.04it/s, train_loss=0.00266, val_loss=0.00313]Epoch 35:  64%|██████▍   | 18/28 [00:00<00:00, 147.62it/s, train_loss=0.00266, val_loss=0.00313]Epoch 35:  64%|██████▍   | 18/28 [00:00<00:00, 145.53it/s, train_loss=0.00242, val_loss=0.00313]Epoch 35:  68%|██████▊   | 19/28 [00:00<00:00, 148.39it/s, train_loss=0.00242, val_loss=0.00313]Epoch 35:  68%|██████▊   | 19/28 [00:00<00:00, 144.02it/s, train_loss=0.0022, val_loss=0.00313] Epoch 35:  71%|███████▏  | 20/28 [00:00<00:00, 146.17it/s, train_loss=0.0022, val_loss=0.00313]Epoch 35:  71%|███████▏  | 20/28 [00:00<00:00, 144.31it/s, train_loss=0.0024, val_loss=0.00313]Epoch 35:  75%|███████▌  | 21/28 [00:00<00:00, 146.76it/s, train_loss=0.0024, val_loss=0.00313]Epoch 35:  75%|███████▌  | 21/28 [00:00<00:00, 142.79it/s, train_loss=0.00236, val_loss=0.00313]Epoch 35:  79%|███████▊  | 22/28 [00:00<00:00, 144.36it/s, train_loss=0.00236, val_loss=0.00313]Epoch 35:  79%|███████▊  | 22/28 [00:00<00:00, 142.77it/s, train_loss=0.00216, val_loss=0.00313]Epoch 35:  82%|████████▏ | 23/28 [00:00<00:00, 144.82it/s, train_loss=0.00216, val_loss=0.00313]Epoch 35:  82%|████████▏ | 23/28 [00:00<00:00, 143.08it/s, train_loss=0.00227, val_loss=0.00313]Epoch 35:  86%|████████▌ | 24/28 [00:00<00:00, 145.19it/s, train_loss=0.00227, val_loss=0.00313]Epoch 35:  86%|████████▌ | 24/28 [00:00<00:00, 141.76it/s, train_loss=0.00342, val_loss=0.00313]Epoch 35:  89%|████████▉ | 25/28 [00:00<00:00, 143.84it/s, train_loss=0.00342, val_loss=0.00313]Epoch 35:  89%|████████▉ | 25/28 [00:00<00:00, 142.22it/s, train_loss=0.00263, val_loss=0.00313]Epoch 35:  93%|█████████▎| 26/28 [00:00<00:00, 144.41it/s, train_loss=0.00263, val_loss=0.00313]Epoch 35:  93%|█████████▎| 26/28 [00:00<00:00, 142.89it/s, train_loss=0.00289, val_loss=0.00313]Epoch 35:  96%|█████████▋| 27/28 [00:00<00:00, 144.63it/s, train_loss=0.00289, val_loss=0.00313]Epoch 35:  96%|█████████▋| 27/28 [00:00<00:00, 142.91it/s, train_loss=0.0022, val_loss=0.00313] Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 144.82it/s, train_loss=0.0022, val_loss=0.00313]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 143.50it/s, train_loss=0.00227, val_loss=0.00313]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 193.61it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 226.41it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 237.70it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 245.28it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 249.13it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 252.17it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 254.45it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 255.75it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 256.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 257.85it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 257.72it/s][A
                                                                         [AEpoch 35: 100%|██████████| 28/28 [00:00<00:00, 114.11it/s, train_loss=0.00227, val_loss=0.00313]Epoch 35: 100%|██████████| 28/28 [00:00<00:00, 113.71it/s, train_loss=0.00227, val_loss=0.00313]Epoch 35:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00313]          Epoch 36:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00313]Epoch 36:   4%|▎         | 1/28 [00:00<00:00, 152.21it/s, train_loss=0.00227, val_loss=0.00313]Epoch 36:   4%|▎         | 1/28 [00:00<00:00, 107.15it/s, train_loss=0.0025, val_loss=0.00313] Epoch 36:   7%|▋         | 2/28 [00:00<00:00, 134.13it/s, train_loss=0.0025, val_loss=0.00313]Epoch 36:   7%|▋         | 2/28 [00:00<00:00, 122.97it/s, train_loss=0.00239, val_loss=0.00313]Epoch 36:  11%|█         | 3/28 [00:00<00:00, 140.93it/s, train_loss=0.00239, val_loss=0.00313]Epoch 36:  11%|█         | 3/28 [00:00<00:00, 120.91it/s, train_loss=0.00243, val_loss=0.00313]Epoch 36:  14%|█▍        | 4/28 [00:00<00:00, 134.47it/s, train_loss=0.00243, val_loss=0.00313]Epoch 36:  14%|█▍        | 4/28 [00:00<00:00, 126.58it/s, train_loss=0.00274, val_loss=0.00313]Epoch 36:  18%|█▊        | 5/28 [00:00<00:00, 138.05it/s, train_loss=0.00274, val_loss=0.00313]Epoch 36:  18%|█▊        | 5/28 [00:00<00:00, 124.24it/s, train_loss=0.00274, val_loss=0.00313]Epoch 36:  21%|██▏       | 6/28 [00:00<00:00, 132.29it/s, train_loss=0.00274, val_loss=0.00313]Epoch 36:  21%|██▏       | 6/28 [00:00<00:00, 126.84it/s, train_loss=0.00248, val_loss=0.00313]Epoch 36:  25%|██▌       | 7/28 [00:00<00:00, 134.57it/s, train_loss=0.00248, val_loss=0.00313]Epoch 36:  25%|██▌       | 7/28 [00:00<00:00, 125.40it/s, train_loss=0.00224, val_loss=0.00313]Epoch 36:  29%|██▊       | 8/28 [00:00<00:00, 132.58it/s, train_loss=0.00224, val_loss=0.00313]Epoch 36:  29%|██▊       | 8/28 [00:00<00:00, 128.43it/s, train_loss=0.00241, val_loss=0.00313]Epoch 36:  32%|███▏      | 9/28 [00:00<00:00, 135.22it/s, train_loss=0.00241, val_loss=0.00313]Epoch 36:  32%|███▏      | 9/28 [00:00<00:00, 131.23it/s, train_loss=0.00232, val_loss=0.00313]Epoch 36:  36%|███▌      | 10/28 [00:00<00:00, 137.47it/s, train_loss=0.00232, val_loss=0.00313]Epoch 36:  36%|███▌      | 10/28 [00:00<00:00, 131.93it/s, train_loss=0.00239, val_loss=0.00313]Epoch 36:  39%|███▉      | 11/28 [00:00<00:00, 137.14it/s, train_loss=0.00239, val_loss=0.00313]Epoch 36:  39%|███▉      | 11/28 [00:00<00:00, 133.73it/s, train_loss=0.00246, val_loss=0.00313]Epoch 36:  43%|████▎     | 12/28 [00:00<00:00, 139.03it/s, train_loss=0.00246, val_loss=0.00313]Epoch 36:  43%|████▎     | 12/28 [00:00<00:00, 135.98it/s, train_loss=0.00241, val_loss=0.00313]Epoch 36:  46%|████▋     | 13/28 [00:00<00:00, 140.24it/s, train_loss=0.00241, val_loss=0.00313]Epoch 36:  46%|████▋     | 13/28 [00:00<00:00, 136.09it/s, train_loss=0.00287, val_loss=0.00313]Epoch 36:  50%|█████     | 14/28 [00:00<00:00, 139.89it/s, train_loss=0.00287, val_loss=0.00313]Epoch 36:  50%|█████     | 14/28 [00:00<00:00, 137.14it/s, train_loss=0.00265, val_loss=0.00313]Epoch 36:  54%|█████▎    | 15/28 [00:00<00:00, 141.03it/s, train_loss=0.00265, val_loss=0.00313]Epoch 36:  54%|█████▎    | 15/28 [00:00<00:00, 138.43it/s, train_loss=0.00231, val_loss=0.00313]Epoch 36:  57%|█████▋    | 16/28 [00:00<00:00, 142.03it/s, train_loss=0.00231, val_loss=0.00313]Epoch 36:  57%|█████▋    | 16/28 [00:00<00:00, 138.87it/s, train_loss=0.00295, val_loss=0.00313]Epoch 36:  61%|██████    | 17/28 [00:00<00:00, 141.33it/s, train_loss=0.00295, val_loss=0.00313]Epoch 36:  61%|██████    | 17/28 [00:00<00:00, 139.27it/s, train_loss=0.00198, val_loss=0.00313]Epoch 36:  64%|██████▍   | 18/28 [00:00<00:00, 142.37it/s, train_loss=0.00198, val_loss=0.00313]Epoch 36:  64%|██████▍   | 18/28 [00:00<00:00, 137.87it/s, train_loss=0.00255, val_loss=0.00313]Epoch 36:  68%|██████▊   | 19/28 [00:00<00:00, 140.34it/s, train_loss=0.00255, val_loss=0.00313]Epoch 36:  68%|██████▊   | 19/28 [00:00<00:00, 138.55it/s, train_loss=0.00266, val_loss=0.00313]Epoch 36:  71%|███████▏  | 20/28 [00:00<00:00, 141.34it/s, train_loss=0.00266, val_loss=0.00313]Epoch 36:  71%|███████▏  | 20/28 [00:00<00:00, 137.27it/s, train_loss=0.0027, val_loss=0.00313] Epoch 36:  75%|███████▌  | 21/28 [00:00<00:00, 139.47it/s, train_loss=0.0027, val_loss=0.00313]Epoch 36:  75%|███████▌  | 21/28 [00:00<00:00, 137.83it/s, train_loss=0.00291, val_loss=0.00313]Epoch 36:  79%|███████▊  | 22/28 [00:00<00:00, 140.30it/s, train_loss=0.00291, val_loss=0.00313]Epoch 36:  79%|███████▊  | 22/28 [00:00<00:00, 136.86it/s, train_loss=0.00225, val_loss=0.00313]Epoch 36:  82%|████████▏ | 23/28 [00:00<00:00, 138.50it/s, train_loss=0.00225, val_loss=0.00313]Epoch 36:  82%|████████▏ | 23/28 [00:00<00:00, 137.02it/s, train_loss=0.0021, val_loss=0.00313] Epoch 36:  86%|████████▌ | 24/28 [00:00<00:00, 138.97it/s, train_loss=0.0021, val_loss=0.00313]Epoch 36:  86%|████████▌ | 24/28 [00:00<00:00, 137.45it/s, train_loss=0.00312, val_loss=0.00313]Epoch 36:  89%|████████▉ | 25/28 [00:00<00:00, 139.17it/s, train_loss=0.00312, val_loss=0.00313]Epoch 36:  89%|████████▉ | 25/28 [00:00<00:00, 137.21it/s, train_loss=0.00251, val_loss=0.00313]Epoch 36:  93%|█████████▎| 26/28 [00:00<00:00, 138.92it/s, train_loss=0.00251, val_loss=0.00313]Epoch 36:  93%|█████████▎| 26/28 [00:00<00:00, 137.59it/s, train_loss=0.00261, val_loss=0.00313]Epoch 36:  96%|█████████▋| 27/28 [00:00<00:00, 139.84it/s, train_loss=0.00261, val_loss=0.00313]Epoch 36:  96%|█████████▋| 27/28 [00:00<00:00, 136.50it/s, train_loss=0.00249, val_loss=0.00313]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 138.30it/s, train_loss=0.00249, val_loss=0.00313]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 137.21it/s, train_loss=0.00322, val_loss=0.00313]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 204.18it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 242.77it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 257.50it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 259.89it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 265.13it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 268.66it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 266.24it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 260.32it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 258.52it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 258.73it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 259.94it/s][A
                                                                         [AEpoch 36: 100%|██████████| 28/28 [00:00<00:00, 110.07it/s, train_loss=0.00322, val_loss=0.00313]Epoch 36: 100%|██████████| 28/28 [00:00<00:00, 109.68it/s, train_loss=0.00322, val_loss=0.00313]Epoch 36:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00322, val_loss=0.00313]          Epoch 37:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00322, val_loss=0.00313]Epoch 37:   4%|▎         | 1/28 [00:00<00:00, 159.72it/s, train_loss=0.00322, val_loss=0.00313]Epoch 37:   4%|▎         | 1/28 [00:00<00:00, 112.54it/s, train_loss=0.00235, val_loss=0.00313]Epoch 37:   7%|▋         | 2/28 [00:00<00:00, 144.95it/s, train_loss=0.00235, val_loss=0.00313]Epoch 37:   7%|▋         | 2/28 [00:00<00:00, 129.51it/s, train_loss=0.00271, val_loss=0.00313]Epoch 37:  11%|█         | 3/28 [00:00<00:00, 149.98it/s, train_loss=0.00271, val_loss=0.00313]Epoch 37:  11%|█         | 3/28 [00:00<00:00, 125.69it/s, train_loss=0.00274, val_loss=0.00313]Epoch 37:  14%|█▍        | 4/28 [00:00<00:00, 136.60it/s, train_loss=0.00274, val_loss=0.00313]Epoch 37:  14%|█▍        | 4/28 [00:00<00:00, 129.57it/s, train_loss=0.00257, val_loss=0.00313]Epoch 37:  18%|█▊        | 5/28 [00:00<00:00, 140.23it/s, train_loss=0.00257, val_loss=0.00313]Epoch 37:  18%|█▊        | 5/28 [00:00<00:00, 126.33it/s, train_loss=0.00247, val_loss=0.00313]Epoch 37:  21%|██▏       | 6/28 [00:00<00:00, 130.44it/s, train_loss=0.00247, val_loss=0.00313]Epoch 37:  21%|██▏       | 6/28 [00:00<00:00, 125.60it/s, train_loss=0.00255, val_loss=0.00313]Epoch 37:  25%|██▌       | 7/28 [00:00<00:00, 132.52it/s, train_loss=0.00255, val_loss=0.00313]Epoch 37:  25%|██▌       | 7/28 [00:00<00:00, 127.82it/s, train_loss=0.0026, val_loss=0.00313] Epoch 37:  29%|██▊       | 8/28 [00:00<00:00, 133.86it/s, train_loss=0.0026, val_loss=0.00313]Epoch 37:  29%|██▊       | 8/28 [00:00<00:00, 129.98it/s, train_loss=0.00272, val_loss=0.00313]Epoch 37:  32%|███▏      | 9/28 [00:00<00:00, 136.14it/s, train_loss=0.00272, val_loss=0.00313]Epoch 37:  32%|███▏      | 9/28 [00:00<00:00, 128.64it/s, train_loss=0.00226, val_loss=0.00313]Epoch 37:  36%|███▌      | 10/28 [00:00<00:00, 132.70it/s, train_loss=0.00226, val_loss=0.00313]Epoch 37:  36%|███▌      | 10/28 [00:00<00:00, 129.73it/s, train_loss=0.00238, val_loss=0.00313]Epoch 37:  39%|███▉      | 11/28 [00:00<00:00, 135.16it/s, train_loss=0.00238, val_loss=0.00313]Epoch 37:  39%|███▉      | 11/28 [00:00<00:00, 128.36it/s, train_loss=0.0024, val_loss=0.00313] Epoch 37:  43%|████▎     | 12/28 [00:00<00:00, 132.52it/s, train_loss=0.0024, val_loss=0.00313]Epoch 37:  43%|████▎     | 12/28 [00:00<00:00, 129.90it/s, train_loss=0.00238, val_loss=0.00313]Epoch 37:  46%|████▋     | 13/28 [00:00<00:00, 134.43it/s, train_loss=0.00238, val_loss=0.00313]Epoch 37:  46%|████▋     | 13/28 [00:00<00:00, 128.79it/s, train_loss=0.00242, val_loss=0.00313]Epoch 37:  50%|█████     | 14/28 [00:00<00:00, 132.03it/s, train_loss=0.00242, val_loss=0.00313]Epoch 37:  50%|█████     | 14/28 [00:00<00:00, 129.91it/s, train_loss=0.00262, val_loss=0.00313]Epoch 37:  54%|█████▎    | 15/28 [00:00<00:00, 133.55it/s, train_loss=0.00262, val_loss=0.00313]Epoch 37:  54%|█████▎    | 15/28 [00:00<00:00, 131.50it/s, train_loss=0.00259, val_loss=0.00313]Epoch 37:  57%|█████▋    | 16/28 [00:00<00:00, 134.57it/s, train_loss=0.00259, val_loss=0.00313]Epoch 37:  57%|█████▋    | 16/28 [00:00<00:00, 131.12it/s, train_loss=0.00307, val_loss=0.00313]Epoch 37:  61%|██████    | 17/28 [00:00<00:00, 134.01it/s, train_loss=0.00307, val_loss=0.00313]Epoch 37:  61%|██████    | 17/28 [00:00<00:00, 132.27it/s, train_loss=0.00234, val_loss=0.00313]Epoch 37:  64%|██████▍   | 18/28 [00:00<00:00, 135.57it/s, train_loss=0.00234, val_loss=0.00313]Epoch 37:  64%|██████▍   | 18/28 [00:00<00:00, 130.98it/s, train_loss=0.0029, val_loss=0.00313] Epoch 37:  68%|██████▊   | 19/28 [00:00<00:00, 133.33it/s, train_loss=0.0029, val_loss=0.00313]Epoch 37:  68%|██████▊   | 19/28 [00:00<00:00, 131.73it/s, train_loss=0.00252, val_loss=0.00313]Epoch 37:  71%|███████▏  | 20/28 [00:00<00:00, 134.21it/s, train_loss=0.00252, val_loss=0.00313]Epoch 37:  71%|███████▏  | 20/28 [00:00<00:00, 130.65it/s, train_loss=0.00268, val_loss=0.00313]Epoch 37:  75%|███████▌  | 21/28 [00:00<00:00, 132.49it/s, train_loss=0.00268, val_loss=0.00313]Epoch 37:  75%|███████▌  | 21/28 [00:00<00:00, 131.17it/s, train_loss=0.00276, val_loss=0.00313]Epoch 37:  79%|███████▊  | 22/28 [00:00<00:00, 133.45it/s, train_loss=0.00276, val_loss=0.00313]Epoch 37:  79%|███████▊  | 22/28 [00:00<00:00, 130.69it/s, train_loss=0.0022, val_loss=0.00313] Epoch 37:  82%|████████▏ | 23/28 [00:00<00:00, 132.68it/s, train_loss=0.0022, val_loss=0.00313]Epoch 37:  82%|████████▏ | 23/28 [00:00<00:00, 131.41it/s, train_loss=0.00275, val_loss=0.00313]Epoch 37:  86%|████████▌ | 24/28 [00:00<00:00, 133.63it/s, train_loss=0.00275, val_loss=0.00313]Epoch 37:  86%|████████▌ | 24/28 [00:00<00:00, 130.65it/s, train_loss=0.00208, val_loss=0.00313]Epoch 37:  89%|████████▉ | 25/28 [00:00<00:00, 132.35it/s, train_loss=0.00208, val_loss=0.00313]Epoch 37:  89%|████████▉ | 25/28 [00:00<00:00, 131.14it/s, train_loss=0.00251, val_loss=0.00313]Epoch 37:  93%|█████████▎| 26/28 [00:00<00:00, 133.14it/s, train_loss=0.00251, val_loss=0.00313]Epoch 37:  93%|█████████▎| 26/28 [00:00<00:00, 130.50it/s, train_loss=0.00238, val_loss=0.00313]Epoch 37:  96%|█████████▋| 27/28 [00:00<00:00, 132.02it/s, train_loss=0.00238, val_loss=0.00313]Epoch 37:  96%|█████████▋| 27/28 [00:00<00:00, 130.90it/s, train_loss=0.00236, val_loss=0.00313]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 132.84it/s, train_loss=0.00236, val_loss=0.00313]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 130.61it/s, train_loss=0.00227, val_loss=0.00313]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 270.34it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 286.71it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 298.41it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 303.12it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 302.99it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 298.74it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 299.68it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 300.32it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 298.92it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 298.40it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 297.90it/s][A
                                                                         [AEpoch 37: 100%|██████████| 28/28 [00:00<00:00, 108.64it/s, train_loss=0.00227, val_loss=0.00313]Epoch 37: 100%|██████████| 28/28 [00:00<00:00, 108.30it/s, train_loss=0.00227, val_loss=0.00313]Epoch 37:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00313]          Epoch 38:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00227, val_loss=0.00313]Epoch 38:   4%|▎         | 1/28 [00:00<00:00, 172.80it/s, train_loss=0.00227, val_loss=0.00313]Epoch 38:   4%|▎         | 1/28 [00:00<00:00, 104.20it/s, train_loss=0.00277, val_loss=0.00313]Epoch 38:   7%|▋         | 2/28 [00:00<00:00, 136.23it/s, train_loss=0.00277, val_loss=0.00313]Epoch 38:   7%|▋         | 2/28 [00:00<00:00, 122.02it/s, train_loss=0.00271, val_loss=0.00313]Epoch 38:  11%|█         | 3/28 [00:00<00:00, 142.90it/s, train_loss=0.00271, val_loss=0.00313]Epoch 38:  11%|█         | 3/28 [00:00<00:00, 120.04it/s, train_loss=0.00248, val_loss=0.00313]Epoch 38:  14%|█▍        | 4/28 [00:00<00:00, 132.40it/s, train_loss=0.00248, val_loss=0.00313]Epoch 38:  14%|█▍        | 4/28 [00:00<00:00, 125.53it/s, train_loss=0.00242, val_loss=0.00313]Epoch 38:  18%|█▊        | 5/28 [00:00<00:00, 136.67it/s, train_loss=0.00242, val_loss=0.00313]Epoch 38:  18%|█▊        | 5/28 [00:00<00:00, 122.64it/s, train_loss=0.00266, val_loss=0.00313]Epoch 38:  21%|██▏       | 6/28 [00:00<00:00, 130.73it/s, train_loss=0.00266, val_loss=0.00313]Epoch 38:  21%|██▏       | 6/28 [00:00<00:00, 125.88it/s, train_loss=0.00236, val_loss=0.00313]Epoch 38:  25%|██▌       | 7/28 [00:00<00:00, 133.99it/s, train_loss=0.00236, val_loss=0.00313]Epoch 38:  25%|██▌       | 7/28 [00:00<00:00, 124.41it/s, train_loss=0.00242, val_loss=0.00313]Epoch 38:  29%|██▊       | 8/28 [00:00<00:00, 130.03it/s, train_loss=0.00242, val_loss=0.00313]Epoch 38:  29%|██▊       | 8/28 [00:00<00:00, 126.56it/s, train_loss=0.00226, val_loss=0.00313]Epoch 38:  32%|███▏      | 9/28 [00:00<00:00, 132.50it/s, train_loss=0.00226, val_loss=0.00313]Epoch 38:  32%|███▏      | 9/28 [00:00<00:00, 125.50it/s, train_loss=0.00261, val_loss=0.00313]Epoch 38:  36%|███▌      | 10/28 [00:00<00:00, 129.76it/s, train_loss=0.00261, val_loss=0.00313]Epoch 38:  36%|███▌      | 10/28 [00:00<00:00, 127.05it/s, train_loss=0.00262, val_loss=0.00313]Epoch 38:  39%|███▉      | 11/28 [00:00<00:00, 132.13it/s, train_loss=0.00262, val_loss=0.00313]Epoch 38:  39%|███▉      | 11/28 [00:00<00:00, 126.44it/s, train_loss=0.0025, val_loss=0.00313] Epoch 38:  43%|████▎     | 12/28 [00:00<00:00, 130.35it/s, train_loss=0.0025, val_loss=0.00313]Epoch 38:  43%|████▎     | 12/28 [00:00<00:00, 127.91it/s, train_loss=0.00268, val_loss=0.00313]Epoch 38:  46%|████▋     | 13/28 [00:00<00:00, 132.71it/s, train_loss=0.00268, val_loss=0.00313]Epoch 38:  46%|████▋     | 13/28 [00:00<00:00, 127.10it/s, train_loss=0.00283, val_loss=0.00313]Epoch 38:  50%|█████     | 14/28 [00:00<00:00, 130.66it/s, train_loss=0.00283, val_loss=0.00313]Epoch 38:  50%|█████     | 14/28 [00:00<00:00, 128.52it/s, train_loss=0.00239, val_loss=0.00313]Epoch 38:  54%|█████▎    | 15/28 [00:00<00:00, 132.22it/s, train_loss=0.00239, val_loss=0.00313]Epoch 38:  54%|█████▎    | 15/28 [00:00<00:00, 130.21it/s, train_loss=0.00242, val_loss=0.00313]Epoch 38:  57%|█████▋    | 16/28 [00:00<00:00, 133.29it/s, train_loss=0.00242, val_loss=0.00313]Epoch 38:  57%|█████▋    | 16/28 [00:00<00:00, 130.00it/s, train_loss=0.00256, val_loss=0.00313]Epoch 38:  61%|██████    | 17/28 [00:00<00:00, 132.96it/s, train_loss=0.00256, val_loss=0.00313]Epoch 38:  61%|██████    | 17/28 [00:00<00:00, 131.05it/s, train_loss=0.00197, val_loss=0.00313]Epoch 38:  64%|██████▍   | 18/28 [00:00<00:00, 134.24it/s, train_loss=0.00197, val_loss=0.00313]Epoch 38:  64%|██████▍   | 18/28 [00:00<00:00, 130.00it/s, train_loss=0.00231, val_loss=0.00313]Epoch 38:  68%|██████▊   | 19/28 [00:00<00:00, 132.40it/s, train_loss=0.00231, val_loss=0.00313]Epoch 38:  68%|██████▊   | 19/28 [00:00<00:00, 130.79it/s, train_loss=0.00253, val_loss=0.00313]Epoch 38:  71%|███████▏  | 20/28 [00:00<00:00, 133.59it/s, train_loss=0.00253, val_loss=0.00313]Epoch 38:  71%|███████▏  | 20/28 [00:00<00:00, 129.84it/s, train_loss=0.00288, val_loss=0.00313]Epoch 38:  75%|███████▌  | 21/28 [00:00<00:00, 131.91it/s, train_loss=0.00288, val_loss=0.00313]Epoch 38:  75%|███████▌  | 21/28 [00:00<00:00, 130.50it/s, train_loss=0.00195, val_loss=0.00313]Epoch 38:  79%|███████▊  | 22/28 [00:00<00:00, 132.96it/s, train_loss=0.00195, val_loss=0.00313]Epoch 38:  79%|███████▊  | 22/28 [00:00<00:00, 129.78it/s, train_loss=0.00247, val_loss=0.00313]Epoch 38:  82%|████████▏ | 23/28 [00:00<00:00, 131.84it/s, train_loss=0.00247, val_loss=0.00313]Epoch 38:  82%|████████▏ | 23/28 [00:00<00:00, 130.55it/s, train_loss=0.00309, val_loss=0.00313]Epoch 38:  86%|████████▌ | 24/28 [00:00<00:00, 132.81it/s, train_loss=0.00309, val_loss=0.00313]Epoch 38:  86%|████████▌ | 24/28 [00:00<00:00, 129.70it/s, train_loss=0.0024, val_loss=0.00313] Epoch 38:  89%|████████▉ | 25/28 [00:00<00:00, 131.45it/s, train_loss=0.0024, val_loss=0.00313]Epoch 38:  89%|████████▉ | 25/28 [00:00<00:00, 130.23it/s, train_loss=0.00234, val_loss=0.00313]Epoch 38:  93%|█████████▎| 26/28 [00:00<00:00, 132.25it/s, train_loss=0.00234, val_loss=0.00313]Epoch 38:  93%|█████████▎| 26/28 [00:00<00:00, 130.95it/s, train_loss=0.00249, val_loss=0.00313]Epoch 38:  96%|█████████▋| 27/28 [00:00<00:00, 132.64it/s, train_loss=0.00249, val_loss=0.00313]Epoch 38:  96%|█████████▋| 27/28 [00:00<00:00, 130.94it/s, train_loss=0.003, val_loss=0.00313]  Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 132.75it/s, train_loss=0.003, val_loss=0.00313]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 131.79it/s, train_loss=0.00273, val_loss=0.00313]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 152.91it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 172.49it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 191.35it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 206.94it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 221.33it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 233.73it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 243.38it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 248.70it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 251.19it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 249.85it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 254.42it/s][A
                                                                         [AEpoch 38: 100%|██████████| 28/28 [00:00<00:00, 106.04it/s, train_loss=0.00273, val_loss=0.00312]Epoch 38: 100%|██████████| 28/28 [00:00<00:00, 105.74it/s, train_loss=0.00273, val_loss=0.00312]Epoch 38:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00273, val_loss=0.00312]          Epoch 39:   0%|          | 0/28 [00:00<?, ?it/s, train_loss=0.00273, val_loss=0.00312]Epoch 39:   4%|▎         | 1/28 [00:00<00:00, 177.47it/s, train_loss=0.00273, val_loss=0.00312]Epoch 39:   4%|▎         | 1/28 [00:00<00:00, 134.94it/s, train_loss=0.00236, val_loss=0.00312]Epoch 39:   7%|▋         | 2/28 [00:00<00:00, 170.25it/s, train_loss=0.00236, val_loss=0.00312]Epoch 39:   7%|▋         | 2/28 [00:00<00:00, 138.08it/s, train_loss=0.00308, val_loss=0.00312]Epoch 39:  11%|█         | 3/28 [00:00<00:00, 154.50it/s, train_loss=0.00308, val_loss=0.00312]Epoch 39:  11%|█         | 3/28 [00:00<00:00, 141.25it/s, train_loss=0.00239, val_loss=0.00312]Epoch 39:  14%|█▍        | 4/28 [00:00<00:00, 155.48it/s, train_loss=0.00239, val_loss=0.00312]Epoch 39:  14%|█▍        | 4/28 [00:00<00:00, 133.25it/s, train_loss=0.00253, val_loss=0.00312]Epoch 39:  18%|█▊        | 5/28 [00:00<00:00, 142.09it/s, train_loss=0.00253, val_loss=0.00312]Epoch 39:  18%|█▊        | 5/28 [00:00<00:00, 135.35it/s, train_loss=0.0023, val_loss=0.00312] Epoch 39:  21%|██▏       | 6/28 [00:00<00:00, 144.72it/s, train_loss=0.0023, val_loss=0.00312]Epoch 39:  21%|██▏       | 6/28 [00:00<00:00, 132.03it/s, train_loss=0.00277, val_loss=0.00312]Epoch 39:  25%|██▌       | 7/28 [00:00<00:00, 138.27it/s, train_loss=0.00277, val_loss=0.00312]Epoch 39:  25%|██▌       | 7/28 [00:00<00:00, 133.72it/s, train_loss=0.00221, val_loss=0.00312]Epoch 39:  29%|██▊       | 8/28 [00:00<00:00, 140.46it/s, train_loss=0.00221, val_loss=0.00312]Epoch 39:  29%|██▊       | 8/28 [00:00<00:00, 131.21it/s, train_loss=0.0024, val_loss=0.00312] Epoch 39:  32%|███▏      | 9/28 [00:00<00:00, 136.08it/s, train_loss=0.0024, val_loss=0.00312]Epoch 39:  32%|███▏      | 9/28 [00:00<00:00, 132.76it/s, train_loss=0.00279, val_loss=0.00312]Epoch 39:  36%|███▌      | 10/28 [00:00<00:00, 138.22it/s, train_loss=0.00279, val_loss=0.00312]Epoch 39:  36%|███▌      | 10/28 [00:00<00:00, 130.89it/s, train_loss=0.00244, val_loss=0.00312]Epoch 39:  39%|███▉      | 11/28 [00:00<00:00, 134.85it/s, train_loss=0.00244, val_loss=0.00312]Epoch 39:  39%|███▉      | 11/28 [00:00<00:00, 132.01it/s, train_loss=0.00256, val_loss=0.00312]Epoch 39:  43%|████▎     | 12/28 [00:00<00:00, 136.51it/s, train_loss=0.00256, val_loss=0.00312]Epoch 39:  43%|████▎     | 12/28 [00:00<00:00, 130.70it/s, train_loss=0.0021, val_loss=0.00312] Epoch 39:  46%|████▋     | 13/28 [00:00<00:00, 133.94it/s, train_loss=0.0021, val_loss=0.00312]Epoch 39:  46%|████▋     | 13/28 [00:00<00:00, 131.55it/s, train_loss=0.0023, val_loss=0.00312]Epoch 39:  50%|█████     | 14/28 [00:00<00:00, 135.27it/s, train_loss=0.0023, val_loss=0.00312]Epoch 39:  50%|█████     | 14/28 [00:00<00:00, 130.71it/s, train_loss=0.00241, val_loss=0.00312]Epoch 39:  54%|█████▎    | 15/28 [00:00<00:00, 134.07it/s, train_loss=0.00241, val_loss=0.00312]Epoch 39:  54%|█████▎    | 15/28 [00:00<00:00, 132.07it/s, train_loss=0.00278, val_loss=0.00312]Epoch 39:  57%|█████▋    | 16/28 [00:00<00:00, 135.78it/s, train_loss=0.00278, val_loss=0.00312]Epoch 39:  57%|█████▋    | 16/28 [00:00<00:00, 133.69it/s, train_loss=0.00296, val_loss=0.00312]Epoch 39:  61%|██████    | 17/28 [00:00<00:00, 136.44it/s, train_loss=0.00296, val_loss=0.00312]Epoch 39:  61%|██████    | 17/28 [00:00<00:00, 133.86it/s, train_loss=0.00279, val_loss=0.00312]Epoch 39:  64%|██████▍   | 18/28 [00:00<00:00, 136.53it/s, train_loss=0.00279, val_loss=0.00312]Epoch 39:  64%|██████▍   | 18/28 [00:00<00:00, 134.66it/s, train_loss=0.00257, val_loss=0.00312]Epoch 39:  68%|██████▊   | 19/28 [00:00<00:00, 137.58it/s, train_loss=0.00257, val_loss=0.00312]Epoch 39:  68%|██████▊   | 19/28 [00:00<00:00, 133.70it/s, train_loss=0.00233, val_loss=0.00312]Epoch 39:  71%|███████▏  | 20/28 [00:00<00:00, 135.66it/s, train_loss=0.00233, val_loss=0.00312]Epoch 39:  71%|███████▏  | 20/28 [00:00<00:00, 134.16it/s, train_loss=0.00211, val_loss=0.00312]Epoch 39:  75%|███████▌  | 21/28 [00:00<00:00, 136.83it/s, train_loss=0.00211, val_loss=0.00312]Epoch 39:  75%|███████▌  | 21/28 [00:00<00:00, 135.15it/s, train_loss=0.00277, val_loss=0.00312]Epoch 39:  79%|███████▊  | 22/28 [00:00<00:00, 137.48it/s, train_loss=0.00277, val_loss=0.00312]Epoch 39:  79%|███████▊  | 22/28 [00:00<00:00, 134.76it/s, train_loss=0.00284, val_loss=0.00312]Epoch 39:  82%|████████▏ | 23/28 [00:00<00:00, 136.97it/s, train_loss=0.00284, val_loss=0.00312]Epoch 39:  82%|████████▏ | 23/28 [00:00<00:00, 135.47it/s, train_loss=0.00231, val_loss=0.00312]Epoch 39:  86%|████████▌ | 24/28 [00:00<00:00, 137.83it/s, train_loss=0.00231, val_loss=0.00312]Epoch 39:  86%|████████▌ | 24/28 [00:00<00:00, 134.63it/s, train_loss=0.00289, val_loss=0.00312]Epoch 39:  89%|████████▉ | 25/28 [00:00<00:00, 136.42it/s, train_loss=0.00289, val_loss=0.00312]Epoch 39:  89%|████████▉ | 25/28 [00:00<00:00, 135.04it/s, train_loss=0.00254, val_loss=0.00312]Epoch 39:  93%|█████████▎| 26/28 [00:00<00:00, 137.13it/s, train_loss=0.00254, val_loss=0.00312]Epoch 39:  93%|█████████▎| 26/28 [00:00<00:00, 134.05it/s, train_loss=0.0026, val_loss=0.00312] Epoch 39:  96%|█████████▋| 27/28 [00:00<00:00, 135.68it/s, train_loss=0.0026, val_loss=0.00312]Epoch 39:  96%|█████████▋| 27/28 [00:00<00:00, 134.44it/s, train_loss=0.00208, val_loss=0.00312]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 136.38it/s, train_loss=0.00208, val_loss=0.00312]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 133.88it/s, train_loss=0.00225, val_loss=0.00312]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 153.72it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 187.02it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 201.54it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 208.00it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 214.20it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 217.28it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 220.15it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 221.43it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 228.04it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 236.44it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 243.47it/s][A
                                                                         [AEpoch 39: 100%|██████████| 28/28 [00:00<00:00, 107.21it/s, train_loss=0.00225, val_loss=0.00312]Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 106.95it/s, train_loss=0.00225, val_loss=0.00312]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 28/28 [00:00<00:00, 106.39it/s, train_loss=0.00225, val_loss=0.00312]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▎         | 1/27 [00:00<00:00, 448.83it/s]Predicting DataLoader 0:   7%|▋         | 2/27 [00:00<00:00, 296.94it/s]Predicting DataLoader 0:  11%|█         | 3/27 [00:00<00:00, 272.16it/s]Predicting DataLoader 0:  15%|█▍        | 4/27 [00:00<00:00, 260.91it/s]Predicting DataLoader 0:  19%|█▊        | 5/27 [00:00<00:00, 253.69it/s]Predicting DataLoader 0:  22%|██▏       | 6/27 [00:00<00:00, 247.21it/s]Predicting DataLoader 0:  26%|██▌       | 7/27 [00:00<00:00, 243.38it/s]Predicting DataLoader 0:  30%|██▉       | 8/27 [00:00<00:00, 241.39it/s]Predicting DataLoader 0:  33%|███▎      | 9/27 [00:00<00:00, 238.50it/s]Predicting DataLoader 0:  37%|███▋      | 10/27 [00:00<00:00, 237.72it/s]Predicting DataLoader 0:  41%|████      | 11/27 [00:00<00:00, 235.21it/s]Predicting DataLoader 0:  44%|████▍     | 12/27 [00:00<00:00, 234.82it/s]Predicting DataLoader 0:  48%|████▊     | 13/27 [00:00<00:00, 233.26it/s]Predicting DataLoader 0:  52%|█████▏    | 14/27 [00:00<00:00, 233.06it/s]Predicting DataLoader 0:  56%|█████▌    | 15/27 [00:00<00:00, 231.30it/s]Predicting DataLoader 0:  59%|█████▉    | 16/27 [00:00<00:00, 230.30it/s]Predicting DataLoader 0:  63%|██████▎   | 17/27 [00:00<00:00, 229.49it/s]Predicting DataLoader 0:  67%|██████▋   | 18/27 [00:00<00:00, 229.22it/s]Predicting DataLoader 0:  70%|███████   | 19/27 [00:00<00:00, 228.66it/s]Predicting DataLoader 0:  74%|███████▍  | 20/27 [00:00<00:00, 228.42it/s]Predicting DataLoader 0:  78%|███████▊  | 21/27 [00:00<00:00, 227.44it/s]Predicting DataLoader 0:  81%|████████▏ | 22/27 [00:00<00:00, 227.09it/s]Predicting DataLoader 0:  85%|████████▌ | 23/27 [00:00<00:00, 226.63it/s]Predicting DataLoader 0:  89%|████████▉ | 24/27 [00:00<00:00, 226.51it/s]Predicting DataLoader 0:  93%|█████████▎| 25/27 [00:00<00:00, 226.10it/s]Predicting DataLoader 0:  96%|█████████▋| 26/27 [00:00<00:00, 225.74it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 227.60it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 225.52it/s][I 2025-08-18 02:11:56,826] A new study created in memory with name: no-name-c03e1e3b-fd66-4f37-8e6d-741e8f5588c2
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2956627959510097 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 32, Horizon length: 7
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 321.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.95it/s][I 2025-08-18 02:12:04,832] Trial 0 finished with value: 23.867020861537956 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 1, 'dropout': 0.2956627959510097}. Best is trial 0 with value: 23.867020861537956.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.43it/s][I 2025-08-18 02:12:14,722] Trial 1 finished with value: 23.99534980328398 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 2, 'dropout': 0.17273399384221277}. Best is trial 0 with value: 23.867020861537956.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.61it/s][I 2025-08-18 02:12:26,206] Trial 2 finished with value: 24.309586273590508 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 3, 'dropout': 0.2674814619262571}. Best is trial 0 with value: 23.867020861537956.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.07it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.73it/s][I 2025-08-18 02:12:42,189] Trial 3 finished with value: 25.7159719951723 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 3, 'dropout': 0.24481122762489904}. Best is trial 0 with value: 23.867020861537956.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 258.27it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.73it/s][I 2025-08-18 02:12:54,345] Trial 4 finished with value: 25.564395551852733 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 3, 'dropout': 0.05157436848074132}. Best is trial 0 with value: 23.867020861537956.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.46015230245461347 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 302.79it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 246.09it/s][I 2025-08-18 02:13:01,843] Trial 5 finished with value: 22.793540061240638 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 1, 'dropout': 0.46015230245461347}. Best is trial 5 with value: 22.793540061240638.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.57it/s][I 2025-08-18 02:13:19,051] Trial 6 finished with value: 25.735017654548308 and parameters: {'hidden_dim': 86, 'n_rnn_layers': 2, 'dropout': 0.31494553783433904}. Best is trial 5 with value: 22.793540061240638.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.88it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.55it/s][I 2025-08-18 02:13:35,944] Trial 7 finished with value: 26.170746858056532 and parameters: {'hidden_dim': 115, 'n_rnn_layers': 4, 'dropout': 0.037239677456950504}. Best is trial 5 with value: 22.793540061240638.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 239.16it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.88it/s][I 2025-08-18 02:13:48,772] Trial 8 finished with value: 25.630042821748276 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 4, 'dropout': 0.10695092032601128}. Best is trial 5 with value: 22.793540061240638.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.39it/s][I 2025-08-18 02:14:01,241] Trial 9 finished with value: 24.10441344033656 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 4, 'dropout': 0.348748997489022}. Best is trial 5 with value: 22.793540061240638.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49988345719747457 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.21it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.69it/s][I 2025-08-18 02:14:07,775] Trial 10 finished with value: 22.399805590971763 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.49988345719747457}. Best is trial 10 with value: 22.399805590971763.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49366510382734696 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.68it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.46it/s][I 2025-08-18 02:14:14,954] Trial 11 finished with value: 22.275323743207647 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.49366510382734696}. Best is trial 11 with value: 22.275323743207647.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4939912627910683 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 281.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 231.14it/s][I 2025-08-18 02:14:22,015] Trial 12 finished with value: 22.275323743207647 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.4939912627910683}. Best is trial 11 with value: 22.275323743207647.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.85it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.94it/s][I 2025-08-18 02:14:30,534] Trial 13 finished with value: 24.032852331419587 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 2, 'dropout': 0.41723638879269354}. Best is trial 11 with value: 22.275323743207647.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3991564538219695 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.64it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.17it/s][I 2025-08-18 02:14:40,592] Trial 14 finished with value: 23.835517962648346 and parameters: {'hidden_dim': 46, 'n_rnn_layers': 1, 'dropout': 0.3991564538219695}. Best is trial 11 with value: 22.275323743207647.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.16it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.20it/s][I 2025-08-18 02:14:52,436] Trial 15 finished with value: 24.427781395903043 and parameters: {'hidden_dim': 42, 'n_rnn_layers': 2, 'dropout': 0.49637639870257994}. Best is trial 11 with value: 22.275323743207647.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.39189043984735034 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 283.86it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.91it/s][I 2025-08-18 02:15:02,153] Trial 16 finished with value: 22.244595212755055 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 1, 'dropout': 0.39189043984735034}. Best is trial 16 with value: 22.244595212755055.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3911167955886614 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.97it/s][I 2025-08-18 02:15:13,537] Trial 17 finished with value: 23.647195786067016 and parameters: {'hidden_dim': 51, 'n_rnn_layers': 1, 'dropout': 0.3911167955886614}. Best is trial 16 with value: 22.244595212755055.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.52it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.90it/s][I 2025-08-18 02:15:30,347] Trial 18 finished with value: 25.36649443890042 and parameters: {'hidden_dim': 65, 'n_rnn_layers': 2, 'dropout': 0.4272478218638944}. Best is trial 16 with value: 22.244595212755055.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35684457573425366 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 316.50it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.37it/s][I 2025-08-18 02:15:39,553] Trial 19 finished with value: 23.838773215336992 and parameters: {'hidden_dim': 37, 'n_rnn_layers': 1, 'dropout': 0.35684457573425366}. Best is trial 16 with value: 22.244595212755055.
[I 2025-08-18 02:15:39,554] A new study created in memory with name: no-name-b3be24f6-1f54-4321-b293-51ad1b1155d0
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 43, 'n_rnn_layers': 1, 'dropout': 0.39189043984735034}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 267.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.61it/s][I 2025-08-18 02:15:53,288] Trial 0 finished with value: 26.901106916148446 and parameters: {'hidden_dim': 54, 'n_rnn_layers': 2, 'dropout': 0.021887212348292606}. Best is trial 0 with value: 26.901106916148446.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20040405116253657 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.57it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.99it/s][I 2025-08-18 02:16:04,875] Trial 1 finished with value: 23.40886214805199 and parameters: {'hidden_dim': 53, 'n_rnn_layers': 1, 'dropout': 0.20040405116253657}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.31491261796538506 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 337.38it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.86it/s][I 2025-08-18 02:16:13,989] Trial 2 finished with value: 23.695592864721284 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 1, 'dropout': 0.31491261796538506}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.78it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.21it/s][I 2025-08-18 02:16:25,578] Trial 3 finished with value: 25.638280463954466 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 3, 'dropout': 0.15427887541493174}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.25it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.39it/s][I 2025-08-18 02:16:42,732] Trial 4 finished with value: 25.92957444833883 and parameters: {'hidden_dim': 74, 'n_rnn_layers': 2, 'dropout': 0.4093349514126407}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3561583374784873 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 354.73it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 293.35it/s][I 2025-08-18 02:16:54,008] Trial 5 finished with value: 23.9368579637078 and parameters: {'hidden_dim': 49, 'n_rnn_layers': 1, 'dropout': 0.3561583374784873}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.81it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.51it/s][I 2025-08-18 02:17:10,437] Trial 6 finished with value: 25.299032652967945 and parameters: {'hidden_dim': 66, 'n_rnn_layers': 2, 'dropout': 0.17158647656110626}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15649552192142507 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 283.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.03it/s][I 2025-08-18 02:17:20,008] Trial 7 finished with value: 23.989769882666884 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 1, 'dropout': 0.15649552192142507}. Best is trial 1 with value: 23.40886214805199.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16342429304637673 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.81it/s][I 2025-08-18 02:17:26,940] Trial 8 finished with value: 23.002631771112764 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 1, 'dropout': 0.16342429304637673}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3338765648816676 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 337.57it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.11it/s][I 2025-08-18 02:17:34,279] Trial 9 finished with value: 23.686764743473425 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 1, 'dropout': 0.3338765648816676}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.51it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.82it/s][I 2025-08-18 02:17:46,296] Trial 10 finished with value: 23.484700167328022 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.49031367508232504}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.75it/s][I 2025-08-18 02:18:03,138] Trial 11 finished with value: 27.841954857870924 and parameters: {'hidden_dim': 121, 'n_rnn_layers': 3, 'dropout': 0.06316772425384576}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23636402531152623 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.75it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 273.80it/s][I 2025-08-18 02:18:09,982] Trial 12 finished with value: 23.116210660526757 and parameters: {'hidden_dim': 18, 'n_rnn_layers': 1, 'dropout': 0.23636402531152623}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.49it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 237.11it/s][I 2025-08-18 02:18:18,094] Trial 13 finished with value: 23.41619948124193 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 2, 'dropout': 0.26084635574422654}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.29it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.66it/s][I 2025-08-18 02:18:30,768] Trial 14 finished with value: 26.084310806233663 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 4, 'dropout': 0.10003141009304914}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23698296720988352 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.14it/s][I 2025-08-18 02:18:39,735] Trial 15 finished with value: 24.227949534766704 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 1, 'dropout': 0.23698296720988352}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.51it/s][I 2025-08-18 02:18:50,706] Trial 16 finished with value: 24.16154293450327 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 3, 'dropout': 0.2622887561889369}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 278.71it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.80it/s][I 2025-08-18 02:19:01,824] Trial 17 finished with value: 26.01088622629107 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 2, 'dropout': 0.09768021734559235}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20881102116293399 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 286.03it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.87it/s][I 2025-08-18 02:19:08,609] Trial 18 finished with value: 23.002631771112764 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 1, 'dropout': 0.20881102116293399}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 309.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 240.78it/s][I 2025-08-18 02:19:18,146] Trial 19 finished with value: 25.22257064796675 and parameters: {'hidden_dim': 27, 'n_rnn_layers': 2, 'dropout': 0.0040199702613814}. Best is trial 8 with value: 23.002631771112764.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16342429304637673 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 1.7 K  | train
6 | V               | Linear           | 20     | train
-------------------------------------------------------------
1.7 K     Trainable params
0         Non-trainable params
1.7 K     Total params
0.007     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 19, 'n_rnn_layers': 1, 'dropout': 0.16342429304637673}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 285.13it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 330.92it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/27 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s] Epoch 0:   4%|▎         | 1/27 [00:00<00:00, 167.06it/s]Epoch 0:   4%|▎         | 1/27 [00:00<00:00, 138.62it/s, train_loss=0.0837]Epoch 0:   7%|▋         | 2/27 [00:00<00:00, 166.92it/s, train_loss=0.0837]Epoch 0:   7%|▋         | 2/27 [00:00<00:00, 135.77it/s, train_loss=0.0635]Epoch 0:  11%|█         | 3/27 [00:00<00:00, 155.75it/s, train_loss=0.0635]Epoch 0:  11%|█         | 3/27 [00:00<00:00, 145.65it/s, train_loss=0.0607]Epoch 0:  15%|█▍        | 4/27 [00:00<00:00, 161.28it/s, train_loss=0.0607]Epoch 0:  15%|█▍        | 4/27 [00:00<00:00, 151.80it/s, train_loss=0.072] Epoch 0:  19%|█▊        | 5/27 [00:00<00:00, 162.83it/s, train_loss=0.072]Epoch 0:  19%|█▊        | 5/27 [00:00<00:00, 151.29it/s, train_loss=0.0769]Epoch 0:  22%|██▏       | 6/27 [00:00<00:00, 160.15it/s, train_loss=0.0769]Epoch 0:  22%|██▏       | 6/27 [00:00<00:00, 154.40it/s, train_loss=0.0777]Epoch 0:  26%|██▌       | 7/27 [00:00<00:00, 162.58it/s, train_loss=0.0777]Epoch 0:  26%|██▌       | 7/27 [00:00<00:00, 156.80it/s, train_loss=0.0713]Epoch 0:  30%|██▉       | 8/27 [00:00<00:00, 162.87it/s, train_loss=0.0713]Epoch 0:  30%|██▉       | 8/27 [00:00<00:00, 155.83it/s, train_loss=0.0499]Epoch 0:  33%|███▎      | 9/27 [00:00<00:00, 160.73it/s, train_loss=0.0499]Epoch 0:  33%|███▎      | 9/27 [00:00<00:00, 156.84it/s, train_loss=0.0828]Epoch 0:  37%|███▋      | 10/27 [00:00<00:00, 163.05it/s, train_loss=0.0828]Epoch 0:  37%|███▋      | 10/27 [00:00<00:00, 159.28it/s, train_loss=0.0403]Epoch 0:  41%|████      | 11/27 [00:00<00:00, 164.71it/s, train_loss=0.0403]Epoch 0:  41%|████      | 11/27 [00:00<00:00, 157.01it/s, train_loss=0.0639]Epoch 0:  44%|████▍     | 12/27 [00:00<00:00, 161.52it/s, train_loss=0.0639]Epoch 0:  44%|████▍     | 12/27 [00:00<00:00, 158.55it/s, train_loss=0.0503]Epoch 0:  48%|████▊     | 13/27 [00:00<00:00, 163.01it/s, train_loss=0.0503]Epoch 0:  48%|████▊     | 13/27 [00:00<00:00, 160.03it/s, train_loss=0.0627]Epoch 0:  52%|█████▏    | 14/27 [00:00<00:00, 163.73it/s, train_loss=0.0627]Epoch 0:  52%|█████▏    | 14/27 [00:00<00:00, 158.46it/s, train_loss=0.0463]Epoch 0:  56%|█████▌    | 15/27 [00:00<00:00, 161.89it/s, train_loss=0.0463]Epoch 0:  56%|█████▌    | 15/27 [00:00<00:00, 159.61it/s, train_loss=0.0683]Epoch 0:  59%|█████▉    | 16/27 [00:00<00:00, 163.11it/s, train_loss=0.0683]Epoch 0:  59%|█████▉    | 16/27 [00:00<00:00, 160.66it/s, train_loss=0.0584]Epoch 0:  63%|██████▎   | 17/27 [00:00<00:00, 161.95it/s, train_loss=0.0584]Epoch 0:  63%|██████▎   | 17/27 [00:00<00:00, 159.46it/s, train_loss=0.0725]Epoch 0:  67%|██████▋   | 18/27 [00:00<00:00, 160.59it/s, train_loss=0.0725]Epoch 0:  67%|██████▋   | 18/27 [00:00<00:00, 158.83it/s, train_loss=0.063] Epoch 0:  70%|███████   | 19/27 [00:00<00:00, 161.43it/s, train_loss=0.063]Epoch 0:  70%|███████   | 19/27 [00:00<00:00, 156.32it/s, train_loss=0.047]Epoch 0:  74%|███████▍  | 20/27 [00:00<00:00, 158.56it/s, train_loss=0.047]Epoch 0:  74%|███████▍  | 20/27 [00:00<00:00, 156.30it/s, train_loss=0.0669]Epoch 0:  78%|███████▊  | 21/27 [00:00<00:00, 158.76it/s, train_loss=0.0669]Epoch 0:  78%|███████▊  | 21/27 [00:00<00:00, 154.24it/s, train_loss=0.0587]Epoch 0:  81%|████████▏ | 22/27 [00:00<00:00, 156.42it/s, train_loss=0.0587]Epoch 0:  81%|████████▏ | 22/27 [00:00<00:00, 154.82it/s, train_loss=0.0547]Epoch 0:  85%|████████▌ | 23/27 [00:00<00:00, 157.08it/s, train_loss=0.0547]Epoch 0:  85%|████████▌ | 23/27 [00:00<00:00, 155.56it/s, train_loss=0.0643]Epoch 0:  89%|████████▉ | 24/27 [00:00<00:00, 155.94it/s, train_loss=0.0643]Epoch 0:  89%|████████▉ | 24/27 [00:00<00:00, 154.55it/s, train_loss=0.045] Epoch 0:  93%|█████████▎| 25/27 [00:00<00:00, 156.57it/s, train_loss=0.045]Epoch 0:  93%|█████████▎| 25/27 [00:00<00:00, 155.17it/s, train_loss=0.0656]Epoch 0:  96%|█████████▋| 26/27 [00:00<00:00, 157.17it/s, train_loss=0.0656]Epoch 0:  96%|█████████▋| 26/27 [00:00<00:00, 153.73it/s, train_loss=0.0482]Epoch 0: 100%|██████████| 27/27 [00:00<00:00, 155.12it/s, train_loss=0.0482]Epoch 0: 100%|██████████| 27/27 [00:00<00:00, 153.83it/s, train_loss=0.0466]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 151.86it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 187.28it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 196.65it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 204.80it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 208.61it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 212.04it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 219.60it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 229.28it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 237.06it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 243.79it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 250.54it/s][A
                                                                         [AEpoch 0: 100%|██████████| 27/27 [00:00<00:00, 119.40it/s, train_loss=0.0466, val_loss=0.068]Epoch 0: 100%|██████████| 27/27 [00:00<00:00, 119.04it/s, train_loss=0.0466, val_loss=0.068]Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0466, val_loss=0.068]          Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0466, val_loss=0.068]Epoch 1:   4%|▎         | 1/27 [00:00<00:00, 195.38it/s, train_loss=0.0466, val_loss=0.068]Epoch 1:   4%|▎         | 1/27 [00:00<00:00, 153.89it/s, train_loss=0.0709, val_loss=0.068]Epoch 1:   7%|▋         | 2/27 [00:00<00:00, 185.67it/s, train_loss=0.0709, val_loss=0.068]Epoch 1:   7%|▋         | 2/27 [00:00<00:00, 146.04it/s, train_loss=0.0679, val_loss=0.068]Epoch 1:  11%|█         | 3/27 [00:00<00:00, 166.55it/s, train_loss=0.0679, val_loss=0.068]Epoch 1:  11%|█         | 3/27 [00:00<00:00, 154.92it/s, train_loss=0.0655, val_loss=0.068]Epoch 1:  15%|█▍        | 4/27 [00:00<00:00, 169.83it/s, train_loss=0.0655, val_loss=0.068]Epoch 1:  15%|█▍        | 4/27 [00:00<00:00, 160.08it/s, train_loss=0.0636, val_loss=0.068]Epoch 1:  19%|█▊        | 5/27 [00:00<00:00, 167.73it/s, train_loss=0.0636, val_loss=0.068]Epoch 1:  19%|█▊        | 5/27 [00:00<00:00, 157.55it/s, train_loss=0.0567, val_loss=0.068]Epoch 1:  22%|██▏       | 6/27 [00:00<00:00, 163.61it/s, train_loss=0.0567, val_loss=0.068]Epoch 1:  22%|██▏       | 6/27 [00:00<00:00, 158.87it/s, train_loss=0.0388, val_loss=0.068]Epoch 1:  26%|██▌       | 7/27 [00:00<00:00, 160.49it/s, train_loss=0.0388, val_loss=0.068]Epoch 1:  26%|██▌       | 7/27 [00:00<00:00, 149.48it/s, train_loss=0.0601, val_loss=0.068]Epoch 1:  30%|██▉       | 8/27 [00:00<00:00, 149.09it/s, train_loss=0.0601, val_loss=0.068]Epoch 1:  30%|██▉       | 8/27 [00:00<00:00, 146.82it/s, train_loss=0.0464, val_loss=0.068]Epoch 1:  33%|███▎      | 9/27 [00:00<00:00, 148.09it/s, train_loss=0.0464, val_loss=0.068]Epoch 1:  33%|███▎      | 9/27 [00:00<00:00, 145.90it/s, train_loss=0.0417, val_loss=0.068]Epoch 1:  37%|███▋      | 10/27 [00:00<00:00, 146.28it/s, train_loss=0.0417, val_loss=0.068]Epoch 1:  37%|███▋      | 10/27 [00:00<00:00, 144.25it/s, train_loss=0.0316, val_loss=0.068]Epoch 1:  41%|████      | 11/27 [00:00<00:00, 145.25it/s, train_loss=0.0316, val_loss=0.068]Epoch 1:  41%|████      | 11/27 [00:00<00:00, 143.45it/s, train_loss=0.0596, val_loss=0.068]Epoch 1:  44%|████▍     | 12/27 [00:00<00:00, 143.97it/s, train_loss=0.0596, val_loss=0.068]Epoch 1:  44%|████▍     | 12/27 [00:00<00:00, 141.56it/s, train_loss=0.0437, val_loss=0.068]Epoch 1:  48%|████▊     | 13/27 [00:00<00:00, 142.85it/s, train_loss=0.0437, val_loss=0.068]Epoch 1:  48%|████▊     | 13/27 [00:00<00:00, 141.42it/s, train_loss=0.0458, val_loss=0.068]Epoch 1:  52%|█████▏    | 14/27 [00:00<00:00, 142.85it/s, train_loss=0.0458, val_loss=0.068]Epoch 1:  52%|█████▏    | 14/27 [00:00<00:00, 139.67it/s, train_loss=0.0537, val_loss=0.068]Epoch 1:  56%|█████▌    | 15/27 [00:00<00:00, 140.70it/s, train_loss=0.0537, val_loss=0.068]Epoch 1:  56%|█████▌    | 15/27 [00:00<00:00, 139.43it/s, train_loss=0.0462, val_loss=0.068]Epoch 1:  59%|█████▉    | 16/27 [00:00<00:00, 140.50it/s, train_loss=0.0462, val_loss=0.068]Epoch 1:  59%|█████▉    | 16/27 [00:00<00:00, 137.44it/s, train_loss=0.0383, val_loss=0.068]Epoch 1:  63%|██████▎   | 17/27 [00:00<00:00, 138.64it/s, train_loss=0.0383, val_loss=0.068]Epoch 1:  63%|██████▎   | 17/27 [00:00<00:00, 137.20it/s, train_loss=0.0276, val_loss=0.068]Epoch 1:  67%|██████▋   | 18/27 [00:00<00:00, 138.08it/s, train_loss=0.0276, val_loss=0.068]Epoch 1:  67%|██████▋   | 18/27 [00:00<00:00, 135.23it/s, train_loss=0.0339, val_loss=0.068]Epoch 1:  70%|███████   | 19/27 [00:00<00:00, 133.92it/s, train_loss=0.0339, val_loss=0.068]Epoch 1:  70%|███████   | 19/27 [00:00<00:00, 133.29it/s, train_loss=0.0375, val_loss=0.068]Epoch 1:  74%|███████▍  | 20/27 [00:00<00:00, 135.05it/s, train_loss=0.0375, val_loss=0.068]Epoch 1:  74%|███████▍  | 20/27 [00:00<00:00, 134.01it/s, train_loss=0.0258, val_loss=0.068]Epoch 1:  78%|███████▊  | 21/27 [00:00<00:00, 136.01it/s, train_loss=0.0258, val_loss=0.068]Epoch 1:  78%|███████▊  | 21/27 [00:00<00:00, 134.83it/s, train_loss=0.0413, val_loss=0.068]Epoch 1:  81%|████████▏ | 22/27 [00:00<00:00, 136.86it/s, train_loss=0.0413, val_loss=0.068]Epoch 1:  81%|████████▏ | 22/27 [00:00<00:00, 134.38it/s, train_loss=0.0232, val_loss=0.068]Epoch 1:  85%|████████▌ | 23/27 [00:00<00:00, 136.27it/s, train_loss=0.0232, val_loss=0.068]Epoch 1:  85%|████████▌ | 23/27 [00:00<00:00, 135.31it/s, train_loss=0.023, val_loss=0.068] Epoch 1:  89%|████████▉ | 24/27 [00:00<00:00, 137.08it/s, train_loss=0.023, val_loss=0.068]Epoch 1:  89%|████████▉ | 24/27 [00:00<00:00, 134.81it/s, train_loss=0.0382, val_loss=0.068]Epoch 1:  93%|█████████▎| 25/27 [00:00<00:00, 136.52it/s, train_loss=0.0382, val_loss=0.068]Epoch 1:  93%|█████████▎| 25/27 [00:00<00:00, 135.58it/s, train_loss=0.0242, val_loss=0.068]Epoch 1:  96%|█████████▋| 26/27 [00:00<00:00, 137.20it/s, train_loss=0.0242, val_loss=0.068]Epoch 1:  96%|█████████▋| 26/27 [00:00<00:00, 135.06it/s, train_loss=0.0527, val_loss=0.068]Epoch 1: 100%|██████████| 27/27 [00:00<00:00, 136.41it/s, train_loss=0.0527, val_loss=0.068]Epoch 1: 100%|██████████| 27/27 [00:00<00:00, 135.53it/s, train_loss=0.0234, val_loss=0.068]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 163.42it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 190.13it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 200.30it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 206.57it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 208.52it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 211.10it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 211.42it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 212.31it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 212.23it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 215.05it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 216.17it/s][A
                                                                         [AEpoch 1: 100%|██████████| 27/27 [00:00<00:00, 104.55it/s, train_loss=0.0234, val_loss=0.0398]Epoch 1: 100%|██████████| 27/27 [00:00<00:00, 104.14it/s, train_loss=0.0234, val_loss=0.0398]Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0234, val_loss=0.0398]          Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0234, val_loss=0.0398]Epoch 2:   4%|▎         | 1/27 [00:00<00:00, 151.66it/s, train_loss=0.0234, val_loss=0.0398]Epoch 2:   4%|▎         | 1/27 [00:00<00:00, 125.55it/s, train_loss=0.0299, val_loss=0.0398]Epoch 2:   7%|▋         | 2/27 [00:00<00:00, 155.75it/s, train_loss=0.0299, val_loss=0.0398]Epoch 2:   7%|▋         | 2/27 [00:00<00:00, 124.31it/s, train_loss=0.0337, val_loss=0.0398]Epoch 2:  11%|█         | 3/27 [00:00<00:00, 141.49it/s, train_loss=0.0337, val_loss=0.0398]Epoch 2:  11%|█         | 3/27 [00:00<00:00, 133.49it/s, train_loss=0.0299, val_loss=0.0398]Epoch 2:  15%|█▍        | 4/27 [00:00<00:00, 148.42it/s, train_loss=0.0299, val_loss=0.0398]Epoch 2:  15%|█▍        | 4/27 [00:00<00:00, 141.30it/s, train_loss=0.0247, val_loss=0.0398]Epoch 2:  19%|█▊        | 5/27 [00:00<00:00, 152.72it/s, train_loss=0.0247, val_loss=0.0398]Epoch 2:  19%|█▊        | 5/27 [00:00<00:00, 142.87it/s, train_loss=0.0245, val_loss=0.0398]Epoch 2:  22%|██▏       | 6/27 [00:00<00:00, 151.36it/s, train_loss=0.0245, val_loss=0.0398]Epoch 2:  22%|██▏       | 6/27 [00:00<00:00, 145.95it/s, train_loss=0.0306, val_loss=0.0398]Epoch 2:  26%|██▌       | 7/27 [00:00<00:00, 154.20it/s, train_loss=0.0306, val_loss=0.0398]Epoch 2:  26%|██▌       | 7/27 [00:00<00:00, 149.67it/s, train_loss=0.0315, val_loss=0.0398]Epoch 2:  30%|██▉       | 8/27 [00:00<00:00, 156.15it/s, train_loss=0.0315, val_loss=0.0398]Epoch 2:  30%|██▉       | 8/27 [00:00<00:00, 149.65it/s, train_loss=0.017, val_loss=0.0398] Epoch 2:  33%|███▎      | 9/27 [00:00<00:00, 154.68it/s, train_loss=0.017, val_loss=0.0398]Epoch 2:  33%|███▎      | 9/27 [00:00<00:00, 150.85it/s, train_loss=0.0229, val_loss=0.0398]Epoch 2:  37%|███▋      | 10/27 [00:00<00:00, 156.24it/s, train_loss=0.0229, val_loss=0.0398]Epoch 2:  37%|███▋      | 10/27 [00:00<00:00, 152.92it/s, train_loss=0.0274, val_loss=0.0398]Epoch 2:  41%|████      | 11/27 [00:00<00:00, 157.21it/s, train_loss=0.0274, val_loss=0.0398]Epoch 2:  41%|████      | 11/27 [00:00<00:00, 152.59it/s, train_loss=0.0181, val_loss=0.0398]Epoch 2:  44%|████▍     | 12/27 [00:00<00:00, 156.32it/s, train_loss=0.0181, val_loss=0.0398]Epoch 2:  44%|████▍     | 12/27 [00:00<00:00, 153.68it/s, train_loss=0.0276, val_loss=0.0398]Epoch 2:  48%|████▊     | 13/27 [00:00<00:00, 157.59it/s, train_loss=0.0276, val_loss=0.0398]Epoch 2:  48%|████▊     | 13/27 [00:00<00:00, 155.00it/s, train_loss=0.0196, val_loss=0.0398]Epoch 2:  52%|█████▏    | 14/27 [00:00<00:00, 158.03it/s, train_loss=0.0196, val_loss=0.0398]Epoch 2:  52%|█████▏    | 14/27 [00:00<00:00, 154.61it/s, train_loss=0.0207, val_loss=0.0398]Epoch 2:  56%|█████▌    | 15/27 [00:00<00:00, 157.51it/s, train_loss=0.0207, val_loss=0.0398]Epoch 2:  56%|█████▌    | 15/27 [00:00<00:00, 155.36it/s, train_loss=0.0293, val_loss=0.0398]Epoch 2:  59%|█████▉    | 16/27 [00:00<00:00, 158.45it/s, train_loss=0.0293, val_loss=0.0398]Epoch 2:  59%|█████▉    | 16/27 [00:00<00:00, 156.32it/s, train_loss=0.017, val_loss=0.0398] Epoch 2:  63%|██████▎   | 17/27 [00:00<00:00, 158.80it/s, train_loss=0.017, val_loss=0.0398]Epoch 2:  63%|██████▎   | 17/27 [00:00<00:00, 155.91it/s, train_loss=0.0164, val_loss=0.0398]Epoch 2:  67%|██████▋   | 18/27 [00:00<00:00, 158.30it/s, train_loss=0.0164, val_loss=0.0398]Epoch 2:  67%|██████▋   | 18/27 [00:00<00:00, 156.48it/s, train_loss=0.0147, val_loss=0.0398]Epoch 2:  70%|███████   | 19/27 [00:00<00:00, 159.00it/s, train_loss=0.0147, val_loss=0.0398]Epoch 2:  70%|███████   | 19/27 [00:00<00:00, 157.20it/s, train_loss=0.0182, val_loss=0.0398]Epoch 2:  74%|███████▍  | 20/27 [00:00<00:00, 159.25it/s, train_loss=0.0182, val_loss=0.0398]Epoch 2:  74%|███████▍  | 20/27 [00:00<00:00, 156.85it/s, train_loss=0.0122, val_loss=0.0398]Epoch 2:  78%|███████▊  | 21/27 [00:00<00:00, 157.57it/s, train_loss=0.0122, val_loss=0.0398]Epoch 2:  78%|███████▊  | 21/27 [00:00<00:00, 155.80it/s, train_loss=0.0201, val_loss=0.0398]Epoch 2:  81%|████████▏ | 22/27 [00:00<00:00, 157.78it/s, train_loss=0.0201, val_loss=0.0398]Epoch 2:  81%|████████▏ | 22/27 [00:00<00:00, 154.47it/s, train_loss=0.0172, val_loss=0.0398]Epoch 2:  85%|████████▌ | 23/27 [00:00<00:00, 156.37it/s, train_loss=0.0172, val_loss=0.0398]Epoch 2:  85%|████████▌ | 23/27 [00:00<00:00, 154.86it/s, train_loss=0.0229, val_loss=0.0398]Epoch 2:  89%|████████▉ | 24/27 [00:00<00:00, 157.10it/s, train_loss=0.0229, val_loss=0.0398]Epoch 2:  89%|████████▉ | 24/27 [00:00<00:00, 155.70it/s, train_loss=0.0156, val_loss=0.0398]Epoch 2:  93%|█████████▎| 25/27 [00:00<00:00, 157.53it/s, train_loss=0.0156, val_loss=0.0398]Epoch 2:  93%|█████████▎| 25/27 [00:00<00:00, 155.38it/s, train_loss=0.0186, val_loss=0.0398]Epoch 2:  96%|█████████▋| 26/27 [00:00<00:00, 157.00it/s, train_loss=0.0186, val_loss=0.0398]Epoch 2:  96%|█████████▋| 26/27 [00:00<00:00, 155.62it/s, train_loss=0.0186, val_loss=0.0398]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 27/27 [00:00<00:00, 156.76it/s, train_loss=0.0186, val_loss=0.0398]Epoch 2: 100%|██████████| 27/27 [00:00<00:00, 156.07it/s, train_loss=0.0131, val_loss=0.0398]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 144.01it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 180.69it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 199.01it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 206.91it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 213.00it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 214.09it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 216.19it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 218.12it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 219.71it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 221.86it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 222.88it/s][A
                                                                         [AEpoch 2: 100%|██████████| 27/27 [00:00<00:00, 116.62it/s, train_loss=0.0131, val_loss=0.0254]Epoch 2: 100%|██████████| 27/27 [00:00<00:00, 116.11it/s, train_loss=0.0131, val_loss=0.0254]Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0131, val_loss=0.0254]          Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0131, val_loss=0.0254]Epoch 3:   4%|▎         | 1/27 [00:00<00:00, 159.43it/s, train_loss=0.0131, val_loss=0.0254]Epoch 3:   4%|▎         | 1/27 [00:00<00:00, 132.50it/s, train_loss=0.0159, val_loss=0.0254]Epoch 3:   7%|▋         | 2/27 [00:00<00:00, 160.18it/s, train_loss=0.0159, val_loss=0.0254]Epoch 3:   7%|▋         | 2/27 [00:00<00:00, 126.94it/s, train_loss=0.016, val_loss=0.0254] Epoch 3:  11%|█         | 3/27 [00:00<00:00, 137.85it/s, train_loss=0.016, val_loss=0.0254]Epoch 3:  11%|█         | 3/27 [00:00<00:00, 130.86it/s, train_loss=0.0178, val_loss=0.0254]Epoch 3:  15%|█▍        | 4/27 [00:00<00:00, 142.17it/s, train_loss=0.0178, val_loss=0.0254]Epoch 3:  15%|█▍        | 4/27 [00:00<00:00, 130.65it/s, train_loss=0.0212, val_loss=0.0254]Epoch 3:  19%|█▊        | 5/27 [00:00<00:00, 139.51it/s, train_loss=0.0212, val_loss=0.0254]Epoch 3:  19%|█▊        | 5/27 [00:00<00:00, 135.25it/s, train_loss=0.0182, val_loss=0.0254]Epoch 3:  22%|██▏       | 6/27 [00:00<00:00, 145.05it/s, train_loss=0.0182, val_loss=0.0254]Epoch 3:  22%|██▏       | 6/27 [00:00<00:00, 140.72it/s, train_loss=0.015, val_loss=0.0254] Epoch 3:  26%|██▌       | 7/27 [00:00<00:00, 147.23it/s, train_loss=0.015, val_loss=0.0254]Epoch 3:  26%|██▌       | 7/27 [00:00<00:00, 141.28it/s, train_loss=0.0179, val_loss=0.0254]Epoch 3:  30%|██▉       | 8/27 [00:00<00:00, 146.57it/s, train_loss=0.0179, val_loss=0.0254]Epoch 3:  30%|██▉       | 8/27 [00:00<00:00, 143.50it/s, train_loss=0.0131, val_loss=0.0254]Epoch 3:  33%|███▎      | 9/27 [00:00<00:00, 149.41it/s, train_loss=0.0131, val_loss=0.0254]Epoch 3:  33%|███▎      | 9/27 [00:00<00:00, 145.90it/s, train_loss=0.0186, val_loss=0.0254]Epoch 3:  37%|███▋      | 10/27 [00:00<00:00, 150.90it/s, train_loss=0.0186, val_loss=0.0254]Epoch 3:  37%|███▋      | 10/27 [00:00<00:00, 146.72it/s, train_loss=0.012, val_loss=0.0254] Epoch 3:  41%|████      | 11/27 [00:00<00:00, 150.18it/s, train_loss=0.012, val_loss=0.0254]Epoch 3:  41%|████      | 11/27 [00:00<00:00, 147.78it/s, train_loss=0.0174, val_loss=0.0254]Epoch 3:  44%|████▍     | 12/27 [00:00<00:00, 151.81it/s, train_loss=0.0174, val_loss=0.0254]Epoch 3:  44%|████▍     | 12/27 [00:00<00:00, 149.11it/s, train_loss=0.0236, val_loss=0.0254]Epoch 3:  48%|████▊     | 13/27 [00:00<00:00, 152.15it/s, train_loss=0.0236, val_loss=0.0254]Epoch 3:  48%|████▊     | 13/27 [00:00<00:00, 149.09it/s, train_loss=0.0146, val_loss=0.0254]Epoch 3:  52%|█████▏    | 14/27 [00:00<00:00, 151.97it/s, train_loss=0.0146, val_loss=0.0254]Epoch 3:  52%|█████▏    | 14/27 [00:00<00:00, 149.92it/s, train_loss=0.0106, val_loss=0.0254]Epoch 3:  56%|█████▌    | 15/27 [00:00<00:00, 153.34it/s, train_loss=0.0106, val_loss=0.0254]Epoch 3:  56%|█████▌    | 15/27 [00:00<00:00, 151.22it/s, train_loss=0.026, val_loss=0.0254] Epoch 3:  59%|█████▉    | 16/27 [00:00<00:00, 153.47it/s, train_loss=0.026, val_loss=0.0254]Epoch 3:  59%|█████▉    | 16/27 [00:00<00:00, 150.91it/s, train_loss=0.0199, val_loss=0.0254]Epoch 3:  63%|██████▎   | 17/27 [00:00<00:00, 153.20it/s, train_loss=0.0199, val_loss=0.0254]Epoch 3:  63%|██████▎   | 17/27 [00:00<00:00, 151.42it/s, train_loss=0.0194, val_loss=0.0254]Epoch 3:  67%|██████▋   | 18/27 [00:00<00:00, 154.22it/s, train_loss=0.0194, val_loss=0.0254]Epoch 3:  67%|██████▋   | 18/27 [00:00<00:00, 149.40it/s, train_loss=0.0193, val_loss=0.0254]Epoch 3:  70%|███████   | 19/27 [00:00<00:00, 151.13it/s, train_loss=0.0193, val_loss=0.0254]Epoch 3:  70%|███████   | 19/27 [00:00<00:00, 149.71it/s, train_loss=0.0216, val_loss=0.0254]Epoch 3:  74%|███████▍  | 20/27 [00:00<00:00, 151.86it/s, train_loss=0.0216, val_loss=0.0254]Epoch 3:  74%|███████▍  | 20/27 [00:00<00:00, 148.22it/s, train_loss=0.0111, val_loss=0.0254]Epoch 3:  78%|███████▊  | 21/27 [00:00<00:00, 149.60it/s, train_loss=0.0111, val_loss=0.0254]Epoch 3:  78%|███████▊  | 21/27 [00:00<00:00, 148.30it/s, train_loss=0.017, val_loss=0.0254] Epoch 3:  81%|████████▏ | 22/27 [00:00<00:00, 150.16it/s, train_loss=0.017, val_loss=0.0254]Epoch 3:  81%|████████▏ | 22/27 [00:00<00:00, 147.04it/s, train_loss=0.0138, val_loss=0.0254]Epoch 3:  85%|████████▌ | 23/27 [00:00<00:00, 148.67it/s, train_loss=0.0138, val_loss=0.0254]Epoch 3:  85%|████████▌ | 23/27 [00:00<00:00, 147.64it/s, train_loss=0.0255, val_loss=0.0254]Epoch 3:  89%|████████▉ | 24/27 [00:00<00:00, 149.77it/s, train_loss=0.0255, val_loss=0.0254]Epoch 3:  89%|████████▉ | 24/27 [00:00<00:00, 148.54it/s, train_loss=0.0126, val_loss=0.0254]Epoch 3:  93%|█████████▎| 25/27 [00:00<00:00, 150.41it/s, train_loss=0.0126, val_loss=0.0254]Epoch 3:  93%|█████████▎| 25/27 [00:00<00:00, 148.56it/s, train_loss=0.00929, val_loss=0.0254]Epoch 3:  96%|█████████▋| 26/27 [00:00<00:00, 150.36it/s, train_loss=0.00929, val_loss=0.0254]Epoch 3:  96%|█████████▋| 26/27 [00:00<00:00, 149.28it/s, train_loss=0.0209, val_loss=0.0254] Epoch 3: 100%|██████████| 27/27 [00:00<00:00, 151.35it/s, train_loss=0.0209, val_loss=0.0254]Epoch 3: 100%|██████████| 27/27 [00:00<00:00, 150.14it/s, train_loss=0.0137, val_loss=0.0254]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 193.60it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 226.35it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 236.09it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 243.31it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 247.66it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 249.51it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 251.49it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 253.35it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 252.97it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 253.58it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 254.32it/s][A
                                                                         [AEpoch 3: 100%|██████████| 27/27 [00:00<00:00, 117.19it/s, train_loss=0.0137, val_loss=0.0218]Epoch 3: 100%|██████████| 27/27 [00:00<00:00, 116.75it/s, train_loss=0.0137, val_loss=0.0218]Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0137, val_loss=0.0218]          Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0137, val_loss=0.0218]Epoch 4:   4%|▎         | 1/27 [00:00<00:00, 150.44it/s, train_loss=0.0137, val_loss=0.0218]Epoch 4:   4%|▎         | 1/27 [00:00<00:00, 127.56it/s, train_loss=0.0147, val_loss=0.0218]Epoch 4:   7%|▋         | 2/27 [00:00<00:00, 153.07it/s, train_loss=0.0147, val_loss=0.0218]Epoch 4:   7%|▋         | 2/27 [00:00<00:00, 139.47it/s, train_loss=0.0154, val_loss=0.0218]Epoch 4:  11%|█         | 3/27 [00:00<00:00, 153.01it/s, train_loss=0.0154, val_loss=0.0218]Epoch 4:  11%|█         | 3/27 [00:00<00:00, 137.91it/s, train_loss=0.0203, val_loss=0.0218]Epoch 4:  15%|█▍        | 4/27 [00:00<00:00, 145.89it/s, train_loss=0.0203, val_loss=0.0218]Epoch 4:  15%|█▍        | 4/27 [00:00<00:00, 141.28it/s, train_loss=0.0158, val_loss=0.0218]Epoch 4:  19%|█▊        | 5/27 [00:00<00:00, 149.89it/s, train_loss=0.0158, val_loss=0.0218]Epoch 4:  19%|█▊        | 5/27 [00:00<00:00, 137.41it/s, train_loss=0.0193, val_loss=0.0218]Epoch 4:  22%|██▏       | 6/27 [00:00<00:00, 143.62it/s, train_loss=0.0193, val_loss=0.0218]Epoch 4:  22%|██▏       | 6/27 [00:00<00:00, 139.88it/s, train_loss=0.0184, val_loss=0.0218]Epoch 4:  26%|██▌       | 7/27 [00:00<00:00, 146.65it/s, train_loss=0.0184, val_loss=0.0218]Epoch 4:  26%|██▌       | 7/27 [00:00<00:00, 137.26it/s, train_loss=0.0173, val_loss=0.0218]Epoch 4:  30%|██▉       | 8/27 [00:00<00:00, 142.82it/s, train_loss=0.0173, val_loss=0.0218]Epoch 4:  30%|██▉       | 8/27 [00:00<00:00, 140.11it/s, train_loss=0.0125, val_loss=0.0218]Epoch 4:  33%|███▎      | 9/27 [00:00<00:00, 146.13it/s, train_loss=0.0125, val_loss=0.0218]Epoch 4:  33%|███▎      | 9/27 [00:00<00:00, 143.11it/s, train_loss=0.014, val_loss=0.0218] Epoch 4:  37%|███▋      | 10/27 [00:00<00:00, 148.84it/s, train_loss=0.014, val_loss=0.0218]Epoch 4:  37%|███▋      | 10/27 [00:00<00:00, 143.94it/s, train_loss=0.0151, val_loss=0.0218]Epoch 4:  41%|████      | 11/27 [00:00<00:00, 147.72it/s, train_loss=0.0151, val_loss=0.0218]Epoch 4:  41%|████      | 11/27 [00:00<00:00, 145.36it/s, train_loss=0.0159, val_loss=0.0218]Epoch 4:  44%|████▍     | 12/27 [00:00<00:00, 149.63it/s, train_loss=0.0159, val_loss=0.0218]Epoch 4:  44%|████▍     | 12/27 [00:00<00:00, 147.10it/s, train_loss=0.0122, val_loss=0.0218]Epoch 4:  48%|████▊     | 13/27 [00:00<00:00, 151.20it/s, train_loss=0.0122, val_loss=0.0218]Epoch 4:  48%|████▊     | 13/27 [00:00<00:00, 147.56it/s, train_loss=0.0105, val_loss=0.0218]Epoch 4:  52%|█████▏    | 14/27 [00:00<00:00, 150.09it/s, train_loss=0.0105, val_loss=0.0218]Epoch 4:  52%|█████▏    | 14/27 [00:00<00:00, 148.23it/s, train_loss=0.016, val_loss=0.0218] Epoch 4:  56%|█████▌    | 15/27 [00:00<00:00, 151.20it/s, train_loss=0.016, val_loss=0.0218]Epoch 4:  56%|█████▌    | 15/27 [00:00<00:00, 145.95it/s, train_loss=0.0142, val_loss=0.0218]Epoch 4:  59%|█████▉    | 16/27 [00:00<00:00, 148.07it/s, train_loss=0.0142, val_loss=0.0218]Epoch 4:  59%|█████▉    | 16/27 [00:00<00:00, 146.49it/s, train_loss=0.0162, val_loss=0.0218]Epoch 4:  63%|██████▎   | 17/27 [00:00<00:00, 149.26it/s, train_loss=0.0162, val_loss=0.0218]Epoch 4:  63%|██████▎   | 17/27 [00:00<00:00, 144.98it/s, train_loss=0.0144, val_loss=0.0218]Epoch 4:  67%|██████▋   | 18/27 [00:00<00:00, 147.01it/s, train_loss=0.0144, val_loss=0.0218]Epoch 4:  67%|██████▋   | 18/27 [00:00<00:00, 145.61it/s, train_loss=0.0141, val_loss=0.0218]Epoch 4:  70%|███████   | 19/27 [00:00<00:00, 147.92it/s, train_loss=0.0141, val_loss=0.0218]Epoch 4:  70%|███████   | 19/27 [00:00<00:00, 144.30it/s, train_loss=0.0153, val_loss=0.0218]Epoch 4:  74%|███████▍  | 20/27 [00:00<00:00, 145.92it/s, train_loss=0.0153, val_loss=0.0218]Epoch 4:  74%|███████▍  | 20/27 [00:00<00:00, 144.74it/s, train_loss=0.0111, val_loss=0.0218]Epoch 4:  78%|███████▊  | 21/27 [00:00<00:00, 146.86it/s, train_loss=0.0111, val_loss=0.0218]Epoch 4:  78%|███████▊  | 21/27 [00:00<00:00, 143.59it/s, train_loss=0.0148, val_loss=0.0218]Epoch 4:  81%|████████▏ | 22/27 [00:00<00:00, 144.83it/s, train_loss=0.0148, val_loss=0.0218]Epoch 4:  81%|████████▏ | 22/27 [00:00<00:00, 142.68it/s, train_loss=0.012, val_loss=0.0218] Epoch 4:  85%|████████▌ | 23/27 [00:00<00:00, 141.28it/s, train_loss=0.012, val_loss=0.0218]Epoch 4:  85%|████████▌ | 23/27 [00:00<00:00, 140.37it/s, train_loss=0.0148, val_loss=0.0218]Epoch 4:  89%|████████▉ | 24/27 [00:00<00:00, 142.09it/s, train_loss=0.0148, val_loss=0.0218]Epoch 4:  89%|████████▉ | 24/27 [00:00<00:00, 140.96it/s, train_loss=0.0082, val_loss=0.0218]Epoch 4:  93%|█████████▎| 25/27 [00:00<00:00, 142.47it/s, train_loss=0.0082, val_loss=0.0218]Epoch 4:  93%|█████████▎| 25/27 [00:00<00:00, 141.33it/s, train_loss=0.0111, val_loss=0.0218]Epoch 4:  96%|█████████▋| 26/27 [00:00<00:00, 142.91it/s, train_loss=0.0111, val_loss=0.0218]Epoch 4:  96%|█████████▋| 26/27 [00:00<00:00, 141.96it/s, train_loss=0.0169, val_loss=0.0218]Epoch 4: 100%|██████████| 27/27 [00:00<00:00, 144.04it/s, train_loss=0.0169, val_loss=0.0218]Epoch 4: 100%|██████████| 27/27 [00:00<00:00, 141.15it/s, train_loss=0.010, val_loss=0.0218] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 166.76it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 201.51it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 225.93it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 237.11it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 245.05it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 247.10it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 249.92it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 253.03it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 254.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 255.17it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 256.68it/s][A
                                                                         [AEpoch 4: 100%|██████████| 27/27 [00:00<00:00, 112.37it/s, train_loss=0.010, val_loss=0.0169]Epoch 4: 100%|██████████| 27/27 [00:00<00:00, 111.94it/s, train_loss=0.010, val_loss=0.0169]Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.010, val_loss=0.0169]          Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.010, val_loss=0.0169]Epoch 5:   4%|▎         | 1/27 [00:00<00:00, 159.55it/s, train_loss=0.010, val_loss=0.0169]Epoch 5:   4%|▎         | 1/27 [00:00<00:00, 134.19it/s, train_loss=0.0111, val_loss=0.0169]Epoch 5:   7%|▋         | 2/27 [00:00<00:00, 155.92it/s, train_loss=0.0111, val_loss=0.0169]Epoch 5:   7%|▋         | 2/27 [00:00<00:00, 136.21it/s, train_loss=0.00948, val_loss=0.0169]Epoch 5:  11%|█         | 3/27 [00:00<00:00, 150.67it/s, train_loss=0.00948, val_loss=0.0169]Epoch 5:  11%|█         | 3/27 [00:00<00:00, 142.14it/s, train_loss=0.0117, val_loss=0.0169] Epoch 5:  15%|█▍        | 4/27 [00:00<00:00, 155.51it/s, train_loss=0.0117, val_loss=0.0169]Epoch 5:  15%|█▍        | 4/27 [00:00<00:00, 136.85it/s, train_loss=0.0108, val_loss=0.0169]Epoch 5:  19%|█▊        | 5/27 [00:00<00:00, 142.42it/s, train_loss=0.0108, val_loss=0.0169]Epoch 5:  19%|█▊        | 5/27 [00:00<00:00, 138.46it/s, train_loss=0.0129, val_loss=0.0169]Epoch 5:  22%|██▏       | 6/27 [00:00<00:00, 145.52it/s, train_loss=0.0129, val_loss=0.0169]Epoch 5:  22%|██▏       | 6/27 [00:00<00:00, 135.87it/s, train_loss=0.0153, val_loss=0.0169]Epoch 5:  26%|██▌       | 7/27 [00:00<00:00, 140.70it/s, train_loss=0.0153, val_loss=0.0169]Epoch 5:  26%|██▌       | 7/27 [00:00<00:00, 137.45it/s, train_loss=0.0131, val_loss=0.0169]Epoch 5:  30%|██▉       | 8/27 [00:00<00:00, 143.31it/s, train_loss=0.0131, val_loss=0.0169]Epoch 5:  30%|██▉       | 8/27 [00:00<00:00, 135.85it/s, train_loss=0.0114, val_loss=0.0169]Epoch 5:  33%|███▎      | 9/27 [00:00<00:00, 139.91it/s, train_loss=0.0114, val_loss=0.0169]Epoch 5:  33%|███▎      | 9/27 [00:00<00:00, 137.59it/s, train_loss=0.0144, val_loss=0.0169]Epoch 5:  37%|███▋      | 10/27 [00:00<00:00, 141.97it/s, train_loss=0.0144, val_loss=0.0169]Epoch 5:  37%|███▋      | 10/27 [00:00<00:00, 135.99it/s, train_loss=0.0164, val_loss=0.0169]Epoch 5:  41%|████      | 11/27 [00:00<00:00, 139.26it/s, train_loss=0.0164, val_loss=0.0169]Epoch 5:  41%|████      | 11/27 [00:00<00:00, 137.40it/s, train_loss=0.0109, val_loss=0.0169]Epoch 5:  44%|████▍     | 12/27 [00:00<00:00, 140.25it/s, train_loss=0.0109, val_loss=0.0169]Epoch 5:  44%|████▍     | 12/27 [00:00<00:00, 136.11it/s, train_loss=0.00821, val_loss=0.0169]Epoch 5:  48%|████▊     | 13/27 [00:00<00:00, 139.61it/s, train_loss=0.00821, val_loss=0.0169]Epoch 5:  48%|████▊     | 13/27 [00:00<00:00, 137.86it/s, train_loss=0.0134, val_loss=0.0169] Epoch 5:  52%|█████▏    | 14/27 [00:00<00:00, 141.89it/s, train_loss=0.0134, val_loss=0.0169]Epoch 5:  52%|█████▏    | 14/27 [00:00<00:00, 139.97it/s, train_loss=0.0116, val_loss=0.0169]Epoch 5:  56%|█████▌    | 15/27 [00:00<00:00, 142.88it/s, train_loss=0.0116, val_loss=0.0169]Epoch 5:  56%|█████▌    | 15/27 [00:00<00:00, 140.39it/s, train_loss=0.00972, val_loss=0.0169]Epoch 5:  59%|█████▉    | 16/27 [00:00<00:00, 142.97it/s, train_loss=0.00972, val_loss=0.0169]Epoch 5:  59%|█████▉    | 16/27 [00:00<00:00, 141.52it/s, train_loss=0.00734, val_loss=0.0169]Epoch 5:  63%|██████▎   | 17/27 [00:00<00:00, 144.65it/s, train_loss=0.00734, val_loss=0.0169]Epoch 5:  63%|██████▎   | 17/27 [00:00<00:00, 142.84it/s, train_loss=0.0105, val_loss=0.0169] Epoch 5:  67%|██████▋   | 18/27 [00:00<00:00, 145.71it/s, train_loss=0.0105, val_loss=0.0169]Epoch 5:  67%|██████▋   | 18/27 [00:00<00:00, 143.31it/s, train_loss=0.00836, val_loss=0.0169]Epoch 5:  70%|███████   | 19/27 [00:00<00:00, 145.50it/s, train_loss=0.00836, val_loss=0.0169]Epoch 5:  70%|███████   | 19/27 [00:00<00:00, 144.24it/s, train_loss=0.00965, val_loss=0.0169]Epoch 5:  74%|███████▍  | 20/27 [00:00<00:00, 146.72it/s, train_loss=0.00965, val_loss=0.0169]Epoch 5:  74%|███████▍  | 20/27 [00:00<00:00, 142.91it/s, train_loss=0.00875, val_loss=0.0169]Epoch 5:  78%|███████▊  | 21/27 [00:00<00:00, 144.82it/s, train_loss=0.00875, val_loss=0.0169]Epoch 5:  78%|███████▊  | 21/27 [00:00<00:00, 143.59it/s, train_loss=0.00778, val_loss=0.0169]Epoch 5:  81%|████████▏ | 22/27 [00:00<00:00, 145.43it/s, train_loss=0.00778, val_loss=0.0169]Epoch 5:  81%|████████▏ | 22/27 [00:00<00:00, 143.62it/s, train_loss=0.0131, val_loss=0.0169] Epoch 5:  85%|████████▌ | 23/27 [00:00<00:00, 145.54it/s, train_loss=0.0131, val_loss=0.0169]Epoch 5:  85%|████████▌ | 23/27 [00:00<00:00, 144.49it/s, train_loss=0.0058, val_loss=0.0169]Epoch 5:  89%|████████▉ | 24/27 [00:00<00:00, 146.15it/s, train_loss=0.0058, val_loss=0.0169]Epoch 5:  89%|████████▉ | 24/27 [00:00<00:00, 144.41it/s, train_loss=0.0115, val_loss=0.0169]Epoch 5:  93%|█████████▎| 25/27 [00:00<00:00, 146.01it/s, train_loss=0.0115, val_loss=0.0169]Epoch 5:  93%|█████████▎| 25/27 [00:00<00:00, 145.02it/s, train_loss=0.0129, val_loss=0.0169]Epoch 5:  96%|█████████▋| 26/27 [00:00<00:00, 146.50it/s, train_loss=0.0129, val_loss=0.0169]Epoch 5:  96%|█████████▋| 26/27 [00:00<00:00, 145.00it/s, train_loss=0.00944, val_loss=0.0169]Epoch 5: 100%|██████████| 27/27 [00:00<00:00, 146.37it/s, train_loss=0.00944, val_loss=0.0169]Epoch 5: 100%|██████████| 27/27 [00:00<00:00, 145.48it/s, train_loss=0.0103, val_loss=0.0169] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 139.52it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 171.01it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 182.65it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 190.42it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 191.72it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 201.42it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 212.12it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 220.72it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 228.13it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 234.40it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 239.38it/s][A
                                                                         [AEpoch 5: 100%|██████████| 27/27 [00:00<00:00, 113.30it/s, train_loss=0.0103, val_loss=0.0103]Epoch 5: 100%|██████████| 27/27 [00:00<00:00, 112.98it/s, train_loss=0.0103, val_loss=0.0103]Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0103, val_loss=0.0103]          Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0103, val_loss=0.0103]Epoch 6:   4%|▎         | 1/27 [00:00<00:00, 165.98it/s, train_loss=0.0103, val_loss=0.0103]Epoch 6:   4%|▎         | 1/27 [00:00<00:00, 141.50it/s, train_loss=0.00825, val_loss=0.0103]Epoch 6:   7%|▋         | 2/27 [00:00<00:00, 168.97it/s, train_loss=0.00825, val_loss=0.0103]Epoch 6:   7%|▋         | 2/27 [00:00<00:00, 153.37it/s, train_loss=0.00682, val_loss=0.0103]Epoch 6:  11%|█         | 3/27 [00:00<00:00, 161.82it/s, train_loss=0.00682, val_loss=0.0103]Epoch 6:  11%|█         | 3/27 [00:00<00:00, 153.20it/s, train_loss=0.00944, val_loss=0.0103]Epoch 6:  15%|█▍        | 4/27 [00:00<00:00, 162.74it/s, train_loss=0.00944, val_loss=0.0103]Epoch 6:  15%|█▍        | 4/27 [00:00<00:00, 154.96it/s, train_loss=0.00907, val_loss=0.0103]Epoch 6:  19%|█▊        | 5/27 [00:00<00:00, 161.04it/s, train_loss=0.00907, val_loss=0.0103]Epoch 6:  19%|█▊        | 5/27 [00:00<00:00, 152.27it/s, train_loss=0.0115, val_loss=0.0103] Epoch 6:  22%|██▏       | 6/27 [00:00<00:00, 158.47it/s, train_loss=0.0115, val_loss=0.0103]Epoch 6:  22%|██▏       | 6/27 [00:00<00:00, 153.33it/s, train_loss=0.00836, val_loss=0.0103]Epoch 6:  26%|██▌       | 7/27 [00:00<00:00, 158.10it/s, train_loss=0.00836, val_loss=0.0103]Epoch 6:  26%|██▌       | 7/27 [00:00<00:00, 150.95it/s, train_loss=0.00976, val_loss=0.0103]Epoch 6:  30%|██▉       | 8/27 [00:00<00:00, 155.43it/s, train_loss=0.00976, val_loss=0.0103]Epoch 6:  30%|██▉       | 8/27 [00:00<00:00, 151.70it/s, train_loss=0.00772, val_loss=0.0103]Epoch 6:  33%|███▎      | 9/27 [00:00<00:00, 155.02it/s, train_loss=0.00772, val_loss=0.0103]Epoch 6:  33%|███▎      | 9/27 [00:00<00:00, 150.61it/s, train_loss=0.00963, val_loss=0.0103]Epoch 6:  37%|███▋      | 10/27 [00:00<00:00, 153.58it/s, train_loss=0.00963, val_loss=0.0103]Epoch 6:  37%|███▋      | 10/27 [00:00<00:00, 150.68it/s, train_loss=0.0085, val_loss=0.0103] Epoch 6:  41%|████      | 11/27 [00:00<00:00, 153.73it/s, train_loss=0.0085, val_loss=0.0103]Epoch 6:  41%|████      | 11/27 [00:00<00:00, 149.88it/s, train_loss=0.00921, val_loss=0.0103]Epoch 6:  44%|████▍     | 12/27 [00:00<00:00, 153.01it/s, train_loss=0.00921, val_loss=0.0103]Epoch 6:  44%|████▍     | 12/27 [00:00<00:00, 150.51it/s, train_loss=0.00618, val_loss=0.0103]Epoch 6:  48%|████▊     | 13/27 [00:00<00:00, 153.07it/s, train_loss=0.00618, val_loss=0.0103]Epoch 6:  48%|████▊     | 13/27 [00:00<00:00, 149.98it/s, train_loss=0.00584, val_loss=0.0103]Epoch 6:  52%|█████▏    | 14/27 [00:00<00:00, 152.33it/s, train_loss=0.00584, val_loss=0.0103]Epoch 6:  52%|█████▏    | 14/27 [00:00<00:00, 150.37it/s, train_loss=0.00715, val_loss=0.0103]Epoch 6:  56%|█████▌    | 15/27 [00:00<00:00, 152.52it/s, train_loss=0.00715, val_loss=0.0103]Epoch 6:  56%|█████▌    | 15/27 [00:00<00:00, 149.90it/s, train_loss=0.0083, val_loss=0.0103] Epoch 6:  59%|█████▉    | 16/27 [00:00<00:00, 151.85it/s, train_loss=0.0083, val_loss=0.0103]Epoch 6:  59%|█████▉    | 16/27 [00:00<00:00, 150.09it/s, train_loss=0.00958, val_loss=0.0103]Epoch 6:  63%|██████▎   | 17/27 [00:00<00:00, 152.37it/s, train_loss=0.00958, val_loss=0.0103]Epoch 6:  63%|██████▎   | 17/27 [00:00<00:00, 149.65it/s, train_loss=0.00921, val_loss=0.0103]Epoch 6:  67%|██████▋   | 18/27 [00:00<00:00, 151.95it/s, train_loss=0.00921, val_loss=0.0103]Epoch 6:  67%|██████▋   | 18/27 [00:00<00:00, 150.40it/s, train_loss=0.00888, val_loss=0.0103]Epoch 6:  70%|███████   | 19/27 [00:00<00:00, 153.09it/s, train_loss=0.00888, val_loss=0.0103]Epoch 6:  70%|███████   | 19/27 [00:00<00:00, 151.30it/s, train_loss=0.00945, val_loss=0.0103]Epoch 6:  74%|███████▍  | 20/27 [00:00<00:00, 152.97it/s, train_loss=0.00945, val_loss=0.0103]Epoch 6:  74%|███████▍  | 20/27 [00:00<00:00, 151.66it/s, train_loss=0.0105, val_loss=0.0103] Epoch 6:  78%|███████▊  | 21/27 [00:00<00:00, 153.61it/s, train_loss=0.0105, val_loss=0.0103]Epoch 6:  78%|███████▊  | 21/27 [00:00<00:00, 152.38it/s, train_loss=0.00791, val_loss=0.0103]Epoch 6:  81%|████████▏ | 22/27 [00:00<00:00, 154.03it/s, train_loss=0.00791, val_loss=0.0103]Epoch 6:  81%|████████▏ | 22/27 [00:00<00:00, 151.81it/s, train_loss=0.0104, val_loss=0.0103] Epoch 6:  85%|████████▌ | 23/27 [00:00<00:00, 153.36it/s, train_loss=0.0104, val_loss=0.0103]Epoch 6:  85%|████████▌ | 23/27 [00:00<00:00, 152.14it/s, train_loss=0.00982, val_loss=0.0103]Epoch 6:  89%|████████▉ | 24/27 [00:00<00:00, 154.07it/s, train_loss=0.00982, val_loss=0.0103]Epoch 6:  89%|████████▉ | 24/27 [00:00<00:00, 151.48it/s, train_loss=0.00716, val_loss=0.0103]Epoch 6:  93%|█████████▎| 25/27 [00:00<00:00, 152.42it/s, train_loss=0.00716, val_loss=0.0103]Epoch 6:  93%|█████████▎| 25/27 [00:00<00:00, 151.28it/s, train_loss=0.0086, val_loss=0.0103] Epoch 6:  96%|█████████▋| 26/27 [00:00<00:00, 152.83it/s, train_loss=0.0086, val_loss=0.0103]Epoch 6:  96%|█████████▋| 26/27 [00:00<00:00, 151.75it/s, train_loss=0.00744, val_loss=0.0103]Epoch 6: 100%|██████████| 27/27 [00:00<00:00, 152.88it/s, train_loss=0.00744, val_loss=0.0103]Epoch 6: 100%|██████████| 27/27 [00:00<00:00, 151.88it/s, train_loss=0.00515, val_loss=0.0103]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 167.73it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 194.25it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 208.15it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 214.15it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 218.60it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 218.53it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 220.29it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 219.92it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 204.67it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 204.81it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 205.98it/s][A
                                                                         [AEpoch 6: 100%|██████████| 27/27 [00:00<00:00, 112.92it/s, train_loss=0.00515, val_loss=0.00832]Epoch 6: 100%|██████████| 27/27 [00:00<00:00, 112.42it/s, train_loss=0.00515, val_loss=0.00832]Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00515, val_loss=0.00832]          Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00515, val_loss=0.00832]Epoch 7:   4%|▎         | 1/27 [00:00<00:00, 167.92it/s, train_loss=0.00515, val_loss=0.00832]Epoch 7:   4%|▎         | 1/27 [00:00<00:00, 140.37it/s, train_loss=0.00774, val_loss=0.00832]Epoch 7:   7%|▋         | 2/27 [00:00<00:00, 165.59it/s, train_loss=0.00774, val_loss=0.00832]Epoch 7:   7%|▋         | 2/27 [00:00<00:00, 147.62it/s, train_loss=0.00716, val_loss=0.00832]Epoch 7:  11%|█         | 3/27 [00:00<00:00, 163.94it/s, train_loss=0.00716, val_loss=0.00832]Epoch 7:  11%|█         | 3/27 [00:00<00:00, 154.32it/s, train_loss=0.0104, val_loss=0.00832] Epoch 7:  15%|█▍        | 4/27 [00:00<00:00, 167.46it/s, train_loss=0.0104, val_loss=0.00832]Epoch 7:  15%|█▍        | 4/27 [00:00<00:00, 157.67it/s, train_loss=0.00747, val_loss=0.00832]Epoch 7:  19%|█▊        | 5/27 [00:00<00:00, 161.46it/s, train_loss=0.00747, val_loss=0.00832]Epoch 7:  19%|█▊        | 5/27 [00:00<00:00, 156.02it/s, train_loss=0.00733, val_loss=0.00832]Epoch 7:  22%|██▏       | 6/27 [00:00<00:00, 162.20it/s, train_loss=0.00733, val_loss=0.00832]Epoch 7:  22%|██▏       | 6/27 [00:00<00:00, 157.00it/s, train_loss=0.00724, val_loss=0.00832]Epoch 7:  26%|██▌       | 7/27 [00:00<00:00, 161.57it/s, train_loss=0.00724, val_loss=0.00832]Epoch 7:  26%|██▌       | 7/27 [00:00<00:00, 154.47it/s, train_loss=0.00499, val_loss=0.00832]Epoch 7:  30%|██▉       | 8/27 [00:00<00:00, 158.53it/s, train_loss=0.00499, val_loss=0.00832]Epoch 7:  30%|██▉       | 8/27 [00:00<00:00, 154.88it/s, train_loss=0.00925, val_loss=0.00832]Epoch 7:  33%|███▎      | 9/27 [00:00<00:00, 159.87it/s, train_loss=0.00925, val_loss=0.00832]Epoch 7:  33%|███▎      | 9/27 [00:00<00:00, 152.85it/s, train_loss=0.00586, val_loss=0.00832]Epoch 7:  37%|███▋      | 10/27 [00:00<00:00, 154.66it/s, train_loss=0.00586, val_loss=0.00832]Epoch 7:  37%|███▋      | 10/27 [00:00<00:00, 151.99it/s, train_loss=0.00707, val_loss=0.00832]Epoch 7:  41%|████      | 11/27 [00:00<00:00, 155.42it/s, train_loss=0.00707, val_loss=0.00832]Epoch 7:  41%|████      | 11/27 [00:00<00:00, 152.93it/s, train_loss=0.00788, val_loss=0.00832]Epoch 7:  44%|████▍     | 12/27 [00:00<00:00, 155.01it/s, train_loss=0.00788, val_loss=0.00832]Epoch 7:  44%|████▍     | 12/27 [00:00<00:00, 152.68it/s, train_loss=0.00604, val_loss=0.00832]Epoch 7:  48%|████▊     | 13/27 [00:00<00:00, 154.75it/s, train_loss=0.00604, val_loss=0.00832]Epoch 7:  48%|████▊     | 13/27 [00:00<00:00, 152.49it/s, train_loss=0.00666, val_loss=0.00832]Epoch 7:  52%|█████▏    | 14/27 [00:00<00:00, 154.12it/s, train_loss=0.00666, val_loss=0.00832]Epoch 7:  52%|█████▏    | 14/27 [00:00<00:00, 152.50it/s, train_loss=0.00771, val_loss=0.00832]Epoch 7:  56%|█████▌    | 15/27 [00:00<00:00, 154.29it/s, train_loss=0.00771, val_loss=0.00832]Epoch 7:  56%|█████▌    | 15/27 [00:00<00:00, 152.43it/s, train_loss=0.0063, val_loss=0.00832] Epoch 7:  59%|█████▉    | 16/27 [00:00<00:00, 154.35it/s, train_loss=0.0063, val_loss=0.00832]Epoch 7:  59%|█████▉    | 16/27 [00:00<00:00, 151.93it/s, train_loss=0.00703, val_loss=0.00832]Epoch 7:  63%|██████▎   | 17/27 [00:00<00:00, 153.68it/s, train_loss=0.00703, val_loss=0.00832]Epoch 7:  63%|██████▎   | 17/27 [00:00<00:00, 152.05it/s, train_loss=0.00808, val_loss=0.00832]Epoch 7:  67%|██████▋   | 18/27 [00:00<00:00, 153.42it/s, train_loss=0.00808, val_loss=0.00832]Epoch 7:  67%|██████▋   | 18/27 [00:00<00:00, 151.56it/s, train_loss=0.0053, val_loss=0.00832] Epoch 7:  70%|███████   | 19/27 [00:00<00:00, 152.99it/s, train_loss=0.0053, val_loss=0.00832]Epoch 7:  70%|███████   | 19/27 [00:00<00:00, 151.67it/s, train_loss=0.00574, val_loss=0.00832]Epoch 7:  74%|███████▍  | 20/27 [00:00<00:00, 153.56it/s, train_loss=0.00574, val_loss=0.00832]Epoch 7:  74%|███████▍  | 20/27 [00:00<00:00, 151.17it/s, train_loss=0.00825, val_loss=0.00832]Epoch 7:  78%|███████▊  | 21/27 [00:00<00:00, 153.16it/s, train_loss=0.00825, val_loss=0.00832]Epoch 7:  78%|███████▊  | 21/27 [00:00<00:00, 151.75it/s, train_loss=0.00629, val_loss=0.00832]Epoch 7:  81%|████████▏ | 22/27 [00:00<00:00, 154.06it/s, train_loss=0.00629, val_loss=0.00832]Epoch 7:  81%|████████▏ | 22/27 [00:00<00:00, 152.49it/s, train_loss=0.00815, val_loss=0.00832]Epoch 7:  85%|████████▌ | 23/27 [00:00<00:00, 154.12it/s, train_loss=0.00815, val_loss=0.00832]Epoch 7:  85%|████████▌ | 23/27 [00:00<00:00, 152.84it/s, train_loss=0.00736, val_loss=0.00832]Epoch 7:  89%|████████▉ | 24/27 [00:00<00:00, 154.68it/s, train_loss=0.00736, val_loss=0.00832]Epoch 7:  89%|████████▉ | 24/27 [00:00<00:00, 153.44it/s, train_loss=0.00635, val_loss=0.00832]Epoch 7:  93%|█████████▎| 25/27 [00:00<00:00, 155.05it/s, train_loss=0.00635, val_loss=0.00832]Epoch 7:  93%|█████████▎| 25/27 [00:00<00:00, 152.94it/s, train_loss=0.00624, val_loss=0.00832]Epoch 7:  96%|█████████▋| 26/27 [00:00<00:00, 154.44it/s, train_loss=0.00624, val_loss=0.00832]Epoch 7:  96%|█████████▋| 26/27 [00:00<00:00, 153.26it/s, train_loss=0.00666, val_loss=0.00832]Epoch 7: 100%|██████████| 27/27 [00:00<00:00, 154.98it/s, train_loss=0.00666, val_loss=0.00832]Epoch 7: 100%|██████████| 27/27 [00:00<00:00, 153.86it/s, train_loss=0.0064, val_loss=0.00832] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 171.66it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 202.32it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 212.02it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 220.51it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 222.44it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 226.15it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 226.28it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 228.23it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 228.63it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 229.88it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 231.20it/s][A
                                                                         [AEpoch 7: 100%|██████████| 27/27 [00:00<00:00, 117.16it/s, train_loss=0.0064, val_loss=0.00712]Epoch 7: 100%|██████████| 27/27 [00:00<00:00, 116.67it/s, train_loss=0.0064, val_loss=0.00712]Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0064, val_loss=0.00712]          Epoch 8:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0064, val_loss=0.00712]Epoch 8:   4%|▎         | 1/27 [00:00<00:00, 156.43it/s, train_loss=0.0064, val_loss=0.00712]Epoch 8:   4%|▎         | 1/27 [00:00<00:00, 133.65it/s, train_loss=0.00825, val_loss=0.00712]Epoch 8:   7%|▋         | 2/27 [00:00<00:00, 153.80it/s, train_loss=0.00825, val_loss=0.00712]Epoch 8:   7%|▋         | 2/27 [00:00<00:00, 139.25it/s, train_loss=0.00714, val_loss=0.00712]Epoch 8:  11%|█         | 3/27 [00:00<00:00, 152.73it/s, train_loss=0.00714, val_loss=0.00712]Epoch 8:  11%|█         | 3/27 [00:00<00:00, 143.75it/s, train_loss=0.00697, val_loss=0.00712]Epoch 8:  15%|█▍        | 4/27 [00:00<00:00, 152.52it/s, train_loss=0.00697, val_loss=0.00712]Epoch 8:  15%|█▍        | 4/27 [00:00<00:00, 143.76it/s, train_loss=0.00581, val_loss=0.00712]Epoch 8:  19%|█▊        | 5/27 [00:00<00:00, 153.11it/s, train_loss=0.00581, val_loss=0.00712]Epoch 8:  19%|█▊        | 5/27 [00:00<00:00, 147.43it/s, train_loss=0.00752, val_loss=0.00712]Epoch 8:  22%|██▏       | 6/27 [00:00<00:00, 156.43it/s, train_loss=0.00752, val_loss=0.00712]Epoch 8:  22%|██▏       | 6/27 [00:00<00:00, 150.75it/s, train_loss=0.00418, val_loss=0.00712]Epoch 8:  26%|██▌       | 7/27 [00:00<00:00, 155.34it/s, train_loss=0.00418, val_loss=0.00712]Epoch 8:  26%|██▌       | 7/27 [00:00<00:00, 151.63it/s, train_loss=0.00494, val_loss=0.00712]Epoch 8:  30%|██▉       | 8/27 [00:00<00:00, 156.84it/s, train_loss=0.00494, val_loss=0.00712]Epoch 8:  30%|██▉       | 8/27 [00:00<00:00, 152.72it/s, train_loss=0.00552, val_loss=0.00712]Epoch 8:  33%|███▎      | 9/27 [00:00<00:00, 156.60it/s, train_loss=0.00552, val_loss=0.00712]Epoch 8:  33%|███▎      | 9/27 [00:00<00:00, 152.17it/s, train_loss=0.00432, val_loss=0.00712]Epoch 8:  37%|███▋      | 10/27 [00:00<00:00, 156.25it/s, train_loss=0.00432, val_loss=0.00712]Epoch 8:  37%|███▋      | 10/27 [00:00<00:00, 153.53it/s, train_loss=0.00721, val_loss=0.00712]Epoch 8:  41%|████      | 11/27 [00:00<00:00, 158.06it/s, train_loss=0.00721, val_loss=0.00712]Epoch 8:  41%|████      | 11/27 [00:00<00:00, 155.09it/s, train_loss=0.00533, val_loss=0.00712]Epoch 8:  44%|████▍     | 12/27 [00:00<00:00, 157.44it/s, train_loss=0.00533, val_loss=0.00712]Epoch 8:  44%|████▍     | 12/27 [00:00<00:00, 155.11it/s, train_loss=0.00672, val_loss=0.00712]Epoch 8:  48%|████▊     | 13/27 [00:00<00:00, 157.91it/s, train_loss=0.00672, val_loss=0.00712]Epoch 8:  48%|████▊     | 13/27 [00:00<00:00, 155.80it/s, train_loss=0.00787, val_loss=0.00712]Epoch 8:  52%|█████▏    | 14/27 [00:00<00:00, 158.18it/s, train_loss=0.00787, val_loss=0.00712]Epoch 8:  52%|█████▏    | 14/27 [00:00<00:00, 154.97it/s, train_loss=0.00566, val_loss=0.00712]Epoch 8:  56%|█████▌    | 15/27 [00:00<00:00, 157.21it/s, train_loss=0.00566, val_loss=0.00712]Epoch 8:  56%|█████▌    | 15/27 [00:00<00:00, 155.11it/s, train_loss=0.00521, val_loss=0.00712]Epoch 8:  59%|█████▉    | 16/27 [00:00<00:00, 157.08it/s, train_loss=0.00521, val_loss=0.00712]Epoch 8:  59%|█████▉    | 16/27 [00:00<00:00, 154.26it/s, train_loss=0.00727, val_loss=0.00712]Epoch 8:  63%|██████▎   | 17/27 [00:00<00:00, 156.04it/s, train_loss=0.00727, val_loss=0.00712]Epoch 8:  63%|██████▎   | 17/27 [00:00<00:00, 154.25it/s, train_loss=0.00599, val_loss=0.00712]Epoch 8:  67%|██████▋   | 18/27 [00:00<00:00, 156.09it/s, train_loss=0.00599, val_loss=0.00712]Epoch 8:  67%|██████▋   | 18/27 [00:00<00:00, 153.67it/s, train_loss=0.00521, val_loss=0.00712]Epoch 8:  70%|███████   | 19/27 [00:00<00:00, 155.39it/s, train_loss=0.00521, val_loss=0.00712]Epoch 8:  70%|███████   | 19/27 [00:00<00:00, 153.74it/s, train_loss=0.00788, val_loss=0.00712]Epoch 8:  74%|███████▍  | 20/27 [00:00<00:00, 155.79it/s, train_loss=0.00788, val_loss=0.00712]Epoch 8:  74%|███████▍  | 20/27 [00:00<00:00, 152.85it/s, train_loss=0.00591, val_loss=0.00712]Epoch 8:  78%|███████▊  | 21/27 [00:00<00:00, 154.03it/s, train_loss=0.00591, val_loss=0.00712]Epoch 8:  78%|███████▊  | 21/27 [00:00<00:00, 152.85it/s, train_loss=0.00449, val_loss=0.00712]Epoch 8:  81%|████████▏ | 22/27 [00:00<00:00, 154.04it/s, train_loss=0.00449, val_loss=0.00712]Epoch 8:  81%|████████▏ | 22/27 [00:00<00:00, 152.51it/s, train_loss=0.00475, val_loss=0.00712]Epoch 8:  85%|████████▌ | 23/27 [00:00<00:00, 153.68it/s, train_loss=0.00475, val_loss=0.00712]Epoch 8:  85%|████████▌ | 23/27 [00:00<00:00, 152.53it/s, train_loss=0.00615, val_loss=0.00712]Epoch 8:  89%|████████▉ | 24/27 [00:00<00:00, 154.11it/s, train_loss=0.00615, val_loss=0.00712]Epoch 8:  89%|████████▉ | 24/27 [00:00<00:00, 152.08it/s, train_loss=0.0069, val_loss=0.00712] Epoch 8:  93%|█████████▎| 25/27 [00:00<00:00, 153.57it/s, train_loss=0.0069, val_loss=0.00712]Epoch 8:  93%|█████████▎| 25/27 [00:00<00:00, 152.49it/s, train_loss=0.00535, val_loss=0.00712]Epoch 8:  96%|█████████▋| 26/27 [00:00<00:00, 154.39it/s, train_loss=0.00535, val_loss=0.00712]Epoch 8:  96%|█████████▋| 26/27 [00:00<00:00, 153.21it/s, train_loss=0.00699, val_loss=0.00712]Epoch 8: 100%|██████████| 27/27 [00:00<00:00, 154.26it/s, train_loss=0.00699, val_loss=0.00712]Epoch 8: 100%|██████████| 27/27 [00:00<00:00, 153.25it/s, train_loss=0.00617, val_loss=0.00712]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 198.90it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 229.62it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 234.87it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 241.39it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 242.34it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 244.86it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 246.15it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 247.67it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 249.25it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 248.14it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 249.49it/s][A
                                                                         [AEpoch 8: 100%|██████████| 27/27 [00:00<00:00, 118.95it/s, train_loss=0.00617, val_loss=0.0066] Epoch 8: 100%|██████████| 27/27 [00:00<00:00, 118.43it/s, train_loss=0.00617, val_loss=0.0066]Epoch 8:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00617, val_loss=0.0066]          Epoch 9:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00617, val_loss=0.0066]Epoch 9:   4%|▎         | 1/27 [00:00<00:00, 100.01it/s, train_loss=0.00617, val_loss=0.0066]Epoch 9:   4%|▎         | 1/27 [00:00<00:00, 91.59it/s, train_loss=0.0046, val_loss=0.0066]  Epoch 9:   7%|▋         | 2/27 [00:00<00:00, 122.51it/s, train_loss=0.0046, val_loss=0.0066]Epoch 9:   7%|▋         | 2/27 [00:00<00:00, 113.59it/s, train_loss=0.0048, val_loss=0.0066]Epoch 9:  11%|█         | 3/27 [00:00<00:00, 129.14it/s, train_loss=0.0048, val_loss=0.0066]Epoch 9:  11%|█         | 3/27 [00:00<00:00, 123.07it/s, train_loss=0.00584, val_loss=0.0066]Epoch 9:  15%|█▍        | 4/27 [00:00<00:00, 132.30it/s, train_loss=0.00584, val_loss=0.0066]Epoch 9:  15%|█▍        | 4/27 [00:00<00:00, 127.27it/s, train_loss=0.00409, val_loss=0.0066]Epoch 9:  19%|█▊        | 5/27 [00:00<00:00, 135.99it/s, train_loss=0.00409, val_loss=0.0066]Epoch 9:  19%|█▊        | 5/27 [00:00<00:00, 131.76it/s, train_loss=0.00586, val_loss=0.0066]Epoch 9:  22%|██▏       | 6/27 [00:00<00:00, 139.44it/s, train_loss=0.00586, val_loss=0.0066]Epoch 9:  22%|██▏       | 6/27 [00:00<00:00, 135.91it/s, train_loss=0.00582, val_loss=0.0066]Epoch 9:  26%|██▌       | 7/27 [00:00<00:00, 141.29it/s, train_loss=0.00582, val_loss=0.0066]Epoch 9:  26%|██▌       | 7/27 [00:00<00:00, 137.55it/s, train_loss=0.00587, val_loss=0.0066]Epoch 9:  30%|██▉       | 8/27 [00:00<00:00, 142.64it/s, train_loss=0.00587, val_loss=0.0066]Epoch 9:  30%|██▉       | 8/27 [00:00<00:00, 139.37it/s, train_loss=0.00658, val_loss=0.0066]Epoch 9:  33%|███▎      | 9/27 [00:00<00:00, 144.81it/s, train_loss=0.00658, val_loss=0.0066]Epoch 9:  33%|███▎      | 9/27 [00:00<00:00, 139.75it/s, train_loss=0.00518, val_loss=0.0066]Epoch 9:  37%|███▋      | 10/27 [00:00<00:00, 144.37it/s, train_loss=0.00518, val_loss=0.0066]Epoch 9:  37%|███▋      | 10/27 [00:00<00:00, 141.92it/s, train_loss=0.00474, val_loss=0.0066]Epoch 9:  41%|████      | 11/27 [00:00<00:00, 146.67it/s, train_loss=0.00474, val_loss=0.0066]Epoch 9:  41%|████      | 11/27 [00:00<00:00, 144.27it/s, train_loss=0.00474, val_loss=0.0066]Epoch 9:  44%|████▍     | 12/27 [00:00<00:00, 146.93it/s, train_loss=0.00474, val_loss=0.0066]Epoch 9:  44%|████▍     | 12/27 [00:00<00:00, 145.02it/s, train_loss=0.00625, val_loss=0.0066]Epoch 9:  48%|████▊     | 13/27 [00:00<00:00, 148.25it/s, train_loss=0.00625, val_loss=0.0066]Epoch 9:  48%|████▊     | 13/27 [00:00<00:00, 146.16it/s, train_loss=0.00598, val_loss=0.0066]Epoch 9:  52%|█████▏    | 14/27 [00:00<00:00, 148.97it/s, train_loss=0.00598, val_loss=0.0066]Epoch 9:  52%|█████▏    | 14/27 [00:00<00:00, 145.78it/s, train_loss=0.00598, val_loss=0.0066]Epoch 9:  56%|█████▌    | 15/27 [00:00<00:00, 148.35it/s, train_loss=0.00598, val_loss=0.0066]Epoch 9:  56%|█████▌    | 15/27 [00:00<00:00, 146.61it/s, train_loss=0.00595, val_loss=0.0066]Epoch 9:  59%|█████▉    | 16/27 [00:00<00:00, 149.81it/s, train_loss=0.00595, val_loss=0.0066]Epoch 9:  59%|█████▉    | 16/27 [00:00<00:00, 147.97it/s, train_loss=0.00552, val_loss=0.0066]Epoch 9:  63%|██████▎   | 17/27 [00:00<00:00, 149.65it/s, train_loss=0.00552, val_loss=0.0066]Epoch 9:  63%|██████▎   | 17/27 [00:00<00:00, 148.08it/s, train_loss=0.00723, val_loss=0.0066]Epoch 9:  67%|██████▋   | 18/27 [00:00<00:00, 150.39it/s, train_loss=0.00723, val_loss=0.0066]Epoch 9:  67%|██████▋   | 18/27 [00:00<00:00, 148.95it/s, train_loss=0.00616, val_loss=0.0066]Epoch 9:  70%|███████   | 19/27 [00:00<00:00, 150.77it/s, train_loss=0.00616, val_loss=0.0066]Epoch 9:  70%|███████   | 19/27 [00:00<00:00, 148.74it/s, train_loss=0.00676, val_loss=0.0066]Epoch 9:  74%|███████▍  | 20/27 [00:00<00:00, 149.78it/s, train_loss=0.00676, val_loss=0.0066]Epoch 9:  74%|███████▍  | 20/27 [00:00<00:00, 148.72it/s, train_loss=0.0056, val_loss=0.0066] Epoch 9:  78%|███████▊  | 21/27 [00:00<00:00, 150.16it/s, train_loss=0.0056, val_loss=0.0066]Epoch 9:  78%|███████▊  | 21/27 [00:00<00:00, 148.47it/s, train_loss=0.00531, val_loss=0.0066]Epoch 9:  81%|████████▏ | 22/27 [00:00<00:00, 149.60it/s, train_loss=0.00531, val_loss=0.0066]Epoch 9:  81%|████████▏ | 22/27 [00:00<00:00, 148.63it/s, train_loss=0.00506, val_loss=0.0066]Epoch 9:  85%|████████▌ | 23/27 [00:00<00:00, 150.26it/s, train_loss=0.00506, val_loss=0.0066]Epoch 9:  85%|████████▌ | 23/27 [00:00<00:00, 148.25it/s, train_loss=0.00648, val_loss=0.0066]Epoch 9:  89%|████████▉ | 24/27 [00:00<00:00, 149.28it/s, train_loss=0.00648, val_loss=0.0066]Epoch 9:  89%|████████▉ | 24/27 [00:00<00:00, 148.40it/s, train_loss=0.00493, val_loss=0.0066]Epoch 9:  93%|█████████▎| 25/27 [00:00<00:00, 149.33it/s, train_loss=0.00493, val_loss=0.0066]Epoch 9:  93%|█████████▎| 25/27 [00:00<00:00, 148.24it/s, train_loss=0.00456, val_loss=0.0066]Epoch 9:  96%|█████████▋| 26/27 [00:00<00:00, 149.26it/s, train_loss=0.00456, val_loss=0.0066]Epoch 9:  96%|█████████▋| 26/27 [00:00<00:00, 148.54it/s, train_loss=0.00519, val_loss=0.0066]Epoch 9: 100%|██████████| 27/27 [00:00<00:00, 149.45it/s, train_loss=0.00519, val_loss=0.0066]Epoch 9: 100%|██████████| 27/27 [00:00<00:00, 148.36it/s, train_loss=0.00724, val_loss=0.0066]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 229.67it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 260.02it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 273.45it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 274.20it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 277.06it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 279.61it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 280.69it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 281.72it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 281.70it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 281.37it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 282.43it/s][A
                                                                         [AEpoch 9: 100%|██████████| 27/27 [00:00<00:00, 119.14it/s, train_loss=0.00724, val_loss=0.00616]Epoch 9: 100%|██████████| 27/27 [00:00<00:00, 118.68it/s, train_loss=0.00724, val_loss=0.00616]Epoch 9:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00724, val_loss=0.00616]          Epoch 10:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00724, val_loss=0.00616]Epoch 10:   4%|▎         | 1/27 [00:00<00:00, 159.48it/s, train_loss=0.00724, val_loss=0.00616]Epoch 10:   4%|▎         | 1/27 [00:00<00:00, 140.49it/s, train_loss=0.00569, val_loss=0.00616]Epoch 10:   7%|▋         | 2/27 [00:00<00:00, 156.42it/s, train_loss=0.00569, val_loss=0.00616]Epoch 10:   7%|▋         | 2/27 [00:00<00:00, 145.84it/s, train_loss=0.00633, val_loss=0.00616]Epoch 10:  11%|█         | 3/27 [00:00<00:00, 158.19it/s, train_loss=0.00633, val_loss=0.00616]Epoch 10:  11%|█         | 3/27 [00:00<00:00, 149.49it/s, train_loss=0.00568, val_loss=0.00616]Epoch 10:  15%|█▍        | 4/27 [00:00<00:00, 156.48it/s, train_loss=0.00568, val_loss=0.00616]Epoch 10:  15%|█▍        | 4/27 [00:00<00:00, 149.81it/s, train_loss=0.00581, val_loss=0.00616]Epoch 10:  19%|█▊        | 5/27 [00:00<00:00, 156.24it/s, train_loss=0.00581, val_loss=0.00616]Epoch 10:  19%|█▊        | 5/27 [00:00<00:00, 151.93it/s, train_loss=0.00393, val_loss=0.00616]Epoch 10:  22%|██▏       | 6/27 [00:00<00:00, 158.42it/s, train_loss=0.00393, val_loss=0.00616]Epoch 10:  22%|██▏       | 6/27 [00:00<00:00, 154.71it/s, train_loss=0.00434, val_loss=0.00616]Epoch 10:  26%|██▌       | 7/27 [00:00<00:00, 157.39it/s, train_loss=0.00434, val_loss=0.00616]Epoch 10:  26%|██▌       | 7/27 [00:00<00:00, 153.89it/s, train_loss=0.00602, val_loss=0.00616]Epoch 10:  30%|██▉       | 8/27 [00:00<00:00, 157.99it/s, train_loss=0.00602, val_loss=0.00616]Epoch 10:  30%|██▉       | 8/27 [00:00<00:00, 154.86it/s, train_loss=0.0041, val_loss=0.00616] Epoch 10:  33%|███▎      | 9/27 [00:00<00:00, 157.35it/s, train_loss=0.0041, val_loss=0.00616]Epoch 10:  33%|███▎      | 9/27 [00:00<00:00, 154.80it/s, train_loss=0.00389, val_loss=0.00616]Epoch 10:  37%|███▋      | 10/27 [00:00<00:00, 157.60it/s, train_loss=0.00389, val_loss=0.00616]Epoch 10:  37%|███▋      | 10/27 [00:00<00:00, 154.79it/s, train_loss=0.00678, val_loss=0.00616]Epoch 10:  41%|████      | 11/27 [00:00<00:00, 157.13it/s, train_loss=0.00678, val_loss=0.00616]Epoch 10:  41%|████      | 11/27 [00:00<00:00, 154.47it/s, train_loss=0.00502, val_loss=0.00616]Epoch 10:  44%|████▍     | 12/27 [00:00<00:00, 156.70it/s, train_loss=0.00502, val_loss=0.00616]Epoch 10:  44%|████▍     | 12/27 [00:00<00:00, 154.58it/s, train_loss=0.00507, val_loss=0.00616]Epoch 10:  48%|████▊     | 13/27 [00:00<00:00, 157.55it/s, train_loss=0.00507, val_loss=0.00616]Epoch 10:  48%|████▊     | 13/27 [00:00<00:00, 153.71it/s, train_loss=0.00522, val_loss=0.00616]Epoch 10:  52%|█████▏    | 14/27 [00:00<00:00, 156.36it/s, train_loss=0.00522, val_loss=0.00616]Epoch 10:  52%|█████▏    | 14/27 [00:00<00:00, 154.46it/s, train_loss=0.0048, val_loss=0.00616] Epoch 10:  56%|█████▌    | 15/27 [00:00<00:00, 157.37it/s, train_loss=0.0048, val_loss=0.00616]Epoch 10:  56%|█████▌    | 15/27 [00:00<00:00, 155.55it/s, train_loss=0.00559, val_loss=0.00616]Epoch 10:  59%|█████▉    | 16/27 [00:00<00:00, 156.98it/s, train_loss=0.00559, val_loss=0.00616]Epoch 10:  59%|█████▉    | 16/27 [00:00<00:00, 155.49it/s, train_loss=0.00664, val_loss=0.00616]Epoch 10:  63%|██████▎   | 17/27 [00:00<00:00, 157.39it/s, train_loss=0.00664, val_loss=0.00616]Epoch 10:  63%|██████▎   | 17/27 [00:00<00:00, 156.08it/s, train_loss=0.00624, val_loss=0.00616]Epoch 10:  67%|██████▋   | 18/27 [00:00<00:00, 157.49it/s, train_loss=0.00624, val_loss=0.00616]Epoch 10:  67%|██████▋   | 18/27 [00:00<00:00, 155.40it/s, train_loss=0.00473, val_loss=0.00616]Epoch 10:  70%|███████   | 19/27 [00:00<00:00, 156.88it/s, train_loss=0.00473, val_loss=0.00616]Epoch 10:  70%|███████   | 19/27 [00:00<00:00, 155.61it/s, train_loss=0.00497, val_loss=0.00616]Epoch 10:  74%|███████▍  | 20/27 [00:00<00:00, 157.30it/s, train_loss=0.00497, val_loss=0.00616]Epoch 10:  74%|███████▍  | 20/27 [00:00<00:00, 154.62it/s, train_loss=0.00621, val_loss=0.00616]Epoch 10:  78%|███████▊  | 21/27 [00:00<00:00, 155.49it/s, train_loss=0.00621, val_loss=0.00616]Epoch 10:  78%|███████▊  | 21/27 [00:00<00:00, 154.37it/s, train_loss=0.00552, val_loss=0.00616]Epoch 10:  81%|████████▏ | 22/27 [00:00<00:00, 155.95it/s, train_loss=0.00552, val_loss=0.00616]Epoch 10:  81%|████████▏ | 22/27 [00:00<00:00, 154.78it/s, train_loss=0.00486, val_loss=0.00616]Epoch 10:  85%|████████▌ | 23/27 [00:00<00:00, 156.06it/s, train_loss=0.00486, val_loss=0.00616]Epoch 10:  85%|████████▌ | 23/27 [00:00<00:00, 154.65it/s, train_loss=0.00515, val_loss=0.00616]Epoch 10:  89%|████████▉ | 24/27 [00:00<00:00, 155.99it/s, train_loss=0.00515, val_loss=0.00616]Epoch 10:  89%|████████▉ | 24/27 [00:00<00:00, 154.85it/s, train_loss=0.00552, val_loss=0.00616]Epoch 10:  93%|█████████▎| 25/27 [00:00<00:00, 156.41it/s, train_loss=0.00552, val_loss=0.00616]Epoch 10:  93%|█████████▎| 25/27 [00:00<00:00, 154.20it/s, train_loss=0.00429, val_loss=0.00616]Epoch 10:  96%|█████████▋| 26/27 [00:00<00:00, 155.24it/s, train_loss=0.00429, val_loss=0.00616]Epoch 10:  96%|█████████▋| 26/27 [00:00<00:00, 154.34it/s, train_loss=0.00385, val_loss=0.00616]Epoch 10: 100%|██████████| 27/27 [00:00<00:00, 155.06it/s, train_loss=0.00385, val_loss=0.00616]Epoch 10: 100%|██████████| 27/27 [00:00<00:00, 153.96it/s, train_loss=0.00657, val_loss=0.00616]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 150.69it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 175.95it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 190.48it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 195.35it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 208.84it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 222.61it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 231.43it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 239.20it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 245.97it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 249.52it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 254.55it/s][A
                                                                         [AEpoch 10: 100%|██████████| 27/27 [00:00<00:00, 119.85it/s, train_loss=0.00657, val_loss=0.00581]Epoch 10: 100%|██████████| 27/27 [00:00<00:00, 119.48it/s, train_loss=0.00657, val_loss=0.00581]Epoch 10:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00657, val_loss=0.00581]          Epoch 11:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00657, val_loss=0.00581]Epoch 11:   4%|▎         | 1/27 [00:00<00:00, 162.76it/s, train_loss=0.00657, val_loss=0.00581]Epoch 11:   4%|▎         | 1/27 [00:00<00:00, 142.11it/s, train_loss=0.00448, val_loss=0.00581]Epoch 11:   7%|▋         | 2/27 [00:00<00:00, 159.76it/s, train_loss=0.00448, val_loss=0.00581]Epoch 11:   7%|▋         | 2/27 [00:00<00:00, 149.53it/s, train_loss=0.00503, val_loss=0.00581]Epoch 11:  11%|█         | 3/27 [00:00<00:00, 153.84it/s, train_loss=0.00503, val_loss=0.00581]Epoch 11:  11%|█         | 3/27 [00:00<00:00, 147.52it/s, train_loss=0.00421, val_loss=0.00581]Epoch 11:  15%|█▍        | 4/27 [00:00<00:00, 155.17it/s, train_loss=0.00421, val_loss=0.00581]Epoch 11:  15%|█▍        | 4/27 [00:00<00:00, 149.77it/s, train_loss=0.00538, val_loss=0.00581]Epoch 11:  19%|█▊        | 5/27 [00:00<00:00, 155.10it/s, train_loss=0.00538, val_loss=0.00581]Epoch 11:  19%|█▊        | 5/27 [00:00<00:00, 149.76it/s, train_loss=0.00649, val_loss=0.00581]Epoch 11:  22%|██▏       | 6/27 [00:00<00:00, 154.29it/s, train_loss=0.00649, val_loss=0.00581]Epoch 11:  22%|██▏       | 6/27 [00:00<00:00, 150.56it/s, train_loss=0.00533, val_loss=0.00581]Epoch 11:  26%|██▌       | 7/27 [00:00<00:00, 155.05it/s, train_loss=0.00533, val_loss=0.00581]Epoch 11:  26%|██▌       | 7/27 [00:00<00:00, 149.61it/s, train_loss=0.00425, val_loss=0.00581]Epoch 11:  30%|██▉       | 8/27 [00:00<00:00, 153.70it/s, train_loss=0.00425, val_loss=0.00581]Epoch 11:  30%|██▉       | 8/27 [00:00<00:00, 150.88it/s, train_loss=0.0046, val_loss=0.00581] Epoch 11:  33%|███▎      | 9/27 [00:00<00:00, 155.05it/s, train_loss=0.0046, val_loss=0.00581]Epoch 11:  33%|███▎      | 9/27 [00:00<00:00, 149.31it/s, train_loss=0.00533, val_loss=0.00581]Epoch 11:  37%|███▋      | 10/27 [00:00<00:00, 152.01it/s, train_loss=0.00533, val_loss=0.00581]Epoch 11:  37%|███▋      | 10/27 [00:00<00:00, 149.90it/s, train_loss=0.00458, val_loss=0.00581]Epoch 11:  41%|████      | 11/27 [00:00<00:00, 152.93it/s, train_loss=0.00458, val_loss=0.00581]Epoch 11:  41%|████      | 11/27 [00:00<00:00, 150.81it/s, train_loss=0.00394, val_loss=0.00581]Epoch 11:  44%|████▍     | 12/27 [00:00<00:00, 152.72it/s, train_loss=0.00394, val_loss=0.00581]Epoch 11:  44%|████▍     | 12/27 [00:00<00:00, 150.93it/s, train_loss=0.00607, val_loss=0.00581]Epoch 11:  48%|████▊     | 13/27 [00:00<00:00, 153.22it/s, train_loss=0.00607, val_loss=0.00581]Epoch 11:  48%|████▊     | 13/27 [00:00<00:00, 151.21it/s, train_loss=0.00526, val_loss=0.00581]Epoch 11:  52%|█████▏    | 14/27 [00:00<00:00, 153.20it/s, train_loss=0.00526, val_loss=0.00581]Epoch 11:  52%|█████▏    | 14/27 [00:00<00:00, 151.66it/s, train_loss=0.00507, val_loss=0.00581]Epoch 11:  56%|█████▌    | 15/27 [00:00<00:00, 153.57it/s, train_loss=0.00507, val_loss=0.00581]Epoch 11:  56%|█████▌    | 15/27 [00:00<00:00, 151.97it/s, train_loss=0.00412, val_loss=0.00581]Epoch 11:  59%|█████▉    | 16/27 [00:00<00:00, 154.30it/s, train_loss=0.00412, val_loss=0.00581]Epoch 11:  59%|█████▉    | 16/27 [00:00<00:00, 151.37it/s, train_loss=0.0059, val_loss=0.00581] Epoch 11:  63%|██████▎   | 17/27 [00:00<00:00, 153.48it/s, train_loss=0.0059, val_loss=0.00581]Epoch 11:  63%|██████▎   | 17/27 [00:00<00:00, 152.10it/s, train_loss=0.00518, val_loss=0.00581]Epoch 11:  67%|██████▋   | 18/27 [00:00<00:00, 154.45it/s, train_loss=0.00518, val_loss=0.00581]Epoch 11:  67%|██████▋   | 18/27 [00:00<00:00, 153.08it/s, train_loss=0.00404, val_loss=0.00581]Epoch 11:  70%|███████   | 19/27 [00:00<00:00, 154.46it/s, train_loss=0.00404, val_loss=0.00581]Epoch 11:  70%|███████   | 19/27 [00:00<00:00, 153.27it/s, train_loss=0.00581, val_loss=0.00581]Epoch 11:  74%|███████▍  | 20/27 [00:00<00:00, 155.00it/s, train_loss=0.00581, val_loss=0.00581]Epoch 11:  74%|███████▍  | 20/27 [00:00<00:00, 153.92it/s, train_loss=0.00567, val_loss=0.00581]Epoch 11:  78%|███████▊  | 21/27 [00:00<00:00, 155.66it/s, train_loss=0.00567, val_loss=0.00581]Epoch 11:  78%|███████▊  | 21/27 [00:00<00:00, 153.28it/s, train_loss=0.00525, val_loss=0.00581]Epoch 11:  81%|████████▏ | 22/27 [00:00<00:00, 154.81it/s, train_loss=0.00525, val_loss=0.00581]Epoch 11:  81%|████████▏ | 22/27 [00:00<00:00, 153.66it/s, train_loss=0.0047, val_loss=0.00581] Epoch 11:  85%|████████▌ | 23/27 [00:00<00:00, 155.45it/s, train_loss=0.0047, val_loss=0.00581]Epoch 11:  85%|████████▌ | 23/27 [00:00<00:00, 154.45it/s, train_loss=0.00435, val_loss=0.00581]Epoch 11:  89%|████████▉ | 24/27 [00:00<00:00, 155.29it/s, train_loss=0.00435, val_loss=0.00581]Epoch 11:  89%|████████▉ | 24/27 [00:00<00:00, 154.34it/s, train_loss=0.00454, val_loss=0.00581]Epoch 11:  93%|█████████▎| 25/27 [00:00<00:00, 155.63it/s, train_loss=0.00454, val_loss=0.00581]Epoch 11:  93%|█████████▎| 25/27 [00:00<00:00, 154.51it/s, train_loss=0.00404, val_loss=0.00581]Epoch 11:  96%|█████████▋| 26/27 [00:00<00:00, 155.49it/s, train_loss=0.00404, val_loss=0.00581]Epoch 11:  96%|█████████▋| 26/27 [00:00<00:00, 154.42it/s, train_loss=0.00453, val_loss=0.00581]Epoch 11: 100%|██████████| 27/27 [00:00<00:00, 155.35it/s, train_loss=0.00453, val_loss=0.00581]Epoch 11: 100%|██████████| 27/27 [00:00<00:00, 154.53it/s, train_loss=0.00629, val_loss=0.00581]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 164.35it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 189.88it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 198.57it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 205.92it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 207.54it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 211.77it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 213.76it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 216.31it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 217.48it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 219.12it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 219.20it/s][A
                                                                         [AEpoch 11: 100%|██████████| 27/27 [00:00<00:00, 115.88it/s, train_loss=0.00629, val_loss=0.00545]Epoch 11: 100%|██████████| 27/27 [00:00<00:00, 115.61it/s, train_loss=0.00629, val_loss=0.00545]Epoch 11:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00629, val_loss=0.00545]          Epoch 12:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00629, val_loss=0.00545]Epoch 12:   4%|▎         | 1/27 [00:00<00:00, 166.12it/s, train_loss=0.00629, val_loss=0.00545]Epoch 12:   4%|▎         | 1/27 [00:00<00:00, 143.61it/s, train_loss=0.00436, val_loss=0.00545]Epoch 12:   7%|▋         | 2/27 [00:00<00:00, 166.82it/s, train_loss=0.00436, val_loss=0.00545]Epoch 12:   7%|▋         | 2/27 [00:00<00:00, 155.91it/s, train_loss=0.00488, val_loss=0.00545]Epoch 12:  11%|█         | 3/27 [00:00<00:00, 159.87it/s, train_loss=0.00488, val_loss=0.00545]Epoch 12:  11%|█         | 3/27 [00:00<00:00, 152.88it/s, train_loss=0.0033, val_loss=0.00545] Epoch 12:  15%|█▍        | 4/27 [00:00<00:00, 161.66it/s, train_loss=0.0033, val_loss=0.00545]Epoch 12:  15%|█▍        | 4/27 [00:00<00:00, 154.21it/s, train_loss=0.00476, val_loss=0.00545]Epoch 12:  19%|█▊        | 5/27 [00:00<00:00, 158.16it/s, train_loss=0.00476, val_loss=0.00545]Epoch 12:  19%|█▊        | 5/27 [00:00<00:00, 153.30it/s, train_loss=0.00542, val_loss=0.00545]Epoch 12:  22%|██▏       | 6/27 [00:00<00:00, 156.23it/s, train_loss=0.00542, val_loss=0.00545]Epoch 12:  22%|██▏       | 6/27 [00:00<00:00, 153.01it/s, train_loss=0.00493, val_loss=0.00545]Epoch 12:  26%|██▌       | 7/27 [00:00<00:00, 156.68it/s, train_loss=0.00493, val_loss=0.00545]Epoch 12:  26%|██▌       | 7/27 [00:00<00:00, 153.49it/s, train_loss=0.0047, val_loss=0.00545] Epoch 12:  30%|██▉       | 8/27 [00:00<00:00, 154.15it/s, train_loss=0.0047, val_loss=0.00545]Epoch 12:  30%|██▉       | 8/27 [00:00<00:00, 151.78it/s, train_loss=0.00493, val_loss=0.00545]Epoch 12:  33%|███▎      | 9/27 [00:00<00:00, 153.45it/s, train_loss=0.00493, val_loss=0.00545]Epoch 12:  33%|███▎      | 9/27 [00:00<00:00, 151.21it/s, train_loss=0.00481, val_loss=0.00545]Epoch 12:  37%|███▋      | 10/27 [00:00<00:00, 152.84it/s, train_loss=0.00481, val_loss=0.00545]Epoch 12:  37%|███▋      | 10/27 [00:00<00:00, 149.37it/s, train_loss=0.00521, val_loss=0.00545]Epoch 12:  41%|████      | 11/27 [00:00<00:00, 150.59it/s, train_loss=0.00521, val_loss=0.00545]Epoch 12:  41%|████      | 11/27 [00:00<00:00, 148.94it/s, train_loss=0.00452, val_loss=0.00545]Epoch 12:  44%|████▍     | 12/27 [00:00<00:00, 150.65it/s, train_loss=0.00452, val_loss=0.00545]Epoch 12:  44%|████▍     | 12/27 [00:00<00:00, 149.06it/s, train_loss=0.00371, val_loss=0.00545]Epoch 12:  48%|████▊     | 13/27 [00:00<00:00, 149.90it/s, train_loss=0.00371, val_loss=0.00545]Epoch 12:  48%|████▊     | 13/27 [00:00<00:00, 148.30it/s, train_loss=0.00517, val_loss=0.00545]Epoch 12:  52%|█████▏    | 14/27 [00:00<00:00, 149.82it/s, train_loss=0.00517, val_loss=0.00545]Epoch 12:  52%|█████▏    | 14/27 [00:00<00:00, 148.45it/s, train_loss=0.00487, val_loss=0.00545]Epoch 12:  56%|█████▌    | 15/27 [00:00<00:00, 150.15it/s, train_loss=0.00487, val_loss=0.00545]Epoch 12:  56%|█████▌    | 15/27 [00:00<00:00, 147.05it/s, train_loss=0.00431, val_loss=0.00545]Epoch 12:  59%|█████▉    | 16/27 [00:00<00:00, 148.13it/s, train_loss=0.00431, val_loss=0.00545]Epoch 12:  59%|█████▉    | 16/27 [00:00<00:00, 146.90it/s, train_loss=0.00711, val_loss=0.00545]Epoch 12:  63%|██████▎   | 17/27 [00:00<00:00, 148.28it/s, train_loss=0.00711, val_loss=0.00545]Epoch 12:  63%|██████▎   | 17/27 [00:00<00:00, 145.57it/s, train_loss=0.00474, val_loss=0.00545]Epoch 12:  67%|██████▋   | 18/27 [00:00<00:00, 146.15it/s, train_loss=0.00474, val_loss=0.00545]Epoch 12:  67%|██████▋   | 18/27 [00:00<00:00, 144.99it/s, train_loss=0.00526, val_loss=0.00545]Epoch 12:  70%|███████   | 19/27 [00:00<00:00, 146.43it/s, train_loss=0.00526, val_loss=0.00545]Epoch 12:  70%|███████   | 19/27 [00:00<00:00, 145.39it/s, train_loss=0.00542, val_loss=0.00545]Epoch 12:  74%|███████▍  | 20/27 [00:00<00:00, 146.89it/s, train_loss=0.00542, val_loss=0.00545]Epoch 12:  74%|███████▍  | 20/27 [00:00<00:00, 145.92it/s, train_loss=0.00404, val_loss=0.00545]Epoch 12:  78%|███████▊  | 21/27 [00:00<00:00, 147.45it/s, train_loss=0.00404, val_loss=0.00545]Epoch 12:  78%|███████▊  | 21/27 [00:00<00:00, 146.33it/s, train_loss=0.00438, val_loss=0.00545]Epoch 12:  81%|████████▏ | 22/27 [00:00<00:00, 148.23it/s, train_loss=0.00438, val_loss=0.00545]Epoch 12:  81%|████████▏ | 22/27 [00:00<00:00, 146.92it/s, train_loss=0.00481, val_loss=0.00545]Epoch 12:  85%|████████▌ | 23/27 [00:00<00:00, 148.42it/s, train_loss=0.00481, val_loss=0.00545]Epoch 12:  85%|████████▌ | 23/27 [00:00<00:00, 146.54it/s, train_loss=0.00434, val_loss=0.00545]Epoch 12:  89%|████████▉ | 24/27 [00:00<00:00, 148.06it/s, train_loss=0.00434, val_loss=0.00545]Epoch 12:  89%|████████▉ | 24/27 [00:00<00:00, 147.07it/s, train_loss=0.00355, val_loss=0.00545]Epoch 12:  93%|█████████▎| 25/27 [00:00<00:00, 149.01it/s, train_loss=0.00355, val_loss=0.00545]Epoch 12:  93%|█████████▎| 25/27 [00:00<00:00, 147.84it/s, train_loss=0.00468, val_loss=0.00545]Epoch 12:  96%|█████████▋| 26/27 [00:00<00:00, 148.96it/s, train_loss=0.00468, val_loss=0.00545]Epoch 12:  96%|█████████▋| 26/27 [00:00<00:00, 148.09it/s, train_loss=0.00472, val_loss=0.00545]Epoch 12: 100%|██████████| 27/27 [00:00<00:00, 149.40it/s, train_loss=0.00472, val_loss=0.00545]Epoch 12: 100%|██████████| 27/27 [00:00<00:00, 148.33it/s, train_loss=0.00475, val_loss=0.00545]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 168.22it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 195.42it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 204.53it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 212.53it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 214.52it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 218.19it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 219.45it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 218.80it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 217.73it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 218.58it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 219.52it/s][A
                                                                         [AEpoch 12: 100%|██████████| 27/27 [00:00<00:00, 112.44it/s, train_loss=0.00475, val_loss=0.00516]Epoch 12: 100%|██████████| 27/27 [00:00<00:00, 111.97it/s, train_loss=0.00475, val_loss=0.00516]Epoch 12:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00475, val_loss=0.00516]          Epoch 13:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00475, val_loss=0.00516]Epoch 13:   4%|▎         | 1/27 [00:00<00:00, 155.31it/s, train_loss=0.00475, val_loss=0.00516]Epoch 13:   4%|▎         | 1/27 [00:00<00:00, 133.07it/s, train_loss=0.00459, val_loss=0.00516]Epoch 13:   7%|▋         | 2/27 [00:00<00:00, 152.18it/s, train_loss=0.00459, val_loss=0.00516]Epoch 13:   7%|▋         | 2/27 [00:00<00:00, 140.27it/s, train_loss=0.00471, val_loss=0.00516]Epoch 13:  11%|█         | 3/27 [00:00<00:00, 157.79it/s, train_loss=0.00471, val_loss=0.00516]Epoch 13:  11%|█         | 3/27 [00:00<00:00, 148.00it/s, train_loss=0.00408, val_loss=0.00516]Epoch 13:  15%|█▍        | 4/27 [00:00<00:00, 163.39it/s, train_loss=0.00408, val_loss=0.00516]Epoch 13:  15%|█▍        | 4/27 [00:00<00:00, 146.96it/s, train_loss=0.00364, val_loss=0.00516]Epoch 13:  19%|█▊        | 5/27 [00:00<00:00, 154.86it/s, train_loss=0.00364, val_loss=0.00516]Epoch 13:  19%|█▊        | 5/27 [00:00<00:00, 149.89it/s, train_loss=0.00517, val_loss=0.00516]Epoch 13:  22%|██▏       | 6/27 [00:00<00:00, 158.35it/s, train_loss=0.00517, val_loss=0.00516]Epoch 13:  22%|██▏       | 6/27 [00:00<00:00, 152.85it/s, train_loss=0.00524, val_loss=0.00516]Epoch 13:  26%|██▌       | 7/27 [00:00<00:00, 157.62it/s, train_loss=0.00524, val_loss=0.00516]Epoch 13:  26%|██▌       | 7/27 [00:00<00:00, 153.77it/s, train_loss=0.00432, val_loss=0.00516]Epoch 13:  30%|██▉       | 8/27 [00:00<00:00, 158.92it/s, train_loss=0.00432, val_loss=0.00516]Epoch 13:  30%|██▉       | 8/27 [00:00<00:00, 155.18it/s, train_loss=0.00517, val_loss=0.00516]Epoch 13:  33%|███▎      | 9/27 [00:00<00:00, 159.50it/s, train_loss=0.00517, val_loss=0.00516]Epoch 13:  33%|███▎      | 9/27 [00:00<00:00, 153.48it/s, train_loss=0.00432, val_loss=0.00516]Epoch 13:  37%|███▋      | 10/27 [00:00<00:00, 157.33it/s, train_loss=0.00432, val_loss=0.00516]Epoch 13:  37%|███▋      | 10/27 [00:00<00:00, 154.55it/s, train_loss=0.00476, val_loss=0.00516]Epoch 13:  41%|████      | 11/27 [00:00<00:00, 159.12it/s, train_loss=0.00476, val_loss=0.00516]Epoch 13:  41%|████      | 11/27 [00:00<00:00, 156.02it/s, train_loss=0.00412, val_loss=0.00516]Epoch 13:  44%|████▍     | 12/27 [00:00<00:00, 157.59it/s, train_loss=0.00412, val_loss=0.00516]Epoch 13:  44%|████▍     | 12/27 [00:00<00:00, 154.94it/s, train_loss=0.00448, val_loss=0.00516]Epoch 13:  48%|████▊     | 13/27 [00:00<00:00, 157.90it/s, train_loss=0.00448, val_loss=0.00516]Epoch 13:  48%|████▊     | 13/27 [00:00<00:00, 155.63it/s, train_loss=0.00438, val_loss=0.00516]Epoch 13:  52%|█████▏    | 14/27 [00:00<00:00, 158.23it/s, train_loss=0.00438, val_loss=0.00516]Epoch 13:  52%|█████▏    | 14/27 [00:00<00:00, 154.97it/s, train_loss=0.0038, val_loss=0.00516] Epoch 13:  56%|█████▌    | 15/27 [00:00<00:00, 157.27it/s, train_loss=0.0038, val_loss=0.00516]Epoch 13:  56%|█████▌    | 15/27 [00:00<00:00, 155.31it/s, train_loss=0.00477, val_loss=0.00516]Epoch 13:  59%|█████▉    | 16/27 [00:00<00:00, 157.54it/s, train_loss=0.00477, val_loss=0.00516]Epoch 13:  59%|█████▉    | 16/27 [00:00<00:00, 154.58it/s, train_loss=0.00375, val_loss=0.00516]Epoch 13:  63%|██████▎   | 17/27 [00:00<00:00, 156.68it/s, train_loss=0.00375, val_loss=0.00516]Epoch 13:  63%|██████▎   | 17/27 [00:00<00:00, 155.01it/s, train_loss=0.00362, val_loss=0.00516]Epoch 13:  67%|██████▋   | 18/27 [00:00<00:00, 156.89it/s, train_loss=0.00362, val_loss=0.00516]Epoch 13:  67%|██████▋   | 18/27 [00:00<00:00, 154.35it/s, train_loss=0.00372, val_loss=0.00516]Epoch 13:  70%|███████   | 19/27 [00:00<00:00, 156.12it/s, train_loss=0.00372, val_loss=0.00516]Epoch 13:  70%|███████   | 19/27 [00:00<00:00, 154.64it/s, train_loss=0.00488, val_loss=0.00516]Epoch 13:  74%|███████▍  | 20/27 [00:00<00:00, 156.32it/s, train_loss=0.00488, val_loss=0.00516]Epoch 13:  74%|███████▍  | 20/27 [00:00<00:00, 154.04it/s, train_loss=0.00532, val_loss=0.00516]Epoch 13:  78%|███████▊  | 21/27 [00:00<00:00, 155.59it/s, train_loss=0.00532, val_loss=0.00516]Epoch 13:  78%|███████▊  | 21/27 [00:00<00:00, 154.12it/s, train_loss=0.00598, val_loss=0.00516]Epoch 13:  81%|████████▏ | 22/27 [00:00<00:00, 155.50it/s, train_loss=0.00598, val_loss=0.00516]Epoch 13:  81%|████████▏ | 22/27 [00:00<00:00, 153.63it/s, train_loss=0.00396, val_loss=0.00516]Epoch 13:  85%|████████▌ | 23/27 [00:00<00:00, 155.41it/s, train_loss=0.00396, val_loss=0.00516]Epoch 13:  85%|████████▌ | 23/27 [00:00<00:00, 154.11it/s, train_loss=0.00423, val_loss=0.00516]Epoch 13:  89%|████████▉ | 24/27 [00:00<00:00, 156.21it/s, train_loss=0.00423, val_loss=0.00516]Epoch 13:  89%|████████▉ | 24/27 [00:00<00:00, 154.92it/s, train_loss=0.00422, val_loss=0.00516]Epoch 13:  93%|█████████▎| 25/27 [00:00<00:00, 156.20it/s, train_loss=0.00422, val_loss=0.00516]Epoch 13:  93%|█████████▎| 25/27 [00:00<00:00, 155.11it/s, train_loss=0.00447, val_loss=0.00516]Epoch 13:  96%|█████████▋| 26/27 [00:00<00:00, 156.74it/s, train_loss=0.00447, val_loss=0.00516]Epoch 13:  96%|█████████▋| 26/27 [00:00<00:00, 155.55it/s, train_loss=0.006, val_loss=0.00516]  Epoch 13: 100%|██████████| 27/27 [00:00<00:00, 157.01it/s, train_loss=0.006, val_loss=0.00516]Epoch 13: 100%|██████████| 27/27 [00:00<00:00, 154.98it/s, train_loss=0.00387, val_loss=0.00516]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 193.88it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 219.91it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 231.22it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 239.45it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 241.41it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 244.97it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 241.67it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 243.25it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 244.26it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 245.42it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 246.91it/s][A
                                                                         [AEpoch 13: 100%|██████████| 27/27 [00:00<00:00, 119.46it/s, train_loss=0.00387, val_loss=0.00495]Epoch 13: 100%|██████████| 27/27 [00:00<00:00, 118.98it/s, train_loss=0.00387, val_loss=0.00495]Epoch 13:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00387, val_loss=0.00495]          Epoch 14:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00387, val_loss=0.00495]Epoch 14:   4%|▎         | 1/27 [00:00<00:00, 147.84it/s, train_loss=0.00387, val_loss=0.00495]Epoch 14:   4%|▎         | 1/27 [00:00<00:00, 127.51it/s, train_loss=0.00418, val_loss=0.00495]Epoch 14:   7%|▋         | 2/27 [00:00<00:00, 153.96it/s, train_loss=0.00418, val_loss=0.00495]Epoch 14:   7%|▋         | 2/27 [00:00<00:00, 141.34it/s, train_loss=0.00409, val_loss=0.00495]Epoch 14:  11%|█         | 3/27 [00:00<00:00, 154.02it/s, train_loss=0.00409, val_loss=0.00495]Epoch 14:  11%|█         | 3/27 [00:00<00:00, 146.30it/s, train_loss=0.00516, val_loss=0.00495]Epoch 14:  15%|█▍        | 4/27 [00:00<00:00, 155.76it/s, train_loss=0.00516, val_loss=0.00495]Epoch 14:  15%|█▍        | 4/27 [00:00<00:00, 149.63it/s, train_loss=0.00566, val_loss=0.00495]Epoch 14:  19%|█▊        | 5/27 [00:00<00:00, 155.06it/s, train_loss=0.00566, val_loss=0.00495]Epoch 14:  19%|█▊        | 5/27 [00:00<00:00, 148.94it/s, train_loss=0.00324, val_loss=0.00495]Epoch 14:  22%|██▏       | 6/27 [00:00<00:00, 153.15it/s, train_loss=0.00324, val_loss=0.00495]Epoch 14:  22%|██▏       | 6/27 [00:00<00:00, 148.87it/s, train_loss=0.00414, val_loss=0.00495]Epoch 14:  26%|██▌       | 7/27 [00:00<00:00, 154.50it/s, train_loss=0.00414, val_loss=0.00495]Epoch 14:  26%|██▌       | 7/27 [00:00<00:00, 147.95it/s, train_loss=0.00477, val_loss=0.00495]Epoch 14:  30%|██▉       | 8/27 [00:00<00:00, 153.03it/s, train_loss=0.00477, val_loss=0.00495]Epoch 14:  30%|██▉       | 8/27 [00:00<00:00, 149.63it/s, train_loss=0.00451, val_loss=0.00495]Epoch 14:  33%|███▎      | 9/27 [00:00<00:00, 155.60it/s, train_loss=0.00451, val_loss=0.00495]Epoch 14:  33%|███▎      | 9/27 [00:00<00:00, 152.27it/s, train_loss=0.00395, val_loss=0.00495]Epoch 14:  37%|███▋      | 10/27 [00:00<00:00, 155.40it/s, train_loss=0.00395, val_loss=0.00495]Epoch 14:  37%|███▋      | 10/27 [00:00<00:00, 152.78it/s, train_loss=0.0038, val_loss=0.00495] Epoch 14:  41%|████      | 11/27 [00:00<00:00, 156.29it/s, train_loss=0.0038, val_loss=0.00495]Epoch 14:  41%|████      | 11/27 [00:00<00:00, 153.99it/s, train_loss=0.00481, val_loss=0.00495]Epoch 14:  44%|████▍     | 12/27 [00:00<00:00, 157.15it/s, train_loss=0.00481, val_loss=0.00495]Epoch 14:  44%|████▍     | 12/27 [00:00<00:00, 152.87it/s, train_loss=0.00419, val_loss=0.00495]Epoch 14:  48%|████▊     | 13/27 [00:00<00:00, 155.77it/s, train_loss=0.00419, val_loss=0.00495]Epoch 14:  48%|████▊     | 13/27 [00:00<00:00, 153.43it/s, train_loss=0.00423, val_loss=0.00495]Epoch 14:  52%|█████▏    | 14/27 [00:00<00:00, 156.85it/s, train_loss=0.00423, val_loss=0.00495]Epoch 14:  52%|█████▏    | 14/27 [00:00<00:00, 154.74it/s, train_loss=0.00307, val_loss=0.00495]Epoch 14:  56%|█████▌    | 15/27 [00:00<00:00, 156.62it/s, train_loss=0.00307, val_loss=0.00495]Epoch 14:  56%|█████▌    | 15/27 [00:00<00:00, 154.77it/s, train_loss=0.00365, val_loss=0.00495]Epoch 14:  59%|█████▉    | 16/27 [00:00<00:00, 157.27it/s, train_loss=0.00365, val_loss=0.00495]Epoch 14:  59%|█████▉    | 16/27 [00:00<00:00, 155.51it/s, train_loss=0.0044, val_loss=0.00495] Epoch 14:  63%|██████▎   | 17/27 [00:00<00:00, 157.62it/s, train_loss=0.0044, val_loss=0.00495]Epoch 14:  63%|██████▎   | 17/27 [00:00<00:00, 154.90it/s, train_loss=0.00388, val_loss=0.00495]Epoch 14:  67%|██████▋   | 18/27 [00:00<00:00, 156.79it/s, train_loss=0.00388, val_loss=0.00495]Epoch 14:  67%|██████▋   | 18/27 [00:00<00:00, 155.08it/s, train_loss=0.00379, val_loss=0.00495]Epoch 14:  70%|███████   | 19/27 [00:00<00:00, 156.86it/s, train_loss=0.00379, val_loss=0.00495]Epoch 14:  70%|███████   | 19/27 [00:00<00:00, 154.47it/s, train_loss=0.00463, val_loss=0.00495]Epoch 14:  74%|███████▍  | 20/27 [00:00<00:00, 156.17it/s, train_loss=0.00463, val_loss=0.00495]Epoch 14:  74%|███████▍  | 20/27 [00:00<00:00, 154.59it/s, train_loss=0.00519, val_loss=0.00495]Epoch 14:  78%|███████▊  | 21/27 [00:00<00:00, 156.32it/s, train_loss=0.00519, val_loss=0.00495]Epoch 14:  78%|███████▊  | 21/27 [00:00<00:00, 154.09it/s, train_loss=0.00415, val_loss=0.00495]Epoch 14:  81%|████████▏ | 22/27 [00:00<00:00, 155.72it/s, train_loss=0.00415, val_loss=0.00495]Epoch 14:  81%|████████▏ | 22/27 [00:00<00:00, 154.46it/s, train_loss=0.00465, val_loss=0.00495]Epoch 14:  85%|████████▌ | 23/27 [00:00<00:00, 155.84it/s, train_loss=0.00465, val_loss=0.00495]Epoch 14:  85%|████████▌ | 23/27 [00:00<00:00, 153.90it/s, train_loss=0.0037, val_loss=0.00495] Epoch 14:  89%|████████▉ | 24/27 [00:00<00:00, 155.18it/s, train_loss=0.0037, val_loss=0.00495]Epoch 14:  89%|████████▉ | 24/27 [00:00<00:00, 153.95it/s, train_loss=0.00491, val_loss=0.00495]Epoch 14:  93%|█████████▎| 25/27 [00:00<00:00, 155.16it/s, train_loss=0.00491, val_loss=0.00495]Epoch 14:  93%|█████████▎| 25/27 [00:00<00:00, 153.51it/s, train_loss=0.00351, val_loss=0.00495]Epoch 14:  96%|█████████▋| 26/27 [00:00<00:00, 155.05it/s, train_loss=0.00351, val_loss=0.00495]Epoch 14:  96%|█████████▋| 26/27 [00:00<00:00, 154.04it/s, train_loss=0.00474, val_loss=0.00495]Epoch 14: 100%|██████████| 27/27 [00:00<00:00, 155.81it/s, train_loss=0.00474, val_loss=0.00495]Epoch 14: 100%|██████████| 27/27 [00:00<00:00, 154.69it/s, train_loss=0.00488, val_loss=0.00495]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 220.92it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 252.08it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 261.15it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 220.54it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 127.94it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 94.83it/s] [A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 104.03it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 88.06it/s] [A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 95.12it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 101.03it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 107.23it/s][A
                                                                         [AEpoch 14: 100%|██████████| 27/27 [00:00<00:00, 95.23it/s, train_loss=0.00488, val_loss=0.0047]  Epoch 14: 100%|██████████| 27/27 [00:00<00:00, 94.94it/s, train_loss=0.00488, val_loss=0.0047]Epoch 14:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00488, val_loss=0.0047]         Epoch 15:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00488, val_loss=0.0047]Epoch 15:   4%|▎         | 1/27 [00:00<00:00, 162.13it/s, train_loss=0.00488, val_loss=0.0047]Epoch 15:   4%|▎         | 1/27 [00:00<00:00, 136.64it/s, train_loss=0.00435, val_loss=0.0047]Epoch 15:   7%|▋         | 2/27 [00:00<00:00, 167.84it/s, train_loss=0.00435, val_loss=0.0047]Epoch 15:   7%|▋         | 2/27 [00:00<00:00, 130.24it/s, train_loss=0.00424, val_loss=0.0047]Epoch 15:  11%|█         | 3/27 [00:00<00:00, 147.62it/s, train_loss=0.00424, val_loss=0.0047]Epoch 15:  11%|█         | 3/27 [00:00<00:00, 139.80it/s, train_loss=0.00429, val_loss=0.0047]Epoch 15:  15%|█▍        | 4/27 [00:00<00:00, 154.30it/s, train_loss=0.00429, val_loss=0.0047]Epoch 15:  15%|█▍        | 4/27 [00:00<00:00, 134.11it/s, train_loss=0.00463, val_loss=0.0047]Epoch 15:  19%|█▊        | 5/27 [00:00<00:00, 141.31it/s, train_loss=0.00463, val_loss=0.0047]Epoch 15:  19%|█▊        | 5/27 [00:00<00:00, 136.65it/s, train_loss=0.00456, val_loss=0.0047]Epoch 15:  22%|██▏       | 6/27 [00:00<00:00, 145.60it/s, train_loss=0.00456, val_loss=0.0047]Epoch 15:  22%|██▏       | 6/27 [00:00<00:00, 134.58it/s, train_loss=0.00333, val_loss=0.0047]Epoch 15:  26%|██▌       | 7/27 [00:00<00:00, 140.76it/s, train_loss=0.00333, val_loss=0.0047]Epoch 15:  26%|██▌       | 7/27 [00:00<00:00, 137.23it/s, train_loss=0.00368, val_loss=0.0047]Epoch 15:  30%|██▉       | 8/27 [00:00<00:00, 143.71it/s, train_loss=0.00368, val_loss=0.0047]Epoch 15:  30%|██▉       | 8/27 [00:00<00:00, 135.36it/s, train_loss=0.00482, val_loss=0.0047]Epoch 15:  33%|███▎      | 9/27 [00:00<00:00, 139.93it/s, train_loss=0.00482, val_loss=0.0047]Epoch 15:  33%|███▎      | 9/27 [00:00<00:00, 137.24it/s, train_loss=0.00454, val_loss=0.0047]Epoch 15:  37%|███▋      | 10/27 [00:00<00:00, 142.21it/s, train_loss=0.00454, val_loss=0.0047]Epoch 15:  37%|███▋      | 10/27 [00:00<00:00, 135.72it/s, train_loss=0.00465, val_loss=0.0047]Epoch 15:  41%|████      | 11/27 [00:00<00:00, 140.02it/s, train_loss=0.00465, val_loss=0.0047]Epoch 15:  41%|████      | 11/27 [00:00<00:00, 137.83it/s, train_loss=0.00364, val_loss=0.0047]Epoch 15:  44%|████▍     | 12/27 [00:00<00:00, 142.73it/s, train_loss=0.00364, val_loss=0.0047]Epoch 15:  44%|████▍     | 12/27 [00:00<00:00, 140.22it/s, train_loss=0.00462, val_loss=0.0047]Epoch 15:  48%|████▊     | 13/27 [00:00<00:00, 145.11it/s, train_loss=0.00462, val_loss=0.0047]Epoch 15:  48%|████▊     | 13/27 [00:00<00:00, 140.90it/s, train_loss=0.00404, val_loss=0.0047]Epoch 15:  52%|█████▏    | 14/27 [00:00<00:00, 144.11it/s, train_loss=0.00404, val_loss=0.0047]Epoch 15:  52%|█████▏    | 14/27 [00:00<00:00, 142.25it/s, train_loss=0.00348, val_loss=0.0047]Epoch 15:  56%|█████▌    | 15/27 [00:00<00:00, 145.31it/s, train_loss=0.00348, val_loss=0.0047]Epoch 15:  56%|█████▌    | 15/27 [00:00<00:00, 140.09it/s, train_loss=0.00444, val_loss=0.0047]Epoch 15:  59%|█████▉    | 16/27 [00:00<00:00, 142.61it/s, train_loss=0.00444, val_loss=0.0047]Epoch 15:  59%|█████▉    | 16/27 [00:00<00:00, 141.14it/s, train_loss=0.00392, val_loss=0.0047]Epoch 15:  63%|██████▎   | 17/27 [00:00<00:00, 144.14it/s, train_loss=0.00392, val_loss=0.0047]Epoch 15:  63%|██████▎   | 17/27 [00:00<00:00, 139.65it/s, train_loss=0.00459, val_loss=0.0047]Epoch 15:  67%|██████▋   | 18/27 [00:00<00:00, 141.40it/s, train_loss=0.00459, val_loss=0.0047]Epoch 15:  67%|██████▋   | 18/27 [00:00<00:00, 140.20it/s, train_loss=0.00333, val_loss=0.0047]Epoch 15:  70%|███████   | 19/27 [00:00<00:00, 143.00it/s, train_loss=0.00333, val_loss=0.0047]Epoch 15:  70%|███████   | 19/27 [00:00<00:00, 139.23it/s, train_loss=0.0043, val_loss=0.0047] Epoch 15:  74%|███████▍  | 20/27 [00:00<00:00, 141.51it/s, train_loss=0.0043, val_loss=0.0047]Epoch 15:  74%|███████▍  | 20/27 [00:00<00:00, 140.31it/s, train_loss=0.00404, val_loss=0.0047]Epoch 15:  78%|███████▊  | 21/27 [00:00<00:00, 141.59it/s, train_loss=0.00404, val_loss=0.0047]Epoch 15:  78%|███████▊  | 21/27 [00:00<00:00, 139.20it/s, train_loss=0.00476, val_loss=0.0047]Epoch 15:  81%|████████▏ | 22/27 [00:00<00:00, 141.30it/s, train_loss=0.00476, val_loss=0.0047]Epoch 15:  81%|████████▏ | 22/27 [00:00<00:00, 140.25it/s, train_loss=0.00332, val_loss=0.0047]Epoch 15:  85%|████████▌ | 23/27 [00:00<00:00, 142.77it/s, train_loss=0.00332, val_loss=0.0047]Epoch 15:  85%|████████▌ | 23/27 [00:00<00:00, 139.29it/s, train_loss=0.00419, val_loss=0.0047]Epoch 15:  89%|████████▉ | 24/27 [00:00<00:00, 140.38it/s, train_loss=0.00419, val_loss=0.0047]Epoch 15:  89%|████████▉ | 24/27 [00:00<00:00, 139.45it/s, train_loss=0.00413, val_loss=0.0047]Epoch 15:  93%|█████████▎| 25/27 [00:00<00:00, 140.94it/s, train_loss=0.00413, val_loss=0.0047]Epoch 15:  93%|█████████▎| 25/27 [00:00<00:00, 139.31it/s, train_loss=0.00377, val_loss=0.0047]Epoch 15:  96%|█████████▋| 26/27 [00:00<00:00, 140.85it/s, train_loss=0.00377, val_loss=0.0047]Epoch 15:  96%|█████████▋| 26/27 [00:00<00:00, 139.90it/s, train_loss=0.00395, val_loss=0.0047]Epoch 15: 100%|██████████| 27/27 [00:00<00:00, 141.82it/s, train_loss=0.00395, val_loss=0.0047]Epoch 15: 100%|██████████| 27/27 [00:00<00:00, 139.24it/s, train_loss=0.00339, val_loss=0.0047]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 267.92it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 293.82it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 305.29it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 309.97it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 310.25it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 312.61it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 313.35it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 310.66it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 305.87it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 305.21it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 305.81it/s][A
                                                                         [AEpoch 15: 100%|██████████| 27/27 [00:00<00:00, 113.35it/s, train_loss=0.00339, val_loss=0.00452]Epoch 15: 100%|██████████| 27/27 [00:00<00:00, 112.95it/s, train_loss=0.00339, val_loss=0.00452]Epoch 15:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00339, val_loss=0.00452]          Epoch 16:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00339, val_loss=0.00452]Epoch 16:   4%|▎         | 1/27 [00:00<00:00, 163.26it/s, train_loss=0.00339, val_loss=0.00452]Epoch 16:   4%|▎         | 1/27 [00:00<00:00, 116.88it/s, train_loss=0.00391, val_loss=0.00452]Epoch 16:   7%|▋         | 2/27 [00:00<00:00, 144.04it/s, train_loss=0.00391, val_loss=0.00452]Epoch 16:   7%|▋         | 2/27 [00:00<00:00, 134.08it/s, train_loss=0.00387, val_loss=0.00452]Epoch 16:  11%|█         | 3/27 [00:00<00:00, 150.91it/s, train_loss=0.00387, val_loss=0.00452]Epoch 16:  11%|█         | 3/27 [00:00<00:00, 129.43it/s, train_loss=0.00429, val_loss=0.00452]Epoch 16:  15%|█▍        | 4/27 [00:00<00:00, 138.21it/s, train_loss=0.00429, val_loss=0.00452]Epoch 16:  15%|█▍        | 4/27 [00:00<00:00, 133.01it/s, train_loss=0.00337, val_loss=0.00452]Epoch 16:  19%|█▊        | 5/27 [00:00<00:00, 143.02it/s, train_loss=0.00337, val_loss=0.00452]Epoch 16:  19%|█▊        | 5/27 [00:00<00:00, 138.12it/s, train_loss=0.00353, val_loss=0.00452]Epoch 16:  22%|██▏       | 6/27 [00:00<00:00, 145.00it/s, train_loss=0.00353, val_loss=0.00452]Epoch 16:  22%|██▏       | 6/27 [00:00<00:00, 137.72it/s, train_loss=0.00348, val_loss=0.00452]Epoch 16:  26%|██▌       | 7/27 [00:00<00:00, 143.62it/s, train_loss=0.00348, val_loss=0.00452]Epoch 16:  26%|██▌       | 7/27 [00:00<00:00, 140.21it/s, train_loss=0.00445, val_loss=0.00452]Epoch 16:  30%|██▉       | 8/27 [00:00<00:00, 146.90it/s, train_loss=0.00445, val_loss=0.00452]Epoch 16:  30%|██▉       | 8/27 [00:00<00:00, 137.82it/s, train_loss=0.00396, val_loss=0.00452]Epoch 16:  33%|███▎      | 9/27 [00:00<00:00, 141.99it/s, train_loss=0.00396, val_loss=0.00452]Epoch 16:  33%|███▎      | 9/27 [00:00<00:00, 139.60it/s, train_loss=0.00299, val_loss=0.00452]Epoch 16:  37%|███▋      | 10/27 [00:00<00:00, 144.42it/s, train_loss=0.00299, val_loss=0.00452]Epoch 16:  37%|███▋      | 10/27 [00:00<00:00, 137.84it/s, train_loss=0.00381, val_loss=0.00452]Epoch 16:  41%|████      | 11/27 [00:00<00:00, 141.15it/s, train_loss=0.00381, val_loss=0.00452]Epoch 16:  41%|████      | 11/27 [00:00<00:00, 139.27it/s, train_loss=0.00363, val_loss=0.00452]Epoch 16:  44%|████▍     | 12/27 [00:00<00:00, 143.20it/s, train_loss=0.00363, val_loss=0.00452]Epoch 16:  44%|████▍     | 12/27 [00:00<00:00, 137.77it/s, train_loss=0.00489, val_loss=0.00452]Epoch 16:  48%|████▊     | 13/27 [00:00<00:00, 140.47it/s, train_loss=0.00489, val_loss=0.00452]Epoch 16:  48%|████▊     | 13/27 [00:00<00:00, 138.74it/s, train_loss=0.00454, val_loss=0.00452]Epoch 16:  52%|█████▏    | 14/27 [00:00<00:00, 142.76it/s, train_loss=0.00454, val_loss=0.00452]Epoch 16:  52%|█████▏    | 14/27 [00:00<00:00, 137.66it/s, train_loss=0.00379, val_loss=0.00452]Epoch 16:  56%|█████▌    | 15/27 [00:00<00:00, 140.25it/s, train_loss=0.00379, val_loss=0.00452]Epoch 16:  56%|█████▌    | 15/27 [00:00<00:00, 138.90it/s, train_loss=0.00384, val_loss=0.00452]Epoch 16:  59%|█████▉    | 16/27 [00:00<00:00, 142.01it/s, train_loss=0.00384, val_loss=0.00452]Epoch 16:  59%|█████▉    | 16/27 [00:00<00:00, 140.49it/s, train_loss=0.00517, val_loss=0.00452]Epoch 16:  63%|██████▎   | 17/27 [00:00<00:00, 143.71it/s, train_loss=0.00517, val_loss=0.00452]Epoch 16:  63%|██████▎   | 17/27 [00:00<00:00, 139.30it/s, train_loss=0.00418, val_loss=0.00452]Epoch 16:  67%|██████▋   | 18/27 [00:00<00:00, 141.54it/s, train_loss=0.00418, val_loss=0.00452]Epoch 16:  67%|██████▋   | 18/27 [00:00<00:00, 140.27it/s, train_loss=0.0044, val_loss=0.00452] Epoch 16:  70%|███████   | 19/27 [00:00<00:00, 142.87it/s, train_loss=0.0044, val_loss=0.00452]Epoch 16:  70%|███████   | 19/27 [00:00<00:00, 141.54it/s, train_loss=0.00361, val_loss=0.00452]Epoch 16:  74%|███████▍  | 20/27 [00:00<00:00, 144.08it/s, train_loss=0.00361, val_loss=0.00452]Epoch 16:  74%|███████▍  | 20/27 [00:00<00:00, 142.01it/s, train_loss=0.00464, val_loss=0.00452]Epoch 16:  78%|███████▊  | 21/27 [00:00<00:00, 143.88it/s, train_loss=0.00464, val_loss=0.00452]Epoch 16:  78%|███████▊  | 21/27 [00:00<00:00, 142.77it/s, train_loss=0.00398, val_loss=0.00452]Epoch 16:  81%|████████▏ | 22/27 [00:00<00:00, 145.01it/s, train_loss=0.00398, val_loss=0.00452]Epoch 16:  81%|████████▏ | 22/27 [00:00<00:00, 141.80it/s, train_loss=0.00347, val_loss=0.00452]Epoch 16:  85%|████████▌ | 23/27 [00:00<00:00, 143.39it/s, train_loss=0.00347, val_loss=0.00452]Epoch 16:  85%|████████▌ | 23/27 [00:00<00:00, 142.31it/s, train_loss=0.00392, val_loss=0.00452]Epoch 16:  89%|████████▉ | 24/27 [00:00<00:00, 144.25it/s, train_loss=0.00392, val_loss=0.00452]Epoch 16:  89%|████████▉ | 24/27 [00:00<00:00, 143.17it/s, train_loss=0.00431, val_loss=0.00452]Epoch 16:  93%|█████████▎| 25/27 [00:00<00:00, 145.15it/s, train_loss=0.00431, val_loss=0.00452]Epoch 16:  93%|█████████▎| 25/27 [00:00<00:00, 142.25it/s, train_loss=0.00374, val_loss=0.00452]Epoch 16:  96%|█████████▋| 26/27 [00:00<00:00, 143.56it/s, train_loss=0.00374, val_loss=0.00452]Epoch 16:  96%|█████████▋| 26/27 [00:00<00:00, 142.68it/s, train_loss=0.00434, val_loss=0.00452]Epoch 16: 100%|██████████| 27/27 [00:00<00:00, 144.39it/s, train_loss=0.00434, val_loss=0.00452]Epoch 16: 100%|██████████| 27/27 [00:00<00:00, 141.94it/s, train_loss=0.00254, val_loss=0.00452]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 155.22it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 186.93it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 197.89it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 206.02it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 210.45it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 212.61it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 214.18it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 221.00it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 229.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 237.18it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 243.85it/s][A
                                                                         [AEpoch 16: 100%|██████████| 27/27 [00:00<00:00, 111.52it/s, train_loss=0.00254, val_loss=0.00439]Epoch 16: 100%|██████████| 27/27 [00:00<00:00, 111.21it/s, train_loss=0.00254, val_loss=0.00439]Epoch 16:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00254, val_loss=0.00439]          Epoch 17:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00254, val_loss=0.00439]Epoch 17:   4%|▎         | 1/27 [00:00<00:00, 170.83it/s, train_loss=0.00254, val_loss=0.00439]Epoch 17:   4%|▎         | 1/27 [00:00<00:00, 144.62it/s, train_loss=0.00382, val_loss=0.00439]Epoch 17:   7%|▋         | 2/27 [00:00<00:00, 174.02it/s, train_loss=0.00382, val_loss=0.00439]Epoch 17:   7%|▋         | 2/27 [00:00<00:00, 148.52it/s, train_loss=0.0041, val_loss=0.00439] Epoch 17:  11%|█         | 3/27 [00:00<00:00, 161.78it/s, train_loss=0.0041, val_loss=0.00439]Epoch 17:  11%|█         | 3/27 [00:00<00:00, 152.31it/s, train_loss=0.00365, val_loss=0.00439]Epoch 17:  15%|█▍        | 4/27 [00:00<00:00, 164.33it/s, train_loss=0.00365, val_loss=0.00439]Epoch 17:  15%|█▍        | 4/27 [00:00<00:00, 156.01it/s, train_loss=0.0045, val_loss=0.00439] Epoch 17:  19%|█▊        | 5/27 [00:00<00:00, 165.90it/s, train_loss=0.0045, val_loss=0.00439]Epoch 17:  19%|█▊        | 5/27 [00:00<00:00, 155.15it/s, train_loss=0.00392, val_loss=0.00439]Epoch 17:  22%|██▏       | 6/27 [00:00<00:00, 160.78it/s, train_loss=0.00392, val_loss=0.00439]Epoch 17:  22%|██▏       | 6/27 [00:00<00:00, 155.97it/s, train_loss=0.00323, val_loss=0.00439]Epoch 17:  26%|██▌       | 7/27 [00:00<00:00, 159.10it/s, train_loss=0.00323, val_loss=0.00439]Epoch 17:  26%|██▌       | 7/27 [00:00<00:00, 154.63it/s, train_loss=0.00427, val_loss=0.00439]Epoch 17:  30%|██▉       | 8/27 [00:00<00:00, 156.57it/s, train_loss=0.00427, val_loss=0.00439]Epoch 17:  30%|██▉       | 8/27 [00:00<00:00, 153.64it/s, train_loss=0.00379, val_loss=0.00439]Epoch 17:  33%|███▎      | 9/27 [00:00<00:00, 157.18it/s, train_loss=0.00379, val_loss=0.00439]Epoch 17:  33%|███▎      | 9/27 [00:00<00:00, 154.05it/s, train_loss=0.00396, val_loss=0.00439]Epoch 17:  37%|███▋      | 10/27 [00:00<00:00, 158.39it/s, train_loss=0.00396, val_loss=0.00439]Epoch 17:  37%|███▋      | 10/27 [00:00<00:00, 149.59it/s, train_loss=0.00384, val_loss=0.00439]Epoch 17:  41%|████      | 11/27 [00:00<00:00, 152.00it/s, train_loss=0.00384, val_loss=0.00439]Epoch 17:  41%|████      | 11/27 [00:00<00:00, 149.57it/s, train_loss=0.00435, val_loss=0.00439]Epoch 17:  44%|████▍     | 12/27 [00:00<00:00, 153.17it/s, train_loss=0.00435, val_loss=0.00439]Epoch 17:  44%|████▍     | 12/27 [00:00<00:00, 147.18it/s, train_loss=0.00395, val_loss=0.00439]Epoch 17:  48%|████▊     | 13/27 [00:00<00:00, 149.72it/s, train_loss=0.00395, val_loss=0.00439]Epoch 17:  48%|████▊     | 13/27 [00:00<00:00, 147.70it/s, train_loss=0.00319, val_loss=0.00439]Epoch 17:  52%|█████▏    | 14/27 [00:00<00:00, 150.86it/s, train_loss=0.00319, val_loss=0.00439]Epoch 17:  52%|█████▏    | 14/27 [00:00<00:00, 145.78it/s, train_loss=0.00361, val_loss=0.00439]Epoch 17:  56%|█████▌    | 15/27 [00:00<00:00, 147.89it/s, train_loss=0.00361, val_loss=0.00439]Epoch 17:  56%|█████▌    | 15/27 [00:00<00:00, 146.32it/s, train_loss=0.00345, val_loss=0.00439]Epoch 17:  59%|█████▉    | 16/27 [00:00<00:00, 148.92it/s, train_loss=0.00345, val_loss=0.00439]Epoch 17:  59%|█████▉    | 16/27 [00:00<00:00, 144.59it/s, train_loss=0.00315, val_loss=0.00439]Epoch 17:  63%|██████▎   | 17/27 [00:00<00:00, 146.37it/s, train_loss=0.00315, val_loss=0.00439]Epoch 17:  63%|██████▎   | 17/27 [00:00<00:00, 145.03it/s, train_loss=0.0033, val_loss=0.00439] Epoch 17:  67%|██████▋   | 18/27 [00:00<00:00, 147.78it/s, train_loss=0.0033, val_loss=0.00439]Epoch 17:  67%|██████▋   | 18/27 [00:00<00:00, 143.52it/s, train_loss=0.00349, val_loss=0.00439]Epoch 17:  70%|███████   | 19/27 [00:00<00:00, 145.45it/s, train_loss=0.00349, val_loss=0.00439]Epoch 17:  70%|███████   | 19/27 [00:00<00:00, 144.11it/s, train_loss=0.00387, val_loss=0.00439]Epoch 17:  74%|███████▍  | 20/27 [00:00<00:00, 145.05it/s, train_loss=0.00387, val_loss=0.00439]Epoch 17:  74%|███████▍  | 20/27 [00:00<00:00, 142.81it/s, train_loss=0.00381, val_loss=0.00439]Epoch 17:  78%|███████▊  | 21/27 [00:00<00:00, 144.68it/s, train_loss=0.00381, val_loss=0.00439]Epoch 17:  78%|███████▊  | 21/27 [00:00<00:00, 143.54it/s, train_loss=0.00455, val_loss=0.00439]Epoch 17:  81%|████████▏ | 22/27 [00:00<00:00, 145.86it/s, train_loss=0.00455, val_loss=0.00439]Epoch 17:  81%|████████▏ | 22/27 [00:00<00:00, 144.63it/s, train_loss=0.00458, val_loss=0.00439]Epoch 17:  85%|████████▌ | 23/27 [00:00<00:00, 146.02it/s, train_loss=0.00458, val_loss=0.00439]Epoch 17:  85%|████████▌ | 23/27 [00:00<00:00, 144.82it/s, train_loss=0.00366, val_loss=0.00439]Epoch 17:  89%|████████▉ | 24/27 [00:00<00:00, 146.51it/s, train_loss=0.00366, val_loss=0.00439]Epoch 17:  89%|████████▉ | 24/27 [00:00<00:00, 145.55it/s, train_loss=0.00389, val_loss=0.00439]Epoch 17:  93%|█████████▎| 25/27 [00:00<00:00, 147.69it/s, train_loss=0.00389, val_loss=0.00439]Epoch 17:  93%|█████████▎| 25/27 [00:00<00:00, 146.46it/s, train_loss=0.00378, val_loss=0.00439]Epoch 17:  96%|█████████▋| 26/27 [00:00<00:00, 147.98it/s, train_loss=0.00378, val_loss=0.00439]Epoch 17:  96%|█████████▋| 26/27 [00:00<00:00, 146.52it/s, train_loss=0.00356, val_loss=0.00439]Epoch 17: 100%|██████████| 27/27 [00:00<00:00, 147.92it/s, train_loss=0.00356, val_loss=0.00439]Epoch 17: 100%|██████████| 27/27 [00:00<00:00, 147.05it/s, train_loss=0.0041, val_loss=0.00439] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 166.80it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 195.11it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 207.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 215.98it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 218.85it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 222.42it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 224.56it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 225.46it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 226.71it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 226.60it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 227.91it/s][A
                                                                         [AEpoch 17: 100%|██████████| 27/27 [00:00<00:00, 112.15it/s, train_loss=0.0041, val_loss=0.00425]Epoch 17: 100%|██████████| 27/27 [00:00<00:00, 111.64it/s, train_loss=0.0041, val_loss=0.00425]Epoch 17:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0041, val_loss=0.00425]          Epoch 18:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0041, val_loss=0.00425]Epoch 18:   4%|▎         | 1/27 [00:00<00:00, 145.40it/s, train_loss=0.0041, val_loss=0.00425]Epoch 18:   4%|▎         | 1/27 [00:00<00:00, 127.91it/s, train_loss=0.00349, val_loss=0.00425]Epoch 18:   7%|▋         | 2/27 [00:00<00:00, 155.57it/s, train_loss=0.00349, val_loss=0.00425]Epoch 18:   7%|▋         | 2/27 [00:00<00:00, 143.72it/s, train_loss=0.00313, val_loss=0.00425]Epoch 18:  11%|█         | 3/27 [00:00<00:00, 164.15it/s, train_loss=0.00313, val_loss=0.00425]Epoch 18:  11%|█         | 3/27 [00:00<00:00, 135.33it/s, train_loss=0.00386, val_loss=0.00425]Epoch 18:  15%|█▍        | 4/27 [00:00<00:00, 146.10it/s, train_loss=0.00386, val_loss=0.00425]Epoch 18:  15%|█▍        | 4/27 [00:00<00:00, 140.28it/s, train_loss=0.00336, val_loss=0.00425]Epoch 18:  19%|█▊        | 5/27 [00:00<00:00, 150.22it/s, train_loss=0.00336, val_loss=0.00425]Epoch 18:  19%|█▊        | 5/27 [00:00<00:00, 136.04it/s, train_loss=0.00435, val_loss=0.00425]Epoch 18:  22%|██▏       | 6/27 [00:00<00:00, 142.55it/s, train_loss=0.00435, val_loss=0.00425]Epoch 18:  22%|██▏       | 6/27 [00:00<00:00, 138.83it/s, train_loss=0.00394, val_loss=0.00425]Epoch 18:  26%|██▌       | 7/27 [00:00<00:00, 145.72it/s, train_loss=0.00394, val_loss=0.00425]Epoch 18:  26%|██▌       | 7/27 [00:00<00:00, 135.56it/s, train_loss=0.00472, val_loss=0.00425]Epoch 18:  30%|██▉       | 8/27 [00:00<00:00, 140.48it/s, train_loss=0.00472, val_loss=0.00425]Epoch 18:  30%|██▉       | 8/27 [00:00<00:00, 137.91it/s, train_loss=0.00414, val_loss=0.00425]Epoch 18:  33%|███▎      | 9/27 [00:00<00:00, 143.39it/s, train_loss=0.00414, val_loss=0.00425]Epoch 18:  33%|███▎      | 9/27 [00:00<00:00, 135.55it/s, train_loss=0.00371, val_loss=0.00425]Epoch 18:  37%|███▋      | 10/27 [00:00<00:00, 139.47it/s, train_loss=0.00371, val_loss=0.00425]Epoch 18:  37%|███▋      | 10/27 [00:00<00:00, 137.44it/s, train_loss=0.0037, val_loss=0.00425] Epoch 18:  41%|████      | 11/27 [00:00<00:00, 141.83it/s, train_loss=0.0037, val_loss=0.00425]Epoch 18:  41%|████      | 11/27 [00:00<00:00, 135.60it/s, train_loss=0.00385, val_loss=0.00425]Epoch 18:  44%|████▍     | 12/27 [00:00<00:00, 138.47it/s, train_loss=0.00385, val_loss=0.00425]Epoch 18:  44%|████▍     | 12/27 [00:00<00:00, 136.64it/s, train_loss=0.00391, val_loss=0.00425]Epoch 18:  48%|████▊     | 13/27 [00:00<00:00, 140.31it/s, train_loss=0.00391, val_loss=0.00425]Epoch 18:  48%|████▊     | 13/27 [00:00<00:00, 135.65it/s, train_loss=0.00358, val_loss=0.00425]Epoch 18:  52%|█████▏    | 14/27 [00:00<00:00, 138.55it/s, train_loss=0.00358, val_loss=0.00425]Epoch 18:  52%|█████▏    | 14/27 [00:00<00:00, 136.86it/s, train_loss=0.00424, val_loss=0.00425]Epoch 18:  56%|█████▌    | 15/27 [00:00<00:00, 140.21it/s, train_loss=0.00424, val_loss=0.00425]Epoch 18:  56%|█████▌    | 15/27 [00:00<00:00, 135.87it/s, train_loss=0.00373, val_loss=0.00425]Epoch 18:  59%|█████▉    | 16/27 [00:00<00:00, 138.42it/s, train_loss=0.00373, val_loss=0.00425]Epoch 18:  59%|█████▉    | 16/27 [00:00<00:00, 136.95it/s, train_loss=0.00357, val_loss=0.00425]Epoch 18:  63%|██████▎   | 17/27 [00:00<00:00, 139.71it/s, train_loss=0.00357, val_loss=0.00425]Epoch 18:  63%|██████▎   | 17/27 [00:00<00:00, 136.11it/s, train_loss=0.00343, val_loss=0.00425]Epoch 18:  67%|██████▋   | 18/27 [00:00<00:00, 138.23it/s, train_loss=0.00343, val_loss=0.00425]Epoch 18:  67%|██████▋   | 18/27 [00:00<00:00, 137.08it/s, train_loss=0.0034, val_loss=0.00425] Epoch 18:  70%|███████   | 19/27 [00:00<00:00, 139.50it/s, train_loss=0.0034, val_loss=0.00425]Epoch 18:  70%|███████   | 19/27 [00:00<00:00, 136.27it/s, train_loss=0.00311, val_loss=0.00425]Epoch 18:  74%|███████▍  | 20/27 [00:00<00:00, 138.02it/s, train_loss=0.00311, val_loss=0.00425]Epoch 18:  74%|███████▍  | 20/27 [00:00<00:00, 137.02it/s, train_loss=0.00274, val_loss=0.00425]Epoch 18:  78%|███████▊  | 21/27 [00:00<00:00, 139.54it/s, train_loss=0.00274, val_loss=0.00425]Epoch 18:  78%|███████▊  | 21/27 [00:00<00:00, 136.21it/s, train_loss=0.00359, val_loss=0.00425]Epoch 18:  81%|████████▏ | 22/27 [00:00<00:00, 138.06it/s, train_loss=0.00359, val_loss=0.00425]Epoch 18:  81%|████████▏ | 22/27 [00:00<00:00, 137.13it/s, train_loss=0.00377, val_loss=0.00425]Epoch 18:  85%|████████▌ | 23/27 [00:00<00:00, 139.39it/s, train_loss=0.00377, val_loss=0.00425]Epoch 18:  85%|████████▌ | 23/27 [00:00<00:00, 138.29it/s, train_loss=0.00351, val_loss=0.00425]Epoch 18:  89%|████████▉ | 24/27 [00:00<00:00, 140.66it/s, train_loss=0.00351, val_loss=0.00425]Epoch 18:  89%|████████▉ | 24/27 [00:00<00:00, 138.76it/s, train_loss=0.00365, val_loss=0.00425]Epoch 18:  93%|█████████▎| 25/27 [00:00<00:00, 140.37it/s, train_loss=0.00365, val_loss=0.00425]Epoch 18:  93%|█████████▎| 25/27 [00:00<00:00, 139.47it/s, train_loss=0.00397, val_loss=0.00425]Epoch 18:  96%|█████████▋| 26/27 [00:00<00:00, 141.38it/s, train_loss=0.00397, val_loss=0.00425]Epoch 18:  96%|█████████▋| 26/27 [00:00<00:00, 140.38it/s, train_loss=0.00343, val_loss=0.00425]Epoch 18: 100%|██████████| 27/27 [00:00<00:00, 142.23it/s, train_loss=0.00343, val_loss=0.00425]Epoch 18: 100%|██████████| 27/27 [00:00<00:00, 140.81it/s, train_loss=0.00429, val_loss=0.00425]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 175.22it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 207.77it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 223.33it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 228.59it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 233.36it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 234.14it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 236.43it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 237.94it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 238.28it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 237.99it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 238.62it/s][A
                                                                         [AEpoch 18: 100%|██████████| 27/27 [00:00<00:00, 110.14it/s, train_loss=0.00429, val_loss=0.00409]Epoch 18: 100%|██████████| 27/27 [00:00<00:00, 109.72it/s, train_loss=0.00429, val_loss=0.00409]Epoch 18:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00429, val_loss=0.00409]          Epoch 19:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00429, val_loss=0.00409]Epoch 19:   4%|▎         | 1/27 [00:00<00:00, 151.94it/s, train_loss=0.00429, val_loss=0.00409]Epoch 19:   4%|▎         | 1/27 [00:00<00:00, 128.91it/s, train_loss=0.00322, val_loss=0.00409]Epoch 19:   7%|▋         | 2/27 [00:00<00:00, 156.13it/s, train_loss=0.00322, val_loss=0.00409]Epoch 19:   7%|▋         | 2/27 [00:00<00:00, 124.96it/s, train_loss=0.00335, val_loss=0.00409]Epoch 19:  11%|█         | 3/27 [00:00<00:00, 138.16it/s, train_loss=0.00335, val_loss=0.00409]Epoch 19:  11%|█         | 3/27 [00:00<00:00, 131.58it/s, train_loss=0.00402, val_loss=0.00409]Epoch 19:  15%|█▍        | 4/27 [00:00<00:00, 139.93it/s, train_loss=0.00402, val_loss=0.00409]Epoch 19:  15%|█▍        | 4/27 [00:00<00:00, 129.31it/s, train_loss=0.00347, val_loss=0.00409]Epoch 19:  19%|█▊        | 5/27 [00:00<00:00, 139.61it/s, train_loss=0.00347, val_loss=0.00409]Epoch 19:  19%|█▊        | 5/27 [00:00<00:00, 135.08it/s, train_loss=0.00343, val_loss=0.00409]Epoch 19:  22%|██▏       | 6/27 [00:00<00:00, 144.86it/s, train_loss=0.00343, val_loss=0.00409]Epoch 19:  22%|██▏       | 6/27 [00:00<00:00, 140.44it/s, train_loss=0.00391, val_loss=0.00409]Epoch 19:  26%|██▌       | 7/27 [00:00<00:00, 147.47it/s, train_loss=0.00391, val_loss=0.00409]Epoch 19:  26%|██▌       | 7/27 [00:00<00:00, 141.10it/s, train_loss=0.00363, val_loss=0.00409]Epoch 19:  30%|██▉       | 8/27 [00:00<00:00, 147.08it/s, train_loss=0.00363, val_loss=0.00409]Epoch 19:  30%|██▉       | 8/27 [00:00<00:00, 144.03it/s, train_loss=0.00387, val_loss=0.00409]Epoch 19:  33%|███▎      | 9/27 [00:00<00:00, 150.25it/s, train_loss=0.00387, val_loss=0.00409]Epoch 19:  33%|███▎      | 9/27 [00:00<00:00, 147.01it/s, train_loss=0.00371, val_loss=0.00409]Epoch 19:  37%|███▋      | 10/27 [00:00<00:00, 151.12it/s, train_loss=0.00371, val_loss=0.00409]Epoch 19:  37%|███▋      | 10/27 [00:00<00:00, 147.10it/s, train_loss=0.00424, val_loss=0.00409]Epoch 19:  41%|████      | 11/27 [00:00<00:00, 150.79it/s, train_loss=0.00424, val_loss=0.00409]Epoch 19:  41%|████      | 11/27 [00:00<00:00, 148.22it/s, train_loss=0.0036, val_loss=0.00409] Epoch 19:  44%|████▍     | 12/27 [00:00<00:00, 152.52it/s, train_loss=0.0036, val_loss=0.00409]Epoch 19:  44%|████▍     | 12/27 [00:00<00:00, 149.93it/s, train_loss=0.00448, val_loss=0.00409]Epoch 19:  48%|████▊     | 13/27 [00:00<00:00, 152.80it/s, train_loss=0.00448, val_loss=0.00409]Epoch 19:  48%|████▊     | 13/27 [00:00<00:00, 149.67it/s, train_loss=0.00369, val_loss=0.00409]Epoch 19:  52%|█████▏    | 14/27 [00:00<00:00, 151.37it/s, train_loss=0.00369, val_loss=0.00409]Epoch 19:  52%|█████▏    | 14/27 [00:00<00:00, 149.69it/s, train_loss=0.00411, val_loss=0.00409]Epoch 19:  56%|█████▌    | 15/27 [00:00<00:00, 152.53it/s, train_loss=0.00411, val_loss=0.00409]Epoch 19:  56%|█████▌    | 15/27 [00:00<00:00, 150.60it/s, train_loss=0.00318, val_loss=0.00409]Epoch 19:  59%|█████▉    | 16/27 [00:00<00:00, 153.58it/s, train_loss=0.00318, val_loss=0.00409]Epoch 19:  59%|█████▉    | 16/27 [00:00<00:00, 150.60it/s, train_loss=0.00426, val_loss=0.00409]Epoch 19:  63%|██████▎   | 17/27 [00:00<00:00, 152.58it/s, train_loss=0.00426, val_loss=0.00409]Epoch 19:  63%|██████▎   | 17/27 [00:00<00:00, 151.03it/s, train_loss=0.00294, val_loss=0.00409]Epoch 19:  67%|██████▋   | 18/27 [00:00<00:00, 151.84it/s, train_loss=0.00294, val_loss=0.00409]Epoch 19:  67%|██████▋   | 18/27 [00:00<00:00, 149.16it/s, train_loss=0.0033, val_loss=0.00409] Epoch 19:  70%|███████   | 19/27 [00:00<00:00, 150.91it/s, train_loss=0.0033, val_loss=0.00409]Epoch 19:  70%|███████   | 19/27 [00:00<00:00, 149.55it/s, train_loss=0.00298, val_loss=0.00409]Epoch 19:  74%|███████▍  | 20/27 [00:00<00:00, 151.83it/s, train_loss=0.00298, val_loss=0.00409]Epoch 19:  74%|███████▍  | 20/27 [00:00<00:00, 147.94it/s, train_loss=0.00377, val_loss=0.00409]Epoch 19:  78%|███████▊  | 21/27 [00:00<00:00, 148.71it/s, train_loss=0.00377, val_loss=0.00409]Epoch 19:  78%|███████▊  | 21/27 [00:00<00:00, 147.44it/s, train_loss=0.00335, val_loss=0.00409]Epoch 19:  81%|████████▏ | 22/27 [00:00<00:00, 148.92it/s, train_loss=0.00335, val_loss=0.00409]Epoch 19:  81%|████████▏ | 22/27 [00:00<00:00, 146.84it/s, train_loss=0.0042, val_loss=0.00409] Epoch 19:  85%|████████▌ | 23/27 [00:00<00:00, 148.43it/s, train_loss=0.0042, val_loss=0.00409]Epoch 19:  85%|████████▌ | 23/27 [00:00<00:00, 147.32it/s, train_loss=0.00379, val_loss=0.00409]Epoch 19:  89%|████████▉ | 24/27 [00:00<00:00, 149.70it/s, train_loss=0.00379, val_loss=0.00409]Epoch 19:  89%|████████▉ | 24/27 [00:00<00:00, 146.62it/s, train_loss=0.00296, val_loss=0.00409]Epoch 19:  93%|█████████▎| 25/27 [00:00<00:00, 148.06it/s, train_loss=0.00296, val_loss=0.00409]Epoch 19:  93%|█████████▎| 25/27 [00:00<00:00, 147.02it/s, train_loss=0.00372, val_loss=0.00409]Epoch 19:  96%|█████████▋| 26/27 [00:00<00:00, 148.76it/s, train_loss=0.00372, val_loss=0.00409]Epoch 19:  96%|█████████▋| 26/27 [00:00<00:00, 147.79it/s, train_loss=0.00301, val_loss=0.00409]Epoch 19: 100%|██████████| 27/27 [00:00<00:00, 149.67it/s, train_loss=0.00301, val_loss=0.00409]Epoch 19: 100%|██████████| 27/27 [00:00<00:00, 146.64it/s, train_loss=0.00302, val_loss=0.00409]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 191.54it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 223.12it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 229.96it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 227.71it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 234.16it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 238.42it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 239.57it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 242.32it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 243.92it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 244.65it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 247.28it/s][A
                                                                         [AEpoch 19: 100%|██████████| 27/27 [00:00<00:00, 113.77it/s, train_loss=0.00302, val_loss=0.00399]Epoch 19: 100%|██████████| 27/27 [00:00<00:00, 113.34it/s, train_loss=0.00302, val_loss=0.00399]Epoch 19:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00399]          Epoch 20:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00399]Epoch 20:   4%|▎         | 1/27 [00:00<00:00, 153.08it/s, train_loss=0.00302, val_loss=0.00399]Epoch 20:   4%|▎         | 1/27 [00:00<00:00, 127.61it/s, train_loss=0.00293, val_loss=0.00399]Epoch 20:   7%|▋         | 2/27 [00:00<00:00, 153.59it/s, train_loss=0.00293, val_loss=0.00399]Epoch 20:   7%|▋         | 2/27 [00:00<00:00, 141.62it/s, train_loss=0.00338, val_loss=0.00399]Epoch 20:  11%|█         | 3/27 [00:00<00:00, 159.07it/s, train_loss=0.00338, val_loss=0.00399]Epoch 20:  11%|█         | 3/27 [00:00<00:00, 132.98it/s, train_loss=0.0032, val_loss=0.00399] Epoch 20:  15%|█▍        | 4/27 [00:00<00:00, 141.41it/s, train_loss=0.0032, val_loss=0.00399]Epoch 20:  15%|█▍        | 4/27 [00:00<00:00, 136.38it/s, train_loss=0.00387, val_loss=0.00399]Epoch 20:  19%|█▊        | 5/27 [00:00<00:00, 145.91it/s, train_loss=0.00387, val_loss=0.00399]Epoch 20:  19%|█▊        | 5/27 [00:00<00:00, 133.66it/s, train_loss=0.003, val_loss=0.00399]  Epoch 20:  22%|██▏       | 6/27 [00:00<00:00, 139.27it/s, train_loss=0.003, val_loss=0.00399]Epoch 20:  22%|██▏       | 6/27 [00:00<00:00, 135.97it/s, train_loss=0.00326, val_loss=0.00399]Epoch 20:  26%|██▌       | 7/27 [00:00<00:00, 140.48it/s, train_loss=0.00326, val_loss=0.00399]Epoch 20:  26%|██▌       | 7/27 [00:00<00:00, 133.98it/s, train_loss=0.0028, val_loss=0.00399] Epoch 20:  30%|██▉       | 8/27 [00:00<00:00, 138.10it/s, train_loss=0.0028, val_loss=0.00399]Epoch 20:  30%|██▉       | 8/27 [00:00<00:00, 135.46it/s, train_loss=0.00382, val_loss=0.00399]Epoch 20:  33%|███▎      | 9/27 [00:00<00:00, 142.17it/s, train_loss=0.00382, val_loss=0.00399]Epoch 20:  33%|███▎      | 9/27 [00:00<00:00, 134.04it/s, train_loss=0.00369, val_loss=0.00399]Epoch 20:  37%|███▋      | 10/27 [00:00<00:00, 138.71it/s, train_loss=0.00369, val_loss=0.00399]Epoch 20:  37%|███▋      | 10/27 [00:00<00:00, 136.57it/s, train_loss=0.00342, val_loss=0.00399]Epoch 20:  41%|████      | 11/27 [00:00<00:00, 141.33it/s, train_loss=0.00342, val_loss=0.00399]Epoch 20:  41%|████      | 11/27 [00:00<00:00, 139.06it/s, train_loss=0.00383, val_loss=0.00399]Epoch 20:  44%|████▍     | 12/27 [00:00<00:00, 142.32it/s, train_loss=0.00383, val_loss=0.00399]Epoch 20:  44%|████▍     | 12/27 [00:00<00:00, 139.81it/s, train_loss=0.00338, val_loss=0.00399]Epoch 20:  48%|████▊     | 13/27 [00:00<00:00, 143.11it/s, train_loss=0.00338, val_loss=0.00399]Epoch 20:  48%|████▊     | 13/27 [00:00<00:00, 141.20it/s, train_loss=0.00383, val_loss=0.00399]Epoch 20:  52%|█████▏    | 14/27 [00:00<00:00, 145.04it/s, train_loss=0.00383, val_loss=0.00399]Epoch 20:  52%|█████▏    | 14/27 [00:00<00:00, 143.06it/s, train_loss=0.00364, val_loss=0.00399]Epoch 20:  56%|█████▌    | 15/27 [00:00<00:00, 145.79it/s, train_loss=0.00364, val_loss=0.00399]Epoch 20:  56%|█████▌    | 15/27 [00:00<00:00, 143.37it/s, train_loss=0.00385, val_loss=0.00399]Epoch 20:  59%|█████▉    | 16/27 [00:00<00:00, 127.95it/s, train_loss=0.00385, val_loss=0.00399]Epoch 20:  59%|█████▉    | 16/27 [00:00<00:00, 126.81it/s, train_loss=0.00336, val_loss=0.00399]Epoch 20:  63%|██████▎   | 17/27 [00:00<00:00, 129.81it/s, train_loss=0.00336, val_loss=0.00399]Epoch 20:  63%|██████▎   | 17/27 [00:00<00:00, 126.55it/s, train_loss=0.00449, val_loss=0.00399]Epoch 20:  67%|██████▋   | 18/27 [00:00<00:00, 128.84it/s, train_loss=0.00449, val_loss=0.00399]Epoch 20:  67%|██████▋   | 18/27 [00:00<00:00, 127.83it/s, train_loss=0.00369, val_loss=0.00399]Epoch 20:  70%|███████   | 19/27 [00:00<00:00, 130.45it/s, train_loss=0.00369, val_loss=0.00399]Epoch 20:  70%|███████   | 19/27 [00:00<00:00, 127.56it/s, train_loss=0.00375, val_loss=0.00399]Epoch 20:  74%|███████▍  | 20/27 [00:00<00:00, 129.62it/s, train_loss=0.00375, val_loss=0.00399]Epoch 20:  74%|███████▍  | 20/27 [00:00<00:00, 128.67it/s, train_loss=0.00337, val_loss=0.00399]Epoch 20:  78%|███████▊  | 21/27 [00:00<00:00, 131.10it/s, train_loss=0.00337, val_loss=0.00399]Epoch 20:  78%|███████▊  | 21/27 [00:00<00:00, 128.39it/s, train_loss=0.00373, val_loss=0.00399]Epoch 20:  81%|████████▏ | 22/27 [00:00<00:00, 130.33it/s, train_loss=0.00373, val_loss=0.00399]Epoch 20:  81%|████████▏ | 22/27 [00:00<00:00, 129.40it/s, train_loss=0.0035, val_loss=0.00399] Epoch 20:  85%|████████▌ | 23/27 [00:00<00:00, 131.46it/s, train_loss=0.0035, val_loss=0.00399]Epoch 20:  85%|████████▌ | 23/27 [00:00<00:00, 130.49it/s, train_loss=0.00321, val_loss=0.00399]Epoch 20:  89%|████████▉ | 24/27 [00:00<00:00, 132.12it/s, train_loss=0.00321, val_loss=0.00399]Epoch 20:  89%|████████▉ | 24/27 [00:00<00:00, 131.18it/s, train_loss=0.00371, val_loss=0.00399]Epoch 20:  93%|█████████▎| 25/27 [00:00<00:00, 132.89it/s, train_loss=0.00371, val_loss=0.00399]Epoch 20:  93%|█████████▎| 25/27 [00:00<00:00, 132.02it/s, train_loss=0.00332, val_loss=0.00399]Epoch 20:  96%|█████████▋| 26/27 [00:00<00:00, 134.00it/s, train_loss=0.00332, val_loss=0.00399]Epoch 20:  96%|█████████▋| 26/27 [00:00<00:00, 131.68it/s, train_loss=0.0032, val_loss=0.00399] Epoch 20: 100%|██████████| 27/27 [00:00<00:00, 133.22it/s, train_loss=0.0032, val_loss=0.00399]Epoch 20: 100%|██████████| 27/27 [00:00<00:00, 132.53it/s, train_loss=0.00343, val_loss=0.00399]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 222.63it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 253.18it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 266.88it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 275.25it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 274.80it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 276.16it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 275.50it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 273.95it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 273.26it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 272.99it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 272.65it/s][A
                                                                         [AEpoch 20: 100%|██████████| 27/27 [00:00<00:00, 108.02it/s, train_loss=0.00343, val_loss=0.00389]Epoch 20: 100%|██████████| 27/27 [00:00<00:00, 107.67it/s, train_loss=0.00343, val_loss=0.00389]Epoch 20:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00343, val_loss=0.00389]          Epoch 21:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00343, val_loss=0.00389]Epoch 21:   4%|▎         | 1/27 [00:00<00:00, 150.10it/s, train_loss=0.00343, val_loss=0.00389]Epoch 21:   4%|▎         | 1/27 [00:00<00:00, 131.43it/s, train_loss=0.0039, val_loss=0.00389] Epoch 21:   7%|▋         | 2/27 [00:00<00:00, 150.78it/s, train_loss=0.0039, val_loss=0.00389]Epoch 21:   7%|▋         | 2/27 [00:00<00:00, 137.52it/s, train_loss=0.00372, val_loss=0.00389]Epoch 21:  11%|█         | 3/27 [00:00<00:00, 153.81it/s, train_loss=0.00372, val_loss=0.00389]Epoch 21:  11%|█         | 3/27 [00:00<00:00, 142.46it/s, train_loss=0.00283, val_loss=0.00389]Epoch 21:  15%|█▍        | 4/27 [00:00<00:00, 151.12it/s, train_loss=0.00283, val_loss=0.00389]Epoch 21:  15%|█▍        | 4/27 [00:00<00:00, 144.85it/s, train_loss=0.00339, val_loss=0.00389]Epoch 21:  19%|█▊        | 5/27 [00:00<00:00, 153.63it/s, train_loss=0.00339, val_loss=0.00389]Epoch 21:  19%|█▊        | 5/27 [00:00<00:00, 138.57it/s, train_loss=0.00436, val_loss=0.00389]Epoch 21:  22%|██▏       | 6/27 [00:00<00:00, 144.25it/s, train_loss=0.00436, val_loss=0.00389]Epoch 21:  22%|██▏       | 6/27 [00:00<00:00, 140.77it/s, train_loss=0.00326, val_loss=0.00389]Epoch 21:  26%|██▌       | 7/27 [00:00<00:00, 147.47it/s, train_loss=0.00326, val_loss=0.00389]Epoch 21:  26%|██▌       | 7/27 [00:00<00:00, 137.97it/s, train_loss=0.00355, val_loss=0.00389]Epoch 21:  30%|██▉       | 8/27 [00:00<00:00, 142.15it/s, train_loss=0.00355, val_loss=0.00389]Epoch 21:  30%|██▉       | 8/27 [00:00<00:00, 139.33it/s, train_loss=0.00377, val_loss=0.00389]Epoch 21:  33%|███▎      | 9/27 [00:00<00:00, 144.18it/s, train_loss=0.00377, val_loss=0.00389]Epoch 21:  33%|███▎      | 9/27 [00:00<00:00, 137.53it/s, train_loss=0.0037, val_loss=0.00389] Epoch 21:  37%|███▋      | 10/27 [00:00<00:00, 141.02it/s, train_loss=0.0037, val_loss=0.00389]Epoch 21:  37%|███▋      | 10/27 [00:00<00:00, 138.94it/s, train_loss=0.00287, val_loss=0.00389]Epoch 21:  41%|████      | 11/27 [00:00<00:00, 142.94it/s, train_loss=0.00287, val_loss=0.00389]Epoch 21:  41%|████      | 11/27 [00:00<00:00, 137.30it/s, train_loss=0.00377, val_loss=0.00389]Epoch 21:  44%|████▍     | 12/27 [00:00<00:00, 140.78it/s, train_loss=0.00377, val_loss=0.00389]Epoch 21:  44%|████▍     | 12/27 [00:00<00:00, 138.79it/s, train_loss=0.00389, val_loss=0.00389]Epoch 21:  48%|████▊     | 13/27 [00:00<00:00, 143.06it/s, train_loss=0.00389, val_loss=0.00389]Epoch 21:  48%|████▊     | 13/27 [00:00<00:00, 140.84it/s, train_loss=0.00315, val_loss=0.00389]Epoch 21:  52%|█████▏    | 14/27 [00:00<00:00, 144.22it/s, train_loss=0.00315, val_loss=0.00389]Epoch 21:  52%|█████▏    | 14/27 [00:00<00:00, 141.33it/s, train_loss=0.00309, val_loss=0.00389]Epoch 21:  56%|█████▌    | 15/27 [00:00<00:00, 144.55it/s, train_loss=0.00309, val_loss=0.00389]Epoch 21:  56%|█████▌    | 15/27 [00:00<00:00, 142.96it/s, train_loss=0.00338, val_loss=0.00389]Epoch 21:  59%|█████▉    | 16/27 [00:00<00:00, 146.44it/s, train_loss=0.00338, val_loss=0.00389]Epoch 21:  59%|█████▉    | 16/27 [00:00<00:00, 144.53it/s, train_loss=0.00384, val_loss=0.00389]Epoch 21:  63%|██████▎   | 17/27 [00:00<00:00, 146.98it/s, train_loss=0.00384, val_loss=0.00389]Epoch 21:  63%|██████▎   | 17/27 [00:00<00:00, 144.80it/s, train_loss=0.00298, val_loss=0.00389]Epoch 21:  67%|██████▋   | 18/27 [00:00<00:00, 147.19it/s, train_loss=0.00298, val_loss=0.00389]Epoch 21:  67%|██████▋   | 18/27 [00:00<00:00, 145.83it/s, train_loss=0.00356, val_loss=0.00389]Epoch 21:  70%|███████   | 19/27 [00:00<00:00, 148.63it/s, train_loss=0.00356, val_loss=0.00389]Epoch 21:  70%|███████   | 19/27 [00:00<00:00, 147.07it/s, train_loss=0.00285, val_loss=0.00389]Epoch 21:  74%|███████▍  | 20/27 [00:00<00:00, 148.85it/s, train_loss=0.00285, val_loss=0.00389]Epoch 21:  74%|███████▍  | 20/27 [00:00<00:00, 147.13it/s, train_loss=0.00376, val_loss=0.00389]Epoch 21:  78%|███████▊  | 21/27 [00:00<00:00, 148.96it/s, train_loss=0.00376, val_loss=0.00389]Epoch 21:  78%|███████▊  | 21/27 [00:00<00:00, 147.67it/s, train_loss=0.00332, val_loss=0.00389]Epoch 21:  81%|████████▏ | 22/27 [00:00<00:00, 149.87it/s, train_loss=0.00332, val_loss=0.00389]Epoch 21:  81%|████████▏ | 22/27 [00:00<00:00, 148.58it/s, train_loss=0.00309, val_loss=0.00389]Epoch 21:  85%|████████▌ | 23/27 [00:00<00:00, 150.61it/s, train_loss=0.00309, val_loss=0.00389]Epoch 21:  85%|████████▌ | 23/27 [00:00<00:00, 148.83it/s, train_loss=0.00312, val_loss=0.00389]Epoch 21:  89%|████████▉ | 24/27 [00:00<00:00, 150.41it/s, train_loss=0.00312, val_loss=0.00389]Epoch 21:  89%|████████▉ | 24/27 [00:00<00:00, 149.21it/s, train_loss=0.00292, val_loss=0.00389]Epoch 21:  93%|█████████▎| 25/27 [00:00<00:00, 150.72it/s, train_loss=0.00292, val_loss=0.00389]Epoch 21:  93%|█████████▎| 25/27 [00:00<00:00, 147.72it/s, train_loss=0.00307, val_loss=0.00389]Epoch 21:  96%|█████████▋| 26/27 [00:00<00:00, 149.22it/s, train_loss=0.00307, val_loss=0.00389]Epoch 21:  96%|█████████▋| 26/27 [00:00<00:00, 148.25it/s, train_loss=0.00328, val_loss=0.00389]Epoch 21: 100%|██████████| 27/27 [00:00<00:00, 149.97it/s, train_loss=0.00328, val_loss=0.00389]Epoch 21: 100%|██████████| 27/27 [00:00<00:00, 147.04it/s, train_loss=0.00415, val_loss=0.00389]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 151.63it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 180.94it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 203.60it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 225.51it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 241.68it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 253.04it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 258.15it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 264.37it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 269.38it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 271.84it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 270.77it/s][A
                                                                         [AEpoch 21: 100%|██████████| 27/27 [00:00<00:00, 116.87it/s, train_loss=0.00415, val_loss=0.00381]Epoch 21: 100%|██████████| 27/27 [00:00<00:00, 116.49it/s, train_loss=0.00415, val_loss=0.00381]Epoch 21:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00415, val_loss=0.00381]          Epoch 22:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00415, val_loss=0.00381]Epoch 22:   4%|▎         | 1/27 [00:00<00:00, 152.34it/s, train_loss=0.00415, val_loss=0.00381]Epoch 22:   4%|▎         | 1/27 [00:00<00:00, 134.10it/s, train_loss=0.00371, val_loss=0.00381]Epoch 22:   7%|▋         | 2/27 [00:00<00:00, 158.86it/s, train_loss=0.00371, val_loss=0.00381]Epoch 22:   7%|▋         | 2/27 [00:00<00:00, 145.49it/s, train_loss=0.00274, val_loss=0.00381]Epoch 22:  11%|█         | 3/27 [00:00<00:00, 157.43it/s, train_loss=0.00274, val_loss=0.00381]Epoch 22:  11%|█         | 3/27 [00:00<00:00, 146.13it/s, train_loss=0.00357, val_loss=0.00381]Epoch 22:  15%|█▍        | 4/27 [00:00<00:00, 156.32it/s, train_loss=0.00357, val_loss=0.00381]Epoch 22:  15%|█▍        | 4/27 [00:00<00:00, 149.34it/s, train_loss=0.00369, val_loss=0.00381]Epoch 22:  19%|█▊        | 5/27 [00:00<00:00, 159.30it/s, train_loss=0.00369, val_loss=0.00381]Epoch 22:  19%|█▊        | 5/27 [00:00<00:00, 152.30it/s, train_loss=0.00325, val_loss=0.00381]Epoch 22:  22%|██▏       | 6/27 [00:00<00:00, 160.87it/s, train_loss=0.00325, val_loss=0.00381]Epoch 22:  22%|██▏       | 6/27 [00:00<00:00, 152.02it/s, train_loss=0.00438, val_loss=0.00381]Epoch 22:  26%|██▌       | 7/27 [00:00<00:00, 157.48it/s, train_loss=0.00438, val_loss=0.00381]Epoch 22:  26%|██▌       | 7/27 [00:00<00:00, 153.74it/s, train_loss=0.00371, val_loss=0.00381]Epoch 22:  30%|██▉       | 8/27 [00:00<00:00, 159.38it/s, train_loss=0.00371, val_loss=0.00381]Epoch 22:  30%|██▉       | 8/27 [00:00<00:00, 155.25it/s, train_loss=0.00282, val_loss=0.00381]Epoch 22:  33%|███▎      | 9/27 [00:00<00:00, 160.60it/s, train_loss=0.00282, val_loss=0.00381]Epoch 22:  33%|███▎      | 9/27 [00:00<00:00, 154.82it/s, train_loss=0.00348, val_loss=0.00381]Epoch 22:  37%|███▋      | 10/27 [00:00<00:00, 157.85it/s, train_loss=0.00348, val_loss=0.00381]Epoch 22:  37%|███▋      | 10/27 [00:00<00:00, 155.18it/s, train_loss=0.0035, val_loss=0.00381] Epoch 22:  41%|████      | 11/27 [00:00<00:00, 158.96it/s, train_loss=0.0035, val_loss=0.00381]Epoch 22:  41%|████      | 11/27 [00:00<00:00, 151.05it/s, train_loss=0.00363, val_loss=0.00381]Epoch 22:  44%|████▍     | 12/27 [00:00<00:00, 153.50it/s, train_loss=0.00363, val_loss=0.00381]Epoch 22:  44%|████▍     | 12/27 [00:00<00:00, 151.24it/s, train_loss=0.00318, val_loss=0.00381]Epoch 22:  48%|████▊     | 13/27 [00:00<00:00, 154.53it/s, train_loss=0.00318, val_loss=0.00381]Epoch 22:  48%|████▊     | 13/27 [00:00<00:00, 148.70it/s, train_loss=0.00282, val_loss=0.00381]Epoch 22:  52%|█████▏    | 14/27 [00:00<00:00, 150.90it/s, train_loss=0.00282, val_loss=0.00381]Epoch 22:  52%|█████▏    | 14/27 [00:00<00:00, 149.02it/s, train_loss=0.00378, val_loss=0.00381]Epoch 22:  56%|█████▌    | 15/27 [00:00<00:00, 152.44it/s, train_loss=0.00378, val_loss=0.00381]Epoch 22:  56%|█████▌    | 15/27 [00:00<00:00, 147.02it/s, train_loss=0.00311, val_loss=0.00381]Epoch 22:  59%|█████▉    | 16/27 [00:00<00:00, 149.34it/s, train_loss=0.00311, val_loss=0.00381]Epoch 22:  59%|█████▉    | 16/27 [00:00<00:00, 147.68it/s, train_loss=0.00266, val_loss=0.00381]Epoch 22:  63%|██████▎   | 17/27 [00:00<00:00, 150.45it/s, train_loss=0.00266, val_loss=0.00381]Epoch 22:  63%|██████▎   | 17/27 [00:00<00:00, 145.72it/s, train_loss=0.00342, val_loss=0.00381]Epoch 22:  67%|██████▋   | 18/27 [00:00<00:00, 147.68it/s, train_loss=0.00342, val_loss=0.00381]Epoch 22:  67%|██████▋   | 18/27 [00:00<00:00, 146.39it/s, train_loss=0.00345, val_loss=0.00381]Epoch 22:  70%|███████   | 19/27 [00:00<00:00, 149.04it/s, train_loss=0.00345, val_loss=0.00381]Epoch 22:  70%|███████   | 19/27 [00:00<00:00, 147.47it/s, train_loss=0.00311, val_loss=0.00381]Epoch 22:  74%|███████▍  | 20/27 [00:00<00:00, 150.17it/s, train_loss=0.00311, val_loss=0.00381]Epoch 22:  74%|███████▍  | 20/27 [00:00<00:00, 147.72it/s, train_loss=0.00361, val_loss=0.00381]Epoch 22:  78%|███████▊  | 21/27 [00:00<00:00, 149.88it/s, train_loss=0.00361, val_loss=0.00381]Epoch 22:  78%|███████▊  | 21/27 [00:00<00:00, 148.54it/s, train_loss=0.00302, val_loss=0.00381]Epoch 22:  81%|████████▏ | 22/27 [00:00<00:00, 150.78it/s, train_loss=0.00302, val_loss=0.00381]Epoch 22:  81%|████████▏ | 22/27 [00:00<00:00, 149.31it/s, train_loss=0.00356, val_loss=0.00381]Epoch 22:  85%|████████▌ | 23/27 [00:00<00:00, 151.56it/s, train_loss=0.00356, val_loss=0.00381]Epoch 22:  85%|████████▌ | 23/27 [00:00<00:00, 149.38it/s, train_loss=0.00329, val_loss=0.00381]Epoch 22:  89%|████████▉ | 24/27 [00:00<00:00, 150.98it/s, train_loss=0.00329, val_loss=0.00381]Epoch 22:  89%|████████▉ | 24/27 [00:00<00:00, 149.79it/s, train_loss=0.0031, val_loss=0.00381] Epoch 22:  93%|█████████▎| 25/27 [00:00<00:00, 151.70it/s, train_loss=0.0031, val_loss=0.00381]Epoch 22:  93%|█████████▎| 25/27 [00:00<00:00, 148.54it/s, train_loss=0.00291, val_loss=0.00381]Epoch 22:  96%|█████████▋| 26/27 [00:00<00:00, 149.65it/s, train_loss=0.00291, val_loss=0.00381]Epoch 22:  96%|█████████▋| 26/27 [00:00<00:00, 148.65it/s, train_loss=0.00382, val_loss=0.00381]Epoch 22: 100%|██████████| 27/27 [00:00<00:00, 150.15it/s, train_loss=0.00382, val_loss=0.00381]Epoch 22: 100%|██████████| 27/27 [00:00<00:00, 149.07it/s, train_loss=0.00324, val_loss=0.00381]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 161.02it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 186.07it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 200.04it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 208.01it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 212.62it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 216.50it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 218.00it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 219.17it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 218.97it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 220.56it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 226.22it/s][A
                                                                         [AEpoch 22: 100%|██████████| 27/27 [00:00<00:00, 113.99it/s, train_loss=0.00324, val_loss=0.00374]Epoch 22: 100%|██████████| 27/27 [00:00<00:00, 113.70it/s, train_loss=0.00324, val_loss=0.00374]Epoch 22:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00324, val_loss=0.00374]          Epoch 23:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00324, val_loss=0.00374]Epoch 23:   4%|▎         | 1/27 [00:00<00:00, 167.46it/s, train_loss=0.00324, val_loss=0.00374]Epoch 23:   4%|▎         | 1/27 [00:00<00:00, 126.49it/s, train_loss=0.00293, val_loss=0.00374]Epoch 23:   7%|▋         | 2/27 [00:00<00:00, 155.74it/s, train_loss=0.00293, val_loss=0.00374]Epoch 23:   7%|▋         | 2/27 [00:00<00:00, 141.55it/s, train_loss=0.00432, val_loss=0.00374]Epoch 23:  11%|█         | 3/27 [00:00<00:00, 162.04it/s, train_loss=0.00432, val_loss=0.00374]Epoch 23:  11%|█         | 3/27 [00:00<00:00, 150.87it/s, train_loss=0.00393, val_loss=0.00374]Epoch 23:  15%|█▍        | 4/27 [00:00<00:00, 159.70it/s, train_loss=0.00393, val_loss=0.00374]Epoch 23:  15%|█▍        | 4/27 [00:00<00:00, 150.22it/s, train_loss=0.00344, val_loss=0.00374]Epoch 23:  19%|█▊        | 5/27 [00:00<00:00, 158.22it/s, train_loss=0.00344, val_loss=0.00374]Epoch 23:  19%|█▊        | 5/27 [00:00<00:00, 152.84it/s, train_loss=0.00352, val_loss=0.00374]Epoch 23:  22%|██▏       | 6/27 [00:00<00:00, 161.70it/s, train_loss=0.00352, val_loss=0.00374]Epoch 23:  22%|██▏       | 6/27 [00:00<00:00, 155.74it/s, train_loss=0.00369, val_loss=0.00374]Epoch 23:  26%|██▌       | 7/27 [00:00<00:00, 160.88it/s, train_loss=0.00369, val_loss=0.00374]Epoch 23:  26%|██▌       | 7/27 [00:00<00:00, 154.60it/s, train_loss=0.00248, val_loss=0.00374]Epoch 23:  30%|██▉       | 8/27 [00:00<00:00, 159.33it/s, train_loss=0.00248, val_loss=0.00374]Epoch 23:  30%|██▉       | 8/27 [00:00<00:00, 155.93it/s, train_loss=0.00351, val_loss=0.00374]Epoch 23:  33%|███▎      | 9/27 [00:00<00:00, 161.52it/s, train_loss=0.00351, val_loss=0.00374]Epoch 23:  33%|███▎      | 9/27 [00:00<00:00, 157.63it/s, train_loss=0.00245, val_loss=0.00374]Epoch 23:  37%|███▋      | 10/27 [00:00<00:00, 160.52it/s, train_loss=0.00245, val_loss=0.00374]Epoch 23:  37%|███▋      | 10/27 [00:00<00:00, 156.70it/s, train_loss=0.00297, val_loss=0.00374]Epoch 23:  41%|████      | 11/27 [00:00<00:00, 159.67it/s, train_loss=0.00297, val_loss=0.00374]Epoch 23:  41%|████      | 11/27 [00:00<00:00, 156.93it/s, train_loss=0.00311, val_loss=0.00374]Epoch 23:  44%|████▍     | 12/27 [00:00<00:00, 160.78it/s, train_loss=0.00311, val_loss=0.00374]Epoch 23:  44%|████▍     | 12/27 [00:00<00:00, 152.99it/s, train_loss=0.00322, val_loss=0.00374]Epoch 23:  48%|████▊     | 13/27 [00:00<00:00, 155.46it/s, train_loss=0.00322, val_loss=0.00374]Epoch 23:  48%|████▊     | 13/27 [00:00<00:00, 153.10it/s, train_loss=0.00416, val_loss=0.00374]Epoch 23:  52%|█████▏    | 14/27 [00:00<00:00, 156.30it/s, train_loss=0.00416, val_loss=0.00374]Epoch 23:  52%|█████▏    | 14/27 [00:00<00:00, 150.51it/s, train_loss=0.00368, val_loss=0.00374]Epoch 23:  56%|█████▌    | 15/27 [00:00<00:00, 152.59it/s, train_loss=0.00368, val_loss=0.00374]Epoch 23:  56%|█████▌    | 15/27 [00:00<00:00, 150.85it/s, train_loss=0.00299, val_loss=0.00374]Epoch 23:  59%|█████▉    | 16/27 [00:00<00:00, 153.46it/s, train_loss=0.00299, val_loss=0.00374]Epoch 23:  59%|█████▉    | 16/27 [00:00<00:00, 148.85it/s, train_loss=0.00282, val_loss=0.00374]Epoch 23:  63%|██████▎   | 17/27 [00:00<00:00, 150.66it/s, train_loss=0.00282, val_loss=0.00374]Epoch 23:  63%|██████▎   | 17/27 [00:00<00:00, 149.22it/s, train_loss=0.00332, val_loss=0.00374]Epoch 23:  67%|██████▋   | 18/27 [00:00<00:00, 151.46it/s, train_loss=0.00332, val_loss=0.00374]Epoch 23:  67%|██████▋   | 18/27 [00:00<00:00, 147.54it/s, train_loss=0.00311, val_loss=0.00374]Epoch 23:  70%|███████   | 19/27 [00:00<00:00, 149.72it/s, train_loss=0.00311, val_loss=0.00374]Epoch 23:  70%|███████   | 19/27 [00:00<00:00, 148.35it/s, train_loss=0.00353, val_loss=0.00374]Epoch 23:  74%|███████▍  | 20/27 [00:00<00:00, 150.36it/s, train_loss=0.00353, val_loss=0.00374]Epoch 23:  74%|███████▍  | 20/27 [00:00<00:00, 148.89it/s, train_loss=0.00364, val_loss=0.00374]Epoch 23:  78%|███████▊  | 21/27 [00:00<00:00, 149.70it/s, train_loss=0.00364, val_loss=0.00374]Epoch 23:  78%|███████▊  | 21/27 [00:00<00:00, 148.56it/s, train_loss=0.00319, val_loss=0.00374]Epoch 23:  81%|████████▏ | 22/27 [00:00<00:00, 150.50it/s, train_loss=0.00319, val_loss=0.00374]Epoch 23:  81%|████████▏ | 22/27 [00:00<00:00, 149.36it/s, train_loss=0.0033, val_loss=0.00374] Epoch 23:  85%|████████▌ | 23/27 [00:00<00:00, 151.59it/s, train_loss=0.0033, val_loss=0.00374]Epoch 23:  85%|████████▌ | 23/27 [00:00<00:00, 147.75it/s, train_loss=0.00369, val_loss=0.00374]Epoch 23:  89%|████████▉ | 24/27 [00:00<00:00, 148.62it/s, train_loss=0.00369, val_loss=0.00374]Epoch 23:  89%|████████▉ | 24/27 [00:00<00:00, 147.50it/s, train_loss=0.00311, val_loss=0.00374]Epoch 23:  93%|█████████▎| 25/27 [00:00<00:00, 148.71it/s, train_loss=0.00311, val_loss=0.00374]Epoch 23:  93%|█████████▎| 25/27 [00:00<00:00, 146.87it/s, train_loss=0.00323, val_loss=0.00374]Epoch 23:  96%|█████████▋| 26/27 [00:00<00:00, 148.42it/s, train_loss=0.00323, val_loss=0.00374]Epoch 23:  96%|█████████▋| 26/27 [00:00<00:00, 147.36it/s, train_loss=0.00282, val_loss=0.00374]Epoch 23: 100%|██████████| 27/27 [00:00<00:00, 149.16it/s, train_loss=0.00282, val_loss=0.00374]Epoch 23: 100%|██████████| 27/27 [00:00<00:00, 146.40it/s, train_loss=0.00266, val_loss=0.00374]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 168.74it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 198.86it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 214.45it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 221.50it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 227.37it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 229.17it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 230.37it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 229.14it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 229.08it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 230.28it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 231.38it/s][A
                                                                         [AEpoch 23: 100%|██████████| 27/27 [00:00<00:00, 112.60it/s, train_loss=0.00266, val_loss=0.00367]Epoch 23: 100%|██████████| 27/27 [00:00<00:00, 112.03it/s, train_loss=0.00266, val_loss=0.00367]Epoch 23:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00266, val_loss=0.00367]          Epoch 24:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00266, val_loss=0.00367]Epoch 24:   4%|▎         | 1/27 [00:00<00:00, 150.76it/s, train_loss=0.00266, val_loss=0.00367]Epoch 24:   4%|▎         | 1/27 [00:00<00:00, 130.17it/s, train_loss=0.00305, val_loss=0.00367]Epoch 24:   7%|▋         | 2/27 [00:00<00:00, 151.09it/s, train_loss=0.00305, val_loss=0.00367]Epoch 24:   7%|▋         | 2/27 [00:00<00:00, 126.65it/s, train_loss=0.00292, val_loss=0.00367]Epoch 24:  11%|█         | 3/27 [00:00<00:00, 145.12it/s, train_loss=0.00292, val_loss=0.00367]Epoch 24:  11%|█         | 3/27 [00:00<00:00, 137.18it/s, train_loss=0.00319, val_loss=0.00367]Epoch 24:  15%|█▍        | 4/27 [00:00<00:00, 152.41it/s, train_loss=0.00319, val_loss=0.00367]Epoch 24:  15%|█▍        | 4/27 [00:00<00:00, 145.13it/s, train_loss=0.00362, val_loss=0.00367]Epoch 24:  19%|█▊        | 5/27 [00:00<00:00, 153.14it/s, train_loss=0.00362, val_loss=0.00367]Epoch 24:  19%|█▊        | 5/27 [00:00<00:00, 144.81it/s, train_loss=0.00318, val_loss=0.00367]Epoch 24:  22%|██▏       | 6/27 [00:00<00:00, 152.00it/s, train_loss=0.00318, val_loss=0.00367]Epoch 24:  22%|██▏       | 6/27 [00:00<00:00, 147.49it/s, train_loss=0.00335, val_loss=0.00367]Epoch 24:  26%|██▌       | 7/27 [00:00<00:00, 155.31it/s, train_loss=0.00335, val_loss=0.00367]Epoch 24:  26%|██▌       | 7/27 [00:00<00:00, 150.75it/s, train_loss=0.00326, val_loss=0.00367]Epoch 24:  30%|██▉       | 8/27 [00:00<00:00, 155.43it/s, train_loss=0.00326, val_loss=0.00367]Epoch 24:  30%|██▉       | 8/27 [00:00<00:00, 150.36it/s, train_loss=0.00364, val_loss=0.00367]Epoch 24:  33%|███▎      | 9/27 [00:00<00:00, 154.88it/s, train_loss=0.00364, val_loss=0.00367]Epoch 24:  33%|███▎      | 9/27 [00:00<00:00, 151.87it/s, train_loss=0.00341, val_loss=0.00367]Epoch 24:  37%|███▋      | 10/27 [00:00<00:00, 157.09it/s, train_loss=0.00341, val_loss=0.00367]Epoch 24:  37%|███▋      | 10/27 [00:00<00:00, 153.69it/s, train_loss=0.00392, val_loss=0.00367]Epoch 24:  41%|████      | 11/27 [00:00<00:00, 156.69it/s, train_loss=0.00392, val_loss=0.00367]Epoch 24:  41%|████      | 11/27 [00:00<00:00, 153.25it/s, train_loss=0.0026, val_loss=0.00367] Epoch 24:  44%|████▍     | 12/27 [00:00<00:00, 156.46it/s, train_loss=0.0026, val_loss=0.00367]Epoch 24:  44%|████▍     | 12/27 [00:00<00:00, 154.16it/s, train_loss=0.00378, val_loss=0.00367]Epoch 24:  48%|████▊     | 13/27 [00:00<00:00, 158.02it/s, train_loss=0.00378, val_loss=0.00367]Epoch 24:  48%|████▊     | 13/27 [00:00<00:00, 155.30it/s, train_loss=0.00348, val_loss=0.00367]Epoch 24:  52%|█████▏    | 14/27 [00:00<00:00, 157.48it/s, train_loss=0.00348, val_loss=0.00367]Epoch 24:  52%|█████▏    | 14/27 [00:00<00:00, 154.71it/s, train_loss=0.00389, val_loss=0.00367]Epoch 24:  56%|█████▌    | 15/27 [00:00<00:00, 156.61it/s, train_loss=0.00389, val_loss=0.00367]Epoch 24:  56%|█████▌    | 15/27 [00:00<00:00, 154.70it/s, train_loss=0.00239, val_loss=0.00367]Epoch 24:  59%|█████▉    | 16/27 [00:00<00:00, 157.14it/s, train_loss=0.00239, val_loss=0.00367]Epoch 24:  59%|█████▉    | 16/27 [00:00<00:00, 152.27it/s, train_loss=0.00298, val_loss=0.00367]Epoch 24:  63%|██████▎   | 17/27 [00:00<00:00, 154.08it/s, train_loss=0.00298, val_loss=0.00367]Epoch 24:  63%|██████▎   | 17/27 [00:00<00:00, 152.34it/s, train_loss=0.00363, val_loss=0.00367]Epoch 24:  67%|██████▋   | 18/27 [00:00<00:00, 154.79it/s, train_loss=0.00363, val_loss=0.00367]Epoch 24:  67%|██████▋   | 18/27 [00:00<00:00, 150.41it/s, train_loss=0.00321, val_loss=0.00367]Epoch 24:  70%|███████   | 19/27 [00:00<00:00, 152.20it/s, train_loss=0.00321, val_loss=0.00367]Epoch 24:  70%|███████   | 19/27 [00:00<00:00, 150.60it/s, train_loss=0.00313, val_loss=0.00367]Epoch 24:  74%|███████▍  | 20/27 [00:00<00:00, 152.67it/s, train_loss=0.00313, val_loss=0.00367]Epoch 24:  74%|███████▍  | 20/27 [00:00<00:00, 148.92it/s, train_loss=0.0036, val_loss=0.00367] Epoch 24:  78%|███████▊  | 21/27 [00:00<00:00, 150.35it/s, train_loss=0.0036, val_loss=0.00367]Epoch 24:  78%|███████▊  | 21/27 [00:00<00:00, 149.09it/s, train_loss=0.00345, val_loss=0.00367]Epoch 24:  81%|████████▏ | 22/27 [00:00<00:00, 151.52it/s, train_loss=0.00345, val_loss=0.00367]Epoch 24:  81%|████████▏ | 22/27 [00:00<00:00, 147.63it/s, train_loss=0.00299, val_loss=0.00367]Epoch 24:  85%|████████▌ | 23/27 [00:00<00:00, 149.39it/s, train_loss=0.00299, val_loss=0.00367]Epoch 24:  85%|████████▌ | 23/27 [00:00<00:00, 148.25it/s, train_loss=0.0023, val_loss=0.00367] Epoch 24:  89%|████████▉ | 24/27 [00:00<00:00, 150.41it/s, train_loss=0.0023, val_loss=0.00367]Epoch 24:  89%|████████▉ | 24/27 [00:00<00:00, 149.05it/s, train_loss=0.00379, val_loss=0.00367]Epoch 24:  93%|█████████▎| 25/27 [00:00<00:00, 151.23it/s, train_loss=0.00379, val_loss=0.00367]Epoch 24:  93%|█████████▎| 25/27 [00:00<00:00, 149.17it/s, train_loss=0.0028, val_loss=0.00367] Epoch 24:  96%|█████████▋| 26/27 [00:00<00:00, 150.73it/s, train_loss=0.0028, val_loss=0.00367]Epoch 24:  96%|█████████▋| 26/27 [00:00<00:00, 149.68it/s, train_loss=0.00294, val_loss=0.00367]Epoch 24: 100%|██████████| 27/27 [00:00<00:00, 151.52it/s, train_loss=0.00294, val_loss=0.00367]Epoch 24: 100%|██████████| 27/27 [00:00<00:00, 150.44it/s, train_loss=0.00297, val_loss=0.00367]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 196.68it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 229.55it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 241.29it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 250.48it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 256.25it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 259.54it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 262.01it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 263.58it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 263.49it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 263.48it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 264.23it/s][A
                                                                         [AEpoch 24: 100%|██████████| 27/27 [00:00<00:00, 117.88it/s, train_loss=0.00297, val_loss=0.00362]Epoch 24: 100%|██████████| 27/27 [00:00<00:00, 117.39it/s, train_loss=0.00297, val_loss=0.00362]Epoch 24:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00362]          Epoch 25:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00362]Epoch 25:   4%|▎         | 1/27 [00:00<00:00, 152.38it/s, train_loss=0.00297, val_loss=0.00362]Epoch 25:   4%|▎         | 1/27 [00:00<00:00, 130.95it/s, train_loss=0.00341, val_loss=0.00362]Epoch 25:   7%|▋         | 2/27 [00:00<00:00, 159.22it/s, train_loss=0.00341, val_loss=0.00362]Epoch 25:   7%|▋         | 2/27 [00:00<00:00, 123.54it/s, train_loss=0.00264, val_loss=0.00362]Epoch 25:  11%|█         | 3/27 [00:00<00:00, 138.24it/s, train_loss=0.00264, val_loss=0.00362]Epoch 25:  11%|█         | 3/27 [00:00<00:00, 130.73it/s, train_loss=0.0031, val_loss=0.00362] Epoch 25:  15%|█▍        | 4/27 [00:00<00:00, 140.50it/s, train_loss=0.0031, val_loss=0.00362]Epoch 25:  15%|█▍        | 4/27 [00:00<00:00, 129.27it/s, train_loss=0.00255, val_loss=0.00362]Epoch 25:  19%|█▊        | 5/27 [00:00<00:00, 137.40it/s, train_loss=0.00255, val_loss=0.00362]Epoch 25:  19%|█▊        | 5/27 [00:00<00:00, 133.24it/s, train_loss=0.00333, val_loss=0.00362]Epoch 25:  22%|██▏       | 6/27 [00:00<00:00, 143.21it/s, train_loss=0.00333, val_loss=0.00362]Epoch 25:  22%|██▏       | 6/27 [00:00<00:00, 131.01it/s, train_loss=0.00261, val_loss=0.00362]Epoch 25:  26%|██▌       | 7/27 [00:00<00:00, 137.56it/s, train_loss=0.00261, val_loss=0.00362]Epoch 25:  26%|██▌       | 7/27 [00:00<00:00, 134.59it/s, train_loss=0.00355, val_loss=0.00362]Epoch 25:  30%|██▉       | 8/27 [00:00<00:00, 141.48it/s, train_loss=0.00355, val_loss=0.00362]Epoch 25:  30%|██▉       | 8/27 [00:00<00:00, 138.19it/s, train_loss=0.00312, val_loss=0.00362]Epoch 25:  33%|███▎      | 9/27 [00:00<00:00, 144.72it/s, train_loss=0.00312, val_loss=0.00362]Epoch 25:  33%|███▎      | 9/27 [00:00<00:00, 139.50it/s, train_loss=0.00306, val_loss=0.00362]Epoch 25:  37%|███▋      | 10/27 [00:00<00:00, 144.27it/s, train_loss=0.00306, val_loss=0.00362]Epoch 25:  37%|███▋      | 10/27 [00:00<00:00, 141.88it/s, train_loss=0.00326, val_loss=0.00362]Epoch 25:  41%|████      | 11/27 [00:00<00:00, 146.51it/s, train_loss=0.00326, val_loss=0.00362]Epoch 25:  41%|████      | 11/27 [00:00<00:00, 143.84it/s, train_loss=0.00323, val_loss=0.00362]Epoch 25:  44%|████▍     | 12/27 [00:00<00:00, 148.23it/s, train_loss=0.00323, val_loss=0.00362]Epoch 25:  44%|████▍     | 12/27 [00:00<00:00, 144.43it/s, train_loss=0.00305, val_loss=0.00362]Epoch 25:  48%|████▊     | 13/27 [00:00<00:00, 147.44it/s, train_loss=0.00305, val_loss=0.00362]Epoch 25:  48%|████▊     | 13/27 [00:00<00:00, 145.37it/s, train_loss=0.00417, val_loss=0.00362]Epoch 25:  52%|█████▏    | 14/27 [00:00<00:00, 148.56it/s, train_loss=0.00417, val_loss=0.00362]Epoch 25:  52%|█████▏    | 14/27 [00:00<00:00, 143.17it/s, train_loss=0.00271, val_loss=0.00362]Epoch 25:  56%|█████▌    | 15/27 [00:00<00:00, 143.59it/s, train_loss=0.00271, val_loss=0.00362]Epoch 25:  56%|█████▌    | 15/27 [00:00<00:00, 141.81it/s, train_loss=0.00282, val_loss=0.00362]Epoch 25:  59%|█████▉    | 16/27 [00:00<00:00, 144.70it/s, train_loss=0.00282, val_loss=0.00362]Epoch 25:  59%|█████▉    | 16/27 [00:00<00:00, 140.02it/s, train_loss=0.00343, val_loss=0.00362]Epoch 25:  63%|██████▎   | 17/27 [00:00<00:00, 142.22it/s, train_loss=0.00343, val_loss=0.00362]Epoch 25:  63%|██████▎   | 17/27 [00:00<00:00, 140.65it/s, train_loss=0.00276, val_loss=0.00362]Epoch 25:  67%|██████▋   | 18/27 [00:00<00:00, 142.43it/s, train_loss=0.00276, val_loss=0.00362]Epoch 25:  67%|██████▋   | 18/27 [00:00<00:00, 139.19it/s, train_loss=0.00365, val_loss=0.00362]Epoch 25:  70%|███████   | 19/27 [00:00<00:00, 141.55it/s, train_loss=0.00365, val_loss=0.00362]Epoch 25:  70%|███████   | 19/27 [00:00<00:00, 140.04it/s, train_loss=0.0029, val_loss=0.00362] Epoch 25:  74%|███████▍  | 20/27 [00:00<00:00, 142.65it/s, train_loss=0.0029, val_loss=0.00362]Epoch 25:  74%|███████▍  | 20/27 [00:00<00:00, 138.88it/s, train_loss=0.00306, val_loss=0.00362]Epoch 25:  78%|███████▊  | 21/27 [00:00<00:00, 140.56it/s, train_loss=0.00306, val_loss=0.00362]Epoch 25:  78%|███████▊  | 21/27 [00:00<00:00, 139.30it/s, train_loss=0.00362, val_loss=0.00362]Epoch 25:  81%|████████▏ | 22/27 [00:00<00:00, 141.41it/s, train_loss=0.00362, val_loss=0.00362]Epoch 25:  81%|████████▏ | 22/27 [00:00<00:00, 138.43it/s, train_loss=0.00399, val_loss=0.00362]Epoch 25:  85%|████████▌ | 23/27 [00:00<00:00, 140.23it/s, train_loss=0.00399, val_loss=0.00362]Epoch 25:  85%|████████▌ | 23/27 [00:00<00:00, 139.02it/s, train_loss=0.00456, val_loss=0.00362]Epoch 25:  89%|████████▉ | 24/27 [00:00<00:00, 140.92it/s, train_loss=0.00456, val_loss=0.00362]Epoch 25:  89%|████████▉ | 24/27 [00:00<00:00, 138.00it/s, train_loss=0.00274, val_loss=0.00362]Epoch 25:  93%|█████████▎| 25/27 [00:00<00:00, 140.03it/s, train_loss=0.00274, val_loss=0.00362]Epoch 25:  93%|█████████▎| 25/27 [00:00<00:00, 138.95it/s, train_loss=0.00307, val_loss=0.00362]Epoch 25:  96%|█████████▋| 26/27 [00:00<00:00, 141.10it/s, train_loss=0.00307, val_loss=0.00362]Epoch 25:  96%|█████████▋| 26/27 [00:00<00:00, 139.93it/s, train_loss=0.00269, val_loss=0.00362]Epoch 25: 100%|██████████| 27/27 [00:00<00:00, 141.91it/s, train_loss=0.00269, val_loss=0.00362]Epoch 25: 100%|██████████| 27/27 [00:00<00:00, 140.21it/s, train_loss=0.00297, val_loss=0.00362]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 205.00it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 234.35it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 244.52it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 244.59it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 248.25it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 251.37it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 252.29it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 253.59it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 254.57it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 254.57it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 255.57it/s][A
                                                                         [AEpoch 25: 100%|██████████| 27/27 [00:00<00:00, 111.45it/s, train_loss=0.00297, val_loss=0.00357]Epoch 25: 100%|██████████| 27/27 [00:00<00:00, 111.06it/s, train_loss=0.00297, val_loss=0.00357]Epoch 25:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00357]          Epoch 26:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00297, val_loss=0.00357]Epoch 26:   4%|▎         | 1/27 [00:00<00:00, 167.06it/s, train_loss=0.00297, val_loss=0.00357]Epoch 26:   4%|▎         | 1/27 [00:00<00:00, 136.06it/s, train_loss=0.00349, val_loss=0.00357]Epoch 26:   7%|▋         | 2/27 [00:00<00:00, 163.26it/s, train_loss=0.00349, val_loss=0.00357]Epoch 26:   7%|▋         | 2/27 [00:00<00:00, 135.66it/s, train_loss=0.00286, val_loss=0.00357]Epoch 26:  11%|█         | 3/27 [00:00<00:00, 152.85it/s, train_loss=0.00286, val_loss=0.00357]Epoch 26:  11%|█         | 3/27 [00:00<00:00, 142.20it/s, train_loss=0.00258, val_loss=0.00357]Epoch 26:  15%|█▍        | 4/27 [00:00<00:00, 155.93it/s, train_loss=0.00258, val_loss=0.00357]Epoch 26:  15%|█▍        | 4/27 [00:00<00:00, 135.12it/s, train_loss=0.00379, val_loss=0.00357]Epoch 26:  19%|█▊        | 5/27 [00:00<00:00, 142.16it/s, train_loss=0.00379, val_loss=0.00357]Epoch 26:  19%|█▊        | 5/27 [00:00<00:00, 136.92it/s, train_loss=0.00354, val_loss=0.00357]Epoch 26:  22%|██▏       | 6/27 [00:00<00:00, 144.03it/s, train_loss=0.00354, val_loss=0.00357]Epoch 26:  22%|██▏       | 6/27 [00:00<00:00, 133.72it/s, train_loss=0.00324, val_loss=0.00357]Epoch 26:  26%|██▌       | 7/27 [00:00<00:00, 139.10it/s, train_loss=0.00324, val_loss=0.00357]Epoch 26:  26%|██▌       | 7/27 [00:00<00:00, 135.53it/s, train_loss=0.00262, val_loss=0.00357]Epoch 26:  30%|██▉       | 8/27 [00:00<00:00, 141.55it/s, train_loss=0.00262, val_loss=0.00357]Epoch 26:  30%|██▉       | 8/27 [00:00<00:00, 133.14it/s, train_loss=0.00345, val_loss=0.00357]Epoch 26:  33%|███▎      | 9/27 [00:00<00:00, 137.96it/s, train_loss=0.00345, val_loss=0.00357]Epoch 26:  33%|███▎      | 9/27 [00:00<00:00, 134.92it/s, train_loss=0.00266, val_loss=0.00357]Epoch 26:  37%|███▋      | 10/27 [00:00<00:00, 140.58it/s, train_loss=0.00266, val_loss=0.00357]Epoch 26:  37%|███▋      | 10/27 [00:00<00:00, 133.61it/s, train_loss=0.00308, val_loss=0.00357]Epoch 26:  41%|████      | 11/27 [00:00<00:00, 137.91it/s, train_loss=0.00308, val_loss=0.00357]Epoch 26:  41%|████      | 11/27 [00:00<00:00, 135.43it/s, train_loss=0.00327, val_loss=0.00357]Epoch 26:  44%|████▍     | 12/27 [00:00<00:00, 140.24it/s, train_loss=0.00327, val_loss=0.00357]Epoch 26:  44%|████▍     | 12/27 [00:00<00:00, 137.85it/s, train_loss=0.00328, val_loss=0.00357]Epoch 26:  48%|████▊     | 13/27 [00:00<00:00, 142.44it/s, train_loss=0.00328, val_loss=0.00357]Epoch 26:  48%|████▊     | 13/27 [00:00<00:00, 136.53it/s, train_loss=0.00346, val_loss=0.00357]Epoch 26:  52%|█████▏    | 14/27 [00:00<00:00, 140.04it/s, train_loss=0.00346, val_loss=0.00357]Epoch 26:  52%|█████▏    | 14/27 [00:00<00:00, 138.28it/s, train_loss=0.00249, val_loss=0.00357]Epoch 26:  56%|█████▌    | 15/27 [00:00<00:00, 141.81it/s, train_loss=0.00249, val_loss=0.00357]Epoch 26:  56%|█████▌    | 15/27 [00:00<00:00, 139.84it/s, train_loss=0.00312, val_loss=0.00357]Epoch 26:  59%|█████▉    | 16/27 [00:00<00:00, 143.32it/s, train_loss=0.00312, val_loss=0.00357]Epoch 26:  59%|█████▉    | 16/27 [00:00<00:00, 140.58it/s, train_loss=0.00325, val_loss=0.00357]Epoch 26:  63%|██████▎   | 17/27 [00:00<00:00, 143.38it/s, train_loss=0.00325, val_loss=0.00357]Epoch 26:  63%|██████▎   | 17/27 [00:00<00:00, 141.75it/s, train_loss=0.0032, val_loss=0.00357] Epoch 26:  67%|██████▋   | 18/27 [00:00<00:00, 144.56it/s, train_loss=0.0032, val_loss=0.00357]Epoch 26:  67%|██████▋   | 18/27 [00:00<00:00, 142.91it/s, train_loss=0.0032, val_loss=0.00357]Epoch 26:  70%|███████   | 19/27 [00:00<00:00, 145.68it/s, train_loss=0.0032, val_loss=0.00357]Epoch 26:  70%|███████   | 19/27 [00:00<00:00, 143.25it/s, train_loss=0.00322, val_loss=0.00357]Epoch 26:  74%|███████▍  | 20/27 [00:00<00:00, 145.51it/s, train_loss=0.00322, val_loss=0.00357]Epoch 26:  74%|███████▍  | 20/27 [00:00<00:00, 144.10it/s, train_loss=0.00301, val_loss=0.00357]Epoch 26:  78%|███████▊  | 21/27 [00:00<00:00, 146.51it/s, train_loss=0.00301, val_loss=0.00357]Epoch 26:  78%|███████▊  | 21/27 [00:00<00:00, 145.08it/s, train_loss=0.0032, val_loss=0.00357] Epoch 26:  81%|████████▏ | 22/27 [00:00<00:00, 147.07it/s, train_loss=0.0032, val_loss=0.00357]Epoch 26:  81%|████████▏ | 22/27 [00:00<00:00, 145.20it/s, train_loss=0.00277, val_loss=0.00357]Epoch 26:  85%|████████▌ | 23/27 [00:00<00:00, 147.14it/s, train_loss=0.00277, val_loss=0.00357]Epoch 26:  85%|████████▌ | 23/27 [00:00<00:00, 145.80it/s, train_loss=0.00351, val_loss=0.00357]Epoch 26:  89%|████████▉ | 24/27 [00:00<00:00, 148.08it/s, train_loss=0.00351, val_loss=0.00357]Epoch 26:  89%|████████▉ | 24/27 [00:00<00:00, 146.66it/s, train_loss=0.00336, val_loss=0.00357]Epoch 26:  93%|█████████▎| 25/27 [00:00<00:00, 148.55it/s, train_loss=0.00336, val_loss=0.00357]Epoch 26:  93%|█████████▎| 25/27 [00:00<00:00, 146.68it/s, train_loss=0.00341, val_loss=0.00357]Epoch 26:  96%|█████████▋| 26/27 [00:00<00:00, 148.38it/s, train_loss=0.00341, val_loss=0.00357]Epoch 26:  96%|█████████▋| 26/27 [00:00<00:00, 147.15it/s, train_loss=0.00289, val_loss=0.00357]Epoch 26: 100%|██████████| 27/27 [00:00<00:00, 149.02it/s, train_loss=0.00289, val_loss=0.00357]Epoch 26: 100%|██████████| 27/27 [00:00<00:00, 146.18it/s, train_loss=0.00295, val_loss=0.00357]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 235.19it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 269.77it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 274.65it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 283.18it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 286.47it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 289.64it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 287.27it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 286.22it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 285.71it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 283.97it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 285.02it/s][A
                                                                         [AEpoch 26: 100%|██████████| 27/27 [00:00<00:00, 117.69it/s, train_loss=0.00295, val_loss=0.00352]Epoch 26: 100%|██████████| 27/27 [00:00<00:00, 117.29it/s, train_loss=0.00295, val_loss=0.00352]Epoch 26:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00295, val_loss=0.00352]          Epoch 27:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00295, val_loss=0.00352]Epoch 27:   4%|▎         | 1/27 [00:00<00:00, 175.69it/s, train_loss=0.00295, val_loss=0.00352]Epoch 27:   4%|▎         | 1/27 [00:00<00:00, 139.42it/s, train_loss=0.00299, val_loss=0.00352]Epoch 27:   7%|▋         | 2/27 [00:00<00:00, 170.70it/s, train_loss=0.00299, val_loss=0.00352]Epoch 27:   7%|▋         | 2/27 [00:00<00:00, 151.39it/s, train_loss=0.00325, val_loss=0.00352]Epoch 27:  11%|█         | 3/27 [00:00<00:00, 167.62it/s, train_loss=0.00325, val_loss=0.00352]Epoch 27:  11%|█         | 3/27 [00:00<00:00, 150.35it/s, train_loss=0.00305, val_loss=0.00352]Epoch 27:  15%|█▍        | 4/27 [00:00<00:00, 162.00it/s, train_loss=0.00305, val_loss=0.00352]Epoch 27:  15%|█▍        | 4/27 [00:00<00:00, 153.52it/s, train_loss=0.00352, val_loss=0.00352]Epoch 27:  19%|█▊        | 5/27 [00:00<00:00, 163.88it/s, train_loss=0.00352, val_loss=0.00352]Epoch 27:  19%|█▊        | 5/27 [00:00<00:00, 156.74it/s, train_loss=0.00294, val_loss=0.00352]Epoch 27:  22%|██▏       | 6/27 [00:00<00:00, 162.70it/s, train_loss=0.00294, val_loss=0.00352]Epoch 27:  22%|██▏       | 6/27 [00:00<00:00, 155.07it/s, train_loss=0.0029, val_loss=0.00352] Epoch 27:  26%|██▌       | 7/27 [00:00<00:00, 160.79it/s, train_loss=0.0029, val_loss=0.00352]Epoch 27:  26%|██▌       | 7/27 [00:00<00:00, 155.89it/s, train_loss=0.00311, val_loss=0.00352]Epoch 27:  30%|██▉       | 8/27 [00:00<00:00, 161.71it/s, train_loss=0.00311, val_loss=0.00352]Epoch 27:  30%|██▉       | 8/27 [00:00<00:00, 157.33it/s, train_loss=0.00348, val_loss=0.00352]Epoch 27:  33%|███▎      | 9/27 [00:00<00:00, 160.89it/s, train_loss=0.00348, val_loss=0.00352]Epoch 27:  33%|███▎      | 9/27 [00:00<00:00, 156.12it/s, train_loss=0.00333, val_loss=0.00352]Epoch 27:  37%|███▋      | 10/27 [00:00<00:00, 160.53it/s, train_loss=0.00333, val_loss=0.00352]Epoch 27:  37%|███▋      | 10/27 [00:00<00:00, 157.21it/s, train_loss=0.00278, val_loss=0.00352]Epoch 27:  41%|████      | 11/27 [00:00<00:00, 161.63it/s, train_loss=0.00278, val_loss=0.00352]Epoch 27:  41%|████      | 11/27 [00:00<00:00, 157.98it/s, train_loss=0.00299, val_loss=0.00352]Epoch 27:  44%|████▍     | 12/27 [00:00<00:00, 160.86it/s, train_loss=0.00299, val_loss=0.00352]Epoch 27:  44%|████▍     | 12/27 [00:00<00:00, 157.13it/s, train_loss=0.00298, val_loss=0.00352]Epoch 27:  48%|████▊     | 13/27 [00:00<00:00, 160.83it/s, train_loss=0.00298, val_loss=0.00352]Epoch 27:  48%|████▊     | 13/27 [00:00<00:00, 158.28it/s, train_loss=0.00289, val_loss=0.00352]Epoch 27:  52%|█████▏    | 14/27 [00:00<00:00, 162.54it/s, train_loss=0.00289, val_loss=0.00352]Epoch 27:  52%|█████▏    | 14/27 [00:00<00:00, 159.54it/s, train_loss=0.00298, val_loss=0.00352]Epoch 27:  56%|█████▌    | 15/27 [00:00<00:00, 162.69it/s, train_loss=0.00298, val_loss=0.00352]Epoch 27:  56%|█████▌    | 15/27 [00:00<00:00, 157.94it/s, train_loss=0.00281, val_loss=0.00352]Epoch 27:  59%|█████▉    | 16/27 [00:00<00:00, 160.41it/s, train_loss=0.00281, val_loss=0.00352]Epoch 27:  59%|█████▉    | 16/27 [00:00<00:00, 158.58it/s, train_loss=0.00305, val_loss=0.00352]Epoch 27:  63%|██████▎   | 17/27 [00:00<00:00, 161.86it/s, train_loss=0.00305, val_loss=0.00352]Epoch 27:  63%|██████▎   | 17/27 [00:00<00:00, 159.41it/s, train_loss=0.00305, val_loss=0.00352]Epoch 27:  67%|██████▋   | 18/27 [00:00<00:00, 161.53it/s, train_loss=0.00305, val_loss=0.00352]Epoch 27:  67%|██████▋   | 18/27 [00:00<00:00, 158.75it/s, train_loss=0.00321, val_loss=0.00352]Epoch 27:  70%|███████   | 19/27 [00:00<00:00, 160.96it/s, train_loss=0.00321, val_loss=0.00352]Epoch 27:  70%|███████   | 19/27 [00:00<00:00, 159.13it/s, train_loss=0.00359, val_loss=0.00352]Epoch 27:  74%|███████▍  | 20/27 [00:00<00:00, 161.76it/s, train_loss=0.00359, val_loss=0.00352]Epoch 27:  74%|███████▍  | 20/27 [00:00<00:00, 159.74it/s, train_loss=0.00256, val_loss=0.00352]Epoch 27:  78%|███████▊  | 21/27 [00:00<00:00, 161.44it/s, train_loss=0.00256, val_loss=0.00352]Epoch 27:  78%|███████▊  | 21/27 [00:00<00:00, 159.11it/s, train_loss=0.00369, val_loss=0.00352]Epoch 27:  81%|████████▏ | 22/27 [00:00<00:00, 160.86it/s, train_loss=0.00369, val_loss=0.00352]Epoch 27:  81%|████████▏ | 22/27 [00:00<00:00, 159.28it/s, train_loss=0.00335, val_loss=0.00352]Epoch 27:  85%|████████▌ | 23/27 [00:00<00:00, 161.53it/s, train_loss=0.00335, val_loss=0.00352]Epoch 27:  85%|████████▌ | 23/27 [00:00<00:00, 157.10it/s, train_loss=0.00347, val_loss=0.00352]Epoch 27:  89%|████████▉ | 24/27 [00:00<00:00, 158.36it/s, train_loss=0.00347, val_loss=0.00352]Epoch 27:  89%|████████▉ | 24/27 [00:00<00:00, 157.05it/s, train_loss=0.00334, val_loss=0.00352]Epoch 27:  93%|█████████▎| 25/27 [00:00<00:00, 158.49it/s, train_loss=0.00334, val_loss=0.00352]Epoch 27:  93%|█████████▎| 25/27 [00:00<00:00, 155.38it/s, train_loss=0.00303, val_loss=0.00352]Epoch 27:  96%|█████████▋| 26/27 [00:00<00:00, 156.91it/s, train_loss=0.00303, val_loss=0.00352]Epoch 27:  96%|█████████▋| 26/27 [00:00<00:00, 155.61it/s, train_loss=0.00277, val_loss=0.00352]Epoch 27: 100%|██████████| 27/27 [00:00<00:00, 155.55it/s, train_loss=0.00277, val_loss=0.00352]Epoch 27: 100%|██████████| 27/27 [00:00<00:00, 154.22it/s, train_loss=0.00279, val_loss=0.00352]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 150.71it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 173.25it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 185.15it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 195.22it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 199.30it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 205.90it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 217.01it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 221.04it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 229.00it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 235.38it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 241.91it/s][A
                                                                         [AEpoch 27: 100%|██████████| 27/27 [00:00<00:00, 118.47it/s, train_loss=0.00279, val_loss=0.0035] Epoch 27: 100%|██████████| 27/27 [00:00<00:00, 118.05it/s, train_loss=0.00279, val_loss=0.0035]Epoch 27:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00279, val_loss=0.0035]          Epoch 28:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00279, val_loss=0.0035]Epoch 28:   4%|▎         | 1/27 [00:00<00:00, 164.08it/s, train_loss=0.00279, val_loss=0.0035]Epoch 28:   4%|▎         | 1/27 [00:00<00:00, 137.89it/s, train_loss=0.00295, val_loss=0.0035]Epoch 28:   7%|▋         | 2/27 [00:00<00:00, 165.39it/s, train_loss=0.00295, val_loss=0.0035]Epoch 28:   7%|▋         | 2/27 [00:00<00:00, 150.45it/s, train_loss=0.00326, val_loss=0.0035]Epoch 28:  11%|█         | 3/27 [00:00<00:00, 170.20it/s, train_loss=0.00326, val_loss=0.0035]Epoch 28:  11%|█         | 3/27 [00:00<00:00, 157.13it/s, train_loss=0.00252, val_loss=0.0035]Epoch 28:  15%|█▍        | 4/27 [00:00<00:00, 165.97it/s, train_loss=0.00252, val_loss=0.0035]Epoch 28:  15%|█▍        | 4/27 [00:00<00:00, 154.69it/s, train_loss=0.00324, val_loss=0.0035]Epoch 28:  19%|█▊        | 5/27 [00:00<00:00, 162.12it/s, train_loss=0.00324, val_loss=0.0035]Epoch 28:  19%|█▊        | 5/27 [00:00<00:00, 155.51it/s, train_loss=0.00337, val_loss=0.0035]Epoch 28:  22%|██▏       | 6/27 [00:00<00:00, 164.22it/s, train_loss=0.00337, val_loss=0.0035]Epoch 28:  22%|██▏       | 6/27 [00:00<00:00, 149.30it/s, train_loss=0.00352, val_loss=0.0035]Epoch 28:  26%|██▌       | 7/27 [00:00<00:00, 153.98it/s, train_loss=0.00352, val_loss=0.0035]Epoch 28:  26%|██▌       | 7/27 [00:00<00:00, 150.07it/s, train_loss=0.00339, val_loss=0.0035]Epoch 28:  30%|██▉       | 8/27 [00:00<00:00, 156.63it/s, train_loss=0.00339, val_loss=0.0035]Epoch 28:  30%|██▉       | 8/27 [00:00<00:00, 146.22it/s, train_loss=0.00308, val_loss=0.0035]Epoch 28:  33%|███▎      | 9/27 [00:00<00:00, 150.84it/s, train_loss=0.00308, val_loss=0.0035]Epoch 28:  33%|███▎      | 9/27 [00:00<00:00, 147.87it/s, train_loss=0.00344, val_loss=0.0035]Epoch 28:  37%|███▋      | 10/27 [00:00<00:00, 153.00it/s, train_loss=0.00344, val_loss=0.0035]Epoch 28:  37%|███▋      | 10/27 [00:00<00:00, 144.60it/s, train_loss=0.00326, val_loss=0.0035]Epoch 28:  41%|████      | 11/27 [00:00<00:00, 147.68it/s, train_loss=0.00326, val_loss=0.0035]Epoch 28:  41%|████      | 11/27 [00:00<00:00, 145.27it/s, train_loss=0.00294, val_loss=0.0035]Epoch 28:  44%|████▍     | 12/27 [00:00<00:00, 149.30it/s, train_loss=0.00294, val_loss=0.0035]Epoch 28:  44%|████▍     | 12/27 [00:00<00:00, 142.54it/s, train_loss=0.0033, val_loss=0.0035] Epoch 28:  48%|████▊     | 13/27 [00:00<00:00, 145.07it/s, train_loss=0.0033, val_loss=0.0035]Epoch 28:  48%|████▊     | 13/27 [00:00<00:00, 143.21it/s, train_loss=0.00358, val_loss=0.0035]Epoch 28:  52%|█████▏    | 14/27 [00:00<00:00, 146.77it/s, train_loss=0.00358, val_loss=0.0035]Epoch 28:  52%|█████▏    | 14/27 [00:00<00:00, 141.64it/s, train_loss=0.00302, val_loss=0.0035]Epoch 28:  56%|█████▌    | 15/27 [00:00<00:00, 144.19it/s, train_loss=0.00302, val_loss=0.0035]Epoch 28:  56%|█████▌    | 15/27 [00:00<00:00, 142.41it/s, train_loss=0.00274, val_loss=0.0035]Epoch 28:  59%|█████▉    | 16/27 [00:00<00:00, 145.37it/s, train_loss=0.00274, val_loss=0.0035]Epoch 28:  59%|█████▉    | 16/27 [00:00<00:00, 141.06it/s, train_loss=0.00278, val_loss=0.0035]Epoch 28:  63%|██████▎   | 17/27 [00:00<00:00, 143.68it/s, train_loss=0.00278, val_loss=0.0035]Epoch 28:  63%|██████▎   | 17/27 [00:00<00:00, 142.24it/s, train_loss=0.00318, val_loss=0.0035]Epoch 28:  67%|██████▋   | 18/27 [00:00<00:00, 145.33it/s, train_loss=0.00318, val_loss=0.0035]Epoch 28:  67%|██████▋   | 18/27 [00:00<00:00, 143.76it/s, train_loss=0.00372, val_loss=0.0035]Epoch 28:  70%|███████   | 19/27 [00:00<00:00, 146.19it/s, train_loss=0.00372, val_loss=0.0035]Epoch 28:  70%|███████   | 19/27 [00:00<00:00, 143.82it/s, train_loss=0.00318, val_loss=0.0035]Epoch 28:  74%|███████▍  | 20/27 [00:00<00:00, 146.23it/s, train_loss=0.00318, val_loss=0.0035]Epoch 28:  74%|███████▍  | 20/27 [00:00<00:00, 144.87it/s, train_loss=0.00282, val_loss=0.0035]Epoch 28:  78%|███████▊  | 21/27 [00:00<00:00, 147.59it/s, train_loss=0.00282, val_loss=0.0035]Epoch 28:  78%|███████▊  | 21/27 [00:00<00:00, 146.00it/s, train_loss=0.00311, val_loss=0.0035]Epoch 28:  81%|████████▏ | 22/27 [00:00<00:00, 147.53it/s, train_loss=0.00311, val_loss=0.0035]Epoch 28:  81%|████████▏ | 22/27 [00:00<00:00, 145.92it/s, train_loss=0.0032, val_loss=0.0035] Epoch 28:  85%|████████▌ | 23/27 [00:00<00:00, 147.75it/s, train_loss=0.0032, val_loss=0.0035]Epoch 28:  85%|████████▌ | 23/27 [00:00<00:00, 146.61it/s, train_loss=0.00247, val_loss=0.0035]Epoch 28:  89%|████████▉ | 24/27 [00:00<00:00, 148.53it/s, train_loss=0.00247, val_loss=0.0035]Epoch 28:  89%|████████▉ | 24/27 [00:00<00:00, 147.19it/s, train_loss=0.0029, val_loss=0.0035] Epoch 28:  93%|█████████▎| 25/27 [00:00<00:00, 148.67it/s, train_loss=0.0029, val_loss=0.0035]Epoch 28:  93%|█████████▎| 25/27 [00:00<00:00, 147.29it/s, train_loss=0.00229, val_loss=0.0035]Epoch 28:  96%|█████████▋| 26/27 [00:00<00:00, 148.98it/s, train_loss=0.00229, val_loss=0.0035]Epoch 28:  96%|█████████▋| 26/27 [00:00<00:00, 147.91it/s, train_loss=0.00274, val_loss=0.0035]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 149.87it/s, train_loss=0.00274, val_loss=0.0035]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 148.64it/s, train_loss=0.00307, val_loss=0.0035]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 165.97it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 195.41it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 210.82it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 218.44it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 223.12it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 226.44it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 227.81it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 229.78it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 230.62it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 231.47it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 232.29it/s][A
                                                                         [AEpoch 28: 100%|██████████| 27/27 [00:00<00:00, 113.74it/s, train_loss=0.00307, val_loss=0.00346]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 113.24it/s, train_loss=0.00307, val_loss=0.00346]Epoch 28:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00307, val_loss=0.00346]          Epoch 29:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00307, val_loss=0.00346]Epoch 29:   4%|▎         | 1/27 [00:00<00:00, 174.48it/s, train_loss=0.00307, val_loss=0.00346]Epoch 29:   4%|▎         | 1/27 [00:00<00:00, 144.86it/s, train_loss=0.00246, val_loss=0.00346]Epoch 29:   7%|▋         | 2/27 [00:00<00:00, 174.00it/s, train_loss=0.00246, val_loss=0.00346]Epoch 29:   7%|▋         | 2/27 [00:00<00:00, 155.51it/s, train_loss=0.00348, val_loss=0.00346]Epoch 29:  11%|█         | 3/27 [00:00<00:00, 170.52it/s, train_loss=0.00348, val_loss=0.00346]Epoch 29:  11%|█         | 3/27 [00:00<00:00, 152.96it/s, train_loss=0.00271, val_loss=0.00346]Epoch 29:  15%|█▍        | 4/27 [00:00<00:00, 163.96it/s, train_loss=0.00271, val_loss=0.00346]Epoch 29:  15%|█▍        | 4/27 [00:00<00:00, 156.40it/s, train_loss=0.00277, val_loss=0.00346]Epoch 29:  19%|█▊        | 5/27 [00:00<00:00, 167.64it/s, train_loss=0.00277, val_loss=0.00346]Epoch 29:  19%|█▊        | 5/27 [00:00<00:00, 159.39it/s, train_loss=0.00321, val_loss=0.00346]Epoch 29:  22%|██▏       | 6/27 [00:00<00:00, 165.17it/s, train_loss=0.00321, val_loss=0.00346]Epoch 29:  22%|██▏       | 6/27 [00:00<00:00, 157.24it/s, train_loss=0.00295, val_loss=0.00346]Epoch 29:  26%|██▌       | 7/27 [00:00<00:00, 163.22it/s, train_loss=0.00295, val_loss=0.00346]Epoch 29:  26%|██▌       | 7/27 [00:00<00:00, 158.54it/s, train_loss=0.0033, val_loss=0.00346] Epoch 29:  30%|██▉       | 8/27 [00:00<00:00, 165.33it/s, train_loss=0.0033, val_loss=0.00346]Epoch 29:  30%|██▉       | 8/27 [00:00<00:00, 160.13it/s, train_loss=0.00334, val_loss=0.00346]Epoch 29:  33%|███▎      | 9/27 [00:00<00:00, 163.96it/s, train_loss=0.00334, val_loss=0.00346]Epoch 29:  33%|███▎      | 9/27 [00:00<00:00, 158.62it/s, train_loss=0.0029, val_loss=0.00346] Epoch 29:  37%|███▋      | 10/27 [00:00<00:00, 162.71it/s, train_loss=0.0029, val_loss=0.00346]Epoch 29:  37%|███▋      | 10/27 [00:00<00:00, 159.43it/s, train_loss=0.00336, val_loss=0.00346]Epoch 29:  41%|████      | 11/27 [00:00<00:00, 164.09it/s, train_loss=0.00336, val_loss=0.00346]Epoch 29:  41%|████      | 11/27 [00:00<00:00, 160.42it/s, train_loss=0.00317, val_loss=0.00346]Epoch 29:  44%|████▍     | 12/27 [00:00<00:00, 162.95it/s, train_loss=0.00317, val_loss=0.00346]Epoch 29:  44%|████▍     | 12/27 [00:00<00:00, 159.35it/s, train_loss=0.00327, val_loss=0.00346]Epoch 29:  48%|████▊     | 13/27 [00:00<00:00, 162.30it/s, train_loss=0.00327, val_loss=0.00346]Epoch 29:  48%|████▊     | 13/27 [00:00<00:00, 159.88it/s, train_loss=0.00282, val_loss=0.00346]Epoch 29:  52%|█████▏    | 14/27 [00:00<00:00, 163.45it/s, train_loss=0.00282, val_loss=0.00346]Epoch 29:  52%|█████▏    | 14/27 [00:00<00:00, 160.61it/s, train_loss=0.00323, val_loss=0.00346]Epoch 29:  56%|█████▌    | 15/27 [00:00<00:00, 162.47it/s, train_loss=0.00323, val_loss=0.00346]Epoch 29:  56%|█████▌    | 15/27 [00:00<00:00, 159.77it/s, train_loss=0.00242, val_loss=0.00346]Epoch 29:  59%|█████▉    | 16/27 [00:00<00:00, 161.74it/s, train_loss=0.00242, val_loss=0.00346]Epoch 29:  59%|█████▉    | 16/27 [00:00<00:00, 159.87it/s, train_loss=0.00328, val_loss=0.00346]Epoch 29:  63%|██████▎   | 17/27 [00:00<00:00, 162.60it/s, train_loss=0.00328, val_loss=0.00346]Epoch 29:  63%|██████▎   | 17/27 [00:00<00:00, 157.09it/s, train_loss=0.00294, val_loss=0.00346]Epoch 29:  67%|██████▋   | 18/27 [00:00<00:00, 158.59it/s, train_loss=0.00294, val_loss=0.00346]Epoch 29:  67%|██████▋   | 18/27 [00:00<00:00, 156.96it/s, train_loss=0.00278, val_loss=0.00346]Epoch 29:  70%|███████   | 19/27 [00:00<00:00, 159.17it/s, train_loss=0.00278, val_loss=0.00346]Epoch 29:  70%|███████   | 19/27 [00:00<00:00, 154.77it/s, train_loss=0.00346, val_loss=0.00346]Epoch 29:  74%|███████▍  | 20/27 [00:00<00:00, 156.87it/s, train_loss=0.00346, val_loss=0.00346]Epoch 29:  74%|███████▍  | 20/27 [00:00<00:00, 155.26it/s, train_loss=0.00238, val_loss=0.00346]Epoch 29:  78%|███████▊  | 21/27 [00:00<00:00, 157.68it/s, train_loss=0.00238, val_loss=0.00346]Epoch 29:  78%|███████▊  | 21/27 [00:00<00:00, 156.19it/s, train_loss=0.0037, val_loss=0.00346] Epoch 29:  81%|████████▏ | 22/27 [00:00<00:00, 157.92it/s, train_loss=0.0037, val_loss=0.00346]Epoch 29:  81%|████████▏ | 22/27 [00:00<00:00, 155.64it/s, train_loss=0.00268, val_loss=0.00346]Epoch 29:  85%|████████▌ | 23/27 [00:00<00:00, 157.45it/s, train_loss=0.00268, val_loss=0.00346]Epoch 29:  85%|████████▌ | 23/27 [00:00<00:00, 156.10it/s, train_loss=0.00337, val_loss=0.00346]Epoch 29:  89%|████████▉ | 24/27 [00:00<00:00, 158.36it/s, train_loss=0.00337, val_loss=0.00346]Epoch 29:  89%|████████▉ | 24/27 [00:00<00:00, 156.84it/s, train_loss=0.00276, val_loss=0.00346]Epoch 29:  93%|█████████▎| 25/27 [00:00<00:00, 158.42it/s, train_loss=0.00276, val_loss=0.00346]Epoch 29:  93%|█████████▎| 25/27 [00:00<00:00, 156.49it/s, train_loss=0.00327, val_loss=0.00346]Epoch 29:  96%|█████████▋| 26/27 [00:00<00:00, 158.15it/s, train_loss=0.00327, val_loss=0.00346]Epoch 29:  96%|█████████▋| 26/27 [00:00<00:00, 156.91it/s, train_loss=0.00326, val_loss=0.00346]Epoch 29: 100%|██████████| 27/27 [00:00<00:00, 158.82it/s, train_loss=0.00326, val_loss=0.00346]Epoch 29: 100%|██████████| 27/27 [00:00<00:00, 157.41it/s, train_loss=0.00304, val_loss=0.00346]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 184.62it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 210.75it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 224.78it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 232.38it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 236.45it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 239.88it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 241.77it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 242.74it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 240.56it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 236.63it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 236.83it/s][A
                                                                         [AEpoch 29: 100%|██████████| 27/27 [00:00<00:00, 118.72it/s, train_loss=0.00304, val_loss=0.00344]Epoch 29: 100%|██████████| 27/27 [00:00<00:00, 118.22it/s, train_loss=0.00304, val_loss=0.00344]Epoch 29:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00304, val_loss=0.00344]          Epoch 30:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00304, val_loss=0.00344]Epoch 30:   4%|▎         | 1/27 [00:00<00:00, 148.74it/s, train_loss=0.00304, val_loss=0.00344]Epoch 30:   4%|▎         | 1/27 [00:00<00:00, 129.29it/s, train_loss=0.00345, val_loss=0.00344]Epoch 30:   7%|▋         | 2/27 [00:00<00:00, 148.42it/s, train_loss=0.00345, val_loss=0.00344]Epoch 30:   7%|▋         | 2/27 [00:00<00:00, 135.34it/s, train_loss=0.00286, val_loss=0.00344]Epoch 30:  11%|█         | 3/27 [00:00<00:00, 149.34it/s, train_loss=0.00286, val_loss=0.00344]Epoch 30:  11%|█         | 3/27 [00:00<00:00, 136.94it/s, train_loss=0.00308, val_loss=0.00344]Epoch 30:  15%|█▍        | 4/27 [00:00<00:00, 150.52it/s, train_loss=0.00308, val_loss=0.00344]Epoch 30:  15%|█▍        | 4/27 [00:00<00:00, 144.06it/s, train_loss=0.00265, val_loss=0.00344]Epoch 30:  19%|█▊        | 5/27 [00:00<00:00, 155.65it/s, train_loss=0.00265, val_loss=0.00344]Epoch 30:  19%|█▊        | 5/27 [00:00<00:00, 148.83it/s, train_loss=0.00305, val_loss=0.00344]Epoch 30:  22%|██▏       | 6/27 [00:00<00:00, 155.80it/s, train_loss=0.00305, val_loss=0.00344]Epoch 30:  22%|██▏       | 6/27 [00:00<00:00, 148.76it/s, train_loss=0.00285, val_loss=0.00344]Epoch 30:  26%|██▌       | 7/27 [00:00<00:00, 155.38it/s, train_loss=0.00285, val_loss=0.00344]Epoch 30:  26%|██▌       | 7/27 [00:00<00:00, 151.28it/s, train_loss=0.00273, val_loss=0.00344]Epoch 30:  30%|██▉       | 8/27 [00:00<00:00, 158.17it/s, train_loss=0.00273, val_loss=0.00344]Epoch 30:  30%|██▉       | 8/27 [00:00<00:00, 153.81it/s, train_loss=0.00288, val_loss=0.00344]Epoch 30:  33%|███▎      | 9/27 [00:00<00:00, 157.16it/s, train_loss=0.00288, val_loss=0.00344]Epoch 30:  33%|███▎      | 9/27 [00:00<00:00, 153.23it/s, train_loss=0.00288, val_loss=0.00344]Epoch 30:  37%|███▋      | 10/27 [00:00<00:00, 157.38it/s, train_loss=0.00288, val_loss=0.00344]Epoch 30:  37%|███▋      | 10/27 [00:00<00:00, 154.53it/s, train_loss=0.00323, val_loss=0.00344]Epoch 30:  41%|████      | 11/27 [00:00<00:00, 159.33it/s, train_loss=0.00323, val_loss=0.00344]Epoch 30:  41%|████      | 11/27 [00:00<00:00, 156.12it/s, train_loss=0.00303, val_loss=0.00344]Epoch 30:  44%|████▍     | 12/27 [00:00<00:00, 159.00it/s, train_loss=0.00303, val_loss=0.00344]Epoch 30:  44%|████▍     | 12/27 [00:00<00:00, 155.41it/s, train_loss=0.00272, val_loss=0.00344]Epoch 30:  48%|████▊     | 13/27 [00:00<00:00, 158.59it/s, train_loss=0.00272, val_loss=0.00344]Epoch 30:  48%|████▊     | 13/27 [00:00<00:00, 156.19it/s, train_loss=0.00328, val_loss=0.00344]Epoch 30:  52%|█████▏    | 14/27 [00:00<00:00, 159.93it/s, train_loss=0.00328, val_loss=0.00344]Epoch 30:  52%|█████▏    | 14/27 [00:00<00:00, 157.24it/s, train_loss=0.00291, val_loss=0.00344]Epoch 30:  56%|█████▌    | 15/27 [00:00<00:00, 159.32it/s, train_loss=0.00291, val_loss=0.00344]Epoch 30:  56%|█████▌    | 15/27 [00:00<00:00, 156.63it/s, train_loss=0.0033, val_loss=0.00344] Epoch 30:  59%|█████▉    | 16/27 [00:00<00:00, 158.38it/s, train_loss=0.0033, val_loss=0.00344]Epoch 30:  59%|█████▉    | 16/27 [00:00<00:00, 156.52it/s, train_loss=0.00244, val_loss=0.00344]Epoch 30:  63%|██████▎   | 17/27 [00:00<00:00, 159.49it/s, train_loss=0.00244, val_loss=0.00344]Epoch 30:  63%|██████▎   | 17/27 [00:00<00:00, 154.20it/s, train_loss=0.00354, val_loss=0.00344]Epoch 30:  67%|██████▋   | 18/27 [00:00<00:00, 155.86it/s, train_loss=0.00354, val_loss=0.00344]Epoch 30:  67%|██████▋   | 18/27 [00:00<00:00, 154.34it/s, train_loss=0.00272, val_loss=0.00344]Epoch 30:  70%|███████   | 19/27 [00:00<00:00, 156.55it/s, train_loss=0.00272, val_loss=0.00344]Epoch 30:  70%|███████   | 19/27 [00:00<00:00, 152.30it/s, train_loss=0.00348, val_loss=0.00344]Epoch 30:  74%|███████▍  | 20/27 [00:00<00:00, 153.94it/s, train_loss=0.00348, val_loss=0.00344]Epoch 30:  74%|███████▍  | 20/27 [00:00<00:00, 152.44it/s, train_loss=0.00321, val_loss=0.00344]Epoch 30:  78%|███████▊  | 21/27 [00:00<00:00, 154.47it/s, train_loss=0.00321, val_loss=0.00344]Epoch 30:  78%|███████▊  | 21/27 [00:00<00:00, 150.79it/s, train_loss=0.00272, val_loss=0.00344]Epoch 30:  81%|████████▏ | 22/27 [00:00<00:00, 152.20it/s, train_loss=0.00272, val_loss=0.00344]Epoch 30:  81%|████████▏ | 22/27 [00:00<00:00, 150.98it/s, train_loss=0.00347, val_loss=0.00344]Epoch 30:  85%|████████▌ | 23/27 [00:00<00:00, 152.76it/s, train_loss=0.00347, val_loss=0.00344]Epoch 30:  85%|████████▌ | 23/27 [00:00<00:00, 149.56it/s, train_loss=0.00324, val_loss=0.00344]Epoch 30:  89%|████████▉ | 24/27 [00:00<00:00, 151.13it/s, train_loss=0.00324, val_loss=0.00344]Epoch 30:  89%|████████▉ | 24/27 [00:00<00:00, 150.01it/s, train_loss=0.00307, val_loss=0.00344]Epoch 30:  93%|█████████▎| 25/27 [00:00<00:00, 152.03it/s, train_loss=0.00307, val_loss=0.00344]Epoch 30:  93%|█████████▎| 25/27 [00:00<00:00, 150.79it/s, train_loss=0.00309, val_loss=0.00344]Epoch 30:  96%|█████████▋| 26/27 [00:00<00:00, 153.02it/s, train_loss=0.00309, val_loss=0.00344]Epoch 30:  96%|█████████▋| 26/27 [00:00<00:00, 150.80it/s, train_loss=0.00276, val_loss=0.00344]Epoch 30: 100%|██████████| 27/27 [00:00<00:00, 152.08it/s, train_loss=0.00276, val_loss=0.00344]Epoch 30: 100%|██████████| 27/27 [00:00<00:00, 151.11it/s, train_loss=0.00314, val_loss=0.00344]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 185.56it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 216.05it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 225.08it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 233.78it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 239.86it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 240.82it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 243.83it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 246.53it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 247.24it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 248.40it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 250.41it/s][A
                                                                         [AEpoch 30: 100%|██████████| 27/27 [00:00<00:00, 117.55it/s, train_loss=0.00314, val_loss=0.00342]Epoch 30: 100%|██████████| 27/27 [00:00<00:00, 117.10it/s, train_loss=0.00314, val_loss=0.00342]Epoch 30:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00314, val_loss=0.00342]          Epoch 31:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00314, val_loss=0.00342]Epoch 31:   4%|▎         | 1/27 [00:00<00:00, 152.33it/s, train_loss=0.00314, val_loss=0.00342]Epoch 31:   4%|▎         | 1/27 [00:00<00:00, 130.83it/s, train_loss=0.00243, val_loss=0.00342]Epoch 31:   7%|▋         | 2/27 [00:00<00:00, 158.71it/s, train_loss=0.00243, val_loss=0.00342]Epoch 31:   7%|▋         | 2/27 [00:00<00:00, 145.26it/s, train_loss=0.00277, val_loss=0.00342]Epoch 31:  11%|█         | 3/27 [00:00<00:00, 155.36it/s, train_loss=0.00277, val_loss=0.00342]Epoch 31:  11%|█         | 3/27 [00:00<00:00, 146.85it/s, train_loss=0.00242, val_loss=0.00342]Epoch 31:  15%|█▍        | 4/27 [00:00<00:00, 156.38it/s, train_loss=0.00242, val_loss=0.00342]Epoch 31:  15%|█▍        | 4/27 [00:00<00:00, 148.84it/s, train_loss=0.00305, val_loss=0.00342]Epoch 31:  19%|█▊        | 5/27 [00:00<00:00, 158.06it/s, train_loss=0.00305, val_loss=0.00342]Epoch 31:  19%|█▊        | 5/27 [00:00<00:00, 142.85it/s, train_loss=0.00313, val_loss=0.00342]Epoch 31:  22%|██▏       | 6/27 [00:00<00:00, 147.92it/s, train_loss=0.00313, val_loss=0.00342]Epoch 31:  22%|██▏       | 6/27 [00:00<00:00, 143.70it/s, train_loss=0.00362, val_loss=0.00342]Epoch 31:  26%|██▌       | 7/27 [00:00<00:00, 148.28it/s, train_loss=0.00362, val_loss=0.00342]Epoch 31:  26%|██▌       | 7/27 [00:00<00:00, 140.59it/s, train_loss=0.0031, val_loss=0.00342] Epoch 31:  30%|██▉       | 8/27 [00:00<00:00, 146.52it/s, train_loss=0.0031, val_loss=0.00342]Epoch 31:  30%|██▉       | 8/27 [00:00<00:00, 143.16it/s, train_loss=0.00315, val_loss=0.00342]Epoch 31:  33%|███▎      | 9/27 [00:00<00:00, 149.76it/s, train_loss=0.00315, val_loss=0.00342]Epoch 31:  33%|███▎      | 9/27 [00:00<00:00, 146.12it/s, train_loss=0.00292, val_loss=0.00342]Epoch 31:  37%|███▋      | 10/27 [00:00<00:00, 150.77it/s, train_loss=0.00292, val_loss=0.00342]Epoch 31:  37%|███▋      | 10/27 [00:00<00:00, 146.04it/s, train_loss=0.00294, val_loss=0.00342]Epoch 31:  41%|████      | 11/27 [00:00<00:00, 150.43it/s, train_loss=0.00294, val_loss=0.00342]Epoch 31:  41%|████      | 11/27 [00:00<00:00, 147.95it/s, train_loss=0.0029, val_loss=0.00342] Epoch 31:  44%|████▍     | 12/27 [00:00<00:00, 152.72it/s, train_loss=0.0029, val_loss=0.00342]Epoch 31:  44%|████▍     | 12/27 [00:00<00:00, 149.96it/s, train_loss=0.00283, val_loss=0.00342]Epoch 31:  48%|████▊     | 13/27 [00:00<00:00, 153.26it/s, train_loss=0.00283, val_loss=0.00342]Epoch 31:  48%|████▊     | 13/27 [00:00<00:00, 149.72it/s, train_loss=0.00314, val_loss=0.00342]Epoch 31:  52%|█████▏    | 14/27 [00:00<00:00, 152.95it/s, train_loss=0.00314, val_loss=0.00342]Epoch 31:  52%|█████▏    | 14/27 [00:00<00:00, 150.82it/s, train_loss=0.00325, val_loss=0.00342]Epoch 31:  56%|█████▌    | 15/27 [00:00<00:00, 154.46it/s, train_loss=0.00325, val_loss=0.00342]Epoch 31:  56%|█████▌    | 15/27 [00:00<00:00, 152.09it/s, train_loss=0.00324, val_loss=0.00342]Epoch 31:  59%|█████▉    | 16/27 [00:00<00:00, 154.57it/s, train_loss=0.00324, val_loss=0.00342]Epoch 31:  59%|█████▉    | 16/27 [00:00<00:00, 151.84it/s, train_loss=0.00269, val_loss=0.00342]Epoch 31:  63%|██████▎   | 17/27 [00:00<00:00, 154.55it/s, train_loss=0.00269, val_loss=0.00342]Epoch 31:  63%|██████▎   | 17/27 [00:00<00:00, 152.75it/s, train_loss=0.00293, val_loss=0.00342]Epoch 31:  67%|██████▋   | 18/27 [00:00<00:00, 155.79it/s, train_loss=0.00293, val_loss=0.00342]Epoch 31:  67%|██████▋   | 18/27 [00:00<00:00, 153.67it/s, train_loss=0.00357, val_loss=0.00342]Epoch 31:  70%|███████   | 19/27 [00:00<00:00, 155.69it/s, train_loss=0.00357, val_loss=0.00342]Epoch 31:  70%|███████   | 19/27 [00:00<00:00, 153.40it/s, train_loss=0.00282, val_loss=0.00342]Epoch 31:  74%|███████▍  | 20/27 [00:00<00:00, 155.55it/s, train_loss=0.00282, val_loss=0.00342]Epoch 31:  74%|███████▍  | 20/27 [00:00<00:00, 154.00it/s, train_loss=0.00252, val_loss=0.00342]Epoch 31:  78%|███████▊  | 21/27 [00:00<00:00, 155.87it/s, train_loss=0.00252, val_loss=0.00342]Epoch 31:  78%|███████▊  | 21/27 [00:00<00:00, 154.33it/s, train_loss=0.0031, val_loss=0.00342] Epoch 31:  81%|████████▏ | 22/27 [00:00<00:00, 155.47it/s, train_loss=0.0031, val_loss=0.00342]Epoch 31:  81%|████████▏ | 22/27 [00:00<00:00, 154.02it/s, train_loss=0.00406, val_loss=0.00342]Epoch 31:  85%|████████▌ | 23/27 [00:00<00:00, 155.59it/s, train_loss=0.00406, val_loss=0.00342]Epoch 31:  85%|████████▌ | 23/27 [00:00<00:00, 154.34it/s, train_loss=0.0028, val_loss=0.00342] Epoch 31:  89%|████████▉ | 24/27 [00:00<00:00, 156.39it/s, train_loss=0.0028, val_loss=0.00342]Epoch 31:  89%|████████▉ | 24/27 [00:00<00:00, 152.47it/s, train_loss=0.00316, val_loss=0.00342]Epoch 31:  93%|█████████▎| 25/27 [00:00<00:00, 153.90it/s, train_loss=0.00316, val_loss=0.00342]Epoch 31:  93%|█████████▎| 25/27 [00:00<00:00, 152.75it/s, train_loss=0.00312, val_loss=0.00342]Epoch 31:  96%|█████████▋| 26/27 [00:00<00:00, 154.37it/s, train_loss=0.00312, val_loss=0.00342]Epoch 31:  96%|█████████▋| 26/27 [00:00<00:00, 151.40it/s, train_loss=0.00287, val_loss=0.00342]Epoch 31: 100%|██████████| 27/27 [00:00<00:00, 152.65it/s, train_loss=0.00287, val_loss=0.00342]Epoch 31: 100%|██████████| 27/27 [00:00<00:00, 151.70it/s, train_loss=0.00272, val_loss=0.00342]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 194.34it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 233.68it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 249.73it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 252.67it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 257.22it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 255.24it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 258.88it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 261.68it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 263.75it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 264.09it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 261.54it/s][A
                                                                         [AEpoch 31: 100%|██████████| 27/27 [00:00<00:00, 117.34it/s, train_loss=0.00272, val_loss=0.00339]Epoch 31: 100%|██████████| 27/27 [00:00<00:00, 116.93it/s, train_loss=0.00272, val_loss=0.00339]Epoch 31:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00272, val_loss=0.00339]          Epoch 32:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00272, val_loss=0.00339]Epoch 32:   4%|▎         | 1/27 [00:00<00:00, 163.46it/s, train_loss=0.00272, val_loss=0.00339]Epoch 32:   4%|▎         | 1/27 [00:00<00:00, 123.67it/s, train_loss=0.00309, val_loss=0.00339]Epoch 32:   7%|▋         | 2/27 [00:00<00:00, 153.70it/s, train_loss=0.00309, val_loss=0.00339]Epoch 32:   7%|▋         | 2/27 [00:00<00:00, 141.38it/s, train_loss=0.0033, val_loss=0.00339] Epoch 32:  11%|█         | 3/27 [00:00<00:00, 157.05it/s, train_loss=0.0033, val_loss=0.00339]Epoch 32:  11%|█         | 3/27 [00:00<00:00, 131.68it/s, train_loss=0.00338, val_loss=0.00339]Epoch 32:  15%|█▍        | 4/27 [00:00<00:00, 143.05it/s, train_loss=0.00338, val_loss=0.00339]Epoch 32:  15%|█▍        | 4/27 [00:00<00:00, 137.47it/s, train_loss=0.0025, val_loss=0.00339] Epoch 32:  19%|█▊        | 5/27 [00:00<00:00, 147.81it/s, train_loss=0.0025, val_loss=0.00339]Epoch 32:  19%|█▊        | 5/27 [00:00<00:00, 134.17it/s, train_loss=0.00321, val_loss=0.00339]Epoch 32:  22%|██▏       | 6/27 [00:00<00:00, 140.17it/s, train_loss=0.00321, val_loss=0.00339]Epoch 32:  22%|██▏       | 6/27 [00:00<00:00, 136.54it/s, train_loss=0.00273, val_loss=0.00339]Epoch 32:  26%|██▌       | 7/27 [00:00<00:00, 143.33it/s, train_loss=0.00273, val_loss=0.00339]Epoch 32:  26%|██▌       | 7/27 [00:00<00:00, 139.56it/s, train_loss=0.00282, val_loss=0.00339]Epoch 32:  30%|██▉       | 8/27 [00:00<00:00, 145.30it/s, train_loss=0.00282, val_loss=0.00339]Epoch 32:  30%|██▉       | 8/27 [00:00<00:00, 138.78it/s, train_loss=0.00277, val_loss=0.00339]Epoch 32:  33%|███▎      | 9/27 [00:00<00:00, 143.18it/s, train_loss=0.00277, val_loss=0.00339]Epoch 32:  33%|███▎      | 9/27 [00:00<00:00, 140.63it/s, train_loss=0.0026, val_loss=0.00339] Epoch 32:  37%|███▋      | 10/27 [00:00<00:00, 145.86it/s, train_loss=0.0026, val_loss=0.00339]Epoch 32:  37%|███▋      | 10/27 [00:00<00:00, 138.61it/s, train_loss=0.00349, val_loss=0.00339]Epoch 32:  41%|████      | 11/27 [00:00<00:00, 142.00it/s, train_loss=0.00349, val_loss=0.00339]Epoch 32:  41%|████      | 11/27 [00:00<00:00, 139.85it/s, train_loss=0.00326, val_loss=0.00339]Epoch 32:  44%|████▍     | 12/27 [00:00<00:00, 144.51it/s, train_loss=0.00326, val_loss=0.00339]Epoch 32:  44%|████▍     | 12/27 [00:00<00:00, 138.37it/s, train_loss=0.00314, val_loss=0.00339]Epoch 32:  48%|████▊     | 13/27 [00:00<00:00, 141.76it/s, train_loss=0.00314, val_loss=0.00339]Epoch 32:  48%|████▊     | 13/27 [00:00<00:00, 139.93it/s, train_loss=0.0027, val_loss=0.00339] Epoch 32:  52%|█████▏    | 14/27 [00:00<00:00, 143.73it/s, train_loss=0.0027, val_loss=0.00339]Epoch 32:  52%|█████▏    | 14/27 [00:00<00:00, 141.68it/s, train_loss=0.00346, val_loss=0.00339]Epoch 32:  56%|█████▌    | 15/27 [00:00<00:00, 145.27it/s, train_loss=0.00346, val_loss=0.00339]Epoch 32:  56%|█████▌    | 15/27 [00:00<00:00, 142.30it/s, train_loss=0.00279, val_loss=0.00339]Epoch 32:  59%|█████▉    | 16/27 [00:00<00:00, 144.91it/s, train_loss=0.00279, val_loss=0.00339]Epoch 32:  59%|█████▉    | 16/27 [00:00<00:00, 143.30it/s, train_loss=0.00293, val_loss=0.00339]Epoch 32:  63%|██████▎   | 17/27 [00:00<00:00, 146.47it/s, train_loss=0.00293, val_loss=0.00339]Epoch 32:  63%|██████▎   | 17/27 [00:00<00:00, 144.62it/s, train_loss=0.00333, val_loss=0.00339]Epoch 32:  67%|██████▋   | 18/27 [00:00<00:00, 147.72it/s, train_loss=0.00333, val_loss=0.00339]Epoch 32:  67%|██████▋   | 18/27 [00:00<00:00, 144.99it/s, train_loss=0.00318, val_loss=0.00339]Epoch 32:  70%|███████   | 19/27 [00:00<00:00, 147.35it/s, train_loss=0.00318, val_loss=0.00339]Epoch 32:  70%|███████   | 19/27 [00:00<00:00, 146.00it/s, train_loss=0.00312, val_loss=0.00339]Epoch 32:  74%|███████▍  | 20/27 [00:00<00:00, 148.58it/s, train_loss=0.00312, val_loss=0.00339]Epoch 32:  74%|███████▍  | 20/27 [00:00<00:00, 147.17it/s, train_loss=0.00302, val_loss=0.00339]Epoch 32:  78%|███████▊  | 21/27 [00:00<00:00, 149.17it/s, train_loss=0.00302, val_loss=0.00339]Epoch 32:  78%|███████▊  | 21/27 [00:00<00:00, 147.21it/s, train_loss=0.00309, val_loss=0.00339]Epoch 32:  81%|████████▏ | 22/27 [00:00<00:00, 149.19it/s, train_loss=0.00309, val_loss=0.00339]Epoch 32:  81%|████████▏ | 22/27 [00:00<00:00, 147.95it/s, train_loss=0.00293, val_loss=0.00339]Epoch 32:  85%|████████▌ | 23/27 [00:00<00:00, 150.34it/s, train_loss=0.00293, val_loss=0.00339]Epoch 32:  85%|████████▌ | 23/27 [00:00<00:00, 148.84it/s, train_loss=0.00271, val_loss=0.00339]Epoch 32:  89%|████████▉ | 24/27 [00:00<00:00, 150.57it/s, train_loss=0.00271, val_loss=0.00339]Epoch 32:  89%|████████▉ | 24/27 [00:00<00:00, 148.83it/s, train_loss=0.00267, val_loss=0.00339]Epoch 32:  93%|█████████▎| 25/27 [00:00<00:00, 150.60it/s, train_loss=0.00267, val_loss=0.00339]Epoch 32:  93%|█████████▎| 25/27 [00:00<00:00, 149.47it/s, train_loss=0.00288, val_loss=0.00339]Epoch 32:  96%|█████████▋| 26/27 [00:00<00:00, 151.56it/s, train_loss=0.00288, val_loss=0.00339]Epoch 32:  96%|█████████▋| 26/27 [00:00<00:00, 150.19it/s, train_loss=0.00284, val_loss=0.00339]Epoch 32: 100%|██████████| 27/27 [00:00<00:00, 152.08it/s, train_loss=0.00284, val_loss=0.00339]Epoch 32: 100%|██████████| 27/27 [00:00<00:00, 150.24it/s, train_loss=0.00285, val_loss=0.00339]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 150.71it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 199.01it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 230.33it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 248.71it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 261.93it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 270.63it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 275.72it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 279.11it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 282.38it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 284.44it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 287.51it/s][A
                                                                         [AEpoch 32: 100%|██████████| 27/27 [00:00<00:00, 119.91it/s, train_loss=0.00285, val_loss=0.00338]Epoch 32: 100%|██████████| 27/27 [00:00<00:00, 119.51it/s, train_loss=0.00285, val_loss=0.00338]Epoch 32:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00285, val_loss=0.00338]          Epoch 33:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00285, val_loss=0.00338]Epoch 33:   4%|▎         | 1/27 [00:00<00:00, 159.87it/s, train_loss=0.00285, val_loss=0.00338]Epoch 33:   4%|▎         | 1/27 [00:00<00:00, 136.97it/s, train_loss=0.00303, val_loss=0.00338]Epoch 33:   7%|▋         | 2/27 [00:00<00:00, 164.68it/s, train_loss=0.00303, val_loss=0.00338]Epoch 33:   7%|▋         | 2/27 [00:00<00:00, 150.25it/s, train_loss=0.00301, val_loss=0.00338]Epoch 33:  11%|█         | 3/27 [00:00<00:00, 169.60it/s, train_loss=0.00301, val_loss=0.00338]Epoch 33:  11%|█         | 3/27 [00:00<00:00, 156.98it/s, train_loss=0.003, val_loss=0.00338]  Epoch 33:  15%|█▍        | 4/27 [00:00<00:00, 166.47it/s, train_loss=0.003, val_loss=0.00338]Epoch 33:  15%|█▍        | 4/27 [00:00<00:00, 154.86it/s, train_loss=0.00265, val_loss=0.00338]Epoch 33:  19%|█▊        | 5/27 [00:00<00:00, 162.85it/s, train_loss=0.00265, val_loss=0.00338]Epoch 33:  19%|█▊        | 5/27 [00:00<00:00, 156.89it/s, train_loss=0.0027, val_loss=0.00338] Epoch 33:  22%|██▏       | 6/27 [00:00<00:00, 165.33it/s, train_loss=0.0027, val_loss=0.00338]Epoch 33:  22%|██▏       | 6/27 [00:00<00:00, 159.20it/s, train_loss=0.00266, val_loss=0.00338]Epoch 33:  26%|██▌       | 7/27 [00:00<00:00, 164.34it/s, train_loss=0.00266, val_loss=0.00338]Epoch 33:  26%|██▌       | 7/27 [00:00<00:00, 157.66it/s, train_loss=0.00294, val_loss=0.00338]Epoch 33:  30%|██▉       | 8/27 [00:00<00:00, 162.62it/s, train_loss=0.00294, val_loss=0.00338]Epoch 33:  30%|██▉       | 8/27 [00:00<00:00, 158.58it/s, train_loss=0.00307, val_loss=0.00338]Epoch 33:  33%|███▎      | 9/27 [00:00<00:00, 164.30it/s, train_loss=0.00307, val_loss=0.00338]Epoch 33:  33%|███▎      | 9/27 [00:00<00:00, 160.04it/s, train_loss=0.00303, val_loss=0.00338]Epoch 33:  37%|███▋      | 10/27 [00:00<00:00, 164.88it/s, train_loss=0.00303, val_loss=0.00338]Epoch 33:  37%|███▋      | 10/27 [00:00<00:00, 159.22it/s, train_loss=0.00329, val_loss=0.00338]Epoch 33:  41%|████      | 11/27 [00:00<00:00, 162.34it/s, train_loss=0.00329, val_loss=0.00338]Epoch 33:  41%|████      | 11/27 [00:00<00:00, 159.53it/s, train_loss=0.00264, val_loss=0.00338]Epoch 33:  44%|████▍     | 12/27 [00:00<00:00, 163.05it/s, train_loss=0.00264, val_loss=0.00338]Epoch 33:  44%|████▍     | 12/27 [00:00<00:00, 155.08it/s, train_loss=0.00324, val_loss=0.00338]Epoch 33:  48%|████▊     | 13/27 [00:00<00:00, 157.76it/s, train_loss=0.00324, val_loss=0.00338]Epoch 33:  48%|████▊     | 13/27 [00:00<00:00, 155.38it/s, train_loss=0.00298, val_loss=0.00338]Epoch 33:  52%|█████▏    | 14/27 [00:00<00:00, 158.13it/s, train_loss=0.00298, val_loss=0.00338]Epoch 33:  52%|█████▏    | 14/27 [00:00<00:00, 155.84it/s, train_loss=0.00263, val_loss=0.00338]Epoch 33:  56%|█████▌    | 15/27 [00:00<00:00, 159.25it/s, train_loss=0.00263, val_loss=0.00338]Epoch 33:  56%|█████▌    | 15/27 [00:00<00:00, 154.53it/s, train_loss=0.00288, val_loss=0.00338]Epoch 33:  59%|█████▉    | 16/27 [00:00<00:00, 157.51it/s, train_loss=0.00288, val_loss=0.00338]Epoch 33:  59%|█████▉    | 16/27 [00:00<00:00, 155.45it/s, train_loss=0.0026, val_loss=0.00338] Epoch 33:  63%|██████▎   | 17/27 [00:00<00:00, 158.85it/s, train_loss=0.0026, val_loss=0.00338]Epoch 33:  63%|██████▎   | 17/27 [00:00<00:00, 156.56it/s, train_loss=0.00336, val_loss=0.00338]Epoch 33:  67%|██████▋   | 18/27 [00:00<00:00, 159.05it/s, train_loss=0.00336, val_loss=0.00338]Epoch 33:  67%|██████▋   | 18/27 [00:00<00:00, 155.99it/s, train_loss=0.00242, val_loss=0.00338]Epoch 33:  70%|███████   | 19/27 [00:00<00:00, 158.45it/s, train_loss=0.00242, val_loss=0.00338]Epoch 33:  70%|███████   | 19/27 [00:00<00:00, 156.71it/s, train_loss=0.00309, val_loss=0.00338]Epoch 33:  74%|███████▍  | 20/27 [00:00<00:00, 159.34it/s, train_loss=0.00309, val_loss=0.00338]Epoch 33:  74%|███████▍  | 20/27 [00:00<00:00, 157.44it/s, train_loss=0.00273, val_loss=0.00338]Epoch 33:  78%|███████▊  | 21/27 [00:00<00:00, 159.31it/s, train_loss=0.00273, val_loss=0.00338]Epoch 33:  78%|███████▊  | 21/27 [00:00<00:00, 156.98it/s, train_loss=0.00302, val_loss=0.00338]Epoch 33:  81%|████████▏ | 22/27 [00:00<00:00, 158.95it/s, train_loss=0.00302, val_loss=0.00338]Epoch 33:  81%|████████▏ | 22/27 [00:00<00:00, 157.45it/s, train_loss=0.00353, val_loss=0.00338]Epoch 33:  85%|████████▌ | 23/27 [00:00<00:00, 159.72it/s, train_loss=0.00353, val_loss=0.00338]Epoch 33:  85%|████████▌ | 23/27 [00:00<00:00, 158.09it/s, train_loss=0.00305, val_loss=0.00338]Epoch 33:  89%|████████▉ | 24/27 [00:00<00:00, 159.68it/s, train_loss=0.00305, val_loss=0.00338]Epoch 33:  89%|████████▉ | 24/27 [00:00<00:00, 157.65it/s, train_loss=0.00333, val_loss=0.00338]Epoch 33:  93%|█████████▎| 25/27 [00:00<00:00, 158.85it/s, train_loss=0.00333, val_loss=0.00338]Epoch 33:  93%|█████████▎| 25/27 [00:00<00:00, 157.64it/s, train_loss=0.00342, val_loss=0.00338]Epoch 33:  96%|█████████▋| 26/27 [00:00<00:00, 159.46it/s, train_loss=0.00342, val_loss=0.00338]Epoch 33:  96%|█████████▋| 26/27 [00:00<00:00, 158.12it/s, train_loss=0.00328, val_loss=0.00338]Epoch 33: 100%|██████████| 27/27 [00:00<00:00, 159.06it/s, train_loss=0.00328, val_loss=0.00338]Epoch 33: 100%|██████████| 27/27 [00:00<00:00, 157.70it/s, train_loss=0.00293, val_loss=0.00338]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 163.27it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 195.49it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 208.23it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 215.58it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 220.44it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 223.24it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 225.77it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 225.96it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 226.57it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 231.84it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 239.03it/s][A
                                                                         [AEpoch 33: 100%|██████████| 27/27 [00:00<00:00, 121.04it/s, train_loss=0.00293, val_loss=0.00337]Epoch 33: 100%|██████████| 27/27 [00:00<00:00, 120.71it/s, train_loss=0.00293, val_loss=0.00337]Epoch 33:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00293, val_loss=0.00337]          Epoch 34:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00293, val_loss=0.00337]Epoch 34:   4%|▎         | 1/27 [00:00<00:00, 180.31it/s, train_loss=0.00293, val_loss=0.00337]Epoch 34:   4%|▎         | 1/27 [00:00<00:00, 134.59it/s, train_loss=0.00318, val_loss=0.00337]Epoch 34:   7%|▋         | 2/27 [00:00<00:00, 164.86it/s, train_loss=0.00318, val_loss=0.00337]Epoch 34:   7%|▋         | 2/27 [00:00<00:00, 149.60it/s, train_loss=0.00255, val_loss=0.00337]Epoch 34:  11%|█         | 3/27 [00:00<00:00, 170.14it/s, train_loss=0.00255, val_loss=0.00337]Epoch 34:  11%|█         | 3/27 [00:00<00:00, 157.14it/s, train_loss=0.0034, val_loss=0.00337] Epoch 34:  15%|█▍        | 4/27 [00:00<00:00, 167.62it/s, train_loss=0.0034, val_loss=0.00337]Epoch 34:  15%|█▍        | 4/27 [00:00<00:00, 154.04it/s, train_loss=0.00328, val_loss=0.00337]Epoch 34:  19%|█▊        | 5/27 [00:00<00:00, 162.67it/s, train_loss=0.00328, val_loss=0.00337]Epoch 34:  19%|█▊        | 5/27 [00:00<00:00, 156.59it/s, train_loss=0.0029, val_loss=0.00337] Epoch 34:  22%|██▏       | 6/27 [00:00<00:00, 163.51it/s, train_loss=0.0029, val_loss=0.00337]Epoch 34:  22%|██▏       | 6/27 [00:00<00:00, 157.54it/s, train_loss=0.00278, val_loss=0.00337]Epoch 34:  26%|██▌       | 7/27 [00:00<00:00, 161.88it/s, train_loss=0.00278, val_loss=0.00337]Epoch 34:  26%|██▌       | 7/27 [00:00<00:00, 156.21it/s, train_loss=0.00295, val_loss=0.00337]Epoch 34:  30%|██▉       | 8/27 [00:00<00:00, 161.27it/s, train_loss=0.00295, val_loss=0.00337]Epoch 34:  30%|██▉       | 8/27 [00:00<00:00, 157.33it/s, train_loss=0.0031, val_loss=0.00337] Epoch 34:  33%|███▎      | 9/27 [00:00<00:00, 163.21it/s, train_loss=0.0031, val_loss=0.00337]Epoch 34:  33%|███▎      | 9/27 [00:00<00:00, 158.79it/s, train_loss=0.00275, val_loss=0.00337]Epoch 34:  37%|███▋      | 10/27 [00:00<00:00, 161.13it/s, train_loss=0.00275, val_loss=0.00337]Epoch 34:  37%|███▋      | 10/27 [00:00<00:00, 157.83it/s, train_loss=0.00299, val_loss=0.00337]Epoch 34:  41%|████      | 11/27 [00:00<00:00, 161.54it/s, train_loss=0.00299, val_loss=0.00337]Epoch 34:  41%|████      | 11/27 [00:00<00:00, 158.60it/s, train_loss=0.00298, val_loss=0.00337]Epoch 34:  44%|████▍     | 12/27 [00:00<00:00, 162.80it/s, train_loss=0.00298, val_loss=0.00337]Epoch 34:  44%|████▍     | 12/27 [00:00<00:00, 159.54it/s, train_loss=0.00306, val_loss=0.00337]Epoch 34:  48%|████▊     | 13/27 [00:00<00:00, 163.20it/s, train_loss=0.00306, val_loss=0.00337]Epoch 34:  48%|████▊     | 13/27 [00:00<00:00, 158.91it/s, train_loss=0.00278, val_loss=0.00337]Epoch 34:  52%|█████▏    | 14/27 [00:00<00:00, 161.53it/s, train_loss=0.00278, val_loss=0.00337]Epoch 34:  52%|█████▏    | 14/27 [00:00<00:00, 159.36it/s, train_loss=0.00252, val_loss=0.00337]Epoch 34:  56%|█████▌    | 15/27 [00:00<00:00, 162.23it/s, train_loss=0.00252, val_loss=0.00337]Epoch 34:  56%|█████▌    | 15/27 [00:00<00:00, 156.30it/s, train_loss=0.00269, val_loss=0.00337]Epoch 34:  59%|█████▉    | 16/27 [00:00<00:00, 158.31it/s, train_loss=0.00269, val_loss=0.00337]Epoch 34:  59%|█████▉    | 16/27 [00:00<00:00, 156.41it/s, train_loss=0.00321, val_loss=0.00337]Epoch 34:  63%|██████▎   | 17/27 [00:00<00:00, 158.44it/s, train_loss=0.00321, val_loss=0.00337]Epoch 34:  63%|██████▎   | 17/27 [00:00<00:00, 156.68it/s, train_loss=0.00289, val_loss=0.00337]Epoch 34:  67%|██████▋   | 18/27 [00:00<00:00, 159.66it/s, train_loss=0.00289, val_loss=0.00337]Epoch 34:  67%|██████▋   | 18/27 [00:00<00:00, 155.01it/s, train_loss=0.00335, val_loss=0.00337]Epoch 34:  70%|███████   | 19/27 [00:00<00:00, 157.47it/s, train_loss=0.00335, val_loss=0.00337]Epoch 34:  70%|███████   | 19/27 [00:00<00:00, 155.76it/s, train_loss=0.0035, val_loss=0.00337] Epoch 34:  74%|███████▍  | 20/27 [00:00<00:00, 158.57it/s, train_loss=0.0035, val_loss=0.00337]Epoch 34:  74%|███████▍  | 20/27 [00:00<00:00, 156.77it/s, train_loss=0.00303, val_loss=0.00337]Epoch 34:  78%|███████▊  | 21/27 [00:00<00:00, 158.92it/s, train_loss=0.00303, val_loss=0.00337]Epoch 34:  78%|███████▊  | 21/27 [00:00<00:00, 156.26it/s, train_loss=0.00252, val_loss=0.00337]Epoch 34:  81%|████████▏ | 22/27 [00:00<00:00, 158.33it/s, train_loss=0.00252, val_loss=0.00337]Epoch 34:  81%|████████▏ | 22/27 [00:00<00:00, 156.83it/s, train_loss=0.00253, val_loss=0.00337]Epoch 34:  85%|████████▌ | 23/27 [00:00<00:00, 159.16it/s, train_loss=0.00253, val_loss=0.00337]Epoch 34:  85%|████████▌ | 23/27 [00:00<00:00, 157.48it/s, train_loss=0.00325, val_loss=0.00337]Epoch 34:  89%|████████▉ | 24/27 [00:00<00:00, 158.90it/s, train_loss=0.00325, val_loss=0.00337]Epoch 34:  89%|████████▉ | 24/27 [00:00<00:00, 157.11it/s, train_loss=0.00377, val_loss=0.00337]Epoch 34:  93%|█████████▎| 25/27 [00:00<00:00, 158.91it/s, train_loss=0.00377, val_loss=0.00337]Epoch 34:  93%|█████████▎| 25/27 [00:00<00:00, 157.58it/s, train_loss=0.00256, val_loss=0.00337]Epoch 34:  96%|█████████▋| 26/27 [00:00<00:00, 159.60it/s, train_loss=0.00256, val_loss=0.00337]Epoch 34:  96%|█████████▋| 26/27 [00:00<00:00, 158.09it/s, train_loss=0.00302, val_loss=0.00337]Epoch 34: 100%|██████████| 27/27 [00:00<00:00, 159.32it/s, train_loss=0.00302, val_loss=0.00337]Epoch 34: 100%|██████████| 27/27 [00:00<00:00, 157.76it/s, train_loss=0.0027, val_loss=0.00337] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 170.82it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 204.30it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 211.28it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 213.07it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 220.19it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 224.23it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 227.59it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 228.87it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 230.70it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 231.79it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 233.36it/s][A
                                                                         [AEpoch 34: 100%|██████████| 27/27 [00:00<00:00, 119.58it/s, train_loss=0.0027, val_loss=0.00336]Epoch 34: 100%|██████████| 27/27 [00:00<00:00, 119.05it/s, train_loss=0.0027, val_loss=0.00336]Epoch 34:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0027, val_loss=0.00336]          Epoch 35:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0027, val_loss=0.00336]Epoch 35:   4%|▎         | 1/27 [00:00<00:00, 160.42it/s, train_loss=0.0027, val_loss=0.00336]Epoch 35:   4%|▎         | 1/27 [00:00<00:00, 136.89it/s, train_loss=0.00289, val_loss=0.00336]Epoch 35:   7%|▋         | 2/27 [00:00<00:00, 170.43it/s, train_loss=0.00289, val_loss=0.00336]Epoch 35:   7%|▋         | 2/27 [00:00<00:00, 132.58it/s, train_loss=0.0031, val_loss=0.00336] Epoch 35:  11%|█         | 3/27 [00:00<00:00, 142.96it/s, train_loss=0.0031, val_loss=0.00336]Epoch 35:  11%|█         | 3/27 [00:00<00:00, 135.95it/s, train_loss=0.00306, val_loss=0.00336]Epoch 35:  15%|█▍        | 4/27 [00:00<00:00, 148.88it/s, train_loss=0.00306, val_loss=0.00336]Epoch 35:  15%|█▍        | 4/27 [00:00<00:00, 142.66it/s, train_loss=0.00331, val_loss=0.00336]Epoch 35:  19%|█▊        | 5/27 [00:00<00:00, 153.62it/s, train_loss=0.00331, val_loss=0.00336]Epoch 35:  19%|█▊        | 5/27 [00:00<00:00, 137.68it/s, train_loss=0.00244, val_loss=0.00336]Epoch 35:  22%|██▏       | 6/27 [00:00<00:00, 145.00it/s, train_loss=0.00244, val_loss=0.00336]Epoch 35:  22%|██▏       | 6/27 [00:00<00:00, 141.02it/s, train_loss=0.00324, val_loss=0.00336]Epoch 35:  26%|██▌       | 7/27 [00:00<00:00, 148.25it/s, train_loss=0.00324, val_loss=0.00336]Epoch 35:  26%|██▌       | 7/27 [00:00<00:00, 144.30it/s, train_loss=0.00331, val_loss=0.00336]Epoch 35:  30%|██▉       | 8/27 [00:00<00:00, 151.34it/s, train_loss=0.00331, val_loss=0.00336]Epoch 35:  30%|██▉       | 8/27 [00:00<00:00, 145.20it/s, train_loss=0.00243, val_loss=0.00336]Epoch 35:  33%|███▎      | 9/27 [00:00<00:00, 150.10it/s, train_loss=0.00243, val_loss=0.00336]Epoch 35:  33%|███▎      | 9/27 [00:00<00:00, 147.34it/s, train_loss=0.00287, val_loss=0.00336]Epoch 35:  37%|███▋      | 10/27 [00:00<00:00, 152.43it/s, train_loss=0.00287, val_loss=0.00336]Epoch 35:  37%|███▋      | 10/27 [00:00<00:00, 149.29it/s, train_loss=0.0031, val_loss=0.00336] Epoch 35:  41%|████      | 11/27 [00:00<00:00, 154.22it/s, train_loss=0.0031, val_loss=0.00336]Epoch 35:  41%|████      | 11/27 [00:00<00:00, 149.50it/s, train_loss=0.00323, val_loss=0.00336]Epoch 35:  44%|████▍     | 12/27 [00:00<00:00, 152.90it/s, train_loss=0.00323, val_loss=0.00336]Epoch 35:  44%|████▍     | 12/27 [00:00<00:00, 150.65it/s, train_loss=0.00371, val_loss=0.00336]Epoch 35:  48%|████▊     | 13/27 [00:00<00:00, 154.23it/s, train_loss=0.00371, val_loss=0.00336]Epoch 35:  48%|████▊     | 13/27 [00:00<00:00, 151.78it/s, train_loss=0.00268, val_loss=0.00336]Epoch 35:  52%|█████▏    | 14/27 [00:00<00:00, 155.54it/s, train_loss=0.00268, val_loss=0.00336]Epoch 35:  52%|█████▏    | 14/27 [00:00<00:00, 151.86it/s, train_loss=0.0027, val_loss=0.00336] Epoch 35:  56%|█████▌    | 15/27 [00:00<00:00, 154.47it/s, train_loss=0.0027, val_loss=0.00336]Epoch 35:  56%|█████▌    | 15/27 [00:00<00:00, 152.67it/s, train_loss=0.00274, val_loss=0.00336]Epoch 35:  59%|█████▉    | 16/27 [00:00<00:00, 155.51it/s, train_loss=0.00274, val_loss=0.00336]Epoch 35:  59%|█████▉    | 16/27 [00:00<00:00, 153.34it/s, train_loss=0.00331, val_loss=0.00336]Epoch 35:  63%|██████▎   | 17/27 [00:00<00:00, 156.22it/s, train_loss=0.00331, val_loss=0.00336]Epoch 35:  63%|██████▎   | 17/27 [00:00<00:00, 153.25it/s, train_loss=0.00304, val_loss=0.00336]Epoch 35:  67%|██████▋   | 18/27 [00:00<00:00, 155.27it/s, train_loss=0.00304, val_loss=0.00336]Epoch 35:  67%|██████▋   | 18/27 [00:00<00:00, 153.70it/s, train_loss=0.00302, val_loss=0.00336]Epoch 35:  70%|███████   | 19/27 [00:00<00:00, 155.98it/s, train_loss=0.00302, val_loss=0.00336]Epoch 35:  70%|███████   | 19/27 [00:00<00:00, 151.33it/s, train_loss=0.00306, val_loss=0.00336]Epoch 35:  74%|███████▍  | 20/27 [00:00<00:00, 153.12it/s, train_loss=0.00306, val_loss=0.00336]Epoch 35:  74%|███████▍  | 20/27 [00:00<00:00, 151.75it/s, train_loss=0.00243, val_loss=0.00336]Epoch 35:  78%|███████▊  | 21/27 [00:00<00:00, 153.58it/s, train_loss=0.00243, val_loss=0.00336]Epoch 35:  78%|███████▊  | 21/27 [00:00<00:00, 152.21it/s, train_loss=0.00264, val_loss=0.00336]Epoch 35:  81%|████████▏ | 22/27 [00:00<00:00, 154.54it/s, train_loss=0.00264, val_loss=0.00336]Epoch 35:  81%|████████▏ | 22/27 [00:00<00:00, 151.43it/s, train_loss=0.0032, val_loss=0.00336] Epoch 35:  85%|████████▌ | 23/27 [00:00<00:00, 153.47it/s, train_loss=0.0032, val_loss=0.00336]Epoch 35:  85%|████████▌ | 23/27 [00:00<00:00, 152.17it/s, train_loss=0.00307, val_loss=0.00336]Epoch 35:  89%|████████▉ | 24/27 [00:00<00:00, 154.44it/s, train_loss=0.00307, val_loss=0.00336]Epoch 35:  89%|████████▉ | 24/27 [00:00<00:00, 153.07it/s, train_loss=0.00266, val_loss=0.00336]Epoch 35:  93%|█████████▎| 25/27 [00:00<00:00, 154.89it/s, train_loss=0.00266, val_loss=0.00336]Epoch 35:  93%|█████████▎| 25/27 [00:00<00:00, 152.75it/s, train_loss=0.00334, val_loss=0.00336]Epoch 35:  96%|█████████▋| 26/27 [00:00<00:00, 154.45it/s, train_loss=0.00334, val_loss=0.00336]Epoch 35:  96%|█████████▋| 26/27 [00:00<00:00, 153.29it/s, train_loss=0.00278, val_loss=0.00336]Epoch 35: 100%|██████████| 27/27 [00:00<00:00, 155.20it/s, train_loss=0.00278, val_loss=0.00336]Epoch 35: 100%|██████████| 27/27 [00:00<00:00, 153.94it/s, train_loss=0.00267, val_loss=0.00336]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 188.47it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 219.62it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 231.47it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 238.59it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 241.56it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 244.24it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 245.54it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 246.13it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 247.02it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 247.33it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 248.33it/s][A
                                                                         [AEpoch 35: 100%|██████████| 27/27 [00:00<00:00, 118.97it/s, train_loss=0.00267, val_loss=0.00335]Epoch 35: 100%|██████████| 27/27 [00:00<00:00, 118.47it/s, train_loss=0.00267, val_loss=0.00335]Epoch 35:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00267, val_loss=0.00335]          Epoch 36:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00267, val_loss=0.00335]Epoch 36:   4%|▎         | 1/27 [00:00<00:00, 162.27it/s, train_loss=0.00267, val_loss=0.00335]Epoch 36:   4%|▎         | 1/27 [00:00<00:00, 138.43it/s, train_loss=0.00335, val_loss=0.00335]Epoch 36:   7%|▋         | 2/27 [00:00<00:00, 164.58it/s, train_loss=0.00335, val_loss=0.00335]Epoch 36:   7%|▋         | 2/27 [00:00<00:00, 149.64it/s, train_loss=0.0027, val_loss=0.00335] Epoch 36:  11%|█         | 3/27 [00:00<00:00, 165.97it/s, train_loss=0.0027, val_loss=0.00335]Epoch 36:  11%|█         | 3/27 [00:00<00:00, 150.64it/s, train_loss=0.00256, val_loss=0.00335]Epoch 36:  15%|█▍        | 4/27 [00:00<00:00, 159.32it/s, train_loss=0.00256, val_loss=0.00335]Epoch 36:  15%|█▍        | 4/27 [00:00<00:00, 151.78it/s, train_loss=0.00236, val_loss=0.00335]Epoch 36:  19%|█▊        | 5/27 [00:00<00:00, 160.24it/s, train_loss=0.00236, val_loss=0.00335]Epoch 36:  19%|█▊        | 5/27 [00:00<00:00, 145.15it/s, train_loss=0.00307, val_loss=0.00335]Epoch 36:  22%|██▏       | 6/27 [00:00<00:00, 153.01it/s, train_loss=0.00307, val_loss=0.00335]Epoch 36:  22%|██▏       | 6/27 [00:00<00:00, 148.71it/s, train_loss=0.00305, val_loss=0.00335]Epoch 36:  26%|██▌       | 7/27 [00:00<00:00, 156.07it/s, train_loss=0.00305, val_loss=0.00335]Epoch 36:  26%|██▌       | 7/27 [00:00<00:00, 151.45it/s, train_loss=0.00279, val_loss=0.00335]Epoch 36:  30%|██▉       | 8/27 [00:00<00:00, 157.64it/s, train_loss=0.00279, val_loss=0.00335]Epoch 36:  30%|██▉       | 8/27 [00:00<00:00, 151.16it/s, train_loss=0.00306, val_loss=0.00335]Epoch 36:  33%|███▎      | 9/27 [00:00<00:00, 153.60it/s, train_loss=0.00306, val_loss=0.00335]Epoch 36:  33%|███▎      | 9/27 [00:00<00:00, 149.81it/s, train_loss=0.00301, val_loss=0.00335]Epoch 36:  37%|███▋      | 10/27 [00:00<00:00, 154.26it/s, train_loss=0.00301, val_loss=0.00335]Epoch 36:  37%|███▋      | 10/27 [00:00<00:00, 146.05it/s, train_loss=0.00225, val_loss=0.00335]Epoch 36:  41%|████      | 11/27 [00:00<00:00, 149.29it/s, train_loss=0.00225, val_loss=0.00335]Epoch 36:  41%|████      | 11/27 [00:00<00:00, 147.07it/s, train_loss=0.00303, val_loss=0.00335]Epoch 36:  44%|████▍     | 12/27 [00:00<00:00, 150.93it/s, train_loss=0.00303, val_loss=0.00335]Epoch 36:  44%|████▍     | 12/27 [00:00<00:00, 148.52it/s, train_loss=0.00308, val_loss=0.00335]Epoch 36:  48%|████▊     | 13/27 [00:00<00:00, 152.39it/s, train_loss=0.00308, val_loss=0.00335]Epoch 36:  48%|████▊     | 13/27 [00:00<00:00, 148.85it/s, train_loss=0.00304, val_loss=0.00335]Epoch 36:  52%|█████▏    | 14/27 [00:00<00:00, 151.78it/s, train_loss=0.00304, val_loss=0.00335]Epoch 36:  52%|█████▏    | 14/27 [00:00<00:00, 149.92it/s, train_loss=0.00254, val_loss=0.00335]Epoch 36:  56%|█████▌    | 15/27 [00:00<00:00, 153.14it/s, train_loss=0.00254, val_loss=0.00335]Epoch 36:  56%|█████▌    | 15/27 [00:00<00:00, 151.01it/s, train_loss=0.00316, val_loss=0.00335]Epoch 36:  59%|█████▉    | 16/27 [00:00<00:00, 154.35it/s, train_loss=0.00316, val_loss=0.00335]Epoch 36:  59%|█████▉    | 16/27 [00:00<00:00, 150.96it/s, train_loss=0.00331, val_loss=0.00335]Epoch 36:  63%|██████▎   | 17/27 [00:00<00:00, 153.32it/s, train_loss=0.00331, val_loss=0.00335]Epoch 36:  63%|██████▎   | 17/27 [00:00<00:00, 151.77it/s, train_loss=0.00288, val_loss=0.00335]Epoch 36:  67%|██████▋   | 18/27 [00:00<00:00, 154.32it/s, train_loss=0.00288, val_loss=0.00335]Epoch 36:  67%|██████▋   | 18/27 [00:00<00:00, 152.45it/s, train_loss=0.00302, val_loss=0.00335]Epoch 36:  70%|███████   | 19/27 [00:00<00:00, 155.18it/s, train_loss=0.00302, val_loss=0.00335]Epoch 36:  70%|███████   | 19/27 [00:00<00:00, 152.37it/s, train_loss=0.00338, val_loss=0.00335]Epoch 36:  74%|███████▍  | 20/27 [00:00<00:00, 154.11it/s, train_loss=0.00338, val_loss=0.00335]Epoch 36:  74%|███████▍  | 20/27 [00:00<00:00, 152.65it/s, train_loss=0.00297, val_loss=0.00335]Epoch 36:  78%|███████▊  | 21/27 [00:00<00:00, 154.80it/s, train_loss=0.00297, val_loss=0.00335]Epoch 36:  78%|███████▊  | 21/27 [00:00<00:00, 150.98it/s, train_loss=0.00237, val_loss=0.00335]Epoch 36:  81%|████████▏ | 22/27 [00:00<00:00, 152.62it/s, train_loss=0.00237, val_loss=0.00335]Epoch 36:  81%|████████▏ | 22/27 [00:00<00:00, 151.41it/s, train_loss=0.00266, val_loss=0.00335]Epoch 36:  85%|████████▌ | 23/27 [00:00<00:00, 153.32it/s, train_loss=0.00266, val_loss=0.00335]Epoch 36:  85%|████████▌ | 23/27 [00:00<00:00, 149.77it/s, train_loss=0.00327, val_loss=0.00335]Epoch 36:  89%|████████▉ | 24/27 [00:00<00:00, 151.25it/s, train_loss=0.00327, val_loss=0.00335]Epoch 36:  89%|████████▉ | 24/27 [00:00<00:00, 150.14it/s, train_loss=0.0034, val_loss=0.00335] Epoch 36:  93%|█████████▎| 25/27 [00:00<00:00, 152.25it/s, train_loss=0.0034, val_loss=0.00335]Epoch 36:  93%|█████████▎| 25/27 [00:00<00:00, 148.86it/s, train_loss=0.00329, val_loss=0.00335]Epoch 36:  96%|█████████▋| 26/27 [00:00<00:00, 150.30it/s, train_loss=0.00329, val_loss=0.00335]Epoch 36:  96%|█████████▋| 26/27 [00:00<00:00, 149.29it/s, train_loss=0.00331, val_loss=0.00335]Epoch 36: 100%|██████████| 27/27 [00:00<00:00, 151.15it/s, train_loss=0.00331, val_loss=0.00335]Epoch 36: 100%|██████████| 27/27 [00:00<00:00, 148.02it/s, train_loss=0.00302, val_loss=0.00335]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 182.31it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 218.56it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 235.43it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 242.45it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 247.27it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 251.01it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 251.56it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 252.96it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 254.03it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 254.48it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 256.01it/s][A
                                                                         [AEpoch 36: 100%|██████████| 27/27 [00:00<00:00, 116.54it/s, train_loss=0.00302, val_loss=0.00335]Epoch 36: 100%|██████████| 27/27 [00:00<00:00, 116.09it/s, train_loss=0.00302, val_loss=0.00335]Epoch 36:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00335]          Epoch 37:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00335]Epoch 37:   4%|▎         | 1/27 [00:00<00:00, 165.44it/s, train_loss=0.00302, val_loss=0.00335]Epoch 37:   4%|▎         | 1/27 [00:00<00:00, 139.20it/s, train_loss=0.00286, val_loss=0.00335]Epoch 37:   7%|▋         | 2/27 [00:00<00:00, 160.58it/s, train_loss=0.00286, val_loss=0.00335]Epoch 37:   7%|▋         | 2/27 [00:00<00:00, 137.17it/s, train_loss=0.00322, val_loss=0.00335]Epoch 37:  11%|█         | 3/27 [00:00<00:00, 150.62it/s, train_loss=0.00322, val_loss=0.00335]Epoch 37:  11%|█         | 3/27 [00:00<00:00, 142.90it/s, train_loss=0.00287, val_loss=0.00335]Epoch 37:  15%|█▍        | 4/27 [00:00<00:00, 155.15it/s, train_loss=0.00287, val_loss=0.00335]Epoch 37:  15%|█▍        | 4/27 [00:00<00:00, 135.23it/s, train_loss=0.0024, val_loss=0.00335] Epoch 37:  19%|█▊        | 5/27 [00:00<00:00, 140.88it/s, train_loss=0.0024, val_loss=0.00335]Epoch 37:  19%|█▊        | 5/27 [00:00<00:00, 137.16it/s, train_loss=0.00337, val_loss=0.00335]Epoch 37:  22%|██▏       | 6/27 [00:00<00:00, 145.01it/s, train_loss=0.00337, val_loss=0.00335]Epoch 37:  22%|██▏       | 6/27 [00:00<00:00, 134.82it/s, train_loss=0.00244, val_loss=0.00335]Epoch 37:  26%|██▌       | 7/27 [00:00<00:00, 140.90it/s, train_loss=0.00244, val_loss=0.00335]Epoch 37:  26%|██▌       | 7/27 [00:00<00:00, 137.45it/s, train_loss=0.00283, val_loss=0.00335]Epoch 37:  30%|██▉       | 8/27 [00:00<00:00, 143.53it/s, train_loss=0.00283, val_loss=0.00335]Epoch 37:  30%|██▉       | 8/27 [00:00<00:00, 135.57it/s, train_loss=0.0026, val_loss=0.00335] Epoch 37:  33%|███▎      | 9/27 [00:00<00:00, 141.09it/s, train_loss=0.0026, val_loss=0.00335]Epoch 37:  33%|███▎      | 9/27 [00:00<00:00, 138.50it/s, train_loss=0.00319, val_loss=0.00335]Epoch 37:  37%|███▋      | 10/27 [00:00<00:00, 143.79it/s, train_loss=0.00319, val_loss=0.00335]Epoch 37:  37%|███▋      | 10/27 [00:00<00:00, 141.15it/s, train_loss=0.00245, val_loss=0.00335]Epoch 37:  41%|████      | 11/27 [00:00<00:00, 145.76it/s, train_loss=0.00245, val_loss=0.00335]Epoch 37:  41%|████      | 11/27 [00:00<00:00, 141.78it/s, train_loss=0.00298, val_loss=0.00335]Epoch 37:  44%|████▍     | 12/27 [00:00<00:00, 145.82it/s, train_loss=0.00298, val_loss=0.00335]Epoch 37:  44%|████▍     | 12/27 [00:00<00:00, 143.72it/s, train_loss=0.0031, val_loss=0.00335] Epoch 37:  48%|████▊     | 13/27 [00:00<00:00, 147.91it/s, train_loss=0.0031, val_loss=0.00335]Epoch 37:  48%|████▊     | 13/27 [00:00<00:00, 145.63it/s, train_loss=0.00304, val_loss=0.00335]Epoch 37:  52%|█████▏    | 14/27 [00:00<00:00, 148.77it/s, train_loss=0.00304, val_loss=0.00335]Epoch 37:  52%|█████▏    | 14/27 [00:00<00:00, 145.89it/s, train_loss=0.0028, val_loss=0.00335] Epoch 37:  56%|█████▌    | 15/27 [00:00<00:00, 148.80it/s, train_loss=0.0028, val_loss=0.00335]Epoch 37:  56%|█████▌    | 15/27 [00:00<00:00, 147.11it/s, train_loss=0.00279, val_loss=0.00335]Epoch 37:  59%|█████▉    | 16/27 [00:00<00:00, 150.44it/s, train_loss=0.00279, val_loss=0.00335]Epoch 37:  59%|█████▉    | 16/27 [00:00<00:00, 148.43it/s, train_loss=0.00311, val_loss=0.00335]Epoch 37:  63%|██████▎   | 17/27 [00:00<00:00, 151.03it/s, train_loss=0.00311, val_loss=0.00335]Epoch 37:  63%|██████▎   | 17/27 [00:00<00:00, 148.43it/s, train_loss=0.00326, val_loss=0.00335]Epoch 37:  67%|██████▋   | 18/27 [00:00<00:00, 150.88it/s, train_loss=0.00326, val_loss=0.00335]Epoch 37:  67%|██████▋   | 18/27 [00:00<00:00, 149.39it/s, train_loss=0.00354, val_loss=0.00335]Epoch 37:  70%|███████   | 19/27 [00:00<00:00, 152.19it/s, train_loss=0.00354, val_loss=0.00335]Epoch 37:  70%|███████   | 19/27 [00:00<00:00, 150.43it/s, train_loss=0.00293, val_loss=0.00335]Epoch 37:  74%|███████▍  | 20/27 [00:00<00:00, 152.60it/s, train_loss=0.00293, val_loss=0.00335]Epoch 37:  74%|███████▍  | 20/27 [00:00<00:00, 150.32it/s, train_loss=0.00306, val_loss=0.00335]Epoch 37:  78%|███████▊  | 21/27 [00:00<00:00, 152.26it/s, train_loss=0.00306, val_loss=0.00335]Epoch 37:  78%|███████▊  | 21/27 [00:00<00:00, 150.91it/s, train_loss=0.00325, val_loss=0.00335]Epoch 37:  81%|████████▏ | 22/27 [00:00<00:00, 153.26it/s, train_loss=0.00325, val_loss=0.00335]Epoch 37:  81%|████████▏ | 22/27 [00:00<00:00, 151.71it/s, train_loss=0.00308, val_loss=0.00335]Epoch 37:  85%|████████▌ | 23/27 [00:00<00:00, 153.93it/s, train_loss=0.00308, val_loss=0.00335]Epoch 37:  85%|████████▌ | 23/27 [00:00<00:00, 151.76it/s, train_loss=0.00271, val_loss=0.00335]Epoch 37:  89%|████████▉ | 24/27 [00:00<00:00, 153.33it/s, train_loss=0.00271, val_loss=0.00335]Epoch 37:  89%|████████▉ | 24/27 [00:00<00:00, 152.18it/s, train_loss=0.00354, val_loss=0.00335]Epoch 37:  93%|█████████▎| 25/27 [00:00<00:00, 154.00it/s, train_loss=0.00354, val_loss=0.00335]Epoch 37:  93%|█████████▎| 25/27 [00:00<00:00, 150.46it/s, train_loss=0.0028, val_loss=0.00335] Epoch 37:  96%|█████████▋| 26/27 [00:00<00:00, 151.92it/s, train_loss=0.0028, val_loss=0.00335]Epoch 37:  96%|█████████▋| 26/27 [00:00<00:00, 150.83it/s, train_loss=0.00287, val_loss=0.00335]Epoch 37: 100%|██████████| 27/27 [00:00<00:00, 152.18it/s, train_loss=0.00287, val_loss=0.00335]Epoch 37: 100%|██████████| 27/27 [00:00<00:00, 151.18it/s, train_loss=0.00274, val_loss=0.00335]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 242.94it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 272.84it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 284.85it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 291.53it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 289.10it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 290.79it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 291.94it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 291.95it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 291.06it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 290.19it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 290.41it/s][A
                                                                         [AEpoch 37: 100%|██████████| 27/27 [00:00<00:00, 121.39it/s, train_loss=0.00274, val_loss=0.00335]Epoch 37: 100%|██████████| 27/27 [00:00<00:00, 120.95it/s, train_loss=0.00274, val_loss=0.00335]Epoch 37:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00274, val_loss=0.00335]          Epoch 38:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00274, val_loss=0.00335]Epoch 38:   4%|▎         | 1/27 [00:00<00:00, 165.68it/s, train_loss=0.00274, val_loss=0.00335]Epoch 38:   4%|▎         | 1/27 [00:00<00:00, 139.57it/s, train_loss=0.00253, val_loss=0.00335]Epoch 38:   7%|▋         | 2/27 [00:00<00:00, 166.13it/s, train_loss=0.00253, val_loss=0.00335]Epoch 38:   7%|▋         | 2/27 [00:00<00:00, 151.82it/s, train_loss=0.00238, val_loss=0.00335]Epoch 38:  11%|█         | 3/27 [00:00<00:00, 170.38it/s, train_loss=0.00238, val_loss=0.00335]Epoch 38:  11%|█         | 3/27 [00:00<00:00, 140.14it/s, train_loss=0.00343, val_loss=0.00335]Epoch 38:  15%|█▍        | 4/27 [00:00<00:00, 150.60it/s, train_loss=0.00343, val_loss=0.00335]Epoch 38:  15%|█▍        | 4/27 [00:00<00:00, 144.12it/s, train_loss=0.00294, val_loss=0.00335]Epoch 38:  19%|█▊        | 5/27 [00:00<00:00, 153.81it/s, train_loss=0.00294, val_loss=0.00335]Epoch 38:  19%|█▊        | 5/27 [00:00<00:00, 147.93it/s, train_loss=0.00255, val_loss=0.00335]Epoch 38:  22%|██▏       | 6/27 [00:00<00:00, 157.10it/s, train_loss=0.00255, val_loss=0.00335]Epoch 38:  22%|██▏       | 6/27 [00:00<00:00, 148.63it/s, train_loss=0.00261, val_loss=0.00335]Epoch 38:  26%|██▌       | 7/27 [00:00<00:00, 154.50it/s, train_loss=0.00261, val_loss=0.00335]Epoch 38:  26%|██▌       | 7/27 [00:00<00:00, 150.73it/s, train_loss=0.00243, val_loss=0.00335]Epoch 38:  30%|██▉       | 8/27 [00:00<00:00, 156.34it/s, train_loss=0.00243, val_loss=0.00335]Epoch 38:  30%|██▉       | 8/27 [00:00<00:00, 146.55it/s, train_loss=0.00248, val_loss=0.00335]Epoch 38:  33%|███▎      | 9/27 [00:00<00:00, 150.18it/s, train_loss=0.00248, val_loss=0.00335]Epoch 38:  33%|███▎      | 9/27 [00:00<00:00, 146.98it/s, train_loss=0.00326, val_loss=0.00335]Epoch 38:  37%|███▋      | 10/27 [00:00<00:00, 151.30it/s, train_loss=0.00326, val_loss=0.00335]Epoch 38:  37%|███▋      | 10/27 [00:00<00:00, 148.28it/s, train_loss=0.00359, val_loss=0.00335]Epoch 38:  41%|████      | 11/27 [00:00<00:00, 151.95it/s, train_loss=0.00359, val_loss=0.00335]Epoch 38:  41%|████      | 11/27 [00:00<00:00, 146.81it/s, train_loss=0.0033, val_loss=0.00335] Epoch 38:  44%|████▍     | 12/27 [00:00<00:00, 150.15it/s, train_loss=0.0033, val_loss=0.00335]Epoch 38:  44%|████▍     | 12/27 [00:00<00:00, 147.86it/s, train_loss=0.00266, val_loss=0.00335]Epoch 38:  48%|████▊     | 13/27 [00:00<00:00, 152.53it/s, train_loss=0.00266, val_loss=0.00335]Epoch 38:  48%|████▊     | 13/27 [00:00<00:00, 146.47it/s, train_loss=0.00325, val_loss=0.00335]Epoch 38:  52%|█████▏    | 14/27 [00:00<00:00, 149.66it/s, train_loss=0.00325, val_loss=0.00335]Epoch 38:  52%|█████▏    | 14/27 [00:00<00:00, 147.70it/s, train_loss=0.00293, val_loss=0.00335]Epoch 38:  56%|█████▌    | 15/27 [00:00<00:00, 150.97it/s, train_loss=0.00293, val_loss=0.00335]Epoch 38:  56%|█████▌    | 15/27 [00:00<00:00, 149.02it/s, train_loss=0.00288, val_loss=0.00335]Epoch 38:  59%|█████▉    | 16/27 [00:00<00:00, 152.50it/s, train_loss=0.00288, val_loss=0.00335]Epoch 38:  59%|█████▉    | 16/27 [00:00<00:00, 147.05it/s, train_loss=0.00342, val_loss=0.00335]Epoch 38:  63%|██████▎   | 17/27 [00:00<00:00, 149.61it/s, train_loss=0.00342, val_loss=0.00335]Epoch 38:  63%|██████▎   | 17/27 [00:00<00:00, 148.18it/s, train_loss=0.00278, val_loss=0.00335]Epoch 38:  67%|██████▋   | 18/27 [00:00<00:00, 150.95it/s, train_loss=0.00278, val_loss=0.00335]Epoch 38:  67%|██████▋   | 18/27 [00:00<00:00, 149.23it/s, train_loss=0.00281, val_loss=0.00335]Epoch 38:  70%|███████   | 19/27 [00:00<00:00, 152.12it/s, train_loss=0.00281, val_loss=0.00335]Epoch 38:  70%|███████   | 19/27 [00:00<00:00, 149.33it/s, train_loss=0.00312, val_loss=0.00335]Epoch 38:  74%|███████▍  | 20/27 [00:00<00:00, 151.56it/s, train_loss=0.00312, val_loss=0.00335]Epoch 38:  74%|███████▍  | 20/27 [00:00<00:00, 150.18it/s, train_loss=0.00267, val_loss=0.00335]Epoch 38:  78%|███████▊  | 21/27 [00:00<00:00, 152.12it/s, train_loss=0.00267, val_loss=0.00335]Epoch 38:  78%|███████▊  | 21/27 [00:00<00:00, 150.63it/s, train_loss=0.00315, val_loss=0.00335]Epoch 38:  81%|████████▏ | 22/27 [00:00<00:00, 151.84it/s, train_loss=0.00315, val_loss=0.00335]Epoch 38:  81%|████████▏ | 22/27 [00:00<00:00, 150.53it/s, train_loss=0.00277, val_loss=0.00335]Epoch 38:  85%|████████▌ | 23/27 [00:00<00:00, 152.21it/s, train_loss=0.00277, val_loss=0.00335]Epoch 38:  85%|████████▌ | 23/27 [00:00<00:00, 151.08it/s, train_loss=0.00242, val_loss=0.00335]Epoch 38:  89%|████████▉ | 24/27 [00:00<00:00, 153.24it/s, train_loss=0.00242, val_loss=0.00335]Epoch 38:  89%|████████▉ | 24/27 [00:00<00:00, 151.74it/s, train_loss=0.00337, val_loss=0.00335]Epoch 38:  93%|█████████▎| 25/27 [00:00<00:00, 152.72it/s, train_loss=0.00337, val_loss=0.00335]Epoch 38:  93%|█████████▎| 25/27 [00:00<00:00, 151.65it/s, train_loss=0.00307, val_loss=0.00335]Epoch 38:  96%|█████████▋| 26/27 [00:00<00:00, 153.19it/s, train_loss=0.00307, val_loss=0.00335]Epoch 38:  96%|█████████▋| 26/27 [00:00<00:00, 152.07it/s, train_loss=0.00391, val_loss=0.00335]Epoch 38: 100%|██████████| 27/27 [00:00<00:00, 153.85it/s, train_loss=0.00391, val_loss=0.00335]Epoch 38: 100%|██████████| 27/27 [00:00<00:00, 150.82it/s, train_loss=0.00314, val_loss=0.00335]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 154.34it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 186.28it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 197.99it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 205.59it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 211.34it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 225.54it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 236.87it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 245.13it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 252.28it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 255.61it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 255.87it/s][A
                                                                         [AEpoch 38: 100%|██████████| 27/27 [00:00<00:00, 117.16it/s, train_loss=0.00314, val_loss=0.00335]Epoch 38: 100%|██████████| 27/27 [00:00<00:00, 116.81it/s, train_loss=0.00314, val_loss=0.00335]Epoch 38:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00314, val_loss=0.00335]          Epoch 39:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00314, val_loss=0.00335]Epoch 39:   4%|▎         | 1/27 [00:00<00:00, 171.33it/s, train_loss=0.00314, val_loss=0.00335]Epoch 39:   4%|▎         | 1/27 [00:00<00:00, 145.30it/s, train_loss=0.00266, val_loss=0.00335]Epoch 39:   7%|▋         | 2/27 [00:00<00:00, 171.01it/s, train_loss=0.00266, val_loss=0.00335]Epoch 39:   7%|▋         | 2/27 [00:00<00:00, 154.87it/s, train_loss=0.00276, val_loss=0.00335]Epoch 39:  11%|█         | 3/27 [00:00<00:00, 166.32it/s, train_loss=0.00276, val_loss=0.00335]Epoch 39:  11%|█         | 3/27 [00:00<00:00, 152.66it/s, train_loss=0.00317, val_loss=0.00335]Epoch 39:  15%|█▍        | 4/27 [00:00<00:00, 162.91it/s, train_loss=0.00317, val_loss=0.00335]Epoch 39:  15%|█▍        | 4/27 [00:00<00:00, 155.74it/s, train_loss=0.0029, val_loss=0.00335] Epoch 39:  19%|█▊        | 5/27 [00:00<00:00, 166.42it/s, train_loss=0.0029, val_loss=0.00335]Epoch 39:  19%|█▊        | 5/27 [00:00<00:00, 158.80it/s, train_loss=0.00253, val_loss=0.00335]Epoch 39:  22%|██▏       | 6/27 [00:00<00:00, 164.37it/s, train_loss=0.00253, val_loss=0.00335]Epoch 39:  22%|██▏       | 6/27 [00:00<00:00, 157.14it/s, train_loss=0.00247, val_loss=0.00335]Epoch 39:  26%|██▌       | 7/27 [00:00<00:00, 162.10it/s, train_loss=0.00247, val_loss=0.00335]Epoch 39:  26%|██▌       | 7/27 [00:00<00:00, 157.97it/s, train_loss=0.00301, val_loss=0.00335]Epoch 39:  30%|██▉       | 8/27 [00:00<00:00, 163.83it/s, train_loss=0.00301, val_loss=0.00335]Epoch 39:  30%|██▉       | 8/27 [00:00<00:00, 159.28it/s, train_loss=0.00349, val_loss=0.00335]Epoch 39:  33%|███▎      | 9/27 [00:00<00:00, 162.29it/s, train_loss=0.00349, val_loss=0.00335]Epoch 39:  33%|███▎      | 9/27 [00:00<00:00, 157.99it/s, train_loss=0.00279, val_loss=0.00335]Epoch 39:  37%|███▋      | 10/27 [00:00<00:00, 161.39it/s, train_loss=0.00279, val_loss=0.00335]Epoch 39:  37%|███▋      | 10/27 [00:00<00:00, 158.32it/s, train_loss=0.00301, val_loss=0.00335]Epoch 39:  41%|████      | 11/27 [00:00<00:00, 162.23it/s, train_loss=0.00301, val_loss=0.00335]Epoch 39:  41%|████      | 11/27 [00:00<00:00, 153.72it/s, train_loss=0.00321, val_loss=0.00335]Epoch 39:  44%|████▍     | 12/27 [00:00<00:00, 155.54it/s, train_loss=0.00321, val_loss=0.00335]Epoch 39:  44%|████▍     | 12/27 [00:00<00:00, 153.30it/s, train_loss=0.00283, val_loss=0.00335]Epoch 39:  48%|████▊     | 13/27 [00:00<00:00, 155.12it/s, train_loss=0.00283, val_loss=0.00335]Epoch 39:  48%|████▊     | 13/27 [00:00<00:00, 150.57it/s, train_loss=0.00261, val_loss=0.00335]Epoch 39:  52%|█████▏    | 14/27 [00:00<00:00, 152.56it/s, train_loss=0.00261, val_loss=0.00335]Epoch 39:  52%|█████▏    | 14/27 [00:00<00:00, 150.73it/s, train_loss=0.00288, val_loss=0.00335]Epoch 39:  56%|█████▌    | 15/27 [00:00<00:00, 153.89it/s, train_loss=0.00288, val_loss=0.00335]Epoch 39:  56%|█████▌    | 15/27 [00:00<00:00, 148.48it/s, train_loss=0.00299, val_loss=0.00335]Epoch 39:  59%|█████▉    | 16/27 [00:00<00:00, 151.04it/s, train_loss=0.00299, val_loss=0.00335]Epoch 39:  59%|█████▉    | 16/27 [00:00<00:00, 149.35it/s, train_loss=0.00294, val_loss=0.00335]Epoch 39:  63%|██████▎   | 17/27 [00:00<00:00, 152.29it/s, train_loss=0.00294, val_loss=0.00335]Epoch 39:  63%|██████▎   | 17/27 [00:00<00:00, 150.47it/s, train_loss=0.00282, val_loss=0.00335]Epoch 39:  67%|██████▋   | 18/27 [00:00<00:00, 152.84it/s, train_loss=0.00282, val_loss=0.00335]Epoch 39:  67%|██████▋   | 18/27 [00:00<00:00, 150.32it/s, train_loss=0.00289, val_loss=0.00335]Epoch 39:  70%|███████   | 19/27 [00:00<00:00, 152.60it/s, train_loss=0.00289, val_loss=0.00335]Epoch 39:  70%|███████   | 19/27 [00:00<00:00, 151.23it/s, train_loss=0.00354, val_loss=0.00335]Epoch 39:  74%|███████▍  | 20/27 [00:00<00:00, 153.84it/s, train_loss=0.00354, val_loss=0.00335]Epoch 39:  74%|███████▍  | 20/27 [00:00<00:00, 152.18it/s, train_loss=0.00281, val_loss=0.00335]Epoch 39:  78%|███████▊  | 21/27 [00:00<00:00, 153.92it/s, train_loss=0.00281, val_loss=0.00335]Epoch 39:  78%|███████▊  | 21/27 [00:00<00:00, 151.93it/s, train_loss=0.00296, val_loss=0.00335]Epoch 39:  81%|████████▏ | 22/27 [00:00<00:00, 153.82it/s, train_loss=0.00296, val_loss=0.00335]Epoch 39:  81%|████████▏ | 22/27 [00:00<00:00, 152.51it/s, train_loss=0.00312, val_loss=0.00335]Epoch 39:  85%|████████▌ | 23/27 [00:00<00:00, 154.82it/s, train_loss=0.00312, val_loss=0.00335]Epoch 39:  85%|████████▌ | 23/27 [00:00<00:00, 153.32it/s, train_loss=0.00286, val_loss=0.00335]Epoch 39:  89%|████████▉ | 24/27 [00:00<00:00, 154.84it/s, train_loss=0.00286, val_loss=0.00335]Epoch 39:  89%|████████▉ | 24/27 [00:00<00:00, 153.09it/s, train_loss=0.00267, val_loss=0.00335]Epoch 39:  93%|█████████▎| 25/27 [00:00<00:00, 154.66it/s, train_loss=0.00267, val_loss=0.00335]Epoch 39:  93%|█████████▎| 25/27 [00:00<00:00, 153.49it/s, train_loss=0.004, val_loss=0.00335]  Epoch 39:  96%|█████████▋| 26/27 [00:00<00:00, 155.52it/s, train_loss=0.004, val_loss=0.00335]Epoch 39:  96%|█████████▋| 26/27 [00:00<00:00, 154.14it/s, train_loss=0.00285, val_loss=0.00335]Epoch 39: 100%|██████████| 27/27 [00:00<00:00, 155.10it/s, train_loss=0.00285, val_loss=0.00335]Epoch 39: 100%|██████████| 27/27 [00:00<00:00, 153.94it/s, train_loss=0.00302, val_loss=0.00335]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 163.96it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 195.50it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 209.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 216.94it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 221.66it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 224.32it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 226.73it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 227.23it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 228.05it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 228.63it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 229.04it/s][A
                                                                         [AEpoch 39: 100%|██████████| 27/27 [00:00<00:00, 116.74it/s, train_loss=0.00302, val_loss=0.00335]Epoch 39: 100%|██████████| 27/27 [00:00<00:00, 116.42it/s, train_loss=0.00302, val_loss=0.00335]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 27/27 [00:00<00:00, 115.78it/s, train_loss=0.00302, val_loss=0.00335]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/27 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▎         | 1/27 [00:00<00:00, 264.86it/s]Predicting DataLoader 0:   7%|▋         | 2/27 [00:00<00:00, 207.76it/s]Predicting DataLoader 0:  11%|█         | 3/27 [00:00<00:00, 191.56it/s]Predicting DataLoader 0:  15%|█▍        | 4/27 [00:00<00:00, 184.99it/s]Predicting DataLoader 0:  19%|█▊        | 5/27 [00:00<00:00, 179.47it/s]Predicting DataLoader 0:  22%|██▏       | 6/27 [00:00<00:00, 175.69it/s]Predicting DataLoader 0:  26%|██▌       | 7/27 [00:00<00:00, 175.38it/s]Predicting DataLoader 0:  30%|██▉       | 8/27 [00:00<00:00, 174.91it/s]Predicting DataLoader 0:  33%|███▎      | 9/27 [00:00<00:00, 173.46it/s]Predicting DataLoader 0:  37%|███▋      | 10/27 [00:00<00:00, 173.44it/s]Predicting DataLoader 0:  41%|████      | 11/27 [00:00<00:00, 173.34it/s]Predicting DataLoader 0:  44%|████▍     | 12/27 [00:00<00:00, 172.07it/s]Predicting DataLoader 0:  48%|████▊     | 13/27 [00:00<00:00, 171.90it/s]Predicting DataLoader 0:  52%|█████▏    | 14/27 [00:00<00:00, 171.90it/s]Predicting DataLoader 0:  56%|█████▌    | 15/27 [00:00<00:00, 170.73it/s]Predicting DataLoader 0:  59%|█████▉    | 16/27 [00:00<00:00, 170.49it/s]Predicting DataLoader 0:  63%|██████▎   | 17/27 [00:00<00:00, 170.29it/s]Predicting DataLoader 0:  67%|██████▋   | 18/27 [00:00<00:00, 169.54it/s]Predicting DataLoader 0:  70%|███████   | 19/27 [00:00<00:00, 168.34it/s]Predicting DataLoader 0:  74%|███████▍  | 20/27 [00:00<00:00, 165.58it/s]Predicting DataLoader 0:  78%|███████▊  | 21/27 [00:00<00:00, 165.44it/s]Predicting DataLoader 0:  81%|████████▏ | 22/27 [00:00<00:00, 164.45it/s]Predicting DataLoader 0:  85%|████████▌ | 23/27 [00:00<00:00, 164.23it/s]Predicting DataLoader 0:  89%|████████▉ | 24/27 [00:00<00:00, 164.30it/s]Predicting DataLoader 0:  93%|█████████▎| 25/27 [00:00<00:00, 161.53it/s]Predicting DataLoader 0:  96%|█████████▋| 26/27 [00:00<00:00, 161.47it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 163.13it/s]Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 162.16it/s][I 2025-08-18 02:19:27,863] A new study created in memory with name: no-name-126b44cd-329d-4b0a-94c3-c7bae6d64b6c
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3999974970625667 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 32, Horizon length: 15
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.56it/s][I 2025-08-18 02:19:40,031] Trial 0 finished with value: 32.71111973119028 and parameters: {'hidden_dim': 47, 'n_rnn_layers': 1, 'dropout': 0.3999974970625667}. Best is trial 0 with value: 32.71111973119028.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.99it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.18it/s][I 2025-08-18 02:19:52,724] Trial 1 finished with value: 52.119555918386176 and parameters: {'hidden_dim': 42, 'n_rnn_layers': 3, 'dropout': 0.2199542752005712}. Best is trial 0 with value: 32.71111973119028.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.79it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.73it/s][I 2025-08-18 02:20:05,098] Trial 2 finished with value: 34.83399546273268 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 3, 'dropout': 0.21693207675170167}. Best is trial 0 with value: 32.71111973119028.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.86it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.57it/s][I 2025-08-18 02:20:23,992] Trial 3 finished with value: 30.330344734431424 and parameters: {'hidden_dim': 99, 'n_rnn_layers': 2, 'dropout': 0.3582265323386051}. Best is trial 3 with value: 30.330344734431424.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.75it/s][I 2025-08-18 02:20:35,267] Trial 4 finished with value: 31.410810667526206 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 2, 'dropout': 0.24991810600828407}. Best is trial 3 with value: 30.330344734431424.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.12it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.69it/s][I 2025-08-18 02:20:55,012] Trial 5 finished with value: 35.21759010948934 and parameters: {'hidden_dim': 101, 'n_rnn_layers': 4, 'dropout': 0.06268086948906187}. Best is trial 3 with value: 30.330344734431424.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1429097600765733 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.13it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.66it/s][I 2025-08-18 02:21:06,830] Trial 6 finished with value: 43.791642907824254 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 1, 'dropout': 0.1429097600765733}. Best is trial 3 with value: 30.330344734431424.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.11it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.37it/s][I 2025-08-18 02:21:28,598] Trial 7 finished with value: 32.144611998129314 and parameters: {'hidden_dim': 92, 'n_rnn_layers': 2, 'dropout': 0.026757859085579982}. Best is trial 3 with value: 30.330344734431424.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30169331245150083 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.88it/s][I 2025-08-18 02:21:42,970] Trial 8 finished with value: 46.08673252124352 and parameters: {'hidden_dim': 61, 'n_rnn_layers': 1, 'dropout': 0.30169331245150083}. Best is trial 3 with value: 30.330344734431424.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.55it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.22it/s][I 2025-08-18 02:21:57,641] Trial 9 finished with value: 29.73141215341388 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 4, 'dropout': 0.406210161100452}. Best is trial 9 with value: 29.73141215341388.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.91it/s][I 2025-08-18 02:22:12,899] Trial 10 finished with value: 40.87337964904121 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 4, 'dropout': 0.4947904306111012}. Best is trial 9 with value: 29.73141215341388.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.51it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.75it/s][I 2025-08-18 02:22:26,581] Trial 11 finished with value: 29.490324238004895 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 3, 'dropout': 0.37010387259450456}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.38it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.22it/s][I 2025-08-18 02:22:42,118] Trial 12 finished with value: 34.414038732815534 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 4, 'dropout': 0.45484614925837097}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.94it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.01it/s][I 2025-08-18 02:22:55,536] Trial 13 finished with value: 30.05790122578228 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 3, 'dropout': 0.36572785006909264}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.99it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.36it/s][I 2025-08-18 02:23:08,497] Trial 14 finished with value: 40.07975087305354 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.41477437793775673}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.31it/s][I 2025-08-18 02:23:21,009] Trial 15 finished with value: 30.919550588385487 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 3, 'dropout': 0.3130148553913068}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.72it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.00it/s][I 2025-08-18 02:23:34,687] Trial 16 finished with value: 34.15130902447864 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 4, 'dropout': 0.3168376033467512}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.41it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.34it/s][I 2025-08-18 02:23:56,015] Trial 17 finished with value: 31.55487856213423 and parameters: {'hidden_dim': 61, 'n_rnn_layers': 3, 'dropout': 0.49054213402074054}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.46it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.93it/s][I 2025-08-18 02:24:10,442] Trial 18 finished with value: 40.672167877083545 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 4, 'dropout': 0.41751015478388587}. Best is trial 11 with value: 29.490324238004895.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.34it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.40it/s][I 2025-08-18 02:24:24,825] Trial 19 finished with value: 25.818556301677503 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 3, 'dropout': 0.15211934125620602}. Best is trial 19 with value: 25.818556301677503.
[I 2025-08-18 02:24:24,825] A new study created in memory with name: no-name-5f4543b1-5592-4d5a-ae6e-3f44ca226ef8
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1782738321712316 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 34, 'n_rnn_layers': 3, 'dropout': 0.15211934125620602}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.89it/s][I 2025-08-18 02:24:38,099] Trial 0 finished with value: 36.61191803119238 and parameters: {'hidden_dim': 109, 'n_rnn_layers': 1, 'dropout': 0.1782738321712316}. Best is trial 0 with value: 36.61191803119238.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.79it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.35it/s][I 2025-08-18 02:24:47,258] Trial 1 finished with value: 31.50628012079382 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 2, 'dropout': 0.2106914821457775}. Best is trial 1 with value: 31.50628012079382.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.24it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.53it/s][I 2025-08-18 02:25:03,351] Trial 2 finished with value: 25.62668749109747 and parameters: {'hidden_dim': 68, 'n_rnn_layers': 4, 'dropout': 0.23799942554996417}. Best is trial 2 with value: 25.62668749109747.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.56it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.71it/s][I 2025-08-18 02:25:17,171] Trial 3 finished with value: 29.652611157048035 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 4, 'dropout': 0.16337869862730137}. Best is trial 2 with value: 25.62668749109747.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.87it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.46it/s][I 2025-08-18 02:25:32,572] Trial 4 finished with value: 29.67307004463009 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 3, 'dropout': 0.13329330341900625}. Best is trial 2 with value: 25.62668749109747.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.69it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.51it/s][I 2025-08-18 02:25:50,998] Trial 5 finished with value: 27.791700879355595 and parameters: {'hidden_dim': 57, 'n_rnn_layers': 4, 'dropout': 0.28792793254452664}. Best is trial 2 with value: 25.62668749109747.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.86it/s][I 2025-08-18 02:26:02,405] Trial 6 finished with value: 40.69735804838949 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 2, 'dropout': 0.14551957934367005}. Best is trial 2 with value: 25.62668749109747.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.90it/s][I 2025-08-18 02:26:18,187] Trial 7 finished with value: 23.444390710327532 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 4, 'dropout': 0.1505145729804872}. Best is trial 7 with value: 23.444390710327532.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37377908447986397 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.30it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.87it/s][I 2025-08-18 02:26:27,041] Trial 8 finished with value: 29.458522579330655 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 1, 'dropout': 0.37377908447986397}. Best is trial 7 with value: 23.444390710327532.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.07335690786574306 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.75it/s][I 2025-08-18 02:26:34,469] Trial 9 finished with value: 34.49979558658405 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 1, 'dropout': 0.07335690786574306}. Best is trial 7 with value: 23.444390710327532.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.79it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.04it/s][I 2025-08-18 02:26:53,771] Trial 10 finished with value: 29.31018620127186 and parameters: {'hidden_dim': 128, 'n_rnn_layers': 3, 'dropout': 0.005144871710359572}. Best is trial 7 with value: 23.444390710327532.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.57it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.33it/s][I 2025-08-18 02:27:13,064] Trial 11 finished with value: 22.991113509435515 and parameters: {'hidden_dim': 79, 'n_rnn_layers': 4, 'dropout': 0.4960187545454241}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.52it/s][I 2025-08-18 02:27:37,254] Trial 12 finished with value: 24.907415355080268 and parameters: {'hidden_dim': 88, 'n_rnn_layers': 3, 'dropout': 0.4850218967697301}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.73it/s][I 2025-08-18 02:27:55,339] Trial 13 finished with value: 31.95957941312262 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 4, 'dropout': 0.48547893621233484}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.60it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.95it/s][I 2025-08-18 02:28:10,451] Trial 14 finished with value: 23.385694280626957 and parameters: {'hidden_dim': 88, 'n_rnn_layers': 3, 'dropout': 0.35488796887430585}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.63it/s][I 2025-08-18 02:28:24,037] Trial 15 finished with value: 40.48803783795304 and parameters: {'hidden_dim': 43, 'n_rnn_layers': 3, 'dropout': 0.367584605926194}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.76it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.19it/s][I 2025-08-18 02:28:47,822] Trial 16 finished with value: 30.04939238560417 and parameters: {'hidden_dim': 93, 'n_rnn_layers': 2, 'dropout': 0.4066947242310622}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.74it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.87it/s][I 2025-08-18 02:29:06,519] Trial 17 finished with value: 23.56606059471909 and parameters: {'hidden_dim': 55, 'n_rnn_layers': 3, 'dropout': 0.3027262871612909}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.70it/s][I 2025-08-18 02:29:25,460] Trial 18 finished with value: 31.01813324974692 and parameters: {'hidden_dim': 104, 'n_rnn_layers': 4, 'dropout': 0.4432310749919988}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.16it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.52it/s][I 2025-08-18 02:29:44,903] Trial 19 finished with value: 33.941627218459324 and parameters: {'hidden_dim': 79, 'n_rnn_layers': 3, 'dropout': 0.2979993994308823}. Best is trial 11 with value: 22.991113509435515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 177 K  | train
6 | V               | Linear           | 80     | train
-------------------------------------------------------------
177 K     Trainable params
0         Non-trainable params
177 K     Total params
0.711     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 79, 'n_rnn_layers': 4, 'dropout': 0.4960187545454241}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 221.85it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 225.09it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/27 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s] Epoch 0:   4%|▎         | 1/27 [00:00<00:00, 80.44it/s]Epoch 0:   4%|▎         | 1/27 [00:00<00:00, 43.16it/s, train_loss=0.0824]Epoch 0:   7%|▋         | 2/27 [00:00<00:00, 61.27it/s, train_loss=0.0824]Epoch 0:   7%|▋         | 2/27 [00:00<00:00, 41.72it/s, train_loss=0.075] Epoch 0:  11%|█         | 3/27 [00:00<00:00, 52.12it/s, train_loss=0.075]Epoch 0:  11%|█         | 3/27 [00:00<00:00, 41.42it/s, train_loss=0.0937]Epoch 0:  15%|█▍        | 4/27 [00:00<00:00, 47.98it/s, train_loss=0.0937]Epoch 0:  15%|█▍        | 4/27 [00:00<00:00, 42.04it/s, train_loss=0.0779]Epoch 0:  19%|█▊        | 5/27 [00:00<00:00, 47.70it/s, train_loss=0.0779]Epoch 0:  19%|█▊        | 5/27 [00:00<00:00, 41.74it/s, train_loss=0.0813]Epoch 0:  22%|██▏       | 6/27 [00:00<00:00, 46.32it/s, train_loss=0.0813]Epoch 0:  22%|██▏       | 6/27 [00:00<00:00, 41.46it/s, train_loss=0.105] Epoch 0:  26%|██▌       | 7/27 [00:00<00:00, 45.24it/s, train_loss=0.105]Epoch 0:  26%|██▌       | 7/27 [00:00<00:00, 41.83it/s, train_loss=0.0913]Epoch 0:  30%|██▉       | 8/27 [00:00<00:00, 44.88it/s, train_loss=0.0913]Epoch 0:  30%|██▉       | 8/27 [00:00<00:00, 41.97it/s, train_loss=0.0772]Epoch 0:  33%|███▎      | 9/27 [00:00<00:00, 44.97it/s, train_loss=0.0772]Epoch 0:  33%|███▎      | 9/27 [00:00<00:00, 41.78it/s, train_loss=0.0611]Epoch 0:  37%|███▋      | 10/27 [00:00<00:00, 44.35it/s, train_loss=0.0611]Epoch 0:  37%|███▋      | 10/27 [00:00<00:00, 41.50it/s, train_loss=0.0627]Epoch 0:  41%|████      | 11/27 [00:00<00:00, 43.88it/s, train_loss=0.0627]Epoch 0:  41%|████      | 11/27 [00:00<00:00, 41.40it/s, train_loss=0.0719]Epoch 0:  44%|████▍     | 12/27 [00:00<00:00, 43.36it/s, train_loss=0.0719]Epoch 0:  44%|████▍     | 12/27 [00:00<00:00, 41.59it/s, train_loss=0.0745]Epoch 0:  48%|████▊     | 13/27 [00:00<00:00, 43.44it/s, train_loss=0.0745]Epoch 0:  48%|████▊     | 13/27 [00:00<00:00, 41.47it/s, train_loss=0.0781]Epoch 0:  52%|█████▏    | 14/27 [00:00<00:00, 43.32it/s, train_loss=0.0781]Epoch 0:  52%|█████▏    | 14/27 [00:00<00:00, 41.39it/s, train_loss=0.0647]Epoch 0:  56%|█████▌    | 15/27 [00:00<00:00, 43.10it/s, train_loss=0.0647]Epoch 0:  56%|█████▌    | 15/27 [00:00<00:00, 41.32it/s, train_loss=0.0748]Epoch 0:  59%|█████▉    | 16/27 [00:00<00:00, 42.89it/s, train_loss=0.0748]Epoch 0:  59%|█████▉    | 16/27 [00:00<00:00, 41.57it/s, train_loss=0.071] Epoch 0:  63%|██████▎   | 17/27 [00:00<00:00, 43.21it/s, train_loss=0.071]Epoch 0:  63%|██████▎   | 17/27 [00:00<00:00, 41.54it/s, train_loss=0.0785]Epoch 0:  67%|██████▋   | 18/27 [00:00<00:00, 42.94it/s, train_loss=0.0785]Epoch 0:  67%|██████▋   | 18/27 [00:00<00:00, 41.76it/s, train_loss=0.063] Epoch 0:  70%|███████   | 19/27 [00:00<00:00, 43.22it/s, train_loss=0.063]Epoch 0:  70%|███████   | 19/27 [00:00<00:00, 41.73it/s, train_loss=0.0743]Epoch 0:  74%|███████▍  | 20/27 [00:00<00:00, 43.00it/s, train_loss=0.0743]Epoch 0:  74%|███████▍  | 20/27 [00:00<00:00, 41.91it/s, train_loss=0.0578]Epoch 0:  78%|███████▊  | 21/27 [00:00<00:00, 43.11it/s, train_loss=0.0578]Epoch 0:  78%|███████▊  | 21/27 [00:00<00:00, 41.93it/s, train_loss=0.0565]Epoch 0:  81%|████████▏ | 22/27 [00:00<00:00, 43.18it/s, train_loss=0.0565]Epoch 0:  81%|████████▏ | 22/27 [00:00<00:00, 41.90it/s, train_loss=0.0434]Epoch 0:  85%|████████▌ | 23/27 [00:00<00:00, 42.98it/s, train_loss=0.0434]Epoch 0:  85%|████████▌ | 23/27 [00:00<00:00, 42.03it/s, train_loss=0.0582]Epoch 0:  89%|████████▉ | 24/27 [00:00<00:00, 43.05it/s, train_loss=0.0582]Epoch 0:  89%|████████▉ | 24/27 [00:00<00:00, 42.04it/s, train_loss=0.068] Epoch 0:  93%|█████████▎| 25/27 [00:00<00:00, 43.12it/s, train_loss=0.068]Epoch 0:  93%|█████████▎| 25/27 [00:00<00:00, 41.99it/s, train_loss=0.0571]Epoch 0:  96%|█████████▋| 26/27 [00:00<00:00, 42.99it/s, train_loss=0.0571]Epoch 0:  96%|█████████▋| 26/27 [00:00<00:00, 42.10it/s, train_loss=0.0449]Epoch 0: 100%|██████████| 27/27 [00:00<00:00, 42.94it/s, train_loss=0.0449]Epoch 0: 100%|██████████| 27/27 [00:00<00:00, 42.26it/s, train_loss=0.0402]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 135.87it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 155.07it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 162.26it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 165.02it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 167.17it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 168.30it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 168.38it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 170.03it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 170.95it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 171.41it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 172.64it/s][A
                                                                         [AEpoch 0: 100%|██████████| 27/27 [00:00<00:00, 37.33it/s, train_loss=0.0402, val_loss=0.0605]Epoch 0: 100%|██████████| 27/27 [00:00<00:00, 37.27it/s, train_loss=0.0402, val_loss=0.0605]Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0402, val_loss=0.0605]         Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0402, val_loss=0.0605]Epoch 1:   4%|▎         | 1/27 [00:00<00:00, 80.68it/s, train_loss=0.0402, val_loss=0.0605]Epoch 1:   4%|▎         | 1/27 [00:00<00:00, 37.85it/s, train_loss=0.0466, val_loss=0.0605]Epoch 1:   7%|▋         | 2/27 [00:00<00:00, 57.20it/s, train_loss=0.0466, val_loss=0.0605]Epoch 1:   7%|▋         | 2/27 [00:00<00:00, 39.75it/s, train_loss=0.0468, val_loss=0.0605]Epoch 1:  11%|█         | 3/27 [00:00<00:00, 49.82it/s, train_loss=0.0468, val_loss=0.0605]Epoch 1:  11%|█         | 3/27 [00:00<00:00, 41.57it/s, train_loss=0.0404, val_loss=0.0605]Epoch 1:  15%|█▍        | 4/27 [00:00<00:00, 49.57it/s, train_loss=0.0404, val_loss=0.0605]Epoch 1:  15%|█▍        | 4/27 [00:00<00:00, 41.62it/s, train_loss=0.0397, val_loss=0.0605]Epoch 1:  19%|█▊        | 5/27 [00:00<00:00, 46.92it/s, train_loss=0.0397, val_loss=0.0605]Epoch 1:  19%|█▊        | 5/27 [00:00<00:00, 42.33it/s, train_loss=0.0363, val_loss=0.0605]Epoch 1:  22%|██▏       | 6/27 [00:00<00:00, 46.24it/s, train_loss=0.0363, val_loss=0.0605]Epoch 1:  22%|██▏       | 6/27 [00:00<00:00, 41.79it/s, train_loss=0.0247, val_loss=0.0605]Epoch 1:  26%|██▌       | 7/27 [00:00<00:00, 45.93it/s, train_loss=0.0247, val_loss=0.0605]Epoch 1:  26%|██▌       | 7/27 [00:00<00:00, 41.68it/s, train_loss=0.0202, val_loss=0.0605]Epoch 1:  30%|██▉       | 8/27 [00:00<00:00, 44.97it/s, train_loss=0.0202, val_loss=0.0605]Epoch 1:  30%|██▉       | 8/27 [00:00<00:00, 42.13it/s, train_loss=0.0263, val_loss=0.0605]Epoch 1:  33%|███▎      | 9/27 [00:00<00:00, 45.01it/s, train_loss=0.0263, val_loss=0.0605]Epoch 1:  33%|███▎      | 9/27 [00:00<00:00, 42.06it/s, train_loss=0.0192, val_loss=0.0605]Epoch 1:  37%|███▋      | 10/27 [00:00<00:00, 44.89it/s, train_loss=0.0192, val_loss=0.0605]Epoch 1:  37%|███▋      | 10/27 [00:00<00:00, 41.94it/s, train_loss=0.0276, val_loss=0.0605]Epoch 1:  41%|████      | 11/27 [00:00<00:00, 44.46it/s, train_loss=0.0276, val_loss=0.0605]Epoch 1:  41%|████      | 11/27 [00:00<00:00, 42.22it/s, train_loss=0.0214, val_loss=0.0605]Epoch 1:  44%|████▍     | 12/27 [00:00<00:00, 44.33it/s, train_loss=0.0214, val_loss=0.0605]Epoch 1:  44%|████▍     | 12/27 [00:00<00:00, 42.31it/s, train_loss=0.0207, val_loss=0.0605]Epoch 1:  48%|████▊     | 13/27 [00:00<00:00, 44.45it/s, train_loss=0.0207, val_loss=0.0605]Epoch 1:  48%|████▊     | 13/27 [00:00<00:00, 42.21it/s, train_loss=0.0311, val_loss=0.0605]Epoch 1:  52%|█████▏    | 14/27 [00:00<00:00, 44.14it/s, train_loss=0.0311, val_loss=0.0605]Epoch 1:  52%|█████▏    | 14/27 [00:00<00:00, 42.39it/s, train_loss=0.0283, val_loss=0.0605]Epoch 1:  56%|█████▌    | 15/27 [00:00<00:00, 44.03it/s, train_loss=0.0283, val_loss=0.0605]Epoch 1:  56%|█████▌    | 15/27 [00:00<00:00, 42.46it/s, train_loss=0.0301, val_loss=0.0605]Epoch 1:  59%|█████▉    | 16/27 [00:00<00:00, 44.17it/s, train_loss=0.0301, val_loss=0.0605]Epoch 1:  59%|█████▉    | 16/27 [00:00<00:00, 42.34it/s, train_loss=0.026, val_loss=0.0605] Epoch 1:  63%|██████▎   | 17/27 [00:00<00:00, 43.91it/s, train_loss=0.026, val_loss=0.0605]Epoch 1:  63%|██████▎   | 17/27 [00:00<00:00, 42.48it/s, train_loss=0.0196, val_loss=0.0605]Epoch 1:  67%|██████▋   | 18/27 [00:00<00:00, 43.86it/s, train_loss=0.0196, val_loss=0.0605]Epoch 1:  67%|██████▋   | 18/27 [00:00<00:00, 42.53it/s, train_loss=0.021, val_loss=0.0605] Epoch 1:  70%|███████   | 19/27 [00:00<00:00, 43.91it/s, train_loss=0.021, val_loss=0.0605]Epoch 1:  70%|███████   | 19/27 [00:00<00:00, 42.42it/s, train_loss=0.0239, val_loss=0.0605]Epoch 1:  74%|███████▍  | 20/27 [00:00<00:00, 43.73it/s, train_loss=0.0239, val_loss=0.0605]Epoch 1:  74%|███████▍  | 20/27 [00:00<00:00, 42.33it/s, train_loss=0.0207, val_loss=0.0605]Epoch 1:  78%|███████▊  | 21/27 [00:00<00:00, 43.46it/s, train_loss=0.0207, val_loss=0.0605]Epoch 1:  78%|███████▊  | 21/27 [00:00<00:00, 42.41it/s, train_loss=0.0283, val_loss=0.0605]Epoch 1:  81%|████████▏ | 22/27 [00:00<00:00, 43.68it/s, train_loss=0.0283, val_loss=0.0605]Epoch 1:  81%|████████▏ | 22/27 [00:00<00:00, 42.36it/s, train_loss=0.0227, val_loss=0.0605]Epoch 1:  85%|████████▌ | 23/27 [00:00<00:00, 43.52it/s, train_loss=0.0227, val_loss=0.0605]Epoch 1:  85%|████████▌ | 23/27 [00:00<00:00, 42.48it/s, train_loss=0.0235, val_loss=0.0605]Epoch 1:  89%|████████▉ | 24/27 [00:00<00:00, 43.53it/s, train_loss=0.0235, val_loss=0.0605]Epoch 1:  89%|████████▉ | 24/27 [00:00<00:00, 42.50it/s, train_loss=0.0249, val_loss=0.0605]Epoch 1:  93%|█████████▎| 25/27 [00:00<00:00, 43.59it/s, train_loss=0.0249, val_loss=0.0605]Epoch 1:  93%|█████████▎| 25/27 [00:00<00:00, 42.45it/s, train_loss=0.0193, val_loss=0.0605]Epoch 1:  96%|█████████▋| 26/27 [00:00<00:00, 43.42it/s, train_loss=0.0193, val_loss=0.0605]Epoch 1:  96%|█████████▋| 26/27 [00:00<00:00, 42.56it/s, train_loss=0.0408, val_loss=0.0605]Epoch 1: 100%|██████████| 27/27 [00:00<00:00, 43.43it/s, train_loss=0.0408, val_loss=0.0605]Epoch 1: 100%|██████████| 27/27 [00:00<00:00, 42.66it/s, train_loss=0.0266, val_loss=0.0605]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 127.90it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 143.77it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 151.04it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 156.19it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 159.58it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 160.75it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 161.43it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 160.91it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 160.02it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 160.26it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 161.63it/s][A
                                                                         [AEpoch 1: 100%|██████████| 27/27 [00:00<00:00, 37.73it/s, train_loss=0.0266, val_loss=0.0317]Epoch 1: 100%|██████████| 27/27 [00:00<00:00, 37.67it/s, train_loss=0.0266, val_loss=0.0317]Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0266, val_loss=0.0317]         Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0266, val_loss=0.0317]Epoch 2:   4%|▎         | 1/27 [00:00<00:00, 74.81it/s, train_loss=0.0266, val_loss=0.0317]Epoch 2:   4%|▎         | 1/27 [00:00<00:00, 41.88it/s, train_loss=0.0276, val_loss=0.0317]Epoch 2:   7%|▋         | 2/27 [00:00<00:00, 57.14it/s, train_loss=0.0276, val_loss=0.0317]Epoch 2:   7%|▋         | 2/27 [00:00<00:00, 41.37it/s, train_loss=0.0364, val_loss=0.0317]Epoch 2:  11%|█         | 3/27 [00:00<00:00, 51.58it/s, train_loss=0.0364, val_loss=0.0317]Epoch 2:  11%|█         | 3/27 [00:00<00:00, 41.13it/s, train_loss=0.0226, val_loss=0.0317]Epoch 2:  15%|█▍        | 4/27 [00:00<00:00, 47.77it/s, train_loss=0.0226, val_loss=0.0317]Epoch 2:  15%|█▍        | 4/27 [00:00<00:00, 41.77it/s, train_loss=0.0154, val_loss=0.0317]Epoch 2:  19%|█▊        | 5/27 [00:00<00:00, 46.51it/s, train_loss=0.0154, val_loss=0.0317]Epoch 2:  19%|█▊        | 5/27 [00:00<00:00, 42.09it/s, train_loss=0.0297, val_loss=0.0317]Epoch 2:  22%|██▏       | 6/27 [00:00<00:00, 46.71it/s, train_loss=0.0297, val_loss=0.0317]Epoch 2:  22%|██▏       | 6/27 [00:00<00:00, 41.79it/s, train_loss=0.015, val_loss=0.0317] Epoch 2:  26%|██▌       | 7/27 [00:00<00:00, 45.71it/s, train_loss=0.015, val_loss=0.0317]Epoch 2:  26%|██▌       | 7/27 [00:00<00:00, 42.24it/s, train_loss=0.0197, val_loss=0.0317]Epoch 2:  30%|██▉       | 8/27 [00:00<00:00, 45.33it/s, train_loss=0.0197, val_loss=0.0317]Epoch 2:  30%|██▉       | 8/27 [00:00<00:00, 42.38it/s, train_loss=0.0222, val_loss=0.0317]Epoch 2:  33%|███▎      | 9/27 [00:00<00:00, 45.45it/s, train_loss=0.0222, val_loss=0.0317]Epoch 2:  33%|███▎      | 9/27 [00:00<00:00, 42.24it/s, train_loss=0.0227, val_loss=0.0317]Epoch 2:  37%|███▋      | 10/27 [00:00<00:00, 44.84it/s, train_loss=0.0227, val_loss=0.0317]Epoch 2:  37%|███▋      | 10/27 [00:00<00:00, 42.45it/s, train_loss=0.0188, val_loss=0.0317]Epoch 2:  41%|████      | 11/27 [00:00<00:00, 44.65it/s, train_loss=0.0188, val_loss=0.0317]Epoch 2:  41%|████      | 11/27 [00:00<00:00, 42.49it/s, train_loss=0.0138, val_loss=0.0317]Epoch 2:  44%|████▍     | 12/27 [00:00<00:00, 44.75it/s, train_loss=0.0138, val_loss=0.0317]Epoch 2:  44%|████▍     | 12/27 [00:00<00:00, 42.32it/s, train_loss=0.0191, val_loss=0.0317]Epoch 2:  48%|████▊     | 13/27 [00:00<00:00, 44.35it/s, train_loss=0.0191, val_loss=0.0317]Epoch 2:  48%|████▊     | 13/27 [00:00<00:00, 42.46it/s, train_loss=0.0245, val_loss=0.0317]Epoch 2:  52%|█████▏    | 14/27 [00:00<00:00, 44.09it/s, train_loss=0.0245, val_loss=0.0317]Epoch 2:  52%|█████▏    | 14/27 [00:00<00:00, 42.51it/s, train_loss=0.017, val_loss=0.0317] Epoch 2:  56%|█████▌    | 15/27 [00:00<00:00, 44.26it/s, train_loss=0.017, val_loss=0.0317]Epoch 2:  56%|█████▌    | 15/27 [00:00<00:00, 42.37it/s, train_loss=0.0355, val_loss=0.0317]Epoch 2:  59%|█████▉    | 16/27 [00:00<00:00, 43.99it/s, train_loss=0.0355, val_loss=0.0317]Epoch 2:  59%|█████▉    | 16/27 [00:00<00:00, 42.26it/s, train_loss=0.0207, val_loss=0.0317]Epoch 2:  63%|██████▎   | 17/27 [00:00<00:00, 43.64it/s, train_loss=0.0207, val_loss=0.0317]Epoch 2:  63%|██████▎   | 17/27 [00:00<00:00, 42.37it/s, train_loss=0.0175, val_loss=0.0317]Epoch 2:  67%|██████▋   | 18/27 [00:00<00:00, 43.71it/s, train_loss=0.0175, val_loss=0.0317]Epoch 2:  67%|██████▋   | 18/27 [00:00<00:00, 42.23it/s, train_loss=0.0263, val_loss=0.0317]Epoch 2:  70%|███████   | 19/27 [00:00<00:00, 43.61it/s, train_loss=0.0263, val_loss=0.0317]Epoch 2:  70%|███████   | 19/27 [00:00<00:00, 42.14it/s, train_loss=0.0178, val_loss=0.0317]Epoch 2:  74%|███████▍  | 20/27 [00:00<00:00, 43.43it/s, train_loss=0.0178, val_loss=0.0317]Epoch 2:  74%|███████▍  | 20/27 [00:00<00:00, 42.06it/s, train_loss=0.0299, val_loss=0.0317]Epoch 2:  78%|███████▊  | 21/27 [00:00<00:00, 43.09it/s, train_loss=0.0299, val_loss=0.0317]Epoch 2:  78%|███████▊  | 21/27 [00:00<00:00, 42.10it/s, train_loss=0.0238, val_loss=0.0317]Epoch 2:  81%|████████▏ | 22/27 [00:00<00:00, 43.18it/s, train_loss=0.0238, val_loss=0.0317]Epoch 2:  81%|████████▏ | 22/27 [00:00<00:00, 41.99it/s, train_loss=0.0199, val_loss=0.0317]Epoch 2:  85%|████████▌ | 23/27 [00:00<00:00, 43.12it/s, train_loss=0.0199, val_loss=0.0317]Epoch 2:  85%|████████▌ | 23/27 [00:00<00:00, 41.92it/s, train_loss=0.0232, val_loss=0.0317]Epoch 2:  89%|████████▉ | 24/27 [00:00<00:00, 42.98it/s, train_loss=0.0232, val_loss=0.0317]Epoch 2:  89%|████████▉ | 24/27 [00:00<00:00, 41.86it/s, train_loss=0.0291, val_loss=0.0317]Epoch 2:  93%|█████████▎| 25/27 [00:00<00:00, 42.75it/s, train_loss=0.0291, val_loss=0.0317]Epoch 2:  93%|█████████▎| 25/27 [00:00<00:00, 41.92it/s, train_loss=0.0148, val_loss=0.0317]Epoch 2:  96%|█████████▋| 26/27 [00:00<00:00, 42.82it/s, train_loss=0.0148, val_loss=0.0317]Epoch 2:  96%|█████████▋| 26/27 [00:00<00:00, 41.85it/s, train_loss=0.0201, val_loss=0.0317]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 27/27 [00:00<00:00, 42.78it/s, train_loss=0.0201, val_loss=0.0317]Epoch 2: 100%|██████████| 27/27 [00:00<00:00, 41.92it/s, train_loss=0.017, val_loss=0.0317] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 135.52it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 157.83it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 166.37it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 165.62it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 169.11it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 171.44it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 171.73it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 170.49it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 172.16it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 173.63it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 174.85it/s][A
                                                                         [AEpoch 2: 100%|██████████| 27/27 [00:00<00:00, 36.92it/s, train_loss=0.017, val_loss=0.0285]Epoch 2: 100%|██████████| 27/27 [00:00<00:00, 36.87it/s, train_loss=0.017, val_loss=0.0285]Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.017, val_loss=0.0285]         Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.017, val_loss=0.0285]Epoch 3:   4%|▎         | 1/27 [00:00<00:00, 88.09it/s, train_loss=0.017, val_loss=0.0285]Epoch 3:   4%|▎         | 1/27 [00:00<00:00, 43.32it/s, train_loss=0.0285, val_loss=0.0285]Epoch 3:   7%|▋         | 2/27 [00:00<00:00, 58.99it/s, train_loss=0.0285, val_loss=0.0285]Epoch 3:   7%|▋         | 2/27 [00:00<00:00, 42.53it/s, train_loss=0.0231, val_loss=0.0285]Epoch 3:  11%|█         | 3/27 [00:00<00:00, 53.10it/s, train_loss=0.0231, val_loss=0.0285]Epoch 3:  11%|█         | 3/27 [00:00<00:00, 41.84it/s, train_loss=0.0152, val_loss=0.0285]Epoch 3:  15%|█▍        | 4/27 [00:00<00:00, 49.07it/s, train_loss=0.0152, val_loss=0.0285]Epoch 3:  15%|█▍        | 4/27 [00:00<00:00, 41.51it/s, train_loss=0.022, val_loss=0.0285] Epoch 3:  19%|█▊        | 5/27 [00:00<00:00, 46.45it/s, train_loss=0.022, val_loss=0.0285]Epoch 3:  19%|█▊        | 5/27 [00:00<00:00, 41.93it/s, train_loss=0.0216, val_loss=0.0285]Epoch 3:  22%|██▏       | 6/27 [00:00<00:00, 46.13it/s, train_loss=0.0216, val_loss=0.0285]Epoch 3:  22%|██▏       | 6/27 [00:00<00:00, 41.61it/s, train_loss=0.0178, val_loss=0.0285]Epoch 3:  26%|██▌       | 7/27 [00:00<00:00, 45.50it/s, train_loss=0.0178, val_loss=0.0285]Epoch 3:  26%|██▌       | 7/27 [00:00<00:00, 41.37it/s, train_loss=0.0166, val_loss=0.0285]Epoch 3:  30%|██▉       | 8/27 [00:00<00:00, 44.69it/s, train_loss=0.0166, val_loss=0.0285]Epoch 3:  30%|██▉       | 8/27 [00:00<00:00, 41.23it/s, train_loss=0.0159, val_loss=0.0285]Epoch 3:  33%|███▎      | 9/27 [00:00<00:00, 43.95it/s, train_loss=0.0159, val_loss=0.0285]Epoch 3:  33%|███▎      | 9/27 [00:00<00:00, 41.50it/s, train_loss=0.0227, val_loss=0.0285]Epoch 3:  37%|███▋      | 10/27 [00:00<00:00, 44.24it/s, train_loss=0.0227, val_loss=0.0285]Epoch 3:  37%|███▋      | 10/27 [00:00<00:00, 41.42it/s, train_loss=0.0116, val_loss=0.0285]Epoch 3:  41%|████      | 11/27 [00:00<00:00, 43.87it/s, train_loss=0.0116, val_loss=0.0285]Epoch 3:  41%|████      | 11/27 [00:00<00:00, 41.68it/s, train_loss=0.0166, val_loss=0.0285]Epoch 3:  44%|████▍     | 12/27 [00:00<00:00, 43.71it/s, train_loss=0.0166, val_loss=0.0285]Epoch 3:  44%|████▍     | 12/27 [00:00<00:00, 41.79it/s, train_loss=0.0174, val_loss=0.0285]Epoch 3:  48%|████▊     | 13/27 [00:00<00:00, 43.89it/s, train_loss=0.0174, val_loss=0.0285]Epoch 3:  48%|████▊     | 13/27 [00:00<00:00, 41.74it/s, train_loss=0.0182, val_loss=0.0285]Epoch 3:  52%|█████▏    | 14/27 [00:00<00:00, 43.41it/s, train_loss=0.0182, val_loss=0.0285]Epoch 3:  52%|█████▏    | 14/27 [00:00<00:00, 41.87it/s, train_loss=0.0119, val_loss=0.0285]Epoch 3:  56%|█████▌    | 15/27 [00:00<00:00, 43.64it/s, train_loss=0.0119, val_loss=0.0285]Epoch 3:  56%|█████▌    | 15/27 [00:00<00:00, 41.80it/s, train_loss=0.0139, val_loss=0.0285]Epoch 3:  59%|█████▉    | 16/27 [00:00<00:00, 43.42it/s, train_loss=0.0139, val_loss=0.0285]Epoch 3:  59%|█████▉    | 16/27 [00:00<00:00, 41.94it/s, train_loss=0.0164, val_loss=0.0285]Epoch 3:  63%|██████▎   | 17/27 [00:00<00:00, 43.33it/s, train_loss=0.0164, val_loss=0.0285]Epoch 3:  63%|██████▎   | 17/27 [00:00<00:00, 41.98it/s, train_loss=0.0168, val_loss=0.0285]Epoch 3:  67%|██████▋   | 18/27 [00:00<00:00, 43.43it/s, train_loss=0.0168, val_loss=0.0285]Epoch 3:  67%|██████▋   | 18/27 [00:00<00:00, 41.87it/s, train_loss=0.0198, val_loss=0.0285]Epoch 3:  70%|███████   | 19/27 [00:00<00:00, 43.23it/s, train_loss=0.0198, val_loss=0.0285]Epoch 3:  70%|███████   | 19/27 [00:00<00:00, 41.97it/s, train_loss=0.0194, val_loss=0.0285]Epoch 3:  74%|███████▍  | 20/27 [00:00<00:00, 43.16it/s, train_loss=0.0194, val_loss=0.0285]Epoch 3:  74%|███████▍  | 20/27 [00:00<00:00, 42.03it/s, train_loss=0.0138, val_loss=0.0285]Epoch 3:  78%|███████▊  | 21/27 [00:00<00:00, 43.28it/s, train_loss=0.0138, val_loss=0.0285]Epoch 3:  78%|███████▊  | 21/27 [00:00<00:00, 41.95it/s, train_loss=0.015, val_loss=0.0285] Epoch 3:  81%|████████▏ | 22/27 [00:00<00:00, 43.04it/s, train_loss=0.015, val_loss=0.0285]Epoch 3:  81%|████████▏ | 22/27 [00:00<00:00, 41.85it/s, train_loss=0.0156, val_loss=0.0285]Epoch 3:  85%|████████▌ | 23/27 [00:00<00:00, 42.86it/s, train_loss=0.0156, val_loss=0.0285]Epoch 3:  85%|████████▌ | 23/27 [00:00<00:00, 41.89it/s, train_loss=0.0139, val_loss=0.0285]Epoch 3:  89%|████████▉ | 24/27 [00:00<00:00, 42.96it/s, train_loss=0.0139, val_loss=0.0285]Epoch 3:  89%|████████▉ | 24/27 [00:00<00:00, 41.82it/s, train_loss=0.016, val_loss=0.0285] Epoch 3:  93%|█████████▎| 25/27 [00:00<00:00, 42.84it/s, train_loss=0.016, val_loss=0.0285]Epoch 3:  93%|█████████▎| 25/27 [00:00<00:00, 41.77it/s, train_loss=0.00975, val_loss=0.0285]Epoch 3:  96%|█████████▋| 26/27 [00:00<00:00, 42.59it/s, train_loss=0.00975, val_loss=0.0285]Epoch 3:  96%|█████████▋| 26/27 [00:00<00:00, 41.79it/s, train_loss=0.0139, val_loss=0.0285] Epoch 3: 100%|██████████| 27/27 [00:00<00:00, 42.65it/s, train_loss=0.0139, val_loss=0.0285]Epoch 3: 100%|██████████| 27/27 [00:00<00:00, 41.84it/s, train_loss=0.0133, val_loss=0.0285]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 148.64it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 166.29it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 180.23it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 185.85it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 190.27it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 193.20it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 194.00it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 192.70it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 191.12it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 190.99it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 192.06it/s][A
                                                                         [AEpoch 3: 100%|██████████| 27/27 [00:00<00:00, 37.13it/s, train_loss=0.0133, val_loss=0.0117]Epoch 3: 100%|██████████| 27/27 [00:00<00:00, 37.09it/s, train_loss=0.0133, val_loss=0.0117]Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0133, val_loss=0.0117]         Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0133, val_loss=0.0117]Epoch 4:   4%|▎         | 1/27 [00:00<00:00, 84.17it/s, train_loss=0.0133, val_loss=0.0117]Epoch 4:   4%|▎         | 1/27 [00:00<00:00, 42.63it/s, train_loss=0.0104, val_loss=0.0117]Epoch 4:   7%|▋         | 2/27 [00:00<00:00, 59.74it/s, train_loss=0.0104, val_loss=0.0117]Epoch 4:   7%|▋         | 2/27 [00:00<00:00, 41.88it/s, train_loss=0.0102, val_loss=0.0117]Epoch 4:  11%|█         | 3/27 [00:00<00:00, 52.61it/s, train_loss=0.0102, val_loss=0.0117]Epoch 4:  11%|█         | 3/27 [00:00<00:00, 41.34it/s, train_loss=0.00979, val_loss=0.0117]Epoch 4:  15%|█▍        | 4/27 [00:00<00:00, 47.89it/s, train_loss=0.00979, val_loss=0.0117]Epoch 4:  15%|█▍        | 4/27 [00:00<00:00, 41.89it/s, train_loss=0.016, val_loss=0.0117]  Epoch 4:  19%|█▊        | 5/27 [00:00<00:00, 46.73it/s, train_loss=0.016, val_loss=0.0117]Epoch 4:  19%|█▊        | 5/27 [00:00<00:00, 42.00it/s, train_loss=0.0158, val_loss=0.0117]Epoch 4:  22%|██▏       | 6/27 [00:00<00:00, 46.71it/s, train_loss=0.0158, val_loss=0.0117]Epoch 4:  22%|██▏       | 6/27 [00:00<00:00, 41.76it/s, train_loss=0.00996, val_loss=0.0117]Epoch 4:  26%|██▌       | 7/27 [00:00<00:00, 45.60it/s, train_loss=0.00996, val_loss=0.0117]Epoch 4:  26%|██▌       | 7/27 [00:00<00:00, 41.99it/s, train_loss=0.0127, val_loss=0.0117] Epoch 4:  30%|██▉       | 8/27 [00:00<00:00, 44.99it/s, train_loss=0.0127, val_loss=0.0117]Epoch 4:  30%|██▉       | 8/27 [00:00<00:00, 42.22it/s, train_loss=0.011, val_loss=0.0117] Epoch 4:  33%|███▎      | 9/27 [00:00<00:00, 45.16it/s, train_loss=0.011, val_loss=0.0117]Epoch 4:  33%|███▎      | 9/27 [00:00<00:00, 41.87it/s, train_loss=0.0116, val_loss=0.0117]Epoch 4:  37%|███▋      | 10/27 [00:00<00:00, 44.49it/s, train_loss=0.0116, val_loss=0.0117]Epoch 4:  37%|███▋      | 10/27 [00:00<00:00, 41.65it/s, train_loss=0.0101, val_loss=0.0117]Epoch 4:  41%|████      | 11/27 [00:00<00:00, 43.67it/s, train_loss=0.0101, val_loss=0.0117]Epoch 4:  41%|████      | 11/27 [00:00<00:00, 41.79it/s, train_loss=0.0115, val_loss=0.0117]Epoch 4:  44%|████▍     | 12/27 [00:00<00:00, 43.98it/s, train_loss=0.0115, val_loss=0.0117]Epoch 4:  44%|████▍     | 12/27 [00:00<00:00, 41.65it/s, train_loss=0.00973, val_loss=0.0117]Epoch 4:  48%|████▊     | 13/27 [00:00<00:00, 43.64it/s, train_loss=0.00973, val_loss=0.0117]Epoch 4:  48%|████▊     | 13/27 [00:00<00:00, 41.52it/s, train_loss=0.00973, val_loss=0.0117]Epoch 4:  52%|█████▏    | 14/27 [00:00<00:00, 43.41it/s, train_loss=0.00973, val_loss=0.0117]Epoch 4:  52%|█████▏    | 14/27 [00:00<00:00, 41.70it/s, train_loss=0.00878, val_loss=0.0117]Epoch 4:  56%|█████▌    | 15/27 [00:00<00:00, 43.24it/s, train_loss=0.00878, val_loss=0.0117]Epoch 4:  56%|█████▌    | 15/27 [00:00<00:00, 41.79it/s, train_loss=0.0105, val_loss=0.0117] Epoch 4:  59%|█████▉    | 16/27 [00:00<00:00, 43.38it/s, train_loss=0.0105, val_loss=0.0117]Epoch 4:  59%|█████▉    | 16/27 [00:00<00:00, 41.62it/s, train_loss=0.0107, val_loss=0.0117]Epoch 4:  63%|██████▎   | 17/27 [00:00<00:00, 43.08it/s, train_loss=0.0107, val_loss=0.0117]Epoch 4:  63%|██████▎   | 17/27 [00:00<00:00, 41.57it/s, train_loss=0.00809, val_loss=0.0117]Epoch 4:  67%|██████▋   | 18/27 [00:00<00:00, 42.82it/s, train_loss=0.00809, val_loss=0.0117]Epoch 4:  67%|██████▋   | 18/27 [00:00<00:00, 41.68it/s, train_loss=0.00972, val_loss=0.0117]Epoch 4:  70%|███████   | 19/27 [00:00<00:00, 43.10it/s, train_loss=0.00972, val_loss=0.0117]Epoch 4:  70%|███████   | 19/27 [00:00<00:00, 41.62it/s, train_loss=0.00772, val_loss=0.0117]Epoch 4:  74%|███████▍  | 20/27 [00:00<00:00, 42.86it/s, train_loss=0.00772, val_loss=0.0117]Epoch 4:  74%|███████▍  | 20/27 [00:00<00:00, 41.73it/s, train_loss=0.00794, val_loss=0.0117]Epoch 4:  78%|███████▊  | 21/27 [00:00<00:00, 42.81it/s, train_loss=0.00794, val_loss=0.0117]Epoch 4:  78%|███████▊  | 21/27 [00:00<00:00, 41.80it/s, train_loss=0.00906, val_loss=0.0117]Epoch 4:  81%|████████▏ | 22/27 [00:00<00:00, 43.01it/s, train_loss=0.00906, val_loss=0.0117]Epoch 4:  81%|████████▏ | 22/27 [00:00<00:00, 41.74it/s, train_loss=0.00903, val_loss=0.0117]Epoch 4:  85%|████████▌ | 23/27 [00:00<00:00, 42.80it/s, train_loss=0.00903, val_loss=0.0117]Epoch 4:  85%|████████▌ | 23/27 [00:00<00:00, 41.83it/s, train_loss=0.0082, val_loss=0.0117] Epoch 4:  89%|████████▉ | 24/27 [00:00<00:00, 42.77it/s, train_loss=0.0082, val_loss=0.0117]Epoch 4:  89%|████████▉ | 24/27 [00:00<00:00, 41.83it/s, train_loss=0.00849, val_loss=0.0117]Epoch 4:  93%|█████████▎| 25/27 [00:00<00:00, 42.86it/s, train_loss=0.00849, val_loss=0.0117]Epoch 4:  93%|█████████▎| 25/27 [00:00<00:00, 41.76it/s, train_loss=0.00773, val_loss=0.0117]Epoch 4:  96%|█████████▋| 26/27 [00:00<00:00, 42.74it/s, train_loss=0.00773, val_loss=0.0117]Epoch 4:  96%|█████████▋| 26/27 [00:00<00:00, 41.69it/s, train_loss=0.00847, val_loss=0.0117]Epoch 4: 100%|██████████| 27/27 [00:00<00:00, 42.53it/s, train_loss=0.00847, val_loss=0.0117]Epoch 4: 100%|██████████| 27/27 [00:00<00:00, 41.87it/s, train_loss=0.0058, val_loss=0.0117] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 113.94it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 130.50it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 142.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 148.85it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 151.87it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 154.04it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 155.77it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 157.86it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 161.51it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 165.66it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 169.48it/s][A
                                                                         [AEpoch 4: 100%|██████████| 27/27 [00:00<00:00, 36.94it/s, train_loss=0.0058, val_loss=0.00873]Epoch 4: 100%|██████████| 27/27 [00:00<00:00, 36.90it/s, train_loss=0.0058, val_loss=0.00873]Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0058, val_loss=0.00873]         Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0058, val_loss=0.00873]Epoch 5:   4%|▎         | 1/27 [00:00<00:00, 84.38it/s, train_loss=0.0058, val_loss=0.00873]Epoch 5:   4%|▎         | 1/27 [00:00<00:00, 42.81it/s, train_loss=0.00634, val_loss=0.00873]Epoch 5:   7%|▋         | 2/27 [00:00<00:00, 54.02it/s, train_loss=0.00634, val_loss=0.00873]Epoch 5:   7%|▋         | 2/27 [00:00<00:00, 41.31it/s, train_loss=0.011, val_loss=0.00873]  Epoch 5:  11%|█         | 3/27 [00:00<00:00, 52.00it/s, train_loss=0.011, val_loss=0.00873]Epoch 5:  11%|█         | 3/27 [00:00<00:00, 41.00it/s, train_loss=0.00903, val_loss=0.00873]Epoch 5:  15%|█▍        | 4/27 [00:00<00:00, 48.08it/s, train_loss=0.00903, val_loss=0.00873]Epoch 5:  15%|█▍        | 4/27 [00:00<00:00, 40.64it/s, train_loss=0.00734, val_loss=0.00873]Epoch 5:  19%|█▊        | 5/27 [00:00<00:00, 45.76it/s, train_loss=0.00734, val_loss=0.00873]Epoch 5:  19%|█▊        | 5/27 [00:00<00:00, 41.22it/s, train_loss=0.00846, val_loss=0.00873]Epoch 5:  22%|██▏       | 6/27 [00:00<00:00, 45.16it/s, train_loss=0.00846, val_loss=0.00873]Epoch 5:  22%|██▏       | 6/27 [00:00<00:00, 41.40it/s, train_loss=0.00934, val_loss=0.00873]Epoch 5:  26%|██▌       | 7/27 [00:00<00:00, 45.33it/s, train_loss=0.00934, val_loss=0.00873]Epoch 5:  26%|██▌       | 7/27 [00:00<00:00, 41.14it/s, train_loss=0.0081, val_loss=0.00873] Epoch 5:  30%|██▉       | 8/27 [00:00<00:00, 44.49it/s, train_loss=0.0081, val_loss=0.00873]Epoch 5:  30%|██▉       | 8/27 [00:00<00:00, 41.01it/s, train_loss=0.0086, val_loss=0.00873]Epoch 5:  33%|███▎      | 9/27 [00:00<00:00, 43.59it/s, train_loss=0.0086, val_loss=0.00873]Epoch 5:  33%|███▎      | 9/27 [00:00<00:00, 41.17it/s, train_loss=0.0071, val_loss=0.00873]Epoch 5:  37%|███▋      | 10/27 [00:00<00:00, 43.50it/s, train_loss=0.0071, val_loss=0.00873]Epoch 5:  37%|███▋      | 10/27 [00:00<00:00, 41.34it/s, train_loss=0.00758, val_loss=0.00873]Epoch 5:  41%|████      | 11/27 [00:00<00:00, 43.77it/s, train_loss=0.00758, val_loss=0.00873]Epoch 5:  41%|████      | 11/27 [00:00<00:00, 41.24it/s, train_loss=0.00728, val_loss=0.00873]Epoch 5:  44%|████▍     | 12/27 [00:00<00:00, 43.39it/s, train_loss=0.00728, val_loss=0.00873]Epoch 5:  44%|████▍     | 12/27 [00:00<00:00, 41.09it/s, train_loss=0.00845, val_loss=0.00873]Epoch 5:  48%|████▊     | 13/27 [00:00<00:00, 42.88it/s, train_loss=0.00845, val_loss=0.00873]Epoch 5:  48%|████▊     | 13/27 [00:00<00:00, 41.22it/s, train_loss=0.00887, val_loss=0.00873]Epoch 5:  52%|█████▏    | 14/27 [00:00<00:00, 42.90it/s, train_loss=0.00887, val_loss=0.00873]Epoch 5:  52%|█████▏    | 14/27 [00:00<00:00, 41.38it/s, train_loss=0.00684, val_loss=0.00873]Epoch 5:  56%|█████▌    | 15/27 [00:00<00:00, 43.12it/s, train_loss=0.00684, val_loss=0.00873]Epoch 5:  56%|█████▌    | 15/27 [00:00<00:00, 41.27it/s, train_loss=0.00772, val_loss=0.00873]Epoch 5:  59%|█████▉    | 16/27 [00:00<00:00, 42.83it/s, train_loss=0.00772, val_loss=0.00873]Epoch 5:  59%|█████▉    | 16/27 [00:00<00:00, 41.15it/s, train_loss=0.00657, val_loss=0.00873]Epoch 5:  63%|██████▎   | 17/27 [00:00<00:00, 42.57it/s, train_loss=0.00657, val_loss=0.00873]Epoch 5:  63%|██████▎   | 17/27 [00:00<00:00, 41.31it/s, train_loss=0.00587, val_loss=0.00873]Epoch 5:  67%|██████▋   | 18/27 [00:00<00:00, 42.56it/s, train_loss=0.00587, val_loss=0.00873]Epoch 5:  67%|██████▋   | 18/27 [00:00<00:00, 41.38it/s, train_loss=0.0064, val_loss=0.00873] Epoch 5:  70%|███████   | 19/27 [00:00<00:00, 42.76it/s, train_loss=0.0064, val_loss=0.00873]Epoch 5:  70%|███████   | 19/27 [00:00<00:00, 41.33it/s, train_loss=0.00766, val_loss=0.00873]Epoch 5:  74%|███████▍  | 20/27 [00:00<00:00, 42.60it/s, train_loss=0.00766, val_loss=0.00873]Epoch 5:  74%|███████▍  | 20/27 [00:00<00:00, 41.22it/s, train_loss=0.00823, val_loss=0.00873]Epoch 5:  78%|███████▊  | 21/27 [00:00<00:00, 42.33it/s, train_loss=0.00823, val_loss=0.00873]Epoch 5:  78%|███████▊  | 21/27 [00:00<00:00, 41.30it/s, train_loss=0.00735, val_loss=0.00873]Epoch 5:  81%|████████▏ | 22/27 [00:00<00:00, 42.30it/s, train_loss=0.00735, val_loss=0.00873]Epoch 5:  81%|████████▏ | 22/27 [00:00<00:00, 41.39it/s, train_loss=0.00735, val_loss=0.00873]Epoch 5:  85%|████████▌ | 23/27 [00:00<00:00, 42.53it/s, train_loss=0.00735, val_loss=0.00873]Epoch 5:  85%|████████▌ | 23/27 [00:00<00:00, 41.35it/s, train_loss=0.00712, val_loss=0.00873]Epoch 5:  89%|████████▉ | 24/27 [00:00<00:00, 42.40it/s, train_loss=0.00712, val_loss=0.00873]Epoch 5:  89%|████████▉ | 24/27 [00:00<00:00, 41.27it/s, train_loss=0.00812, val_loss=0.00873]Epoch 5:  93%|█████████▎| 25/27 [00:00<00:00, 42.18it/s, train_loss=0.00812, val_loss=0.00873]Epoch 5:  93%|█████████▎| 25/27 [00:00<00:00, 41.35it/s, train_loss=0.00662, val_loss=0.00873]Epoch 5:  96%|█████████▋| 26/27 [00:00<00:00, 42.24it/s, train_loss=0.00662, val_loss=0.00873]Epoch 5:  96%|█████████▋| 26/27 [00:00<00:00, 41.42it/s, train_loss=0.00746, val_loss=0.00873]Epoch 5: 100%|██████████| 27/27 [00:00<00:00, 42.24it/s, train_loss=0.00746, val_loss=0.00873]Epoch 5: 100%|██████████| 27/27 [00:00<00:00, 41.43it/s, train_loss=0.00579, val_loss=0.00873]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 116.90it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 136.05it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 147.70it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 154.40it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 158.17it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 161.04it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 160.29it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 160.41it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 161.58it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 162.78it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 163.99it/s][A
                                                                         [AEpoch 5: 100%|██████████| 27/27 [00:00<00:00, 36.61it/s, train_loss=0.00579, val_loss=0.00693]Epoch 5: 100%|██████████| 27/27 [00:00<00:00, 36.56it/s, train_loss=0.00579, val_loss=0.00693]Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00579, val_loss=0.00693]         Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00579, val_loss=0.00693]Epoch 6:   4%|▎         | 1/27 [00:00<00:00, 83.68it/s, train_loss=0.00579, val_loss=0.00693]Epoch 6:   4%|▎         | 1/27 [00:00<00:00, 38.35it/s, train_loss=0.00705, val_loss=0.00693]Epoch 6:   7%|▋         | 2/27 [00:00<00:00, 56.27it/s, train_loss=0.00705, val_loss=0.00693]Epoch 6:   7%|▋         | 2/27 [00:00<00:00, 40.69it/s, train_loss=0.00563, val_loss=0.00693]Epoch 6:  11%|█         | 3/27 [00:00<00:00, 50.07it/s, train_loss=0.00563, val_loss=0.00693]Epoch 6:  11%|█         | 3/27 [00:00<00:00, 41.47it/s, train_loss=0.0076, val_loss=0.00693] Epoch 6:  15%|█▍        | 4/27 [00:00<00:00, 49.14it/s, train_loss=0.0076, val_loss=0.00693]Epoch 6:  15%|█▍        | 4/27 [00:00<00:00, 41.25it/s, train_loss=0.00701, val_loss=0.00693]Epoch 6:  19%|█▊        | 5/27 [00:00<00:00, 46.35it/s, train_loss=0.00701, val_loss=0.00693]Epoch 6:  19%|█▊        | 5/27 [00:00<00:00, 41.76it/s, train_loss=0.00619, val_loss=0.00693]Epoch 6:  22%|██▏       | 6/27 [00:00<00:00, 45.79it/s, train_loss=0.00619, val_loss=0.00693]Epoch 6:  22%|██▏       | 6/27 [00:00<00:00, 41.88it/s, train_loss=0.00665, val_loss=0.00693]Epoch 6:  26%|██▌       | 7/27 [00:00<00:00, 45.88it/s, train_loss=0.00665, val_loss=0.00693]Epoch 6:  26%|██▌       | 7/27 [00:00<00:00, 41.66it/s, train_loss=0.00733, val_loss=0.00693]Epoch 6:  30%|██▉       | 8/27 [00:00<00:00, 44.99it/s, train_loss=0.00733, val_loss=0.00693]Epoch 6:  30%|██▉       | 8/27 [00:00<00:00, 41.39it/s, train_loss=0.00608, val_loss=0.00693]Epoch 6:  33%|███▎      | 9/27 [00:00<00:00, 44.04it/s, train_loss=0.00608, val_loss=0.00693]Epoch 6:  33%|███▎      | 9/27 [00:00<00:00, 41.59it/s, train_loss=0.00679, val_loss=0.00693]Epoch 6:  37%|███▋      | 10/27 [00:00<00:00, 43.86it/s, train_loss=0.00679, val_loss=0.00693]Epoch 6:  37%|███▋      | 10/27 [00:00<00:00, 41.68it/s, train_loss=0.00516, val_loss=0.00693]Epoch 6:  41%|████      | 11/27 [00:00<00:00, 44.17it/s, train_loss=0.00516, val_loss=0.00693]Epoch 6:  41%|████      | 11/27 [00:00<00:00, 41.54it/s, train_loss=0.00573, val_loss=0.00693]Epoch 6:  44%|████▍     | 12/27 [00:00<00:00, 43.73it/s, train_loss=0.00573, val_loss=0.00693]Epoch 6:  44%|████▍     | 12/27 [00:00<00:00, 41.38it/s, train_loss=0.00487, val_loss=0.00693]Epoch 6:  48%|████▊     | 13/27 [00:00<00:00, 43.17it/s, train_loss=0.00487, val_loss=0.00693]Epoch 6:  48%|████▊     | 13/27 [00:00<00:00, 41.53it/s, train_loss=0.00526, val_loss=0.00693]Epoch 6:  52%|█████▏    | 14/27 [00:00<00:00, 43.21it/s, train_loss=0.00526, val_loss=0.00693]Epoch 6:  52%|█████▏    | 14/27 [00:00<00:00, 41.64it/s, train_loss=0.00771, val_loss=0.00693]Epoch 6:  56%|█████▌    | 15/27 [00:00<00:00, 43.40it/s, train_loss=0.00771, val_loss=0.00693]Epoch 6:  56%|█████▌    | 15/27 [00:00<00:00, 41.53it/s, train_loss=0.00586, val_loss=0.00693]Epoch 6:  59%|█████▉    | 16/27 [00:00<00:00, 42.80it/s, train_loss=0.00586, val_loss=0.00693]Epoch 6:  59%|█████▉    | 16/27 [00:00<00:00, 41.23it/s, train_loss=0.0058, val_loss=0.00693] Epoch 6:  63%|██████▎   | 17/27 [00:00<00:00, 42.75it/s, train_loss=0.0058, val_loss=0.00693]Epoch 6:  63%|██████▎   | 17/27 [00:00<00:00, 41.12it/s, train_loss=0.00679, val_loss=0.00693]Epoch 6:  67%|██████▋   | 18/27 [00:00<00:00, 42.52it/s, train_loss=0.00679, val_loss=0.00693]Epoch 6:  67%|██████▋   | 18/27 [00:00<00:00, 41.02it/s, train_loss=0.00602, val_loss=0.00693]Epoch 6:  70%|███████   | 19/27 [00:00<00:00, 42.35it/s, train_loss=0.00602, val_loss=0.00693]Epoch 6:  70%|███████   | 19/27 [00:00<00:00, 40.95it/s, train_loss=0.00558, val_loss=0.00693]Epoch 6:  74%|███████▍  | 20/27 [00:00<00:00, 42.09it/s, train_loss=0.00558, val_loss=0.00693]Epoch 6:  74%|███████▍  | 20/27 [00:00<00:00, 41.04it/s, train_loss=0.00561, val_loss=0.00693]Epoch 6:  78%|███████▊  | 21/27 [00:00<00:00, 42.04it/s, train_loss=0.00561, val_loss=0.00693]Epoch 6:  78%|███████▊  | 21/27 [00:00<00:00, 41.15it/s, train_loss=0.00644, val_loss=0.00693]Epoch 6:  81%|████████▏ | 22/27 [00:00<00:00, 42.36it/s, train_loss=0.00644, val_loss=0.00693]Epoch 6:  81%|████████▏ | 22/27 [00:00<00:00, 41.14it/s, train_loss=0.00637, val_loss=0.00693]Epoch 6:  85%|████████▌ | 23/27 [00:00<00:00, 42.14it/s, train_loss=0.00637, val_loss=0.00693]Epoch 6:  85%|████████▌ | 23/27 [00:00<00:00, 41.25it/s, train_loss=0.00485, val_loss=0.00693]Epoch 6:  89%|████████▉ | 24/27 [00:00<00:00, 42.18it/s, train_loss=0.00485, val_loss=0.00693]Epoch 6:  89%|████████▉ | 24/27 [00:00<00:00, 41.30it/s, train_loss=0.00569, val_loss=0.00693]Epoch 6:  93%|█████████▎| 25/27 [00:00<00:00, 42.37it/s, train_loss=0.00569, val_loss=0.00693]Epoch 6:  93%|█████████▎| 25/27 [00:00<00:00, 41.27it/s, train_loss=0.00553, val_loss=0.00693]Epoch 6:  96%|█████████▋| 26/27 [00:00<00:00, 42.25it/s, train_loss=0.00553, val_loss=0.00693]Epoch 6:  96%|█████████▋| 26/27 [00:00<00:00, 41.18it/s, train_loss=0.00532, val_loss=0.00693]Epoch 6: 100%|██████████| 27/27 [00:00<00:00, 41.99it/s, train_loss=0.00532, val_loss=0.00693]Epoch 6: 100%|██████████| 27/27 [00:00<00:00, 41.37it/s, train_loss=0.00569, val_loss=0.00693]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 127.44it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 147.60it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 157.66it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 162.34it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 160.63it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 160.69it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 163.04it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 165.27it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 167.16it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 168.23it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 169.63it/s][A
                                                                         [AEpoch 6: 100%|██████████| 27/27 [00:00<00:00, 36.61it/s, train_loss=0.00569, val_loss=0.00561]Epoch 6: 100%|██████████| 27/27 [00:00<00:00, 36.54it/s, train_loss=0.00569, val_loss=0.00561]Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00569, val_loss=0.00561]         Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00569, val_loss=0.00561]Epoch 7:   4%|▎         | 1/27 [00:00<00:00, 79.30it/s, train_loss=0.00569, val_loss=0.00561]Epoch 7:   4%|▎         | 1/27 [00:00<00:00, 38.83it/s, train_loss=0.00584, val_loss=0.00561]Epoch 7:   7%|▋         | 2/27 [00:00<00:00, 56.65it/s, train_loss=0.00584, val_loss=0.00561]Epoch 7:   7%|▋         | 2/27 [00:00<00:00, 39.37it/s, train_loss=0.00718, val_loss=0.00561]Epoch 7:  11%|█         | 3/27 [00:00<00:00, 49.42it/s, train_loss=0.00718, val_loss=0.00561]Epoch 7:  11%|█         | 3/27 [00:00<00:00, 39.26it/s, train_loss=0.00679, val_loss=0.00561]Epoch 7:  15%|█▍        | 4/27 [00:00<00:00, 45.59it/s, train_loss=0.00679, val_loss=0.00561]Epoch 7:  15%|█▍        | 4/27 [00:00<00:00, 40.20it/s, train_loss=0.00578, val_loss=0.00561]Epoch 7:  19%|█▊        | 5/27 [00:00<00:00, 44.95it/s, train_loss=0.00578, val_loss=0.00561]Epoch 7:  19%|█▊        | 5/27 [00:00<00:00, 40.64it/s, train_loss=0.00529, val_loss=0.00561]Epoch 7:  22%|██▏       | 6/27 [00:00<00:00, 45.43it/s, train_loss=0.00529, val_loss=0.00561]Epoch 7:  22%|██▏       | 6/27 [00:00<00:00, 40.69it/s, train_loss=0.00489, val_loss=0.00561]Epoch 7:  26%|██▌       | 7/27 [00:00<00:00, 44.42it/s, train_loss=0.00489, val_loss=0.00561]Epoch 7:  26%|██▌       | 7/27 [00:00<00:00, 41.12it/s, train_loss=0.0052, val_loss=0.00561] Epoch 7:  30%|██▉       | 8/27 [00:00<00:00, 44.23it/s, train_loss=0.0052, val_loss=0.00561]Epoch 7:  30%|██▉       | 8/27 [00:00<00:00, 41.36it/s, train_loss=0.00478, val_loss=0.00561]Epoch 7:  33%|███▎      | 9/27 [00:00<00:00, 44.33it/s, train_loss=0.00478, val_loss=0.00561]Epoch 7:  33%|███▎      | 9/27 [00:00<00:00, 41.21it/s, train_loss=0.00524, val_loss=0.00561]Epoch 7:  37%|███▋      | 10/27 [00:00<00:00, 43.82it/s, train_loss=0.00524, val_loss=0.00561]Epoch 7:  37%|███▋      | 10/27 [00:00<00:00, 41.05it/s, train_loss=0.00512, val_loss=0.00561]Epoch 7:  41%|████      | 11/27 [00:00<00:00, 43.20it/s, train_loss=0.00512, val_loss=0.00561]Epoch 7:  41%|████      | 11/27 [00:00<00:00, 41.23it/s, train_loss=0.00524, val_loss=0.00561]Epoch 7:  44%|████▍     | 12/27 [00:00<00:00, 43.15it/s, train_loss=0.00524, val_loss=0.00561]Epoch 7:  44%|████▍     | 12/27 [00:00<00:00, 41.35it/s, train_loss=0.00544, val_loss=0.00561]Epoch 7:  48%|████▊     | 13/27 [00:00<00:00, 43.43it/s, train_loss=0.00544, val_loss=0.00561]Epoch 7:  48%|████▊     | 13/27 [00:00<00:00, 41.27it/s, train_loss=0.00457, val_loss=0.00561]Epoch 7:  52%|█████▏    | 14/27 [00:00<00:00, 43.11it/s, train_loss=0.00457, val_loss=0.00561]Epoch 7:  52%|█████▏    | 14/27 [00:00<00:00, 41.08it/s, train_loss=0.00615, val_loss=0.00561]Epoch 7:  56%|█████▌    | 15/27 [00:00<00:00, 42.65it/s, train_loss=0.00615, val_loss=0.00561]Epoch 7:  56%|█████▌    | 15/27 [00:00<00:00, 41.25it/s, train_loss=0.00544, val_loss=0.00561]Epoch 7:  59%|█████▉    | 16/27 [00:00<00:00, 42.65it/s, train_loss=0.00544, val_loss=0.00561]Epoch 7:  59%|█████▉    | 16/27 [00:00<00:00, 41.37it/s, train_loss=0.00486, val_loss=0.00561]Epoch 7:  63%|██████▎   | 17/27 [00:00<00:00, 42.92it/s, train_loss=0.00486, val_loss=0.00561]Epoch 7:  63%|██████▎   | 17/27 [00:00<00:00, 41.29it/s, train_loss=0.0059, val_loss=0.00561] Epoch 7:  67%|██████▋   | 18/27 [00:00<00:00, 42.69it/s, train_loss=0.0059, val_loss=0.00561]Epoch 7:  67%|██████▋   | 18/27 [00:00<00:00, 41.18it/s, train_loss=0.00635, val_loss=0.00561]Epoch 7:  70%|███████   | 19/27 [00:00<00:00, 42.39it/s, train_loss=0.00635, val_loss=0.00561]Epoch 7:  70%|███████   | 19/27 [00:00<00:00, 41.06it/s, train_loss=0.00554, val_loss=0.00561]Epoch 7:  74%|███████▍  | 20/27 [00:00<00:00, 42.13it/s, train_loss=0.00554, val_loss=0.00561]Epoch 7:  74%|███████▍  | 20/27 [00:00<00:00, 41.14it/s, train_loss=0.00491, val_loss=0.00561]Epoch 7:  78%|███████▊  | 21/27 [00:00<00:00, 42.25it/s, train_loss=0.00491, val_loss=0.00561]Epoch 7:  78%|███████▊  | 21/27 [00:00<00:00, 41.07it/s, train_loss=0.00584, val_loss=0.00561]Epoch 7:  81%|████████▏ | 22/27 [00:00<00:00, 42.24it/s, train_loss=0.00584, val_loss=0.00561]Epoch 7:  81%|████████▏ | 22/27 [00:00<00:00, 41.02it/s, train_loss=0.0041, val_loss=0.00561] Epoch 7:  85%|████████▌ | 23/27 [00:00<00:00, 42.13it/s, train_loss=0.0041, val_loss=0.00561]Epoch 7:  85%|████████▌ | 23/27 [00:00<00:00, 40.96it/s, train_loss=0.00509, val_loss=0.00561]Epoch 7:  89%|████████▉ | 24/27 [00:00<00:00, 41.86it/s, train_loss=0.00509, val_loss=0.00561]Epoch 7:  89%|████████▉ | 24/27 [00:00<00:00, 40.84it/s, train_loss=0.00479, val_loss=0.00561]Epoch 7:  93%|█████████▎| 25/27 [00:00<00:00, 41.81it/s, train_loss=0.00479, val_loss=0.00561]Epoch 7:  93%|█████████▎| 25/27 [00:00<00:00, 40.81it/s, train_loss=0.00567, val_loss=0.00561]Epoch 7:  96%|█████████▋| 26/27 [00:00<00:00, 41.65it/s, train_loss=0.00567, val_loss=0.00561]Epoch 7:  96%|█████████▋| 26/27 [00:00<00:00, 40.91it/s, train_loss=0.00452, val_loss=0.00561]Epoch 7: 100%|██████████| 27/27 [00:00<00:00, 41.88it/s, train_loss=0.00452, val_loss=0.00561]Epoch 7: 100%|██████████| 27/27 [00:00<00:00, 41.01it/s, train_loss=0.00568, val_loss=0.00561]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 135.18it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 150.63it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 161.50it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 165.63it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 168.33it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 170.53it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 171.24it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 172.78it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 174.48it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 142.15it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 144.83it/s][A
                                                                         [AEpoch 7: 100%|██████████| 27/27 [00:00<00:00, 36.33it/s, train_loss=0.00568, val_loss=0.00481]Epoch 7: 100%|██████████| 27/27 [00:00<00:00, 36.28it/s, train_loss=0.00568, val_loss=0.00481]Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00568, val_loss=0.00481]         Epoch 8:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00568, val_loss=0.00481]Epoch 8:   4%|▎         | 1/27 [00:00<00:00, 83.49it/s, train_loss=0.00568, val_loss=0.00481]Epoch 8:   4%|▎         | 1/27 [00:00<00:00, 42.67it/s, train_loss=0.00552, val_loss=0.00481]Epoch 8:   7%|▋         | 2/27 [00:00<00:00, 57.04it/s, train_loss=0.00552, val_loss=0.00481]Epoch 8:   7%|▋         | 2/27 [00:00<00:00, 41.86it/s, train_loss=0.00518, val_loss=0.00481]Epoch 8:  11%|█         | 3/27 [00:00<00:00, 52.62it/s, train_loss=0.00518, val_loss=0.00481]Epoch 8:  11%|█         | 3/27 [00:00<00:00, 41.10it/s, train_loss=0.00477, val_loss=0.00481]Epoch 8:  15%|█▍        | 4/27 [00:00<00:00, 48.54it/s, train_loss=0.00477, val_loss=0.00481]Epoch 8:  15%|█▍        | 4/27 [00:00<00:00, 40.89it/s, train_loss=0.00466, val_loss=0.00481]Epoch 8:  19%|█▊        | 5/27 [00:00<00:00, 45.95it/s, train_loss=0.00466, val_loss=0.00481]Epoch 8:  19%|█▊        | 5/27 [00:00<00:00, 41.38it/s, train_loss=0.00646, val_loss=0.00481]Epoch 8:  22%|██▏       | 6/27 [00:00<00:00, 45.32it/s, train_loss=0.00646, val_loss=0.00481]Epoch 8:  22%|██▏       | 6/27 [00:00<00:00, 41.59it/s, train_loss=0.00497, val_loss=0.00481]Epoch 8:  26%|██▌       | 7/27 [00:00<00:00, 45.50it/s, train_loss=0.00497, val_loss=0.00481]Epoch 8:  26%|██▌       | 7/27 [00:00<00:00, 41.37it/s, train_loss=0.00435, val_loss=0.00481]Epoch 8:  30%|██▉       | 8/27 [00:00<00:00, 44.70it/s, train_loss=0.00435, val_loss=0.00481]Epoch 8:  30%|██▉       | 8/27 [00:00<00:00, 41.17it/s, train_loss=0.00489, val_loss=0.00481]Epoch 8:  33%|███▎      | 9/27 [00:00<00:00, 43.79it/s, train_loss=0.00489, val_loss=0.00481]Epoch 8:  33%|███▎      | 9/27 [00:00<00:00, 40.90it/s, train_loss=0.00541, val_loss=0.00481]Epoch 8:  37%|███▋      | 10/27 [00:00<00:00, 43.09it/s, train_loss=0.00541, val_loss=0.00481]Epoch 8:  37%|███▋      | 10/27 [00:00<00:00, 41.07it/s, train_loss=0.00424, val_loss=0.00481]Epoch 8:  41%|████      | 11/27 [00:00<00:00, 43.19it/s, train_loss=0.00424, val_loss=0.00481]Epoch 8:  41%|████      | 11/27 [00:00<00:00, 41.07it/s, train_loss=0.00463, val_loss=0.00481]Epoch 8:  44%|████▍     | 12/27 [00:00<00:00, 43.32it/s, train_loss=0.00463, val_loss=0.00481]Epoch 8:  44%|████▍     | 12/27 [00:00<00:00, 41.03it/s, train_loss=0.00508, val_loss=0.00481]Epoch 8:  48%|████▊     | 13/27 [00:00<00:00, 42.85it/s, train_loss=0.00508, val_loss=0.00481]Epoch 8:  48%|████▊     | 13/27 [00:00<00:00, 41.23it/s, train_loss=0.00439, val_loss=0.00481]Epoch 8:  52%|█████▏    | 14/27 [00:00<00:00, 42.88it/s, train_loss=0.00439, val_loss=0.00481]Epoch 8:  52%|█████▏    | 14/27 [00:00<00:00, 41.37it/s, train_loss=0.00415, val_loss=0.00481]Epoch 8:  56%|█████▌    | 15/27 [00:00<00:00, 43.14it/s, train_loss=0.00415, val_loss=0.00481]Epoch 8:  56%|█████▌    | 15/27 [00:00<00:00, 41.31it/s, train_loss=0.00378, val_loss=0.00481]Epoch 8:  59%|█████▉    | 16/27 [00:00<00:00, 42.85it/s, train_loss=0.00378, val_loss=0.00481]Epoch 8:  59%|█████▉    | 16/27 [00:00<00:00, 41.16it/s, train_loss=0.00506, val_loss=0.00481]Epoch 8:  63%|██████▎   | 17/27 [00:00<00:00, 42.48it/s, train_loss=0.00506, val_loss=0.00481]Epoch 8:  63%|██████▎   | 17/27 [00:00<00:00, 41.30it/s, train_loss=0.00556, val_loss=0.00481]Epoch 8:  67%|██████▋   | 18/27 [00:00<00:00, 42.53it/s, train_loss=0.00556, val_loss=0.00481]Epoch 8:  67%|██████▋   | 18/27 [00:00<00:00, 41.21it/s, train_loss=0.00439, val_loss=0.00481]Epoch 8:  70%|███████   | 19/27 [00:00<00:00, 42.58it/s, train_loss=0.00439, val_loss=0.00481]Epoch 8:  70%|███████   | 19/27 [00:00<00:00, 41.13it/s, train_loss=0.00529, val_loss=0.00481]Epoch 8:  74%|███████▍  | 20/27 [00:00<00:00, 42.34it/s, train_loss=0.00529, val_loss=0.00481]Epoch 8:  74%|███████▍  | 20/27 [00:00<00:00, 41.01it/s, train_loss=0.00413, val_loss=0.00481]Epoch 8:  78%|███████▊  | 21/27 [00:00<00:00, 42.26it/s, train_loss=0.00413, val_loss=0.00481]Epoch 8:  78%|███████▊  | 21/27 [00:00<00:00, 41.00it/s, train_loss=0.00431, val_loss=0.00481]Epoch 8:  81%|████████▏ | 22/27 [00:00<00:00, 41.97it/s, train_loss=0.00431, val_loss=0.00481]Epoch 8:  81%|████████▏ | 22/27 [00:00<00:00, 41.09it/s, train_loss=0.00437, val_loss=0.00481]Epoch 8:  85%|████████▌ | 23/27 [00:00<00:00, 42.11it/s, train_loss=0.00437, val_loss=0.00481]Epoch 8:  85%|████████▌ | 23/27 [00:00<00:00, 41.04it/s, train_loss=0.00408, val_loss=0.00481]Epoch 8:  89%|████████▉ | 24/27 [00:00<00:00, 42.06it/s, train_loss=0.00408, val_loss=0.00481]Epoch 8:  89%|████████▉ | 24/27 [00:00<00:00, 40.99it/s, train_loss=0.00387, val_loss=0.00481]Epoch 8:  93%|█████████▎| 25/27 [00:00<00:00, 41.98it/s, train_loss=0.00387, val_loss=0.00481]Epoch 8:  93%|█████████▎| 25/27 [00:00<00:00, 40.92it/s, train_loss=0.00505, val_loss=0.00481]Epoch 8:  96%|█████████▋| 26/27 [00:00<00:00, 41.84it/s, train_loss=0.00505, val_loss=0.00481]Epoch 8:  96%|█████████▋| 26/27 [00:00<00:00, 41.02it/s, train_loss=0.00437, val_loss=0.00481]Epoch 8: 100%|██████████| 27/27 [00:00<00:00, 41.83it/s, train_loss=0.00437, val_loss=0.00481]Epoch 8: 100%|██████████| 27/27 [00:00<00:00, 41.21it/s, train_loss=0.00535, val_loss=0.00481]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 146.13it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 165.58it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 177.31it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 184.86it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 189.20it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 192.14it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 193.03it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 192.67it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 191.42it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 190.02it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 191.64it/s][A
                                                                         [AEpoch 8: 100%|██████████| 27/27 [00:00<00:00, 36.51it/s, train_loss=0.00535, val_loss=0.00434]Epoch 8: 100%|██████████| 27/27 [00:00<00:00, 36.46it/s, train_loss=0.00535, val_loss=0.00434]Epoch 8:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00535, val_loss=0.00434]         Epoch 9:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00535, val_loss=0.00434]Epoch 9:   4%|▎         | 1/27 [00:00<00:00, 84.58it/s, train_loss=0.00535, val_loss=0.00434]Epoch 9:   4%|▎         | 1/27 [00:00<00:00, 41.59it/s, train_loss=0.00483, val_loss=0.00434]Epoch 9:   7%|▋         | 2/27 [00:00<00:00, 55.66it/s, train_loss=0.00483, val_loss=0.00434]Epoch 9:   7%|▋         | 2/27 [00:00<00:00, 41.61it/s, train_loss=0.00471, val_loss=0.00434]Epoch 9:  11%|█         | 3/27 [00:00<00:00, 52.48it/s, train_loss=0.00471, val_loss=0.00434]Epoch 9:  11%|█         | 3/27 [00:00<00:00, 41.17it/s, train_loss=0.00512, val_loss=0.00434]Epoch 9:  15%|█▍        | 4/27 [00:00<00:00, 48.46it/s, train_loss=0.00512, val_loss=0.00434]Epoch 9:  15%|█▍        | 4/27 [00:00<00:00, 40.90it/s, train_loss=0.0051, val_loss=0.00434] Epoch 9:  19%|█▊        | 5/27 [00:00<00:00, 45.61it/s, train_loss=0.0051, val_loss=0.00434]Epoch 9:  19%|█▊        | 5/27 [00:00<00:00, 41.26it/s, train_loss=0.00514, val_loss=0.00434]Epoch 9:  22%|██▏       | 6/27 [00:00<00:00, 45.51it/s, train_loss=0.00514, val_loss=0.00434]Epoch 9:  22%|██▏       | 6/27 [00:00<00:00, 40.99it/s, train_loss=0.00452, val_loss=0.00434]Epoch 9:  26%|██▌       | 7/27 [00:00<00:00, 44.89it/s, train_loss=0.00452, val_loss=0.00434]Epoch 9:  26%|██▌       | 7/27 [00:00<00:00, 40.83it/s, train_loss=0.00449, val_loss=0.00434]Epoch 9:  30%|██▉       | 8/27 [00:00<00:00, 44.04it/s, train_loss=0.00449, val_loss=0.00434]Epoch 9:  30%|██▉       | 8/27 [00:00<00:00, 40.50it/s, train_loss=0.00519, val_loss=0.00434]Epoch 9:  33%|███▎      | 9/27 [00:00<00:00, 43.31it/s, train_loss=0.00519, val_loss=0.00434]Epoch 9:  33%|███▎      | 9/27 [00:00<00:00, 40.41it/s, train_loss=0.00335, val_loss=0.00434]Epoch 9:  37%|███▋      | 10/27 [00:00<00:00, 42.76it/s, train_loss=0.00335, val_loss=0.00434]Epoch 9:  37%|███▋      | 10/27 [00:00<00:00, 40.67it/s, train_loss=0.00389, val_loss=0.00434]Epoch 9:  41%|████      | 11/27 [00:00<00:00, 42.79it/s, train_loss=0.00389, val_loss=0.00434]Epoch 9:  41%|████      | 11/27 [00:00<00:00, 40.93it/s, train_loss=0.00379, val_loss=0.00434]Epoch 9:  44%|████▍     | 12/27 [00:00<00:00, 43.15it/s, train_loss=0.00379, val_loss=0.00434]Epoch 9:  44%|████▍     | 12/27 [00:00<00:00, 40.87it/s, train_loss=0.00387, val_loss=0.00434]Epoch 9:  48%|████▊     | 13/27 [00:00<00:00, 42.83it/s, train_loss=0.00387, val_loss=0.00434]Epoch 9:  48%|████▊     | 13/27 [00:00<00:00, 40.72it/s, train_loss=0.00423, val_loss=0.00434]Epoch 9:  52%|█████▏    | 14/27 [00:00<00:00, 42.43it/s, train_loss=0.00423, val_loss=0.00434]Epoch 9:  52%|█████▏    | 14/27 [00:00<00:00, 40.64it/s, train_loss=0.00445, val_loss=0.00434]Epoch 9:  56%|█████▌    | 15/27 [00:00<00:00, 42.13it/s, train_loss=0.00445, val_loss=0.00434]Epoch 9:  56%|█████▌    | 15/27 [00:00<00:00, 40.82it/s, train_loss=0.00459, val_loss=0.00434]Epoch 9:  59%|█████▉    | 16/27 [00:00<00:00, 42.49it/s, train_loss=0.00459, val_loss=0.00434]Epoch 9:  59%|█████▉    | 16/27 [00:00<00:00, 40.82it/s, train_loss=0.004, val_loss=0.00434]  Epoch 9:  63%|██████▎   | 17/27 [00:00<00:00, 42.34it/s, train_loss=0.004, val_loss=0.00434]Epoch 9:  63%|██████▎   | 17/27 [00:00<00:00, 40.80it/s, train_loss=0.00344, val_loss=0.00434]Epoch 9:  67%|██████▋   | 18/27 [00:00<00:00, 42.01it/s, train_loss=0.00344, val_loss=0.00434]Epoch 9:  67%|██████▋   | 18/27 [00:00<00:00, 40.93it/s, train_loss=0.00359, val_loss=0.00434]Epoch 9:  70%|███████   | 19/27 [00:00<00:00, 42.29it/s, train_loss=0.00359, val_loss=0.00434]Epoch 9:  70%|███████   | 19/27 [00:00<00:00, 40.87it/s, train_loss=0.00374, val_loss=0.00434]Epoch 9:  74%|███████▍  | 20/27 [00:00<00:00, 42.17it/s, train_loss=0.00374, val_loss=0.00434]Epoch 9:  74%|███████▍  | 20/27 [00:00<00:00, 40.83it/s, train_loss=0.00497, val_loss=0.00434]Epoch 9:  78%|███████▊  | 21/27 [00:00<00:00, 42.05it/s, train_loss=0.00497, val_loss=0.00434]Epoch 9:  78%|███████▊  | 21/27 [00:00<00:00, 40.74it/s, train_loss=0.00424, val_loss=0.00434]Epoch 9:  81%|████████▏ | 22/27 [00:00<00:00, 41.75it/s, train_loss=0.00424, val_loss=0.00434]Epoch 9:  81%|████████▏ | 22/27 [00:00<00:00, 40.65it/s, train_loss=0.00391, val_loss=0.00434]Epoch 9:  85%|████████▌ | 23/27 [00:00<00:00, 41.58it/s, train_loss=0.00391, val_loss=0.00434]Epoch 9:  85%|████████▌ | 23/27 [00:00<00:00, 40.71it/s, train_loss=0.00475, val_loss=0.00434]Epoch 9:  89%|████████▉ | 24/27 [00:00<00:00, 41.69it/s, train_loss=0.00475, val_loss=0.00434]Epoch 9:  89%|████████▉ | 24/27 [00:00<00:00, 40.70it/s, train_loss=0.0039, val_loss=0.00434] Epoch 9:  93%|█████████▎| 25/27 [00:00<00:00, 41.73it/s, train_loss=0.0039, val_loss=0.00434]Epoch 9:  93%|█████████▎| 25/27 [00:00<00:00, 40.68it/s, train_loss=0.00354, val_loss=0.00434]Epoch 9:  96%|█████████▋| 26/27 [00:00<00:00, 41.65it/s, train_loss=0.00354, val_loss=0.00434]Epoch 9:  96%|█████████▋| 26/27 [00:00<00:00, 40.63it/s, train_loss=0.00352, val_loss=0.00434]Epoch 9: 100%|██████████| 27/27 [00:00<00:00, 41.47it/s, train_loss=0.00352, val_loss=0.00434]Epoch 9: 100%|██████████| 27/27 [00:00<00:00, 40.84it/s, train_loss=0.0037, val_loss=0.00434] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 109.16it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 127.47it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 138.16it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 144.87it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 148.17it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 150.54it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 152.11it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 153.65it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 154.59it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 157.80it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 162.12it/s][A
                                                                         [AEpoch 9: 100%|██████████| 27/27 [00:00<00:00, 36.12it/s, train_loss=0.0037, val_loss=0.00387]Epoch 9: 100%|██████████| 27/27 [00:00<00:00, 36.08it/s, train_loss=0.0037, val_loss=0.00387]Epoch 9:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0037, val_loss=0.00387]         Epoch 10:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0037, val_loss=0.00387]Epoch 10:   4%|▎         | 1/27 [00:00<00:00, 84.53it/s, train_loss=0.0037, val_loss=0.00387]Epoch 10:   4%|▎         | 1/27 [00:00<00:00, 42.56it/s, train_loss=0.0039, val_loss=0.00387]Epoch 10:   7%|▋         | 2/27 [00:00<00:00, 58.00it/s, train_loss=0.0039, val_loss=0.00387]Epoch 10:   7%|▋         | 2/27 [00:00<00:00, 41.54it/s, train_loss=0.00412, val_loss=0.00387]Epoch 10:  11%|█         | 3/27 [00:00<00:00, 52.33it/s, train_loss=0.00412, val_loss=0.00387]Epoch 10:  11%|█         | 3/27 [00:00<00:00, 41.16it/s, train_loss=0.00401, val_loss=0.00387]Epoch 10:  15%|█▍        | 4/27 [00:00<00:00, 48.44it/s, train_loss=0.00401, val_loss=0.00387]Epoch 10:  15%|█▍        | 4/27 [00:00<00:00, 40.97it/s, train_loss=0.00373, val_loss=0.00387]Epoch 10:  19%|█▊        | 5/27 [00:00<00:00, 45.74it/s, train_loss=0.00373, val_loss=0.00387]Epoch 10:  19%|█▊        | 5/27 [00:00<00:00, 41.39it/s, train_loss=0.0042, val_loss=0.00387] Epoch 10:  22%|██▏       | 6/27 [00:00<00:00, 45.71it/s, train_loss=0.0042, val_loss=0.00387]Epoch 10:  22%|██▏       | 6/27 [00:00<00:00, 41.10it/s, train_loss=0.00385, val_loss=0.00387]Epoch 10:  26%|██▌       | 7/27 [00:00<00:00, 45.09it/s, train_loss=0.00385, val_loss=0.00387]Epoch 10:  26%|██▌       | 7/27 [00:00<00:00, 40.98it/s, train_loss=0.00466, val_loss=0.00387]Epoch 10:  30%|██▉       | 8/27 [00:00<00:00, 44.28it/s, train_loss=0.00466, val_loss=0.00387]Epoch 10:  30%|██▉       | 8/27 [00:00<00:00, 40.78it/s, train_loss=0.00367, val_loss=0.00387]Epoch 10:  33%|███▎      | 9/27 [00:00<00:00, 43.38it/s, train_loss=0.00367, val_loss=0.00387]Epoch 10:  33%|███▎      | 9/27 [00:00<00:00, 40.58it/s, train_loss=0.00383, val_loss=0.00387]Epoch 10:  37%|███▋      | 10/27 [00:00<00:00, 42.80it/s, train_loss=0.00383, val_loss=0.00387]Epoch 10:  37%|███▋      | 10/27 [00:00<00:00, 40.74it/s, train_loss=0.00342, val_loss=0.00387]Epoch 10:  41%|████      | 11/27 [00:00<00:00, 42.93it/s, train_loss=0.00342, val_loss=0.00387]Epoch 10:  41%|████      | 11/27 [00:00<00:00, 40.64it/s, train_loss=0.0038, val_loss=0.00387] Epoch 10:  44%|████▍     | 12/27 [00:00<00:00, 42.82it/s, train_loss=0.0038, val_loss=0.00387]Epoch 10:  44%|████▍     | 12/27 [00:00<00:00, 40.60it/s, train_loss=0.00376, val_loss=0.00387]Epoch 10:  48%|████▊     | 13/27 [00:00<00:00, 42.61it/s, train_loss=0.00376, val_loss=0.00387]Epoch 10:  48%|████▊     | 13/27 [00:00<00:00, 40.57it/s, train_loss=0.00423, val_loss=0.00387]Epoch 10:  52%|█████▏    | 14/27 [00:00<00:00, 42.22it/s, train_loss=0.00423, val_loss=0.00387]Epoch 10:  52%|█████▏    | 14/27 [00:00<00:00, 40.75it/s, train_loss=0.00376, val_loss=0.00387]Epoch 10:  56%|█████▌    | 15/27 [00:00<00:00, 42.27it/s, train_loss=0.00376, val_loss=0.00387]Epoch 10:  56%|█████▌    | 15/27 [00:00<00:00, 40.91it/s, train_loss=0.00393, val_loss=0.00387]Epoch 10:  59%|█████▉    | 16/27 [00:00<00:00, 42.47it/s, train_loss=0.00393, val_loss=0.00387]Epoch 10:  59%|█████▉    | 16/27 [00:00<00:00, 40.81it/s, train_loss=0.00339, val_loss=0.00387]Epoch 10:  63%|██████▎   | 17/27 [00:00<00:00, 42.23it/s, train_loss=0.00339, val_loss=0.00387]Epoch 10:  63%|██████▎   | 17/27 [00:00<00:00, 40.66it/s, train_loss=0.00413, val_loss=0.00387]Epoch 10:  67%|██████▋   | 18/27 [00:00<00:00, 42.06it/s, train_loss=0.00413, val_loss=0.00387]Epoch 10:  67%|██████▋   | 18/27 [00:00<00:00, 40.59it/s, train_loss=0.00363, val_loss=0.00387]Epoch 10:  70%|███████   | 19/27 [00:00<00:00, 41.97it/s, train_loss=0.00363, val_loss=0.00387]Epoch 10:  70%|███████   | 19/27 [00:00<00:00, 40.79it/s, train_loss=0.00363, val_loss=0.00387]Epoch 10:  74%|███████▍  | 20/27 [00:00<00:00, 41.92it/s, train_loss=0.00363, val_loss=0.00387]Epoch 10:  74%|███████▍  | 20/27 [00:00<00:00, 40.88it/s, train_loss=0.00373, val_loss=0.00387]Epoch 10:  78%|███████▊  | 21/27 [00:00<00:00, 42.16it/s, train_loss=0.00373, val_loss=0.00387]Epoch 10:  78%|███████▊  | 21/27 [00:00<00:00, 40.88it/s, train_loss=0.00389, val_loss=0.00387]Epoch 10:  81%|████████▏ | 22/27 [00:00<00:00, 42.02it/s, train_loss=0.00389, val_loss=0.00387]Epoch 10:  81%|████████▏ | 22/27 [00:00<00:00, 41.02it/s, train_loss=0.00396, val_loss=0.00387]Epoch 10:  85%|████████▌ | 23/27 [00:00<00:00, 42.02it/s, train_loss=0.00396, val_loss=0.00387]Epoch 10:  85%|████████▌ | 23/27 [00:00<00:00, 41.12it/s, train_loss=0.00316, val_loss=0.00387]Epoch 10:  89%|████████▉ | 24/27 [00:00<00:00, 42.18it/s, train_loss=0.00316, val_loss=0.00387]Epoch 10:  89%|████████▉ | 24/27 [00:00<00:00, 41.08it/s, train_loss=0.00418, val_loss=0.00387]Epoch 10:  93%|█████████▎| 25/27 [00:00<00:00, 42.09it/s, train_loss=0.00418, val_loss=0.00387]Epoch 10:  93%|█████████▎| 25/27 [00:00<00:00, 41.04it/s, train_loss=0.00476, val_loss=0.00387]Epoch 10:  96%|█████████▋| 26/27 [00:00<00:00, 41.88it/s, train_loss=0.00476, val_loss=0.00387]Epoch 10:  96%|█████████▋| 26/27 [00:00<00:00, 41.11it/s, train_loss=0.00388, val_loss=0.00387]Epoch 10: 100%|██████████| 27/27 [00:00<00:00, 41.98it/s, train_loss=0.00388, val_loss=0.00387]Epoch 10: 100%|██████████| 27/27 [00:00<00:00, 41.18it/s, train_loss=0.00424, val_loss=0.00387]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 118.61it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 138.25it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 149.41it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 155.95it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 159.81it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 162.64it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 161.98it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 161.81it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 163.01it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 163.66it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 164.97it/s][A
                                                                         [AEpoch 10: 100%|██████████| 27/27 [00:00<00:00, 36.45it/s, train_loss=0.00424, val_loss=0.00349]Epoch 10: 100%|██████████| 27/27 [00:00<00:00, 36.40it/s, train_loss=0.00424, val_loss=0.00349]Epoch 10:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00424, val_loss=0.00349]         Epoch 11:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00424, val_loss=0.00349]Epoch 11:   4%|▎         | 1/27 [00:00<00:00, 84.47it/s, train_loss=0.00424, val_loss=0.00349]Epoch 11:   4%|▎         | 1/27 [00:00<00:00, 38.20it/s, train_loss=0.00391, val_loss=0.00349]Epoch 11:   7%|▋         | 2/27 [00:00<00:00, 55.87it/s, train_loss=0.00391, val_loss=0.00349]Epoch 11:   7%|▋         | 2/27 [00:00<00:00, 40.93it/s, train_loss=0.00323, val_loss=0.00349]Epoch 11:  11%|█         | 3/27 [00:00<00:00, 49.19it/s, train_loss=0.00323, val_loss=0.00349]Epoch 11:  11%|█         | 3/27 [00:00<00:00, 41.70it/s, train_loss=0.00388, val_loss=0.00349]Epoch 11:  15%|█▍        | 4/27 [00:00<00:00, 49.26it/s, train_loss=0.00388, val_loss=0.00349]Epoch 11:  15%|█▍        | 4/27 [00:00<00:00, 41.45it/s, train_loss=0.00418, val_loss=0.00349]Epoch 11:  19%|█▊        | 5/27 [00:00<00:00, 46.79it/s, train_loss=0.00418, val_loss=0.00349]Epoch 11:  19%|█▊        | 5/27 [00:00<00:00, 41.93it/s, train_loss=0.00385, val_loss=0.00349]Epoch 11:  22%|██▏       | 6/27 [00:00<00:00, 45.95it/s, train_loss=0.00385, val_loss=0.00349]Epoch 11:  22%|██▏       | 6/27 [00:00<00:00, 41.98it/s, train_loss=0.00362, val_loss=0.00349]Epoch 11:  26%|██▌       | 7/27 [00:00<00:00, 46.02it/s, train_loss=0.00362, val_loss=0.00349]Epoch 11:  26%|██▌       | 7/27 [00:00<00:00, 41.76it/s, train_loss=0.00312, val_loss=0.00349]Epoch 11:  30%|██▉       | 8/27 [00:00<00:00, 45.11it/s, train_loss=0.00312, val_loss=0.00349]Epoch 11:  30%|██▉       | 8/27 [00:00<00:00, 41.46it/s, train_loss=0.00408, val_loss=0.00349]Epoch 11:  33%|███▎      | 9/27 [00:00<00:00, 44.12it/s, train_loss=0.00408, val_loss=0.00349]Epoch 11:  33%|███▎      | 9/27 [00:00<00:00, 41.72it/s, train_loss=0.00311, val_loss=0.00349]Epoch 11:  37%|███▋      | 10/27 [00:00<00:00, 43.99it/s, train_loss=0.00311, val_loss=0.00349]Epoch 11:  37%|███▋      | 10/27 [00:00<00:00, 41.76it/s, train_loss=0.00324, val_loss=0.00349]Epoch 11:  41%|████      | 11/27 [00:00<00:00, 44.17it/s, train_loss=0.00324, val_loss=0.00349]Epoch 11:  41%|████      | 11/27 [00:00<00:00, 41.64it/s, train_loss=0.00316, val_loss=0.00349]Epoch 11:  44%|████▍     | 12/27 [00:00<00:00, 43.85it/s, train_loss=0.00316, val_loss=0.00349]Epoch 11:  44%|████▍     | 12/27 [00:00<00:00, 41.52it/s, train_loss=0.00352, val_loss=0.00349]Epoch 11:  48%|████▊     | 13/27 [00:00<00:00, 43.47it/s, train_loss=0.00352, val_loss=0.00349]Epoch 11:  48%|████▊     | 13/27 [00:00<00:00, 41.69it/s, train_loss=0.00336, val_loss=0.00349]Epoch 11:  52%|█████▏    | 14/27 [00:00<00:00, 43.52it/s, train_loss=0.00336, val_loss=0.00349]Epoch 11:  52%|█████▏    | 14/27 [00:00<00:00, 41.52it/s, train_loss=0.00335, val_loss=0.00349]Epoch 11:  56%|█████▌    | 15/27 [00:00<00:00, 43.27it/s, train_loss=0.00335, val_loss=0.00349]Epoch 11:  56%|█████▌    | 15/27 [00:00<00:00, 41.42it/s, train_loss=0.00301, val_loss=0.00349]Epoch 11:  59%|█████▉    | 16/27 [00:00<00:00, 43.04it/s, train_loss=0.00301, val_loss=0.00349]Epoch 11:  59%|█████▉    | 16/27 [00:00<00:00, 41.36it/s, train_loss=0.00315, val_loss=0.00349]Epoch 11:  63%|██████▎   | 17/27 [00:00<00:00, 42.83it/s, train_loss=0.00315, val_loss=0.00349]Epoch 11:  63%|██████▎   | 17/27 [00:00<00:00, 41.49it/s, train_loss=0.00394, val_loss=0.00349]Epoch 11:  67%|██████▋   | 18/27 [00:00<00:00, 42.90it/s, train_loss=0.00394, val_loss=0.00349]Epoch 11:  67%|██████▋   | 18/27 [00:00<00:00, 41.37it/s, train_loss=0.00363, val_loss=0.00349]Epoch 11:  70%|███████   | 19/27 [00:00<00:00, 42.73it/s, train_loss=0.00363, val_loss=0.00349]Epoch 11:  70%|███████   | 19/27 [00:00<00:00, 41.30it/s, train_loss=0.00333, val_loss=0.00349]Epoch 11:  74%|███████▍  | 20/27 [00:00<00:00, 42.58it/s, train_loss=0.00333, val_loss=0.00349]Epoch 11:  74%|███████▍  | 20/27 [00:00<00:00, 41.25it/s, train_loss=0.00307, val_loss=0.00349]Epoch 11:  78%|███████▊  | 21/27 [00:00<00:00, 42.39it/s, train_loss=0.00307, val_loss=0.00349]Epoch 11:  78%|███████▊  | 21/27 [00:00<00:00, 41.32it/s, train_loss=0.00283, val_loss=0.00349]Epoch 11:  81%|████████▏ | 22/27 [00:00<00:00, 42.50it/s, train_loss=0.00283, val_loss=0.00349]Epoch 11:  81%|████████▏ | 22/27 [00:00<00:00, 41.29it/s, train_loss=0.00348, val_loss=0.00349]Epoch 11:  85%|████████▌ | 23/27 [00:00<00:00, 42.41it/s, train_loss=0.00348, val_loss=0.00349]Epoch 11:  85%|████████▌ | 23/27 [00:00<00:00, 41.27it/s, train_loss=0.00347, val_loss=0.00349]Epoch 11:  89%|████████▉ | 24/27 [00:00<00:00, 42.31it/s, train_loss=0.00347, val_loss=0.00349]Epoch 11:  89%|████████▉ | 24/27 [00:00<00:00, 41.36it/s, train_loss=0.00314, val_loss=0.00349]Epoch 11:  93%|█████████▎| 25/27 [00:00<00:00, 42.40it/s, train_loss=0.00314, val_loss=0.00349]Epoch 11:  93%|█████████▎| 25/27 [00:00<00:00, 41.32it/s, train_loss=0.00391, val_loss=0.00349]Epoch 11:  96%|█████████▋| 26/27 [00:00<00:00, 42.33it/s, train_loss=0.00391, val_loss=0.00349]Epoch 11:  96%|█████████▋| 26/27 [00:00<00:00, 41.29it/s, train_loss=0.00358, val_loss=0.00349]Epoch 11: 100%|██████████| 27/27 [00:00<00:00, 42.13it/s, train_loss=0.00358, val_loss=0.00349]Epoch 11: 100%|██████████| 27/27 [00:00<00:00, 41.50it/s, train_loss=0.00302, val_loss=0.00349]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 118.20it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 142.64it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 154.55it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 156.90it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 155.96it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 159.87it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 162.68it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 164.06it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 165.13it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 166.49it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 167.91it/s][A
                                                                         [AEpoch 11: 100%|██████████| 27/27 [00:00<00:00, 36.66it/s, train_loss=0.00302, val_loss=0.00332]Epoch 11: 100%|██████████| 27/27 [00:00<00:00, 36.60it/s, train_loss=0.00302, val_loss=0.00332]Epoch 11:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00332]         Epoch 12:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00332]Epoch 12:   4%|▎         | 1/27 [00:00<00:00, 93.31it/s, train_loss=0.00302, val_loss=0.00332]Epoch 12:   4%|▎         | 1/27 [00:00<00:00, 38.77it/s, train_loss=0.00277, val_loss=0.00332]Epoch 12:   7%|▋         | 2/27 [00:00<00:00, 56.54it/s, train_loss=0.00277, val_loss=0.00332]Epoch 12:   7%|▋         | 2/27 [00:00<00:00, 39.33it/s, train_loss=0.00304, val_loss=0.00332]Epoch 12:  11%|█         | 3/27 [00:00<00:00, 49.32it/s, train_loss=0.00304, val_loss=0.00332]Epoch 12:  11%|█         | 3/27 [00:00<00:00, 40.58it/s, train_loss=0.00314, val_loss=0.00332]Epoch 12:  15%|█▍        | 4/27 [00:00<00:00, 47.74it/s, train_loss=0.00314, val_loss=0.00332]Epoch 12:  15%|█▍        | 4/27 [00:00<00:00, 41.20it/s, train_loss=0.00334, val_loss=0.00332]Epoch 12:  19%|█▊        | 5/27 [00:00<00:00, 46.99it/s, train_loss=0.00334, val_loss=0.00332]Epoch 12:  19%|█▊        | 5/27 [00:00<00:00, 40.96it/s, train_loss=0.00329, val_loss=0.00332]Epoch 12:  22%|██▏       | 6/27 [00:00<00:00, 45.65it/s, train_loss=0.00329, val_loss=0.00332]Epoch 12:  22%|██▏       | 6/27 [00:00<00:00, 41.53it/s, train_loss=0.00344, val_loss=0.00332]Epoch 12:  26%|██▌       | 7/27 [00:00<00:00, 45.38it/s, train_loss=0.00344, val_loss=0.00332]Epoch 12:  26%|██▌       | 7/27 [00:00<00:00, 41.63it/s, train_loss=0.003, val_loss=0.00332]  Epoch 12:  30%|██▉       | 8/27 [00:00<00:00, 45.10it/s, train_loss=0.003, val_loss=0.00332]Epoch 12:  30%|██▉       | 8/27 [00:00<00:00, 41.49it/s, train_loss=0.00316, val_loss=0.00332]Epoch 12:  33%|███▎      | 9/27 [00:00<00:00, 44.55it/s, train_loss=0.00316, val_loss=0.00332]Epoch 12:  33%|███▎      | 9/27 [00:00<00:00, 41.81it/s, train_loss=0.0032, val_loss=0.00332] Epoch 12:  37%|███▋      | 10/27 [00:00<00:00, 44.44it/s, train_loss=0.0032, val_loss=0.00332]Epoch 12:  37%|███▋      | 10/27 [00:00<00:00, 41.94it/s, train_loss=0.00302, val_loss=0.00332]Epoch 12:  41%|████      | 11/27 [00:00<00:00, 44.41it/s, train_loss=0.00302, val_loss=0.00332]Epoch 12:  41%|████      | 11/27 [00:00<00:00, 41.81it/s, train_loss=0.00326, val_loss=0.00332]Epoch 12:  44%|████▍     | 12/27 [00:00<00:00, 44.01it/s, train_loss=0.00326, val_loss=0.00332]Epoch 12:  44%|████▍     | 12/27 [00:00<00:00, 42.01it/s, train_loss=0.00348, val_loss=0.00332]Epoch 12:  48%|████▊     | 13/27 [00:00<00:00, 43.97it/s, train_loss=0.00348, val_loss=0.00332]Epoch 12:  48%|████▊     | 13/27 [00:00<00:00, 42.10it/s, train_loss=0.00313, val_loss=0.00332]Epoch 12:  52%|█████▏    | 14/27 [00:00<00:00, 43.97it/s, train_loss=0.00313, val_loss=0.00332]Epoch 12:  52%|█████▏    | 14/27 [00:00<00:00, 41.93it/s, train_loss=0.00293, val_loss=0.00332]Epoch 12:  56%|█████▌    | 15/27 [00:00<00:00, 43.65it/s, train_loss=0.00293, val_loss=0.00332]Epoch 12:  56%|█████▌    | 15/27 [00:00<00:00, 41.81it/s, train_loss=0.00296, val_loss=0.00332]Epoch 12:  59%|█████▉    | 16/27 [00:00<00:00, 43.35it/s, train_loss=0.00296, val_loss=0.00332]Epoch 12:  59%|█████▉    | 16/27 [00:00<00:00, 41.85it/s, train_loss=0.00382, val_loss=0.00332]Epoch 12:  63%|██████▎   | 17/27 [00:00<00:00, 43.39it/s, train_loss=0.00382, val_loss=0.00332]Epoch 12:  63%|██████▎   | 17/27 [00:00<00:00, 41.72it/s, train_loss=0.00322, val_loss=0.00332]Epoch 12:  67%|██████▋   | 18/27 [00:00<00:00, 43.16it/s, train_loss=0.00322, val_loss=0.00332]Epoch 12:  67%|██████▋   | 18/27 [00:00<00:00, 41.64it/s, train_loss=0.00328, val_loss=0.00332]Epoch 12:  70%|███████   | 19/27 [00:00<00:00, 42.99it/s, train_loss=0.00328, val_loss=0.00332]Epoch 12:  70%|███████   | 19/27 [00:00<00:00, 41.56it/s, train_loss=0.00342, val_loss=0.00332]Epoch 12:  74%|███████▍  | 20/27 [00:00<00:00, 42.82it/s, train_loss=0.00342, val_loss=0.00332]Epoch 12:  74%|███████▍  | 20/27 [00:00<00:00, 41.66it/s, train_loss=0.00278, val_loss=0.00332]Epoch 12:  78%|███████▊  | 21/27 [00:00<00:00, 42.93it/s, train_loss=0.00278, val_loss=0.00332]Epoch 12:  78%|███████▊  | 21/27 [00:00<00:00, 41.59it/s, train_loss=0.00308, val_loss=0.00332]Epoch 12:  81%|████████▏ | 22/27 [00:00<00:00, 42.74it/s, train_loss=0.00308, val_loss=0.00332]Epoch 12:  81%|████████▏ | 22/27 [00:00<00:00, 41.49it/s, train_loss=0.00317, val_loss=0.00332]Epoch 12:  85%|████████▌ | 23/27 [00:00<00:00, 42.60it/s, train_loss=0.00317, val_loss=0.00332]Epoch 12:  85%|████████▌ | 23/27 [00:00<00:00, 41.41it/s, train_loss=0.00309, val_loss=0.00332]Epoch 12:  89%|████████▉ | 24/27 [00:00<00:00, 42.41it/s, train_loss=0.00309, val_loss=0.00332]Epoch 12:  89%|████████▉ | 24/27 [00:00<00:00, 41.46it/s, train_loss=0.00297, val_loss=0.00332]Epoch 12:  93%|█████████▎| 25/27 [00:00<00:00, 42.40it/s, train_loss=0.00297, val_loss=0.00332]Epoch 12:  93%|█████████▎| 25/27 [00:00<00:00, 41.40it/s, train_loss=0.00313, val_loss=0.00332]Epoch 12:  96%|█████████▋| 26/27 [00:00<00:00, 42.42it/s, train_loss=0.00313, val_loss=0.00332]Epoch 12:  96%|█████████▋| 26/27 [00:00<00:00, 41.37it/s, train_loss=0.00332, val_loss=0.00332]Epoch 12: 100%|██████████| 27/27 [00:00<00:00, 42.31it/s, train_loss=0.00332, val_loss=0.00332]Epoch 12: 100%|██████████| 27/27 [00:00<00:00, 41.59it/s, train_loss=0.00308, val_loss=0.00332]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 150.24it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 167.09it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 173.56it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 178.18it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 181.17it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 182.05it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 181.71it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 182.49it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 182.97it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 184.00it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 185.00it/s][A
                                                                         [AEpoch 12: 100%|██████████| 27/27 [00:00<00:00, 36.87it/s, train_loss=0.00308, val_loss=0.00305]Epoch 12: 100%|██████████| 27/27 [00:00<00:00, 36.82it/s, train_loss=0.00308, val_loss=0.00305]Epoch 12:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00308, val_loss=0.00305]         Epoch 13:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00308, val_loss=0.00305]Epoch 13:   4%|▎         | 1/27 [00:00<00:00, 93.44it/s, train_loss=0.00308, val_loss=0.00305]Epoch 13:   4%|▎         | 1/27 [00:00<00:00, 42.77it/s, train_loss=0.00272, val_loss=0.00305]Epoch 13:   7%|▋         | 2/27 [00:00<00:00, 59.94it/s, train_loss=0.00272, val_loss=0.00305]Epoch 13:   7%|▋         | 2/27 [00:00<00:00, 42.44it/s, train_loss=0.00283, val_loss=0.00305]Epoch 13:  11%|█         | 3/27 [00:00<00:00, 52.96it/s, train_loss=0.00283, val_loss=0.00305]Epoch 13:  11%|█         | 3/27 [00:00<00:00, 41.63it/s, train_loss=0.00327, val_loss=0.00305]Epoch 13:  15%|█▍        | 4/27 [00:00<00:00, 48.38it/s, train_loss=0.00327, val_loss=0.00305]Epoch 13:  15%|█▍        | 4/27 [00:00<00:00, 40.90it/s, train_loss=0.00296, val_loss=0.00305]Epoch 13:  19%|█▊        | 5/27 [00:00<00:00, 46.25it/s, train_loss=0.00296, val_loss=0.00305]Epoch 13:  19%|█▊        | 5/27 [00:00<00:00, 40.54it/s, train_loss=0.00256, val_loss=0.00305]Epoch 13:  22%|██▏       | 6/27 [00:00<00:00, 45.09it/s, train_loss=0.00256, val_loss=0.00305]Epoch 13:  22%|██▏       | 6/27 [00:00<00:00, 40.51it/s, train_loss=0.00269, val_loss=0.00305]Epoch 13:  26%|██▌       | 7/27 [00:00<00:00, 44.21it/s, train_loss=0.00269, val_loss=0.00305]Epoch 13:  26%|██▌       | 7/27 [00:00<00:00, 40.73it/s, train_loss=0.00316, val_loss=0.00305]Epoch 13:  30%|██▉       | 8/27 [00:00<00:00, 44.01it/s, train_loss=0.00316, val_loss=0.00305]Epoch 13:  30%|██▉       | 8/27 [00:00<00:00, 40.59it/s, train_loss=0.00338, val_loss=0.00305]Epoch 13:  33%|███▎      | 9/27 [00:00<00:00, 43.55it/s, train_loss=0.00338, val_loss=0.00305]Epoch 13:  33%|███▎      | 9/27 [00:00<00:00, 40.46it/s, train_loss=0.00335, val_loss=0.00305]Epoch 13:  37%|███▋      | 10/27 [00:00<00:00, 42.74it/s, train_loss=0.00335, val_loss=0.00305]Epoch 13:  37%|███▋      | 10/27 [00:00<00:00, 40.31it/s, train_loss=0.00323, val_loss=0.00305]Epoch 13:  41%|████      | 11/27 [00:00<00:00, 42.74it/s, train_loss=0.00323, val_loss=0.00305]Epoch 13:  41%|████      | 11/27 [00:00<00:00, 40.68it/s, train_loss=0.00316, val_loss=0.00305]Epoch 13:  44%|████▍     | 12/27 [00:00<00:00, 42.84it/s, train_loss=0.00316, val_loss=0.00305]Epoch 13:  44%|████▍     | 12/27 [00:00<00:00, 40.78it/s, train_loss=0.003, val_loss=0.00305]  Epoch 13:  48%|████▊     | 13/27 [00:00<00:00, 42.81it/s, train_loss=0.003, val_loss=0.00305]Epoch 13:  48%|████▊     | 13/27 [00:00<00:00, 40.74it/s, train_loss=0.00289, val_loss=0.00305]Epoch 13:  52%|█████▏    | 14/27 [00:00<00:00, 42.61it/s, train_loss=0.00289, val_loss=0.00305]Epoch 13:  52%|█████▏    | 14/27 [00:00<00:00, 40.99it/s, train_loss=0.00288, val_loss=0.00305]Epoch 13:  56%|█████▌    | 15/27 [00:00<00:00, 42.57it/s, train_loss=0.00288, val_loss=0.00305]Epoch 13:  56%|█████▌    | 15/27 [00:00<00:00, 41.10it/s, train_loss=0.0029, val_loss=0.00305] Epoch 13:  59%|█████▉    | 16/27 [00:00<00:00, 42.75it/s, train_loss=0.0029, val_loss=0.00305]Epoch 13:  59%|█████▉    | 16/27 [00:00<00:00, 41.06it/s, train_loss=0.00252, val_loss=0.00305]Epoch 13:  63%|██████▎   | 17/27 [00:00<00:00, 42.57it/s, train_loss=0.00252, val_loss=0.00305]Epoch 13:  63%|██████▎   | 17/27 [00:00<00:00, 40.95it/s, train_loss=0.00283, val_loss=0.00305]Epoch 13:  67%|██████▋   | 18/27 [00:00<00:00, 42.25it/s, train_loss=0.00283, val_loss=0.00305]Epoch 13:  67%|██████▋   | 18/27 [00:00<00:00, 41.07it/s, train_loss=0.00325, val_loss=0.00305]Epoch 13:  70%|███████   | 19/27 [00:00<00:00, 42.32it/s, train_loss=0.00325, val_loss=0.00305]Epoch 13:  70%|███████   | 19/27 [00:00<00:00, 41.00it/s, train_loss=0.00347, val_loss=0.00305]Epoch 13:  74%|███████▍  | 20/27 [00:00<00:00, 42.28it/s, train_loss=0.00347, val_loss=0.00305]Epoch 13:  74%|███████▍  | 20/27 [00:00<00:00, 40.94it/s, train_loss=0.00265, val_loss=0.00305]Epoch 13:  78%|███████▊  | 21/27 [00:00<00:00, 42.15it/s, train_loss=0.00265, val_loss=0.00305]Epoch 13:  78%|███████▊  | 21/27 [00:00<00:00, 40.91it/s, train_loss=0.00279, val_loss=0.00305]Epoch 13:  81%|████████▏ | 22/27 [00:00<00:00, 41.96it/s, train_loss=0.00279, val_loss=0.00305]Epoch 13:  81%|████████▏ | 22/27 [00:00<00:00, 41.03it/s, train_loss=0.00265, val_loss=0.00305]Epoch 13:  85%|████████▌ | 23/27 [00:00<00:00, 42.05it/s, train_loss=0.00265, val_loss=0.00305]Epoch 13:  85%|████████▌ | 23/27 [00:00<00:00, 40.96it/s, train_loss=0.00289, val_loss=0.00305]Epoch 13:  89%|████████▉ | 24/27 [00:00<00:00, 42.02it/s, train_loss=0.00289, val_loss=0.00305]Epoch 13:  89%|████████▉ | 24/27 [00:00<00:00, 40.90it/s, train_loss=0.00307, val_loss=0.00305]Epoch 13:  93%|█████████▎| 25/27 [00:00<00:00, 41.90it/s, train_loss=0.00307, val_loss=0.00305]Epoch 13:  93%|█████████▎| 25/27 [00:00<00:00, 40.83it/s, train_loss=0.003, val_loss=0.00305]  Epoch 13:  96%|█████████▋| 26/27 [00:00<00:00, 41.75it/s, train_loss=0.003, val_loss=0.00305]Epoch 13:  96%|█████████▋| 26/27 [00:00<00:00, 40.95it/s, train_loss=0.00282, val_loss=0.00305]Epoch 13: 100%|██████████| 27/27 [00:00<00:00, 41.69it/s, train_loss=0.00282, val_loss=0.00305]Epoch 13: 100%|██████████| 27/27 [00:00<00:00, 41.13it/s, train_loss=0.00273, val_loss=0.00305]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 131.49it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 163.26it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 176.00it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 182.14it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 185.16it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 187.66it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 190.35it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 191.23it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 189.40it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 187.01it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 188.61it/s][A
                                                                         [AEpoch 13: 100%|██████████| 27/27 [00:00<00:00, 36.45it/s, train_loss=0.00273, val_loss=0.00276]Epoch 13: 100%|██████████| 27/27 [00:00<00:00, 36.39it/s, train_loss=0.00273, val_loss=0.00276]Epoch 13:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00273, val_loss=0.00276]         Epoch 14:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00273, val_loss=0.00276]Epoch 14:   4%|▎         | 1/27 [00:00<00:00, 87.95it/s, train_loss=0.00273, val_loss=0.00276]Epoch 14:   4%|▎         | 1/27 [00:00<00:00, 42.77it/s, train_loss=0.00271, val_loss=0.00276]Epoch 14:   7%|▋         | 2/27 [00:00<00:00, 57.82it/s, train_loss=0.00271, val_loss=0.00276]Epoch 14:   7%|▋         | 2/27 [00:00<00:00, 42.14it/s, train_loss=0.00266, val_loss=0.00276]Epoch 14:  11%|█         | 3/27 [00:00<00:00, 52.33it/s, train_loss=0.00266, val_loss=0.00276]Epoch 14:  11%|█         | 3/27 [00:00<00:00, 41.35it/s, train_loss=0.00292, val_loss=0.00276]Epoch 14:  15%|█▍        | 4/27 [00:00<00:00, 48.57it/s, train_loss=0.00292, val_loss=0.00276]Epoch 14:  15%|█▍        | 4/27 [00:00<00:00, 40.98it/s, train_loss=0.00311, val_loss=0.00276]Epoch 14:  19%|█▊        | 5/27 [00:00<00:00, 46.20it/s, train_loss=0.00311, val_loss=0.00276]Epoch 14:  19%|█▊        | 5/27 [00:00<00:00, 41.58it/s, train_loss=0.0026, val_loss=0.00276] Epoch 14:  22%|██▏       | 6/27 [00:00<00:00, 45.69it/s, train_loss=0.0026, val_loss=0.00276]Epoch 14:  22%|██▏       | 6/27 [00:00<00:00, 41.64it/s, train_loss=0.00267, val_loss=0.00276]Epoch 14:  26%|██▌       | 7/27 [00:00<00:00, 45.55it/s, train_loss=0.00267, val_loss=0.00276]Epoch 14:  26%|██▌       | 7/27 [00:00<00:00, 41.45it/s, train_loss=0.00289, val_loss=0.00276]Epoch 14:  30%|██▉       | 8/27 [00:00<00:00, 44.80it/s, train_loss=0.00289, val_loss=0.00276]Epoch 14:  30%|██▉       | 8/27 [00:00<00:00, 41.24it/s, train_loss=0.00273, val_loss=0.00276]Epoch 14:  33%|███▎      | 9/27 [00:00<00:00, 43.99it/s, train_loss=0.00273, val_loss=0.00276]Epoch 14:  33%|███▎      | 9/27 [00:00<00:00, 41.49it/s, train_loss=0.0026, val_loss=0.00276] Epoch 14:  37%|███▋      | 10/27 [00:00<00:00, 43.89it/s, train_loss=0.0026, val_loss=0.00276]Epoch 14:  37%|███▋      | 10/27 [00:00<00:00, 41.67it/s, train_loss=0.00251, val_loss=0.00276]Epoch 14:  41%|████      | 11/27 [00:00<00:00, 44.07it/s, train_loss=0.00251, val_loss=0.00276]Epoch 14:  41%|████      | 11/27 [00:00<00:00, 41.50it/s, train_loss=0.00257, val_loss=0.00276]Epoch 14:  44%|████▍     | 12/27 [00:00<00:00, 43.64it/s, train_loss=0.00257, val_loss=0.00276]Epoch 14:  44%|████▍     | 12/27 [00:00<00:00, 41.37it/s, train_loss=0.00276, val_loss=0.00276]Epoch 14:  48%|████▊     | 13/27 [00:00<00:00, 43.05it/s, train_loss=0.00276, val_loss=0.00276]Epoch 14:  48%|████▊     | 13/27 [00:00<00:00, 41.44it/s, train_loss=0.00281, val_loss=0.00276]Epoch 14:  52%|█████▏    | 14/27 [00:00<00:00, 43.34it/s, train_loss=0.00281, val_loss=0.00276]Epoch 14:  52%|█████▏    | 14/27 [00:00<00:00, 41.35it/s, train_loss=0.00277, val_loss=0.00276]Epoch 14:  56%|█████▌    | 15/27 [00:00<00:00, 43.12it/s, train_loss=0.00277, val_loss=0.00276]Epoch 14:  56%|█████▌    | 15/27 [00:00<00:00, 41.31it/s, train_loss=0.00265, val_loss=0.00276]Epoch 14:  59%|█████▉    | 16/27 [00:00<00:00, 42.82it/s, train_loss=0.00265, val_loss=0.00276]Epoch 14:  59%|█████▉    | 16/27 [00:00<00:00, 41.47it/s, train_loss=0.00266, val_loss=0.00276]Epoch 14:  63%|██████▎   | 17/27 [00:00<00:00, 42.74it/s, train_loss=0.00266, val_loss=0.00276]Epoch 14:  63%|██████▎   | 17/27 [00:00<00:00, 41.52it/s, train_loss=0.00284, val_loss=0.00276]Epoch 14:  67%|██████▋   | 18/27 [00:00<00:00, 42.99it/s, train_loss=0.00284, val_loss=0.00276]Epoch 14:  67%|██████▋   | 18/27 [00:00<00:00, 41.47it/s, train_loss=0.00293, val_loss=0.00276]Epoch 14:  70%|███████   | 19/27 [00:00<00:00, 42.80it/s, train_loss=0.00293, val_loss=0.00276]Epoch 14:  70%|███████   | 19/27 [00:00<00:00, 41.62it/s, train_loss=0.00256, val_loss=0.00276]Epoch 14:  74%|███████▍  | 20/27 [00:00<00:00, 42.79it/s, train_loss=0.00256, val_loss=0.00276]Epoch 14:  74%|███████▍  | 20/27 [00:00<00:00, 41.62it/s, train_loss=0.00265, val_loss=0.00276]Epoch 14:  78%|███████▊  | 21/27 [00:00<00:00, 42.87it/s, train_loss=0.00265, val_loss=0.00276]Epoch 14:  78%|███████▊  | 21/27 [00:00<00:00, 41.56it/s, train_loss=0.00234, val_loss=0.00276]Epoch 14:  81%|████████▏ | 22/27 [00:00<00:00, 42.74it/s, train_loss=0.00234, val_loss=0.00276]Epoch 14:  81%|████████▏ | 22/27 [00:00<00:00, 41.67it/s, train_loss=0.0026, val_loss=0.00276] Epoch 14:  85%|████████▌ | 23/27 [00:00<00:00, 42.68it/s, train_loss=0.0026, val_loss=0.00276]Epoch 14:  85%|████████▌ | 23/27 [00:00<00:00, 41.71it/s, train_loss=0.00258, val_loss=0.00276]Epoch 14:  89%|████████▉ | 24/27 [00:00<00:00, 42.50it/s, train_loss=0.00258, val_loss=0.00276]Epoch 14:  89%|████████▉ | 24/27 [00:00<00:00, 41.58it/s, train_loss=0.00257, val_loss=0.00276]Epoch 14:  93%|█████████▎| 25/27 [00:00<00:00, 42.61it/s, train_loss=0.00257, val_loss=0.00276]Epoch 14:  93%|█████████▎| 25/27 [00:00<00:00, 41.53it/s, train_loss=0.00275, val_loss=0.00276]Epoch 14:  96%|█████████▋| 26/27 [00:00<00:00, 42.52it/s, train_loss=0.00275, val_loss=0.00276]Epoch 14:  96%|█████████▋| 26/27 [00:00<00:00, 41.48it/s, train_loss=0.00278, val_loss=0.00276]Epoch 14: 100%|██████████| 27/27 [00:00<00:00, 42.33it/s, train_loss=0.00278, val_loss=0.00276]Epoch 14: 100%|██████████| 27/27 [00:00<00:00, 41.67it/s, train_loss=0.00257, val_loss=0.00276]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 121.82it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 143.90it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 152.07it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 155.67it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 158.84it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 161.01it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 162.45it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 163.06it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 166.47it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 170.38it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 174.37it/s][A
                                                                         [AEpoch 14: 100%|██████████| 27/27 [00:00<00:00, 36.73it/s, train_loss=0.00257, val_loss=0.00256]Epoch 14: 100%|██████████| 27/27 [00:00<00:00, 36.70it/s, train_loss=0.00257, val_loss=0.00256]Epoch 14:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00257, val_loss=0.00256]         Epoch 15:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00257, val_loss=0.00256]Epoch 15:   4%|▎         | 1/27 [00:00<00:00, 95.41it/s, train_loss=0.00257, val_loss=0.00256]Epoch 15:   4%|▎         | 1/27 [00:00<00:00, 39.81it/s, train_loss=0.0023, val_loss=0.00256] Epoch 15:   7%|▋         | 2/27 [00:00<00:00, 57.66it/s, train_loss=0.0023, val_loss=0.00256]Epoch 15:   7%|▋         | 2/27 [00:00<00:00, 42.03it/s, train_loss=0.00279, val_loss=0.00256]Epoch 15:  11%|█         | 3/27 [00:00<00:00, 51.25it/s, train_loss=0.00279, val_loss=0.00256]Epoch 15:  11%|█         | 3/27 [00:00<00:00, 42.24it/s, train_loss=0.00308, val_loss=0.00256]Epoch 15:  15%|█▍        | 4/27 [00:00<00:00, 49.72it/s, train_loss=0.00308, val_loss=0.00256]Epoch 15:  15%|█▍        | 4/27 [00:00<00:00, 41.56it/s, train_loss=0.00283, val_loss=0.00256]Epoch 15:  19%|█▊        | 5/27 [00:00<00:00, 47.28it/s, train_loss=0.00283, val_loss=0.00256]Epoch 15:  19%|█▊        | 5/27 [00:00<00:00, 41.30it/s, train_loss=0.00277, val_loss=0.00256]Epoch 15:  22%|██▏       | 6/27 [00:00<00:00, 45.45it/s, train_loss=0.00277, val_loss=0.00256]Epoch 15:  22%|██▏       | 6/27 [00:00<00:00, 41.68it/s, train_loss=0.00232, val_loss=0.00256]Epoch 15:  26%|██▌       | 7/27 [00:00<00:00, 45.63it/s, train_loss=0.00232, val_loss=0.00256]Epoch 15:  26%|██▌       | 7/27 [00:00<00:00, 41.48it/s, train_loss=0.00278, val_loss=0.00256]Epoch 15:  30%|██▉       | 8/27 [00:00<00:00, 44.87it/s, train_loss=0.00278, val_loss=0.00256]Epoch 15:  30%|██▉       | 8/27 [00:00<00:00, 41.29it/s, train_loss=0.00254, val_loss=0.00256]Epoch 15:  33%|███▎      | 9/27 [00:00<00:00, 44.07it/s, train_loss=0.00254, val_loss=0.00256]Epoch 15:  33%|███▎      | 9/27 [00:00<00:00, 41.56it/s, train_loss=0.00232, val_loss=0.00256]Epoch 15:  37%|███▋      | 10/27 [00:00<00:00, 43.95it/s, train_loss=0.00232, val_loss=0.00256]Epoch 15:  37%|███▋      | 10/27 [00:00<00:00, 41.67it/s, train_loss=0.00232, val_loss=0.00256]Epoch 15:  41%|████      | 11/27 [00:00<00:00, 44.08it/s, train_loss=0.00232, val_loss=0.00256]Epoch 15:  41%|████      | 11/27 [00:00<00:00, 41.47it/s, train_loss=0.00262, val_loss=0.00256]Epoch 15:  44%|████▍     | 12/27 [00:00<00:00, 43.63it/s, train_loss=0.00262, val_loss=0.00256]Epoch 15:  44%|████▍     | 12/27 [00:00<00:00, 41.33it/s, train_loss=0.00273, val_loss=0.00256]Epoch 15:  48%|████▊     | 13/27 [00:00<00:00, 43.19it/s, train_loss=0.00273, val_loss=0.00256]Epoch 15:  48%|████▊     | 13/27 [00:00<00:00, 41.42it/s, train_loss=0.00291, val_loss=0.00256]Epoch 15:  52%|█████▏    | 14/27 [00:00<00:00, 43.07it/s, train_loss=0.00291, val_loss=0.00256]Epoch 15:  52%|█████▏    | 14/27 [00:00<00:00, 41.55it/s, train_loss=0.0022, val_loss=0.00256] Epoch 15:  56%|█████▌    | 15/27 [00:00<00:00, 43.30it/s, train_loss=0.0022, val_loss=0.00256]Epoch 15:  56%|█████▌    | 15/27 [00:00<00:00, 41.46it/s, train_loss=0.00243, val_loss=0.00256]Epoch 15:  59%|█████▉    | 16/27 [00:00<00:00, 43.03it/s, train_loss=0.00243, val_loss=0.00256]Epoch 15:  59%|█████▉    | 16/27 [00:00<00:00, 41.36it/s, train_loss=0.0023, val_loss=0.00256] Epoch 15:  63%|██████▎   | 17/27 [00:00<00:00, 42.66it/s, train_loss=0.0023, val_loss=0.00256]Epoch 15:  63%|██████▎   | 17/27 [00:00<00:00, 41.45it/s, train_loss=0.00252, val_loss=0.00256]Epoch 15:  67%|██████▋   | 18/27 [00:00<00:00, 42.92it/s, train_loss=0.00252, val_loss=0.00256]Epoch 15:  67%|██████▋   | 18/27 [00:00<00:00, 41.40it/s, train_loss=0.00255, val_loss=0.00256]Epoch 15:  70%|███████   | 19/27 [00:00<00:00, 42.76it/s, train_loss=0.00255, val_loss=0.00256]Epoch 15:  70%|███████   | 19/27 [00:00<00:00, 41.37it/s, train_loss=0.00224, val_loss=0.00256]Epoch 15:  74%|███████▍  | 20/27 [00:00<00:00, 42.50it/s, train_loss=0.00224, val_loss=0.00256]Epoch 15:  74%|███████▍  | 20/27 [00:00<00:00, 41.46it/s, train_loss=0.00277, val_loss=0.00256]Epoch 15:  78%|███████▊  | 21/27 [00:00<00:00, 42.58it/s, train_loss=0.00277, val_loss=0.00256]Epoch 15:  78%|███████▊  | 21/27 [00:00<00:00, 41.34it/s, train_loss=0.00243, val_loss=0.00256]Epoch 15:  81%|████████▏ | 22/27 [00:00<00:00, 42.55it/s, train_loss=0.00243, val_loss=0.00256]Epoch 15:  81%|████████▏ | 22/27 [00:00<00:00, 41.30it/s, train_loss=0.00249, val_loss=0.00256]Epoch 15:  85%|████████▌ | 23/27 [00:00<00:00, 42.42it/s, train_loss=0.00249, val_loss=0.00256]Epoch 15:  85%|████████▌ | 23/27 [00:00<00:00, 41.13it/s, train_loss=0.00228, val_loss=0.00256]Epoch 15:  89%|████████▉ | 24/27 [00:00<00:00, 40.98it/s, train_loss=0.00228, val_loss=0.00256]Epoch 15:  89%|████████▉ | 24/27 [00:00<00:00, 39.77it/s, train_loss=0.0028, val_loss=0.00256] Epoch 15:  93%|█████████▎| 25/27 [00:00<00:00, 39.62it/s, train_loss=0.0028, val_loss=0.00256]Epoch 15:  93%|█████████▎| 25/27 [00:00<00:00, 38.56it/s, train_loss=0.00248, val_loss=0.00256]Epoch 15:  96%|█████████▋| 26/27 [00:00<00:00, 38.47it/s, train_loss=0.00248, val_loss=0.00256]Epoch 15:  96%|█████████▋| 26/27 [00:00<00:00, 37.51it/s, train_loss=0.00263, val_loss=0.00256]Epoch 15: 100%|██████████| 27/27 [00:00<00:00, 37.51it/s, train_loss=0.00263, val_loss=0.00256]Epoch 15: 100%|██████████| 27/27 [00:00<00:00, 36.59it/s, train_loss=0.00264, val_loss=0.00256]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:01,  8.11it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 11.06it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 12.66it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 13.64it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 14.31it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 14.79it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 15.16it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 15.44it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 15.67it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 15.86it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 16.01it/s][A
                                                                        [AEpoch 15: 100%|██████████| 27/27 [00:01<00:00, 17.05it/s, train_loss=0.00264, val_loss=0.00236]Epoch 15: 100%|██████████| 27/27 [00:01<00:00, 16.85it/s, train_loss=0.00264, val_loss=0.00236]Epoch 15:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00264, val_loss=0.00236]         Epoch 16:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00264, val_loss=0.00236]Epoch 16:   4%|▎         | 1/27 [00:00<00:01, 21.66it/s, train_loss=0.00264, val_loss=0.00236]Epoch 16:   4%|▎         | 1/27 [00:00<00:01, 15.72it/s, train_loss=0.0026, val_loss=0.00236] Epoch 16:   7%|▋         | 2/27 [00:00<00:01, 22.01it/s, train_loss=0.0026, val_loss=0.00236]Epoch 16:   7%|▋         | 2/27 [00:00<00:01, 18.56it/s, train_loss=0.00241, val_loss=0.00236]Epoch 16:  11%|█         | 3/27 [00:00<00:01, 22.11it/s, train_loss=0.00241, val_loss=0.00236]Epoch 16:  11%|█         | 3/27 [00:00<00:01, 19.50it/s, train_loss=0.00258, val_loss=0.00236]Epoch 16:  15%|█▍        | 4/27 [00:00<00:01, 22.09it/s, train_loss=0.00258, val_loss=0.00236]Epoch 16:  15%|█▍        | 4/27 [00:00<00:01, 20.21it/s, train_loss=0.00258, val_loss=0.00236]Epoch 16:  19%|█▊        | 5/27 [00:00<00:00, 22.11it/s, train_loss=0.00258, val_loss=0.00236]Epoch 16:  19%|█▊        | 5/27 [00:00<00:01, 20.53it/s, train_loss=0.0023, val_loss=0.00236] Epoch 16:  22%|██▏       | 6/27 [00:00<00:00, 22.08it/s, train_loss=0.0023, val_loss=0.00236]Epoch 16:  22%|██▏       | 6/27 [00:00<00:01, 20.70it/s, train_loss=0.00248, val_loss=0.00236]Epoch 16:  26%|██▌       | 7/27 [00:00<00:00, 21.94it/s, train_loss=0.00248, val_loss=0.00236]Epoch 16:  26%|██▌       | 7/27 [00:00<00:00, 20.84it/s, train_loss=0.00241, val_loss=0.00236]Epoch 16:  30%|██▉       | 8/27 [00:00<00:00, 21.98it/s, train_loss=0.00241, val_loss=0.00236]Epoch 16:  30%|██▉       | 8/27 [00:00<00:00, 20.94it/s, train_loss=0.00242, val_loss=0.00236]Epoch 16:  33%|███▎      | 9/27 [00:00<00:00, 21.88it/s, train_loss=0.00242, val_loss=0.00236]Epoch 16:  33%|███▎      | 9/27 [00:00<00:00, 20.96it/s, train_loss=0.00244, val_loss=0.00236]Epoch 16:  37%|███▋      | 10/27 [00:00<00:00, 21.84it/s, train_loss=0.00244, val_loss=0.00236]Epoch 16:  37%|███▋      | 10/27 [00:00<00:00, 21.07it/s, train_loss=0.00257, val_loss=0.00236]Epoch 16:  41%|████      | 11/27 [00:00<00:00, 21.88it/s, train_loss=0.00257, val_loss=0.00236]Epoch 16:  41%|████      | 11/27 [00:00<00:00, 21.16it/s, train_loss=0.00251, val_loss=0.00236]Epoch 16:  44%|████▍     | 12/27 [00:00<00:00, 21.87it/s, train_loss=0.00251, val_loss=0.00236]Epoch 16:  44%|████▍     | 12/27 [00:00<00:00, 21.21it/s, train_loss=0.00256, val_loss=0.00236]Epoch 16:  48%|████▊     | 13/27 [00:00<00:00, 21.91it/s, train_loss=0.00256, val_loss=0.00236]Epoch 16:  48%|████▊     | 13/27 [00:00<00:00, 21.29it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  52%|█████▏    | 14/27 [00:00<00:00, 21.92it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  52%|█████▏    | 14/27 [00:00<00:00, 21.35it/s, train_loss=0.00254, val_loss=0.00236]Epoch 16:  56%|█████▌    | 15/27 [00:00<00:00, 21.95it/s, train_loss=0.00254, val_loss=0.00236]Epoch 16:  56%|█████▌    | 15/27 [00:00<00:00, 21.40it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  59%|█████▉    | 16/27 [00:00<00:00, 21.97it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  59%|█████▉    | 16/27 [00:00<00:00, 21.44it/s, train_loss=0.00254, val_loss=0.00236]Epoch 16:  63%|██████▎   | 17/27 [00:00<00:00, 21.98it/s, train_loss=0.00254, val_loss=0.00236]Epoch 16:  63%|██████▎   | 17/27 [00:00<00:00, 21.48it/s, train_loss=0.00263, val_loss=0.00236]Epoch 16:  67%|██████▋   | 18/27 [00:00<00:00, 21.99it/s, train_loss=0.00263, val_loss=0.00236]Epoch 16:  67%|██████▋   | 18/27 [00:00<00:00, 21.51it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  70%|███████   | 19/27 [00:00<00:00, 21.96it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  70%|███████   | 19/27 [00:00<00:00, 21.50it/s, train_loss=0.00279, val_loss=0.00236]Epoch 16:  74%|███████▍  | 20/27 [00:00<00:00, 21.93it/s, train_loss=0.00279, val_loss=0.00236]Epoch 16:  74%|███████▍  | 20/27 [00:00<00:00, 21.50it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  78%|███████▊  | 21/27 [00:00<00:00, 21.93it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  78%|███████▊  | 21/27 [00:00<00:00, 21.56it/s, train_loss=0.0023, val_loss=0.00236] Epoch 16:  81%|████████▏ | 22/27 [00:01<00:00, 21.96it/s, train_loss=0.0023, val_loss=0.00236]Epoch 16:  81%|████████▏ | 22/27 [00:01<00:00, 21.58it/s, train_loss=0.00267, val_loss=0.00236]Epoch 16:  85%|████████▌ | 23/27 [00:01<00:00, 21.94it/s, train_loss=0.00267, val_loss=0.00236]Epoch 16:  85%|████████▌ | 23/27 [00:01<00:00, 21.59it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  89%|████████▉ | 24/27 [00:01<00:00, 21.96it/s, train_loss=0.00239, val_loss=0.00236]Epoch 16:  89%|████████▉ | 24/27 [00:01<00:00, 21.62it/s, train_loss=0.00249, val_loss=0.00236]Epoch 16:  93%|█████████▎| 25/27 [00:01<00:00, 21.95it/s, train_loss=0.00249, val_loss=0.00236]Epoch 16:  93%|█████████▎| 25/27 [00:01<00:00, 21.61it/s, train_loss=0.00206, val_loss=0.00236]Epoch 16:  96%|█████████▋| 26/27 [00:01<00:00, 21.95it/s, train_loss=0.00206, val_loss=0.00236]Epoch 16:  96%|█████████▋| 26/27 [00:01<00:00, 21.64it/s, train_loss=0.0019, val_loss=0.00236] Epoch 16: 100%|██████████| 27/27 [00:01<00:00, 21.97it/s, train_loss=0.0019, val_loss=0.00236]Epoch 16: 100%|██████████| 27/27 [00:01<00:00, 21.67it/s, train_loss=0.00255, val_loss=0.00236]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:01,  7.95it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 10.94it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 12.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 13.55it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 14.15it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 14.65it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 15.04it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 15.34it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 15.55it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 15.75it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 15.92it/s][A
                                                                        [AEpoch 16: 100%|██████████| 27/27 [00:02<00:00, 12.90it/s, train_loss=0.00255, val_loss=0.00228]Epoch 16: 100%|██████████| 27/27 [00:02<00:00, 12.79it/s, train_loss=0.00255, val_loss=0.00228]Epoch 16:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00255, val_loss=0.00228]         Epoch 17:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00255, val_loss=0.00228]Epoch 17:   4%|▎         | 1/27 [00:00<00:01, 21.33it/s, train_loss=0.00255, val_loss=0.00228]Epoch 17:   4%|▎         | 1/27 [00:00<00:01, 15.45it/s, train_loss=0.0024, val_loss=0.00228] Epoch 17:   7%|▋         | 2/27 [00:00<00:01, 21.58it/s, train_loss=0.0024, val_loss=0.00228]Epoch 17:   7%|▋         | 2/27 [00:00<00:01, 18.01it/s, train_loss=0.00237, val_loss=0.00228]Epoch 17:  11%|█         | 3/27 [00:00<00:01, 21.52it/s, train_loss=0.00237, val_loss=0.00228]Epoch 17:  11%|█         | 3/27 [00:00<00:01, 19.18it/s, train_loss=0.00218, val_loss=0.00228]Epoch 17:  15%|█▍        | 4/27 [00:00<00:01, 21.50it/s, train_loss=0.00218, val_loss=0.00228]Epoch 17:  15%|█▍        | 4/27 [00:00<00:01, 19.73it/s, train_loss=0.00239, val_loss=0.00228]Epoch 17:  19%|█▊        | 5/27 [00:00<00:01, 21.63it/s, train_loss=0.00239, val_loss=0.00228]Epoch 17:  19%|█▊        | 5/27 [00:00<00:01, 20.20it/s, train_loss=0.0021, val_loss=0.00228] Epoch 17:  22%|██▏       | 6/27 [00:00<00:00, 21.77it/s, train_loss=0.0021, val_loss=0.00228]Epoch 17:  22%|██▏       | 6/27 [00:00<00:01, 20.51it/s, train_loss=0.00239, val_loss=0.00228]Epoch 17:  26%|██▌       | 7/27 [00:00<00:00, 21.79it/s, train_loss=0.00239, val_loss=0.00228]Epoch 17:  26%|██▌       | 7/27 [00:00<00:00, 20.69it/s, train_loss=0.00241, val_loss=0.00228]Epoch 17:  30%|██▉       | 8/27 [00:00<00:00, 21.84it/s, train_loss=0.00241, val_loss=0.00228]Epoch 17:  30%|██▉       | 8/27 [00:00<00:00, 20.87it/s, train_loss=0.00235, val_loss=0.00228]Epoch 17:  33%|███▎      | 9/27 [00:00<00:00, 21.83it/s, train_loss=0.00235, val_loss=0.00228]Epoch 17:  33%|███▎      | 9/27 [00:00<00:00, 20.91it/s, train_loss=0.00233, val_loss=0.00228]Epoch 17:  37%|███▋      | 10/27 [00:00<00:00, 21.81it/s, train_loss=0.00233, val_loss=0.00228]Epoch 17:  37%|███▋      | 10/27 [00:00<00:00, 21.03it/s, train_loss=0.00263, val_loss=0.00228]Epoch 17:  41%|████      | 11/27 [00:00<00:00, 21.86it/s, train_loss=0.00263, val_loss=0.00228]Epoch 17:  41%|████      | 11/27 [00:00<00:00, 21.13it/s, train_loss=0.00276, val_loss=0.00228]Epoch 17:  44%|████▍     | 12/27 [00:00<00:00, 21.90it/s, train_loss=0.00276, val_loss=0.00228]Epoch 17:  44%|████▍     | 12/27 [00:00<00:00, 21.21it/s, train_loss=0.00232, val_loss=0.00228]Epoch 17:  48%|████▊     | 13/27 [00:00<00:00, 21.88it/s, train_loss=0.00232, val_loss=0.00228]Epoch 17:  48%|████▊     | 13/27 [00:00<00:00, 21.23it/s, train_loss=0.00235, val_loss=0.00228]Epoch 17:  52%|█████▏    | 14/27 [00:00<00:00, 21.87it/s, train_loss=0.00235, val_loss=0.00228]Epoch 17:  52%|█████▏    | 14/27 [00:00<00:00, 21.29it/s, train_loss=0.00236, val_loss=0.00228]Epoch 17:  56%|█████▌    | 15/27 [00:00<00:00, 21.87it/s, train_loss=0.00236, val_loss=0.00228]Epoch 17:  56%|█████▌    | 15/27 [00:00<00:00, 21.31it/s, train_loss=0.00225, val_loss=0.00228]Epoch 17:  59%|█████▉    | 16/27 [00:00<00:00, 21.87it/s, train_loss=0.00225, val_loss=0.00228]Epoch 17:  59%|█████▉    | 16/27 [00:00<00:00, 21.37it/s, train_loss=0.00221, val_loss=0.00228]Epoch 17:  63%|██████▎   | 17/27 [00:00<00:00, 21.90it/s, train_loss=0.00221, val_loss=0.00228]Epoch 17:  63%|██████▎   | 17/27 [00:00<00:00, 21.42it/s, train_loss=0.00208, val_loss=0.00228]Epoch 17:  67%|██████▋   | 18/27 [00:00<00:00, 21.97it/s, train_loss=0.00208, val_loss=0.00228]Epoch 17:  67%|██████▋   | 18/27 [00:00<00:00, 21.47it/s, train_loss=0.00249, val_loss=0.00228]Epoch 17:  70%|███████   | 19/27 [00:00<00:00, 21.97it/s, train_loss=0.00249, val_loss=0.00228]Epoch 17:  70%|███████   | 19/27 [00:00<00:00, 21.53it/s, train_loss=0.00217, val_loss=0.00228]Epoch 17:  74%|███████▍  | 20/27 [00:00<00:00, 22.01it/s, train_loss=0.00217, val_loss=0.00228]Epoch 17:  74%|███████▍  | 20/27 [00:00<00:00, 21.58it/s, train_loss=0.00196, val_loss=0.00228]Epoch 17:  78%|███████▊  | 21/27 [00:00<00:00, 22.03it/s, train_loss=0.00196, val_loss=0.00228]Epoch 17:  78%|███████▊  | 21/27 [00:00<00:00, 21.60it/s, train_loss=0.00228, val_loss=0.00228]Epoch 17:  81%|████████▏ | 22/27 [00:00<00:00, 22.02it/s, train_loss=0.00228, val_loss=0.00228]Epoch 17:  81%|████████▏ | 22/27 [00:01<00:00, 21.64it/s, train_loss=0.00228, val_loss=0.00228]Epoch 17:  85%|████████▌ | 23/27 [00:01<00:00, 22.04it/s, train_loss=0.00228, val_loss=0.00228]Epoch 17:  85%|████████▌ | 23/27 [00:01<00:00, 21.46it/s, train_loss=0.00224, val_loss=0.00228]Epoch 17:  89%|████████▉ | 24/27 [00:01<00:00, 21.81it/s, train_loss=0.00224, val_loss=0.00228]Epoch 17:  89%|████████▉ | 24/27 [00:01<00:00, 21.48it/s, train_loss=0.00201, val_loss=0.00228]Epoch 17:  93%|█████████▎| 25/27 [00:01<00:00, 21.87it/s, train_loss=0.00201, val_loss=0.00228]Epoch 17:  93%|█████████▎| 25/27 [00:01<00:00, 21.53it/s, train_loss=0.00213, val_loss=0.00228]Epoch 17:  96%|█████████▋| 26/27 [00:01<00:00, 21.90it/s, train_loss=0.00213, val_loss=0.00228]Epoch 17:  96%|█████████▋| 26/27 [00:01<00:00, 21.44it/s, train_loss=0.00229, val_loss=0.00228]Epoch 17: 100%|██████████| 27/27 [00:01<00:00, 21.78it/s, train_loss=0.00229, val_loss=0.00228]Epoch 17: 100%|██████████| 27/27 [00:01<00:00, 21.47it/s, train_loss=0.00214, val_loss=0.00228]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:01,  7.99it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 11.04it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 12.66it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 13.67it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 14.29it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 14.79it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 15.17it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 15.48it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 15.72it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 15.91it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 16.07it/s][A
                                                                        [AEpoch 17: 100%|██████████| 27/27 [00:02<00:00, 12.86it/s, train_loss=0.00214, val_loss=0.00225]Epoch 17: 100%|██████████| 27/27 [00:02<00:00, 12.75it/s, train_loss=0.00214, val_loss=0.00225]Epoch 17:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00214, val_loss=0.00225]         Epoch 18:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00214, val_loss=0.00225]Epoch 18:   4%|▎         | 1/27 [00:00<00:01, 21.87it/s, train_loss=0.00214, val_loss=0.00225]Epoch 18:   4%|▎         | 1/27 [00:00<00:01, 15.79it/s, train_loss=0.00219, val_loss=0.00225]Epoch 18:   7%|▋         | 2/27 [00:00<00:01, 21.87it/s, train_loss=0.00219, val_loss=0.00225]Epoch 18:   7%|▋         | 2/27 [00:00<00:01, 18.40it/s, train_loss=0.00232, val_loss=0.00225]Epoch 18:  11%|█         | 3/27 [00:00<00:01, 22.00it/s, train_loss=0.00232, val_loss=0.00225]Epoch 18:  11%|█         | 3/27 [00:00<00:01, 19.40it/s, train_loss=0.00235, val_loss=0.00225]Epoch 18:  15%|█▍        | 4/27 [00:00<00:01, 21.75it/s, train_loss=0.00235, val_loss=0.00225]Epoch 18:  15%|█▍        | 4/27 [00:00<00:01, 19.81it/s, train_loss=0.00219, val_loss=0.00225]Epoch 18:  19%|█▊        | 5/27 [00:00<00:01, 21.73it/s, train_loss=0.00219, val_loss=0.00225]Epoch 18:  19%|█▊        | 5/27 [00:00<00:01, 20.24it/s, train_loss=0.00217, val_loss=0.00225]Epoch 18:  22%|██▏       | 6/27 [00:00<00:00, 21.81it/s, train_loss=0.00217, val_loss=0.00225]Epoch 18:  22%|██▏       | 6/27 [00:00<00:01, 20.54it/s, train_loss=0.00249, val_loss=0.00225]Epoch 18:  26%|██▌       | 7/27 [00:00<00:00, 21.93it/s, train_loss=0.00249, val_loss=0.00225]Epoch 18:  26%|██▌       | 7/27 [00:00<00:00, 20.78it/s, train_loss=0.0022, val_loss=0.00225] Epoch 18:  30%|██▉       | 8/27 [00:00<00:00, 21.91it/s, train_loss=0.0022, val_loss=0.00225]Epoch 18:  30%|██▉       | 8/27 [00:00<00:00, 20.88it/s, train_loss=0.00231, val_loss=0.00225]Epoch 18:  33%|███▎      | 9/27 [00:00<00:00, 21.86it/s, train_loss=0.00231, val_loss=0.00225]Epoch 18:  33%|███▎      | 9/27 [00:00<00:00, 21.01it/s, train_loss=0.00212, val_loss=0.00225]Epoch 18:  37%|███▋      | 10/27 [00:00<00:00, 21.96it/s, train_loss=0.00212, val_loss=0.00225]Epoch 18:  37%|███▋      | 10/27 [00:00<00:00, 21.43it/s, train_loss=0.00225, val_loss=0.00225]Epoch 18:  41%|████      | 11/27 [00:00<00:00, 23.06it/s, train_loss=0.00225, val_loss=0.00225]Epoch 18:  41%|████      | 11/27 [00:00<00:00, 22.41it/s, train_loss=0.0021, val_loss=0.00225] Epoch 18:  44%|████▍     | 12/27 [00:00<00:00, 23.99it/s, train_loss=0.0021, val_loss=0.00225]Epoch 18:  44%|████▍     | 12/27 [00:00<00:00, 23.27it/s, train_loss=0.00208, val_loss=0.00225]Epoch 18:  48%|████▊     | 13/27 [00:00<00:00, 24.72it/s, train_loss=0.00208, val_loss=0.00225]Epoch 18:  48%|████▊     | 13/27 [00:00<00:00, 24.16it/s, train_loss=0.00223, val_loss=0.00225]Epoch 18:  52%|█████▏    | 14/27 [00:00<00:00, 25.50it/s, train_loss=0.00223, val_loss=0.00225]Epoch 18:  52%|█████▏    | 14/27 [00:00<00:00, 24.90it/s, train_loss=0.00222, val_loss=0.00225]Epoch 18:  56%|█████▌    | 15/27 [00:00<00:00, 26.24it/s, train_loss=0.00222, val_loss=0.00225]Epoch 18:  56%|█████▌    | 15/27 [00:00<00:00, 25.53it/s, train_loss=0.00253, val_loss=0.00225]Epoch 18:  59%|█████▉    | 16/27 [00:00<00:00, 26.81it/s, train_loss=0.00253, val_loss=0.00225]Epoch 18:  59%|█████▉    | 16/27 [00:00<00:00, 26.13it/s, train_loss=0.00196, val_loss=0.00225]Epoch 18:  63%|██████▎   | 17/27 [00:00<00:00, 27.28it/s, train_loss=0.00196, val_loss=0.00225]Epoch 18:  63%|██████▎   | 17/27 [00:00<00:00, 26.75it/s, train_loss=0.00229, val_loss=0.00225]Epoch 18:  67%|██████▋   | 18/27 [00:00<00:00, 27.92it/s, train_loss=0.00229, val_loss=0.00225]Epoch 18:  67%|██████▋   | 18/27 [00:00<00:00, 27.27it/s, train_loss=0.00225, val_loss=0.00225]Epoch 18:  70%|███████   | 19/27 [00:00<00:00, 28.36it/s, train_loss=0.00225, val_loss=0.00225]Epoch 18:  70%|███████   | 19/27 [00:00<00:00, 27.83it/s, train_loss=0.00228, val_loss=0.00225]Epoch 18:  74%|███████▍  | 20/27 [00:00<00:00, 28.81it/s, train_loss=0.00228, val_loss=0.00225]Epoch 18:  74%|███████▍  | 20/27 [00:00<00:00, 28.30it/s, train_loss=0.00239, val_loss=0.00225]Epoch 18:  78%|███████▊  | 21/27 [00:00<00:00, 29.30it/s, train_loss=0.00239, val_loss=0.00225]Epoch 18:  78%|███████▊  | 21/27 [00:00<00:00, 28.70it/s, train_loss=0.00223, val_loss=0.00225]Epoch 18:  81%|████████▏ | 22/27 [00:00<00:00, 29.66it/s, train_loss=0.00223, val_loss=0.00225]Epoch 18:  81%|████████▏ | 22/27 [00:00<00:00, 29.05it/s, train_loss=0.00228, val_loss=0.00225]Epoch 18:  85%|████████▌ | 23/27 [00:00<00:00, 29.93it/s, train_loss=0.00228, val_loss=0.00225]Epoch 18:  85%|████████▌ | 23/27 [00:00<00:00, 29.47it/s, train_loss=0.00215, val_loss=0.00225]Epoch 18:  89%|████████▉ | 24/27 [00:00<00:00, 30.30it/s, train_loss=0.00215, val_loss=0.00225]Epoch 18:  89%|████████▉ | 24/27 [00:00<00:00, 29.87it/s, train_loss=0.00234, val_loss=0.00225]Epoch 18:  93%|█████████▎| 25/27 [00:00<00:00, 30.75it/s, train_loss=0.00234, val_loss=0.00225]Epoch 18:  93%|█████████▎| 25/27 [00:00<00:00, 30.18it/s, train_loss=0.0023, val_loss=0.00225] Epoch 18:  96%|█████████▋| 26/27 [00:00<00:00, 31.01it/s, train_loss=0.0023, val_loss=0.00225]Epoch 18:  96%|█████████▋| 26/27 [00:00<00:00, 30.45it/s, train_loss=0.00233, val_loss=0.00225]Epoch 18: 100%|██████████| 27/27 [00:00<00:00, 31.22it/s, train_loss=0.00233, val_loss=0.00225]Epoch 18: 100%|██████████| 27/27 [00:00<00:00, 30.85it/s, train_loss=0.00245, val_loss=0.00225]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 156.28it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 167.96it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 174.93it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 181.33it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 186.44it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 189.32it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 190.99it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 187.19it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 185.88it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 186.41it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 187.61it/s][A
                                                                         [AEpoch 18: 100%|██████████| 27/27 [00:00<00:00, 28.18it/s, train_loss=0.00245, val_loss=0.00222]Epoch 18: 100%|██████████| 27/27 [00:00<00:00, 28.16it/s, train_loss=0.00245, val_loss=0.00222]Epoch 18:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00245, val_loss=0.00222]         Epoch 19:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00245, val_loss=0.00222]Epoch 19:   4%|▎         | 1/27 [00:00<00:00, 83.59it/s, train_loss=0.00245, val_loss=0.00222]Epoch 19:   4%|▎         | 1/27 [00:00<00:00, 41.99it/s, train_loss=0.00218, val_loss=0.00222]Epoch 19:   7%|▋         | 2/27 [00:00<00:00, 56.82it/s, train_loss=0.00218, val_loss=0.00222]Epoch 19:   7%|▋         | 2/27 [00:00<00:00, 42.04it/s, train_loss=0.00209, val_loss=0.00222]Epoch 19:  11%|█         | 3/27 [00:00<00:00, 52.82it/s, train_loss=0.00209, val_loss=0.00222]Epoch 19:  11%|█         | 3/27 [00:00<00:00, 41.52it/s, train_loss=0.00221, val_loss=0.00222]Epoch 19:  15%|█▍        | 4/27 [00:00<00:00, 48.53it/s, train_loss=0.00221, val_loss=0.00222]Epoch 19:  15%|█▍        | 4/27 [00:00<00:00, 41.11it/s, train_loss=0.00227, val_loss=0.00222]Epoch 19:  19%|█▊        | 5/27 [00:00<00:00, 45.62it/s, train_loss=0.00227, val_loss=0.00222]Epoch 19:  19%|█▊        | 5/27 [00:00<00:00, 41.32it/s, train_loss=0.00204, val_loss=0.00222]Epoch 19:  22%|██▏       | 6/27 [00:00<00:00, 45.55it/s, train_loss=0.00204, val_loss=0.00222]Epoch 19:  22%|██▏       | 6/27 [00:00<00:00, 40.99it/s, train_loss=0.00233, val_loss=0.00222]Epoch 19:  26%|██▌       | 7/27 [00:00<00:00, 44.91it/s, train_loss=0.00233, val_loss=0.00222]Epoch 19:  26%|██▌       | 7/27 [00:00<00:00, 40.79it/s, train_loss=0.00221, val_loss=0.00222]Epoch 19:  30%|██▉       | 8/27 [00:00<00:00, 44.11it/s, train_loss=0.00221, val_loss=0.00222]Epoch 19:  30%|██▉       | 8/27 [00:00<00:00, 40.68it/s, train_loss=0.00221, val_loss=0.00222]Epoch 19:  33%|███▎      | 9/27 [00:00<00:00, 43.34it/s, train_loss=0.00221, val_loss=0.00222]Epoch 19:  33%|███▎      | 9/27 [00:00<00:00, 40.95it/s, train_loss=0.00225, val_loss=0.00222]Epoch 19:  37%|███▋      | 10/27 [00:00<00:00, 43.30it/s, train_loss=0.00225, val_loss=0.00222]Epoch 19:  37%|███▋      | 10/27 [00:00<00:00, 41.15it/s, train_loss=0.00229, val_loss=0.00222]Epoch 19:  41%|████      | 11/27 [00:00<00:00, 43.56it/s, train_loss=0.00229, val_loss=0.00222]Epoch 19:  41%|████      | 11/27 [00:00<00:00, 41.06it/s, train_loss=0.00199, val_loss=0.00222]Epoch 19:  44%|████▍     | 12/27 [00:00<00:00, 43.19it/s, train_loss=0.00199, val_loss=0.00222]Epoch 19:  44%|████▍     | 12/27 [00:00<00:00, 40.89it/s, train_loss=0.0023, val_loss=0.00222] Epoch 19:  48%|████▊     | 13/27 [00:00<00:00, 42.69it/s, train_loss=0.0023, val_loss=0.00222]Epoch 19:  48%|████▊     | 13/27 [00:00<00:00, 41.04it/s, train_loss=0.00249, val_loss=0.00222]Epoch 19:  52%|█████▏    | 14/27 [00:00<00:00, 42.79it/s, train_loss=0.00249, val_loss=0.00222]Epoch 19:  52%|█████▏    | 14/27 [00:00<00:00, 41.22it/s, train_loss=0.00232, val_loss=0.00222]Epoch 19:  56%|█████▌    | 15/27 [00:00<00:00, 43.00it/s, train_loss=0.00232, val_loss=0.00222]Epoch 19:  56%|█████▌    | 15/27 [00:00<00:00, 41.17it/s, train_loss=0.00205, val_loss=0.00222]Epoch 19:  59%|█████▉    | 16/27 [00:00<00:00, 42.62it/s, train_loss=0.00205, val_loss=0.00222]Epoch 19:  59%|█████▉    | 16/27 [00:00<00:00, 41.31it/s, train_loss=0.00217, val_loss=0.00222]Epoch 19:  63%|██████▎   | 17/27 [00:00<00:00, 42.65it/s, train_loss=0.00217, val_loss=0.00222]Epoch 19:  63%|██████▎   | 17/27 [00:00<00:00, 41.37it/s, train_loss=0.00237, val_loss=0.00222]Epoch 19:  67%|██████▋   | 18/27 [00:00<00:00, 42.85it/s, train_loss=0.00237, val_loss=0.00222]Epoch 19:  67%|██████▋   | 18/27 [00:00<00:00, 41.28it/s, train_loss=0.00227, val_loss=0.00222]Epoch 19:  70%|███████   | 19/27 [00:00<00:00, 42.53it/s, train_loss=0.00227, val_loss=0.00222]Epoch 19:  70%|███████   | 19/27 [00:00<00:00, 41.10it/s, train_loss=0.00218, val_loss=0.00222]Epoch 19:  74%|███████▍  | 20/27 [00:00<00:00, 42.39it/s, train_loss=0.00218, val_loss=0.00222]Epoch 19:  74%|███████▍  | 20/27 [00:00<00:00, 41.06it/s, train_loss=0.00202, val_loss=0.00222]Epoch 19:  78%|███████▊  | 21/27 [00:00<00:00, 42.10it/s, train_loss=0.00202, val_loss=0.00222]Epoch 19:  78%|███████▊  | 21/27 [00:00<00:00, 41.15it/s, train_loss=0.00215, val_loss=0.00222]Epoch 19:  81%|████████▏ | 22/27 [00:00<00:00, 42.36it/s, train_loss=0.00215, val_loss=0.00222]Epoch 19:  81%|████████▏ | 22/27 [00:00<00:00, 41.09it/s, train_loss=0.0021, val_loss=0.00222] Epoch 19:  85%|████████▌ | 23/27 [00:00<00:00, 42.22it/s, train_loss=0.0021, val_loss=0.00222]Epoch 19:  85%|████████▌ | 23/27 [00:00<00:00, 41.08it/s, train_loss=0.00219, val_loss=0.00222]Epoch 19:  89%|████████▉ | 24/27 [00:00<00:00, 41.97it/s, train_loss=0.00219, val_loss=0.00222]Epoch 19:  89%|████████▉ | 24/27 [00:00<00:00, 41.14it/s, train_loss=0.0022, val_loss=0.00222] Epoch 19:  93%|█████████▎| 25/27 [00:00<00:00, 42.15it/s, train_loss=0.0022, val_loss=0.00222]Epoch 19:  93%|█████████▎| 25/27 [00:00<00:00, 41.10it/s, train_loss=0.0022, val_loss=0.00222]Epoch 19:  96%|█████████▋| 26/27 [00:00<00:00, 42.10it/s, train_loss=0.0022, val_loss=0.00222]Epoch 19:  96%|█████████▋| 26/27 [00:00<00:00, 41.07it/s, train_loss=0.00205, val_loss=0.00222]Epoch 19: 100%|██████████| 27/27 [00:00<00:00, 41.92it/s, train_loss=0.00205, val_loss=0.00222]Epoch 19: 100%|██████████| 27/27 [00:00<00:00, 41.26it/s, train_loss=0.0018, val_loss=0.00222] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 112.63it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 130.81it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 142.27it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 148.74it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 151.57it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 154.11it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 158.91it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 164.22it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 168.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 172.46it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 176.29it/s][A
                                                                         [AEpoch 19: 100%|██████████| 27/27 [00:00<00:00, 36.45it/s, train_loss=0.0018, val_loss=0.00216]Epoch 19: 100%|██████████| 27/27 [00:00<00:00, 36.41it/s, train_loss=0.0018, val_loss=0.00216]Epoch 19:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0018, val_loss=0.00216]         Epoch 20:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.0018, val_loss=0.00216]Epoch 20:   4%|▎         | 1/27 [00:00<00:00, 81.69it/s, train_loss=0.0018, val_loss=0.00216]Epoch 20:   4%|▎         | 1/27 [00:00<00:00, 42.28it/s, train_loss=0.00211, val_loss=0.00216]Epoch 20:   7%|▋         | 2/27 [00:00<00:00, 57.54it/s, train_loss=0.00211, val_loss=0.00216]Epoch 20:   7%|▋         | 2/27 [00:00<00:00, 41.38it/s, train_loss=0.00219, val_loss=0.00216]Epoch 20:  11%|█         | 3/27 [00:00<00:00, 51.94it/s, train_loss=0.00219, val_loss=0.00216]Epoch 20:  11%|█         | 3/27 [00:00<00:00, 41.14it/s, train_loss=0.00217, val_loss=0.00216]Epoch 20:  15%|█▍        | 4/27 [00:00<00:00, 48.23it/s, train_loss=0.00217, val_loss=0.00216]Epoch 20:  15%|█▍        | 4/27 [00:00<00:00, 40.60it/s, train_loss=0.0023, val_loss=0.00216] Epoch 20:  19%|█▊        | 5/27 [00:00<00:00, 45.64it/s, train_loss=0.0023, val_loss=0.00216]Epoch 20:  19%|█▊        | 5/27 [00:00<00:00, 41.16it/s, train_loss=0.00202, val_loss=0.00216]Epoch 20:  22%|██▏       | 6/27 [00:00<00:00, 45.12it/s, train_loss=0.00202, val_loss=0.00216]Epoch 20:  22%|██▏       | 6/27 [00:00<00:00, 41.34it/s, train_loss=0.00195, val_loss=0.00216]Epoch 20:  26%|██▌       | 7/27 [00:00<00:00, 45.31it/s, train_loss=0.00195, val_loss=0.00216]Epoch 20:  26%|██▌       | 7/27 [00:00<00:00, 41.11it/s, train_loss=0.00212, val_loss=0.00216]Epoch 20:  30%|██▉       | 8/27 [00:00<00:00, 44.48it/s, train_loss=0.00212, val_loss=0.00216]Epoch 20:  30%|██▉       | 8/27 [00:00<00:00, 40.98it/s, train_loss=0.00195, val_loss=0.00216]Epoch 20:  33%|███▎      | 9/27 [00:00<00:00, 43.46it/s, train_loss=0.00195, val_loss=0.00216]Epoch 20:  33%|███▎      | 9/27 [00:00<00:00, 41.15it/s, train_loss=0.00206, val_loss=0.00216]Epoch 20:  37%|███▋      | 10/27 [00:00<00:00, 43.60it/s, train_loss=0.00206, val_loss=0.00216]Epoch 20:  37%|███▋      | 10/27 [00:00<00:00, 40.96it/s, train_loss=0.00226, val_loss=0.00216]Epoch 20:  41%|████      | 11/27 [00:00<00:00, 43.36it/s, train_loss=0.00226, val_loss=0.00216]Epoch 20:  41%|████      | 11/27 [00:00<00:00, 40.82it/s, train_loss=0.0022, val_loss=0.00216] Epoch 20:  44%|████▍     | 12/27 [00:00<00:00, 42.95it/s, train_loss=0.0022, val_loss=0.00216]Epoch 20:  44%|████▍     | 12/27 [00:00<00:00, 40.71it/s, train_loss=0.00208, val_loss=0.00216]Epoch 20:  48%|████▊     | 13/27 [00:00<00:00, 42.44it/s, train_loss=0.00208, val_loss=0.00216]Epoch 20:  48%|████▊     | 13/27 [00:00<00:00, 40.84it/s, train_loss=0.00228, val_loss=0.00216]Epoch 20:  52%|█████▏    | 14/27 [00:00<00:00, 42.47it/s, train_loss=0.00228, val_loss=0.00216]Epoch 20:  52%|█████▏    | 14/27 [00:00<00:00, 41.03it/s, train_loss=0.00211, val_loss=0.00216]Epoch 20:  56%|█████▌    | 15/27 [00:00<00:00, 42.80it/s, train_loss=0.00211, val_loss=0.00216]Epoch 20:  56%|█████▌    | 15/27 [00:00<00:00, 40.97it/s, train_loss=0.00195, val_loss=0.00216]Epoch 20:  59%|█████▉    | 16/27 [00:00<00:00, 42.50it/s, train_loss=0.00195, val_loss=0.00216]Epoch 20:  59%|█████▉    | 16/27 [00:00<00:00, 40.86it/s, train_loss=0.00228, val_loss=0.00216]Epoch 20:  63%|██████▎   | 17/27 [00:00<00:00, 42.24it/s, train_loss=0.00228, val_loss=0.00216]Epoch 20:  63%|██████▎   | 17/27 [00:00<00:00, 41.01it/s, train_loss=0.00209, val_loss=0.00216]Epoch 20:  67%|██████▋   | 18/27 [00:00<00:00, 42.27it/s, train_loss=0.00209, val_loss=0.00216]Epoch 20:  67%|██████▋   | 18/27 [00:00<00:00, 41.13it/s, train_loss=0.0021, val_loss=0.00216] Epoch 20:  70%|███████   | 19/27 [00:00<00:00, 42.54it/s, train_loss=0.0021, val_loss=0.00216]Epoch 20:  70%|███████   | 19/27 [00:00<00:00, 41.06it/s, train_loss=0.00208, val_loss=0.00216]Epoch 20:  74%|███████▍  | 20/27 [00:00<00:00, 42.18it/s, train_loss=0.00208, val_loss=0.00216]Epoch 20:  74%|███████▍  | 20/27 [00:00<00:00, 41.18it/s, train_loss=0.00221, val_loss=0.00216]Epoch 20:  78%|███████▊  | 21/27 [00:00<00:00, 42.24it/s, train_loss=0.00221, val_loss=0.00216]Epoch 20:  78%|███████▊  | 21/27 [00:00<00:00, 41.19it/s, train_loss=0.00225, val_loss=0.00216]Epoch 20:  81%|████████▏ | 22/27 [00:00<00:00, 42.39it/s, train_loss=0.00225, val_loss=0.00216]Epoch 20:  81%|████████▏ | 22/27 [00:00<00:00, 41.15it/s, train_loss=0.00226, val_loss=0.00216]Epoch 20:  85%|████████▌ | 23/27 [00:00<00:00, 42.26it/s, train_loss=0.00226, val_loss=0.00216]Epoch 20:  85%|████████▌ | 23/27 [00:00<00:00, 41.25it/s, train_loss=0.00207, val_loss=0.00216]Epoch 20:  89%|████████▉ | 24/27 [00:00<00:00, 42.02it/s, train_loss=0.00207, val_loss=0.00216]Epoch 20:  89%|████████▉ | 24/27 [00:00<00:00, 41.20it/s, train_loss=0.00193, val_loss=0.00216]Epoch 20:  93%|█████████▎| 25/27 [00:00<00:00, 42.24it/s, train_loss=0.00193, val_loss=0.00216]Epoch 20:  93%|█████████▎| 25/27 [00:00<00:00, 41.17it/s, train_loss=0.00223, val_loss=0.00216]Epoch 20:  96%|█████████▋| 26/27 [00:00<00:00, 42.16it/s, train_loss=0.00223, val_loss=0.00216]Epoch 20:  96%|█████████▋| 26/27 [00:00<00:00, 41.14it/s, train_loss=0.00211, val_loss=0.00216]Epoch 20: 100%|██████████| 27/27 [00:00<00:00, 41.94it/s, train_loss=0.00211, val_loss=0.00216]Epoch 20: 100%|██████████| 27/27 [00:00<00:00, 41.32it/s, train_loss=0.00203, val_loss=0.00216]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 114.96it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 137.32it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 143.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 143.55it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 145.37it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 149.90it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 153.26it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 156.26it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 157.98it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 159.37it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 160.83it/s][A
                                                                         [AEpoch 20: 100%|██████████| 27/27 [00:00<00:00, 36.52it/s, train_loss=0.00203, val_loss=0.00208]Epoch 20: 100%|██████████| 27/27 [00:00<00:00, 36.46it/s, train_loss=0.00203, val_loss=0.00208]Epoch 20:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00203, val_loss=0.00208]         Epoch 21:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00203, val_loss=0.00208]Epoch 21:   4%|▎         | 1/27 [00:00<00:00, 91.94it/s, train_loss=0.00203, val_loss=0.00208]Epoch 21:   4%|▎         | 1/27 [00:00<00:00, 39.36it/s, train_loss=0.00191, val_loss=0.00208]Epoch 21:   7%|▋         | 2/27 [00:00<00:00, 56.36it/s, train_loss=0.00191, val_loss=0.00208]Epoch 21:   7%|▋         | 2/27 [00:00<00:00, 41.53it/s, train_loss=0.00201, val_loss=0.00208]Epoch 21:  11%|█         | 3/27 [00:00<00:00, 51.09it/s, train_loss=0.00201, val_loss=0.00208]Epoch 21:  11%|█         | 3/27 [00:00<00:00, 42.03it/s, train_loss=0.00227, val_loss=0.00208]Epoch 21:  15%|█▍        | 4/27 [00:00<00:00, 49.67it/s, train_loss=0.00227, val_loss=0.00208]Epoch 21:  15%|█▍        | 4/27 [00:00<00:00, 41.69it/s, train_loss=0.00205, val_loss=0.00208]Epoch 21:  19%|█▊        | 5/27 [00:00<00:00, 46.74it/s, train_loss=0.00205, val_loss=0.00208]Epoch 21:  19%|█▊        | 5/27 [00:00<00:00, 42.04it/s, train_loss=0.00234, val_loss=0.00208]Epoch 21:  22%|██▏       | 6/27 [00:00<00:00, 46.04it/s, train_loss=0.00234, val_loss=0.00208]Epoch 21:  22%|██▏       | 6/27 [00:00<00:00, 42.05it/s, train_loss=0.00221, val_loss=0.00208]Epoch 21:  26%|██▌       | 7/27 [00:00<00:00, 45.99it/s, train_loss=0.00221, val_loss=0.00208]Epoch 21:  26%|██▌       | 7/27 [00:00<00:00, 41.78it/s, train_loss=0.00217, val_loss=0.00208]Epoch 21:  30%|██▉       | 8/27 [00:00<00:00, 44.98it/s, train_loss=0.00217, val_loss=0.00208]Epoch 21:  30%|██▉       | 8/27 [00:00<00:00, 41.55it/s, train_loss=0.0019, val_loss=0.00208] Epoch 21:  33%|███▎      | 9/27 [00:00<00:00, 44.01it/s, train_loss=0.0019, val_loss=0.00208]Epoch 21:  33%|███▎      | 9/27 [00:00<00:00, 41.69it/s, train_loss=0.00213, val_loss=0.00208]Epoch 21:  37%|███▋      | 10/27 [00:00<00:00, 44.32it/s, train_loss=0.00213, val_loss=0.00208]Epoch 21:  37%|███▋      | 10/27 [00:00<00:00, 41.46it/s, train_loss=0.00227, val_loss=0.00208]Epoch 21:  41%|████      | 11/27 [00:00<00:00, 43.86it/s, train_loss=0.00227, val_loss=0.00208]Epoch 21:  41%|████      | 11/27 [00:00<00:00, 41.32it/s, train_loss=0.00219, val_loss=0.00208]Epoch 21:  44%|████▍     | 12/27 [00:00<00:00, 43.48it/s, train_loss=0.00219, val_loss=0.00208]Epoch 21:  44%|████▍     | 12/27 [00:00<00:00, 41.24it/s, train_loss=0.00211, val_loss=0.00208]Epoch 21:  48%|████▊     | 13/27 [00:00<00:00, 42.95it/s, train_loss=0.00211, val_loss=0.00208]Epoch 21:  48%|████▊     | 13/27 [00:00<00:00, 41.38it/s, train_loss=0.00206, val_loss=0.00208]Epoch 21:  52%|█████▏    | 14/27 [00:00<00:00, 43.24it/s, train_loss=0.00206, val_loss=0.00208]Epoch 21:  52%|█████▏    | 14/27 [00:00<00:00, 41.28it/s, train_loss=0.0023, val_loss=0.00208] Epoch 21:  56%|█████▌    | 15/27 [00:00<00:00, 43.02it/s, train_loss=0.0023, val_loss=0.00208]Epoch 21:  56%|█████▌    | 15/27 [00:00<00:00, 41.20it/s, train_loss=0.00221, val_loss=0.00208]Epoch 21:  59%|█████▉    | 16/27 [00:00<00:00, 42.72it/s, train_loss=0.00221, val_loss=0.00208]Epoch 21:  59%|█████▉    | 16/27 [00:00<00:00, 41.32it/s, train_loss=0.00229, val_loss=0.00208]Epoch 21:  63%|██████▎   | 17/27 [00:00<00:00, 42.60it/s, train_loss=0.00229, val_loss=0.00208]Epoch 21:  63%|██████▎   | 17/27 [00:00<00:00, 41.45it/s, train_loss=0.00183, val_loss=0.00208]Epoch 21:  67%|██████▋   | 18/27 [00:00<00:00, 42.84it/s, train_loss=0.00183, val_loss=0.00208]Epoch 21:  67%|██████▋   | 18/27 [00:00<00:00, 41.34it/s, train_loss=0.00208, val_loss=0.00208]Epoch 21:  70%|███████   | 19/27 [00:00<00:00, 42.66it/s, train_loss=0.00208, val_loss=0.00208]Epoch 21:  70%|███████   | 19/27 [00:00<00:00, 41.22it/s, train_loss=0.0021, val_loss=0.00208] Epoch 21:  74%|███████▍  | 20/27 [00:00<00:00, 42.37it/s, train_loss=0.0021, val_loss=0.00208]Epoch 21:  74%|███████▍  | 20/27 [00:00<00:00, 41.31it/s, train_loss=0.00193, val_loss=0.00208]Epoch 21:  78%|███████▊  | 21/27 [00:00<00:00, 42.42it/s, train_loss=0.00193, val_loss=0.00208]Epoch 21:  78%|███████▊  | 21/27 [00:00<00:00, 41.39it/s, train_loss=0.00193, val_loss=0.00208]Epoch 21:  81%|████████▏ | 22/27 [00:00<00:00, 42.60it/s, train_loss=0.00193, val_loss=0.00208]Epoch 21:  81%|████████▏ | 22/27 [00:00<00:00, 41.35it/s, train_loss=0.00214, val_loss=0.00208]Epoch 21:  85%|████████▌ | 23/27 [00:00<00:00, 42.36it/s, train_loss=0.00214, val_loss=0.00208]Epoch 21:  85%|████████▌ | 23/27 [00:00<00:00, 41.42it/s, train_loss=0.00218, val_loss=0.00208]Epoch 21:  89%|████████▉ | 24/27 [00:00<00:00, 42.36it/s, train_loss=0.00218, val_loss=0.00208]Epoch 21:  89%|████████▉ | 24/27 [00:00<00:00, 41.49it/s, train_loss=0.00204, val_loss=0.00208]Epoch 21:  93%|█████████▎| 25/27 [00:00<00:00, 42.54it/s, train_loss=0.00204, val_loss=0.00208]Epoch 21:  93%|█████████▎| 25/27 [00:00<00:00, 41.45it/s, train_loss=0.00223, val_loss=0.00208]Epoch 21:  96%|█████████▋| 26/27 [00:00<00:00, 42.38it/s, train_loss=0.00223, val_loss=0.00208]Epoch 21:  96%|█████████▋| 26/27 [00:00<00:00, 41.53it/s, train_loss=0.00231, val_loss=0.00208]Epoch 21: 100%|██████████| 27/27 [00:00<00:00, 42.34it/s, train_loss=0.00231, val_loss=0.00208]Epoch 21: 100%|██████████| 27/27 [00:00<00:00, 41.70it/s, train_loss=0.00222, val_loss=0.00208]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 124.28it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 142.84it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 154.71it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 161.50it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 165.89it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 168.98it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 170.53it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 168.06it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 169.01it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 170.10it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 171.34it/s][A
                                                                         [AEpoch 21: 100%|██████████| 27/27 [00:00<00:00, 36.86it/s, train_loss=0.00222, val_loss=0.00206]Epoch 21: 100%|██████████| 27/27 [00:00<00:00, 36.80it/s, train_loss=0.00222, val_loss=0.00206]Epoch 21:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00222, val_loss=0.00206]         Epoch 22:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00222, val_loss=0.00206]Epoch 22:   4%|▎         | 1/27 [00:00<00:00, 86.78it/s, train_loss=0.00222, val_loss=0.00206]Epoch 22:   4%|▎         | 1/27 [00:00<00:00, 42.27it/s, train_loss=0.00213, val_loss=0.00206]Epoch 22:   7%|▋         | 2/27 [00:00<00:00, 57.95it/s, train_loss=0.00213, val_loss=0.00206]Epoch 22:   7%|▋         | 2/27 [00:00<00:00, 42.22it/s, train_loss=0.00213, val_loss=0.00206]Epoch 22:  11%|█         | 3/27 [00:00<00:00, 52.79it/s, train_loss=0.00213, val_loss=0.00206]Epoch 22:  11%|█         | 3/27 [00:00<00:00, 41.37it/s, train_loss=0.00218, val_loss=0.00206]Epoch 22:  15%|█▍        | 4/27 [00:00<00:00, 48.60it/s, train_loss=0.00218, val_loss=0.00206]Epoch 22:  15%|█▍        | 4/27 [00:00<00:00, 41.08it/s, train_loss=0.00199, val_loss=0.00206]Epoch 22:  19%|█▊        | 5/27 [00:00<00:00, 46.24it/s, train_loss=0.00199, val_loss=0.00206]Epoch 22:  19%|█▊        | 5/27 [00:00<00:00, 41.60it/s, train_loss=0.00205, val_loss=0.00206]Epoch 22:  22%|██▏       | 6/27 [00:00<00:00, 46.40it/s, train_loss=0.00205, val_loss=0.00206]Epoch 22:  22%|██▏       | 6/27 [00:00<00:00, 41.43it/s, train_loss=0.0022, val_loss=0.00206] Epoch 22:  26%|██▌       | 7/27 [00:00<00:00, 45.29it/s, train_loss=0.0022, val_loss=0.00206]Epoch 22:  26%|██▌       | 7/27 [00:00<00:00, 41.84it/s, train_loss=0.00221, val_loss=0.00206]Epoch 22:  30%|██▉       | 8/27 [00:00<00:00, 44.87it/s, train_loss=0.00221, val_loss=0.00206]Epoch 22:  30%|██▉       | 8/27 [00:00<00:00, 41.77it/s, train_loss=0.00205, val_loss=0.00206]Epoch 22:  33%|███▎      | 9/27 [00:00<00:00, 44.83it/s, train_loss=0.00205, val_loss=0.00206]Epoch 22:  33%|███▎      | 9/27 [00:00<00:00, 41.62it/s, train_loss=0.0019, val_loss=0.00206] Epoch 22:  37%|███▋      | 10/27 [00:00<00:00, 44.33it/s, train_loss=0.0019, val_loss=0.00206]Epoch 22:  37%|███▋      | 10/27 [00:00<00:00, 41.82it/s, train_loss=0.00224, val_loss=0.00206]Epoch 22:  41%|████      | 11/27 [00:00<00:00, 44.01it/s, train_loss=0.00224, val_loss=0.00206]Epoch 22:  41%|████      | 11/27 [00:00<00:00, 41.95it/s, train_loss=0.00192, val_loss=0.00206]Epoch 22:  44%|████▍     | 12/27 [00:00<00:00, 44.15it/s, train_loss=0.00192, val_loss=0.00206]Epoch 22:  44%|████▍     | 12/27 [00:00<00:00, 41.75it/s, train_loss=0.00203, val_loss=0.00206]Epoch 22:  48%|████▊     | 13/27 [00:00<00:00, 43.66it/s, train_loss=0.00203, val_loss=0.00206]Epoch 22:  48%|████▊     | 13/27 [00:00<00:00, 41.92it/s, train_loss=0.00198, val_loss=0.00206]Epoch 22:  52%|█████▏    | 14/27 [00:00<00:00, 43.62it/s, train_loss=0.00198, val_loss=0.00206]Epoch 22:  52%|█████▏    | 14/27 [00:00<00:00, 41.92it/s, train_loss=0.00212, val_loss=0.00206]Epoch 22:  56%|█████▌    | 15/27 [00:00<00:00, 43.72it/s, train_loss=0.00212, val_loss=0.00206]Epoch 22:  56%|█████▌    | 15/27 [00:00<00:00, 41.82it/s, train_loss=0.00205, val_loss=0.00206]Epoch 22:  59%|█████▉    | 16/27 [00:00<00:00, 43.45it/s, train_loss=0.00205, val_loss=0.00206]Epoch 22:  59%|█████▉    | 16/27 [00:00<00:00, 41.95it/s, train_loss=0.00209, val_loss=0.00206]Epoch 22:  63%|██████▎   | 17/27 [00:00<00:00, 43.33it/s, train_loss=0.00209, val_loss=0.00206]Epoch 22:  63%|██████▎   | 17/27 [00:00<00:00, 42.06it/s, train_loss=0.00187, val_loss=0.00206]Epoch 22:  67%|██████▋   | 18/27 [00:00<00:00, 43.54it/s, train_loss=0.00187, val_loss=0.00206]Epoch 22:  67%|██████▋   | 18/27 [00:00<00:00, 41.95it/s, train_loss=0.00212, val_loss=0.00206]Epoch 22:  70%|███████   | 19/27 [00:00<00:00, 43.32it/s, train_loss=0.00212, val_loss=0.00206]Epoch 22:  70%|███████   | 19/27 [00:00<00:00, 42.07it/s, train_loss=0.00196, val_loss=0.00206]Epoch 22:  74%|███████▍  | 20/27 [00:00<00:00, 43.23it/s, train_loss=0.00196, val_loss=0.00206]Epoch 22:  74%|███████▍  | 20/27 [00:00<00:00, 42.13it/s, train_loss=0.002, val_loss=0.00206]  Epoch 22:  78%|███████▊  | 21/27 [00:00<00:00, 43.32it/s, train_loss=0.002, val_loss=0.00206]Epoch 22:  78%|███████▊  | 21/27 [00:00<00:00, 42.00it/s, train_loss=0.00196, val_loss=0.00206]Epoch 22:  81%|████████▏ | 22/27 [00:00<00:00, 43.17it/s, train_loss=0.00196, val_loss=0.00206]Epoch 22:  81%|████████▏ | 22/27 [00:00<00:00, 41.91it/s, train_loss=0.00196, val_loss=0.00206]Epoch 22:  85%|████████▌ | 23/27 [00:00<00:00, 42.94it/s, train_loss=0.00196, val_loss=0.00206]Epoch 22:  85%|████████▌ | 23/27 [00:00<00:00, 41.98it/s, train_loss=0.00194, val_loss=0.00206]Epoch 22:  89%|████████▉ | 24/27 [00:00<00:00, 43.12it/s, train_loss=0.00194, val_loss=0.00206]Epoch 22:  89%|████████▉ | 24/27 [00:00<00:00, 41.94it/s, train_loss=0.00221, val_loss=0.00206]Epoch 22:  93%|█████████▎| 25/27 [00:00<00:00, 43.01it/s, train_loss=0.00221, val_loss=0.00206]Epoch 22:  93%|█████████▎| 25/27 [00:00<00:00, 42.04it/s, train_loss=0.0024, val_loss=0.00206] Epoch 22:  96%|█████████▋| 26/27 [00:00<00:00, 42.96it/s, train_loss=0.0024, val_loss=0.00206]Epoch 22:  96%|█████████▋| 26/27 [00:00<00:00, 42.04it/s, train_loss=0.00222, val_loss=0.00206]Epoch 22: 100%|██████████| 27/27 [00:00<00:00, 43.01it/s, train_loss=0.00222, val_loss=0.00206]Epoch 22: 100%|██████████| 27/27 [00:00<00:00, 42.09it/s, train_loss=0.00189, val_loss=0.00206]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 142.38it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 165.77it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 177.07it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 182.14it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 185.57it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 186.04it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 185.19it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 185.29it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 184.79it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 185.60it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 186.88it/s][A
                                                                         [AEpoch 22: 100%|██████████| 27/27 [00:00<00:00, 36.58it/s, train_loss=0.00189, val_loss=0.00199]Epoch 22: 100%|██████████| 27/27 [00:00<00:00, 36.53it/s, train_loss=0.00189, val_loss=0.00199]Epoch 22:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00189, val_loss=0.00199]         Epoch 23:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00189, val_loss=0.00199]Epoch 23:   4%|▎         | 1/27 [00:00<00:00, 86.18it/s, train_loss=0.00189, val_loss=0.00199]Epoch 23:   4%|▎         | 1/27 [00:00<00:00, 41.89it/s, train_loss=0.00225, val_loss=0.00199]Epoch 23:   7%|▋         | 2/27 [00:00<00:00, 60.05it/s, train_loss=0.00225, val_loss=0.00199]Epoch 23:   7%|▋         | 2/27 [00:00<00:00, 41.01it/s, train_loss=0.00204, val_loss=0.00199]Epoch 23:  11%|█         | 3/27 [00:00<00:00, 51.35it/s, train_loss=0.00204, val_loss=0.00199]Epoch 23:  11%|█         | 3/27 [00:00<00:00, 40.87it/s, train_loss=0.00211, val_loss=0.00199]Epoch 23:  15%|█▍        | 4/27 [00:00<00:00, 47.44it/s, train_loss=0.00211, val_loss=0.00199]Epoch 23:  15%|█▍        | 4/27 [00:00<00:00, 41.47it/s, train_loss=0.00201, val_loss=0.00199]Epoch 23:  19%|█▊        | 5/27 [00:00<00:00, 47.20it/s, train_loss=0.00201, val_loss=0.00199]Epoch 23:  19%|█▊        | 5/27 [00:00<00:00, 41.23it/s, train_loss=0.00213, val_loss=0.00199]Epoch 23:  22%|██▏       | 6/27 [00:00<00:00, 45.86it/s, train_loss=0.00213, val_loss=0.00199]Epoch 23:  22%|██▏       | 6/27 [00:00<00:00, 41.04it/s, train_loss=0.00187, val_loss=0.00199]Epoch 23:  26%|██▌       | 7/27 [00:00<00:00, 44.71it/s, train_loss=0.00187, val_loss=0.00199]Epoch 23:  26%|██▌       | 7/27 [00:00<00:00, 41.44it/s, train_loss=0.00193, val_loss=0.00199]Epoch 23:  30%|██▉       | 8/27 [00:00<00:00, 44.51it/s, train_loss=0.00193, val_loss=0.00199]Epoch 23:  30%|██▉       | 8/27 [00:00<00:00, 41.50it/s, train_loss=0.00195, val_loss=0.00199]Epoch 23:  33%|███▎      | 9/27 [00:00<00:00, 44.62it/s, train_loss=0.00195, val_loss=0.00199]Epoch 23:  33%|███▎      | 9/27 [00:00<00:00, 41.41it/s, train_loss=0.00204, val_loss=0.00199]Epoch 23:  37%|███▋      | 10/27 [00:00<00:00, 43.97it/s, train_loss=0.00204, val_loss=0.00199]Epoch 23:  37%|███▋      | 10/27 [00:00<00:00, 41.72it/s, train_loss=0.00209, val_loss=0.00199]Epoch 23:  41%|████      | 11/27 [00:00<00:00, 44.04it/s, train_loss=0.00209, val_loss=0.00199]Epoch 23:  41%|████      | 11/27 [00:00<00:00, 41.66it/s, train_loss=0.00202, val_loss=0.00199]Epoch 23:  44%|████▍     | 12/27 [00:00<00:00, 43.94it/s, train_loss=0.00202, val_loss=0.00199]Epoch 23:  44%|████▍     | 12/27 [00:00<00:00, 41.57it/s, train_loss=0.00214, val_loss=0.00199]Epoch 23:  48%|████▊     | 13/27 [00:00<00:00, 43.50it/s, train_loss=0.00214, val_loss=0.00199]Epoch 23:  48%|████▊     | 13/27 [00:00<00:00, 41.73it/s, train_loss=0.00188, val_loss=0.00199]Epoch 23:  52%|█████▏    | 14/27 [00:00<00:00, 43.43it/s, train_loss=0.00188, val_loss=0.00199]Epoch 23:  52%|█████▏    | 14/27 [00:00<00:00, 41.72it/s, train_loss=0.00202, val_loss=0.00199]Epoch 23:  56%|█████▌    | 15/27 [00:00<00:00, 43.52it/s, train_loss=0.00202, val_loss=0.00199]Epoch 23:  56%|█████▌    | 15/27 [00:00<00:00, 41.58it/s, train_loss=0.00184, val_loss=0.00199]Epoch 23:  59%|█████▉    | 16/27 [00:00<00:00, 43.22it/s, train_loss=0.00184, val_loss=0.00199]Epoch 23:  59%|█████▉    | 16/27 [00:00<00:00, 41.50it/s, train_loss=0.00201, val_loss=0.00199]Epoch 23:  63%|██████▎   | 17/27 [00:00<00:00, 42.90it/s, train_loss=0.00201, val_loss=0.00199]Epoch 23:  63%|██████▎   | 17/27 [00:00<00:00, 41.62it/s, train_loss=0.002, val_loss=0.00199]  Epoch 23:  67%|██████▋   | 18/27 [00:00<00:00, 43.09it/s, train_loss=0.002, val_loss=0.00199]Epoch 23:  67%|██████▋   | 18/27 [00:00<00:00, 41.51it/s, train_loss=0.00222, val_loss=0.00199]Epoch 23:  70%|███████   | 19/27 [00:00<00:00, 42.89it/s, train_loss=0.00222, val_loss=0.00199]Epoch 23:  70%|███████   | 19/27 [00:00<00:00, 41.39it/s, train_loss=0.00222, val_loss=0.00199]Epoch 23:  74%|███████▍  | 20/27 [00:00<00:00, 42.56it/s, train_loss=0.00222, val_loss=0.00199]Epoch 23:  74%|███████▍  | 20/27 [00:00<00:00, 41.51it/s, train_loss=0.00219, val_loss=0.00199]Epoch 23:  78%|███████▊  | 21/27 [00:00<00:00, 42.67it/s, train_loss=0.00219, val_loss=0.00199]Epoch 23:  78%|███████▊  | 21/27 [00:00<00:00, 41.41it/s, train_loss=0.00234, val_loss=0.00199]Epoch 23:  81%|████████▏ | 22/27 [00:00<00:00, 42.32it/s, train_loss=0.00234, val_loss=0.00199]Epoch 23:  81%|████████▏ | 22/27 [00:00<00:00, 41.27it/s, train_loss=0.00213, val_loss=0.00199]Epoch 23:  85%|████████▌ | 23/27 [00:00<00:00, 42.42it/s, train_loss=0.00213, val_loss=0.00199]Epoch 23:  85%|████████▌ | 23/27 [00:00<00:00, 41.20it/s, train_loss=0.00192, val_loss=0.00199]Epoch 23:  89%|████████▉ | 24/27 [00:00<00:00, 42.27it/s, train_loss=0.00192, val_loss=0.00199]Epoch 23:  89%|████████▉ | 24/27 [00:00<00:00, 41.15it/s, train_loss=0.00213, val_loss=0.00199]Epoch 23:  93%|█████████▎| 25/27 [00:00<00:00, 42.08it/s, train_loss=0.00213, val_loss=0.00199]Epoch 23:  93%|█████████▎| 25/27 [00:00<00:00, 41.24it/s, train_loss=0.00195, val_loss=0.00199]Epoch 23:  96%|█████████▋| 26/27 [00:00<00:00, 42.22it/s, train_loss=0.00195, val_loss=0.00199]Epoch 23:  96%|█████████▋| 26/27 [00:00<00:00, 41.20it/s, train_loss=0.00194, val_loss=0.00199]Epoch 23: 100%|██████████| 27/27 [00:00<00:00, 42.15it/s, train_loss=0.00194, val_loss=0.00199]Epoch 23: 100%|██████████| 27/27 [00:00<00:00, 41.27it/s, train_loss=0.00212, val_loss=0.00199]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 144.27it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 162.68it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 175.83it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 182.56it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 186.05it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 189.70it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 191.87it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 192.95it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 193.54it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 193.50it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 194.03it/s][A
                                                                         [AEpoch 23: 100%|██████████| 27/27 [00:00<00:00, 36.63it/s, train_loss=0.00212, val_loss=0.00198]Epoch 23: 100%|██████████| 27/27 [00:00<00:00, 36.58it/s, train_loss=0.00212, val_loss=0.00198]Epoch 23:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00212, val_loss=0.00198]         Epoch 24:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00212, val_loss=0.00198]Epoch 24:   4%|▎         | 1/27 [00:00<00:00, 83.35it/s, train_loss=0.00212, val_loss=0.00198]Epoch 24:   4%|▎         | 1/27 [00:00<00:00, 42.62it/s, train_loss=0.00202, val_loss=0.00198]Epoch 24:   7%|▋         | 2/27 [00:00<00:00, 56.72it/s, train_loss=0.00202, val_loss=0.00198]Epoch 24:   7%|▋         | 2/27 [00:00<00:00, 42.14it/s, train_loss=0.00198, val_loss=0.00198]Epoch 24:  11%|█         | 3/27 [00:00<00:00, 52.32it/s, train_loss=0.00198, val_loss=0.00198]Epoch 24:  11%|█         | 3/27 [00:00<00:00, 41.38it/s, train_loss=0.00203, val_loss=0.00198]Epoch 24:  15%|█▍        | 4/27 [00:00<00:00, 48.72it/s, train_loss=0.00203, val_loss=0.00198]Epoch 24:  15%|█▍        | 4/27 [00:00<00:00, 41.12it/s, train_loss=0.00188, val_loss=0.00198]Epoch 24:  19%|█▊        | 5/27 [00:00<00:00, 45.81it/s, train_loss=0.00188, val_loss=0.00198]Epoch 24:  19%|█▊        | 5/27 [00:00<00:00, 41.41it/s, train_loss=0.00217, val_loss=0.00198]Epoch 24:  22%|██▏       | 6/27 [00:00<00:00, 45.64it/s, train_loss=0.00217, val_loss=0.00198]Epoch 24:  22%|██▏       | 6/27 [00:00<00:00, 41.11it/s, train_loss=0.00191, val_loss=0.00198]Epoch 24:  26%|██▌       | 7/27 [00:00<00:00, 45.05it/s, train_loss=0.00191, val_loss=0.00198]Epoch 24:  26%|██▌       | 7/27 [00:00<00:00, 40.99it/s, train_loss=0.00214, val_loss=0.00198]Epoch 24:  30%|██▉       | 8/27 [00:00<00:00, 44.31it/s, train_loss=0.00214, val_loss=0.00198]Epoch 24:  30%|██▉       | 8/27 [00:00<00:00, 40.76it/s, train_loss=0.00217, val_loss=0.00198]Epoch 24:  33%|███▎      | 9/27 [00:00<00:00, 43.34it/s, train_loss=0.00217, val_loss=0.00198]Epoch 24:  33%|███▎      | 9/27 [00:00<00:00, 40.96it/s, train_loss=0.00195, val_loss=0.00198]Epoch 24:  37%|███▋      | 10/27 [00:00<00:00, 42.85it/s, train_loss=0.00195, val_loss=0.00198]Epoch 24:  37%|███▋      | 10/27 [00:00<00:00, 41.15it/s, train_loss=0.00208, val_loss=0.00198]Epoch 24:  41%|████      | 11/27 [00:00<00:00, 42.99it/s, train_loss=0.00208, val_loss=0.00198]Epoch 24:  41%|████      | 11/27 [00:00<00:00, 40.98it/s, train_loss=0.00206, val_loss=0.00198]Epoch 24:  44%|████▍     | 12/27 [00:00<00:00, 42.67it/s, train_loss=0.00206, val_loss=0.00198]Epoch 24:  44%|████▍     | 12/27 [00:00<00:00, 40.82it/s, train_loss=0.00195, val_loss=0.00198]Epoch 24:  48%|████▊     | 13/27 [00:00<00:00, 41.67it/s, train_loss=0.00195, val_loss=0.00198]Epoch 24:  48%|████▊     | 13/27 [00:00<00:00, 41.01it/s, train_loss=0.00197, val_loss=0.00198]Epoch 24:  52%|█████▏    | 14/27 [00:00<00:00, 42.79it/s, train_loss=0.00197, val_loss=0.00198]Epoch 24:  52%|█████▏    | 14/27 [00:00<00:00, 41.10it/s, train_loss=0.00187, val_loss=0.00198]Epoch 24:  56%|█████▌    | 15/27 [00:00<00:00, 42.89it/s, train_loss=0.00187, val_loss=0.00198]Epoch 24:  56%|█████▌    | 15/27 [00:00<00:00, 41.08it/s, train_loss=0.0023, val_loss=0.00198] Epoch 24:  59%|█████▉    | 16/27 [00:00<00:00, 42.64it/s, train_loss=0.0023, val_loss=0.00198]Epoch 24:  59%|█████▉    | 16/27 [00:00<00:00, 41.26it/s, train_loss=0.00209, val_loss=0.00198]Epoch 24:  63%|██████▎   | 17/27 [00:00<00:00, 42.71it/s, train_loss=0.00209, val_loss=0.00198]Epoch 24:  63%|██████▎   | 17/27 [00:00<00:00, 41.34it/s, train_loss=0.00203, val_loss=0.00198]Epoch 24:  67%|██████▋   | 18/27 [00:00<00:00, 42.81it/s, train_loss=0.00203, val_loss=0.00198]Epoch 24:  67%|██████▋   | 18/27 [00:00<00:00, 41.28it/s, train_loss=0.00233, val_loss=0.00198]Epoch 24:  70%|███████   | 19/27 [00:00<00:00, 42.56it/s, train_loss=0.00233, val_loss=0.00198]Epoch 24:  70%|███████   | 19/27 [00:00<00:00, 41.39it/s, train_loss=0.00208, val_loss=0.00198]Epoch 24:  74%|███████▍  | 20/27 [00:00<00:00, 42.60it/s, train_loss=0.00208, val_loss=0.00198]Epoch 24:  74%|███████▍  | 20/27 [00:00<00:00, 41.47it/s, train_loss=0.00182, val_loss=0.00198]Epoch 24:  78%|███████▊  | 21/27 [00:00<00:00, 42.73it/s, train_loss=0.00182, val_loss=0.00198]Epoch 24:  78%|███████▊  | 21/27 [00:00<00:00, 41.43it/s, train_loss=0.00217, val_loss=0.00198]Epoch 24:  81%|████████▏ | 22/27 [00:00<00:00, 42.55it/s, train_loss=0.00217, val_loss=0.00198]Epoch 24:  81%|████████▏ | 22/27 [00:00<00:00, 41.54it/s, train_loss=0.00202, val_loss=0.00198]Epoch 24:  85%|████████▌ | 23/27 [00:00<00:00, 42.57it/s, train_loss=0.00202, val_loss=0.00198]Epoch 24:  85%|████████▌ | 23/27 [00:00<00:00, 41.55it/s, train_loss=0.00198, val_loss=0.00198]Epoch 24:  89%|████████▉ | 24/27 [00:00<00:00, 42.63it/s, train_loss=0.00198, val_loss=0.00198]Epoch 24:  89%|████████▉ | 24/27 [00:00<00:00, 41.46it/s, train_loss=0.00199, val_loss=0.00198]Epoch 24:  93%|█████████▎| 25/27 [00:00<00:00, 42.48it/s, train_loss=0.00199, val_loss=0.00198]Epoch 24:  93%|█████████▎| 25/27 [00:00<00:00, 41.36it/s, train_loss=0.00202, val_loss=0.00198]Epoch 24:  96%|█████████▋| 26/27 [00:00<00:00, 42.28it/s, train_loss=0.00202, val_loss=0.00198]Epoch 24:  96%|█████████▋| 26/27 [00:00<00:00, 41.42it/s, train_loss=0.00195, val_loss=0.00198]Epoch 24: 100%|██████████| 27/27 [00:00<00:00, 42.28it/s, train_loss=0.00195, val_loss=0.00198]Epoch 24: 100%|██████████| 27/27 [00:00<00:00, 41.59it/s, train_loss=0.00222, val_loss=0.00198]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 109.23it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 123.30it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 132.36it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 139.17it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 143.73it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 152.70it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 160.21it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 165.71it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 169.27it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 171.84it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 175.75it/s][A
                                                                         [AEpoch 24: 100%|██████████| 27/27 [00:00<00:00, 36.60it/s, train_loss=0.00222, val_loss=0.00202]Epoch 24: 100%|██████████| 27/27 [00:00<00:00, 36.56it/s, train_loss=0.00222, val_loss=0.00202]Epoch 24:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00222, val_loss=0.00202]         Epoch 25:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00222, val_loss=0.00202]Epoch 25:   4%|▎         | 1/27 [00:00<00:00, 88.93it/s, train_loss=0.00222, val_loss=0.00202]Epoch 25:   4%|▎         | 1/27 [00:00<00:00, 42.60it/s, train_loss=0.00176, val_loss=0.00202]Epoch 25:   7%|▋         | 2/27 [00:00<00:00, 61.02it/s, train_loss=0.00176, val_loss=0.00202]Epoch 25:   7%|▋         | 2/27 [00:00<00:00, 41.45it/s, train_loss=0.00213, val_loss=0.00202]Epoch 25:  11%|█         | 3/27 [00:00<00:00, 50.97it/s, train_loss=0.00213, val_loss=0.00202]Epoch 25:  11%|█         | 3/27 [00:00<00:00, 42.06it/s, train_loss=0.00205, val_loss=0.00202]Epoch 25:  15%|█▍        | 4/27 [00:00<00:00, 48.97it/s, train_loss=0.00205, val_loss=0.00202]Epoch 25:  15%|█▍        | 4/27 [00:00<00:00, 42.12it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  19%|█▊        | 5/27 [00:00<00:00, 48.07it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  19%|█▊        | 5/27 [00:00<00:00, 41.78it/s, train_loss=0.002, val_loss=0.00202]  Epoch 25:  22%|██▏       | 6/27 [00:00<00:00, 46.41it/s, train_loss=0.002, val_loss=0.00202]Epoch 25:  22%|██▏       | 6/27 [00:00<00:00, 41.53it/s, train_loss=0.00209, val_loss=0.00202]Epoch 25:  26%|██▌       | 7/27 [00:00<00:00, 45.06it/s, train_loss=0.00209, val_loss=0.00202]Epoch 25:  26%|██▌       | 7/27 [00:00<00:00, 41.72it/s, train_loss=0.002, val_loss=0.00202]  Epoch 25:  30%|██▉       | 8/27 [00:00<00:00, 45.17it/s, train_loss=0.002, val_loss=0.00202]Epoch 25:  30%|██▉       | 8/27 [00:00<00:00, 41.45it/s, train_loss=0.0022, val_loss=0.00202]Epoch 25:  33%|███▎      | 9/27 [00:00<00:00, 44.47it/s, train_loss=0.0022, val_loss=0.00202]Epoch 25:  33%|███▎      | 9/27 [00:00<00:00, 41.32it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  37%|███▋      | 10/27 [00:00<00:00, 43.72it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  37%|███▋      | 10/27 [00:00<00:00, 41.43it/s, train_loss=0.00194, val_loss=0.00202]Epoch 25:  41%|████      | 11/27 [00:00<00:00, 43.75it/s, train_loss=0.00194, val_loss=0.00202]Epoch 25:  41%|████      | 11/27 [00:00<00:00, 41.24it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  44%|████▍     | 12/27 [00:00<00:00, 43.45it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  44%|████▍     | 12/27 [00:00<00:00, 41.12it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  48%|████▊     | 13/27 [00:00<00:00, 42.82it/s, train_loss=0.00201, val_loss=0.00202]Epoch 25:  48%|████▊     | 13/27 [00:00<00:00, 40.87it/s, train_loss=0.0018, val_loss=0.00202] Epoch 25:  52%|█████▏    | 14/27 [00:00<00:00, 42.57it/s, train_loss=0.0018, val_loss=0.00202]Epoch 25:  52%|█████▏    | 14/27 [00:00<00:00, 41.01it/s, train_loss=0.00174, val_loss=0.00202]Epoch 25:  56%|█████▌    | 15/27 [00:00<00:00, 42.58it/s, train_loss=0.00174, val_loss=0.00202]Epoch 25:  56%|█████▌    | 15/27 [00:00<00:00, 41.08it/s, train_loss=0.00235, val_loss=0.00202]Epoch 25:  59%|█████▉    | 16/27 [00:00<00:00, 42.75it/s, train_loss=0.00235, val_loss=0.00202]Epoch 25:  59%|█████▉    | 16/27 [00:00<00:00, 41.06it/s, train_loss=0.00172, val_loss=0.00202]Epoch 25:  63%|██████▎   | 17/27 [00:00<00:00, 42.50it/s, train_loss=0.00172, val_loss=0.00202]Epoch 25:  63%|██████▎   | 17/27 [00:00<00:00, 41.22it/s, train_loss=0.00189, val_loss=0.00202]Epoch 25:  67%|██████▋   | 18/27 [00:00<00:00, 42.57it/s, train_loss=0.00189, val_loss=0.00202]Epoch 25:  67%|██████▋   | 18/27 [00:00<00:00, 41.32it/s, train_loss=0.00199, val_loss=0.00202]Epoch 25:  70%|███████   | 19/27 [00:00<00:00, 42.72it/s, train_loss=0.00199, val_loss=0.00202]Epoch 25:  70%|███████   | 19/27 [00:00<00:00, 41.27it/s, train_loss=0.002, val_loss=0.00202]  Epoch 25:  74%|███████▍  | 20/27 [00:00<00:00, 42.47it/s, train_loss=0.002, val_loss=0.00202]Epoch 25:  74%|███████▍  | 20/27 [00:00<00:00, 41.39it/s, train_loss=0.00191, val_loss=0.00202]Epoch 25:  78%|███████▊  | 21/27 [00:00<00:00, 42.53it/s, train_loss=0.00191, val_loss=0.00202]Epoch 25:  78%|███████▊  | 21/27 [00:00<00:00, 41.43it/s, train_loss=0.002, val_loss=0.00202]  Epoch 25:  81%|████████▏ | 22/27 [00:00<00:00, 42.57it/s, train_loss=0.002, val_loss=0.00202]Epoch 25:  81%|████████▏ | 22/27 [00:00<00:00, 41.32it/s, train_loss=0.00211, val_loss=0.00202]Epoch 25:  85%|████████▌ | 23/27 [00:00<00:00, 42.45it/s, train_loss=0.00211, val_loss=0.00202]Epoch 25:  85%|████████▌ | 23/27 [00:00<00:00, 41.28it/s, train_loss=0.00188, val_loss=0.00202]Epoch 25:  89%|████████▉ | 24/27 [00:00<00:00, 42.18it/s, train_loss=0.00188, val_loss=0.00202]Epoch 25:  89%|████████▉ | 24/27 [00:00<00:00, 41.35it/s, train_loss=0.00178, val_loss=0.00202]Epoch 25:  93%|█████████▎| 25/27 [00:00<00:00, 42.38it/s, train_loss=0.00178, val_loss=0.00202]Epoch 25:  93%|█████████▎| 25/27 [00:00<00:00, 41.30it/s, train_loss=0.00199, val_loss=0.00202]Epoch 25:  96%|█████████▋| 26/27 [00:00<00:00, 42.28it/s, train_loss=0.00199, val_loss=0.00202]Epoch 25:  96%|█████████▋| 26/27 [00:00<00:00, 41.26it/s, train_loss=0.002, val_loss=0.00202]  Epoch 25: 100%|██████████| 27/27 [00:00<00:00, 42.17it/s, train_loss=0.002, val_loss=0.00202]Epoch 25: 100%|██████████| 27/27 [00:00<00:00, 41.47it/s, train_loss=0.00182, val_loss=0.00202]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 126.34it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 148.50it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 156.78it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 162.04it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 164.66it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 166.69it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 167.95it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 169.05it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 169.87it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 170.45it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 171.26it/s][A
                                                                         [AEpoch 25: 100%|██████████| 27/27 [00:00<00:00, 36.52it/s, train_loss=0.00182, val_loss=0.00202]Epoch 25: 100%|██████████| 27/27 [00:00<00:00, 36.46it/s, train_loss=0.00182, val_loss=0.00202]Epoch 25:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00182, val_loss=0.00202]         Epoch 26:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00182, val_loss=0.00202]Epoch 26:   4%|▎         | 1/27 [00:00<00:00, 90.22it/s, train_loss=0.00182, val_loss=0.00202]Epoch 26:   4%|▎         | 1/27 [00:00<00:00, 43.88it/s, train_loss=0.00184, val_loss=0.00202]Epoch 26:   7%|▋         | 2/27 [00:00<00:00, 62.12it/s, train_loss=0.00184, val_loss=0.00202]Epoch 26:   7%|▋         | 2/27 [00:00<00:00, 41.85it/s, train_loss=0.00188, val_loss=0.00202]Epoch 26:  11%|█         | 3/27 [00:00<00:00, 52.44it/s, train_loss=0.00188, val_loss=0.00202]Epoch 26:  11%|█         | 3/27 [00:00<00:00, 41.35it/s, train_loss=0.00201, val_loss=0.00202]Epoch 26:  15%|█▍        | 4/27 [00:00<00:00, 47.10it/s, train_loss=0.00201, val_loss=0.00202]Epoch 26:  15%|█▍        | 4/27 [00:00<00:00, 40.23it/s, train_loss=0.00199, val_loss=0.00202]Epoch 26:  19%|█▊        | 5/27 [00:00<00:00, 45.95it/s, train_loss=0.00199, val_loss=0.00202]Epoch 26:  19%|█▊        | 5/27 [00:00<00:00, 41.00it/s, train_loss=0.00207, val_loss=0.00202]Epoch 26:  22%|██▏       | 6/27 [00:00<00:00, 45.45it/s, train_loss=0.00207, val_loss=0.00202]Epoch 26:  22%|██▏       | 6/27 [00:00<00:00, 41.40it/s, train_loss=0.0019, val_loss=0.00202] Epoch 26:  26%|██▌       | 7/27 [00:00<00:00, 45.42it/s, train_loss=0.0019, val_loss=0.00202]Epoch 26:  26%|██▌       | 7/27 [00:00<00:00, 41.25it/s, train_loss=0.00201, val_loss=0.00202]Epoch 26:  30%|██▉       | 8/27 [00:00<00:00, 44.36it/s, train_loss=0.00201, val_loss=0.00202]Epoch 26:  30%|██▉       | 8/27 [00:00<00:00, 41.52it/s, train_loss=0.00183, val_loss=0.00202]Epoch 26:  33%|███▎      | 9/27 [00:00<00:00, 44.29it/s, train_loss=0.00183, val_loss=0.00202]Epoch 26:  33%|███▎      | 9/27 [00:00<00:00, 41.61it/s, train_loss=0.00196, val_loss=0.00202]Epoch 26:  37%|███▋      | 10/27 [00:00<00:00, 44.33it/s, train_loss=0.00196, val_loss=0.00202]Epoch 26:  37%|███▋      | 10/27 [00:00<00:00, 41.48it/s, train_loss=0.00207, val_loss=0.00202]Epoch 26:  41%|████      | 11/27 [00:00<00:00, 43.76it/s, train_loss=0.00207, val_loss=0.00202]Epoch 26:  41%|████      | 11/27 [00:00<00:00, 41.21it/s, train_loss=0.002, val_loss=0.00202]  Epoch 26:  44%|████▍     | 12/27 [00:00<00:00, 43.22it/s, train_loss=0.002, val_loss=0.00202]Epoch 26:  44%|████▍     | 12/27 [00:00<00:00, 41.36it/s, train_loss=0.00178, val_loss=0.00202]Epoch 26:  48%|████▊     | 13/27 [00:00<00:00, 43.21it/s, train_loss=0.00178, val_loss=0.00202]Epoch 26:  48%|████▊     | 13/27 [00:00<00:00, 41.51it/s, train_loss=0.00181, val_loss=0.00202]Epoch 26:  52%|█████▏    | 14/27 [00:00<00:00, 43.40it/s, train_loss=0.00181, val_loss=0.00202]Epoch 26:  52%|█████▏    | 14/27 [00:00<00:00, 41.40it/s, train_loss=0.00195, val_loss=0.00202]Epoch 26:  56%|█████▌    | 15/27 [00:00<00:00, 43.10it/s, train_loss=0.00195, val_loss=0.00202]Epoch 26:  56%|█████▌    | 15/27 [00:00<00:00, 41.31it/s, train_loss=0.00202, val_loss=0.00202]Epoch 26:  59%|█████▉    | 16/27 [00:00<00:00, 42.75it/s, train_loss=0.00202, val_loss=0.00202]Epoch 26:  59%|█████▉    | 16/27 [00:00<00:00, 41.39it/s, train_loss=0.00181, val_loss=0.00202]Epoch 26:  63%|██████▎   | 17/27 [00:00<00:00, 42.86it/s, train_loss=0.00181, val_loss=0.00202]Epoch 26:  63%|██████▎   | 17/27 [00:00<00:00, 41.27it/s, train_loss=0.00213, val_loss=0.00202]Epoch 26:  67%|██████▋   | 18/27 [00:00<00:00, 42.71it/s, train_loss=0.00213, val_loss=0.00202]Epoch 26:  67%|██████▋   | 18/27 [00:00<00:00, 41.20it/s, train_loss=0.00203, val_loss=0.00202]Epoch 26:  70%|███████   | 19/27 [00:00<00:00, 42.53it/s, train_loss=0.00203, val_loss=0.00202]Epoch 26:  70%|███████   | 19/27 [00:00<00:00, 41.13it/s, train_loss=0.00178, val_loss=0.00202]Epoch 26:  74%|███████▍  | 20/27 [00:00<00:00, 42.31it/s, train_loss=0.00178, val_loss=0.00202]Epoch 26:  74%|███████▍  | 20/27 [00:00<00:00, 41.24it/s, train_loss=0.00195, val_loss=0.00202]Epoch 26:  78%|███████▊  | 21/27 [00:00<00:00, 42.49it/s, train_loss=0.00195, val_loss=0.00202]Epoch 26:  78%|███████▊  | 21/27 [00:00<00:00, 41.21it/s, train_loss=0.00204, val_loss=0.00202]Epoch 26:  81%|████████▏ | 22/27 [00:00<00:00, 42.37it/s, train_loss=0.00204, val_loss=0.00202]Epoch 26:  81%|████████▏ | 22/27 [00:00<00:00, 41.32it/s, train_loss=0.00175, val_loss=0.00202]Epoch 26:  85%|████████▌ | 23/27 [00:00<00:00, 42.40it/s, train_loss=0.00175, val_loss=0.00202]Epoch 26:  85%|████████▌ | 23/27 [00:00<00:00, 41.40it/s, train_loss=0.00189, val_loss=0.00202]Epoch 26:  89%|████████▉ | 24/27 [00:00<00:00, 42.47it/s, train_loss=0.00189, val_loss=0.00202]Epoch 26:  89%|████████▉ | 24/27 [00:00<00:00, 41.32it/s, train_loss=0.00212, val_loss=0.00202]Epoch 26:  93%|█████████▎| 25/27 [00:00<00:00, 42.30it/s, train_loss=0.00212, val_loss=0.00202]Epoch 26:  93%|█████████▎| 25/27 [00:00<00:00, 41.27it/s, train_loss=0.00201, val_loss=0.00202]Epoch 26:  96%|█████████▋| 26/27 [00:00<00:00, 42.17it/s, train_loss=0.00201, val_loss=0.00202]Epoch 26:  96%|█████████▋| 26/27 [00:00<00:00, 41.34it/s, train_loss=0.00196, val_loss=0.00202]Epoch 26: 100%|██████████| 27/27 [00:00<00:00, 42.31it/s, train_loss=0.00196, val_loss=0.00202]Epoch 26: 100%|██████████| 27/27 [00:00<00:00, 41.43it/s, train_loss=0.00205, val_loss=0.00202]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 118.83it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 116.25it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 131.62it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 140.95it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 147.35it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 150.70it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 153.55it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 156.48it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 158.44it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 159.86it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 160.82it/s][A
                                                                         [AEpoch 26: 100%|██████████| 27/27 [00:00<00:00, 36.50it/s, train_loss=0.00205, val_loss=0.00198]Epoch 26: 100%|██████████| 27/27 [00:00<00:00, 36.44it/s, train_loss=0.00205, val_loss=0.00198]Epoch 26:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00205, val_loss=0.00198]         Epoch 27:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00205, val_loss=0.00198]Epoch 27:   4%|▎         | 1/27 [00:00<00:00, 93.63it/s, train_loss=0.00205, val_loss=0.00198]Epoch 27:   4%|▎         | 1/27 [00:00<00:00, 39.26it/s, train_loss=0.002, val_loss=0.00198]  Epoch 27:   7%|▋         | 2/27 [00:00<00:00, 55.43it/s, train_loss=0.002, val_loss=0.00198]Epoch 27:   7%|▋         | 2/27 [00:00<00:00, 41.11it/s, train_loss=0.00183, val_loss=0.00198]Epoch 27:  11%|█         | 3/27 [00:00<00:00, 51.13it/s, train_loss=0.00183, val_loss=0.00198]Epoch 27:  11%|█         | 3/27 [00:00<00:00, 40.70it/s, train_loss=0.00192, val_loss=0.00198]Epoch 27:  15%|█▍        | 4/27 [00:00<00:00, 48.37it/s, train_loss=0.00192, val_loss=0.00198]Epoch 27:  15%|█▍        | 4/27 [00:00<00:00, 40.78it/s, train_loss=0.00184, val_loss=0.00198]Epoch 27:  19%|█▊        | 5/27 [00:00<00:00, 46.32it/s, train_loss=0.00184, val_loss=0.00198]Epoch 27:  19%|█▊        | 5/27 [00:00<00:00, 41.36it/s, train_loss=0.00186, val_loss=0.00198]Epoch 27:  22%|██▏       | 6/27 [00:00<00:00, 45.95it/s, train_loss=0.00186, val_loss=0.00198]Epoch 27:  22%|██▏       | 6/27 [00:00<00:00, 41.20it/s, train_loss=0.00202, val_loss=0.00198]Epoch 27:  26%|██▌       | 7/27 [00:00<00:00, 45.17it/s, train_loss=0.00202, val_loss=0.00198]Epoch 27:  26%|██▌       | 7/27 [00:00<00:00, 41.63it/s, train_loss=0.00188, val_loss=0.00198]Epoch 27:  30%|██▉       | 8/27 [00:00<00:00, 44.94it/s, train_loss=0.00188, val_loss=0.00198]Epoch 27:  30%|██▉       | 8/27 [00:00<00:00, 41.72it/s, train_loss=0.00195, val_loss=0.00198]Epoch 27:  33%|███▎      | 9/27 [00:00<00:00, 44.78it/s, train_loss=0.00195, val_loss=0.00198]Epoch 27:  33%|███▎      | 9/27 [00:00<00:00, 41.57it/s, train_loss=0.00182, val_loss=0.00198]Epoch 27:  37%|███▋      | 10/27 [00:00<00:00, 44.25it/s, train_loss=0.00182, val_loss=0.00198]Epoch 27:  37%|███▋      | 10/27 [00:00<00:00, 41.84it/s, train_loss=0.00187, val_loss=0.00198]Epoch 27:  41%|████      | 11/27 [00:00<00:00, 44.19it/s, train_loss=0.00187, val_loss=0.00198]Epoch 27:  41%|████      | 11/27 [00:00<00:00, 41.90it/s, train_loss=0.00211, val_loss=0.00198]Epoch 27:  44%|████▍     | 12/27 [00:00<00:00, 44.14it/s, train_loss=0.00211, val_loss=0.00198]Epoch 27:  44%|████▍     | 12/27 [00:00<00:00, 41.77it/s, train_loss=0.00181, val_loss=0.00198]Epoch 27:  48%|████▊     | 13/27 [00:00<00:00, 43.81it/s, train_loss=0.00181, val_loss=0.00198]Epoch 27:  48%|████▊     | 13/27 [00:00<00:00, 41.96it/s, train_loss=0.00191, val_loss=0.00198]Epoch 27:  52%|█████▏    | 14/27 [00:00<00:00, 43.75it/s, train_loss=0.00191, val_loss=0.00198]Epoch 27:  52%|█████▏    | 14/27 [00:00<00:00, 42.04it/s, train_loss=0.00198, val_loss=0.00198]Epoch 27:  56%|█████▌    | 15/27 [00:00<00:00, 43.84it/s, train_loss=0.00198, val_loss=0.00198]Epoch 27:  56%|█████▌    | 15/27 [00:00<00:00, 41.93it/s, train_loss=0.00203, val_loss=0.00198]Epoch 27:  59%|█████▉    | 16/27 [00:00<00:00, 43.39it/s, train_loss=0.00203, val_loss=0.00198]Epoch 27:  59%|█████▉    | 16/27 [00:00<00:00, 42.05it/s, train_loss=0.0017, val_loss=0.00198] Epoch 27:  63%|██████▎   | 17/27 [00:00<00:00, 43.51it/s, train_loss=0.0017, val_loss=0.00198]Epoch 27:  63%|██████▎   | 17/27 [00:00<00:00, 42.09it/s, train_loss=0.00192, val_loss=0.00198]Epoch 27:  67%|██████▋   | 18/27 [00:00<00:00, 43.56it/s, train_loss=0.00192, val_loss=0.00198]Epoch 27:  67%|██████▋   | 18/27 [00:00<00:00, 41.94it/s, train_loss=0.002, val_loss=0.00198]  Epoch 27:  70%|███████   | 19/27 [00:00<00:00, 43.29it/s, train_loss=0.002, val_loss=0.00198]Epoch 27:  70%|███████   | 19/27 [00:00<00:00, 41.84it/s, train_loss=0.00198, val_loss=0.00198]Epoch 27:  74%|███████▍  | 20/27 [00:00<00:00, 43.08it/s, train_loss=0.00198, val_loss=0.00198]Epoch 27:  74%|███████▍  | 20/27 [00:00<00:00, 41.92it/s, train_loss=0.0022, val_loss=0.00198] Epoch 27:  78%|███████▊  | 21/27 [00:00<00:00, 43.16it/s, train_loss=0.0022, val_loss=0.00198]Epoch 27:  78%|███████▊  | 21/27 [00:00<00:00, 41.84it/s, train_loss=0.00198, val_loss=0.00198]Epoch 27:  81%|████████▏ | 22/27 [00:00<00:00, 42.98it/s, train_loss=0.00198, val_loss=0.00198]Epoch 27:  81%|████████▏ | 22/27 [00:00<00:00, 41.73it/s, train_loss=0.00205, val_loss=0.00198]Epoch 27:  85%|████████▌ | 23/27 [00:00<00:00, 42.80it/s, train_loss=0.00205, val_loss=0.00198]Epoch 27:  85%|████████▌ | 23/27 [00:00<00:00, 41.80it/s, train_loss=0.002, val_loss=0.00198]  Epoch 27:  89%|████████▉ | 24/27 [00:00<00:00, 42.86it/s, train_loss=0.002, val_loss=0.00198]Epoch 27:  89%|████████▉ | 24/27 [00:00<00:00, 41.82it/s, train_loss=0.00205, val_loss=0.00198]Epoch 27:  93%|█████████▎| 25/27 [00:00<00:00, 42.88it/s, train_loss=0.00205, val_loss=0.00198]Epoch 27:  93%|█████████▎| 25/27 [00:00<00:00, 41.74it/s, train_loss=0.00201, val_loss=0.00198]Epoch 27:  96%|█████████▋| 26/27 [00:00<00:00, 42.74it/s, train_loss=0.00201, val_loss=0.00198]Epoch 27:  96%|█████████▋| 26/27 [00:00<00:00, 41.85it/s, train_loss=0.00193, val_loss=0.00198]Epoch 27: 100%|██████████| 27/27 [00:00<00:00, 42.78it/s, train_loss=0.00193, val_loss=0.00198]Epoch 27: 100%|██████████| 27/27 [00:00<00:00, 42.00it/s, train_loss=0.00193, val_loss=0.00198]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 140.70it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 159.97it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 169.59it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 176.02it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 180.04it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 183.11it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 185.34it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 185.87it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 185.92it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 185.94it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 186.76it/s][A
                                                                         [AEpoch 27: 100%|██████████| 27/27 [00:00<00:00, 37.17it/s, train_loss=0.00193, val_loss=0.00201]Epoch 27: 100%|██████████| 27/27 [00:00<00:00, 37.12it/s, train_loss=0.00193, val_loss=0.00201]Epoch 27:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00193, val_loss=0.00201]         Epoch 28:   0%|          | 0/27 [00:00<?, ?it/s, train_loss=0.00193, val_loss=0.00201]Epoch 28:   4%|▎         | 1/27 [00:00<00:00, 94.55it/s, train_loss=0.00193, val_loss=0.00201]Epoch 28:   4%|▎         | 1/27 [00:00<00:00, 42.62it/s, train_loss=0.00202, val_loss=0.00201]Epoch 28:   7%|▋         | 2/27 [00:00<00:00, 59.99it/s, train_loss=0.00202, val_loss=0.00201]Epoch 28:   7%|▋         | 2/27 [00:00<00:00, 41.30it/s, train_loss=0.00212, val_loss=0.00201]Epoch 28:  11%|█         | 3/27 [00:00<00:00, 51.83it/s, train_loss=0.00212, val_loss=0.00201]Epoch 28:  11%|█         | 3/27 [00:00<00:00, 40.97it/s, train_loss=0.00182, val_loss=0.00201]Epoch 28:  15%|█▍        | 4/27 [00:00<00:00, 48.23it/s, train_loss=0.00182, val_loss=0.00201]Epoch 28:  15%|█▍        | 4/27 [00:00<00:00, 40.73it/s, train_loss=0.00185, val_loss=0.00201]Epoch 28:  19%|█▊        | 5/27 [00:00<00:00, 46.02it/s, train_loss=0.00185, val_loss=0.00201]Epoch 28:  19%|█▊        | 5/27 [00:00<00:00, 41.15it/s, train_loss=0.00198, val_loss=0.00201]Epoch 28:  22%|██▏       | 6/27 [00:00<00:00, 45.76it/s, train_loss=0.00198, val_loss=0.00201]Epoch 28:  22%|██▏       | 6/27 [00:00<00:00, 40.89it/s, train_loss=0.00189, val_loss=0.00201]Epoch 28:  26%|██▌       | 7/27 [00:00<00:00, 44.76it/s, train_loss=0.00189, val_loss=0.00201]Epoch 28:  26%|██▌       | 7/27 [00:00<00:00, 40.65it/s, train_loss=0.00184, val_loss=0.00201]Epoch 28:  30%|██▉       | 8/27 [00:00<00:00, 44.04it/s, train_loss=0.00184, val_loss=0.00201]Epoch 28:  30%|██▉       | 8/27 [00:00<00:00, 41.11it/s, train_loss=0.00189, val_loss=0.00201]Epoch 28:  33%|███▎      | 9/27 [00:00<00:00, 44.05it/s, train_loss=0.00189, val_loss=0.00201]Epoch 28:  33%|███▎      | 9/27 [00:00<00:00, 41.31it/s, train_loss=0.00215, val_loss=0.00201]Epoch 28:  37%|███▋      | 10/27 [00:00<00:00, 43.89it/s, train_loss=0.00215, val_loss=0.00201]Epoch 28:  37%|███▋      | 10/27 [00:00<00:00, 41.15it/s, train_loss=0.00199, val_loss=0.00201]Epoch 28:  41%|████      | 11/27 [00:00<00:00, 43.57it/s, train_loss=0.00199, val_loss=0.00201]Epoch 28:  41%|████      | 11/27 [00:00<00:00, 41.08it/s, train_loss=0.0019, val_loss=0.00201] Epoch 28:  44%|████▍     | 12/27 [00:00<00:00, 43.19it/s, train_loss=0.0019, val_loss=0.00201]Epoch 28:  44%|████▍     | 12/27 [00:00<00:00, 41.28it/s, train_loss=0.00191, val_loss=0.00201]Epoch 28:  48%|████▊     | 13/27 [00:00<00:00, 43.33it/s, train_loss=0.00191, val_loss=0.00201]Epoch 28:  48%|████▊     | 13/27 [00:00<00:00, 41.16it/s, train_loss=0.00191, val_loss=0.00201]Epoch 28:  52%|█████▏    | 14/27 [00:00<00:00, 43.07it/s, train_loss=0.00191, val_loss=0.00201]Epoch 28:  52%|█████▏    | 14/27 [00:00<00:00, 41.11it/s, train_loss=0.00181, val_loss=0.00201]Epoch 28:  56%|█████▌    | 15/27 [00:00<00:00, 42.78it/s, train_loss=0.00181, val_loss=0.00201]Epoch 28:  56%|█████▌    | 15/27 [00:00<00:00, 41.24it/s, train_loss=0.00198, val_loss=0.00201]Epoch 28:  59%|█████▉    | 16/27 [00:00<00:00, 42.77it/s, train_loss=0.00198, val_loss=0.00201]Epoch 28:  59%|█████▉    | 16/27 [00:00<00:00, 41.15it/s, train_loss=0.0018, val_loss=0.00201] Epoch 28:  63%|██████▎   | 17/27 [00:00<00:00, 42.70it/s, train_loss=0.0018, val_loss=0.00201]Epoch 28:  63%|██████▎   | 17/27 [00:00<00:00, 41.11it/s, train_loss=0.00164, val_loss=0.00201]Epoch 28:  67%|██████▋   | 18/27 [00:00<00:00, 42.55it/s, train_loss=0.00164, val_loss=0.00201]Epoch 28:  67%|██████▋   | 18/27 [00:00<00:00, 41.28it/s, train_loss=0.00204, val_loss=0.00201]Epoch 28:  70%|███████   | 19/27 [00:00<00:00, 42.64it/s, train_loss=0.00204, val_loss=0.00201]Epoch 28:  70%|███████   | 19/27 [00:00<00:00, 41.30it/s, train_loss=0.00194, val_loss=0.00201]Epoch 28:  74%|███████▍  | 20/27 [00:00<00:00, 42.62it/s, train_loss=0.00194, val_loss=0.00201]Epoch 28:  74%|███████▍  | 20/27 [00:00<00:00, 41.24it/s, train_loss=0.00207, val_loss=0.00201]Epoch 28:  78%|███████▊  | 21/27 [00:00<00:00, 42.46it/s, train_loss=0.00207, val_loss=0.00201]Epoch 28:  78%|███████▊  | 21/27 [00:00<00:00, 41.19it/s, train_loss=0.00203, val_loss=0.00201]Epoch 28:  81%|████████▏ | 22/27 [00:00<00:00, 42.31it/s, train_loss=0.00203, val_loss=0.00201]Epoch 28:  81%|████████▏ | 22/27 [00:00<00:00, 41.28it/s, train_loss=0.00192, val_loss=0.00201]Epoch 28:  85%|████████▌ | 23/27 [00:00<00:00, 42.42it/s, train_loss=0.00192, val_loss=0.00201]Epoch 28:  85%|████████▌ | 23/27 [00:00<00:00, 41.21it/s, train_loss=0.00214, val_loss=0.00201]Epoch 28:  89%|████████▉ | 24/27 [00:00<00:00, 42.28it/s, train_loss=0.00214, val_loss=0.00201]Epoch 28:  89%|████████▉ | 24/27 [00:00<00:00, 41.13it/s, train_loss=0.00208, val_loss=0.00201]Epoch 28:  93%|█████████▎| 25/27 [00:00<00:00, 42.01it/s, train_loss=0.00208, val_loss=0.00201]Epoch 28:  93%|█████████▎| 25/27 [00:00<00:00, 41.22it/s, train_loss=0.00186, val_loss=0.00201]Epoch 28:  96%|█████████▋| 26/27 [00:00<00:00, 42.10it/s, train_loss=0.00186, val_loss=0.00201]Epoch 28:  96%|█████████▋| 26/27 [00:00<00:00, 41.29it/s, train_loss=0.00191, val_loss=0.00201]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 42.29it/s, train_loss=0.00191, val_loss=0.00201]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 41.41it/s, train_loss=0.00185, val_loss=0.00201]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/11 [00:00<?, ?it/s][A
Validation DataLoader 0:   9%|▉         | 1/11 [00:00<00:00, 149.98it/s][A
Validation DataLoader 0:  18%|█▊        | 2/11 [00:00<00:00, 150.51it/s][A
Validation DataLoader 0:  27%|██▋       | 3/11 [00:00<00:00, 161.22it/s][A
Validation DataLoader 0:  36%|███▋      | 4/11 [00:00<00:00, 172.20it/s][A
Validation DataLoader 0:  45%|████▌     | 5/11 [00:00<00:00, 175.78it/s][A
Validation DataLoader 0:  55%|█████▍    | 6/11 [00:00<00:00, 178.60it/s][A
Validation DataLoader 0:  64%|██████▎   | 7/11 [00:00<00:00, 181.78it/s][A
Validation DataLoader 0:  73%|███████▎  | 8/11 [00:00<00:00, 184.19it/s][A
Validation DataLoader 0:  82%|████████▏ | 9/11 [00:00<00:00, 186.52it/s][A
Validation DataLoader 0:  91%|█████████ | 10/11 [00:00<00:00, 186.67it/s][A
Validation DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 188.03it/s][A
                                                                         [AEpoch 28: 100%|██████████| 27/27 [00:00<00:00, 36.63it/s, train_loss=0.00185, val_loss=0.00198]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 36.58it/s, train_loss=0.00185, val_loss=0.00198]Epoch 28: 100%|██████████| 27/27 [00:00<00:00, 36.43it/s, train_loss=0.00185, val_loss=0.00198]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/26 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▍         | 1/26 [00:00<00:00, 129.87it/s]Predicting DataLoader 0:   8%|▊         | 2/26 [00:00<00:00, 121.99it/s]Predicting DataLoader 0:  12%|█▏        | 3/26 [00:00<00:00, 104.15it/s]Predicting DataLoader 0:  15%|█▌        | 4/26 [00:00<00:00, 105.85it/s]Predicting DataLoader 0:  19%|█▉        | 5/26 [00:00<00:00, 107.00it/s]Predicting DataLoader 0:  23%|██▎       | 6/26 [00:00<00:00, 106.47it/s]Predicting DataLoader 0:  27%|██▋       | 7/26 [00:00<00:00, 106.97it/s]Predicting DataLoader 0:  31%|███       | 8/26 [00:00<00:00, 103.41it/s]Predicting DataLoader 0:  35%|███▍      | 9/26 [00:00<00:00, 103.96it/s]Predicting DataLoader 0:  38%|███▊      | 10/26 [00:00<00:00, 104.68it/s]Predicting DataLoader 0:  42%|████▏     | 11/26 [00:00<00:00, 102.13it/s]Predicting DataLoader 0:  46%|████▌     | 12/26 [00:00<00:00, 103.26it/s]Predicting DataLoader 0:  50%|█████     | 13/26 [00:00<00:00, 101.65it/s]Predicting DataLoader 0:  54%|█████▍    | 14/26 [00:00<00:00, 102.28it/s]Predicting DataLoader 0:  58%|█████▊    | 15/26 [00:00<00:00, 102.85it/s]Predicting DataLoader 0:  62%|██████▏   | 16/26 [00:00<00:00, 103.06it/s]Predicting DataLoader 0:  65%|██████▌   | 17/26 [00:00<00:00, 103.50it/s]Predicting DataLoader 0:  69%|██████▉   | 18/26 [00:00<00:00, 101.94it/s]Predicting DataLoader 0:  73%|███████▎  | 19/26 [00:00<00:00, 102.16it/s]Predicting DataLoader 0:  77%|███████▋  | 20/26 [00:00<00:00, 101.83it/s]Predicting DataLoader 0:  81%|████████  | 21/26 [00:00<00:00, 102.07it/s]Predicting DataLoader 0:  85%|████████▍ | 22/26 [00:00<00:00, 102.53it/s]Predicting DataLoader 0:  88%|████████▊ | 23/26 [00:00<00:00, 101.53it/s]Predicting DataLoader 0:  92%|█████████▏| 24/26 [00:00<00:00, 101.88it/s]Predicting DataLoader 0:  96%|█████████▌| 25/26 [00:00<00:00, 101.53it/s]Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 101.69it/s]Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 101.23it/s][I 2025-08-18 02:30:10,570] A new study created in memory with name: no-name-fbcea6ad-7386-4363-90ed-db117ff03fb1
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 32, Horizon length: 30
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.87it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.44it/s][I 2025-08-18 02:30:34,302] Trial 0 finished with value: 37.39096367879785 and parameters: {'hidden_dim': 116, 'n_rnn_layers': 3, 'dropout': 0.02934269733036854}. Best is trial 0 with value: 37.39096367879785.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.68it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.25it/s][I 2025-08-18 02:30:58,801] Trial 1 finished with value: 24.36908568095488 and parameters: {'hidden_dim': 84, 'n_rnn_layers': 4, 'dropout': 0.3076803626670877}. Best is trial 1 with value: 24.36908568095488.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.10it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.39it/s][I 2025-08-18 02:31:17,252] Trial 2 finished with value: 62.578556365203845 and parameters: {'hidden_dim': 40, 'n_rnn_layers': 4, 'dropout': 0.1720690745944845}. Best is trial 1 with value: 24.36908568095488.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.46it/s][I 2025-08-18 02:31:50,095] Trial 3 finished with value: 23.043822538247703 and parameters: {'hidden_dim': 110, 'n_rnn_layers': 4, 'dropout': 0.002412544583570153}. Best is trial 3 with value: 23.043822538247703.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.39it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s][I 2025-08-18 02:32:07,186] Trial 4 finished with value: 43.5302557622276 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 3, 'dropout': 0.3109624331058014}. Best is trial 3 with value: 23.043822538247703.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.97it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.36it/s] [I 2025-08-18 02:32:26,342] Trial 5 finished with value: 25.1385600274565 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 3, 'dropout': 0.44192125631878865}. Best is trial 3 with value: 23.043822538247703.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.30it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.16it/s][I 2025-08-18 02:32:45,624] Trial 6 finished with value: 27.516231803617625 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 4, 'dropout': 0.21746855118679725}. Best is trial 3 with value: 23.043822538247703.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.55it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.38it/s][I 2025-08-18 02:33:01,765] Trial 7 finished with value: 26.723283746215753 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 3, 'dropout': 0.053399203454004285}. Best is trial 3 with value: 23.043822538247703.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.91it/s] [I 2025-08-18 02:33:27,654] Trial 8 finished with value: 21.673230996512554 and parameters: {'hidden_dim': 41, 'n_rnn_layers': 4, 'dropout': 0.4241968193654782}. Best is trial 8 with value: 21.673230996512554.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40305516448725603 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.15it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.01it/s][I 2025-08-18 02:33:37,304] Trial 9 finished with value: 28.64689040506196 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 1, 'dropout': 0.40305516448725603}. Best is trial 8 with value: 21.673230996512554.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49982078404273583 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.57it/s][I 2025-08-18 02:33:55,450] Trial 10 finished with value: 58.80794811345175 and parameters: {'hidden_dim': 63, 'n_rnn_layers': 1, 'dropout': 0.49982078404273583}. Best is trial 8 with value: 21.673230996512554.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.93it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.88it/s][I 2025-08-18 02:34:19,868] Trial 11 finished with value: 24.600758825049596 and parameters: {'hidden_dim': 65, 'n_rnn_layers': 2, 'dropout': 0.13716356263131518}. Best is trial 8 with value: 21.673230996512554.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.77it/s] [I 2025-08-18 02:35:02,436] Trial 12 finished with value: 22.333981209686655 and parameters: {'hidden_dim': 128, 'n_rnn_layers': 4, 'dropout': 0.35148577179998797}. Best is trial 8 with value: 21.673230996512554.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.75it/s] [I 2025-08-18 02:35:23,074] Trial 13 finished with value: 21.357973521880933 and parameters: {'hidden_dim': 58, 'n_rnn_layers': 2, 'dropout': 0.3618436269255986}. Best is trial 13 with value: 21.357973521880933.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.88it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.21it/s][I 2025-08-18 02:35:41,418] Trial 14 finished with value: 24.24211208730869 and parameters: {'hidden_dim': 57, 'n_rnn_layers': 2, 'dropout': 0.4262373791463793}. Best is trial 13 with value: 21.357973521880933.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.24it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.76it/s][I 2025-08-18 02:35:57,909] Trial 15 finished with value: 27.963417729969017 and parameters: {'hidden_dim': 52, 'n_rnn_layers': 2, 'dropout': 0.36071410528224407}. Best is trial 13 with value: 21.357973521880933.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.25it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.96it/s] [I 2025-08-18 02:36:23,693] Trial 16 finished with value: 23.670616156502586 and parameters: {'hidden_dim': 79, 'n_rnn_layers': 2, 'dropout': 0.4835058037821406}. Best is trial 13 with value: 21.357973521880933.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.271724197769238 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.66it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.06it/s][I 2025-08-18 02:36:35,705] Trial 17 finished with value: 45.20975823472866 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 1, 'dropout': 0.271724197769238}. Best is trial 13 with value: 21.357973521880933.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.13it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.54it/s] [I 2025-08-18 02:36:50,992] Trial 18 finished with value: 22.66043215982091 and parameters: {'hidden_dim': 48, 'n_rnn_layers': 3, 'dropout': 0.3551203427268949}. Best is trial 13 with value: 21.357973521880933.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.99it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.99it/s][I 2025-08-18 02:37:02,205] Trial 19 finished with value: 29.178415780018145 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 2, 'dropout': 0.3906277061851515}. Best is trial 13 with value: 21.357973521880933.
[I 2025-08-18 02:37:02,205] A new study created in memory with name: no-name-3a3cf422-f98f-4551-93c1-be44b5e567d7
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 58, 'n_rnn_layers': 2, 'dropout': 0.3618436269255986}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.12it/s][I 2025-08-18 02:37:24,181] Trial 0 finished with value: 24.882166803268753 and parameters: {'hidden_dim': 42, 'n_rnn_layers': 4, 'dropout': 0.01862073476183901}. Best is trial 0 with value: 24.882166803268753.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.75it/s] [I 2025-08-18 02:37:43,511] Trial 1 finished with value: 41.43995771973266 and parameters: {'hidden_dim': 63, 'n_rnn_layers': 2, 'dropout': 0.02655989023512978}. Best is trial 0 with value: 24.882166803268753.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.57it/s] [I 2025-08-18 02:38:09,380] Trial 2 finished with value: 49.2396822867136 and parameters: {'hidden_dim': 94, 'n_rnn_layers': 2, 'dropout': 0.37269387417456695}. Best is trial 0 with value: 24.882166803268753.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.03it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.98it/s][I 2025-08-18 02:38:26,649] Trial 3 finished with value: 47.21509008740968 and parameters: {'hidden_dim': 54, 'n_rnn_layers': 2, 'dropout': 0.23407347625467528}. Best is trial 0 with value: 24.882166803268753.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.44it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.99it/s][I 2025-08-18 02:38:49,300] Trial 4 finished with value: 28.183189509022522 and parameters: {'hidden_dim': 37, 'n_rnn_layers': 4, 'dropout': 0.031039571409403444}. Best is trial 0 with value: 24.882166803268753.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.52it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.49it/s][I 2025-08-18 02:39:06,959] Trial 5 finished with value: 26.293278372230013 and parameters: {'hidden_dim': 18, 'n_rnn_layers': 4, 'dropout': 0.09334728013926158}. Best is trial 0 with value: 24.882166803268753.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.20it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.10it/s][I 2025-08-18 02:39:25,513] Trial 6 finished with value: 23.307368672566586 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 3, 'dropout': 0.14098566773844923}. Best is trial 6 with value: 23.307368672566586.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.13it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.31it/s][I 2025-08-18 02:39:44,142] Trial 7 finished with value: 23.351049129014747 and parameters: {'hidden_dim': 27, 'n_rnn_layers': 4, 'dropout': 0.4307120138414461}. Best is trial 6 with value: 23.307368672566586.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3365058927896892 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.48it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.44it/s][I 2025-08-18 02:40:03,912] Trial 8 finished with value: 43.09410718198216 and parameters: {'hidden_dim': 66, 'n_rnn_layers': 1, 'dropout': 0.3365058927896892}. Best is trial 6 with value: 23.307368672566586.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23900334618681113 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.78it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.36it/s] [I 2025-08-18 02:40:14,951] Trial 9 finished with value: 29.821163456132716 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 1, 'dropout': 0.23900334618681113}. Best is trial 6 with value: 23.307368672566586.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.77it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.71it/s][I 2025-08-18 02:40:42,960] Trial 10 finished with value: 21.519875032911713 and parameters: {'hidden_dim': 112, 'n_rnn_layers': 3, 'dropout': 0.1607669155568706}. Best is trial 10 with value: 21.519875032911713.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.67it/s][I 2025-08-18 02:41:21,788] Trial 11 finished with value: 38.39822624637862 and parameters: {'hidden_dim': 115, 'n_rnn_layers': 3, 'dropout': 0.1536030970251491}. Best is trial 10 with value: 21.519875032911713.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.91it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.25it/s][I 2025-08-18 02:41:38,716] Trial 12 finished with value: 21.313218531462326 and parameters: {'hidden_dim': 32, 'n_rnn_layers': 3, 'dropout': 0.15712721870046117}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.87it/s][I 2025-08-18 02:41:59,902] Trial 13 finished with value: 49.28433071140843 and parameters: {'hidden_dim': 88, 'n_rnn_layers': 3, 'dropout': 0.1910476801139528}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.36it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.17it/s][I 2025-08-18 02:42:16,646] Trial 14 finished with value: 41.37619506708281 and parameters: {'hidden_dim': 27, 'n_rnn_layers': 3, 'dropout': 0.3045901287682735}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.76it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.29it/s] [I 2025-08-18 02:42:39,739] Trial 15 finished with value: 38.11867361446923 and parameters: {'hidden_dim': 128, 'n_rnn_layers': 3, 'dropout': 0.08675266159560516}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.91it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.58it/s][I 2025-08-18 02:42:53,639] Trial 16 finished with value: 53.61268142673253 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 2, 'dropout': 0.2823567809578801}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.73it/s][I 2025-08-18 02:43:14,032] Trial 17 finished with value: 40.92583283378144 and parameters: {'hidden_dim': 52, 'n_rnn_layers': 3, 'dropout': 0.4886491196557054}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.99it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.55it/s] [I 2025-08-18 02:43:39,120] Trial 18 finished with value: 58.01282232184174 and parameters: {'hidden_dim': 79, 'n_rnn_layers': 2, 'dropout': 0.1578384169690623}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.84it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.73it/s][I 2025-08-18 02:43:57,194] Trial 19 finished with value: 22.135243608435083 and parameters: {'hidden_dim': 32, 'n_rnn_layers': 4, 'dropout': 0.09425754681773613}. Best is trial 12 with value: 21.313218531462326.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 21.4 K | train
6 | V               | Linear           | 33     | train
-------------------------------------------------------------
21.4 K    Trainable params
0         Non-trainable params
21.4 K    Total params
0.086     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 32, 'n_rnn_layers': 3, 'dropout': 0.15712721870046117}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 185.10it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 195.70it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/26 [00:00<?, ?it/s] Epoch 0:   4%|▍         | 1/26 [00:00<00:00, 76.67it/s]Epoch 0:   4%|▍         | 1/26 [00:00<00:00, 63.31it/s, train_loss=0.0546]Epoch 0:   8%|▊         | 2/26 [00:00<00:00, 80.17it/s, train_loss=0.0546]Epoch 0:   8%|▊         | 2/26 [00:00<00:00, 62.59it/s, train_loss=0.0569]Epoch 0:  12%|█▏        | 3/26 [00:00<00:00, 69.65it/s, train_loss=0.0569]Epoch 0:  12%|█▏        | 3/26 [00:00<00:00, 64.86it/s, train_loss=0.0384]Epoch 0:  15%|█▌        | 4/26 [00:00<00:00, 72.45it/s, train_loss=0.0384]Epoch 0:  15%|█▌        | 4/26 [00:00<00:00, 66.32it/s, train_loss=0.0558]Epoch 0:  19%|█▉        | 5/26 [00:00<00:00, 70.42it/s, train_loss=0.0558]Epoch 0:  19%|█▉        | 5/26 [00:00<00:00, 66.48it/s, train_loss=0.0583]Epoch 0:  23%|██▎       | 6/26 [00:00<00:00, 71.17it/s, train_loss=0.0583]Epoch 0:  23%|██▎       | 6/26 [00:00<00:00, 67.05it/s, train_loss=0.0544]Epoch 0:  27%|██▋       | 7/26 [00:00<00:00, 69.65it/s, train_loss=0.0544]Epoch 0:  27%|██▋       | 7/26 [00:00<00:00, 67.03it/s, train_loss=0.0501]Epoch 0:  31%|███       | 8/26 [00:00<00:00, 70.40it/s, train_loss=0.0501]Epoch 0:  31%|███       | 8/26 [00:00<00:00, 67.36it/s, train_loss=0.0391]Epoch 0:  35%|███▍      | 9/26 [00:00<00:00, 69.44it/s, train_loss=0.0391]Epoch 0:  35%|███▍      | 9/26 [00:00<00:00, 67.23it/s, train_loss=0.0523]Epoch 0:  38%|███▊      | 10/26 [00:00<00:00, 70.13it/s, train_loss=0.0523]Epoch 0:  38%|███▊      | 10/26 [00:00<00:00, 67.70it/s, train_loss=0.0504]Epoch 0:  42%|████▏     | 11/26 [00:00<00:00, 69.56it/s, train_loss=0.0504]Epoch 0:  42%|████▏     | 11/26 [00:00<00:00, 67.37it/s, train_loss=0.045] Epoch 0:  46%|████▌     | 12/26 [00:00<00:00, 69.73it/s, train_loss=0.045]Epoch 0:  46%|████▌     | 12/26 [00:00<00:00, 67.72it/s, train_loss=0.0505]Epoch 0:  50%|█████     | 13/26 [00:00<00:00, 69.23it/s, train_loss=0.0505]Epoch 0:  50%|█████     | 13/26 [00:00<00:00, 67.45it/s, train_loss=0.0471]Epoch 0:  54%|█████▍    | 14/26 [00:00<00:00, 69.47it/s, train_loss=0.0471]Epoch 0:  54%|█████▍    | 14/26 [00:00<00:00, 67.74it/s, train_loss=0.0384]Epoch 0:  58%|█████▊    | 15/26 [00:00<00:00, 69.14it/s, train_loss=0.0384]Epoch 0:  58%|█████▊    | 15/26 [00:00<00:00, 67.54it/s, train_loss=0.0421]Epoch 0:  62%|██████▏   | 16/26 [00:00<00:00, 69.31it/s, train_loss=0.0421]Epoch 0:  62%|██████▏   | 16/26 [00:00<00:00, 67.76it/s, train_loss=0.0407]Epoch 0:  65%|██████▌   | 17/26 [00:00<00:00, 68.88it/s, train_loss=0.0407]Epoch 0:  65%|██████▌   | 17/26 [00:00<00:00, 67.61it/s, train_loss=0.0356]Epoch 0:  69%|██████▉   | 18/26 [00:00<00:00, 69.19it/s, train_loss=0.0356]Epoch 0:  69%|██████▉   | 18/26 [00:00<00:00, 67.80it/s, train_loss=0.0552]Epoch 0:  73%|███████▎  | 19/26 [00:00<00:00, 68.78it/s, train_loss=0.0552]Epoch 0:  73%|███████▎  | 19/26 [00:00<00:00, 67.74it/s, train_loss=0.0413]Epoch 0:  77%|███████▋  | 20/26 [00:00<00:00, 69.13it/s, train_loss=0.0413]Epoch 0:  77%|███████▋  | 20/26 [00:00<00:00, 67.89it/s, train_loss=0.041] Epoch 0:  81%|████████  | 21/26 [00:00<00:00, 68.80it/s, train_loss=0.041]Epoch 0:  81%|████████  | 21/26 [00:00<00:00, 67.82it/s, train_loss=0.0401]Epoch 0:  85%|████████▍ | 22/26 [00:00<00:00, 69.12it/s, train_loss=0.0401]Epoch 0:  85%|████████▍ | 22/26 [00:00<00:00, 67.96it/s, train_loss=0.0453]Epoch 0:  88%|████████▊ | 23/26 [00:00<00:00, 68.74it/s, train_loss=0.0453]Epoch 0:  88%|████████▊ | 23/26 [00:00<00:00, 67.89it/s, train_loss=0.023] Epoch 0:  92%|█████████▏| 24/26 [00:00<00:00, 69.04it/s, train_loss=0.023]Epoch 0:  92%|█████████▏| 24/26 [00:00<00:00, 68.00it/s, train_loss=0.0468]Epoch 0:  96%|█████████▌| 25/26 [00:00<00:00, 68.72it/s, train_loss=0.0468]Epoch 0:  96%|█████████▌| 25/26 [00:00<00:00, 67.95it/s, train_loss=0.0387]Epoch 0: 100%|██████████| 26/26 [00:00<00:00, 69.00it/s, train_loss=0.0387]Epoch 0: 100%|██████████| 26/26 [00:00<00:00, 68.10it/s, train_loss=0.0321]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 116.25it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 136.14it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 147.76it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 148.32it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 150.39it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 153.19it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 152.07it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 155.85it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 161.24it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 165.96it/s][A
                                                                         [AEpoch 0: 100%|██████████| 26/26 [00:00<00:00, 57.65it/s, train_loss=0.0321, val_loss=0.0413]Epoch 0: 100%|██████████| 26/26 [00:00<00:00, 57.57it/s, train_loss=0.0321, val_loss=0.0413]Epoch 0:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0321, val_loss=0.0413]         Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0321, val_loss=0.0413]Epoch 1:   4%|▍         | 1/26 [00:00<00:00, 86.59it/s, train_loss=0.0321, val_loss=0.0413]Epoch 1:   4%|▍         | 1/26 [00:00<00:00, 62.48it/s, train_loss=0.0246, val_loss=0.0413]Epoch 1:   8%|▊         | 2/26 [00:00<00:00, 80.56it/s, train_loss=0.0246, val_loss=0.0413]Epoch 1:   8%|▊         | 2/26 [00:00<00:00, 66.80it/s, train_loss=0.042, val_loss=0.0413] Epoch 1:  12%|█▏        | 3/26 [00:00<00:00, 74.00it/s, train_loss=0.042, val_loss=0.0413]Epoch 1:  12%|█▏        | 3/26 [00:00<00:00, 65.98it/s, train_loss=0.0303, val_loss=0.0413]Epoch 1:  15%|█▌        | 4/26 [00:00<00:00, 73.46it/s, train_loss=0.0303, val_loss=0.0413]Epoch 1:  15%|█▌        | 4/26 [00:00<00:00, 67.10it/s, train_loss=0.0479, val_loss=0.0413]Epoch 1:  19%|█▉        | 5/26 [00:00<00:00, 71.00it/s, train_loss=0.0479, val_loss=0.0413]Epoch 1:  19%|█▉        | 5/26 [00:00<00:00, 67.01it/s, train_loss=0.0346, val_loss=0.0413]Epoch 1:  23%|██▎       | 6/26 [00:00<00:00, 71.91it/s, train_loss=0.0346, val_loss=0.0413]Epoch 1:  23%|██▎       | 6/26 [00:00<00:00, 67.57it/s, train_loss=0.0215, val_loss=0.0413]Epoch 1:  27%|██▋       | 7/26 [00:00<00:00, 70.28it/s, train_loss=0.0215, val_loss=0.0413]Epoch 1:  27%|██▋       | 7/26 [00:00<00:00, 67.44it/s, train_loss=0.0319, val_loss=0.0413]Epoch 1:  31%|███       | 8/26 [00:00<00:00, 71.03it/s, train_loss=0.0319, val_loss=0.0413]Epoch 1:  31%|███       | 8/26 [00:00<00:00, 67.83it/s, train_loss=0.0271, val_loss=0.0413]Epoch 1:  35%|███▍      | 9/26 [00:00<00:00, 69.83it/s, train_loss=0.0271, val_loss=0.0413]Epoch 1:  35%|███▍      | 9/26 [00:00<00:00, 67.71it/s, train_loss=0.0195, val_loss=0.0413]Epoch 1:  38%|███▊      | 10/26 [00:00<00:00, 70.53it/s, train_loss=0.0195, val_loss=0.0413]Epoch 1:  38%|███▊      | 10/26 [00:00<00:00, 67.97it/s, train_loss=0.0233, val_loss=0.0413]Epoch 1:  42%|████▏     | 11/26 [00:00<00:00, 68.94it/s, train_loss=0.0233, val_loss=0.0413]Epoch 1:  42%|████▏     | 11/26 [00:00<00:00, 67.71it/s, train_loss=0.0157, val_loss=0.0413]Epoch 1:  46%|████▌     | 12/26 [00:00<00:00, 69.91it/s, train_loss=0.0157, val_loss=0.0413]Epoch 1:  46%|████▌     | 12/26 [00:00<00:00, 67.91it/s, train_loss=0.0232, val_loss=0.0413]Epoch 1:  50%|█████     | 13/26 [00:00<00:00, 69.43it/s, train_loss=0.0232, val_loss=0.0413]Epoch 1:  50%|█████     | 13/26 [00:00<00:00, 67.80it/s, train_loss=0.0241, val_loss=0.0413]Epoch 1:  54%|█████▍    | 14/26 [00:00<00:00, 69.57it/s, train_loss=0.0241, val_loss=0.0413]Epoch 1:  54%|█████▍    | 14/26 [00:00<00:00, 67.17it/s, train_loss=0.0205, val_loss=0.0413]Epoch 1:  58%|█████▊    | 15/26 [00:00<00:00, 68.29it/s, train_loss=0.0205, val_loss=0.0413]Epoch 1:  58%|█████▊    | 15/26 [00:00<00:00, 67.21it/s, train_loss=0.0173, val_loss=0.0413]Epoch 1:  62%|██████▏   | 16/26 [00:00<00:00, 68.95it/s, train_loss=0.0173, val_loss=0.0413]Epoch 1:  62%|██████▏   | 16/26 [00:00<00:00, 67.43it/s, train_loss=0.0209, val_loss=0.0413]Epoch 1:  65%|██████▌   | 17/26 [00:00<00:00, 68.41it/s, train_loss=0.0209, val_loss=0.0413]Epoch 1:  65%|██████▌   | 17/26 [00:00<00:00, 67.45it/s, train_loss=0.0312, val_loss=0.0413]Epoch 1:  69%|██████▉   | 18/26 [00:00<00:00, 68.92it/s, train_loss=0.0312, val_loss=0.0413]Epoch 1:  69%|██████▉   | 18/26 [00:00<00:00, 67.59it/s, train_loss=0.0335, val_loss=0.0413]Epoch 1:  73%|███████▎  | 19/26 [00:00<00:00, 68.67it/s, train_loss=0.0335, val_loss=0.0413]Epoch 1:  73%|███████▎  | 19/26 [00:00<00:00, 67.52it/s, train_loss=0.0241, val_loss=0.0413]Epoch 1:  77%|███████▋  | 20/26 [00:00<00:00, 68.95it/s, train_loss=0.0241, val_loss=0.0413]Epoch 1:  77%|███████▋  | 20/26 [00:00<00:00, 67.69it/s, train_loss=0.0158, val_loss=0.0413]Epoch 1:  81%|████████  | 21/26 [00:00<00:00, 68.68it/s, train_loss=0.0158, val_loss=0.0413]Epoch 1:  81%|████████  | 21/26 [00:00<00:00, 67.63it/s, train_loss=0.027, val_loss=0.0413] Epoch 1:  85%|████████▍ | 22/26 [00:00<00:00, 68.93it/s, train_loss=0.027, val_loss=0.0413]Epoch 1:  85%|████████▍ | 22/26 [00:00<00:00, 67.80it/s, train_loss=0.0197, val_loss=0.0413]Epoch 1:  88%|████████▊ | 23/26 [00:00<00:00, 68.68it/s, train_loss=0.0197, val_loss=0.0413]Epoch 1:  88%|████████▊ | 23/26 [00:00<00:00, 67.63it/s, train_loss=0.0174, val_loss=0.0413]Epoch 1:  92%|█████████▏| 24/26 [00:00<00:00, 68.80it/s, train_loss=0.0174, val_loss=0.0413]Epoch 1:  92%|█████████▏| 24/26 [00:00<00:00, 67.76it/s, train_loss=0.0289, val_loss=0.0413]Epoch 1:  96%|█████████▌| 25/26 [00:00<00:00, 68.53it/s, train_loss=0.0289, val_loss=0.0413]Epoch 1:  96%|█████████▌| 25/26 [00:00<00:00, 67.69it/s, train_loss=0.0187, val_loss=0.0413]Epoch 1: 100%|██████████| 26/26 [00:00<00:00, 68.67it/s, train_loss=0.0187, val_loss=0.0413]Epoch 1: 100%|██████████| 26/26 [00:00<00:00, 67.82it/s, train_loss=0.015, val_loss=0.0413] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 117.74it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 130.65it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 137.69it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 139.79it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 141.66it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 144.93it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 145.20it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 146.10it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 146.29it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 146.91it/s][A
                                                                         [AEpoch 1: 100%|██████████| 26/26 [00:00<00:00, 56.54it/s, train_loss=0.015, val_loss=0.0273]Epoch 1: 100%|██████████| 26/26 [00:00<00:00, 56.41it/s, train_loss=0.015, val_loss=0.0273]Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.015, val_loss=0.0273]         Epoch 2:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.015, val_loss=0.0273]Epoch 2:   4%|▍         | 1/26 [00:00<00:00, 76.59it/s, train_loss=0.015, val_loss=0.0273]Epoch 2:   4%|▍         | 1/26 [00:00<00:00, 65.09it/s, train_loss=0.0256, val_loss=0.0273]Epoch 2:   8%|▊         | 2/26 [00:00<00:00, 68.38it/s, train_loss=0.0256, val_loss=0.0273]Epoch 2:   8%|▊         | 2/26 [00:00<00:00, 62.79it/s, train_loss=0.018, val_loss=0.0273] Epoch 2:  12%|█▏        | 3/26 [00:00<00:00, 71.78it/s, train_loss=0.018, val_loss=0.0273]Epoch 2:  12%|█▏        | 3/26 [00:00<00:00, 65.11it/s, train_loss=0.0249, val_loss=0.0273]Epoch 2:  15%|█▌        | 4/26 [00:00<00:00, 69.88it/s, train_loss=0.0249, val_loss=0.0273]Epoch 2:  15%|█▌        | 4/26 [00:00<00:00, 64.74it/s, train_loss=0.0225, val_loss=0.0273]Epoch 2:  19%|█▉        | 5/26 [00:00<00:00, 70.39it/s, train_loss=0.0225, val_loss=0.0273]Epoch 2:  19%|█▉        | 5/26 [00:00<00:00, 66.04it/s, train_loss=0.0232, val_loss=0.0273]Epoch 2:  23%|██▎       | 6/26 [00:00<00:00, 70.04it/s, train_loss=0.0232, val_loss=0.0273]Epoch 2:  23%|██▎       | 6/26 [00:00<00:00, 65.74it/s, train_loss=0.0183, val_loss=0.0273]Epoch 2:  27%|██▋       | 7/26 [00:00<00:00, 69.87it/s, train_loss=0.0183, val_loss=0.0273]Epoch 2:  27%|██▋       | 7/26 [00:00<00:00, 66.55it/s, train_loss=0.0148, val_loss=0.0273]Epoch 2:  31%|███       | 8/26 [00:00<00:00, 69.38it/s, train_loss=0.0148, val_loss=0.0273]Epoch 2:  31%|███       | 8/26 [00:00<00:00, 66.23it/s, train_loss=0.0185, val_loss=0.0273]Epoch 2:  35%|███▍      | 9/26 [00:00<00:00, 69.35it/s, train_loss=0.0185, val_loss=0.0273]Epoch 2:  35%|███▍      | 9/26 [00:00<00:00, 66.79it/s, train_loss=0.0227, val_loss=0.0273]Epoch 2:  38%|███▊      | 10/26 [00:00<00:00, 69.20it/s, train_loss=0.0227, val_loss=0.0273]Epoch 2:  38%|███▊      | 10/26 [00:00<00:00, 66.63it/s, train_loss=0.0292, val_loss=0.0273]Epoch 2:  42%|████▏     | 11/26 [00:00<00:00, 69.02it/s, train_loss=0.0292, val_loss=0.0273]Epoch 2:  42%|████▏     | 11/26 [00:00<00:00, 66.96it/s, train_loss=0.0172, val_loss=0.0273]Epoch 2:  46%|████▌     | 12/26 [00:00<00:00, 69.17it/s, train_loss=0.0172, val_loss=0.0273]Epoch 2:  46%|████▌     | 12/26 [00:00<00:00, 66.91it/s, train_loss=0.0167, val_loss=0.0273]Epoch 2:  50%|█████     | 13/26 [00:00<00:00, 69.03it/s, train_loss=0.0167, val_loss=0.0273]Epoch 2:  50%|█████     | 13/26 [00:00<00:00, 67.20it/s, train_loss=0.0179, val_loss=0.0273]Epoch 2:  54%|█████▍    | 14/26 [00:00<00:00, 68.96it/s, train_loss=0.0179, val_loss=0.0273]Epoch 2:  54%|█████▍    | 14/26 [00:00<00:00, 67.11it/s, train_loss=0.0276, val_loss=0.0273]Epoch 2:  58%|█████▊    | 15/26 [00:00<00:00, 68.94it/s, train_loss=0.0276, val_loss=0.0273]Epoch 2:  58%|█████▊    | 15/26 [00:00<00:00, 67.33it/s, train_loss=0.0173, val_loss=0.0273]Epoch 2:  62%|██████▏   | 16/26 [00:00<00:00, 68.90it/s, train_loss=0.0173, val_loss=0.0273]Epoch 2:  62%|██████▏   | 16/26 [00:00<00:00, 67.28it/s, train_loss=0.018, val_loss=0.0273] Epoch 2:  65%|██████▌   | 17/26 [00:00<00:00, 68.83it/s, train_loss=0.018, val_loss=0.0273]Epoch 2:  65%|██████▌   | 17/26 [00:00<00:00, 67.44it/s, train_loss=0.0139, val_loss=0.0273]Epoch 2:  69%|██████▉   | 18/26 [00:00<00:00, 68.84it/s, train_loss=0.0139, val_loss=0.0273]Epoch 2:  69%|██████▉   | 18/26 [00:00<00:00, 67.36it/s, train_loss=0.021, val_loss=0.0273] Epoch 2:  73%|███████▎  | 19/26 [00:00<00:00, 68.75it/s, train_loss=0.021, val_loss=0.0273]Epoch 2:  73%|███████▎  | 19/26 [00:00<00:00, 67.52it/s, train_loss=0.024, val_loss=0.0273]Epoch 2:  77%|███████▋  | 20/26 [00:00<00:00, 68.64it/s, train_loss=0.024, val_loss=0.0273]Epoch 2:  77%|███████▋  | 20/26 [00:00<00:00, 67.43it/s, train_loss=0.0201, val_loss=0.0273]Epoch 2:  81%|████████  | 21/26 [00:00<00:00, 68.71it/s, train_loss=0.0201, val_loss=0.0273]Epoch 2:  81%|████████  | 21/26 [00:00<00:00, 67.54it/s, train_loss=0.0164, val_loss=0.0273]Epoch 2:  85%|████████▍ | 22/26 [00:00<00:00, 68.64it/s, train_loss=0.0164, val_loss=0.0273]Epoch 2:  85%|████████▍ | 22/26 [00:00<00:00, 67.49it/s, train_loss=0.0273, val_loss=0.0273]Epoch 2:  88%|████████▊ | 23/26 [00:00<00:00, 68.62it/s, train_loss=0.0273, val_loss=0.0273]Epoch 2:  88%|████████▊ | 23/26 [00:00<00:00, 67.60it/s, train_loss=0.0254, val_loss=0.0273]Epoch 2:  92%|█████████▏| 24/26 [00:00<00:00, 68.70it/s, train_loss=0.0254, val_loss=0.0273]Epoch 2:  92%|█████████▏| 24/26 [00:00<00:00, 67.58it/s, train_loss=0.0215, val_loss=0.0273]Epoch 2:  96%|█████████▌| 25/26 [00:00<00:00, 68.72it/s, train_loss=0.0215, val_loss=0.0273]Epoch 2:  96%|█████████▌| 25/26 [00:00<00:00, 67.75it/s, train_loss=0.0272, val_loss=0.0273]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 26/26 [00:00<00:00, 68.59it/s, train_loss=0.0272, val_loss=0.0273]Epoch 2: 100%|██████████| 26/26 [00:00<00:00, 67.65it/s, train_loss=0.0187, val_loss=0.0273]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 126.05it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 151.76it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 162.98it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 166.51it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 168.97it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 171.96it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 173.84it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 173.97it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 175.47it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 177.17it/s][A
                                                                         [AEpoch 2: 100%|██████████| 26/26 [00:00<00:00, 58.00it/s, train_loss=0.0187, val_loss=0.0249]Epoch 2: 100%|██████████| 26/26 [00:00<00:00, 57.88it/s, train_loss=0.0187, val_loss=0.0249]Epoch 2:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0187, val_loss=0.0249]         Epoch 3:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0187, val_loss=0.0249]Epoch 3:   4%|▍         | 1/26 [00:00<00:00, 84.42it/s, train_loss=0.0187, val_loss=0.0249]Epoch 3:   4%|▍         | 1/26 [00:00<00:00, 66.82it/s, train_loss=0.0252, val_loss=0.0249]Epoch 3:   8%|▊         | 2/26 [00:00<00:00, 75.89it/s, train_loss=0.0252, val_loss=0.0249]Epoch 3:   8%|▊         | 2/26 [00:00<00:00, 64.05it/s, train_loss=0.0226, val_loss=0.0249]Epoch 3:  12%|█▏        | 3/26 [00:00<00:00, 70.59it/s, train_loss=0.0226, val_loss=0.0249]Epoch 3:  12%|█▏        | 3/26 [00:00<00:00, 66.02it/s, train_loss=0.0158, val_loss=0.0249]Epoch 3:  15%|█▌        | 4/26 [00:00<00:00, 69.83it/s, train_loss=0.0158, val_loss=0.0249]Epoch 3:  15%|█▌        | 4/26 [00:00<00:00, 65.60it/s, train_loss=0.0185, val_loss=0.0249]Epoch 3:  19%|█▉        | 5/26 [00:00<00:00, 69.82it/s, train_loss=0.0185, val_loss=0.0249]Epoch 3:  19%|█▉        | 5/26 [00:00<00:00, 66.50it/s, train_loss=0.0173, val_loss=0.0249]Epoch 3:  23%|██▎       | 6/26 [00:00<00:00, 69.34it/s, train_loss=0.0173, val_loss=0.0249]Epoch 3:  23%|██▎       | 6/26 [00:00<00:00, 66.46it/s, train_loss=0.0153, val_loss=0.0249]Epoch 3:  27%|██▋       | 7/26 [00:00<00:00, 69.10it/s, train_loss=0.0153, val_loss=0.0249]Epoch 3:  27%|██▋       | 7/26 [00:00<00:00, 66.92it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  31%|███       | 8/26 [00:00<00:00, 69.02it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  31%|███       | 8/26 [00:00<00:00, 66.78it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  35%|███▍      | 9/26 [00:00<00:00, 69.08it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  35%|███▍      | 9/26 [00:00<00:00, 67.35it/s, train_loss=0.0268, val_loss=0.0249]Epoch 3:  38%|███▊      | 10/26 [00:00<00:00, 68.94it/s, train_loss=0.0268, val_loss=0.0249]Epoch 3:  38%|███▊      | 10/26 [00:00<00:00, 66.89it/s, train_loss=0.0179, val_loss=0.0249]Epoch 3:  42%|████▏     | 11/26 [00:00<00:00, 68.95it/s, train_loss=0.0179, val_loss=0.0249]Epoch 3:  42%|████▏     | 11/26 [00:00<00:00, 67.32it/s, train_loss=0.0176, val_loss=0.0249]Epoch 3:  46%|████▌     | 12/26 [00:00<00:00, 68.91it/s, train_loss=0.0176, val_loss=0.0249]Epoch 3:  46%|████▌     | 12/26 [00:00<00:00, 66.99it/s, train_loss=0.0202, val_loss=0.0249]Epoch 3:  50%|█████     | 13/26 [00:00<00:00, 68.75it/s, train_loss=0.0202, val_loss=0.0249]Epoch 3:  50%|█████     | 13/26 [00:00<00:00, 67.32it/s, train_loss=0.0191, val_loss=0.0249]Epoch 3:  54%|█████▍    | 14/26 [00:00<00:00, 68.64it/s, train_loss=0.0191, val_loss=0.0249]Epoch 3:  54%|█████▍    | 14/26 [00:00<00:00, 67.05it/s, train_loss=0.0141, val_loss=0.0249]Epoch 3:  58%|█████▊    | 15/26 [00:00<00:00, 68.48it/s, train_loss=0.0141, val_loss=0.0249]Epoch 3:  58%|█████▊    | 15/26 [00:00<00:00, 67.30it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  62%|██████▏   | 16/26 [00:00<00:00, 68.45it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  62%|██████▏   | 16/26 [00:00<00:00, 67.05it/s, train_loss=0.0189, val_loss=0.0249]Epoch 3:  65%|██████▌   | 17/26 [00:00<00:00, 68.29it/s, train_loss=0.0189, val_loss=0.0249]Epoch 3:  65%|██████▌   | 17/26 [00:00<00:00, 67.25it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  69%|██████▉   | 18/26 [00:00<00:00, 68.04it/s, train_loss=0.0171, val_loss=0.0249]Epoch 3:  69%|██████▉   | 18/26 [00:00<00:00, 67.02it/s, train_loss=0.0162, val_loss=0.0249]Epoch 3:  73%|███████▎  | 19/26 [00:00<00:00, 68.08it/s, train_loss=0.0162, val_loss=0.0249]Epoch 3:  73%|███████▎  | 19/26 [00:00<00:00, 67.21it/s, train_loss=0.0121, val_loss=0.0249]Epoch 3:  77%|███████▋  | 20/26 [00:00<00:00, 68.06it/s, train_loss=0.0121, val_loss=0.0249]Epoch 3:  77%|███████▋  | 20/26 [00:00<00:00, 67.03it/s, train_loss=0.0149, val_loss=0.0249]Epoch 3:  81%|████████  | 21/26 [00:00<00:00, 68.00it/s, train_loss=0.0149, val_loss=0.0249]Epoch 3:  81%|████████  | 21/26 [00:00<00:00, 67.17it/s, train_loss=0.0168, val_loss=0.0249]Epoch 3:  85%|████████▍ | 22/26 [00:00<00:00, 67.87it/s, train_loss=0.0168, val_loss=0.0249]Epoch 3:  85%|████████▍ | 22/26 [00:00<00:00, 67.03it/s, train_loss=0.0172, val_loss=0.0249]Epoch 3:  88%|████████▊ | 23/26 [00:00<00:00, 67.86it/s, train_loss=0.0172, val_loss=0.0249]Epoch 3:  88%|████████▊ | 23/26 [00:00<00:00, 67.16it/s, train_loss=0.0109, val_loss=0.0249]Epoch 3:  92%|█████████▏| 24/26 [00:00<00:00, 67.88it/s, train_loss=0.0109, val_loss=0.0249]Epoch 3:  92%|█████████▏| 24/26 [00:00<00:00, 67.10it/s, train_loss=0.0172, val_loss=0.0249]Epoch 3:  96%|█████████▌| 25/26 [00:00<00:00, 67.93it/s, train_loss=0.0172, val_loss=0.0249]Epoch 3:  96%|█████████▌| 25/26 [00:00<00:00, 67.19it/s, train_loss=0.0172, val_loss=0.0249]Epoch 3: 100%|██████████| 26/26 [00:00<00:00, 67.81it/s, train_loss=0.0172, val_loss=0.0249]Epoch 3: 100%|██████████| 26/26 [00:00<00:00, 67.19it/s, train_loss=0.0131, val_loss=0.0249]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 166.69it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 186.26it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 194.09it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 198.94it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 201.63it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 203.43it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 202.28it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 202.13it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 202.02it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 200.99it/s][A
                                                                         [AEpoch 3: 100%|██████████| 26/26 [00:00<00:00, 58.75it/s, train_loss=0.0131, val_loss=0.0136]Epoch 3: 100%|██████████| 26/26 [00:00<00:00, 58.64it/s, train_loss=0.0131, val_loss=0.0136]Epoch 3:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0131, val_loss=0.0136]         Epoch 4:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0131, val_loss=0.0136]Epoch 4:   4%|▍         | 1/26 [00:00<00:00, 83.20it/s, train_loss=0.0131, val_loss=0.0136]Epoch 4:   4%|▍         | 1/26 [00:00<00:00, 66.57it/s, train_loss=0.0158, val_loss=0.0136]Epoch 4:   8%|▊         | 2/26 [00:00<00:00, 78.51it/s, train_loss=0.0158, val_loss=0.0136]Epoch 4:   8%|▊         | 2/26 [00:00<00:00, 63.53it/s, train_loss=0.0147, val_loss=0.0136]Epoch 4:  12%|█▏        | 3/26 [00:00<00:00, 70.94it/s, train_loss=0.0147, val_loss=0.0136]Epoch 4:  12%|█▏        | 3/26 [00:00<00:00, 65.86it/s, train_loss=0.0101, val_loss=0.0136]Epoch 4:  15%|█▌        | 4/26 [00:00<00:00, 70.49it/s, train_loss=0.0101, val_loss=0.0136]Epoch 4:  15%|█▌        | 4/26 [00:00<00:00, 64.69it/s, train_loss=0.0135, val_loss=0.0136]Epoch 4:  19%|█▉        | 5/26 [00:00<00:00, 69.03it/s, train_loss=0.0135, val_loss=0.0136]Epoch 4:  19%|█▉        | 5/26 [00:00<00:00, 65.74it/s, train_loss=0.0165, val_loss=0.0136]Epoch 4:  23%|██▎       | 6/26 [00:00<00:00, 68.59it/s, train_loss=0.0165, val_loss=0.0136]Epoch 4:  23%|██▎       | 6/26 [00:00<00:00, 65.24it/s, train_loss=0.0176, val_loss=0.0136]Epoch 4:  27%|██▋       | 7/26 [00:00<00:00, 68.28it/s, train_loss=0.0176, val_loss=0.0136]Epoch 4:  27%|██▋       | 7/26 [00:00<00:00, 65.83it/s, train_loss=0.0154, val_loss=0.0136]Epoch 4:  31%|███       | 8/26 [00:00<00:00, 68.02it/s, train_loss=0.0154, val_loss=0.0136]Epoch 4:  31%|███       | 8/26 [00:00<00:00, 65.83it/s, train_loss=0.0142, val_loss=0.0136]Epoch 4:  35%|███▍      | 9/26 [00:00<00:00, 68.14it/s, train_loss=0.0142, val_loss=0.0136]Epoch 4:  35%|███▍      | 9/26 [00:00<00:00, 66.30it/s, train_loss=0.0102, val_loss=0.0136]Epoch 4:  38%|███▊      | 10/26 [00:00<00:00, 67.99it/s, train_loss=0.0102, val_loss=0.0136]Epoch 4:  38%|███▊      | 10/26 [00:00<00:00, 66.10it/s, train_loss=0.00983, val_loss=0.0136]Epoch 4:  42%|████▏     | 11/26 [00:00<00:00, 67.96it/s, train_loss=0.00983, val_loss=0.0136]Epoch 4:  42%|████▏     | 11/26 [00:00<00:00, 66.40it/s, train_loss=0.0129, val_loss=0.0136] Epoch 4:  46%|████▌     | 12/26 [00:00<00:00, 67.85it/s, train_loss=0.0129, val_loss=0.0136]Epoch 4:  46%|████▌     | 12/26 [00:00<00:00, 66.35it/s, train_loss=0.0103, val_loss=0.0136]Epoch 4:  50%|█████     | 13/26 [00:00<00:00, 67.94it/s, train_loss=0.0103, val_loss=0.0136]Epoch 4:  50%|█████     | 13/26 [00:00<00:00, 66.57it/s, train_loss=0.0104, val_loss=0.0136]Epoch 4:  54%|█████▍    | 14/26 [00:00<00:00, 67.81it/s, train_loss=0.0104, val_loss=0.0136]Epoch 4:  54%|█████▍    | 14/26 [00:00<00:00, 66.49it/s, train_loss=0.00932, val_loss=0.0136]Epoch 4:  58%|█████▊    | 15/26 [00:00<00:00, 67.95it/s, train_loss=0.00932, val_loss=0.0136]Epoch 4:  58%|█████▊    | 15/26 [00:00<00:00, 66.83it/s, train_loss=0.0092, val_loss=0.0136] Epoch 4:  62%|██████▏   | 16/26 [00:00<00:00, 67.83it/s, train_loss=0.0092, val_loss=0.0136]Epoch 4:  62%|██████▏   | 16/26 [00:00<00:00, 66.57it/s, train_loss=0.0119, val_loss=0.0136]Epoch 4:  65%|██████▌   | 17/26 [00:00<00:00, 67.86it/s, train_loss=0.0119, val_loss=0.0136]Epoch 4:  65%|██████▌   | 17/26 [00:00<00:00, 66.85it/s, train_loss=0.0107, val_loss=0.0136]Epoch 4:  69%|██████▉   | 18/26 [00:00<00:00, 67.77it/s, train_loss=0.0107, val_loss=0.0136]Epoch 4:  69%|██████▉   | 18/26 [00:00<00:00, 66.61it/s, train_loss=0.0112, val_loss=0.0136]Epoch 4:  73%|███████▎  | 19/26 [00:00<00:00, 67.74it/s, train_loss=0.0112, val_loss=0.0136]Epoch 4:  73%|███████▎  | 19/26 [00:00<00:00, 66.82it/s, train_loss=0.0101, val_loss=0.0136]Epoch 4:  77%|███████▋  | 20/26 [00:00<00:00, 67.61it/s, train_loss=0.0101, val_loss=0.0136]Epoch 4:  77%|███████▋  | 20/26 [00:00<00:00, 66.68it/s, train_loss=0.00842, val_loss=0.0136]Epoch 4:  81%|████████  | 21/26 [00:00<00:00, 67.67it/s, train_loss=0.00842, val_loss=0.0136]Epoch 4:  81%|████████  | 21/26 [00:00<00:00, 66.86it/s, train_loss=0.00915, val_loss=0.0136]Epoch 4:  85%|████████▍ | 22/26 [00:00<00:00, 67.55it/s, train_loss=0.00915, val_loss=0.0136]Epoch 4:  85%|████████▍ | 22/26 [00:00<00:00, 66.74it/s, train_loss=0.00865, val_loss=0.0136]Epoch 4:  88%|████████▊ | 23/26 [00:00<00:00, 67.71it/s, train_loss=0.00865, val_loss=0.0136]Epoch 4:  88%|████████▊ | 23/26 [00:00<00:00, 66.92it/s, train_loss=0.00988, val_loss=0.0136]Epoch 4:  92%|█████████▏| 24/26 [00:00<00:00, 67.57it/s, train_loss=0.00988, val_loss=0.0136]Epoch 4:  92%|█████████▏| 24/26 [00:00<00:00, 66.79it/s, train_loss=0.0112, val_loss=0.0136] Epoch 4:  96%|█████████▌| 25/26 [00:00<00:00, 67.63it/s, train_loss=0.0112, val_loss=0.0136]Epoch 4:  96%|█████████▌| 25/26 [00:00<00:00, 66.92it/s, train_loss=0.00864, val_loss=0.0136]Epoch 4: 100%|██████████| 26/26 [00:00<00:00, 67.39it/s, train_loss=0.00864, val_loss=0.0136]Epoch 4: 100%|██████████| 26/26 [00:00<00:00, 66.83it/s, train_loss=0.0118, val_loss=0.0136] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 110.73it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 124.46it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 134.56it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 142.38it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 142.55it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 146.85it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 150.62it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 151.85it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 151.21it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 153.48it/s][A
                                                                         [AEpoch 4: 100%|██████████| 26/26 [00:00<00:00, 56.10it/s, train_loss=0.0118, val_loss=0.00851]Epoch 4: 100%|██████████| 26/26 [00:00<00:00, 56.03it/s, train_loss=0.0118, val_loss=0.00851]Epoch 4:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0118, val_loss=0.00851]         Epoch 5:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0118, val_loss=0.00851]Epoch 5:   4%|▍         | 1/26 [00:00<00:00, 91.56it/s, train_loss=0.0118, val_loss=0.00851]Epoch 5:   4%|▍         | 1/26 [00:00<00:00, 58.97it/s, train_loss=0.00945, val_loss=0.00851]Epoch 5:   8%|▊         | 2/26 [00:00<00:00, 71.33it/s, train_loss=0.00945, val_loss=0.00851]Epoch 5:   8%|▊         | 2/26 [00:00<00:00, 64.25it/s, train_loss=0.0101, val_loss=0.00851] Epoch 5:  12%|█▏        | 3/26 [00:00<00:00, 71.87it/s, train_loss=0.0101, val_loss=0.00851]Epoch 5:  12%|█▏        | 3/26 [00:00<00:00, 64.72it/s, train_loss=0.00769, val_loss=0.00851]Epoch 5:  15%|█▌        | 4/26 [00:00<00:00, 70.20it/s, train_loss=0.00769, val_loss=0.00851]Epoch 5:  15%|█▌        | 4/26 [00:00<00:00, 66.23it/s, train_loss=0.00771, val_loss=0.00851]Epoch 5:  19%|█▉        | 5/26 [00:00<00:00, 70.17it/s, train_loss=0.00771, val_loss=0.00851]Epoch 5:  19%|█▉        | 5/26 [00:00<00:00, 66.13it/s, train_loss=0.0114, val_loss=0.00851] Epoch 5:  23%|██▎       | 6/26 [00:00<00:00, 69.65it/s, train_loss=0.0114, val_loss=0.00851]Epoch 5:  23%|██▎       | 6/26 [00:00<00:00, 66.90it/s, train_loss=0.0079, val_loss=0.00851]Epoch 5:  27%|██▋       | 7/26 [00:00<00:00, 69.50it/s, train_loss=0.0079, val_loss=0.00851]Epoch 5:  27%|██▋       | 7/26 [00:00<00:00, 67.19it/s, train_loss=0.00894, val_loss=0.00851]Epoch 5:  31%|███       | 8/26 [00:00<00:00, 69.41it/s, train_loss=0.00894, val_loss=0.00851]Epoch 5:  31%|███       | 8/26 [00:00<00:00, 67.62it/s, train_loss=0.00561, val_loss=0.00851]Epoch 5:  35%|███▍      | 9/26 [00:00<00:00, 68.56it/s, train_loss=0.00561, val_loss=0.00851]Epoch 5:  35%|███▍      | 9/26 [00:00<00:00, 67.25it/s, train_loss=0.0075, val_loss=0.00851] Epoch 5:  38%|███▊      | 10/26 [00:00<00:00, 69.31it/s, train_loss=0.0075, val_loss=0.00851]Epoch 5:  38%|███▊      | 10/26 [00:00<00:00, 67.01it/s, train_loss=0.0067, val_loss=0.00851]Epoch 5:  42%|████▏     | 11/26 [00:00<00:00, 68.68it/s, train_loss=0.0067, val_loss=0.00851]Epoch 5:  42%|████▏     | 11/26 [00:00<00:00, 67.26it/s, train_loss=0.0071, val_loss=0.00851]Epoch 5:  46%|████▌     | 12/26 [00:00<00:00, 68.71it/s, train_loss=0.0071, val_loss=0.00851]Epoch 5:  46%|████▌     | 12/26 [00:00<00:00, 67.22it/s, train_loss=0.0105, val_loss=0.00851]Epoch 5:  50%|█████     | 13/26 [00:00<00:00, 68.80it/s, train_loss=0.0105, val_loss=0.00851]Epoch 5:  50%|█████     | 13/26 [00:00<00:00, 67.42it/s, train_loss=0.00555, val_loss=0.00851]Epoch 5:  54%|█████▍    | 14/26 [00:00<00:00, 68.67it/s, train_loss=0.00555, val_loss=0.00851]Epoch 5:  54%|█████▍    | 14/26 [00:00<00:00, 67.63it/s, train_loss=0.00769, val_loss=0.00851]Epoch 5:  58%|█████▊    | 15/26 [00:00<00:00, 68.95it/s, train_loss=0.00769, val_loss=0.00851]Epoch 5:  58%|█████▊    | 15/26 [00:00<00:00, 67.77it/s, train_loss=0.0079, val_loss=0.00851] Epoch 5:  62%|██████▏   | 16/26 [00:00<00:00, 68.76it/s, train_loss=0.0079, val_loss=0.00851]Epoch 5:  62%|██████▏   | 16/26 [00:00<00:00, 67.91it/s, train_loss=0.00747, val_loss=0.00851]Epoch 5:  65%|██████▌   | 17/26 [00:00<00:00, 69.12it/s, train_loss=0.00747, val_loss=0.00851]Epoch 5:  65%|██████▌   | 17/26 [00:00<00:00, 68.01it/s, train_loss=0.00768, val_loss=0.00851]Epoch 5:  69%|██████▉   | 18/26 [00:00<00:00, 68.99it/s, train_loss=0.00768, val_loss=0.00851]Epoch 5:  69%|██████▉   | 18/26 [00:00<00:00, 68.13it/s, train_loss=0.00718, val_loss=0.00851]Epoch 5:  73%|███████▎  | 19/26 [00:00<00:00, 69.16it/s, train_loss=0.00718, val_loss=0.00851]Epoch 5:  73%|███████▎  | 19/26 [00:00<00:00, 68.18it/s, train_loss=0.00711, val_loss=0.00851]Epoch 5:  77%|███████▋  | 20/26 [00:00<00:00, 69.08it/s, train_loss=0.00711, val_loss=0.00851]Epoch 5:  77%|███████▋  | 20/26 [00:00<00:00, 68.34it/s, train_loss=0.00916, val_loss=0.00851]Epoch 5:  81%|████████  | 21/26 [00:00<00:00, 69.32it/s, train_loss=0.00916, val_loss=0.00851]Epoch 5:  81%|████████  | 21/26 [00:00<00:00, 68.49it/s, train_loss=0.00647, val_loss=0.00851]Epoch 5:  85%|████████▍ | 22/26 [00:00<00:00, 69.27it/s, train_loss=0.00647, val_loss=0.00851]Epoch 5:  85%|████████▍ | 22/26 [00:00<00:00, 68.49it/s, train_loss=0.00734, val_loss=0.00851]Epoch 5:  88%|████████▊ | 23/26 [00:00<00:00, 69.38it/s, train_loss=0.00734, val_loss=0.00851]Epoch 5:  88%|████████▊ | 23/26 [00:00<00:00, 68.59it/s, train_loss=0.00725, val_loss=0.00851]Epoch 5:  92%|█████████▏| 24/26 [00:00<00:00, 69.15it/s, train_loss=0.00725, val_loss=0.00851]Epoch 5:  92%|█████████▏| 24/26 [00:00<00:00, 68.57it/s, train_loss=0.00718, val_loss=0.00851]Epoch 5:  96%|█████████▌| 25/26 [00:00<00:00, 69.35it/s, train_loss=0.00718, val_loss=0.00851]Epoch 5:  96%|█████████▌| 25/26 [00:00<00:00, 68.65it/s, train_loss=0.00729, val_loss=0.00851]Epoch 5: 100%|██████████| 26/26 [00:00<00:00, 69.29it/s, train_loss=0.00729, val_loss=0.00851]Epoch 5: 100%|██████████| 26/26 [00:00<00:00, 68.75it/s, train_loss=0.00656, val_loss=0.00851]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 119.72it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 144.55it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 157.09it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 163.63it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 168.13it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 169.74it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 171.89it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 172.90it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 173.29it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 174.76it/s][A
                                                                         [AEpoch 5: 100%|██████████| 26/26 [00:00<00:00, 58.67it/s, train_loss=0.00656, val_loss=0.00781]Epoch 5: 100%|██████████| 26/26 [00:00<00:00, 58.54it/s, train_loss=0.00656, val_loss=0.00781]Epoch 5:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00656, val_loss=0.00781]         Epoch 6:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00656, val_loss=0.00781]Epoch 6:   4%|▍         | 1/26 [00:00<00:00, 81.66it/s, train_loss=0.00656, val_loss=0.00781]Epoch 6:   4%|▍         | 1/26 [00:00<00:00, 64.32it/s, train_loss=0.00732, val_loss=0.00781]Epoch 6:   8%|▊         | 2/26 [00:00<00:00, 74.38it/s, train_loss=0.00732, val_loss=0.00781]Epoch 6:   8%|▊         | 2/26 [00:00<00:00, 66.13it/s, train_loss=0.00673, val_loss=0.00781]Epoch 6:  12%|█▏        | 3/26 [00:00<00:00, 73.15it/s, train_loss=0.00673, val_loss=0.00781]Epoch 6:  12%|█▏        | 3/26 [00:00<00:00, 67.19it/s, train_loss=0.00619, val_loss=0.00781]Epoch 6:  15%|█▌        | 4/26 [00:00<00:00, 71.61it/s, train_loss=0.00619, val_loss=0.00781]Epoch 6:  15%|█▌        | 4/26 [00:00<00:00, 67.74it/s, train_loss=0.00818, val_loss=0.00781]Epoch 6:  19%|█▉        | 5/26 [00:00<00:00, 71.66it/s, train_loss=0.00818, val_loss=0.00781]Epoch 6:  19%|█▉        | 5/26 [00:00<00:00, 68.05it/s, train_loss=0.00604, val_loss=0.00781]Epoch 6:  23%|██▎       | 6/26 [00:00<00:00, 71.23it/s, train_loss=0.00604, val_loss=0.00781]Epoch 6:  23%|██▎       | 6/26 [00:00<00:00, 68.58it/s, train_loss=0.00634, val_loss=0.00781]Epoch 6:  27%|██▋       | 7/26 [00:00<00:00, 71.56it/s, train_loss=0.00634, val_loss=0.00781]Epoch 6:  27%|██▋       | 7/26 [00:00<00:00, 68.95it/s, train_loss=0.00649, val_loss=0.00781]Epoch 6:  31%|███       | 8/26 [00:00<00:00, 71.06it/s, train_loss=0.00649, val_loss=0.00781]Epoch 6:  31%|███       | 8/26 [00:00<00:00, 68.87it/s, train_loss=0.00581, val_loss=0.00781]Epoch 6:  35%|███▍      | 9/26 [00:00<00:00, 71.20it/s, train_loss=0.00581, val_loss=0.00781]Epoch 6:  35%|███▍      | 9/26 [00:00<00:00, 69.16it/s, train_loss=0.00597, val_loss=0.00781]Epoch 6:  38%|███▊      | 10/26 [00:00<00:00, 70.69it/s, train_loss=0.00597, val_loss=0.00781]Epoch 6:  38%|███▊      | 10/26 [00:00<00:00, 69.07it/s, train_loss=0.00676, val_loss=0.00781]Epoch 6:  42%|████▏     | 11/26 [00:00<00:00, 70.84it/s, train_loss=0.00676, val_loss=0.00781]Epoch 6:  42%|████▏     | 11/26 [00:00<00:00, 69.24it/s, train_loss=0.00552, val_loss=0.00781]Epoch 6:  46%|████▌     | 12/26 [00:00<00:00, 70.67it/s, train_loss=0.00552, val_loss=0.00781]Epoch 6:  46%|████▌     | 12/26 [00:00<00:00, 69.17it/s, train_loss=0.00708, val_loss=0.00781]Epoch 6:  50%|█████     | 13/26 [00:00<00:00, 70.67it/s, train_loss=0.00708, val_loss=0.00781]Epoch 6:  50%|█████     | 13/26 [00:00<00:00, 69.23it/s, train_loss=0.0071, val_loss=0.00781] Epoch 6:  54%|█████▍    | 14/26 [00:00<00:00, 70.35it/s, train_loss=0.0071, val_loss=0.00781]Epoch 6:  54%|█████▍    | 14/26 [00:00<00:00, 69.23it/s, train_loss=0.0061, val_loss=0.00781]Epoch 6:  58%|█████▊    | 15/26 [00:00<00:00, 70.55it/s, train_loss=0.0061, val_loss=0.00781]Epoch 6:  58%|█████▊    | 15/26 [00:00<00:00, 69.27it/s, train_loss=0.00606, val_loss=0.00781]Epoch 6:  62%|██████▏   | 16/26 [00:00<00:00, 70.42it/s, train_loss=0.00606, val_loss=0.00781]Epoch 6:  62%|██████▏   | 16/26 [00:00<00:00, 69.37it/s, train_loss=0.00638, val_loss=0.00781]Epoch 6:  65%|██████▌   | 17/26 [00:00<00:00, 70.57it/s, train_loss=0.00638, val_loss=0.00781]Epoch 6:  65%|██████▌   | 17/26 [00:00<00:00, 69.43it/s, train_loss=0.00578, val_loss=0.00781]Epoch 6:  69%|██████▉   | 18/26 [00:00<00:00, 70.36it/s, train_loss=0.00578, val_loss=0.00781]Epoch 6:  69%|██████▉   | 18/26 [00:00<00:00, 69.46it/s, train_loss=0.00679, val_loss=0.00781]Epoch 6:  73%|███████▎  | 19/26 [00:00<00:00, 70.52it/s, train_loss=0.00679, val_loss=0.00781]Epoch 6:  73%|███████▎  | 19/26 [00:00<00:00, 69.49it/s, train_loss=0.00609, val_loss=0.00781]Epoch 6:  77%|███████▋  | 20/26 [00:00<00:00, 70.32it/s, train_loss=0.00609, val_loss=0.00781]Epoch 6:  77%|███████▋  | 20/26 [00:00<00:00, 69.53it/s, train_loss=0.00641, val_loss=0.00781]Epoch 6:  81%|████████  | 21/26 [00:00<00:00, 70.46it/s, train_loss=0.00641, val_loss=0.00781]Epoch 6:  81%|████████  | 21/26 [00:00<00:00, 69.52it/s, train_loss=0.0058, val_loss=0.00781] Epoch 6:  85%|████████▍ | 22/26 [00:00<00:00, 70.28it/s, train_loss=0.0058, val_loss=0.00781]Epoch 6:  85%|████████▍ | 22/26 [00:00<00:00, 69.52it/s, train_loss=0.0072, val_loss=0.00781]Epoch 6:  88%|████████▊ | 23/26 [00:00<00:00, 70.37it/s, train_loss=0.0072, val_loss=0.00781]Epoch 6:  88%|████████▊ | 23/26 [00:00<00:00, 69.54it/s, train_loss=0.0058, val_loss=0.00781]Epoch 6:  92%|█████████▏| 24/26 [00:00<00:00, 70.22it/s, train_loss=0.0058, val_loss=0.00781]Epoch 6:  92%|█████████▏| 24/26 [00:00<00:00, 69.54it/s, train_loss=0.00592, val_loss=0.00781]Epoch 6:  96%|█████████▌| 25/26 [00:00<00:00, 70.38it/s, train_loss=0.00592, val_loss=0.00781]Epoch 6:  96%|█████████▌| 25/26 [00:00<00:00, 69.63it/s, train_loss=0.00622, val_loss=0.00781]Epoch 6: 100%|██████████| 26/26 [00:00<00:00, 70.29it/s, train_loss=0.00622, val_loss=0.00781]Epoch 6: 100%|██████████| 26/26 [00:00<00:00, 69.62it/s, train_loss=0.00501, val_loss=0.00781]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 161.09it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 183.14it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 191.76it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 194.01it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 194.74it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 194.81it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 195.65it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 196.97it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 197.33it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 198.14it/s][A
                                                                         [AEpoch 6: 100%|██████████| 26/26 [00:00<00:00, 60.26it/s, train_loss=0.00501, val_loss=0.00668]Epoch 6: 100%|██████████| 26/26 [00:00<00:00, 60.13it/s, train_loss=0.00501, val_loss=0.00668]Epoch 6:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00501, val_loss=0.00668]         Epoch 7:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00501, val_loss=0.00668]Epoch 7:   4%|▍         | 1/26 [00:00<00:00, 82.60it/s, train_loss=0.00501, val_loss=0.00668]Epoch 7:   4%|▍         | 1/26 [00:00<00:00, 64.73it/s, train_loss=0.00682, val_loss=0.00668]Epoch 7:   8%|▊         | 2/26 [00:00<00:00, 76.57it/s, train_loss=0.00682, val_loss=0.00668]Epoch 7:   8%|▊         | 2/26 [00:00<00:00, 67.20it/s, train_loss=0.0056, val_loss=0.00668] Epoch 7:  12%|█▏        | 3/26 [00:00<00:00, 70.34it/s, train_loss=0.0056, val_loss=0.00668]Epoch 7:  12%|█▏        | 3/26 [00:00<00:00, 67.33it/s, train_loss=0.00478, val_loss=0.00668]Epoch 7:  15%|█▌        | 4/26 [00:00<00:00, 72.46it/s, train_loss=0.00478, val_loss=0.00668]Epoch 7:  15%|█▌        | 4/26 [00:00<00:00, 67.77it/s, train_loss=0.00548, val_loss=0.00668]Epoch 7:  19%|█▉        | 5/26 [00:00<00:00, 70.73it/s, train_loss=0.00548, val_loss=0.00668]Epoch 7:  19%|█▉        | 5/26 [00:00<00:00, 68.30it/s, train_loss=0.00482, val_loss=0.00668]Epoch 7:  23%|██▎       | 6/26 [00:00<00:00, 71.70it/s, train_loss=0.00482, val_loss=0.00668]Epoch 7:  23%|██▎       | 6/26 [00:00<00:00, 68.50it/s, train_loss=0.00661, val_loss=0.00668]Epoch 7:  27%|██▋       | 7/26 [00:00<00:00, 70.46it/s, train_loss=0.00661, val_loss=0.00668]Epoch 7:  27%|██▋       | 7/26 [00:00<00:00, 68.68it/s, train_loss=0.0061, val_loss=0.00668] Epoch 7:  31%|███       | 8/26 [00:00<00:00, 71.26it/s, train_loss=0.0061, val_loss=0.00668]Epoch 7:  31%|███       | 8/26 [00:00<00:00, 68.82it/s, train_loss=0.00546, val_loss=0.00668]Epoch 7:  35%|███▍      | 9/26 [00:00<00:00, 70.23it/s, train_loss=0.00546, val_loss=0.00668]Epoch 7:  35%|███▍      | 9/26 [00:00<00:00, 68.91it/s, train_loss=0.00491, val_loss=0.00668]Epoch 7:  38%|███▊      | 10/26 [00:00<00:00, 71.03it/s, train_loss=0.00491, val_loss=0.00668]Epoch 7:  38%|███▊      | 10/26 [00:00<00:00, 68.96it/s, train_loss=0.00612, val_loss=0.00668]Epoch 7:  42%|████▏     | 11/26 [00:00<00:00, 70.03it/s, train_loss=0.00612, val_loss=0.00668]Epoch 7:  42%|████▏     | 11/26 [00:00<00:00, 68.85it/s, train_loss=0.00681, val_loss=0.00668]Epoch 7:  46%|████▌     | 12/26 [00:00<00:00, 70.72it/s, train_loss=0.00681, val_loss=0.00668]Epoch 7:  46%|████▌     | 12/26 [00:00<00:00, 69.08it/s, train_loss=0.00511, val_loss=0.00668]Epoch 7:  50%|█████     | 13/26 [00:00<00:00, 70.24it/s, train_loss=0.00511, val_loss=0.00668]Epoch 7:  50%|█████     | 13/26 [00:00<00:00, 69.05it/s, train_loss=0.00598, val_loss=0.00668]Epoch 7:  54%|█████▍    | 14/26 [00:00<00:00, 70.55it/s, train_loss=0.00598, val_loss=0.00668]Epoch 7:  54%|█████▍    | 14/26 [00:00<00:00, 69.16it/s, train_loss=0.00487, val_loss=0.00668]Epoch 7:  58%|█████▊    | 15/26 [00:00<00:00, 70.53it/s, train_loss=0.00487, val_loss=0.00668]Epoch 7:  58%|█████▊    | 15/26 [00:00<00:00, 69.18it/s, train_loss=0.00454, val_loss=0.00668]Epoch 7:  62%|██████▏   | 16/26 [00:00<00:00, 71.01it/s, train_loss=0.00454, val_loss=0.00668]Epoch 7:  62%|██████▏   | 16/26 [00:00<00:00, 69.30it/s, train_loss=0.00473, val_loss=0.00668]Epoch 7:  65%|██████▌   | 17/26 [00:00<00:00, 70.60it/s, train_loss=0.00473, val_loss=0.00668]Epoch 7:  65%|██████▌   | 17/26 [00:00<00:00, 69.27it/s, train_loss=0.00732, val_loss=0.00668]Epoch 7:  69%|██████▉   | 18/26 [00:00<00:00, 70.83it/s, train_loss=0.00732, val_loss=0.00668]Epoch 7:  69%|██████▉   | 18/26 [00:00<00:00, 69.32it/s, train_loss=0.00452, val_loss=0.00668]Epoch 7:  73%|███████▎  | 19/26 [00:00<00:00, 70.41it/s, train_loss=0.00452, val_loss=0.00668]Epoch 7:  73%|███████▎  | 19/26 [00:00<00:00, 69.36it/s, train_loss=0.00582, val_loss=0.00668]Epoch 7:  77%|███████▋  | 20/26 [00:00<00:00, 70.78it/s, train_loss=0.00582, val_loss=0.00668]Epoch 7:  77%|███████▋  | 20/26 [00:00<00:00, 69.41it/s, train_loss=0.00505, val_loss=0.00668]Epoch 7:  81%|████████  | 21/26 [00:00<00:00, 70.38it/s, train_loss=0.00505, val_loss=0.00668]Epoch 7:  81%|████████  | 21/26 [00:00<00:00, 69.45it/s, train_loss=0.00574, val_loss=0.00668]Epoch 7:  85%|████████▍ | 22/26 [00:00<00:00, 70.62it/s, train_loss=0.00574, val_loss=0.00668]Epoch 7:  85%|████████▍ | 22/26 [00:00<00:00, 69.43it/s, train_loss=0.00551, val_loss=0.00668]Epoch 7:  88%|████████▊ | 23/26 [00:00<00:00, 70.15it/s, train_loss=0.00551, val_loss=0.00668]Epoch 7:  88%|████████▊ | 23/26 [00:00<00:00, 69.35it/s, train_loss=0.00549, val_loss=0.00668]Epoch 7:  92%|█████████▏| 24/26 [00:00<00:00, 69.90it/s, train_loss=0.00549, val_loss=0.00668]Epoch 7:  92%|█████████▏| 24/26 [00:00<00:00, 69.15it/s, train_loss=0.00514, val_loss=0.00668]Epoch 7:  96%|█████████▌| 25/26 [00:00<00:00, 69.96it/s, train_loss=0.00514, val_loss=0.00668]Epoch 7:  96%|█████████▌| 25/26 [00:00<00:00, 69.10it/s, train_loss=0.00533, val_loss=0.00668]Epoch 7: 100%|██████████| 26/26 [00:00<00:00, 69.87it/s, train_loss=0.00533, val_loss=0.00668]Epoch 7: 100%|██████████| 26/26 [00:00<00:00, 69.07it/s, train_loss=0.00521, val_loss=0.00668]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 115.22it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 134.19it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 140.60it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 140.92it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 147.03it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 153.59it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 158.62it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 163.88it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 168.05it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 171.78it/s][A
                                                                         [AEpoch 7: 100%|██████████| 26/26 [00:00<00:00, 58.86it/s, train_loss=0.00521, val_loss=0.00585]Epoch 7: 100%|██████████| 26/26 [00:00<00:00, 58.76it/s, train_loss=0.00521, val_loss=0.00585]Epoch 7:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00521, val_loss=0.00585]         Epoch 8:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00521, val_loss=0.00585]Epoch 8:   4%|▍         | 1/26 [00:00<00:00, 84.59it/s, train_loss=0.00521, val_loss=0.00585]Epoch 8:   4%|▍         | 1/26 [00:00<00:00, 67.27it/s, train_loss=0.00456, val_loss=0.00585]Epoch 8:   8%|▊         | 2/26 [00:00<00:00, 77.92it/s, train_loss=0.00456, val_loss=0.00585]Epoch 8:   8%|▊         | 2/26 [00:00<00:00, 66.37it/s, train_loss=0.00541, val_loss=0.00585]Epoch 8:  12%|█▏        | 3/26 [00:00<00:00, 73.09it/s, train_loss=0.00541, val_loss=0.00585]Epoch 8:  12%|█▏        | 3/26 [00:00<00:00, 67.69it/s, train_loss=0.00539, val_loss=0.00585]Epoch 8:  15%|█▌        | 4/26 [00:00<00:00, 72.36it/s, train_loss=0.00539, val_loss=0.00585]Epoch 8:  15%|█▌        | 4/26 [00:00<00:00, 66.98it/s, train_loss=0.00403, val_loss=0.00585]Epoch 8:  19%|█▉        | 5/26 [00:00<00:00, 71.53it/s, train_loss=0.00403, val_loss=0.00585]Epoch 8:  19%|█▉        | 5/26 [00:00<00:00, 67.69it/s, train_loss=0.00483, val_loss=0.00585]Epoch 8:  23%|██▎       | 6/26 [00:00<00:00, 71.62it/s, train_loss=0.00483, val_loss=0.00585]Epoch 8:  23%|██▎       | 6/26 [00:00<00:00, 67.83it/s, train_loss=0.00543, val_loss=0.00585]Epoch 8:  27%|██▋       | 7/26 [00:00<00:00, 71.59it/s, train_loss=0.00543, val_loss=0.00585]Epoch 8:  27%|██▋       | 7/26 [00:00<00:00, 67.96it/s, train_loss=0.00574, val_loss=0.00585]Epoch 8:  31%|███       | 8/26 [00:00<00:00, 70.07it/s, train_loss=0.00574, val_loss=0.00585]Epoch 8:  31%|███       | 8/26 [00:00<00:00, 68.13it/s, train_loss=0.0048, val_loss=0.00585] Epoch 8:  35%|███▍      | 9/26 [00:00<00:00, 71.27it/s, train_loss=0.0048, val_loss=0.00585]Epoch 8:  35%|███▍      | 9/26 [00:00<00:00, 68.32it/s, train_loss=0.00604, val_loss=0.00585]Epoch 8:  38%|███▊      | 10/26 [00:00<00:00, 70.11it/s, train_loss=0.00604, val_loss=0.00585]Epoch 8:  38%|███▊      | 10/26 [00:00<00:00, 68.53it/s, train_loss=0.00527, val_loss=0.00585]Epoch 8:  42%|████▏     | 11/26 [00:00<00:00, 71.11it/s, train_loss=0.00527, val_loss=0.00585]Epoch 8:  42%|████▏     | 11/26 [00:00<00:00, 68.60it/s, train_loss=0.00482, val_loss=0.00585]Epoch 8:  46%|████▌     | 12/26 [00:00<00:00, 69.64it/s, train_loss=0.00482, val_loss=0.00585]Epoch 8:  46%|████▌     | 12/26 [00:00<00:00, 68.12it/s, train_loss=0.00557, val_loss=0.00585]Epoch 8:  50%|█████     | 13/26 [00:00<00:00, 70.07it/s, train_loss=0.00557, val_loss=0.00585]Epoch 8:  50%|█████     | 13/26 [00:00<00:00, 67.62it/s, train_loss=0.00487, val_loss=0.00585]Epoch 8:  54%|█████▍    | 14/26 [00:00<00:00, 69.28it/s, train_loss=0.00487, val_loss=0.00585]Epoch 8:  54%|█████▍    | 14/26 [00:00<00:00, 67.72it/s, train_loss=0.00528, val_loss=0.00585]Epoch 8:  58%|█████▊    | 15/26 [00:00<00:00, 68.90it/s, train_loss=0.00528, val_loss=0.00585]Epoch 8:  58%|█████▊    | 15/26 [00:00<00:00, 67.85it/s, train_loss=0.00514, val_loss=0.00585]Epoch 8:  62%|██████▏   | 16/26 [00:00<00:00, 69.56it/s, train_loss=0.00514, val_loss=0.00585]Epoch 8:  62%|██████▏   | 16/26 [00:00<00:00, 67.92it/s, train_loss=0.00495, val_loss=0.00585]Epoch 8:  65%|██████▌   | 17/26 [00:00<00:00, 69.09it/s, train_loss=0.00495, val_loss=0.00585]Epoch 8:  65%|██████▌   | 17/26 [00:00<00:00, 68.17it/s, train_loss=0.00543, val_loss=0.00585]Epoch 8:  69%|██████▉   | 18/26 [00:00<00:00, 69.80it/s, train_loss=0.00543, val_loss=0.00585]Epoch 8:  69%|██████▉   | 18/26 [00:00<00:00, 68.34it/s, train_loss=0.0039, val_loss=0.00585] Epoch 8:  73%|███████▎  | 19/26 [00:00<00:00, 69.37it/s, train_loss=0.0039, val_loss=0.00585]Epoch 8:  73%|███████▎  | 19/26 [00:00<00:00, 68.37it/s, train_loss=0.00515, val_loss=0.00585]Epoch 8:  77%|███████▋  | 20/26 [00:00<00:00, 69.81it/s, train_loss=0.00515, val_loss=0.00585]Epoch 8:  77%|███████▋  | 20/26 [00:00<00:00, 68.48it/s, train_loss=0.00527, val_loss=0.00585]Epoch 8:  81%|████████  | 21/26 [00:00<00:00, 69.41it/s, train_loss=0.00527, val_loss=0.00585]Epoch 8:  81%|████████  | 21/26 [00:00<00:00, 68.51it/s, train_loss=0.00418, val_loss=0.00585]Epoch 8:  85%|████████▍ | 22/26 [00:00<00:00, 69.77it/s, train_loss=0.00418, val_loss=0.00585]Epoch 8:  85%|████████▍ | 22/26 [00:00<00:00, 68.57it/s, train_loss=0.00498, val_loss=0.00585]Epoch 8:  88%|████████▊ | 23/26 [00:00<00:00, 69.22it/s, train_loss=0.00498, val_loss=0.00585]Epoch 8:  88%|████████▊ | 23/26 [00:00<00:00, 68.56it/s, train_loss=0.00447, val_loss=0.00585]Epoch 8:  92%|█████████▏| 24/26 [00:00<00:00, 69.69it/s, train_loss=0.00447, val_loss=0.00585]Epoch 8:  92%|█████████▏| 24/26 [00:00<00:00, 68.59it/s, train_loss=0.0054, val_loss=0.00585] Epoch 8:  96%|█████████▌| 25/26 [00:00<00:00, 69.25it/s, train_loss=0.0054, val_loss=0.00585]Epoch 8:  96%|█████████▌| 25/26 [00:00<00:00, 68.64it/s, train_loss=0.00497, val_loss=0.00585]Epoch 8: 100%|██████████| 26/26 [00:00<00:00, 69.70it/s, train_loss=0.00497, val_loss=0.00585]Epoch 8: 100%|██████████| 26/26 [00:00<00:00, 68.74it/s, train_loss=0.00464, val_loss=0.00585]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 122.48it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 141.54it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 149.13it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 153.48it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 158.07it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 157.07it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 158.30it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 158.95it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 159.59it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 161.62it/s][A
                                                                         [AEpoch 8: 100%|██████████| 26/26 [00:00<00:00, 57.98it/s, train_loss=0.00464, val_loss=0.00527]Epoch 8: 100%|██████████| 26/26 [00:00<00:00, 57.85it/s, train_loss=0.00464, val_loss=0.00527]Epoch 8:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00464, val_loss=0.00527]         Epoch 9:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00464, val_loss=0.00527]Epoch 9:   4%|▍         | 1/26 [00:00<00:00, 81.80it/s, train_loss=0.00464, val_loss=0.00527]Epoch 9:   4%|▍         | 1/26 [00:00<00:00, 64.95it/s, train_loss=0.00398, val_loss=0.00527]Epoch 9:   8%|▊         | 2/26 [00:00<00:00, 82.81it/s, train_loss=0.00398, val_loss=0.00527]Epoch 9:   8%|▊         | 2/26 [00:00<00:00, 67.99it/s, train_loss=0.00486, val_loss=0.00527]Epoch 9:  12%|█▏        | 3/26 [00:00<00:00, 75.25it/s, train_loss=0.00486, val_loss=0.00527]Epoch 9:  12%|█▏        | 3/26 [00:00<00:00, 68.32it/s, train_loss=0.00453, val_loss=0.00527]Epoch 9:  15%|█▌        | 4/26 [00:00<00:00, 75.61it/s, train_loss=0.00453, val_loss=0.00527]Epoch 9:  15%|█▌        | 4/26 [00:00<00:00, 68.90it/s, train_loss=0.00501, val_loss=0.00527]Epoch 9:  19%|█▉        | 5/26 [00:00<00:00, 72.69it/s, train_loss=0.00501, val_loss=0.00527]Epoch 9:  19%|█▉        | 5/26 [00:00<00:00, 68.98it/s, train_loss=0.00476, val_loss=0.00527]Epoch 9:  23%|██▎       | 6/26 [00:00<00:00, 73.50it/s, train_loss=0.00476, val_loss=0.00527]Epoch 9:  23%|██▎       | 6/26 [00:00<00:00, 69.12it/s, train_loss=0.00515, val_loss=0.00527]Epoch 9:  27%|██▋       | 7/26 [00:00<00:00, 71.53it/s, train_loss=0.00515, val_loss=0.00527]Epoch 9:  27%|██▋       | 7/26 [00:00<00:00, 69.24it/s, train_loss=0.0044, val_loss=0.00527] Epoch 9:  31%|███       | 8/26 [00:00<00:00, 72.45it/s, train_loss=0.0044, val_loss=0.00527]Epoch 9:  31%|███       | 8/26 [00:00<00:00, 69.08it/s, train_loss=0.00455, val_loss=0.00527]Epoch 9:  35%|███▍      | 9/26 [00:00<00:00, 71.17it/s, train_loss=0.00455, val_loss=0.00527]Epoch 9:  35%|███▍      | 9/26 [00:00<00:00, 69.34it/s, train_loss=0.00585, val_loss=0.00527]Epoch 9:  38%|███▊      | 10/26 [00:00<00:00, 72.12it/s, train_loss=0.00585, val_loss=0.00527]Epoch 9:  38%|███▊      | 10/26 [00:00<00:00, 69.41it/s, train_loss=0.00423, val_loss=0.00527]Epoch 9:  42%|████▏     | 11/26 [00:00<00:00, 70.93it/s, train_loss=0.00423, val_loss=0.00527]Epoch 9:  42%|████▏     | 11/26 [00:00<00:00, 69.46it/s, train_loss=0.00431, val_loss=0.00527]Epoch 9:  46%|████▌     | 12/26 [00:00<00:00, 71.76it/s, train_loss=0.00431, val_loss=0.00527]Epoch 9:  46%|████▌     | 12/26 [00:00<00:00, 69.43it/s, train_loss=0.0045, val_loss=0.00527] Epoch 9:  50%|█████     | 13/26 [00:00<00:00, 70.68it/s, train_loss=0.0045, val_loss=0.00527]Epoch 9:  50%|█████     | 13/26 [00:00<00:00, 69.46it/s, train_loss=0.00447, val_loss=0.00527]Epoch 9:  54%|█████▍    | 14/26 [00:00<00:00, 71.38it/s, train_loss=0.00447, val_loss=0.00527]Epoch 9:  54%|█████▍    | 14/26 [00:00<00:00, 69.39it/s, train_loss=0.00518, val_loss=0.00527]Epoch 9:  58%|█████▊    | 15/26 [00:00<00:00, 70.59it/s, train_loss=0.00518, val_loss=0.00527]Epoch 9:  58%|█████▊    | 15/26 [00:00<00:00, 69.49it/s, train_loss=0.00481, val_loss=0.00527]Epoch 9:  62%|██████▏   | 16/26 [00:00<00:00, 71.18it/s, train_loss=0.00481, val_loss=0.00527]Epoch 9:  62%|██████▏   | 16/26 [00:00<00:00, 69.47it/s, train_loss=0.00466, val_loss=0.00527]Epoch 9:  65%|██████▌   | 17/26 [00:00<00:00, 70.30it/s, train_loss=0.00466, val_loss=0.00527]Epoch 9:  65%|██████▌   | 17/26 [00:00<00:00, 69.34it/s, train_loss=0.00371, val_loss=0.00527]Epoch 9:  69%|██████▉   | 18/26 [00:00<00:00, 70.85it/s, train_loss=0.00371, val_loss=0.00527]Epoch 9:  69%|██████▉   | 18/26 [00:00<00:00, 69.32it/s, train_loss=0.00512, val_loss=0.00527]Epoch 9:  73%|███████▎  | 19/26 [00:00<00:00, 70.15it/s, train_loss=0.00512, val_loss=0.00527]Epoch 9:  73%|███████▎  | 19/26 [00:00<00:00, 69.30it/s, train_loss=0.00437, val_loss=0.00527]Epoch 9:  77%|███████▋  | 20/26 [00:00<00:00, 70.65it/s, train_loss=0.00437, val_loss=0.00527]Epoch 9:  77%|███████▋  | 20/26 [00:00<00:00, 69.28it/s, train_loss=0.00453, val_loss=0.00527]Epoch 9:  81%|████████  | 21/26 [00:00<00:00, 70.10it/s, train_loss=0.00453, val_loss=0.00527]Epoch 9:  81%|████████  | 21/26 [00:00<00:00, 69.32it/s, train_loss=0.00331, val_loss=0.00527]Epoch 9:  85%|████████▍ | 22/26 [00:00<00:00, 70.66it/s, train_loss=0.00331, val_loss=0.00527]Epoch 9:  85%|████████▍ | 22/26 [00:00<00:00, 69.42it/s, train_loss=0.00432, val_loss=0.00527]Epoch 9:  88%|████████▊ | 23/26 [00:00<00:00, 70.22it/s, train_loss=0.00432, val_loss=0.00527]Epoch 9:  88%|████████▊ | 23/26 [00:00<00:00, 69.38it/s, train_loss=0.00478, val_loss=0.00527]Epoch 9:  92%|█████████▏| 24/26 [00:00<00:00, 70.45it/s, train_loss=0.00478, val_loss=0.00527]Epoch 9:  92%|█████████▏| 24/26 [00:00<00:00, 69.41it/s, train_loss=0.00521, val_loss=0.00527]Epoch 9:  96%|█████████▌| 25/26 [00:00<00:00, 70.00it/s, train_loss=0.00521, val_loss=0.00527]Epoch 9:  96%|█████████▌| 25/26 [00:00<00:00, 69.38it/s, train_loss=0.00418, val_loss=0.00527]Epoch 9: 100%|██████████| 26/26 [00:00<00:00, 70.38it/s, train_loss=0.00418, val_loss=0.00527]Epoch 9: 100%|██████████| 26/26 [00:00<00:00, 69.45it/s, train_loss=0.0048, val_loss=0.00527] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 136.22it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 154.96it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 164.48it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 165.82it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 168.45it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 171.24it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 173.30it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 172.90it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 173.63it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 174.51it/s][A
                                                                         [AEpoch 9: 100%|██████████| 26/26 [00:00<00:00, 59.11it/s, train_loss=0.0048, val_loss=0.00487]Epoch 9: 100%|██████████| 26/26 [00:00<00:00, 58.99it/s, train_loss=0.0048, val_loss=0.00487]Epoch 9:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0048, val_loss=0.00487]         Epoch 10:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0048, val_loss=0.00487]Epoch 10:   4%|▍         | 1/26 [00:00<00:00, 86.06it/s, train_loss=0.0048, val_loss=0.00487]Epoch 10:   4%|▍         | 1/26 [00:00<00:00, 66.88it/s, train_loss=0.0046, val_loss=0.00487]Epoch 10:   8%|▊         | 2/26 [00:00<00:00, 83.68it/s, train_loss=0.0046, val_loss=0.00487]Epoch 10:   8%|▊         | 2/26 [00:00<00:00, 68.18it/s, train_loss=0.00433, val_loss=0.00487]Epoch 10:  12%|█▏        | 3/26 [00:00<00:00, 74.98it/s, train_loss=0.00433, val_loss=0.00487]Epoch 10:  12%|█▏        | 3/26 [00:00<00:00, 69.09it/s, train_loss=0.00453, val_loss=0.00487]Epoch 10:  15%|█▌        | 4/26 [00:00<00:00, 76.55it/s, train_loss=0.00453, val_loss=0.00487]Epoch 10:  15%|█▌        | 4/26 [00:00<00:00, 69.12it/s, train_loss=0.00535, val_loss=0.00487]Epoch 10:  19%|█▉        | 5/26 [00:00<00:00, 72.71it/s, train_loss=0.00535, val_loss=0.00487]Epoch 10:  19%|█▉        | 5/26 [00:00<00:00, 69.28it/s, train_loss=0.004, val_loss=0.00487]  Epoch 10:  23%|██▎       | 6/26 [00:00<00:00, 74.08it/s, train_loss=0.004, val_loss=0.00487]Epoch 10:  23%|██▎       | 6/26 [00:00<00:00, 69.31it/s, train_loss=0.00441, val_loss=0.00487]Epoch 10:  27%|██▋       | 7/26 [00:00<00:00, 71.46it/s, train_loss=0.00441, val_loss=0.00487]Epoch 10:  27%|██▋       | 7/26 [00:00<00:00, 69.15it/s, train_loss=0.00406, val_loss=0.00487]Epoch 10:  31%|███       | 8/26 [00:00<00:00, 72.96it/s, train_loss=0.00406, val_loss=0.00487]Epoch 10:  31%|███       | 8/26 [00:00<00:00, 69.40it/s, train_loss=0.00418, val_loss=0.00487]Epoch 10:  35%|███▍      | 9/26 [00:00<00:00, 71.21it/s, train_loss=0.00418, val_loss=0.00487]Epoch 10:  35%|███▍      | 9/26 [00:00<00:00, 69.38it/s, train_loss=0.00423, val_loss=0.00487]Epoch 10:  38%|███▊      | 10/26 [00:00<00:00, 72.11it/s, train_loss=0.00423, val_loss=0.00487]Epoch 10:  38%|███▊      | 10/26 [00:00<00:00, 69.56it/s, train_loss=0.00336, val_loss=0.00487]Epoch 10:  42%|████▏     | 11/26 [00:00<00:00, 71.24it/s, train_loss=0.00336, val_loss=0.00487]Epoch 10:  42%|████▏     | 11/26 [00:00<00:00, 69.49it/s, train_loss=0.00453, val_loss=0.00487]Epoch 10:  46%|████▌     | 12/26 [00:00<00:00, 71.95it/s, train_loss=0.00453, val_loss=0.00487]Epoch 10:  46%|████▌     | 12/26 [00:00<00:00, 69.61it/s, train_loss=0.00395, val_loss=0.00487]Epoch 10:  50%|█████     | 13/26 [00:00<00:00, 70.98it/s, train_loss=0.00395, val_loss=0.00487]Epoch 10:  50%|█████     | 13/26 [00:00<00:00, 69.62it/s, train_loss=0.004, val_loss=0.00487]  Epoch 10:  54%|█████▍    | 14/26 [00:00<00:00, 71.62it/s, train_loss=0.004, val_loss=0.00487]Epoch 10:  54%|█████▍    | 14/26 [00:00<00:00, 69.63it/s, train_loss=0.00404, val_loss=0.00487]Epoch 10:  58%|█████▊    | 15/26 [00:00<00:00, 70.75it/s, train_loss=0.00404, val_loss=0.00487]Epoch 10:  58%|█████▊    | 15/26 [00:00<00:00, 69.66it/s, train_loss=0.00411, val_loss=0.00487]Epoch 10:  62%|██████▏   | 16/26 [00:00<00:00, 71.38it/s, train_loss=0.00411, val_loss=0.00487]Epoch 10:  62%|██████▏   | 16/26 [00:00<00:00, 69.68it/s, train_loss=0.00426, val_loss=0.00487]Epoch 10:  65%|██████▌   | 17/26 [00:00<00:00, 70.67it/s, train_loss=0.00426, val_loss=0.00487]Epoch 10:  65%|██████▌   | 17/26 [00:00<00:00, 69.71it/s, train_loss=0.00442, val_loss=0.00487]Epoch 10:  69%|██████▉   | 18/26 [00:00<00:00, 71.30it/s, train_loss=0.00442, val_loss=0.00487]Epoch 10:  69%|██████▉   | 18/26 [00:00<00:00, 69.73it/s, train_loss=0.00423, val_loss=0.00487]Epoch 10:  73%|███████▎  | 19/26 [00:00<00:00, 70.66it/s, train_loss=0.00423, val_loss=0.00487]Epoch 10:  73%|███████▎  | 19/26 [00:00<00:00, 69.79it/s, train_loss=0.00423, val_loss=0.00487]Epoch 10:  77%|███████▋  | 20/26 [00:00<00:00, 71.19it/s, train_loss=0.00423, val_loss=0.00487]Epoch 10:  77%|███████▋  | 20/26 [00:00<00:00, 69.79it/s, train_loss=0.00414, val_loss=0.00487]Epoch 10:  81%|████████  | 21/26 [00:00<00:00, 70.55it/s, train_loss=0.00414, val_loss=0.00487]Epoch 10:  81%|████████  | 21/26 [00:00<00:00, 69.77it/s, train_loss=0.00461, val_loss=0.00487]Epoch 10:  85%|████████▍ | 22/26 [00:00<00:00, 71.00it/s, train_loss=0.00461, val_loss=0.00487]Epoch 10:  85%|████████▍ | 22/26 [00:00<00:00, 69.74it/s, train_loss=0.0044, val_loss=0.00487] Epoch 10:  88%|████████▊ | 23/26 [00:00<00:00, 70.47it/s, train_loss=0.0044, val_loss=0.00487]Epoch 10:  88%|████████▊ | 23/26 [00:00<00:00, 69.76it/s, train_loss=0.00514, val_loss=0.00487]Epoch 10:  92%|█████████▏| 24/26 [00:00<00:00, 70.93it/s, train_loss=0.00514, val_loss=0.00487]Epoch 10:  92%|█████████▏| 24/26 [00:00<00:00, 69.73it/s, train_loss=0.00519, val_loss=0.00487]Epoch 10:  96%|█████████▌| 25/26 [00:00<00:00, 70.40it/s, train_loss=0.00519, val_loss=0.00487]Epoch 10:  96%|█████████▌| 25/26 [00:00<00:00, 69.74it/s, train_loss=0.0043, val_loss=0.00487] Epoch 10: 100%|██████████| 26/26 [00:00<00:00, 70.78it/s, train_loss=0.0043, val_loss=0.00487]Epoch 10: 100%|██████████| 26/26 [00:00<00:00, 69.78it/s, train_loss=0.00387, val_loss=0.00487]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 168.64it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 170.74it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 177.72it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 182.47it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 185.94it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 182.49it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 183.63it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 185.39it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 186.27it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 187.40it/s][A
                                                                         [AEpoch 10: 100%|██████████| 26/26 [00:00<00:00, 60.02it/s, train_loss=0.00387, val_loss=0.00459]Epoch 10: 100%|██████████| 26/26 [00:00<00:00, 59.92it/s, train_loss=0.00387, val_loss=0.00459]Epoch 10:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00387, val_loss=0.00459]         Epoch 11:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00387, val_loss=0.00459]Epoch 11:   4%|▍         | 1/26 [00:00<00:00, 85.76it/s, train_loss=0.00387, val_loss=0.00459]Epoch 11:   4%|▍         | 1/26 [00:00<00:00, 66.16it/s, train_loss=0.00436, val_loss=0.00459]Epoch 11:   8%|▊         | 2/26 [00:00<00:00, 55.17it/s, train_loss=0.00436, val_loss=0.00459]Epoch 11:   8%|▊         | 2/26 [00:00<00:00, 50.27it/s, train_loss=0.00437, val_loss=0.00459]Epoch 11:  12%|█▏        | 3/26 [00:00<00:00, 61.19it/s, train_loss=0.00437, val_loss=0.00459]Epoch 11:  12%|█▏        | 3/26 [00:00<00:00, 54.19it/s, train_loss=0.00399, val_loss=0.00459]Epoch 11:  15%|█▌        | 4/26 [00:00<00:00, 60.23it/s, train_loss=0.00399, val_loss=0.00459]Epoch 11:  15%|█▌        | 4/26 [00:00<00:00, 56.96it/s, train_loss=0.00441, val_loss=0.00459]Epoch 11:  19%|█▉        | 5/26 [00:00<00:00, 61.67it/s, train_loss=0.00441, val_loss=0.00459]Epoch 11:  19%|█▉        | 5/26 [00:00<00:00, 58.16it/s, train_loss=0.00478, val_loss=0.00459]Epoch 11:  23%|██▎       | 6/26 [00:00<00:00, 63.12it/s, train_loss=0.00478, val_loss=0.00459]Epoch 11:  23%|██▎       | 6/26 [00:00<00:00, 59.79it/s, train_loss=0.00402, val_loss=0.00459]Epoch 11:  27%|██▋       | 7/26 [00:00<00:00, 62.84it/s, train_loss=0.00402, val_loss=0.00459]Epoch 11:  27%|██▋       | 7/26 [00:00<00:00, 61.00it/s, train_loss=0.00453, val_loss=0.00459]Epoch 11:  31%|███       | 8/26 [00:00<00:00, 64.60it/s, train_loss=0.00453, val_loss=0.00459]Epoch 11:  31%|███       | 8/26 [00:00<00:00, 61.87it/s, train_loss=0.00401, val_loss=0.00459]Epoch 11:  35%|███▍      | 9/26 [00:00<00:00, 64.06it/s, train_loss=0.00401, val_loss=0.00459]Epoch 11:  35%|███▍      | 9/26 [00:00<00:00, 62.59it/s, train_loss=0.00369, val_loss=0.00459]Epoch 11:  38%|███▊      | 10/26 [00:00<00:00, 65.57it/s, train_loss=0.00369, val_loss=0.00459]Epoch 11:  38%|███▊      | 10/26 [00:00<00:00, 63.23it/s, train_loss=0.00402, val_loss=0.00459]Epoch 11:  42%|████▏     | 11/26 [00:00<00:00, 65.05it/s, train_loss=0.00402, val_loss=0.00459]Epoch 11:  42%|████▏     | 11/26 [00:00<00:00, 63.80it/s, train_loss=0.00371, val_loss=0.00459]Epoch 11:  46%|████▌     | 12/26 [00:00<00:00, 66.14it/s, train_loss=0.00371, val_loss=0.00459]Epoch 11:  46%|████▌     | 12/26 [00:00<00:00, 64.19it/s, train_loss=0.00393, val_loss=0.00459]Epoch 11:  50%|█████     | 13/26 [00:00<00:00, 65.67it/s, train_loss=0.00393, val_loss=0.00459]Epoch 11:  50%|█████     | 13/26 [00:00<00:00, 64.56it/s, train_loss=0.00467, val_loss=0.00459]Epoch 11:  54%|█████▍    | 14/26 [00:00<00:00, 66.73it/s, train_loss=0.00467, val_loss=0.00459]Epoch 11:  54%|█████▍    | 14/26 [00:00<00:00, 65.00it/s, train_loss=0.00432, val_loss=0.00459]Epoch 11:  58%|█████▊    | 15/26 [00:00<00:00, 66.31it/s, train_loss=0.00432, val_loss=0.00459]Epoch 11:  58%|█████▊    | 15/26 [00:00<00:00, 65.26it/s, train_loss=0.00358, val_loss=0.00459]Epoch 11:  62%|██████▏   | 16/26 [00:00<00:00, 67.07it/s, train_loss=0.00358, val_loss=0.00459]Epoch 11:  62%|██████▏   | 16/26 [00:00<00:00, 65.60it/s, train_loss=0.00326, val_loss=0.00459]Epoch 11:  65%|██████▌   | 17/26 [00:00<00:00, 66.71it/s, train_loss=0.00326, val_loss=0.00459]Epoch 11:  65%|██████▌   | 17/26 [00:00<00:00, 65.79it/s, train_loss=0.00409, val_loss=0.00459]Epoch 11:  69%|██████▉   | 18/26 [00:00<00:00, 67.42it/s, train_loss=0.00409, val_loss=0.00459]Epoch 11:  69%|██████▉   | 18/26 [00:00<00:00, 66.06it/s, train_loss=0.00382, val_loss=0.00459]Epoch 11:  73%|███████▎  | 19/26 [00:00<00:00, 67.06it/s, train_loss=0.00382, val_loss=0.00459]Epoch 11:  73%|███████▎  | 19/26 [00:00<00:00, 66.25it/s, train_loss=0.00441, val_loss=0.00459]Epoch 11:  77%|███████▋  | 20/26 [00:00<00:00, 67.65it/s, train_loss=0.00441, val_loss=0.00459]Epoch 11:  77%|███████▋  | 20/26 [00:00<00:00, 66.42it/s, train_loss=0.00436, val_loss=0.00459]Epoch 11:  81%|████████  | 21/26 [00:00<00:00, 67.30it/s, train_loss=0.00436, val_loss=0.00459]Epoch 11:  81%|████████  | 21/26 [00:00<00:00, 66.59it/s, train_loss=0.00409, val_loss=0.00459]Epoch 11:  85%|████████▍ | 22/26 [00:00<00:00, 67.91it/s, train_loss=0.00409, val_loss=0.00459]Epoch 11:  85%|████████▍ | 22/26 [00:00<00:00, 66.75it/s, train_loss=0.00403, val_loss=0.00459]Epoch 11:  88%|████████▊ | 23/26 [00:00<00:00, 67.54it/s, train_loss=0.00403, val_loss=0.00459]Epoch 11:  88%|████████▊ | 23/26 [00:00<00:00, 66.89it/s, train_loss=0.00318, val_loss=0.00459]Epoch 11:  92%|█████████▏| 24/26 [00:00<00:00, 68.07it/s, train_loss=0.00318, val_loss=0.00459]Epoch 11:  92%|█████████▏| 24/26 [00:00<00:00, 66.99it/s, train_loss=0.00426, val_loss=0.00459]Epoch 11:  96%|█████████▌| 25/26 [00:00<00:00, 67.70it/s, train_loss=0.00426, val_loss=0.00459]Epoch 11:  96%|█████████▌| 25/26 [00:00<00:00, 67.09it/s, train_loss=0.00364, val_loss=0.00459]Epoch 11: 100%|██████████| 26/26 [00:00<00:00, 68.16it/s, train_loss=0.00364, val_loss=0.00459]Epoch 11: 100%|██████████| 26/26 [00:00<00:00, 67.23it/s, train_loss=0.00357, val_loss=0.00459]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 115.94it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 131.19it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 136.38it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 142.67it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 144.26it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 147.03it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 147.97it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 149.28it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 147.65it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 150.81it/s][A
                                                                         [AEpoch 11: 100%|██████████| 26/26 [00:00<00:00, 56.62it/s, train_loss=0.00357, val_loss=0.00441]Epoch 11: 100%|██████████| 26/26 [00:00<00:00, 56.55it/s, train_loss=0.00357, val_loss=0.00441]Epoch 11:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00357, val_loss=0.00441]         Epoch 12:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00357, val_loss=0.00441]Epoch 12:   4%|▍         | 1/26 [00:00<00:00, 88.92it/s, train_loss=0.00357, val_loss=0.00441]Epoch 12:   4%|▍         | 1/26 [00:00<00:00, 68.37it/s, train_loss=0.00372, val_loss=0.00441]Epoch 12:   8%|▊         | 2/26 [00:00<00:00, 85.85it/s, train_loss=0.00372, val_loss=0.00441]Epoch 12:   8%|▊         | 2/26 [00:00<00:00, 66.95it/s, train_loss=0.00376, val_loss=0.00441]Epoch 12:  12%|█▏        | 3/26 [00:00<00:00, 74.79it/s, train_loss=0.00376, val_loss=0.00441]Epoch 12:  12%|█▏        | 3/26 [00:00<00:00, 68.09it/s, train_loss=0.00356, val_loss=0.00441]Epoch 12:  15%|█▌        | 4/26 [00:00<00:00, 73.13it/s, train_loss=0.00356, val_loss=0.00441]Epoch 12:  15%|█▌        | 4/26 [00:00<00:00, 67.66it/s, train_loss=0.00384, val_loss=0.00441]Epoch 12:  19%|█▉        | 5/26 [00:00<00:00, 73.29it/s, train_loss=0.00384, val_loss=0.00441]Epoch 12:  19%|█▉        | 5/26 [00:00<00:00, 67.98it/s, train_loss=0.00413, val_loss=0.00441]Epoch 12:  23%|██▎       | 6/26 [00:00<00:00, 70.95it/s, train_loss=0.00413, val_loss=0.00441]Epoch 12:  23%|██▎       | 6/26 [00:00<00:00, 68.33it/s, train_loss=0.00407, val_loss=0.00441]Epoch 12:  27%|██▋       | 7/26 [00:00<00:00, 72.33it/s, train_loss=0.00407, val_loss=0.00441]Epoch 12:  27%|██▋       | 7/26 [00:00<00:00, 68.49it/s, train_loss=0.00441, val_loss=0.00441]Epoch 12:  31%|███       | 8/26 [00:00<00:00, 70.55it/s, train_loss=0.00441, val_loss=0.00441]Epoch 12:  31%|███       | 8/26 [00:00<00:00, 68.59it/s, train_loss=0.00384, val_loss=0.00441]Epoch 12:  35%|███▍      | 9/26 [00:00<00:00, 71.68it/s, train_loss=0.00384, val_loss=0.00441]Epoch 12:  35%|███▍      | 9/26 [00:00<00:00, 68.70it/s, train_loss=0.00391, val_loss=0.00441]Epoch 12:  38%|███▊      | 10/26 [00:00<00:00, 70.87it/s, train_loss=0.00391, val_loss=0.00441]Epoch 12:  38%|███▊      | 10/26 [00:00<00:00, 68.83it/s, train_loss=0.00387, val_loss=0.00441]Epoch 12:  42%|████▏     | 11/26 [00:00<00:00, 71.33it/s, train_loss=0.00387, val_loss=0.00441]Epoch 12:  42%|████▏     | 11/26 [00:00<00:00, 68.88it/s, train_loss=0.00355, val_loss=0.00441]Epoch 12:  46%|████▌     | 12/26 [00:00<00:00, 70.58it/s, train_loss=0.00355, val_loss=0.00441]Epoch 12:  46%|████▌     | 12/26 [00:00<00:00, 68.90it/s, train_loss=0.00383, val_loss=0.00441]Epoch 12:  50%|█████     | 13/26 [00:00<00:00, 71.04it/s, train_loss=0.00383, val_loss=0.00441]Epoch 12:  50%|█████     | 13/26 [00:00<00:00, 68.93it/s, train_loss=0.0036, val_loss=0.00441] Epoch 12:  54%|█████▍    | 14/26 [00:00<00:00, 70.52it/s, train_loss=0.0036, val_loss=0.00441]Epoch 12:  54%|█████▍    | 14/26 [00:00<00:00, 68.99it/s, train_loss=0.00332, val_loss=0.00441]Epoch 12:  58%|█████▊    | 15/26 [00:00<00:00, 70.80it/s, train_loss=0.00332, val_loss=0.00441]Epoch 12:  58%|█████▊    | 15/26 [00:00<00:00, 68.98it/s, train_loss=0.0043, val_loss=0.00441] Epoch 12:  62%|██████▏   | 16/26 [00:00<00:00, 70.27it/s, train_loss=0.0043, val_loss=0.00441]Epoch 12:  62%|██████▏   | 16/26 [00:00<00:00, 69.00it/s, train_loss=0.00368, val_loss=0.00441]Epoch 12:  65%|██████▌   | 17/26 [00:00<00:00, 70.59it/s, train_loss=0.00368, val_loss=0.00441]Epoch 12:  65%|██████▌   | 17/26 [00:00<00:00, 68.99it/s, train_loss=0.00425, val_loss=0.00441]Epoch 12:  69%|██████▉   | 18/26 [00:00<00:00, 70.10it/s, train_loss=0.00425, val_loss=0.00441]Epoch 12:  69%|██████▉   | 18/26 [00:00<00:00, 68.99it/s, train_loss=0.00315, val_loss=0.00441]Epoch 12:  73%|███████▎  | 19/26 [00:00<00:00, 70.19it/s, train_loss=0.00315, val_loss=0.00441]Epoch 12:  73%|███████▎  | 19/26 [00:00<00:00, 68.96it/s, train_loss=0.00398, val_loss=0.00441]Epoch 12:  77%|███████▋  | 20/26 [00:00<00:00, 69.85it/s, train_loss=0.00398, val_loss=0.00441]Epoch 12:  77%|███████▋  | 20/26 [00:00<00:00, 68.96it/s, train_loss=0.00351, val_loss=0.00441]Epoch 12:  81%|████████  | 21/26 [00:00<00:00, 70.32it/s, train_loss=0.00351, val_loss=0.00441]Epoch 12:  81%|████████  | 21/26 [00:00<00:00, 69.05it/s, train_loss=0.00358, val_loss=0.00441]Epoch 12:  85%|████████▍ | 22/26 [00:00<00:00, 69.84it/s, train_loss=0.00358, val_loss=0.00441]Epoch 12:  85%|████████▍ | 22/26 [00:00<00:00, 69.05it/s, train_loss=0.00401, val_loss=0.00441]Epoch 12:  88%|████████▊ | 23/26 [00:00<00:00, 70.26it/s, train_loss=0.00401, val_loss=0.00441]Epoch 12:  88%|████████▊ | 23/26 [00:00<00:00, 69.10it/s, train_loss=0.00338, val_loss=0.00441]Epoch 12:  92%|█████████▏| 24/26 [00:00<00:00, 69.79it/s, train_loss=0.00338, val_loss=0.00441]Epoch 12:  92%|█████████▏| 24/26 [00:00<00:00, 69.15it/s, train_loss=0.0034, val_loss=0.00441] Epoch 12:  96%|█████████▌| 25/26 [00:00<00:00, 70.25it/s, train_loss=0.0034, val_loss=0.00441]Epoch 12:  96%|█████████▌| 25/26 [00:00<00:00, 69.20it/s, train_loss=0.00407, val_loss=0.00441]Epoch 12: 100%|██████████| 26/26 [00:00<00:00, 69.92it/s, train_loss=0.00407, val_loss=0.00441]Epoch 12: 100%|██████████| 26/26 [00:00<00:00, 69.30it/s, train_loss=0.00359, val_loss=0.00441]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 133.29it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 146.21it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 154.36it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 160.66it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 161.09it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 162.02it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 160.87it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 161.31it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 161.81it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 162.04it/s][A
                                                                         [AEpoch 12: 100%|██████████| 26/26 [00:00<00:00, 58.33it/s, train_loss=0.00359, val_loss=0.00413]Epoch 12: 100%|██████████| 26/26 [00:00<00:00, 58.19it/s, train_loss=0.00359, val_loss=0.00413]Epoch 12:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00359, val_loss=0.00413]         Epoch 13:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00359, val_loss=0.00413]Epoch 13:   4%|▍         | 1/26 [00:00<00:00, 85.41it/s, train_loss=0.00359, val_loss=0.00413]Epoch 13:   4%|▍         | 1/26 [00:00<00:00, 60.78it/s, train_loss=0.00396, val_loss=0.00413]Epoch 13:   8%|▊         | 2/26 [00:00<00:00, 74.88it/s, train_loss=0.00396, val_loss=0.00413]Epoch 13:   8%|▊         | 2/26 [00:00<00:00, 64.58it/s, train_loss=0.0037, val_loss=0.00413] Epoch 13:  12%|█▏        | 3/26 [00:00<00:00, 71.05it/s, train_loss=0.0037, val_loss=0.00413]Epoch 13:  12%|█▏        | 3/26 [00:00<00:00, 65.91it/s, train_loss=0.00318, val_loss=0.00413]Epoch 13:  15%|█▌        | 4/26 [00:00<00:00, 73.81it/s, train_loss=0.00318, val_loss=0.00413]Epoch 13:  15%|█▌        | 4/26 [00:00<00:00, 67.26it/s, train_loss=0.00304, val_loss=0.00413]Epoch 13:  19%|█▉        | 5/26 [00:00<00:00, 71.57it/s, train_loss=0.00304, val_loss=0.00413]Epoch 13:  19%|█▉        | 5/26 [00:00<00:00, 67.40it/s, train_loss=0.00401, val_loss=0.00413]Epoch 13:  23%|██▎       | 6/26 [00:00<00:00, 72.33it/s, train_loss=0.00401, val_loss=0.00413]Epoch 13:  23%|██▎       | 6/26 [00:00<00:00, 67.90it/s, train_loss=0.0034, val_loss=0.00413] Epoch 13:  27%|██▋       | 7/26 [00:00<00:00, 70.62it/s, train_loss=0.0034, val_loss=0.00413]Epoch 13:  27%|██▋       | 7/26 [00:00<00:00, 68.02it/s, train_loss=0.00383, val_loss=0.00413]Epoch 13:  31%|███       | 8/26 [00:00<00:00, 71.56it/s, train_loss=0.00383, val_loss=0.00413]Epoch 13:  31%|███       | 8/26 [00:00<00:00, 68.25it/s, train_loss=0.00349, val_loss=0.00413]Epoch 13:  35%|███▍      | 9/26 [00:00<00:00, 70.33it/s, train_loss=0.00349, val_loss=0.00413]Epoch 13:  35%|███▍      | 9/26 [00:00<00:00, 68.43it/s, train_loss=0.00325, val_loss=0.00413]Epoch 13:  38%|███▊      | 10/26 [00:00<00:00, 71.22it/s, train_loss=0.00325, val_loss=0.00413]Epoch 13:  38%|███▊      | 10/26 [00:00<00:00, 68.50it/s, train_loss=0.00356, val_loss=0.00413]Epoch 13:  42%|████▏     | 11/26 [00:00<00:00, 70.11it/s, train_loss=0.00356, val_loss=0.00413]Epoch 13:  42%|████▏     | 11/26 [00:00<00:00, 68.57it/s, train_loss=0.00329, val_loss=0.00413]Epoch 13:  46%|████▌     | 12/26 [00:00<00:00, 70.91it/s, train_loss=0.00329, val_loss=0.00413]Epoch 13:  46%|████▌     | 12/26 [00:00<00:00, 68.58it/s, train_loss=0.00346, val_loss=0.00413]Epoch 13:  50%|█████     | 13/26 [00:00<00:00, 69.91it/s, train_loss=0.00346, val_loss=0.00413]Epoch 13:  50%|█████     | 13/26 [00:00<00:00, 68.63it/s, train_loss=0.00362, val_loss=0.00413]Epoch 13:  54%|█████▍    | 14/26 [00:00<00:00, 70.60it/s, train_loss=0.00362, val_loss=0.00413]Epoch 13:  54%|█████▍    | 14/26 [00:00<00:00, 68.66it/s, train_loss=0.00356, val_loss=0.00413]Epoch 13:  58%|█████▊    | 15/26 [00:00<00:00, 69.79it/s, train_loss=0.00356, val_loss=0.00413]Epoch 13:  58%|█████▊    | 15/26 [00:00<00:00, 68.67it/s, train_loss=0.00419, val_loss=0.00413]Epoch 13:  62%|██████▏   | 16/26 [00:00<00:00, 70.24it/s, train_loss=0.00419, val_loss=0.00413]Epoch 13:  62%|██████▏   | 16/26 [00:00<00:00, 68.65it/s, train_loss=0.00333, val_loss=0.00413]Epoch 13:  65%|██████▌   | 17/26 [00:00<00:00, 69.56it/s, train_loss=0.00333, val_loss=0.00413]Epoch 13:  65%|██████▌   | 17/26 [00:00<00:00, 68.60it/s, train_loss=0.00367, val_loss=0.00413]Epoch 13:  69%|██████▉   | 18/26 [00:00<00:00, 70.08it/s, train_loss=0.00367, val_loss=0.00413]Epoch 13:  69%|██████▉   | 18/26 [00:00<00:00, 68.56it/s, train_loss=0.0034, val_loss=0.00413] Epoch 13:  73%|███████▎  | 19/26 [00:00<00:00, 69.43it/s, train_loss=0.0034, val_loss=0.00413]Epoch 13:  73%|███████▎  | 19/26 [00:00<00:00, 68.56it/s, train_loss=0.00342, val_loss=0.00413]Epoch 13:  77%|███████▋  | 20/26 [00:00<00:00, 69.92it/s, train_loss=0.00342, val_loss=0.00413]Epoch 13:  77%|███████▋  | 20/26 [00:00<00:00, 68.54it/s, train_loss=0.00406, val_loss=0.00413]Epoch 13:  81%|████████  | 21/26 [00:00<00:00, 69.32it/s, train_loss=0.00406, val_loss=0.00413]Epoch 13:  81%|████████  | 21/26 [00:00<00:00, 68.52it/s, train_loss=0.00374, val_loss=0.00413]Epoch 13:  85%|████████▍ | 22/26 [00:00<00:00, 69.78it/s, train_loss=0.00374, val_loss=0.00413]Epoch 13:  85%|████████▍ | 22/26 [00:00<00:00, 68.50it/s, train_loss=0.00344, val_loss=0.00413]Epoch 13:  88%|████████▊ | 23/26 [00:00<00:00, 69.22it/s, train_loss=0.00344, val_loss=0.00413]Epoch 13:  88%|████████▊ | 23/26 [00:00<00:00, 68.46it/s, train_loss=0.00331, val_loss=0.00413]Epoch 13:  92%|█████████▏| 24/26 [00:00<00:00, 69.59it/s, train_loss=0.00331, val_loss=0.00413]Epoch 13:  92%|█████████▏| 24/26 [00:00<00:00, 68.49it/s, train_loss=0.00319, val_loss=0.00413]Epoch 13:  96%|█████████▌| 25/26 [00:00<00:00, 69.23it/s, train_loss=0.00319, val_loss=0.00413]Epoch 13:  96%|█████████▌| 25/26 [00:00<00:00, 68.48it/s, train_loss=0.0031, val_loss=0.00413] Epoch 13: 100%|██████████| 26/26 [00:00<00:00, 69.58it/s, train_loss=0.0031, val_loss=0.00413]Epoch 13: 100%|██████████| 26/26 [00:00<00:00, 68.58it/s, train_loss=0.00386, val_loss=0.00413]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 134.71it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 154.02it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 164.90it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 170.23it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 170.26it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 171.73it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 173.25it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 169.73it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 170.57it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 172.90it/s][A
                                                                         [AEpoch 13: 100%|██████████| 26/26 [00:00<00:00, 58.40it/s, train_loss=0.00386, val_loss=0.00382]Epoch 13: 100%|██████████| 26/26 [00:00<00:00, 58.28it/s, train_loss=0.00386, val_loss=0.00382]Epoch 13:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00386, val_loss=0.00382]         Epoch 14:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00386, val_loss=0.00382]Epoch 14:   4%|▍         | 1/26 [00:00<00:00, 82.81it/s, train_loss=0.00386, val_loss=0.00382]Epoch 14:   4%|▍         | 1/26 [00:00<00:00, 59.66it/s, train_loss=0.00307, val_loss=0.00382]Epoch 14:   8%|▊         | 2/26 [00:00<00:00, 77.06it/s, train_loss=0.00307, val_loss=0.00382]Epoch 14:   8%|▊         | 2/26 [00:00<00:00, 63.46it/s, train_loss=0.00361, val_loss=0.00382]Epoch 14:  12%|█▏        | 3/26 [00:00<00:00, 70.34it/s, train_loss=0.00361, val_loss=0.00382]Epoch 14:  12%|█▏        | 3/26 [00:00<00:00, 65.02it/s, train_loss=0.00289, val_loss=0.00382]Epoch 14:  15%|█▌        | 4/26 [00:00<00:00, 72.52it/s, train_loss=0.00289, val_loss=0.00382]Epoch 14:  15%|█▌        | 4/26 [00:00<00:00, 65.69it/s, train_loss=0.00356, val_loss=0.00382]Epoch 14:  19%|█▉        | 5/26 [00:00<00:00, 69.63it/s, train_loss=0.00356, val_loss=0.00382]Epoch 14:  19%|█▉        | 5/26 [00:00<00:00, 66.28it/s, train_loss=0.00302, val_loss=0.00382]Epoch 14:  23%|██▎       | 6/26 [00:00<00:00, 71.11it/s, train_loss=0.00302, val_loss=0.00382]Epoch 14:  23%|██▎       | 6/26 [00:00<00:00, 66.53it/s, train_loss=0.00314, val_loss=0.00382]Epoch 14:  27%|██▋       | 7/26 [00:00<00:00, 69.07it/s, train_loss=0.00314, val_loss=0.00382]Epoch 14:  27%|██▋       | 7/26 [00:00<00:00, 66.76it/s, train_loss=0.00325, val_loss=0.00382]Epoch 14:  31%|███       | 8/26 [00:00<00:00, 70.25it/s, train_loss=0.00325, val_loss=0.00382]Epoch 14:  31%|███       | 8/26 [00:00<00:00, 66.88it/s, train_loss=0.0034, val_loss=0.00382] Epoch 14:  35%|███▍      | 9/26 [00:00<00:00, 68.86it/s, train_loss=0.0034, val_loss=0.00382]Epoch 14:  35%|███▍      | 9/26 [00:00<00:00, 66.94it/s, train_loss=0.00358, val_loss=0.00382]Epoch 14:  38%|███▊      | 10/26 [00:00<00:00, 69.98it/s, train_loss=0.00358, val_loss=0.00382]Epoch 14:  38%|███▊      | 10/26 [00:00<00:00, 67.20it/s, train_loss=0.00377, val_loss=0.00382]Epoch 14:  42%|████▏     | 11/26 [00:00<00:00, 68.99it/s, train_loss=0.00377, val_loss=0.00382]Epoch 14:  42%|████▏     | 11/26 [00:00<00:00, 67.27it/s, train_loss=0.00348, val_loss=0.00382]Epoch 14:  46%|████▌     | 12/26 [00:00<00:00, 69.56it/s, train_loss=0.00348, val_loss=0.00382]Epoch 14:  46%|████▌     | 12/26 [00:00<00:00, 67.38it/s, train_loss=0.00393, val_loss=0.00382]Epoch 14:  50%|█████     | 13/26 [00:00<00:00, 69.49it/s, train_loss=0.00393, val_loss=0.00382]Epoch 14:  50%|█████     | 13/26 [00:00<00:00, 67.89it/s, train_loss=0.0036, val_loss=0.00382] Epoch 14:  54%|█████▍    | 14/26 [00:00<00:00, 68.26it/s, train_loss=0.0036, val_loss=0.00382]Epoch 14:  54%|█████▍    | 14/26 [00:00<00:00, 66.74it/s, train_loss=0.00299, val_loss=0.00382]Epoch 14:  58%|█████▊    | 15/26 [00:00<00:00, 68.71it/s, train_loss=0.00299, val_loss=0.00382]Epoch 14:  58%|█████▊    | 15/26 [00:00<00:00, 63.19it/s, train_loss=0.00353, val_loss=0.00382]Epoch 14:  62%|██████▏   | 16/26 [00:00<00:00, 64.96it/s, train_loss=0.00353, val_loss=0.00382]Epoch 14:  62%|██████▏   | 16/26 [00:00<00:00, 60.47it/s, train_loss=0.00278, val_loss=0.00382]Epoch 14:  65%|██████▌   | 17/26 [00:00<00:00, 61.77it/s, train_loss=0.00278, val_loss=0.00382]Epoch 14:  65%|██████▌   | 17/26 [00:00<00:00, 60.98it/s, train_loss=0.0036, val_loss=0.00382] Epoch 14:  69%|██████▉   | 18/26 [00:00<00:00, 62.57it/s, train_loss=0.0036, val_loss=0.00382]Epoch 14:  69%|██████▉   | 18/26 [00:00<00:00, 61.35it/s, train_loss=0.00357, val_loss=0.00382]Epoch 14:  73%|███████▎  | 19/26 [00:00<00:00, 62.50it/s, train_loss=0.00357, val_loss=0.00382]Epoch 14:  73%|███████▎  | 19/26 [00:00<00:00, 61.43it/s, train_loss=0.0031, val_loss=0.00382] Epoch 14:  77%|███████▋  | 20/26 [00:00<00:00, 62.89it/s, train_loss=0.0031, val_loss=0.00382]Epoch 14:  77%|███████▋  | 20/26 [00:00<00:00, 61.73it/s, train_loss=0.0036, val_loss=0.00382]Epoch 14:  81%|████████  | 21/26 [00:00<00:00, 62.70it/s, train_loss=0.0036, val_loss=0.00382]Epoch 14:  81%|████████  | 21/26 [00:00<00:00, 61.88it/s, train_loss=0.00346, val_loss=0.00382]Epoch 14:  85%|████████▍ | 22/26 [00:00<00:00, 63.19it/s, train_loss=0.00346, val_loss=0.00382]Epoch 14:  85%|████████▍ | 22/26 [00:00<00:00, 62.12it/s, train_loss=0.00317, val_loss=0.00382]Epoch 14:  88%|████████▊ | 23/26 [00:00<00:00, 62.96it/s, train_loss=0.00317, val_loss=0.00382]Epoch 14:  88%|████████▊ | 23/26 [00:00<00:00, 62.23it/s, train_loss=0.00375, val_loss=0.00382]Epoch 14:  92%|█████████▏| 24/26 [00:00<00:00, 63.41it/s, train_loss=0.00375, val_loss=0.00382]Epoch 14:  92%|█████████▏| 24/26 [00:00<00:00, 62.43it/s, train_loss=0.00267, val_loss=0.00382]Epoch 14:  96%|█████████▌| 25/26 [00:00<00:00, 63.12it/s, train_loss=0.00267, val_loss=0.00382]Epoch 14:  96%|█████████▌| 25/26 [00:00<00:00, 62.53it/s, train_loss=0.00332, val_loss=0.00382]Epoch 14: 100%|██████████| 26/26 [00:00<00:00, 63.61it/s, train_loss=0.00332, val_loss=0.00382]Epoch 14: 100%|██████████| 26/26 [00:00<00:00, 62.75it/s, train_loss=0.00314, val_loss=0.00382]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 154.45it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 159.73it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 171.42it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 178.84it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 185.15it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 188.85it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 191.15it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 193.55it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 191.27it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 191.98it/s][A
                                                                         [AEpoch 14: 100%|██████████| 26/26 [00:00<00:00, 54.82it/s, train_loss=0.00314, val_loss=0.00363]Epoch 14: 100%|██████████| 26/26 [00:00<00:00, 54.72it/s, train_loss=0.00314, val_loss=0.00363]Epoch 14:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00314, val_loss=0.00363]         Epoch 15:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00314, val_loss=0.00363]Epoch 15:   4%|▍         | 1/26 [00:00<00:00, 87.78it/s, train_loss=0.00314, val_loss=0.00363]Epoch 15:   4%|▍         | 1/26 [00:00<00:00, 65.61it/s, train_loss=0.00268, val_loss=0.00363]Epoch 15:   8%|▊         | 2/26 [00:00<00:00, 83.82it/s, train_loss=0.00268, val_loss=0.00363]Epoch 15:   8%|▊         | 2/26 [00:00<00:00, 62.45it/s, train_loss=0.00306, val_loss=0.00363]Epoch 15:  12%|█▏        | 3/26 [00:00<00:00, 70.76it/s, train_loss=0.00306, val_loss=0.00363]Epoch 15:  12%|█▏        | 3/26 [00:00<00:00, 63.66it/s, train_loss=0.00321, val_loss=0.00363]Epoch 15:  15%|█▌        | 4/26 [00:00<00:00, 69.23it/s, train_loss=0.00321, val_loss=0.00363]Epoch 15:  15%|█▌        | 4/26 [00:00<00:00, 63.43it/s, train_loss=0.00314, val_loss=0.00363]Epoch 15:  19%|█▉        | 5/26 [00:00<00:00, 69.69it/s, train_loss=0.00314, val_loss=0.00363]Epoch 15:  19%|█▉        | 5/26 [00:00<00:00, 64.34it/s, train_loss=0.00331, val_loss=0.00363]Epoch 15:  23%|██▎       | 6/26 [00:00<00:00, 67.74it/s, train_loss=0.00331, val_loss=0.00363]Epoch 15:  23%|██▎       | 6/26 [00:00<00:00, 64.42it/s, train_loss=0.00372, val_loss=0.00363]Epoch 15:  27%|██▋       | 7/26 [00:00<00:00, 68.76it/s, train_loss=0.00372, val_loss=0.00363]Epoch 15:  27%|██▋       | 7/26 [00:00<00:00, 64.95it/s, train_loss=0.00313, val_loss=0.00363]Epoch 15:  31%|███       | 8/26 [00:00<00:00, 67.43it/s, train_loss=0.00313, val_loss=0.00363]Epoch 15:  31%|███       | 8/26 [00:00<00:00, 64.90it/s, train_loss=0.00333, val_loss=0.00363]Epoch 15:  35%|███▍      | 9/26 [00:00<00:00, 68.14it/s, train_loss=0.00333, val_loss=0.00363]Epoch 15:  35%|███▍      | 9/26 [00:00<00:00, 65.22it/s, train_loss=0.00309, val_loss=0.00363]Epoch 15:  38%|███▊      | 10/26 [00:00<00:00, 67.13it/s, train_loss=0.00309, val_loss=0.00363]Epoch 15:  38%|███▊      | 10/26 [00:00<00:00, 65.18it/s, train_loss=0.00327, val_loss=0.00363]Epoch 15:  42%|████▏     | 11/26 [00:00<00:00, 67.78it/s, train_loss=0.00327, val_loss=0.00363]Epoch 15:  42%|████▏     | 11/26 [00:00<00:00, 65.40it/s, train_loss=0.00328, val_loss=0.00363]Epoch 15:  46%|████▌     | 12/26 [00:00<00:00, 66.96it/s, train_loss=0.00328, val_loss=0.00363]Epoch 15:  46%|████▌     | 12/26 [00:00<00:00, 65.36it/s, train_loss=0.00332, val_loss=0.00363]Epoch 15:  50%|█████     | 13/26 [00:00<00:00, 67.55it/s, train_loss=0.00332, val_loss=0.00363]Epoch 15:  50%|█████     | 13/26 [00:00<00:00, 65.55it/s, train_loss=0.00289, val_loss=0.00363]Epoch 15:  54%|█████▍    | 14/26 [00:00<00:00, 66.91it/s, train_loss=0.00289, val_loss=0.00363]Epoch 15:  54%|█████▍    | 14/26 [00:00<00:00, 65.51it/s, train_loss=0.00313, val_loss=0.00363]Epoch 15:  58%|█████▊    | 15/26 [00:00<00:00, 67.52it/s, train_loss=0.00313, val_loss=0.00363]Epoch 15:  58%|█████▊    | 15/26 [00:00<00:00, 65.76it/s, train_loss=0.00332, val_loss=0.00363]Epoch 15:  62%|██████▏   | 16/26 [00:00<00:00, 67.10it/s, train_loss=0.00332, val_loss=0.00363]Epoch 15:  62%|██████▏   | 16/26 [00:00<00:00, 65.54it/s, train_loss=0.00323, val_loss=0.00363]Epoch 15:  65%|██████▌   | 17/26 [00:00<00:00, 67.16it/s, train_loss=0.00323, val_loss=0.00363]Epoch 15:  65%|██████▌   | 17/26 [00:00<00:00, 65.71it/s, train_loss=0.0034, val_loss=0.00363] Epoch 15:  69%|██████▉   | 18/26 [00:00<00:00, 66.80it/s, train_loss=0.0034, val_loss=0.00363]Epoch 15:  69%|██████▉   | 18/26 [00:00<00:00, 65.48it/s, train_loss=0.00301, val_loss=0.00363]Epoch 15:  73%|███████▎  | 19/26 [00:00<00:00, 67.01it/s, train_loss=0.00301, val_loss=0.00363]Epoch 15:  73%|███████▎  | 19/26 [00:00<00:00, 65.66it/s, train_loss=0.0032, val_loss=0.00363] Epoch 15:  77%|███████▋  | 20/26 [00:00<00:00, 66.67it/s, train_loss=0.0032, val_loss=0.00363]Epoch 15:  77%|███████▋  | 20/26 [00:00<00:00, 65.54it/s, train_loss=0.00288, val_loss=0.00363]Epoch 15:  81%|████████  | 21/26 [00:00<00:00, 66.92it/s, train_loss=0.00288, val_loss=0.00363]Epoch 15:  81%|████████  | 21/26 [00:00<00:00, 65.67it/s, train_loss=0.00291, val_loss=0.00363]Epoch 15:  85%|████████▍ | 22/26 [00:00<00:00, 66.52it/s, train_loss=0.00291, val_loss=0.00363]Epoch 15:  85%|████████▍ | 22/26 [00:00<00:00, 65.63it/s, train_loss=0.00301, val_loss=0.00363]Epoch 15:  88%|████████▊ | 23/26 [00:00<00:00, 66.86it/s, train_loss=0.00301, val_loss=0.00363]Epoch 15:  88%|████████▊ | 23/26 [00:00<00:00, 65.74it/s, train_loss=0.00304, val_loss=0.00363]Epoch 15:  92%|█████████▏| 24/26 [00:00<00:00, 66.41it/s, train_loss=0.00304, val_loss=0.00363]Epoch 15:  92%|█████████▏| 24/26 [00:00<00:00, 65.71it/s, train_loss=0.00312, val_loss=0.00363]Epoch 15:  96%|█████████▌| 25/26 [00:00<00:00, 66.86it/s, train_loss=0.00312, val_loss=0.00363]Epoch 15:  96%|█████████▌| 25/26 [00:00<00:00, 65.81it/s, train_loss=0.00308, val_loss=0.00363]Epoch 15: 100%|██████████| 26/26 [00:00<00:00, 66.55it/s, train_loss=0.00308, val_loss=0.00363]Epoch 15: 100%|██████████| 26/26 [00:00<00:00, 65.84it/s, train_loss=0.00302, val_loss=0.00363]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 122.71it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 136.52it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 143.76it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 151.15it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 153.31it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 154.27it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 156.32it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 156.79it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 157.60it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 159.24it/s][A
                                                                         [AEpoch 15: 100%|██████████| 26/26 [00:00<00:00, 55.58it/s, train_loss=0.00302, val_loss=0.00347]Epoch 15: 100%|██████████| 26/26 [00:00<00:00, 55.43it/s, train_loss=0.00302, val_loss=0.00347]Epoch 15:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00347]         Epoch 16:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00302, val_loss=0.00347]Epoch 16:   4%|▍         | 1/26 [00:00<00:00, 94.44it/s, train_loss=0.00302, val_loss=0.00347]Epoch 16:   4%|▍         | 1/26 [00:00<00:00, 67.30it/s, train_loss=0.00292, val_loss=0.00347]Epoch 16:   8%|▊         | 2/26 [00:00<00:00, 77.74it/s, train_loss=0.00292, val_loss=0.00347]Epoch 16:   8%|▊         | 2/26 [00:00<00:00, 65.85it/s, train_loss=0.00306, val_loss=0.00347]Epoch 16:  12%|█▏        | 3/26 [00:00<00:00, 77.36it/s, train_loss=0.00306, val_loss=0.00347]Epoch 16:  12%|█▏        | 3/26 [00:00<00:00, 67.04it/s, train_loss=0.00299, val_loss=0.00347]Epoch 16:  15%|█▌        | 4/26 [00:00<00:00, 72.15it/s, train_loss=0.00299, val_loss=0.00347]Epoch 16:  15%|█▌        | 4/26 [00:00<00:00, 65.92it/s, train_loss=0.00289, val_loss=0.00347]Epoch 16:  19%|█▉        | 5/26 [00:00<00:00, 71.96it/s, train_loss=0.00289, val_loss=0.00347]Epoch 16:  19%|█▉        | 5/26 [00:00<00:00, 66.51it/s, train_loss=0.00325, val_loss=0.00347]Epoch 16:  23%|██▎       | 6/26 [00:00<00:00, 69.96it/s, train_loss=0.00325, val_loss=0.00347]Epoch 16:  23%|██▎       | 6/26 [00:00<00:00, 65.95it/s, train_loss=0.00295, val_loss=0.00347]Epoch 16:  27%|██▋       | 7/26 [00:00<00:00, 70.30it/s, train_loss=0.00295, val_loss=0.00347]Epoch 16:  27%|██▋       | 7/26 [00:00<00:00, 66.32it/s, train_loss=0.00293, val_loss=0.00347]Epoch 16:  31%|███       | 8/26 [00:00<00:00, 68.68it/s, train_loss=0.00293, val_loss=0.00347]Epoch 16:  31%|███       | 8/26 [00:00<00:00, 66.17it/s, train_loss=0.00316, val_loss=0.00347]Epoch 16:  35%|███▍      | 9/26 [00:00<00:00, 69.42it/s, train_loss=0.00316, val_loss=0.00347]Epoch 16:  35%|███▍      | 9/26 [00:00<00:00, 66.44it/s, train_loss=0.00277, val_loss=0.00347]Epoch 16:  38%|███▊      | 10/26 [00:00<00:00, 68.31it/s, train_loss=0.00277, val_loss=0.00347]Epoch 16:  38%|███▊      | 10/26 [00:00<00:00, 66.27it/s, train_loss=0.00305, val_loss=0.00347]Epoch 16:  42%|████▏     | 11/26 [00:00<00:00, 68.92it/s, train_loss=0.00305, val_loss=0.00347]Epoch 16:  42%|████▏     | 11/26 [00:00<00:00, 66.45it/s, train_loss=0.00287, val_loss=0.00347]Epoch 16:  46%|████▌     | 12/26 [00:00<00:00, 68.07it/s, train_loss=0.00287, val_loss=0.00347]Epoch 16:  46%|████▌     | 12/26 [00:00<00:00, 66.33it/s, train_loss=0.00307, val_loss=0.00347]Epoch 16:  50%|█████     | 13/26 [00:00<00:00, 68.52it/s, train_loss=0.00307, val_loss=0.00347]Epoch 16:  50%|█████     | 13/26 [00:00<00:00, 66.43it/s, train_loss=0.00298, val_loss=0.00347]Epoch 16:  54%|█████▍    | 14/26 [00:00<00:00, 67.75it/s, train_loss=0.00298, val_loss=0.00347]Epoch 16:  54%|█████▍    | 14/26 [00:00<00:00, 66.31it/s, train_loss=0.0032, val_loss=0.00347] Epoch 16:  58%|█████▊    | 15/26 [00:00<00:00, 68.21it/s, train_loss=0.0032, val_loss=0.00347]Epoch 16:  58%|█████▊    | 15/26 [00:00<00:00, 66.41it/s, train_loss=0.00283, val_loss=0.00347]Epoch 16:  62%|██████▏   | 16/26 [00:00<00:00, 67.58it/s, train_loss=0.00283, val_loss=0.00347]Epoch 16:  62%|██████▏   | 16/26 [00:00<00:00, 66.30it/s, train_loss=0.00341, val_loss=0.00347]Epoch 16:  65%|██████▌   | 17/26 [00:00<00:00, 67.96it/s, train_loss=0.00341, val_loss=0.00347]Epoch 16:  65%|██████▌   | 17/26 [00:00<00:00, 66.39it/s, train_loss=0.00272, val_loss=0.00347]Epoch 16:  69%|██████▉   | 18/26 [00:00<00:00, 67.40it/s, train_loss=0.00272, val_loss=0.00347]Epoch 16:  69%|██████▉   | 18/26 [00:00<00:00, 66.30it/s, train_loss=0.00281, val_loss=0.00347]Epoch 16:  73%|███████▎  | 19/26 [00:00<00:00, 67.65it/s, train_loss=0.00281, val_loss=0.00347]Epoch 16:  73%|███████▎  | 19/26 [00:00<00:00, 66.35it/s, train_loss=0.00309, val_loss=0.00347]Epoch 16:  77%|███████▋  | 20/26 [00:00<00:00, 67.27it/s, train_loss=0.00309, val_loss=0.00347]Epoch 16:  77%|███████▋  | 20/26 [00:00<00:00, 66.27it/s, train_loss=0.00297, val_loss=0.00347]Epoch 16:  81%|████████  | 21/26 [00:00<00:00, 67.65it/s, train_loss=0.00297, val_loss=0.00347]Epoch 16:  81%|████████  | 21/26 [00:00<00:00, 66.41it/s, train_loss=0.00303, val_loss=0.00347]Epoch 16:  85%|████████▍ | 22/26 [00:00<00:00, 67.34it/s, train_loss=0.00303, val_loss=0.00347]Epoch 16:  85%|████████▍ | 22/26 [00:00<00:00, 66.23it/s, train_loss=0.00265, val_loss=0.00347]Epoch 16:  88%|████████▊ | 23/26 [00:00<00:00, 67.53it/s, train_loss=0.00265, val_loss=0.00347]Epoch 16:  88%|████████▊ | 23/26 [00:00<00:00, 66.36it/s, train_loss=0.00273, val_loss=0.00347]Epoch 16:  92%|█████████▏| 24/26 [00:00<00:00, 67.20it/s, train_loss=0.00273, val_loss=0.00347]Epoch 16:  92%|█████████▏| 24/26 [00:00<00:00, 66.19it/s, train_loss=0.0029, val_loss=0.00347] Epoch 16:  96%|█████████▌| 25/26 [00:00<00:00, 67.31it/s, train_loss=0.0029, val_loss=0.00347]Epoch 16:  96%|█████████▌| 25/26 [00:00<00:00, 66.26it/s, train_loss=0.00269, val_loss=0.00347]Epoch 16: 100%|██████████| 26/26 [00:00<00:00, 66.98it/s, train_loss=0.00269, val_loss=0.00347]Epoch 16: 100%|██████████| 26/26 [00:00<00:00, 66.26it/s, train_loss=0.00294, val_loss=0.00347]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 126.53it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 145.29it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 154.31it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 159.13it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 162.37it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 164.41it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 157.80it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 159.24it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 161.37it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 162.07it/s][A
                                                                         [AEpoch 16: 100%|██████████| 26/26 [00:00<00:00, 56.29it/s, train_loss=0.00294, val_loss=0.00328]Epoch 16: 100%|██████████| 26/26 [00:00<00:00, 56.17it/s, train_loss=0.00294, val_loss=0.00328]Epoch 16:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00294, val_loss=0.00328]         Epoch 17:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00294, val_loss=0.00328]Epoch 17:   4%|▍         | 1/26 [00:00<00:00, 85.72it/s, train_loss=0.00294, val_loss=0.00328]Epoch 17:   4%|▍         | 1/26 [00:00<00:00, 63.49it/s, train_loss=0.00282, val_loss=0.00328]Epoch 17:   8%|▊         | 2/26 [00:00<00:00, 76.79it/s, train_loss=0.00282, val_loss=0.00328]Epoch 17:   8%|▊         | 2/26 [00:00<00:00, 61.58it/s, train_loss=0.00291, val_loss=0.00328]Epoch 17:  12%|█▏        | 3/26 [00:00<00:00, 71.20it/s, train_loss=0.00291, val_loss=0.00328]Epoch 17:  12%|█▏        | 3/26 [00:00<00:00, 60.31it/s, train_loss=0.00286, val_loss=0.00328]Epoch 17:  15%|█▌        | 4/26 [00:00<00:00, 65.32it/s, train_loss=0.00286, val_loss=0.00328]Epoch 17:  15%|█▌        | 4/26 [00:00<00:00, 61.43it/s, train_loss=0.00267, val_loss=0.00328]Epoch 17:  19%|█▉        | 5/26 [00:00<00:00, 67.29it/s, train_loss=0.00267, val_loss=0.00328]Epoch 17:  19%|█▉        | 5/26 [00:00<00:00, 60.78it/s, train_loss=0.00291, val_loss=0.00328]Epoch 17:  23%|██▎       | 6/26 [00:00<00:00, 64.59it/s, train_loss=0.00291, val_loss=0.00328]Epoch 17:  23%|██▎       | 6/26 [00:00<00:00, 62.01it/s, train_loss=0.00274, val_loss=0.00328]Epoch 17:  27%|██▋       | 7/26 [00:00<00:00, 66.38it/s, train_loss=0.00274, val_loss=0.00328]Epoch 17:  27%|██▋       | 7/26 [00:00<00:00, 61.71it/s, train_loss=0.00281, val_loss=0.00328]Epoch 17:  31%|███       | 8/26 [00:00<00:00, 64.74it/s, train_loss=0.00281, val_loss=0.00328]Epoch 17:  31%|███       | 8/26 [00:00<00:00, 62.56it/s, train_loss=0.00293, val_loss=0.00328]Epoch 17:  35%|███▍      | 9/26 [00:00<00:00, 65.40it/s, train_loss=0.00293, val_loss=0.00328]Epoch 17:  35%|███▍      | 9/26 [00:00<00:00, 62.26it/s, train_loss=0.0029, val_loss=0.00328] Epoch 17:  38%|███▊      | 10/26 [00:00<00:00, 65.25it/s, train_loss=0.0029, val_loss=0.00328]Epoch 17:  38%|███▊      | 10/26 [00:00<00:00, 62.91it/s, train_loss=0.00303, val_loss=0.00328]Epoch 17:  42%|████▏     | 11/26 [00:00<00:00, 64.87it/s, train_loss=0.00303, val_loss=0.00328]Epoch 17:  42%|████▏     | 11/26 [00:00<00:00, 62.86it/s, train_loss=0.00275, val_loss=0.00328]Epoch 17:  46%|████▌     | 12/26 [00:00<00:00, 65.26it/s, train_loss=0.00275, val_loss=0.00328]Epoch 17:  46%|████▌     | 12/26 [00:00<00:00, 63.31it/s, train_loss=0.00269, val_loss=0.00328]Epoch 17:  50%|█████     | 13/26 [00:00<00:00, 64.92it/s, train_loss=0.00269, val_loss=0.00328]Epoch 17:  50%|█████     | 13/26 [00:00<00:00, 63.30it/s, train_loss=0.00261, val_loss=0.00328]Epoch 17:  54%|█████▍    | 14/26 [00:00<00:00, 65.40it/s, train_loss=0.00261, val_loss=0.00328]Epoch 17:  54%|█████▍    | 14/26 [00:00<00:00, 63.67it/s, train_loss=0.00237, val_loss=0.00328]Epoch 17:  58%|█████▊    | 15/26 [00:00<00:00, 65.01it/s, train_loss=0.00237, val_loss=0.00328]Epoch 17:  58%|█████▊    | 15/26 [00:00<00:00, 63.62it/s, train_loss=0.00268, val_loss=0.00328]Epoch 17:  62%|██████▏   | 16/26 [00:00<00:00, 65.41it/s, train_loss=0.00268, val_loss=0.00328]Epoch 17:  62%|██████▏   | 16/26 [00:00<00:00, 63.87it/s, train_loss=0.0027, val_loss=0.00328] Epoch 17:  65%|██████▌   | 17/26 [00:00<00:00, 64.92it/s, train_loss=0.0027, val_loss=0.00328]Epoch 17:  65%|██████▌   | 17/26 [00:00<00:00, 63.93it/s, train_loss=0.00272, val_loss=0.00328]Epoch 17:  69%|██████▉   | 18/26 [00:00<00:00, 65.44it/s, train_loss=0.00272, val_loss=0.00328]Epoch 17:  69%|██████▉   | 18/26 [00:00<00:00, 64.11it/s, train_loss=0.00343, val_loss=0.00328]Epoch 17:  73%|███████▎  | 19/26 [00:00<00:00, 65.17it/s, train_loss=0.00343, val_loss=0.00328]Epoch 17:  73%|███████▎  | 19/26 [00:00<00:00, 64.15it/s, train_loss=0.00274, val_loss=0.00328]Epoch 17:  77%|███████▋  | 20/26 [00:00<00:00, 65.55it/s, train_loss=0.00274, val_loss=0.00328]Epoch 17:  77%|███████▋  | 20/26 [00:00<00:00, 64.32it/s, train_loss=0.00269, val_loss=0.00328]Epoch 17:  81%|████████  | 21/26 [00:00<00:00, 65.25it/s, train_loss=0.00269, val_loss=0.00328]Epoch 17:  81%|████████  | 21/26 [00:00<00:00, 64.34it/s, train_loss=0.00267, val_loss=0.00328]Epoch 17:  85%|████████▍ | 22/26 [00:00<00:00, 65.62it/s, train_loss=0.00267, val_loss=0.00328]Epoch 17:  85%|████████▍ | 22/26 [00:00<00:00, 64.48it/s, train_loss=0.00306, val_loss=0.00328]Epoch 17:  88%|████████▊ | 23/26 [00:00<00:00, 65.27it/s, train_loss=0.00306, val_loss=0.00328]Epoch 17:  88%|████████▊ | 23/26 [00:00<00:00, 64.49it/s, train_loss=0.00309, val_loss=0.00328]Epoch 17:  92%|█████████▏| 24/26 [00:00<00:00, 65.64it/s, train_loss=0.00309, val_loss=0.00328]Epoch 17:  92%|█████████▏| 24/26 [00:00<00:00, 64.59it/s, train_loss=0.00282, val_loss=0.00328]Epoch 17:  96%|█████████▌| 25/26 [00:00<00:00, 65.43it/s, train_loss=0.00282, val_loss=0.00328]Epoch 17:  96%|█████████▌| 25/26 [00:00<00:00, 64.59it/s, train_loss=0.00271, val_loss=0.00328]Epoch 17: 100%|██████████| 26/26 [00:00<00:00, 65.72it/s, train_loss=0.00271, val_loss=0.00328]Epoch 17: 100%|██████████| 26/26 [00:00<00:00, 64.81it/s, train_loss=0.0027, val_loss=0.00328] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 150.27it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 165.22it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 168.29it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 170.73it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 173.83it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 176.85it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 177.14it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 177.80it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 177.16it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 178.27it/s][A
                                                                         [AEpoch 17: 100%|██████████| 26/26 [00:00<00:00, 55.96it/s, train_loss=0.0027, val_loss=0.00315]Epoch 17: 100%|██████████| 26/26 [00:00<00:00, 55.85it/s, train_loss=0.0027, val_loss=0.00315]Epoch 17:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0027, val_loss=0.00315]         Epoch 18:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0027, val_loss=0.00315]Epoch 18:   4%|▍         | 1/26 [00:00<00:00, 88.60it/s, train_loss=0.0027, val_loss=0.00315]Epoch 18:   4%|▍         | 1/26 [00:00<00:00, 65.28it/s, train_loss=0.00274, val_loss=0.00315]Epoch 18:   8%|▊         | 2/26 [00:00<00:00, 72.74it/s, train_loss=0.00274, val_loss=0.00315]Epoch 18:   8%|▊         | 2/26 [00:00<00:00, 62.79it/s, train_loss=0.00276, val_loss=0.00315]Epoch 18:  12%|█▏        | 3/26 [00:00<00:00, 73.17it/s, train_loss=0.00276, val_loss=0.00315]Epoch 18:  12%|█▏        | 3/26 [00:00<00:00, 64.29it/s, train_loss=0.00266, val_loss=0.00315]Epoch 18:  15%|█▌        | 4/26 [00:00<00:00, 69.47it/s, train_loss=0.00266, val_loss=0.00315]Epoch 18:  15%|█▌        | 4/26 [00:00<00:00, 64.30it/s, train_loss=0.00262, val_loss=0.00315]Epoch 18:  19%|█▉        | 5/26 [00:00<00:00, 70.16it/s, train_loss=0.00262, val_loss=0.00315]Epoch 18:  19%|█▉        | 5/26 [00:00<00:00, 64.96it/s, train_loss=0.00268, val_loss=0.00315]Epoch 18:  23%|██▎       | 6/26 [00:00<00:00, 68.21it/s, train_loss=0.00268, val_loss=0.00315]Epoch 18:  23%|██▎       | 6/26 [00:00<00:00, 64.96it/s, train_loss=0.0025, val_loss=0.00315] Epoch 18:  27%|██▋       | 7/26 [00:00<00:00, 69.08it/s, train_loss=0.0025, val_loss=0.00315]Epoch 18:  27%|██▋       | 7/26 [00:00<00:00, 65.32it/s, train_loss=0.00289, val_loss=0.00315]Epoch 18:  31%|███       | 8/26 [00:00<00:00, 67.68it/s, train_loss=0.00289, val_loss=0.00315]Epoch 18:  31%|███       | 8/26 [00:00<00:00, 65.29it/s, train_loss=0.00278, val_loss=0.00315]Epoch 18:  35%|███▍      | 9/26 [00:00<00:00, 68.38it/s, train_loss=0.00278, val_loss=0.00315]Epoch 18:  35%|███▍      | 9/26 [00:00<00:00, 65.51it/s, train_loss=0.00319, val_loss=0.00315]Epoch 18:  38%|███▊      | 10/26 [00:00<00:00, 67.42it/s, train_loss=0.00319, val_loss=0.00315]Epoch 18:  38%|███▊      | 10/26 [00:00<00:00, 65.43it/s, train_loss=0.00298, val_loss=0.00315]Epoch 18:  42%|████▏     | 11/26 [00:00<00:00, 68.19it/s, train_loss=0.00298, val_loss=0.00315]Epoch 18:  42%|████▏     | 11/26 [00:00<00:00, 65.78it/s, train_loss=0.00282, val_loss=0.00315]Epoch 18:  46%|████▌     | 12/26 [00:00<00:00, 67.61it/s, train_loss=0.00282, val_loss=0.00315]Epoch 18:  46%|████▌     | 12/26 [00:00<00:00, 65.47it/s, train_loss=0.00268, val_loss=0.00315]Epoch 18:  50%|█████     | 13/26 [00:00<00:00, 67.73it/s, train_loss=0.00268, val_loss=0.00315]Epoch 18:  50%|█████     | 13/26 [00:00<00:00, 65.73it/s, train_loss=0.00246, val_loss=0.00315]Epoch 18:  54%|█████▍    | 14/26 [00:00<00:00, 67.19it/s, train_loss=0.00246, val_loss=0.00315]Epoch 18:  54%|█████▍    | 14/26 [00:00<00:00, 65.46it/s, train_loss=0.0027, val_loss=0.00315] Epoch 18:  58%|█████▊    | 15/26 [00:00<00:00, 67.37it/s, train_loss=0.0027, val_loss=0.00315]Epoch 18:  58%|█████▊    | 15/26 [00:00<00:00, 65.65it/s, train_loss=0.00254, val_loss=0.00315]Epoch 18:  62%|██████▏   | 16/26 [00:00<00:00, 66.93it/s, train_loss=0.00254, val_loss=0.00315]Epoch 18:  62%|██████▏   | 16/26 [00:00<00:00, 65.49it/s, train_loss=0.00254, val_loss=0.00315]Epoch 18:  65%|██████▌   | 17/26 [00:00<00:00, 67.24it/s, train_loss=0.00254, val_loss=0.00315]Epoch 18:  65%|██████▌   | 17/26 [00:00<00:00, 65.69it/s, train_loss=0.00267, val_loss=0.00315]Epoch 18:  69%|██████▉   | 18/26 [00:00<00:00, 66.79it/s, train_loss=0.00267, val_loss=0.00315]Epoch 18:  69%|██████▉   | 18/26 [00:00<00:00, 65.52it/s, train_loss=0.00278, val_loss=0.00315]Epoch 18:  73%|███████▎  | 19/26 [00:00<00:00, 67.05it/s, train_loss=0.00278, val_loss=0.00315]Epoch 18:  73%|███████▎  | 19/26 [00:00<00:00, 65.67it/s, train_loss=0.00298, val_loss=0.00315]Epoch 18:  77%|███████▋  | 20/26 [00:00<00:00, 66.48it/s, train_loss=0.00298, val_loss=0.00315]Epoch 18:  77%|███████▋  | 20/26 [00:00<00:00, 65.53it/s, train_loss=0.00292, val_loss=0.00315]Epoch 18:  81%|████████  | 21/26 [00:00<00:00, 66.84it/s, train_loss=0.00292, val_loss=0.00315]Epoch 18:  81%|████████  | 21/26 [00:00<00:00, 65.61it/s, train_loss=0.00257, val_loss=0.00315]Epoch 18:  85%|████████▍ | 22/26 [00:00<00:00, 66.48it/s, train_loss=0.00257, val_loss=0.00315]Epoch 18:  85%|████████▍ | 22/26 [00:00<00:00, 65.57it/s, train_loss=0.00289, val_loss=0.00315]Epoch 18:  88%|████████▊ | 23/26 [00:00<00:00, 66.75it/s, train_loss=0.00289, val_loss=0.00315]Epoch 18:  88%|████████▊ | 23/26 [00:00<00:00, 65.65it/s, train_loss=0.00241, val_loss=0.00315]Epoch 18:  92%|█████████▏| 24/26 [00:00<00:00, 66.36it/s, train_loss=0.00241, val_loss=0.00315]Epoch 18:  92%|█████████▏| 24/26 [00:00<00:00, 65.61it/s, train_loss=0.00285, val_loss=0.00315]Epoch 18:  96%|█████████▌| 25/26 [00:00<00:00, 66.67it/s, train_loss=0.00285, val_loss=0.00315]Epoch 18:  96%|█████████▌| 25/26 [00:00<00:00, 65.67it/s, train_loss=0.00253, val_loss=0.00315]Epoch 18: 100%|██████████| 26/26 [00:00<00:00, 66.31it/s, train_loss=0.00253, val_loss=0.00315]Epoch 18: 100%|██████████| 26/26 [00:00<00:00, 65.68it/s, train_loss=0.00262, val_loss=0.00315]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 115.78it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 132.16it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 140.54it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 152.25it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 162.79it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 170.25it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 175.45it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 176.65it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 179.09it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 182.36it/s][A
                                                                         [AEpoch 18: 100%|██████████| 26/26 [00:00<00:00, 56.64it/s, train_loss=0.00262, val_loss=0.00308]Epoch 18: 100%|██████████| 26/26 [00:00<00:00, 56.54it/s, train_loss=0.00262, val_loss=0.00308]Epoch 18:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00262, val_loss=0.00308]         Epoch 19:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00262, val_loss=0.00308]Epoch 19:   4%|▍         | 1/26 [00:00<00:00, 89.68it/s, train_loss=0.00262, val_loss=0.00308]Epoch 19:   4%|▍         | 1/26 [00:00<00:00, 65.76it/s, train_loss=0.00271, val_loss=0.00308]Epoch 19:   8%|▊         | 2/26 [00:00<00:00, 84.06it/s, train_loss=0.00271, val_loss=0.00308]Epoch 19:   8%|▊         | 2/26 [00:00<00:00, 62.61it/s, train_loss=0.0026, val_loss=0.00308] Epoch 19:  12%|█▏        | 3/26 [00:00<00:00, 71.51it/s, train_loss=0.0026, val_loss=0.00308]Epoch 19:  12%|█▏        | 3/26 [00:00<00:00, 64.44it/s, train_loss=0.00293, val_loss=0.00308]Epoch 19:  15%|█▌        | 4/26 [00:00<00:00, 69.67it/s, train_loss=0.00293, val_loss=0.00308]Epoch 19:  15%|█▌        | 4/26 [00:00<00:00, 62.93it/s, train_loss=0.00292, val_loss=0.00308]Epoch 19:  19%|█▉        | 5/26 [00:00<00:00, 69.05it/s, train_loss=0.00292, val_loss=0.00308]Epoch 19:  19%|█▉        | 5/26 [00:00<00:00, 64.00it/s, train_loss=0.00263, val_loss=0.00308]Epoch 19:  23%|██▎       | 6/26 [00:00<00:00, 67.51it/s, train_loss=0.00263, val_loss=0.00308]Epoch 19:  23%|██▎       | 6/26 [00:00<00:00, 63.71it/s, train_loss=0.0023, val_loss=0.00308] Epoch 19:  27%|██▋       | 7/26 [00:00<00:00, 67.99it/s, train_loss=0.0023, val_loss=0.00308]Epoch 19:  27%|██▋       | 7/26 [00:00<00:00, 64.31it/s, train_loss=0.00238, val_loss=0.00308]Epoch 19:  31%|███       | 8/26 [00:00<00:00, 66.77it/s, train_loss=0.00238, val_loss=0.00308]Epoch 19:  31%|███       | 8/26 [00:00<00:00, 64.39it/s, train_loss=0.00239, val_loss=0.00308]Epoch 19:  35%|███▍      | 9/26 [00:00<00:00, 67.57it/s, train_loss=0.00239, val_loss=0.00308]Epoch 19:  35%|███▍      | 9/26 [00:00<00:00, 64.72it/s, train_loss=0.00264, val_loss=0.00308]Epoch 19:  38%|███▊      | 10/26 [00:00<00:00, 66.63it/s, train_loss=0.00264, val_loss=0.00308]Epoch 19:  38%|███▊      | 10/26 [00:00<00:00, 64.73it/s, train_loss=0.00253, val_loss=0.00308]Epoch 19:  42%|████▏     | 11/26 [00:00<00:00, 67.26it/s, train_loss=0.00253, val_loss=0.00308]Epoch 19:  42%|████▏     | 11/26 [00:00<00:00, 64.94it/s, train_loss=0.00293, val_loss=0.00308]Epoch 19:  46%|████▌     | 12/26 [00:00<00:00, 66.52it/s, train_loss=0.00293, val_loss=0.00308]Epoch 19:  46%|████▌     | 12/26 [00:00<00:00, 64.91it/s, train_loss=0.00252, val_loss=0.00308]Epoch 19:  50%|█████     | 13/26 [00:00<00:00, 67.01it/s, train_loss=0.00252, val_loss=0.00308]Epoch 19:  50%|█████     | 13/26 [00:00<00:00, 65.09it/s, train_loss=0.00277, val_loss=0.00308]Epoch 19:  54%|█████▍    | 14/26 [00:00<00:00, 66.25it/s, train_loss=0.00277, val_loss=0.00308]Epoch 19:  54%|█████▍    | 14/26 [00:00<00:00, 65.08it/s, train_loss=0.00266, val_loss=0.00308]Epoch 19:  58%|█████▊    | 15/26 [00:00<00:00, 67.01it/s, train_loss=0.00266, val_loss=0.00308]Epoch 19:  58%|█████▊    | 15/26 [00:00<00:00, 65.24it/s, train_loss=0.00272, val_loss=0.00308]Epoch 19:  62%|██████▏   | 16/26 [00:00<00:00, 66.66it/s, train_loss=0.00272, val_loss=0.00308]Epoch 19:  62%|██████▏   | 16/26 [00:00<00:00, 65.18it/s, train_loss=0.00305, val_loss=0.00308]Epoch 19:  65%|██████▌   | 17/26 [00:00<00:00, 66.88it/s, train_loss=0.00305, val_loss=0.00308]Epoch 19:  65%|██████▌   | 17/26 [00:00<00:00, 65.32it/s, train_loss=0.00241, val_loss=0.00308]Epoch 19:  69%|██████▉   | 18/26 [00:00<00:00, 66.54it/s, train_loss=0.00241, val_loss=0.00308]Epoch 19:  69%|██████▉   | 18/26 [00:00<00:00, 65.27it/s, train_loss=0.00244, val_loss=0.00308]Epoch 19:  73%|███████▎  | 19/26 [00:00<00:00, 66.82it/s, train_loss=0.00244, val_loss=0.00308]Epoch 19:  73%|███████▎  | 19/26 [00:00<00:00, 65.47it/s, train_loss=0.00235, val_loss=0.00308]Epoch 19:  77%|███████▋  | 20/26 [00:00<00:00, 66.46it/s, train_loss=0.00235, val_loss=0.00308]Epoch 19:  77%|███████▋  | 20/26 [00:00<00:00, 65.31it/s, train_loss=0.0023, val_loss=0.00308] Epoch 19:  81%|████████  | 21/26 [00:00<00:00, 66.58it/s, train_loss=0.0023, val_loss=0.00308]Epoch 19:  81%|████████  | 21/26 [00:00<00:00, 65.41it/s, train_loss=0.00286, val_loss=0.00308]Epoch 19:  85%|████████▍ | 22/26 [00:00<00:00, 66.25it/s, train_loss=0.00286, val_loss=0.00308]Epoch 19:  85%|████████▍ | 22/26 [00:00<00:00, 65.37it/s, train_loss=0.00262, val_loss=0.00308]Epoch 19:  88%|████████▊ | 23/26 [00:00<00:00, 66.62it/s, train_loss=0.00262, val_loss=0.00308]Epoch 19:  88%|████████▊ | 23/26 [00:00<00:00, 65.49it/s, train_loss=0.00271, val_loss=0.00308]Epoch 19:  92%|█████████▏| 24/26 [00:00<00:00, 66.30it/s, train_loss=0.00271, val_loss=0.00308]Epoch 19:  92%|█████████▏| 24/26 [00:00<00:00, 65.46it/s, train_loss=0.00249, val_loss=0.00308]Epoch 19:  96%|█████████▌| 25/26 [00:00<00:00, 66.58it/s, train_loss=0.00249, val_loss=0.00308]Epoch 19:  96%|█████████▌| 25/26 [00:00<00:00, 65.56it/s, train_loss=0.00237, val_loss=0.00308]Epoch 19: 100%|██████████| 26/26 [00:00<00:00, 66.30it/s, train_loss=0.00237, val_loss=0.00308]Epoch 19: 100%|██████████| 26/26 [00:00<00:00, 65.58it/s, train_loss=0.00243, val_loss=0.00308]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 122.09it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 141.29it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 144.23it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 149.06it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 151.59it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 153.85it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 156.16it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 158.13it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 157.64it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 158.49it/s][A
                                                                         [AEpoch 19: 100%|██████████| 26/26 [00:00<00:00, 55.48it/s, train_loss=0.00243, val_loss=0.00288]Epoch 19: 100%|██████████| 26/26 [00:00<00:00, 55.34it/s, train_loss=0.00243, val_loss=0.00288]Epoch 19:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00243, val_loss=0.00288]         Epoch 20:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00243, val_loss=0.00288]Epoch 20:   4%|▍         | 1/26 [00:00<00:00, 90.43it/s, train_loss=0.00243, val_loss=0.00288]Epoch 20:   4%|▍         | 1/26 [00:00<00:00, 65.68it/s, train_loss=0.00254, val_loss=0.00288]Epoch 20:   8%|▊         | 2/26 [00:00<00:00, 78.03it/s, train_loss=0.00254, val_loss=0.00288]Epoch 20:   8%|▊         | 2/26 [00:00<00:00, 63.99it/s, train_loss=0.00255, val_loss=0.00288]Epoch 20:  12%|█▏        | 3/26 [00:00<00:00, 74.60it/s, train_loss=0.00255, val_loss=0.00288]Epoch 20:  12%|█▏        | 3/26 [00:00<00:00, 65.54it/s, train_loss=0.00254, val_loss=0.00288]Epoch 20:  15%|█▌        | 4/26 [00:00<00:00, 70.87it/s, train_loss=0.00254, val_loss=0.00288]Epoch 20:  15%|█▌        | 4/26 [00:00<00:00, 64.63it/s, train_loss=0.00262, val_loss=0.00288]Epoch 20:  19%|█▉        | 5/26 [00:00<00:00, 70.77it/s, train_loss=0.00262, val_loss=0.00288]Epoch 20:  19%|█▉        | 5/26 [00:00<00:00, 65.46it/s, train_loss=0.00215, val_loss=0.00288]Epoch 20:  23%|██▎       | 6/26 [00:00<00:00, 68.38it/s, train_loss=0.00215, val_loss=0.00288]Epoch 20:  23%|██▎       | 6/26 [00:00<00:00, 64.96it/s, train_loss=0.0022, val_loss=0.00288] Epoch 20:  27%|██▋       | 7/26 [00:00<00:00, 69.09it/s, train_loss=0.0022, val_loss=0.00288]Epoch 20:  27%|██▋       | 7/26 [00:00<00:00, 65.48it/s, train_loss=0.00272, val_loss=0.00288]Epoch 20:  31%|███       | 8/26 [00:00<00:00, 67.91it/s, train_loss=0.00272, val_loss=0.00288]Epoch 20:  31%|███       | 8/26 [00:00<00:00, 65.05it/s, train_loss=0.00238, val_loss=0.00288]Epoch 20:  35%|███▍      | 9/26 [00:00<00:00, 68.26it/s, train_loss=0.00238, val_loss=0.00288]Epoch 20:  35%|███▍      | 9/26 [00:00<00:00, 65.37it/s, train_loss=0.00236, val_loss=0.00288]Epoch 20:  38%|███▊      | 10/26 [00:00<00:00, 67.38it/s, train_loss=0.00236, val_loss=0.00288]Epoch 20:  38%|███▊      | 10/26 [00:00<00:00, 65.26it/s, train_loss=0.00276, val_loss=0.00288]Epoch 20:  42%|████▏     | 11/26 [00:00<00:00, 67.84it/s, train_loss=0.00276, val_loss=0.00288]Epoch 20:  42%|████▏     | 11/26 [00:00<00:00, 65.48it/s, train_loss=0.0024, val_loss=0.00288] Epoch 20:  46%|████▌     | 12/26 [00:00<00:00, 67.01it/s, train_loss=0.0024, val_loss=0.00288]Epoch 20:  46%|████▌     | 12/26 [00:00<00:00, 65.40it/s, train_loss=0.00254, val_loss=0.00288]Epoch 20:  50%|█████     | 13/26 [00:00<00:00, 67.56it/s, train_loss=0.00254, val_loss=0.00288]Epoch 20:  50%|█████     | 13/26 [00:00<00:00, 65.59it/s, train_loss=0.00258, val_loss=0.00288]Epoch 20:  54%|█████▍    | 14/26 [00:00<00:00, 66.91it/s, train_loss=0.00258, val_loss=0.00288]Epoch 20:  54%|█████▍    | 14/26 [00:00<00:00, 65.52it/s, train_loss=0.00244, val_loss=0.00288]Epoch 20:  58%|█████▊    | 15/26 [00:00<00:00, 67.46it/s, train_loss=0.00244, val_loss=0.00288]Epoch 20:  58%|█████▊    | 15/26 [00:00<00:00, 65.66it/s, train_loss=0.00252, val_loss=0.00288]Epoch 20:  62%|██████▏   | 16/26 [00:00<00:00, 66.84it/s, train_loss=0.00252, val_loss=0.00288]Epoch 20:  62%|██████▏   | 16/26 [00:00<00:00, 65.61it/s, train_loss=0.00247, val_loss=0.00288]Epoch 20:  65%|██████▌   | 17/26 [00:00<00:00, 67.27it/s, train_loss=0.00247, val_loss=0.00288]Epoch 20:  65%|██████▌   | 17/26 [00:00<00:00, 65.73it/s, train_loss=0.00222, val_loss=0.00288]Epoch 20:  69%|██████▉   | 18/26 [00:00<00:00, 66.74it/s, train_loss=0.00222, val_loss=0.00288]Epoch 20:  69%|██████▉   | 18/26 [00:00<00:00, 65.66it/s, train_loss=0.00263, val_loss=0.00288]Epoch 20:  73%|███████▎  | 19/26 [00:00<00:00, 67.09it/s, train_loss=0.00263, val_loss=0.00288]Epoch 20:  73%|███████▎  | 19/26 [00:00<00:00, 65.75it/s, train_loss=0.00234, val_loss=0.00288]Epoch 20:  77%|███████▋  | 20/26 [00:00<00:00, 66.68it/s, train_loss=0.00234, val_loss=0.00288]Epoch 20:  77%|███████▋  | 20/26 [00:00<00:00, 65.70it/s, train_loss=0.00232, val_loss=0.00288]Epoch 20:  81%|████████  | 21/26 [00:00<00:00, 67.13it/s, train_loss=0.00232, val_loss=0.00288]Epoch 20:  81%|████████  | 21/26 [00:00<00:00, 65.89it/s, train_loss=0.00249, val_loss=0.00288]Epoch 20:  85%|████████▍ | 22/26 [00:00<00:00, 66.79it/s, train_loss=0.00249, val_loss=0.00288]Epoch 20:  85%|████████▍ | 22/26 [00:00<00:00, 65.70it/s, train_loss=0.00237, val_loss=0.00288]Epoch 20:  88%|████████▊ | 23/26 [00:00<00:00, 66.93it/s, train_loss=0.00237, val_loss=0.00288]Epoch 20:  88%|████████▊ | 23/26 [00:00<00:00, 65.83it/s, train_loss=0.00219, val_loss=0.00288]Epoch 20:  92%|█████████▏| 24/26 [00:00<00:00, 66.58it/s, train_loss=0.00219, val_loss=0.00288]Epoch 20:  92%|█████████▏| 24/26 [00:00<00:00, 65.67it/s, train_loss=0.00225, val_loss=0.00288]Epoch 20:  96%|█████████▌| 25/26 [00:00<00:00, 66.66it/s, train_loss=0.00225, val_loss=0.00288]Epoch 20:  96%|█████████▌| 25/26 [00:00<00:00, 65.68it/s, train_loss=0.0025, val_loss=0.00288] Epoch 20: 100%|██████████| 26/26 [00:00<00:00, 66.37it/s, train_loss=0.0025, val_loss=0.00288]Epoch 20: 100%|██████████| 26/26 [00:00<00:00, 65.69it/s, train_loss=0.00268, val_loss=0.00288]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 132.81it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 150.12it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 156.10it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 161.11it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 165.04it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 167.61it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 167.93it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 168.87it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 169.90it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 171.40it/s][A
                                                                         [AEpoch 20: 100%|██████████| 26/26 [00:00<00:00, 56.21it/s, train_loss=0.00268, val_loss=0.00284]Epoch 20: 100%|██████████| 26/26 [00:00<00:00, 56.08it/s, train_loss=0.00268, val_loss=0.00284]Epoch 20:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00268, val_loss=0.00284]         Epoch 21:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00268, val_loss=0.00284]Epoch 21:   4%|▍         | 1/26 [00:00<00:00, 86.02it/s, train_loss=0.00268, val_loss=0.00284]Epoch 21:   4%|▍         | 1/26 [00:00<00:00, 55.68it/s, train_loss=0.00232, val_loss=0.00284]Epoch 21:   8%|▊         | 2/26 [00:00<00:00, 72.27it/s, train_loss=0.00232, val_loss=0.00284]Epoch 21:   8%|▊         | 2/26 [00:00<00:00, 61.10it/s, train_loss=0.00199, val_loss=0.00284]Epoch 21:  12%|█▏        | 3/26 [00:00<00:00, 69.15it/s, train_loss=0.00199, val_loss=0.00284]Epoch 21:  12%|█▏        | 3/26 [00:00<00:00, 61.58it/s, train_loss=0.00246, val_loss=0.00284]Epoch 21:  15%|█▌        | 4/26 [00:00<00:00, 69.36it/s, train_loss=0.00246, val_loss=0.00284]Epoch 21:  15%|█▌        | 4/26 [00:00<00:00, 62.96it/s, train_loss=0.00223, val_loss=0.00284]Epoch 21:  19%|█▉        | 5/26 [00:00<00:00, 67.12it/s, train_loss=0.00223, val_loss=0.00284]Epoch 21:  19%|█▉        | 5/26 [00:00<00:00, 63.24it/s, train_loss=0.00233, val_loss=0.00284]Epoch 21:  23%|██▎       | 6/26 [00:00<00:00, 68.02it/s, train_loss=0.00233, val_loss=0.00284]Epoch 21:  23%|██▎       | 6/26 [00:00<00:00, 63.84it/s, train_loss=0.00235, val_loss=0.00284]Epoch 21:  27%|██▋       | 7/26 [00:00<00:00, 66.87it/s, train_loss=0.00235, val_loss=0.00284]Epoch 21:  27%|██▋       | 7/26 [00:00<00:00, 63.91it/s, train_loss=0.00245, val_loss=0.00284]Epoch 21:  31%|███       | 8/26 [00:00<00:00, 67.46it/s, train_loss=0.00245, val_loss=0.00284]Epoch 21:  31%|███       | 8/26 [00:00<00:00, 64.53it/s, train_loss=0.00253, val_loss=0.00284]Epoch 21:  35%|███▍      | 9/26 [00:00<00:00, 66.66it/s, train_loss=0.00253, val_loss=0.00284]Epoch 21:  35%|███▍      | 9/26 [00:00<00:00, 64.23it/s, train_loss=0.00239, val_loss=0.00284]Epoch 21:  38%|███▊      | 10/26 [00:00<00:00, 67.14it/s, train_loss=0.00239, val_loss=0.00284]Epoch 21:  38%|███▊      | 10/26 [00:00<00:00, 64.57it/s, train_loss=0.00249, val_loss=0.00284]Epoch 21:  42%|████▏     | 11/26 [00:00<00:00, 66.29it/s, train_loss=0.00249, val_loss=0.00284]Epoch 21:  42%|████▏     | 11/26 [00:00<00:00, 64.51it/s, train_loss=0.0021, val_loss=0.00284] Epoch 21:  46%|████▌     | 12/26 [00:00<00:00, 66.90it/s, train_loss=0.0021, val_loss=0.00284]Epoch 21:  46%|████▌     | 12/26 [00:00<00:00, 64.79it/s, train_loss=0.00262, val_loss=0.00284]Epoch 21:  50%|█████     | 13/26 [00:00<00:00, 66.21it/s, train_loss=0.00262, val_loss=0.00284]Epoch 21:  50%|█████     | 13/26 [00:00<00:00, 64.64it/s, train_loss=0.00255, val_loss=0.00284]Epoch 21:  54%|█████▍    | 14/26 [00:00<00:00, 66.64it/s, train_loss=0.00255, val_loss=0.00284]Epoch 21:  54%|█████▍    | 14/26 [00:00<00:00, 64.86it/s, train_loss=0.00223, val_loss=0.00284]Epoch 21:  58%|█████▊    | 15/26 [00:00<00:00, 66.26it/s, train_loss=0.00223, val_loss=0.00284]Epoch 21:  58%|█████▊    | 15/26 [00:00<00:00, 64.83it/s, train_loss=0.00247, val_loss=0.00284]Epoch 21:  62%|██████▏   | 16/26 [00:00<00:00, 66.60it/s, train_loss=0.00247, val_loss=0.00284]Epoch 21:  62%|██████▏   | 16/26 [00:00<00:00, 64.97it/s, train_loss=0.00241, val_loss=0.00284]Epoch 21:  65%|██████▌   | 17/26 [00:00<00:00, 66.12it/s, train_loss=0.00241, val_loss=0.00284]Epoch 21:  65%|██████▌   | 17/26 [00:00<00:00, 64.97it/s, train_loss=0.00234, val_loss=0.00284]Epoch 21:  69%|██████▉   | 18/26 [00:00<00:00, 66.56it/s, train_loss=0.00234, val_loss=0.00284]Epoch 21:  69%|██████▉   | 18/26 [00:00<00:00, 65.12it/s, train_loss=0.00243, val_loss=0.00284]Epoch 21:  73%|███████▎  | 19/26 [00:00<00:00, 66.10it/s, train_loss=0.00243, val_loss=0.00284]Epoch 21:  73%|███████▎  | 19/26 [00:00<00:00, 65.09it/s, train_loss=0.00207, val_loss=0.00284]Epoch 21:  77%|███████▋  | 20/26 [00:00<00:00, 66.52it/s, train_loss=0.00207, val_loss=0.00284]Epoch 21:  77%|███████▋  | 20/26 [00:00<00:00, 65.22it/s, train_loss=0.0023, val_loss=0.00284] Epoch 21:  81%|████████  | 21/26 [00:00<00:00, 66.12it/s, train_loss=0.0023, val_loss=0.00284]Epoch 21:  81%|████████  | 21/26 [00:00<00:00, 65.18it/s, train_loss=0.00236, val_loss=0.00284]Epoch 21:  85%|████████▍ | 22/26 [00:00<00:00, 66.45it/s, train_loss=0.00236, val_loss=0.00284]Epoch 21:  85%|████████▍ | 22/26 [00:00<00:00, 65.27it/s, train_loss=0.0026, val_loss=0.00284] Epoch 21:  88%|████████▊ | 23/26 [00:00<00:00, 66.07it/s, train_loss=0.0026, val_loss=0.00284]Epoch 21:  88%|████████▊ | 23/26 [00:00<00:00, 65.24it/s, train_loss=0.00249, val_loss=0.00284]Epoch 21:  92%|█████████▏| 24/26 [00:00<00:00, 66.39it/s, train_loss=0.00249, val_loss=0.00284]Epoch 21:  92%|█████████▏| 24/26 [00:00<00:00, 65.31it/s, train_loss=0.00239, val_loss=0.00284]Epoch 21:  96%|█████████▌| 25/26 [00:00<00:00, 66.07it/s, train_loss=0.00239, val_loss=0.00284]Epoch 21:  96%|█████████▌| 25/26 [00:00<00:00, 64.54it/s, train_loss=0.00246, val_loss=0.00284]Epoch 21: 100%|██████████| 26/26 [00:00<00:00, 65.18it/s, train_loss=0.00246, val_loss=0.00284]Epoch 21: 100%|██████████| 26/26 [00:00<00:00, 64.66it/s, train_loss=0.00242, val_loss=0.00284]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 146.86it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 165.93it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 178.21it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 183.95it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 188.02it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 183.78it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 183.88it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 186.71it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 186.78it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 187.36it/s][A
                                                                         [AEpoch 21: 100%|██████████| 26/26 [00:00<00:00, 56.06it/s, train_loss=0.00242, val_loss=0.00269]Epoch 21: 100%|██████████| 26/26 [00:00<00:00, 55.96it/s, train_loss=0.00242, val_loss=0.00269]Epoch 21:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00242, val_loss=0.00269]         Epoch 22:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00242, val_loss=0.00269]Epoch 22:   4%|▍         | 1/26 [00:00<00:00, 85.59it/s, train_loss=0.00242, val_loss=0.00269]Epoch 22:   4%|▍         | 1/26 [00:00<00:00, 65.80it/s, train_loss=0.00228, val_loss=0.00269]Epoch 22:   8%|▊         | 2/26 [00:00<00:00, 83.60it/s, train_loss=0.00228, val_loss=0.00269]Epoch 22:   8%|▊         | 2/26 [00:00<00:00, 66.93it/s, train_loss=0.00234, val_loss=0.00269]Epoch 22:  12%|█▏        | 3/26 [00:00<00:00, 73.46it/s, train_loss=0.00234, val_loss=0.00269]Epoch 22:  12%|█▏        | 3/26 [00:00<00:00, 65.54it/s, train_loss=0.00258, val_loss=0.00269]Epoch 22:  15%|█▌        | 4/26 [00:00<00:00, 73.05it/s, train_loss=0.00258, val_loss=0.00269]Epoch 22:  15%|█▌        | 4/26 [00:00<00:00, 66.08it/s, train_loss=0.00235, val_loss=0.00269]Epoch 22:  19%|█▉        | 5/26 [00:00<00:00, 70.10it/s, train_loss=0.00235, val_loss=0.00269]Epoch 22:  19%|█▉        | 5/26 [00:00<00:00, 65.74it/s, train_loss=0.00261, val_loss=0.00269]Epoch 22:  23%|██▎       | 6/26 [00:00<00:00, 70.75it/s, train_loss=0.00261, val_loss=0.00269]Epoch 22:  23%|██▎       | 6/26 [00:00<00:00, 66.04it/s, train_loss=0.0022, val_loss=0.00269] Epoch 22:  27%|██▋       | 7/26 [00:00<00:00, 68.66it/s, train_loss=0.0022, val_loss=0.00269]Epoch 22:  27%|██▋       | 7/26 [00:00<00:00, 65.84it/s, train_loss=0.00236, val_loss=0.00269]Epoch 22:  31%|███       | 8/26 [00:00<00:00, 69.44it/s, train_loss=0.00236, val_loss=0.00269]Epoch 22:  31%|███       | 8/26 [00:00<00:00, 66.00it/s, train_loss=0.00223, val_loss=0.00269]Epoch 22:  35%|███▍      | 9/26 [00:00<00:00, 68.03it/s, train_loss=0.00223, val_loss=0.00269]Epoch 22:  35%|███▍      | 9/26 [00:00<00:00, 65.82it/s, train_loss=0.00236, val_loss=0.00269]Epoch 22:  38%|███▊      | 10/26 [00:00<00:00, 68.68it/s, train_loss=0.00236, val_loss=0.00269]Epoch 22:  38%|███▊      | 10/26 [00:00<00:00, 65.94it/s, train_loss=0.00218, val_loss=0.00269]Epoch 22:  42%|████▏     | 11/26 [00:00<00:00, 67.65it/s, train_loss=0.00218, val_loss=0.00269]Epoch 22:  42%|████▏     | 11/26 [00:00<00:00, 65.79it/s, train_loss=0.00212, val_loss=0.00269]Epoch 22:  46%|████▌     | 12/26 [00:00<00:00, 68.27it/s, train_loss=0.00212, val_loss=0.00269]Epoch 22:  46%|████▌     | 12/26 [00:00<00:00, 66.06it/s, train_loss=0.0022, val_loss=0.00269] Epoch 22:  50%|█████     | 13/26 [00:00<00:00, 67.60it/s, train_loss=0.0022, val_loss=0.00269]Epoch 22:  50%|█████     | 13/26 [00:00<00:00, 65.73it/s, train_loss=0.00235, val_loss=0.00269]Epoch 22:  54%|█████▍    | 14/26 [00:00<00:00, 67.73it/s, train_loss=0.00235, val_loss=0.00269]Epoch 22:  54%|█████▍    | 14/26 [00:00<00:00, 65.91it/s, train_loss=0.00223, val_loss=0.00269]Epoch 22:  58%|█████▊    | 15/26 [00:00<00:00, 67.24it/s, train_loss=0.00223, val_loss=0.00269]Epoch 22:  58%|█████▊    | 15/26 [00:00<00:00, 65.65it/s, train_loss=0.00252, val_loss=0.00269]Epoch 22:  62%|██████▏   | 16/26 [00:00<00:00, 67.49it/s, train_loss=0.00252, val_loss=0.00269]Epoch 22:  62%|██████▏   | 16/26 [00:00<00:00, 65.82it/s, train_loss=0.00216, val_loss=0.00269]Epoch 22:  65%|██████▌   | 17/26 [00:00<00:00, 66.99it/s, train_loss=0.00216, val_loss=0.00269]Epoch 22:  65%|██████▌   | 17/26 [00:00<00:00, 65.63it/s, train_loss=0.00225, val_loss=0.00269]Epoch 22:  69%|██████▉   | 18/26 [00:00<00:00, 67.24it/s, train_loss=0.00225, val_loss=0.00269]Epoch 22:  69%|██████▉   | 18/26 [00:00<00:00, 65.75it/s, train_loss=0.00217, val_loss=0.00269]Epoch 22:  73%|███████▎  | 19/26 [00:00<00:00, 66.75it/s, train_loss=0.00217, val_loss=0.00269]Epoch 22:  73%|███████▎  | 19/26 [00:00<00:00, 65.59it/s, train_loss=0.00227, val_loss=0.00269]Epoch 22:  77%|███████▋  | 20/26 [00:00<00:00, 66.98it/s, train_loss=0.00227, val_loss=0.00269]Epoch 22:  77%|███████▋  | 20/26 [00:00<00:00, 65.68it/s, train_loss=0.00243, val_loss=0.00269]Epoch 22:  81%|████████  | 21/26 [00:00<00:00, 66.53it/s, train_loss=0.00243, val_loss=0.00269]Epoch 22:  81%|████████  | 21/26 [00:00<00:00, 65.63it/s, train_loss=0.00232, val_loss=0.00269]Epoch 22:  85%|████████▍ | 22/26 [00:00<00:00, 66.92it/s, train_loss=0.00232, val_loss=0.00269]Epoch 22:  85%|████████▍ | 22/26 [00:00<00:00, 65.71it/s, train_loss=0.00217, val_loss=0.00269]Epoch 22:  88%|████████▊ | 23/26 [00:00<00:00, 66.53it/s, train_loss=0.00217, val_loss=0.00269]Epoch 22:  88%|████████▊ | 23/26 [00:00<00:00, 65.65it/s, train_loss=0.00224, val_loss=0.00269]Epoch 22:  92%|█████████▏| 24/26 [00:00<00:00, 66.83it/s, train_loss=0.00224, val_loss=0.00269]Epoch 22:  92%|█████████▏| 24/26 [00:00<00:00, 65.71it/s, train_loss=0.00243, val_loss=0.00269]Epoch 22:  96%|█████████▌| 25/26 [00:00<00:00, 66.44it/s, train_loss=0.00243, val_loss=0.00269]Epoch 22:  96%|█████████▌| 25/26 [00:00<00:00, 65.65it/s, train_loss=0.00221, val_loss=0.00269]Epoch 22: 100%|██████████| 26/26 [00:00<00:00, 66.71it/s, train_loss=0.00221, val_loss=0.00269]Epoch 22: 100%|██████████| 26/26 [00:00<00:00, 65.75it/s, train_loss=0.0022, val_loss=0.00269] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 116.09it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 132.39it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 143.72it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 144.06it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 146.89it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 150.71it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 153.91it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 158.64it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 162.55it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 166.64it/s][A
                                                                         [AEpoch 22: 100%|██████████| 26/26 [00:00<00:00, 56.12it/s, train_loss=0.0022, val_loss=0.00271]Epoch 22: 100%|██████████| 26/26 [00:00<00:00, 56.03it/s, train_loss=0.0022, val_loss=0.00271]Epoch 22:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0022, val_loss=0.00271]         Epoch 23:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0022, val_loss=0.00271]Epoch 23:   4%|▍         | 1/26 [00:00<00:00, 87.66it/s, train_loss=0.0022, val_loss=0.00271]Epoch 23:   4%|▍         | 1/26 [00:00<00:00, 64.96it/s, train_loss=0.0023, val_loss=0.00271]Epoch 23:   8%|▊         | 2/26 [00:00<00:00, 83.70it/s, train_loss=0.0023, val_loss=0.00271]Epoch 23:   8%|▊         | 2/26 [00:00<00:00, 62.12it/s, train_loss=0.0023, val_loss=0.00271]Epoch 23:  12%|█▏        | 3/26 [00:00<00:00, 69.86it/s, train_loss=0.0023, val_loss=0.00271]Epoch 23:  12%|█▏        | 3/26 [00:00<00:00, 63.84it/s, train_loss=0.00207, val_loss=0.00271]Epoch 23:  15%|█▌        | 4/26 [00:00<00:00, 70.31it/s, train_loss=0.00207, val_loss=0.00271]Epoch 23:  15%|█▌        | 4/26 [00:00<00:00, 62.54it/s, train_loss=0.0023, val_loss=0.00271] Epoch 23:  19%|█▉        | 5/26 [00:00<00:00, 68.71it/s, train_loss=0.0023, val_loss=0.00271]Epoch 23:  19%|█▉        | 5/26 [00:00<00:00, 63.65it/s, train_loss=0.00228, val_loss=0.00271]Epoch 23:  23%|██▎       | 6/26 [00:00<00:00, 67.08it/s, train_loss=0.00228, val_loss=0.00271]Epoch 23:  23%|██▎       | 6/26 [00:00<00:00, 63.35it/s, train_loss=0.00219, val_loss=0.00271]Epoch 23:  27%|██▋       | 7/26 [00:00<00:00, 67.68it/s, train_loss=0.00219, val_loss=0.00271]Epoch 23:  27%|██▋       | 7/26 [00:00<00:00, 63.98it/s, train_loss=0.0025, val_loss=0.00271] Epoch 23:  31%|███       | 8/26 [00:00<00:00, 66.64it/s, train_loss=0.0025, val_loss=0.00271]Epoch 23:  31%|███       | 8/26 [00:00<00:00, 63.82it/s, train_loss=0.00252, val_loss=0.00271]Epoch 23:  35%|███▍      | 9/26 [00:00<00:00, 67.07it/s, train_loss=0.00252, val_loss=0.00271]Epoch 23:  35%|███▍      | 9/26 [00:00<00:00, 64.23it/s, train_loss=0.00234, val_loss=0.00271]Epoch 23:  38%|███▊      | 10/26 [00:00<00:00, 66.18it/s, train_loss=0.00234, val_loss=0.00271]Epoch 23:  38%|███▊      | 10/26 [00:00<00:00, 64.22it/s, train_loss=0.00208, val_loss=0.00271]Epoch 23:  42%|████▏     | 11/26 [00:00<00:00, 66.82it/s, train_loss=0.00208, val_loss=0.00271]Epoch 23:  42%|████▏     | 11/26 [00:00<00:00, 64.48it/s, train_loss=0.00201, val_loss=0.00271]Epoch 23:  46%|████▌     | 12/26 [00:00<00:00, 66.06it/s, train_loss=0.00201, val_loss=0.00271]Epoch 23:  46%|████▌     | 12/26 [00:00<00:00, 64.47it/s, train_loss=0.00238, val_loss=0.00271]Epoch 23:  50%|█████     | 13/26 [00:00<00:00, 66.72it/s, train_loss=0.00238, val_loss=0.00271]Epoch 23:  50%|█████     | 13/26 [00:00<00:00, 64.70it/s, train_loss=0.002, val_loss=0.00271]  Epoch 23:  54%|█████▍    | 14/26 [00:00<00:00, 66.10it/s, train_loss=0.002, val_loss=0.00271]Epoch 23:  54%|█████▍    | 14/26 [00:00<00:00, 64.65it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  58%|█████▊    | 15/26 [00:00<00:00, 66.25it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  58%|█████▊    | 15/26 [00:00<00:00, 64.64it/s, train_loss=0.00248, val_loss=0.00271]Epoch 23:  62%|██████▏   | 16/26 [00:00<00:00, 65.78it/s, train_loss=0.00248, val_loss=0.00271]Epoch 23:  62%|██████▏   | 16/26 [00:00<00:00, 64.63it/s, train_loss=0.00195, val_loss=0.00271]Epoch 23:  65%|██████▌   | 17/26 [00:00<00:00, 66.20it/s, train_loss=0.00195, val_loss=0.00271]Epoch 23:  65%|██████▌   | 17/26 [00:00<00:00, 64.75it/s, train_loss=0.0023, val_loss=0.00271] Epoch 23:  69%|██████▉   | 18/26 [00:00<00:00, 65.79it/s, train_loss=0.0023, val_loss=0.00271]Epoch 23:  69%|██████▉   | 18/26 [00:00<00:00, 64.72it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  73%|███████▎  | 19/26 [00:00<00:00, 66.28it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  73%|███████▎  | 19/26 [00:00<00:00, 64.92it/s, train_loss=0.00236, val_loss=0.00271]Epoch 23:  77%|███████▋  | 20/26 [00:00<00:00, 65.94it/s, train_loss=0.00236, val_loss=0.00271]Epoch 23:  77%|███████▋  | 20/26 [00:00<00:00, 64.77it/s, train_loss=0.00226, val_loss=0.00271]Epoch 23:  81%|████████  | 21/26 [00:00<00:00, 66.15it/s, train_loss=0.00226, val_loss=0.00271]Epoch 23:  81%|████████  | 21/26 [00:00<00:00, 64.93it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  85%|████████▍ | 22/26 [00:00<00:00, 65.80it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  85%|████████▍ | 22/26 [00:00<00:00, 64.82it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  88%|████████▊ | 23/26 [00:00<00:00, 66.07it/s, train_loss=0.00221, val_loss=0.00271]Epoch 23:  88%|████████▊ | 23/26 [00:00<00:00, 64.95it/s, train_loss=0.00216, val_loss=0.00271]Epoch 23:  92%|█████████▏| 24/26 [00:00<00:00, 65.79it/s, train_loss=0.00216, val_loss=0.00271]Epoch 23:  92%|█████████▏| 24/26 [00:00<00:00, 64.86it/s, train_loss=0.00235, val_loss=0.00271]Epoch 23:  96%|█████████▌| 25/26 [00:00<00:00, 66.00it/s, train_loss=0.00235, val_loss=0.00271]Epoch 23:  96%|█████████▌| 25/26 [00:00<00:00, 64.97it/s, train_loss=0.00239, val_loss=0.00271]Epoch 23: 100%|██████████| 26/26 [00:00<00:00, 65.68it/s, train_loss=0.00239, val_loss=0.00271]Epoch 23: 100%|██████████| 26/26 [00:00<00:00, 65.01it/s, train_loss=0.00204, val_loss=0.00271]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 124.21it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 142.39it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 145.70it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 149.17it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 154.66it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 154.36it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 155.93it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 158.36it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 159.61it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 159.09it/s][A
                                                                         [AEpoch 23: 100%|██████████| 26/26 [00:00<00:00, 55.20it/s, train_loss=0.00204, val_loss=0.0026] Epoch 23: 100%|██████████| 26/26 [00:00<00:00, 55.08it/s, train_loss=0.00204, val_loss=0.0026]Epoch 23:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00204, val_loss=0.0026]         Epoch 24:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00204, val_loss=0.0026]Epoch 24:   4%|▍         | 1/26 [00:00<00:00, 85.67it/s, train_loss=0.00204, val_loss=0.0026]Epoch 24:   4%|▍         | 1/26 [00:00<00:00, 63.52it/s, train_loss=0.00238, val_loss=0.0026]Epoch 24:   8%|▊         | 2/26 [00:00<00:00, 77.46it/s, train_loss=0.00238, val_loss=0.0026]Epoch 24:   8%|▊         | 2/26 [00:00<00:00, 61.27it/s, train_loss=0.00227, val_loss=0.0026]Epoch 24:  12%|█▏        | 3/26 [00:00<00:00, 72.49it/s, train_loss=0.00227, val_loss=0.0026]Epoch 24:  12%|█▏        | 3/26 [00:00<00:00, 63.78it/s, train_loss=0.00241, val_loss=0.0026]Epoch 24:  15%|█▌        | 4/26 [00:00<00:00, 70.59it/s, train_loss=0.00241, val_loss=0.0026]Epoch 24:  15%|█▌        | 4/26 [00:00<00:00, 62.93it/s, train_loss=0.00214, val_loss=0.0026]Epoch 24:  19%|█▉        | 5/26 [00:00<00:00, 69.30it/s, train_loss=0.00214, val_loss=0.0026]Epoch 24:  19%|█▉        | 5/26 [00:00<00:00, 64.13it/s, train_loss=0.00208, val_loss=0.0026]Epoch 24:  23%|██▎       | 6/26 [00:00<00:00, 67.84it/s, train_loss=0.00208, val_loss=0.0026]Epoch 24:  23%|██▎       | 6/26 [00:00<00:00, 63.67it/s, train_loss=0.00226, val_loss=0.0026]Epoch 24:  27%|██▋       | 7/26 [00:00<00:00, 67.85it/s, train_loss=0.00226, val_loss=0.0026]Epoch 24:  27%|██▋       | 7/26 [00:00<00:00, 64.29it/s, train_loss=0.00239, val_loss=0.0026]Epoch 24:  31%|███       | 8/26 [00:00<00:00, 66.77it/s, train_loss=0.00239, val_loss=0.0026]Epoch 24:  31%|███       | 8/26 [00:00<00:00, 63.98it/s, train_loss=0.00234, val_loss=0.0026]Epoch 24:  35%|███▍      | 9/26 [00:00<00:00, 67.17it/s, train_loss=0.00234, val_loss=0.0026]Epoch 24:  35%|███▍      | 9/26 [00:00<00:00, 64.42it/s, train_loss=0.00183, val_loss=0.0026]Epoch 24:  38%|███▊      | 10/26 [00:00<00:00, 66.43it/s, train_loss=0.00183, val_loss=0.0026]Epoch 24:  38%|███▊      | 10/26 [00:00<00:00, 64.15it/s, train_loss=0.00197, val_loss=0.0026]Epoch 24:  42%|████▏     | 11/26 [00:00<00:00, 66.99it/s, train_loss=0.00197, val_loss=0.0026]Epoch 24:  42%|████▏     | 11/26 [00:00<00:00, 64.52it/s, train_loss=0.00223, val_loss=0.0026]Epoch 24:  46%|████▌     | 12/26 [00:00<00:00, 66.48it/s, train_loss=0.00223, val_loss=0.0026]Epoch 24:  46%|████▌     | 12/26 [00:00<00:00, 64.30it/s, train_loss=0.00242, val_loss=0.0026]Epoch 24:  50%|█████     | 13/26 [00:00<00:00, 66.62it/s, train_loss=0.00242, val_loss=0.0026]Epoch 24:  50%|█████     | 13/26 [00:00<00:00, 64.57it/s, train_loss=0.00218, val_loss=0.0026]Epoch 24:  54%|█████▍    | 14/26 [00:00<00:00, 66.17it/s, train_loss=0.00218, val_loss=0.0026]Epoch 24:  54%|█████▍    | 14/26 [00:00<00:00, 64.47it/s, train_loss=0.00225, val_loss=0.0026]Epoch 24:  58%|█████▊    | 15/26 [00:00<00:00, 66.42it/s, train_loss=0.00225, val_loss=0.0026]Epoch 24:  58%|█████▊    | 15/26 [00:00<00:00, 64.69it/s, train_loss=0.00207, val_loss=0.0026]Epoch 24:  62%|██████▏   | 16/26 [00:00<00:00, 66.05it/s, train_loss=0.00207, val_loss=0.0026]Epoch 24:  62%|██████▏   | 16/26 [00:00<00:00, 64.58it/s, train_loss=0.00206, val_loss=0.0026]Epoch 24:  65%|██████▌   | 17/26 [00:00<00:00, 66.36it/s, train_loss=0.00206, val_loss=0.0026]Epoch 24:  65%|██████▌   | 17/26 [00:00<00:00, 64.76it/s, train_loss=0.00224, val_loss=0.0026]Epoch 24:  69%|██████▉   | 18/26 [00:00<00:00, 65.93it/s, train_loss=0.00224, val_loss=0.0026]Epoch 24:  69%|██████▉   | 18/26 [00:00<00:00, 64.68it/s, train_loss=0.00218, val_loss=0.0026]Epoch 24:  73%|███████▎  | 19/26 [00:00<00:00, 66.15it/s, train_loss=0.00218, val_loss=0.0026]Epoch 24:  73%|███████▎  | 19/26 [00:00<00:00, 64.82it/s, train_loss=0.00231, val_loss=0.0026]Epoch 24:  77%|███████▋  | 20/26 [00:00<00:00, 65.80it/s, train_loss=0.00231, val_loss=0.0026]Epoch 24:  77%|███████▋  | 20/26 [00:00<00:00, 64.80it/s, train_loss=0.00195, val_loss=0.0026]Epoch 24:  81%|████████  | 21/26 [00:00<00:00, 66.11it/s, train_loss=0.00195, val_loss=0.0026]Epoch 24:  81%|████████  | 21/26 [00:00<00:00, 64.90it/s, train_loss=0.00223, val_loss=0.0026]Epoch 24:  85%|████████▍ | 22/26 [00:00<00:00, 65.68it/s, train_loss=0.00223, val_loss=0.0026]Epoch 24:  85%|████████▍ | 22/26 [00:00<00:00, 64.87it/s, train_loss=0.00217, val_loss=0.0026]Epoch 24:  88%|████████▊ | 23/26 [00:00<00:00, 65.43it/s, train_loss=0.00217, val_loss=0.0026]Epoch 24:  88%|████████▊ | 23/26 [00:00<00:00, 64.26it/s, train_loss=0.002, val_loss=0.0026]  Epoch 24:  92%|█████████▏| 24/26 [00:00<00:00, 65.47it/s, train_loss=0.002, val_loss=0.0026]Epoch 24:  92%|█████████▏| 24/26 [00:00<00:00, 64.43it/s, train_loss=0.00194, val_loss=0.0026]Epoch 24:  96%|█████████▌| 25/26 [00:00<00:00, 65.48it/s, train_loss=0.00194, val_loss=0.0026]Epoch 24:  96%|█████████▌| 25/26 [00:00<00:00, 64.28it/s, train_loss=0.00228, val_loss=0.0026]Epoch 24: 100%|██████████| 26/26 [00:00<00:00, 65.44it/s, train_loss=0.00228, val_loss=0.0026]Epoch 24: 100%|██████████| 26/26 [00:00<00:00, 64.49it/s, train_loss=0.00195, val_loss=0.0026]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 140.31it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 158.40it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 166.77it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 163.48it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 169.58it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 168.75it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 170.19it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 169.68it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 172.13it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 171.49it/s][A
                                                                         [AEpoch 24: 100%|██████████| 26/26 [00:00<00:00, 55.18it/s, train_loss=0.00195, val_loss=0.00255]Epoch 24: 100%|██████████| 26/26 [00:00<00:00, 55.08it/s, train_loss=0.00195, val_loss=0.00255]Epoch 24:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00195, val_loss=0.00255]         Epoch 25:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00195, val_loss=0.00255]Epoch 25:   4%|▍         | 1/26 [00:00<00:00, 87.88it/s, train_loss=0.00195, val_loss=0.00255]Epoch 25:   4%|▍         | 1/26 [00:00<00:00, 64.34it/s, train_loss=0.00221, val_loss=0.00255]Epoch 25:   8%|▊         | 2/26 [00:00<00:00, 78.89it/s, train_loss=0.00221, val_loss=0.00255]Epoch 25:   8%|▊         | 2/26 [00:00<00:00, 61.43it/s, train_loss=0.0021, val_loss=0.00255] Epoch 25:  12%|█▏        | 3/26 [00:00<00:00, 72.08it/s, train_loss=0.0021, val_loss=0.00255]Epoch 25:  12%|█▏        | 3/26 [00:00<00:00, 63.30it/s, train_loss=0.00213, val_loss=0.00255]Epoch 25:  15%|█▌        | 4/26 [00:00<00:00, 68.67it/s, train_loss=0.00213, val_loss=0.00255]Epoch 25:  15%|█▌        | 4/26 [00:00<00:00, 63.58it/s, train_loss=0.002, val_loss=0.00255]  Epoch 25:  19%|█▉        | 5/26 [00:00<00:00, 69.48it/s, train_loss=0.002, val_loss=0.00255]Epoch 25:  19%|█▉        | 5/26 [00:00<00:00, 64.33it/s, train_loss=0.00202, val_loss=0.00255]Epoch 25:  23%|██▎       | 6/26 [00:00<00:00, 67.48it/s, train_loss=0.00202, val_loss=0.00255]Epoch 25:  23%|██▎       | 6/26 [00:00<00:00, 64.31it/s, train_loss=0.00211, val_loss=0.00255]Epoch 25:  27%|██▋       | 7/26 [00:00<00:00, 68.21it/s, train_loss=0.00211, val_loss=0.00255]Epoch 25:  27%|██▋       | 7/26 [00:00<00:00, 64.66it/s, train_loss=0.00211, val_loss=0.00255]Epoch 25:  31%|███       | 8/26 [00:00<00:00, 67.06it/s, train_loss=0.00211, val_loss=0.00255]Epoch 25:  31%|███       | 8/26 [00:00<00:00, 64.62it/s, train_loss=0.00235, val_loss=0.00255]Epoch 25:  35%|███▍      | 9/26 [00:00<00:00, 68.00it/s, train_loss=0.00235, val_loss=0.00255]Epoch 25:  35%|███▍      | 9/26 [00:00<00:00, 65.10it/s, train_loss=0.00237, val_loss=0.00255]Epoch 25:  38%|███▊      | 10/26 [00:00<00:00, 67.30it/s, train_loss=0.00237, val_loss=0.00255]Epoch 25:  38%|███▊      | 10/26 [00:00<00:00, 64.73it/s, train_loss=0.00215, val_loss=0.00255]Epoch 25:  42%|████▏     | 11/26 [00:00<00:00, 67.40it/s, train_loss=0.00215, val_loss=0.00255]Epoch 25:  42%|████▏     | 11/26 [00:00<00:00, 65.08it/s, train_loss=0.00199, val_loss=0.00255]Epoch 25:  46%|████▌     | 12/26 [00:00<00:00, 66.96it/s, train_loss=0.00199, val_loss=0.00255]Epoch 25:  46%|████▌     | 12/26 [00:00<00:00, 64.80it/s, train_loss=0.00206, val_loss=0.00255]Epoch 25:  50%|█████     | 13/26 [00:00<00:00, 67.10it/s, train_loss=0.00206, val_loss=0.00255]Epoch 25:  50%|█████     | 13/26 [00:00<00:00, 65.07it/s, train_loss=0.002, val_loss=0.00255]  Epoch 25:  54%|█████▍    | 14/26 [00:00<00:00, 66.52it/s, train_loss=0.002, val_loss=0.00255]Epoch 25:  54%|█████▍    | 14/26 [00:00<00:00, 64.83it/s, train_loss=0.00191, val_loss=0.00255]Epoch 25:  58%|█████▊    | 15/26 [00:00<00:00, 66.81it/s, train_loss=0.00191, val_loss=0.00255]Epoch 25:  58%|█████▊    | 15/26 [00:00<00:00, 65.06it/s, train_loss=0.0023, val_loss=0.00255] Epoch 25:  62%|██████▏   | 16/26 [00:00<00:00, 66.33it/s, train_loss=0.0023, val_loss=0.00255]Epoch 25:  62%|██████▏   | 16/26 [00:00<00:00, 64.87it/s, train_loss=0.00216, val_loss=0.00255]Epoch 25:  65%|██████▌   | 17/26 [00:00<00:00, 66.38it/s, train_loss=0.00216, val_loss=0.00255]Epoch 25:  65%|██████▌   | 17/26 [00:00<00:00, 64.97it/s, train_loss=0.00228, val_loss=0.00255]Epoch 25:  69%|██████▉   | 18/26 [00:00<00:00, 66.02it/s, train_loss=0.00228, val_loss=0.00255]Epoch 25:  69%|██████▉   | 18/26 [00:00<00:00, 64.92it/s, train_loss=0.00224, val_loss=0.00255]Epoch 25:  73%|███████▎  | 19/26 [00:00<00:00, 66.44it/s, train_loss=0.00224, val_loss=0.00255]Epoch 25:  73%|███████▎  | 19/26 [00:00<00:00, 65.06it/s, train_loss=0.00212, val_loss=0.00255]Epoch 25:  77%|███████▋  | 20/26 [00:00<00:00, 66.02it/s, train_loss=0.00212, val_loss=0.00255]Epoch 25:  77%|███████▋  | 20/26 [00:00<00:00, 65.01it/s, train_loss=0.00209, val_loss=0.00255]Epoch 25:  81%|████████  | 21/26 [00:00<00:00, 66.35it/s, train_loss=0.00209, val_loss=0.00255]Epoch 25:  81%|████████  | 21/26 [00:00<00:00, 65.12it/s, train_loss=0.00192, val_loss=0.00255]Epoch 25:  85%|████████▍ | 22/26 [00:00<00:00, 66.02it/s, train_loss=0.00192, val_loss=0.00255]Epoch 25:  85%|████████▍ | 22/26 [00:00<00:00, 65.09it/s, train_loss=0.00211, val_loss=0.00255]Epoch 25:  88%|████████▊ | 23/26 [00:00<00:00, 66.35it/s, train_loss=0.00211, val_loss=0.00255]Epoch 25:  88%|████████▊ | 23/26 [00:00<00:00, 65.21it/s, train_loss=0.00214, val_loss=0.00255]Epoch 25:  92%|█████████▏| 24/26 [00:00<00:00, 65.96it/s, train_loss=0.00214, val_loss=0.00255]Epoch 25:  92%|█████████▏| 24/26 [00:00<00:00, 65.18it/s, train_loss=0.00213, val_loss=0.00255]Epoch 25:  96%|█████████▌| 25/26 [00:00<00:00, 66.30it/s, train_loss=0.00213, val_loss=0.00255]Epoch 25:  96%|█████████▌| 25/26 [00:00<00:00, 65.25it/s, train_loss=0.00223, val_loss=0.00255]Epoch 25: 100%|██████████| 26/26 [00:00<00:00, 65.97it/s, train_loss=0.00223, val_loss=0.00255]Epoch 25: 100%|██████████| 26/26 [00:00<00:00, 65.28it/s, train_loss=0.0022, val_loss=0.00255] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 155.29it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 173.17it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 185.17it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 192.79it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 195.83it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 198.89it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 200.14it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 196.09it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 194.99it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 196.66it/s][A
                                                                         [AEpoch 25: 100%|██████████| 26/26 [00:00<00:00, 57.05it/s, train_loss=0.0022, val_loss=0.00247]Epoch 25: 100%|██████████| 26/26 [00:00<00:00, 56.94it/s, train_loss=0.0022, val_loss=0.00247]Epoch 25:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0022, val_loss=0.00247]         Epoch 26:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0022, val_loss=0.00247]Epoch 26:   4%|▍         | 1/26 [00:00<00:00, 85.02it/s, train_loss=0.0022, val_loss=0.00247]Epoch 26:   4%|▍         | 1/26 [00:00<00:00, 63.25it/s, train_loss=0.00201, val_loss=0.00247]Epoch 26:   8%|▊         | 2/26 [00:00<00:00, 76.90it/s, train_loss=0.00201, val_loss=0.00247]Epoch 26:   8%|▊         | 2/26 [00:00<00:00, 59.89it/s, train_loss=0.00215, val_loss=0.00247]Epoch 26:  12%|█▏        | 3/26 [00:00<00:00, 71.33it/s, train_loss=0.00215, val_loss=0.00247]Epoch 26:  12%|█▏        | 3/26 [00:00<00:00, 62.42it/s, train_loss=0.00226, val_loss=0.00247]Epoch 26:  15%|█▌        | 4/26 [00:00<00:00, 68.19it/s, train_loss=0.00226, val_loss=0.00247]Epoch 26:  15%|█▌        | 4/26 [00:00<00:00, 62.33it/s, train_loss=0.00209, val_loss=0.00247]Epoch 26:  19%|█▉        | 5/26 [00:00<00:00, 68.51it/s, train_loss=0.00209, val_loss=0.00247]Epoch 26:  19%|█▉        | 5/26 [00:00<00:00, 63.37it/s, train_loss=0.00207, val_loss=0.00247]Epoch 26:  23%|██▎       | 6/26 [00:00<00:00, 66.85it/s, train_loss=0.00207, val_loss=0.00247]Epoch 26:  23%|██▎       | 6/26 [00:00<00:00, 63.25it/s, train_loss=0.00215, val_loss=0.00247]Epoch 26:  27%|██▋       | 7/26 [00:00<00:00, 67.47it/s, train_loss=0.00215, val_loss=0.00247]Epoch 26:  27%|██▋       | 7/26 [00:00<00:00, 63.81it/s, train_loss=0.0022, val_loss=0.00247] Epoch 26:  31%|███       | 8/26 [00:00<00:00, 66.23it/s, train_loss=0.0022, val_loss=0.00247]Epoch 26:  31%|███       | 8/26 [00:00<00:00, 63.87it/s, train_loss=0.00206, val_loss=0.00247]Epoch 26:  35%|███▍      | 9/26 [00:00<00:00, 67.18it/s, train_loss=0.00206, val_loss=0.00247]Epoch 26:  35%|███▍      | 9/26 [00:00<00:00, 64.27it/s, train_loss=0.00206, val_loss=0.00247]Epoch 26:  38%|███▊      | 10/26 [00:00<00:00, 66.35it/s, train_loss=0.00206, val_loss=0.00247]Epoch 26:  38%|███▊      | 10/26 [00:00<00:00, 64.26it/s, train_loss=0.00222, val_loss=0.00247]Epoch 26:  42%|████▏     | 11/26 [00:00<00:00, 66.86it/s, train_loss=0.00222, val_loss=0.00247]Epoch 26:  42%|████▏     | 11/26 [00:00<00:00, 64.53it/s, train_loss=0.00236, val_loss=0.00247]Epoch 26:  46%|████▌     | 12/26 [00:00<00:00, 66.04it/s, train_loss=0.00236, val_loss=0.00247]Epoch 26:  46%|████▌     | 12/26 [00:00<00:00, 64.51it/s, train_loss=0.00203, val_loss=0.00247]Epoch 26:  50%|█████     | 13/26 [00:00<00:00, 66.60it/s, train_loss=0.00203, val_loss=0.00247]Epoch 26:  50%|█████     | 13/26 [00:00<00:00, 64.65it/s, train_loss=0.0022, val_loss=0.00247] Epoch 26:  54%|█████▍    | 14/26 [00:00<00:00, 66.03it/s, train_loss=0.0022, val_loss=0.00247]Epoch 26:  54%|█████▍    | 14/26 [00:00<00:00, 64.60it/s, train_loss=0.00202, val_loss=0.00247]Epoch 26:  58%|█████▊    | 15/26 [00:00<00:00, 66.59it/s, train_loss=0.00202, val_loss=0.00247]Epoch 26:  58%|█████▊    | 15/26 [00:00<00:00, 64.85it/s, train_loss=0.00191, val_loss=0.00247]Epoch 26:  62%|██████▏   | 16/26 [00:00<00:00, 66.23it/s, train_loss=0.00191, val_loss=0.00247]Epoch 26:  62%|██████▏   | 16/26 [00:00<00:00, 64.66it/s, train_loss=0.00213, val_loss=0.00247]Epoch 26:  65%|██████▌   | 17/26 [00:00<00:00, 66.45it/s, train_loss=0.00213, val_loss=0.00247]Epoch 26:  65%|██████▌   | 17/26 [00:00<00:00, 64.90it/s, train_loss=0.00214, val_loss=0.00247]Epoch 26:  69%|██████▉   | 18/26 [00:00<00:00, 66.08it/s, train_loss=0.00214, val_loss=0.00247]Epoch 26:  69%|██████▉   | 18/26 [00:00<00:00, 64.73it/s, train_loss=0.00213, val_loss=0.00247]Epoch 26:  73%|███████▎  | 19/26 [00:00<00:00, 66.19it/s, train_loss=0.00213, val_loss=0.00247]Epoch 26:  73%|███████▎  | 19/26 [00:00<00:00, 64.85it/s, train_loss=0.00193, val_loss=0.00247]Epoch 26:  77%|███████▋  | 20/26 [00:00<00:00, 65.91it/s, train_loss=0.00193, val_loss=0.00247]Epoch 26:  77%|███████▋  | 20/26 [00:00<00:00, 64.82it/s, train_loss=0.00217, val_loss=0.00247]Epoch 26:  81%|████████  | 21/26 [00:00<00:00, 66.24it/s, train_loss=0.00217, val_loss=0.00247]Epoch 26:  81%|████████  | 21/26 [00:00<00:00, 64.99it/s, train_loss=0.00189, val_loss=0.00247]Epoch 26:  85%|████████▍ | 22/26 [00:00<00:00, 65.94it/s, train_loss=0.00189, val_loss=0.00247]Epoch 26:  85%|████████▍ | 22/26 [00:00<00:00, 64.87it/s, train_loss=0.00215, val_loss=0.00247]Epoch 26:  88%|████████▊ | 23/26 [00:00<00:00, 66.02it/s, train_loss=0.00215, val_loss=0.00247]Epoch 26:  88%|████████▊ | 23/26 [00:00<00:00, 64.47it/s, train_loss=0.00218, val_loss=0.00247]Epoch 26:  92%|█████████▏| 24/26 [00:00<00:00, 65.32it/s, train_loss=0.00218, val_loss=0.00247]Epoch 26:  92%|█████████▏| 24/26 [00:00<00:00, 64.61it/s, train_loss=0.00224, val_loss=0.00247]Epoch 26:  96%|█████████▌| 25/26 [00:00<00:00, 65.59it/s, train_loss=0.00224, val_loss=0.00247]Epoch 26:  96%|█████████▌| 25/26 [00:00<00:00, 64.37it/s, train_loss=0.00207, val_loss=0.00247]Epoch 26: 100%|██████████| 26/26 [00:00<00:00, 65.46it/s, train_loss=0.00207, val_loss=0.00247]Epoch 26: 100%|██████████| 26/26 [00:00<00:00, 64.54it/s, train_loss=0.00204, val_loss=0.00247]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 115.53it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 135.71it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 147.87it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 153.65it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 153.27it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 154.60it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 156.70it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 155.96it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 156.39it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 158.53it/s][A
                                                                         [AEpoch 26: 100%|██████████| 26/26 [00:00<00:00, 54.90it/s, train_loss=0.00204, val_loss=0.00244]Epoch 26: 100%|██████████| 26/26 [00:00<00:00, 54.82it/s, train_loss=0.00204, val_loss=0.00244]Epoch 26:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00204, val_loss=0.00244]         Epoch 27:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00204, val_loss=0.00244]Epoch 27:   4%|▍         | 1/26 [00:00<00:00, 90.03it/s, train_loss=0.00204, val_loss=0.00244]Epoch 27:   4%|▍         | 1/26 [00:00<00:00, 66.08it/s, train_loss=0.00213, val_loss=0.00244]Epoch 27:   8%|▊         | 2/26 [00:00<00:00, 84.05it/s, train_loss=0.00213, val_loss=0.00244]Epoch 27:   8%|▊         | 2/26 [00:00<00:00, 62.35it/s, train_loss=0.002, val_loss=0.00244]  Epoch 27:  12%|█▏        | 3/26 [00:00<00:00, 69.66it/s, train_loss=0.002, val_loss=0.00244]Epoch 27:  12%|█▏        | 3/26 [00:00<00:00, 63.52it/s, train_loss=0.00195, val_loss=0.00244]Epoch 27:  15%|█▌        | 4/26 [00:00<00:00, 70.08it/s, train_loss=0.00195, val_loss=0.00244]Epoch 27:  15%|█▌        | 4/26 [00:00<00:00, 62.18it/s, train_loss=0.00212, val_loss=0.00244]Epoch 27:  19%|█▉        | 5/26 [00:00<00:00, 67.10it/s, train_loss=0.00212, val_loss=0.00244]Epoch 27:  19%|█▉        | 5/26 [00:00<00:00, 62.89it/s, train_loss=0.00206, val_loss=0.00244]Epoch 27:  23%|██▎       | 6/26 [00:00<00:00, 66.50it/s, train_loss=0.00206, val_loss=0.00244]Epoch 27:  23%|██▎       | 6/26 [00:00<00:00, 62.82it/s, train_loss=0.00194, val_loss=0.00244]Epoch 27:  27%|██▋       | 7/26 [00:00<00:00, 66.01it/s, train_loss=0.00194, val_loss=0.00244]Epoch 27:  27%|██▋       | 7/26 [00:00<00:00, 63.22it/s, train_loss=0.00209, val_loss=0.00244]Epoch 27:  31%|███       | 8/26 [00:00<00:00, 65.98it/s, train_loss=0.00209, val_loss=0.00244]Epoch 27:  31%|███       | 8/26 [00:00<00:00, 63.38it/s, train_loss=0.00215, val_loss=0.00244]Epoch 27:  35%|███▍      | 9/26 [00:00<00:00, 65.63it/s, train_loss=0.00215, val_loss=0.00244]Epoch 27:  35%|███▍      | 9/26 [00:00<00:00, 63.64it/s, train_loss=0.00212, val_loss=0.00244]Epoch 27:  38%|███▊      | 10/26 [00:00<00:00, 65.88it/s, train_loss=0.00212, val_loss=0.00244]Epoch 27:  38%|███▊      | 10/26 [00:00<00:00, 63.68it/s, train_loss=0.00194, val_loss=0.00244]Epoch 27:  42%|████▏     | 11/26 [00:00<00:00, 66.02it/s, train_loss=0.00194, val_loss=0.00244]Epoch 27:  42%|████▏     | 11/26 [00:00<00:00, 63.99it/s, train_loss=0.0021, val_loss=0.00244] Epoch 27:  46%|████▌     | 12/26 [00:00<00:00, 66.10it/s, train_loss=0.0021, val_loss=0.00244]Epoch 27:  46%|████▌     | 12/26 [00:00<00:00, 63.88it/s, train_loss=0.00199, val_loss=0.00244]Epoch 27:  50%|█████     | 13/26 [00:00<00:00, 65.97it/s, train_loss=0.00199, val_loss=0.00244]Epoch 27:  50%|█████     | 13/26 [00:00<00:00, 64.12it/s, train_loss=0.00203, val_loss=0.00244]Epoch 27:  54%|█████▍    | 14/26 [00:00<00:00, 65.95it/s, train_loss=0.00203, val_loss=0.00244]Epoch 27:  54%|█████▍    | 14/26 [00:00<00:00, 64.11it/s, train_loss=0.00213, val_loss=0.00244]Epoch 27:  58%|█████▊    | 15/26 [00:00<00:00, 65.93it/s, train_loss=0.00213, val_loss=0.00244]Epoch 27:  58%|█████▊    | 15/26 [00:00<00:00, 64.31it/s, train_loss=0.00225, val_loss=0.00244]Epoch 27:  62%|██████▏   | 16/26 [00:00<00:00, 65.91it/s, train_loss=0.00225, val_loss=0.00244]Epoch 27:  62%|██████▏   | 16/26 [00:00<00:00, 64.31it/s, train_loss=0.00217, val_loss=0.00244]Epoch 27:  65%|██████▌   | 17/26 [00:00<00:00, 65.99it/s, train_loss=0.00217, val_loss=0.00244]Epoch 27:  65%|██████▌   | 17/26 [00:00<00:00, 64.49it/s, train_loss=0.00231, val_loss=0.00244]Epoch 27:  69%|██████▉   | 18/26 [00:00<00:00, 65.92it/s, train_loss=0.00231, val_loss=0.00244]Epoch 27:  69%|██████▉   | 18/26 [00:00<00:00, 64.46it/s, train_loss=0.00189, val_loss=0.00244]Epoch 27:  73%|███████▎  | 19/26 [00:00<00:00, 66.06it/s, train_loss=0.00189, val_loss=0.00244]Epoch 27:  73%|███████▎  | 19/26 [00:00<00:00, 64.71it/s, train_loss=0.00203, val_loss=0.00244]Epoch 27:  77%|███████▋  | 20/26 [00:00<00:00, 66.06it/s, train_loss=0.00203, val_loss=0.00244]Epoch 27:  77%|███████▋  | 20/26 [00:00<00:00, 64.54it/s, train_loss=0.00213, val_loss=0.00244]Epoch 27:  81%|████████  | 21/26 [00:00<00:00, 65.94it/s, train_loss=0.00213, val_loss=0.00244]Epoch 27:  81%|████████  | 21/26 [00:00<00:00, 64.73it/s, train_loss=0.002, val_loss=0.00244]  Epoch 27:  85%|████████▍ | 22/26 [00:00<00:00, 65.94it/s, train_loss=0.002, val_loss=0.00244]Epoch 27:  85%|████████▍ | 22/26 [00:00<00:00, 64.59it/s, train_loss=0.00192, val_loss=0.00244]Epoch 27:  88%|████████▊ | 23/26 [00:00<00:00, 65.88it/s, train_loss=0.00192, val_loss=0.00244]Epoch 27:  88%|████████▊ | 23/26 [00:00<00:00, 64.75it/s, train_loss=0.00193, val_loss=0.00244]Epoch 27:  92%|█████████▏| 24/26 [00:00<00:00, 65.80it/s, train_loss=0.00193, val_loss=0.00244]Epoch 27:  92%|█████████▏| 24/26 [00:00<00:00, 64.64it/s, train_loss=0.0021, val_loss=0.00244] Epoch 27:  96%|█████████▌| 25/26 [00:00<00:00, 65.62it/s, train_loss=0.0021, val_loss=0.00244]Epoch 27:  96%|█████████▌| 25/26 [00:00<00:00, 64.25it/s, train_loss=0.00223, val_loss=0.00244]Epoch 27: 100%|██████████| 26/26 [00:00<00:00, 65.06it/s, train_loss=0.00223, val_loss=0.00244]Epoch 27: 100%|██████████| 26/26 [00:00<00:00, 64.26it/s, train_loss=0.00225, val_loss=0.00244]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 123.34it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 141.49it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 149.74it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 157.61it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 160.79it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 161.77it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 162.90it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 164.57it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 166.29it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 167.10it/s][A
                                                                         [AEpoch 27: 100%|██████████| 26/26 [00:00<00:00, 54.86it/s, train_loss=0.00225, val_loss=0.00243]Epoch 27: 100%|██████████| 26/26 [00:00<00:00, 54.75it/s, train_loss=0.00225, val_loss=0.00243]Epoch 27:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00225, val_loss=0.00243]         Epoch 28:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00225, val_loss=0.00243]Epoch 28:   4%|▍         | 1/26 [00:00<00:00, 91.17it/s, train_loss=0.00225, val_loss=0.00243]Epoch 28:   4%|▍         | 1/26 [00:00<00:00, 62.99it/s, train_loss=0.00231, val_loss=0.00243]Epoch 28:   8%|▊         | 2/26 [00:00<00:00, 79.18it/s, train_loss=0.00231, val_loss=0.00243]Epoch 28:   8%|▊         | 2/26 [00:00<00:00, 60.98it/s, train_loss=0.00194, val_loss=0.00243]Epoch 28:  12%|█▏        | 3/26 [00:00<00:00, 71.58it/s, train_loss=0.00194, val_loss=0.00243]Epoch 28:  12%|█▏        | 3/26 [00:00<00:00, 62.92it/s, train_loss=0.00217, val_loss=0.00243]Epoch 28:  15%|█▌        | 4/26 [00:00<00:00, 67.86it/s, train_loss=0.00217, val_loss=0.00243]Epoch 28:  15%|█▌        | 4/26 [00:00<00:00, 63.26it/s, train_loss=0.00206, val_loss=0.00243]Epoch 28:  19%|█▉        | 5/26 [00:00<00:00, 69.66it/s, train_loss=0.00206, val_loss=0.00243]Epoch 28:  19%|█▉        | 5/26 [00:00<00:00, 64.44it/s, train_loss=0.00229, val_loss=0.00243]Epoch 28:  23%|██▎       | 6/26 [00:00<00:00, 68.66it/s, train_loss=0.00229, val_loss=0.00243]Epoch 28:  23%|██▎       | 6/26 [00:00<00:00, 63.71it/s, train_loss=0.00214, val_loss=0.00243]Epoch 28:  27%|██▋       | 7/26 [00:00<00:00, 68.11it/s, train_loss=0.00214, val_loss=0.00243]Epoch 28:  27%|██▋       | 7/26 [00:00<00:00, 64.46it/s, train_loss=0.00197, val_loss=0.00243]Epoch 28:  31%|███       | 8/26 [00:00<00:00, 67.18it/s, train_loss=0.00197, val_loss=0.00243]Epoch 28:  31%|███       | 8/26 [00:00<00:00, 64.09it/s, train_loss=0.0021, val_loss=0.00243] Epoch 28:  35%|███▍      | 9/26 [00:00<00:00, 67.40it/s, train_loss=0.0021, val_loss=0.00243]Epoch 28:  35%|███▍      | 9/26 [00:00<00:00, 64.55it/s, train_loss=0.00191, val_loss=0.00243]Epoch 28:  38%|███▊      | 10/26 [00:00<00:00, 66.51it/s, train_loss=0.00191, val_loss=0.00243]Epoch 28:  38%|███▊      | 10/26 [00:00<00:00, 64.34it/s, train_loss=0.00187, val_loss=0.00243]Epoch 28:  42%|████▏     | 11/26 [00:00<00:00, 67.10it/s, train_loss=0.00187, val_loss=0.00243]Epoch 28:  42%|████▏     | 11/26 [00:00<00:00, 64.71it/s, train_loss=0.00192, val_loss=0.00243]Epoch 28:  46%|████▌     | 12/26 [00:00<00:00, 66.43it/s, train_loss=0.00192, val_loss=0.00243]Epoch 28:  46%|████▌     | 12/26 [00:00<00:00, 64.51it/s, train_loss=0.00193, val_loss=0.00243]Epoch 28:  50%|█████     | 13/26 [00:00<00:00, 66.75it/s, train_loss=0.00193, val_loss=0.00243]Epoch 28:  50%|█████     | 13/26 [00:00<00:00, 64.81it/s, train_loss=0.0021, val_loss=0.00243] Epoch 28:  54%|█████▍    | 14/26 [00:00<00:00, 66.18it/s, train_loss=0.0021, val_loss=0.00243]Epoch 28:  54%|█████▍    | 14/26 [00:00<00:00, 64.65it/s, train_loss=0.00198, val_loss=0.00243]Epoch 28:  58%|█████▊    | 15/26 [00:00<00:00, 66.35it/s, train_loss=0.00198, val_loss=0.00243]Epoch 28:  58%|█████▊    | 15/26 [00:00<00:00, 64.76it/s, train_loss=0.00199, val_loss=0.00243]Epoch 28:  62%|██████▏   | 16/26 [00:00<00:00, 65.91it/s, train_loss=0.00199, val_loss=0.00243]Epoch 28:  62%|██████▏   | 16/26 [00:00<00:00, 64.73it/s, train_loss=0.00199, val_loss=0.00243]Epoch 28:  65%|██████▌   | 17/26 [00:00<00:00, 66.48it/s, train_loss=0.00199, val_loss=0.00243]Epoch 28:  65%|██████▌   | 17/26 [00:00<00:00, 64.91it/s, train_loss=0.0022, val_loss=0.00243] Epoch 28:  69%|██████▉   | 18/26 [00:00<00:00, 66.04it/s, train_loss=0.0022, val_loss=0.00243]Epoch 28:  69%|██████▉   | 18/26 [00:00<00:00, 64.82it/s, train_loss=0.00217, val_loss=0.00243]Epoch 28:  73%|███████▎  | 19/26 [00:00<00:00, 66.35it/s, train_loss=0.00217, val_loss=0.00243]Epoch 28:  73%|███████▎  | 19/26 [00:00<00:00, 64.95it/s, train_loss=0.00201, val_loss=0.00243]Epoch 28:  77%|███████▋  | 20/26 [00:00<00:00, 65.90it/s, train_loss=0.00201, val_loss=0.00243]Epoch 28:  77%|███████▋  | 20/26 [00:00<00:00, 64.92it/s, train_loss=0.00213, val_loss=0.00243]Epoch 28:  81%|████████  | 21/26 [00:00<00:00, 66.26it/s, train_loss=0.00213, val_loss=0.00243]Epoch 28:  81%|████████  | 21/26 [00:00<00:00, 65.03it/s, train_loss=0.00201, val_loss=0.00243]Epoch 28:  85%|████████▍ | 22/26 [00:00<00:00, 65.89it/s, train_loss=0.00201, val_loss=0.00243]Epoch 28:  85%|████████▍ | 22/26 [00:00<00:00, 65.00it/s, train_loss=0.00205, val_loss=0.00243]Epoch 28:  88%|████████▊ | 23/26 [00:00<00:00, 66.19it/s, train_loss=0.00205, val_loss=0.00243]Epoch 28:  88%|████████▊ | 23/26 [00:00<00:00, 65.07it/s, train_loss=0.00206, val_loss=0.00243]Epoch 28:  92%|█████████▏| 24/26 [00:00<00:00, 65.91it/s, train_loss=0.00206, val_loss=0.00243]Epoch 28:  92%|█████████▏| 24/26 [00:00<00:00, 65.02it/s, train_loss=0.00206, val_loss=0.00243]Epoch 28:  96%|█████████▌| 25/26 [00:00<00:00, 66.21it/s, train_loss=0.00206, val_loss=0.00243]Epoch 28:  96%|█████████▌| 25/26 [00:00<00:00, 65.17it/s, train_loss=0.00196, val_loss=0.00243]Epoch 28: 100%|██████████| 26/26 [00:00<00:00, 65.99it/s, train_loss=0.00196, val_loss=0.00243]Epoch 28: 100%|██████████| 26/26 [00:00<00:00, 65.10it/s, train_loss=0.00203, val_loss=0.00243]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 138.80it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 158.34it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 170.99it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 175.27it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 178.17it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 176.34it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 173.11it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 172.21it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 173.20it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 172.45it/s][A
                                                                         [AEpoch 28: 100%|██████████| 26/26 [00:00<00:00, 55.94it/s, train_loss=0.00203, val_loss=0.00237]Epoch 28: 100%|██████████| 26/26 [00:00<00:00, 55.85it/s, train_loss=0.00203, val_loss=0.00237]Epoch 28:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00203, val_loss=0.00237]         Epoch 29:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00203, val_loss=0.00237]Epoch 29:   4%|▍         | 1/26 [00:00<00:00, 86.83it/s, train_loss=0.00203, val_loss=0.00237]Epoch 29:   4%|▍         | 1/26 [00:00<00:00, 64.35it/s, train_loss=0.00195, val_loss=0.00237]Epoch 29:   8%|▊         | 2/26 [00:00<00:00, 77.17it/s, train_loss=0.00195, val_loss=0.00237]Epoch 29:   8%|▊         | 2/26 [00:00<00:00, 61.25it/s, train_loss=0.00215, val_loss=0.00237]Epoch 29:  12%|█▏        | 3/26 [00:00<00:00, 71.91it/s, train_loss=0.00215, val_loss=0.00237]Epoch 29:  12%|█▏        | 3/26 [00:00<00:00, 63.20it/s, train_loss=0.00224, val_loss=0.00237]Epoch 29:  15%|█▌        | 4/26 [00:00<00:00, 68.43it/s, train_loss=0.00224, val_loss=0.00237]Epoch 29:  15%|█▌        | 4/26 [00:00<00:00, 63.48it/s, train_loss=0.00198, val_loss=0.00237]Epoch 29:  19%|█▉        | 5/26 [00:00<00:00, 69.48it/s, train_loss=0.00198, val_loss=0.00237]Epoch 29:  19%|█▉        | 5/26 [00:00<00:00, 64.19it/s, train_loss=0.00196, val_loss=0.00237]Epoch 29:  23%|██▎       | 6/26 [00:00<00:00, 67.36it/s, train_loss=0.00196, val_loss=0.00237]Epoch 29:  23%|██▎       | 6/26 [00:00<00:00, 64.18it/s, train_loss=0.00192, val_loss=0.00237]Epoch 29:  27%|██▋       | 7/26 [00:00<00:00, 68.41it/s, train_loss=0.00192, val_loss=0.00237]Epoch 29:  27%|██▋       | 7/26 [00:00<00:00, 64.59it/s, train_loss=0.00206, val_loss=0.00237]Epoch 29:  31%|███       | 8/26 [00:00<00:00, 67.11it/s, train_loss=0.00206, val_loss=0.00237]Epoch 29:  31%|███       | 8/26 [00:00<00:00, 64.56it/s, train_loss=0.00191, val_loss=0.00237]Epoch 29:  35%|███▍      | 9/26 [00:00<00:00, 67.38it/s, train_loss=0.00191, val_loss=0.00237]Epoch 29:  35%|███▍      | 9/26 [00:00<00:00, 63.48it/s, train_loss=0.0021, val_loss=0.00237] Epoch 29:  38%|███▊      | 10/26 [00:00<00:00, 65.63it/s, train_loss=0.0021, val_loss=0.00237]Epoch 29:  38%|███▊      | 10/26 [00:00<00:00, 63.95it/s, train_loss=0.00193, val_loss=0.00237]Epoch 29:  42%|████▏     | 11/26 [00:00<00:00, 66.25it/s, train_loss=0.00193, val_loss=0.00237]Epoch 29:  42%|████▏     | 11/26 [00:00<00:00, 63.47it/s, train_loss=0.00195, val_loss=0.00237]Epoch 29:  46%|████▌     | 12/26 [00:00<00:00, 65.93it/s, train_loss=0.00195, val_loss=0.00237]Epoch 29:  46%|████▌     | 12/26 [00:00<00:00, 63.90it/s, train_loss=0.00206, val_loss=0.00237]Epoch 29:  50%|█████     | 13/26 [00:00<00:00, 65.60it/s, train_loss=0.00206, val_loss=0.00237]Epoch 29:  50%|█████     | 13/26 [00:00<00:00, 63.71it/s, train_loss=0.00204, val_loss=0.00237]Epoch 29:  54%|█████▍    | 14/26 [00:00<00:00, 65.86it/s, train_loss=0.00204, val_loss=0.00237]Epoch 29:  54%|█████▍    | 14/26 [00:00<00:00, 64.05it/s, train_loss=0.00203, val_loss=0.00237]Epoch 29:  58%|█████▊    | 15/26 [00:00<00:00, 65.43it/s, train_loss=0.00203, val_loss=0.00237]Epoch 29:  58%|█████▊    | 15/26 [00:00<00:00, 63.96it/s, train_loss=0.00175, val_loss=0.00237]Epoch 29:  62%|██████▏   | 16/26 [00:00<00:00, 65.64it/s, train_loss=0.00175, val_loss=0.00237]Epoch 29:  62%|██████▏   | 16/26 [00:00<00:00, 64.12it/s, train_loss=0.00224, val_loss=0.00237]Epoch 29:  65%|██████▌   | 17/26 [00:00<00:00, 65.25it/s, train_loss=0.00224, val_loss=0.00237]Epoch 29:  65%|██████▌   | 17/26 [00:00<00:00, 64.12it/s, train_loss=0.00205, val_loss=0.00237]Epoch 29:  69%|██████▉   | 18/26 [00:00<00:00, 65.72it/s, train_loss=0.00205, val_loss=0.00237]Epoch 29:  69%|██████▉   | 18/26 [00:00<00:00, 64.33it/s, train_loss=0.00191, val_loss=0.00237]Epoch 29:  73%|███████▎  | 19/26 [00:00<00:00, 65.37it/s, train_loss=0.00191, val_loss=0.00237]Epoch 29:  73%|███████▎  | 19/26 [00:00<00:00, 64.25it/s, train_loss=0.00199, val_loss=0.00237]Epoch 29:  77%|███████▋  | 20/26 [00:00<00:00, 65.66it/s, train_loss=0.00199, val_loss=0.00237]Epoch 29:  77%|███████▋  | 20/26 [00:00<00:00, 64.40it/s, train_loss=0.00219, val_loss=0.00237]Epoch 29:  81%|████████  | 21/26 [00:00<00:00, 65.33it/s, train_loss=0.00219, val_loss=0.00237]Epoch 29:  81%|████████  | 21/26 [00:00<00:00, 64.39it/s, train_loss=0.00203, val_loss=0.00237]Epoch 29:  85%|████████▍ | 22/26 [00:00<00:00, 65.66it/s, train_loss=0.00203, val_loss=0.00237]Epoch 29:  85%|████████▍ | 22/26 [00:00<00:00, 64.51it/s, train_loss=0.00191, val_loss=0.00237]Epoch 29:  88%|████████▊ | 23/26 [00:00<00:00, 65.29it/s, train_loss=0.00191, val_loss=0.00237]Epoch 29:  88%|████████▊ | 23/26 [00:00<00:00, 64.49it/s, train_loss=0.00193, val_loss=0.00237]Epoch 29:  92%|█████████▏| 24/26 [00:00<00:00, 65.51it/s, train_loss=0.00193, val_loss=0.00237]Epoch 29:  92%|█████████▏| 24/26 [00:00<00:00, 64.09it/s, train_loss=0.00195, val_loss=0.00237]Epoch 29:  96%|█████████▌| 25/26 [00:00<00:00, 64.87it/s, train_loss=0.00195, val_loss=0.00237]Epoch 29:  96%|█████████▌| 25/26 [00:00<00:00, 64.15it/s, train_loss=0.00196, val_loss=0.00237]Epoch 29: 100%|██████████| 26/26 [00:00<00:00, 64.95it/s, train_loss=0.00196, val_loss=0.00237]Epoch 29: 100%|██████████| 26/26 [00:00<00:00, 64.11it/s, train_loss=0.00182, val_loss=0.00237]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 124.40it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 153.84it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 171.29it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 181.69it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 184.43it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 185.08it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 189.31it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 192.13it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 194.05it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 196.47it/s][A
                                                                         [AEpoch 29: 100%|██████████| 26/26 [00:00<00:00, 55.94it/s, train_loss=0.00182, val_loss=0.00236]Epoch 29: 100%|██████████| 26/26 [00:00<00:00, 55.82it/s, train_loss=0.00182, val_loss=0.00236]Epoch 29:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00182, val_loss=0.00236]         Epoch 30:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00182, val_loss=0.00236]Epoch 30:   4%|▍         | 1/26 [00:00<00:00, 87.48it/s, train_loss=0.00182, val_loss=0.00236]Epoch 30:   4%|▍         | 1/26 [00:00<00:00, 64.11it/s, train_loss=0.00216, val_loss=0.00236]Epoch 30:   8%|▊         | 2/26 [00:00<00:00, 78.63it/s, train_loss=0.00216, val_loss=0.00236]Epoch 30:   8%|▊         | 2/26 [00:00<00:00, 61.26it/s, train_loss=0.00192, val_loss=0.00236]Epoch 30:  12%|█▏        | 3/26 [00:00<00:00, 72.53it/s, train_loss=0.00192, val_loss=0.00236]Epoch 30:  12%|█▏        | 3/26 [00:00<00:00, 63.51it/s, train_loss=0.00186, val_loss=0.00236]Epoch 30:  15%|█▌        | 4/26 [00:00<00:00, 68.86it/s, train_loss=0.00186, val_loss=0.00236]Epoch 30:  15%|█▌        | 4/26 [00:00<00:00, 63.13it/s, train_loss=0.00211, val_loss=0.00236]Epoch 30:  19%|█▉        | 5/26 [00:00<00:00, 69.41it/s, train_loss=0.00211, val_loss=0.00236]Epoch 30:  19%|█▉        | 5/26 [00:00<00:00, 64.06it/s, train_loss=0.00211, val_loss=0.00236]Epoch 30:  23%|██▎       | 6/26 [00:00<00:00, 67.50it/s, train_loss=0.00211, val_loss=0.00236]Epoch 30:  23%|██▎       | 6/26 [00:00<00:00, 63.88it/s, train_loss=0.00204, val_loss=0.00236]Epoch 30:  27%|██▋       | 7/26 [00:00<00:00, 68.18it/s, train_loss=0.00204, val_loss=0.00236]Epoch 30:  27%|██▋       | 7/26 [00:00<00:00, 64.35it/s, train_loss=0.00212, val_loss=0.00236]Epoch 30:  31%|███       | 8/26 [00:00<00:00, 66.82it/s, train_loss=0.00212, val_loss=0.00236]Epoch 30:  31%|███       | 8/26 [00:00<00:00, 64.37it/s, train_loss=0.002, val_loss=0.00236]  Epoch 30:  35%|███▍      | 9/26 [00:00<00:00, 67.52it/s, train_loss=0.002, val_loss=0.00236]Epoch 30:  35%|███▍      | 9/26 [00:00<00:00, 64.69it/s, train_loss=0.00209, val_loss=0.00236]Epoch 30:  38%|███▊      | 10/26 [00:00<00:00, 66.61it/s, train_loss=0.00209, val_loss=0.00236]Epoch 30:  38%|███▊      | 10/26 [00:00<00:00, 64.52it/s, train_loss=0.00212, val_loss=0.00236]Epoch 30:  42%|████▏     | 11/26 [00:00<00:00, 67.03it/s, train_loss=0.00212, val_loss=0.00236]Epoch 30:  42%|████▏     | 11/26 [00:00<00:00, 64.76it/s, train_loss=0.00215, val_loss=0.00236]Epoch 30:  46%|████▌     | 12/26 [00:00<00:00, 66.24it/s, train_loss=0.00215, val_loss=0.00236]Epoch 30:  46%|████▌     | 12/26 [00:00<00:00, 64.69it/s, train_loss=0.00208, val_loss=0.00236]Epoch 30:  50%|█████     | 13/26 [00:00<00:00, 66.83it/s, train_loss=0.00208, val_loss=0.00236]Epoch 30:  50%|█████     | 13/26 [00:00<00:00, 64.88it/s, train_loss=0.00216, val_loss=0.00236]Epoch 30:  54%|█████▍    | 14/26 [00:00<00:00, 66.23it/s, train_loss=0.00216, val_loss=0.00236]Epoch 30:  54%|█████▍    | 14/26 [00:00<00:00, 64.84it/s, train_loss=0.00194, val_loss=0.00236]Epoch 30:  58%|█████▊    | 15/26 [00:00<00:00, 66.84it/s, train_loss=0.00194, val_loss=0.00236]Epoch 30:  58%|█████▊    | 15/26 [00:00<00:00, 65.11it/s, train_loss=0.00178, val_loss=0.00236]Epoch 30:  62%|██████▏   | 16/26 [00:00<00:00, 66.47it/s, train_loss=0.00178, val_loss=0.00236]Epoch 30:  62%|██████▏   | 16/26 [00:00<00:00, 64.90it/s, train_loss=0.00203, val_loss=0.00236]Epoch 30:  65%|██████▌   | 17/26 [00:00<00:00, 66.62it/s, train_loss=0.00203, val_loss=0.00236]Epoch 30:  65%|██████▌   | 17/26 [00:00<00:00, 65.13it/s, train_loss=0.00193, val_loss=0.00236]Epoch 30:  69%|██████▉   | 18/26 [00:00<00:00, 66.30it/s, train_loss=0.00193, val_loss=0.00236]Epoch 30:  69%|██████▉   | 18/26 [00:00<00:00, 64.95it/s, train_loss=0.00183, val_loss=0.00236]Epoch 30:  73%|███████▎  | 19/26 [00:00<00:00, 66.50it/s, train_loss=0.00183, val_loss=0.00236]Epoch 30:  73%|███████▎  | 19/26 [00:00<00:00, 65.14it/s, train_loss=0.00201, val_loss=0.00236]Epoch 30:  77%|███████▋  | 20/26 [00:00<00:00, 66.16it/s, train_loss=0.00201, val_loss=0.00236]Epoch 30:  77%|███████▋  | 20/26 [00:00<00:00, 64.98it/s, train_loss=0.00196, val_loss=0.00236]Epoch 30:  81%|████████  | 21/26 [00:00<00:00, 66.37it/s, train_loss=0.00196, val_loss=0.00236]Epoch 30:  81%|████████  | 21/26 [00:00<00:00, 65.13it/s, train_loss=0.00169, val_loss=0.00236]Epoch 30:  85%|████████▍ | 22/26 [00:00<00:00, 66.02it/s, train_loss=0.00169, val_loss=0.00236]Epoch 30:  85%|████████▍ | 22/26 [00:00<00:00, 65.02it/s, train_loss=0.00199, val_loss=0.00236]Epoch 30:  88%|████████▊ | 23/26 [00:00<00:00, 66.26it/s, train_loss=0.00199, val_loss=0.00236]Epoch 30:  88%|████████▊ | 23/26 [00:00<00:00, 65.13it/s, train_loss=0.00199, val_loss=0.00236]Epoch 30:  92%|█████████▏| 24/26 [00:00<00:00, 65.96it/s, train_loss=0.00199, val_loss=0.00236]Epoch 30:  92%|█████████▏| 24/26 [00:00<00:00, 65.08it/s, train_loss=0.00207, val_loss=0.00236]Epoch 30:  96%|█████████▌| 25/26 [00:00<00:00, 66.23it/s, train_loss=0.00207, val_loss=0.00236]Epoch 30:  96%|█████████▌| 25/26 [00:00<00:00, 65.17it/s, train_loss=0.00184, val_loss=0.00236]Epoch 30: 100%|██████████| 26/26 [00:00<00:00, 65.86it/s, train_loss=0.00184, val_loss=0.00236]Epoch 30: 100%|██████████| 26/26 [00:00<00:00, 65.19it/s, train_loss=0.00207, val_loss=0.00236]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 122.11it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 141.48it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 148.17it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 152.65it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 156.70it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 157.80it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 158.51it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 159.88it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 157.05it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 157.81it/s][A
                                                                         [AEpoch 30: 100%|██████████| 26/26 [00:00<00:00, 55.23it/s, train_loss=0.00207, val_loss=0.00233]Epoch 30: 100%|██████████| 26/26 [00:00<00:00, 55.11it/s, train_loss=0.00207, val_loss=0.00233]Epoch 30:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00207, val_loss=0.00233]         Epoch 31:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00207, val_loss=0.00233]Epoch 31:   4%|▍         | 1/26 [00:00<00:00, 90.43it/s, train_loss=0.00207, val_loss=0.00233]Epoch 31:   4%|▍         | 1/26 [00:00<00:00, 66.35it/s, train_loss=0.00211, val_loss=0.00233]Epoch 31:   8%|▊         | 2/26 [00:00<00:00, 84.05it/s, train_loss=0.00211, val_loss=0.00233]Epoch 31:   8%|▊         | 2/26 [00:00<00:00, 62.79it/s, train_loss=0.00204, val_loss=0.00233]Epoch 31:  12%|█▏        | 3/26 [00:00<00:00, 70.67it/s, train_loss=0.00204, val_loss=0.00233]Epoch 31:  12%|█▏        | 3/26 [00:00<00:00, 64.39it/s, train_loss=0.00196, val_loss=0.00233]Epoch 31:  15%|█▌        | 4/26 [00:00<00:00, 69.49it/s, train_loss=0.00196, val_loss=0.00233]Epoch 31:  15%|█▌        | 4/26 [00:00<00:00, 63.05it/s, train_loss=0.00186, val_loss=0.00233]Epoch 31:  19%|█▉        | 5/26 [00:00<00:00, 69.27it/s, train_loss=0.00186, val_loss=0.00233]Epoch 31:  19%|█▉        | 5/26 [00:00<00:00, 64.07it/s, train_loss=0.00185, val_loss=0.00233]Epoch 31:  23%|██▎       | 6/26 [00:00<00:00, 67.64it/s, train_loss=0.00185, val_loss=0.00233]Epoch 31:  23%|██▎       | 6/26 [00:00<00:00, 63.69it/s, train_loss=0.00205, val_loss=0.00233]Epoch 31:  27%|██▋       | 7/26 [00:00<00:00, 67.66it/s, train_loss=0.00205, val_loss=0.00233]Epoch 31:  27%|██▋       | 7/26 [00:00<00:00, 64.06it/s, train_loss=0.00201, val_loss=0.00233]Epoch 31:  31%|███       | 8/26 [00:00<00:00, 66.62it/s, train_loss=0.00201, val_loss=0.00233]Epoch 31:  31%|███       | 8/26 [00:00<00:00, 64.15it/s, train_loss=0.002, val_loss=0.00233]  Epoch 31:  35%|███▍      | 9/26 [00:00<00:00, 67.44it/s, train_loss=0.002, val_loss=0.00233]Epoch 31:  35%|███▍      | 9/26 [00:00<00:00, 64.54it/s, train_loss=0.00215, val_loss=0.00233]Epoch 31:  38%|███▊      | 10/26 [00:00<00:00, 66.56it/s, train_loss=0.00215, val_loss=0.00233]Epoch 31:  38%|███▊      | 10/26 [00:00<00:00, 64.33it/s, train_loss=0.00214, val_loss=0.00233]Epoch 31:  42%|████▏     | 11/26 [00:00<00:00, 66.75it/s, train_loss=0.00214, val_loss=0.00233]Epoch 31:  42%|████▏     | 11/26 [00:00<00:00, 64.47it/s, train_loss=0.0021, val_loss=0.00233] Epoch 31:  46%|████▌     | 12/26 [00:00<00:00, 66.06it/s, train_loss=0.0021, val_loss=0.00233]Epoch 31:  46%|████▌     | 12/26 [00:00<00:00, 64.50it/s, train_loss=0.00186, val_loss=0.00233]Epoch 31:  50%|█████     | 13/26 [00:00<00:00, 66.76it/s, train_loss=0.00186, val_loss=0.00233]Epoch 31:  50%|█████     | 13/26 [00:00<00:00, 64.74it/s, train_loss=0.00208, val_loss=0.00233]Epoch 31:  54%|█████▍    | 14/26 [00:00<00:00, 66.12it/s, train_loss=0.00208, val_loss=0.00233]Epoch 31:  54%|█████▍    | 14/26 [00:00<00:00, 64.70it/s, train_loss=0.002, val_loss=0.00233]  Epoch 31:  58%|█████▊    | 15/26 [00:00<00:00, 66.59it/s, train_loss=0.002, val_loss=0.00233]Epoch 31:  58%|█████▊    | 15/26 [00:00<00:00, 64.87it/s, train_loss=0.00202, val_loss=0.00233]Epoch 31:  62%|██████▏   | 16/26 [00:00<00:00, 65.97it/s, train_loss=0.00202, val_loss=0.00233]Epoch 31:  62%|██████▏   | 16/26 [00:00<00:00, 64.82it/s, train_loss=0.00223, val_loss=0.00233]Epoch 31:  65%|██████▌   | 17/26 [00:00<00:00, 66.36it/s, train_loss=0.00223, val_loss=0.00233]Epoch 31:  65%|██████▌   | 17/26 [00:00<00:00, 64.94it/s, train_loss=0.0019, val_loss=0.00233] Epoch 31:  69%|██████▉   | 18/26 [00:00<00:00, 65.98it/s, train_loss=0.0019, val_loss=0.00233]Epoch 31:  69%|██████▉   | 18/26 [00:00<00:00, 64.90it/s, train_loss=0.00196, val_loss=0.00233]Epoch 31:  73%|███████▎  | 19/26 [00:00<00:00, 66.36it/s, train_loss=0.00196, val_loss=0.00233]Epoch 31:  73%|███████▎  | 19/26 [00:00<00:00, 65.02it/s, train_loss=0.00199, val_loss=0.00233]Epoch 31:  77%|███████▋  | 20/26 [00:00<00:00, 66.05it/s, train_loss=0.00199, val_loss=0.00233]Epoch 31:  77%|███████▋  | 20/26 [00:00<00:00, 64.98it/s, train_loss=0.00172, val_loss=0.00233]Epoch 31:  81%|████████  | 21/26 [00:00<00:00, 66.40it/s, train_loss=0.00172, val_loss=0.00233]Epoch 31:  81%|████████  | 21/26 [00:00<00:00, 65.18it/s, train_loss=0.00193, val_loss=0.00233]Epoch 31:  85%|████████▍ | 22/26 [00:00<00:00, 66.15it/s, train_loss=0.00193, val_loss=0.00233]Epoch 31:  85%|████████▍ | 22/26 [00:00<00:00, 65.01it/s, train_loss=0.00206, val_loss=0.00233]Epoch 31:  88%|████████▊ | 23/26 [00:00<00:00, 66.31it/s, train_loss=0.00206, val_loss=0.00233]Epoch 31:  88%|████████▊ | 23/26 [00:00<00:00, 65.18it/s, train_loss=0.00202, val_loss=0.00233]Epoch 31:  92%|█████████▏| 24/26 [00:00<00:00, 66.04it/s, train_loss=0.00202, val_loss=0.00233]Epoch 31:  92%|█████████▏| 24/26 [00:00<00:00, 65.03it/s, train_loss=0.00186, val_loss=0.00233]Epoch 31:  96%|█████████▌| 25/26 [00:00<00:00, 66.19it/s, train_loss=0.00186, val_loss=0.00233]Epoch 31:  96%|█████████▌| 25/26 [00:00<00:00, 65.18it/s, train_loss=0.00185, val_loss=0.00233]Epoch 31: 100%|██████████| 26/26 [00:00<00:00, 65.96it/s, train_loss=0.00185, val_loss=0.00233]Epoch 31: 100%|██████████| 26/26 [00:00<00:00, 65.11it/s, train_loss=0.00207, val_loss=0.00233]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 129.39it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 147.93it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 159.33it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 159.00it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 161.64it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 161.36it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 155.25it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 156.95it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 159.81it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 157.79it/s][A
                                                                         [AEpoch 31: 100%|██████████| 26/26 [00:00<00:00, 55.28it/s, train_loss=0.00207, val_loss=0.00231]Epoch 31: 100%|██████████| 26/26 [00:00<00:00, 55.18it/s, train_loss=0.00207, val_loss=0.00231]Epoch 31:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00207, val_loss=0.00231]         Epoch 32:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00207, val_loss=0.00231]Epoch 32:   4%|▍         | 1/26 [00:00<00:00, 85.03it/s, train_loss=0.00207, val_loss=0.00231]Epoch 32:   4%|▍         | 1/26 [00:00<00:00, 64.11it/s, train_loss=0.00211, val_loss=0.00231]Epoch 32:   8%|▊         | 2/26 [00:00<00:00, 77.15it/s, train_loss=0.00211, val_loss=0.00231]Epoch 32:   8%|▊         | 2/26 [00:00<00:00, 61.28it/s, train_loss=0.00207, val_loss=0.00231]Epoch 32:  12%|█▏        | 3/26 [00:00<00:00, 70.76it/s, train_loss=0.00207, val_loss=0.00231]Epoch 32:  12%|█▏        | 3/26 [00:00<00:00, 59.41it/s, train_loss=0.00201, val_loss=0.00231]Epoch 32:  15%|█▌        | 4/26 [00:00<00:00, 65.16it/s, train_loss=0.00201, val_loss=0.00231]Epoch 32:  15%|█▌        | 4/26 [00:00<00:00, 61.11it/s, train_loss=0.002, val_loss=0.00231]  Epoch 32:  19%|█▉        | 5/26 [00:00<00:00, 65.48it/s, train_loss=0.002, val_loss=0.00231]Epoch 32:  19%|█▉        | 5/26 [00:00<00:00, 60.72it/s, train_loss=0.00206, val_loss=0.00231]Epoch 32:  23%|██▎       | 6/26 [00:00<00:00, 65.84it/s, train_loss=0.00206, val_loss=0.00231]Epoch 32:  23%|██▎       | 6/26 [00:00<00:00, 61.98it/s, train_loss=0.00192, val_loss=0.00231]Epoch 32:  27%|██▋       | 7/26 [00:00<00:00, 65.20it/s, train_loss=0.00192, val_loss=0.00231]Epoch 32:  27%|██▋       | 7/26 [00:00<00:00, 61.95it/s, train_loss=0.00194, val_loss=0.00231]Epoch 32:  31%|███       | 8/26 [00:00<00:00, 65.68it/s, train_loss=0.00194, val_loss=0.00231]Epoch 32:  31%|███       | 8/26 [00:00<00:00, 62.71it/s, train_loss=0.00199, val_loss=0.00231]Epoch 32:  35%|███▍      | 9/26 [00:00<00:00, 65.15it/s, train_loss=0.00199, val_loss=0.00231]Epoch 32:  35%|███▍      | 9/26 [00:00<00:00, 62.61it/s, train_loss=0.00183, val_loss=0.00231]Epoch 32:  38%|███▊      | 10/26 [00:00<00:00, 65.55it/s, train_loss=0.00183, val_loss=0.00231]Epoch 32:  38%|███▊      | 10/26 [00:00<00:00, 63.15it/s, train_loss=0.00188, val_loss=0.00231]Epoch 32:  42%|████▏     | 11/26 [00:00<00:00, 64.94it/s, train_loss=0.00188, val_loss=0.00231]Epoch 32:  42%|████▏     | 11/26 [00:00<00:00, 63.08it/s, train_loss=0.00203, val_loss=0.00231]Epoch 32:  46%|████▌     | 12/26 [00:00<00:00, 65.36it/s, train_loss=0.00203, val_loss=0.00231]Epoch 32:  46%|████▌     | 12/26 [00:00<00:00, 63.44it/s, train_loss=0.00189, val_loss=0.00231]Epoch 32:  50%|█████     | 13/26 [00:00<00:00, 64.93it/s, train_loss=0.00189, val_loss=0.00231]Epoch 32:  50%|█████     | 13/26 [00:00<00:00, 63.32it/s, train_loss=0.00198, val_loss=0.00231]Epoch 32:  54%|█████▍    | 14/26 [00:00<00:00, 62.63it/s, train_loss=0.00198, val_loss=0.00231]Epoch 32:  54%|█████▍    | 14/26 [00:00<00:00, 61.47it/s, train_loss=0.00191, val_loss=0.00231]Epoch 32:  58%|█████▊    | 15/26 [00:00<00:00, 62.82it/s, train_loss=0.00191, val_loss=0.00231]Epoch 32:  58%|█████▊    | 15/26 [00:00<00:00, 61.64it/s, train_loss=0.00205, val_loss=0.00231]Epoch 32:  62%|██████▏   | 16/26 [00:00<00:00, 63.39it/s, train_loss=0.00205, val_loss=0.00231]Epoch 32:  62%|██████▏   | 16/26 [00:00<00:00, 61.97it/s, train_loss=0.00197, val_loss=0.00231]Epoch 32:  65%|██████▌   | 17/26 [00:00<00:00, 63.18it/s, train_loss=0.00197, val_loss=0.00231]Epoch 32:  65%|██████▌   | 17/26 [00:00<00:00, 62.08it/s, train_loss=0.00196, val_loss=0.00231]Epoch 32:  69%|██████▉   | 18/26 [00:00<00:00, 63.65it/s, train_loss=0.00196, val_loss=0.00231]Epoch 32:  69%|██████▉   | 18/26 [00:00<00:00, 62.35it/s, train_loss=0.00197, val_loss=0.00231]Epoch 32:  73%|███████▎  | 19/26 [00:00<00:00, 63.38it/s, train_loss=0.00197, val_loss=0.00231]Epoch 32:  73%|███████▎  | 19/26 [00:00<00:00, 62.46it/s, train_loss=0.00183, val_loss=0.00231]Epoch 32:  77%|███████▋  | 20/26 [00:00<00:00, 63.84it/s, train_loss=0.00183, val_loss=0.00231]Epoch 32:  77%|███████▋  | 20/26 [00:00<00:00, 62.67it/s, train_loss=0.00202, val_loss=0.00231]Epoch 32:  81%|████████  | 21/26 [00:00<00:00, 63.56it/s, train_loss=0.00202, val_loss=0.00231]Epoch 32:  81%|████████  | 21/26 [00:00<00:00, 62.75it/s, train_loss=0.00213, val_loss=0.00231]Epoch 32:  85%|████████▍ | 22/26 [00:00<00:00, 64.03it/s, train_loss=0.00213, val_loss=0.00231]Epoch 32:  85%|████████▍ | 22/26 [00:00<00:00, 62.94it/s, train_loss=0.00199, val_loss=0.00231]Epoch 32:  88%|████████▊ | 23/26 [00:00<00:00, 63.80it/s, train_loss=0.00199, val_loss=0.00231]Epoch 32:  88%|████████▊ | 23/26 [00:00<00:00, 62.99it/s, train_loss=0.00194, val_loss=0.00231]Epoch 32:  92%|█████████▏| 24/26 [00:00<00:00, 64.13it/s, train_loss=0.00194, val_loss=0.00231]Epoch 32:  92%|█████████▏| 24/26 [00:00<00:00, 63.14it/s, train_loss=0.00222, val_loss=0.00231]Epoch 32:  96%|█████████▌| 25/26 [00:00<00:00, 63.98it/s, train_loss=0.00222, val_loss=0.00231]Epoch 32:  96%|█████████▌| 25/26 [00:00<00:00, 63.17it/s, train_loss=0.00186, val_loss=0.00231]Epoch 32: 100%|██████████| 26/26 [00:00<00:00, 64.29it/s, train_loss=0.00186, val_loss=0.00231]Epoch 32: 100%|██████████| 26/26 [00:00<00:00, 63.41it/s, train_loss=0.00196, val_loss=0.00231]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 149.10it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 164.57it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 170.34it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 174.17it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 175.62it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 176.92it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 178.47it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 178.26it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 178.24it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 178.67it/s][A
                                                                         [AEpoch 32: 100%|██████████| 26/26 [00:00<00:00, 54.91it/s, train_loss=0.00196, val_loss=0.00226]Epoch 32: 100%|██████████| 26/26 [00:00<00:00, 54.80it/s, train_loss=0.00196, val_loss=0.00226]Epoch 32:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00196, val_loss=0.00226]         Epoch 33:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00196, val_loss=0.00226]Epoch 33:   4%|▍         | 1/26 [00:00<00:00, 86.32it/s, train_loss=0.00196, val_loss=0.00226]Epoch 33:   4%|▍         | 1/26 [00:00<00:00, 63.67it/s, train_loss=0.00204, val_loss=0.00226]Epoch 33:   8%|▊         | 2/26 [00:00<00:00, 77.16it/s, train_loss=0.00204, val_loss=0.00226]Epoch 33:   8%|▊         | 2/26 [00:00<00:00, 60.98it/s, train_loss=0.00196, val_loss=0.00226]Epoch 33:  12%|█▏        | 3/26 [00:00<00:00, 71.56it/s, train_loss=0.00196, val_loss=0.00226]Epoch 33:  12%|█▏        | 3/26 [00:00<00:00, 62.95it/s, train_loss=0.00205, val_loss=0.00226]Epoch 33:  15%|█▌        | 4/26 [00:00<00:00, 68.34it/s, train_loss=0.00205, val_loss=0.00226]Epoch 33:  15%|█▌        | 4/26 [00:00<00:00, 63.27it/s, train_loss=0.00209, val_loss=0.00226]Epoch 33:  19%|█▉        | 5/26 [00:00<00:00, 69.18it/s, train_loss=0.00209, val_loss=0.00226]Epoch 33:  19%|█▉        | 5/26 [00:00<00:00, 64.01it/s, train_loss=0.0019, val_loss=0.00226] Epoch 33:  23%|██▎       | 6/26 [00:00<00:00, 67.23it/s, train_loss=0.0019, val_loss=0.00226]Epoch 33:  23%|██▎       | 6/26 [00:00<00:00, 63.98it/s, train_loss=0.00196, val_loss=0.00226]Epoch 33:  27%|██▋       | 7/26 [00:00<00:00, 67.23it/s, train_loss=0.00196, val_loss=0.00226]Epoch 33:  27%|██▋       | 7/26 [00:00<00:00, 62.47it/s, train_loss=0.00201, val_loss=0.00226]Epoch 33:  31%|███       | 8/26 [00:00<00:00, 65.26it/s, train_loss=0.00201, val_loss=0.00226]Epoch 33:  31%|███       | 8/26 [00:00<00:00, 62.83it/s, train_loss=0.00202, val_loss=0.00226]Epoch 33:  35%|███▍      | 9/26 [00:00<00:00, 65.02it/s, train_loss=0.00202, val_loss=0.00226]Epoch 33:  35%|███▍      | 9/26 [00:00<00:00, 62.76it/s, train_loss=0.00215, val_loss=0.00226]Epoch 33:  38%|███▊      | 10/26 [00:00<00:00, 65.57it/s, train_loss=0.00215, val_loss=0.00226]Epoch 33:  38%|███▊      | 10/26 [00:00<00:00, 63.15it/s, train_loss=0.00198, val_loss=0.00226]Epoch 33:  42%|████▏     | 11/26 [00:00<00:00, 64.88it/s, train_loss=0.00198, val_loss=0.00226]Epoch 33:  42%|████▏     | 11/26 [00:00<00:00, 63.27it/s, train_loss=0.00198, val_loss=0.00226]Epoch 33:  46%|████▌     | 12/26 [00:00<00:00, 65.73it/s, train_loss=0.00198, val_loss=0.00226]Epoch 33:  46%|████▌     | 12/26 [00:00<00:00, 63.70it/s, train_loss=0.00184, val_loss=0.00226]Epoch 33:  50%|█████     | 13/26 [00:00<00:00, 65.33it/s, train_loss=0.00184, val_loss=0.00226]Epoch 33:  50%|█████     | 13/26 [00:00<00:00, 63.55it/s, train_loss=0.00172, val_loss=0.00226]Epoch 33:  54%|█████▍    | 14/26 [00:00<00:00, 65.66it/s, train_loss=0.00172, val_loss=0.00226]Epoch 33:  54%|█████▍    | 14/26 [00:00<00:00, 63.89it/s, train_loss=0.00183, val_loss=0.00226]Epoch 33:  58%|█████▊    | 15/26 [00:00<00:00, 65.29it/s, train_loss=0.00183, val_loss=0.00226]Epoch 33:  58%|█████▊    | 15/26 [00:00<00:00, 63.77it/s, train_loss=0.00205, val_loss=0.00226]Epoch 33:  62%|██████▏   | 16/26 [00:00<00:00, 65.55it/s, train_loss=0.00205, val_loss=0.00226]Epoch 33:  62%|██████▏   | 16/26 [00:00<00:00, 64.00it/s, train_loss=0.00192, val_loss=0.00226]Epoch 33:  65%|██████▌   | 17/26 [00:00<00:00, 65.15it/s, train_loss=0.00192, val_loss=0.00226]Epoch 33:  65%|██████▌   | 17/26 [00:00<00:00, 63.93it/s, train_loss=0.00212, val_loss=0.00226]Epoch 33:  69%|██████▉   | 18/26 [00:00<00:00, 65.50it/s, train_loss=0.00212, val_loss=0.00226]Epoch 33:  69%|██████▉   | 18/26 [00:00<00:00, 64.13it/s, train_loss=0.00204, val_loss=0.00226]Epoch 33:  73%|███████▎  | 19/26 [00:00<00:00, 65.15it/s, train_loss=0.00204, val_loss=0.00226]Epoch 33:  73%|███████▎  | 19/26 [00:00<00:00, 64.12it/s, train_loss=0.00193, val_loss=0.00226]Epoch 33:  77%|███████▋  | 20/26 [00:00<00:00, 65.07it/s, train_loss=0.00193, val_loss=0.00226]Epoch 33:  77%|███████▋  | 20/26 [00:00<00:00, 64.16it/s, train_loss=0.00199, val_loss=0.00226]Epoch 33:  81%|████████  | 21/26 [00:00<00:00, 64.83it/s, train_loss=0.00199, val_loss=0.00226]Epoch 33:  81%|████████  | 21/26 [00:00<00:00, 64.15it/s, train_loss=0.00201, val_loss=0.00226]Epoch 33:  85%|████████▍ | 22/26 [00:00<00:00, 65.05it/s, train_loss=0.00201, val_loss=0.00226]Epoch 33:  85%|████████▍ | 22/26 [00:00<00:00, 64.20it/s, train_loss=0.00212, val_loss=0.00226]Epoch 33:  88%|████████▊ | 23/26 [00:00<00:00, 64.76it/s, train_loss=0.00212, val_loss=0.00226]Epoch 33:  88%|████████▊ | 23/26 [00:00<00:00, 64.18it/s, train_loss=0.00194, val_loss=0.00226]Epoch 33:  92%|█████████▏| 24/26 [00:00<00:00, 65.06it/s, train_loss=0.00194, val_loss=0.00226]Epoch 33:  92%|█████████▏| 24/26 [00:00<00:00, 64.25it/s, train_loss=0.00197, val_loss=0.00226]Epoch 33:  96%|█████████▌| 25/26 [00:00<00:00, 64.83it/s, train_loss=0.00197, val_loss=0.00226]Epoch 33:  96%|█████████▌| 25/26 [00:00<00:00, 64.27it/s, train_loss=0.0021, val_loss=0.00226] Epoch 33: 100%|██████████| 26/26 [00:00<00:00, 65.05it/s, train_loss=0.0021, val_loss=0.00226]Epoch 33: 100%|██████████| 26/26 [00:00<00:00, 64.39it/s, train_loss=0.0019, val_loss=0.00226]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 103.68it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 118.23it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 125.01it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 126.83it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 131.33it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 135.97it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 140.35it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 143.80it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 146.10it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 148.30it/s][A
                                                                         [AEpoch 33: 100%|██████████| 26/26 [00:00<00:00, 54.09it/s, train_loss=0.0019, val_loss=0.00227]Epoch 33: 100%|██████████| 26/26 [00:00<00:00, 54.00it/s, train_loss=0.0019, val_loss=0.00227]Epoch 33:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0019, val_loss=0.00227]         Epoch 34:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.0019, val_loss=0.00227]Epoch 34:   4%|▍         | 1/26 [00:00<00:00, 78.27it/s, train_loss=0.0019, val_loss=0.00227]Epoch 34:   4%|▍         | 1/26 [00:00<00:00, 53.79it/s, train_loss=0.0021, val_loss=0.00227]Epoch 34:   8%|▊         | 2/26 [00:00<00:00, 67.33it/s, train_loss=0.0021, val_loss=0.00227]Epoch 34:   8%|▊         | 2/26 [00:00<00:00, 58.53it/s, train_loss=0.00194, val_loss=0.00227]Epoch 34:  12%|█▏        | 3/26 [00:00<00:00, 63.44it/s, train_loss=0.00194, val_loss=0.00227]Epoch 34:  12%|█▏        | 3/26 [00:00<00:00, 59.24it/s, train_loss=0.00214, val_loss=0.00227]Epoch 34:  15%|█▌        | 4/26 [00:00<00:00, 64.87it/s, train_loss=0.00214, val_loss=0.00227]Epoch 34:  15%|█▌        | 4/26 [00:00<00:00, 60.46it/s, train_loss=0.00187, val_loss=0.00227]Epoch 34:  19%|█▉        | 5/26 [00:00<00:00, 64.12it/s, train_loss=0.00187, val_loss=0.00227]Epoch 34:  19%|█▉        | 5/26 [00:00<00:00, 61.35it/s, train_loss=0.00181, val_loss=0.00227]Epoch 34:  23%|██▎       | 6/26 [00:00<00:00, 65.18it/s, train_loss=0.00181, val_loss=0.00227]Epoch 34:  23%|██▎       | 6/26 [00:00<00:00, 62.09it/s, train_loss=0.00189, val_loss=0.00227]Epoch 34:  27%|██▋       | 7/26 [00:00<00:00, 64.43it/s, train_loss=0.00189, val_loss=0.00227]Epoch 34:  27%|██▋       | 7/26 [00:00<00:00, 62.37it/s, train_loss=0.00193, val_loss=0.00227]Epoch 34:  31%|███       | 8/26 [00:00<00:00, 65.15it/s, train_loss=0.00193, val_loss=0.00227]Epoch 34:  31%|███       | 8/26 [00:00<00:00, 62.78it/s, train_loss=0.00216, val_loss=0.00227]Epoch 34:  35%|███▍      | 9/26 [00:00<00:00, 64.54it/s, train_loss=0.00216, val_loss=0.00227]Epoch 34:  35%|███▍      | 9/26 [00:00<00:00, 62.93it/s, train_loss=0.00189, val_loss=0.00227]Epoch 34:  38%|███▊      | 10/26 [00:00<00:00, 65.19it/s, train_loss=0.00189, val_loss=0.00227]Epoch 34:  38%|███▊      | 10/26 [00:00<00:00, 63.19it/s, train_loss=0.00185, val_loss=0.00227]Epoch 34:  42%|████▏     | 11/26 [00:00<00:00, 64.59it/s, train_loss=0.00185, val_loss=0.00227]Epoch 34:  42%|████▏     | 11/26 [00:00<00:00, 63.28it/s, train_loss=0.00192, val_loss=0.00227]Epoch 34:  46%|████▌     | 12/26 [00:00<00:00, 64.99it/s, train_loss=0.00192, val_loss=0.00227]Epoch 34:  46%|████▌     | 12/26 [00:00<00:00, 63.44it/s, train_loss=0.00187, val_loss=0.00227]Epoch 34:  50%|█████     | 13/26 [00:00<00:00, 64.51it/s, train_loss=0.00187, val_loss=0.00227]Epoch 34:  50%|█████     | 13/26 [00:00<00:00, 63.47it/s, train_loss=0.00206, val_loss=0.00227]Epoch 34:  54%|█████▍    | 14/26 [00:00<00:00, 64.74it/s, train_loss=0.00206, val_loss=0.00227]Epoch 34:  54%|█████▍    | 14/26 [00:00<00:00, 63.50it/s, train_loss=0.00182, val_loss=0.00227]Epoch 34:  58%|█████▊    | 15/26 [00:00<00:00, 64.33it/s, train_loss=0.00182, val_loss=0.00227]Epoch 34:  58%|█████▊    | 15/26 [00:00<00:00, 63.43it/s, train_loss=0.00202, val_loss=0.00227]Epoch 34:  62%|██████▏   | 16/26 [00:00<00:00, 64.72it/s, train_loss=0.00202, val_loss=0.00227]Epoch 34:  62%|██████▏   | 16/26 [00:00<00:00, 63.00it/s, train_loss=0.00207, val_loss=0.00227]Epoch 34:  65%|██████▌   | 17/26 [00:00<00:00, 63.89it/s, train_loss=0.00207, val_loss=0.00227]Epoch 34:  65%|██████▌   | 17/26 [00:00<00:00, 63.10it/s, train_loss=0.00197, val_loss=0.00227]Epoch 34:  69%|██████▉   | 18/26 [00:00<00:00, 64.34it/s, train_loss=0.00197, val_loss=0.00227]Epoch 34:  69%|██████▉   | 18/26 [00:00<00:00, 63.30it/s, train_loss=0.00213, val_loss=0.00227]Epoch 34:  73%|███████▎  | 19/26 [00:00<00:00, 64.11it/s, train_loss=0.00213, val_loss=0.00227]Epoch 34:  73%|███████▎  | 19/26 [00:00<00:00, 63.42it/s, train_loss=0.00189, val_loss=0.00227]Epoch 34:  77%|███████▋  | 20/26 [00:00<00:00, 64.50it/s, train_loss=0.00189, val_loss=0.00227]Epoch 34:  77%|███████▋  | 20/26 [00:00<00:00, 63.54it/s, train_loss=0.00196, val_loss=0.00227]Epoch 34:  81%|████████  | 21/26 [00:00<00:00, 64.33it/s, train_loss=0.00196, val_loss=0.00227]Epoch 34:  81%|████████  | 21/26 [00:00<00:00, 63.53it/s, train_loss=0.00179, val_loss=0.00227]Epoch 34:  85%|████████▍ | 22/26 [00:00<00:00, 64.54it/s, train_loss=0.00179, val_loss=0.00227]Epoch 34:  85%|████████▍ | 22/26 [00:00<00:00, 63.66it/s, train_loss=0.00196, val_loss=0.00227]Epoch 34:  88%|████████▊ | 23/26 [00:00<00:00, 64.34it/s, train_loss=0.00196, val_loss=0.00227]Epoch 34:  88%|████████▊ | 23/26 [00:00<00:00, 63.65it/s, train_loss=0.00182, val_loss=0.00227]Epoch 34:  92%|█████████▏| 24/26 [00:00<00:00, 64.53it/s, train_loss=0.00182, val_loss=0.00227]Epoch 34:  92%|█████████▏| 24/26 [00:00<00:00, 63.75it/s, train_loss=0.00211, val_loss=0.00227]Epoch 34:  96%|█████████▌| 25/26 [00:00<00:00, 64.34it/s, train_loss=0.00211, val_loss=0.00227]Epoch 34:  96%|█████████▌| 25/26 [00:00<00:00, 63.74it/s, train_loss=0.00196, val_loss=0.00227]Epoch 34: 100%|██████████| 26/26 [00:00<00:00, 64.55it/s, train_loss=0.00196, val_loss=0.00227]Epoch 34: 100%|██████████| 26/26 [00:00<00:00, 63.85it/s, train_loss=0.00187, val_loss=0.00227]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 119.63it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 127.97it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 131.54it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 132.14it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 133.36it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 133.44it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 134.41it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 134.44it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 135.10it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 136.39it/s][A
                                                                         [AEpoch 34: 100%|██████████| 26/26 [00:00<00:00, 52.98it/s, train_loss=0.00187, val_loss=0.0023] Epoch 34: 100%|██████████| 26/26 [00:00<00:00, 52.86it/s, train_loss=0.00187, val_loss=0.0023]Epoch 34:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00187, val_loss=0.0023]         Epoch 35:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00187, val_loss=0.0023]Epoch 35:   4%|▍         | 1/26 [00:00<00:00, 76.00it/s, train_loss=0.00187, val_loss=0.0023]Epoch 35:   4%|▍         | 1/26 [00:00<00:00, 60.67it/s, train_loss=0.00199, val_loss=0.0023]Epoch 35:   8%|▊         | 2/26 [00:00<00:00, 74.94it/s, train_loss=0.00199, val_loss=0.0023]Epoch 35:   8%|▊         | 2/26 [00:00<00:00, 64.04it/s, train_loss=0.00191, val_loss=0.0023]Epoch 35:  12%|█▏        | 3/26 [00:00<00:00, 69.47it/s, train_loss=0.00191, val_loss=0.0023]Epoch 35:  12%|█▏        | 3/26 [00:00<00:00, 63.19it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  15%|█▌        | 4/26 [00:00<00:00, 69.16it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  15%|█▌        | 4/26 [00:00<00:00, 64.07it/s, train_loss=0.00185, val_loss=0.0023]Epoch 35:  19%|█▉        | 5/26 [00:00<00:00, 67.30it/s, train_loss=0.00185, val_loss=0.0023]Epoch 35:  19%|█▉        | 5/26 [00:00<00:00, 63.70it/s, train_loss=0.00197, val_loss=0.0023]Epoch 35:  23%|██▎       | 6/26 [00:00<00:00, 68.45it/s, train_loss=0.00197, val_loss=0.0023]Epoch 35:  23%|██▎       | 6/26 [00:00<00:00, 64.17it/s, train_loss=0.00177, val_loss=0.0023]Epoch 35:  27%|██▋       | 7/26 [00:00<00:00, 66.69it/s, train_loss=0.00177, val_loss=0.0023]Epoch 35:  27%|██▋       | 7/26 [00:00<00:00, 63.76it/s, train_loss=0.00192, val_loss=0.0023]Epoch 35:  31%|███       | 8/26 [00:00<00:00, 67.41it/s, train_loss=0.00192, val_loss=0.0023]Epoch 35:  31%|███       | 8/26 [00:00<00:00, 64.21it/s, train_loss=0.0022, val_loss=0.0023] Epoch 35:  35%|███▍      | 9/26 [00:00<00:00, 66.65it/s, train_loss=0.0022, val_loss=0.0023]Epoch 35:  35%|███▍      | 9/26 [00:00<00:00, 64.12it/s, train_loss=0.00219, val_loss=0.0023]Epoch 35:  38%|███▊      | 10/26 [00:00<00:00, 67.09it/s, train_loss=0.00219, val_loss=0.0023]Epoch 35:  38%|███▊      | 10/26 [00:00<00:00, 64.48it/s, train_loss=0.00197, val_loss=0.0023]Epoch 35:  42%|████▏     | 11/26 [00:00<00:00, 66.56it/s, train_loss=0.00197, val_loss=0.0023]Epoch 35:  42%|████▏     | 11/26 [00:00<00:00, 64.24it/s, train_loss=0.00203, val_loss=0.0023]Epoch 35:  46%|████▌     | 12/26 [00:00<00:00, 66.62it/s, train_loss=0.00203, val_loss=0.0023]Epoch 35:  46%|████▌     | 12/26 [00:00<00:00, 64.50it/s, train_loss=0.00193, val_loss=0.0023]Epoch 35:  50%|█████     | 13/26 [00:00<00:00, 66.11it/s, train_loss=0.00193, val_loss=0.0023]Epoch 35:  50%|█████     | 13/26 [00:00<00:00, 64.45it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  54%|█████▍    | 14/26 [00:00<00:00, 66.55it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  54%|█████▍    | 14/26 [00:00<00:00, 64.69it/s, train_loss=0.00191, val_loss=0.0023]Epoch 35:  58%|█████▊    | 15/26 [00:00<00:00, 66.12it/s, train_loss=0.00191, val_loss=0.0023]Epoch 35:  58%|█████▊    | 15/26 [00:00<00:00, 64.65it/s, train_loss=0.00177, val_loss=0.0023]Epoch 35:  62%|██████▏   | 16/26 [00:00<00:00, 66.42it/s, train_loss=0.00177, val_loss=0.0023]Epoch 35:  62%|██████▏   | 16/26 [00:00<00:00, 64.80it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  65%|██████▌   | 17/26 [00:00<00:00, 66.04it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  65%|██████▌   | 17/26 [00:00<00:00, 64.75it/s, train_loss=0.00191, val_loss=0.0023]Epoch 35:  69%|██████▉   | 18/26 [00:00<00:00, 66.26it/s, train_loss=0.00191, val_loss=0.0023]Epoch 35:  69%|██████▉   | 18/26 [00:00<00:00, 64.88it/s, train_loss=0.00188, val_loss=0.0023]Epoch 35:  73%|███████▎  | 19/26 [00:00<00:00, 65.89it/s, train_loss=0.00188, val_loss=0.0023]Epoch 35:  73%|███████▎  | 19/26 [00:00<00:00, 64.88it/s, train_loss=0.00192, val_loss=0.0023]Epoch 35:  77%|███████▋  | 20/26 [00:00<00:00, 66.27it/s, train_loss=0.00192, val_loss=0.0023]Epoch 35:  77%|███████▋  | 20/26 [00:00<00:00, 64.97it/s, train_loss=0.00213, val_loss=0.0023]Epoch 35:  81%|████████  | 21/26 [00:00<00:00, 65.88it/s, train_loss=0.00213, val_loss=0.0023]Epoch 35:  81%|████████  | 21/26 [00:00<00:00, 64.95it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  85%|████████▍ | 22/26 [00:00<00:00, 66.35it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35:  85%|████████▍ | 22/26 [00:00<00:00, 65.12it/s, train_loss=0.00203, val_loss=0.0023]Epoch 35:  88%|████████▊ | 23/26 [00:00<00:00, 66.10it/s, train_loss=0.00203, val_loss=0.0023]Epoch 35:  88%|████████▊ | 23/26 [00:00<00:00, 64.99it/s, train_loss=0.00181, val_loss=0.0023]Epoch 35:  92%|█████████▏| 24/26 [00:00<00:00, 66.24it/s, train_loss=0.00181, val_loss=0.0023]Epoch 35:  92%|█████████▏| 24/26 [00:00<00:00, 65.15it/s, train_loss=0.002, val_loss=0.0023]  Epoch 35:  96%|█████████▌| 25/26 [00:00<00:00, 66.08it/s, train_loss=0.002, val_loss=0.0023]Epoch 35:  96%|█████████▌| 25/26 [00:00<00:00, 65.02it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35: 100%|██████████| 26/26 [00:00<00:00, 66.15it/s, train_loss=0.00195, val_loss=0.0023]Epoch 35: 100%|██████████| 26/26 [00:00<00:00, 65.18it/s, train_loss=0.00191, val_loss=0.0023]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 134.14it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 153.37it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 160.80it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 165.48it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 170.40it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 173.70it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 176.20it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 173.94it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 173.46it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 175.39it/s][A
                                                                         [AEpoch 35: 100%|██████████| 26/26 [00:00<00:00, 56.07it/s, train_loss=0.00191, val_loss=0.00225]Epoch 35: 100%|██████████| 26/26 [00:00<00:00, 55.96it/s, train_loss=0.00191, val_loss=0.00225]Epoch 35:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00191, val_loss=0.00225]         Epoch 36:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00191, val_loss=0.00225]Epoch 36:   4%|▍         | 1/26 [00:00<00:00, 88.85it/s, train_loss=0.00191, val_loss=0.00225]Epoch 36:   4%|▍         | 1/26 [00:00<00:00, 64.59it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:   8%|▊         | 2/26 [00:00<00:00, 79.02it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:   8%|▊         | 2/26 [00:00<00:00, 61.55it/s, train_loss=0.00201, val_loss=0.00225]Epoch 36:  12%|█▏        | 3/26 [00:00<00:00, 72.17it/s, train_loss=0.00201, val_loss=0.00225]Epoch 36:  12%|█▏        | 3/26 [00:00<00:00, 63.30it/s, train_loss=0.00204, val_loss=0.00225]Epoch 36:  15%|█▌        | 4/26 [00:00<00:00, 68.64it/s, train_loss=0.00204, val_loss=0.00225]Epoch 36:  15%|█▌        | 4/26 [00:00<00:00, 63.78it/s, train_loss=0.00187, val_loss=0.00225]Epoch 36:  19%|█▉        | 5/26 [00:00<00:00, 69.74it/s, train_loss=0.00187, val_loss=0.00225]Epoch 36:  19%|█▉        | 5/26 [00:00<00:00, 64.44it/s, train_loss=0.00182, val_loss=0.00225]Epoch 36:  23%|██▎       | 6/26 [00:00<00:00, 67.77it/s, train_loss=0.00182, val_loss=0.00225]Epoch 36:  23%|██▎       | 6/26 [00:00<00:00, 64.43it/s, train_loss=0.00186, val_loss=0.00225]Epoch 36:  27%|██▋       | 7/26 [00:00<00:00, 68.27it/s, train_loss=0.00186, val_loss=0.00225]Epoch 36:  27%|██▋       | 7/26 [00:00<00:00, 64.77it/s, train_loss=0.00187, val_loss=0.00225]Epoch 36:  31%|███       | 8/26 [00:00<00:00, 67.55it/s, train_loss=0.00187, val_loss=0.00225]Epoch 36:  31%|███       | 8/26 [00:00<00:00, 64.67it/s, train_loss=0.00191, val_loss=0.00225]Epoch 36:  35%|███▍      | 9/26 [00:00<00:00, 68.10it/s, train_loss=0.00191, val_loss=0.00225]Epoch 36:  35%|███▍      | 9/26 [00:00<00:00, 65.13it/s, train_loss=0.00191, val_loss=0.00225]Epoch 36:  38%|███▊      | 10/26 [00:00<00:00, 67.39it/s, train_loss=0.00191, val_loss=0.00225]Epoch 36:  38%|███▊      | 10/26 [00:00<00:00, 64.79it/s, train_loss=0.00192, val_loss=0.00225]Epoch 36:  42%|████▏     | 11/26 [00:00<00:00, 67.52it/s, train_loss=0.00192, val_loss=0.00225]Epoch 36:  42%|████▏     | 11/26 [00:00<00:00, 65.11it/s, train_loss=0.0019, val_loss=0.00225] Epoch 36:  46%|████▌     | 12/26 [00:00<00:00, 66.86it/s, train_loss=0.0019, val_loss=0.00225]Epoch 36:  46%|████▌     | 12/26 [00:00<00:00, 64.94it/s, train_loss=0.00181, val_loss=0.00225]Epoch 36:  50%|█████     | 13/26 [00:00<00:00, 67.24it/s, train_loss=0.00181, val_loss=0.00225]Epoch 36:  50%|█████     | 13/26 [00:00<00:00, 65.21it/s, train_loss=0.00199, val_loss=0.00225]Epoch 36:  54%|█████▍    | 14/26 [00:00<00:00, 66.77it/s, train_loss=0.00199, val_loss=0.00225]Epoch 36:  54%|█████▍    | 14/26 [00:00<00:00, 64.96it/s, train_loss=0.00171, val_loss=0.00225]Epoch 36:  58%|█████▊    | 15/26 [00:00<00:00, 66.91it/s, train_loss=0.00171, val_loss=0.00225]Epoch 36:  58%|█████▊    | 15/26 [00:00<00:00, 65.12it/s, train_loss=0.00204, val_loss=0.00225]Epoch 36:  62%|██████▏   | 16/26 [00:00<00:00, 66.46it/s, train_loss=0.00204, val_loss=0.00225]Epoch 36:  62%|██████▏   | 16/26 [00:00<00:00, 65.06it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:  65%|██████▌   | 17/26 [00:00<00:00, 66.77it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:  65%|██████▌   | 17/26 [00:00<00:00, 65.19it/s, train_loss=0.00184, val_loss=0.00225]Epoch 36:  69%|██████▉   | 18/26 [00:00<00:00, 66.21it/s, train_loss=0.00184, val_loss=0.00225]Epoch 36:  69%|██████▉   | 18/26 [00:00<00:00, 65.09it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:  73%|███████▎  | 19/26 [00:00<00:00, 66.48it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:  73%|███████▎  | 19/26 [00:00<00:00, 65.18it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:  77%|███████▋  | 20/26 [00:00<00:00, 66.23it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36:  77%|███████▋  | 20/26 [00:00<00:00, 65.12it/s, train_loss=0.00222, val_loss=0.00225]Epoch 36:  81%|████████  | 21/26 [00:00<00:00, 66.47it/s, train_loss=0.00222, val_loss=0.00225]Epoch 36:  81%|████████  | 21/26 [00:00<00:00, 65.24it/s, train_loss=0.00195, val_loss=0.00225]Epoch 36:  85%|████████▍ | 22/26 [00:00<00:00, 66.19it/s, train_loss=0.00195, val_loss=0.00225]Epoch 36:  85%|████████▍ | 22/26 [00:00<00:00, 65.19it/s, train_loss=0.00194, val_loss=0.00225]Epoch 36:  88%|████████▊ | 23/26 [00:00<00:00, 66.40it/s, train_loss=0.00194, val_loss=0.00225]Epoch 36:  88%|████████▊ | 23/26 [00:00<00:00, 65.28it/s, train_loss=0.00199, val_loss=0.00225]Epoch 36:  92%|█████████▏| 24/26 [00:00<00:00, 66.13it/s, train_loss=0.00199, val_loss=0.00225]Epoch 36:  92%|█████████▏| 24/26 [00:00<00:00, 65.23it/s, train_loss=0.00196, val_loss=0.00225]Epoch 36:  96%|█████████▌| 25/26 [00:00<00:00, 66.39it/s, train_loss=0.00196, val_loss=0.00225]Epoch 36:  96%|█████████▌| 25/26 [00:00<00:00, 65.31it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36: 100%|██████████| 26/26 [00:00<00:00, 66.14it/s, train_loss=0.00197, val_loss=0.00225]Epoch 36: 100%|██████████| 26/26 [00:00<00:00, 65.35it/s, train_loss=0.00199, val_loss=0.00225]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 163.75it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 181.77it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 189.78it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 193.75it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 196.12it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 198.71it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 198.08it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 195.56it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 195.85it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 196.81it/s][A
                                                                         [AEpoch 36: 100%|██████████| 26/26 [00:00<00:00, 56.99it/s, train_loss=0.00199, val_loss=0.00226]Epoch 36: 100%|██████████| 26/26 [00:00<00:00, 56.89it/s, train_loss=0.00199, val_loss=0.00226]Epoch 36:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00199, val_loss=0.00226]         Epoch 37:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00199, val_loss=0.00226]Epoch 37:   4%|▍         | 1/26 [00:00<00:00, 93.59it/s, train_loss=0.00199, val_loss=0.00226]Epoch 37:   4%|▍         | 1/26 [00:00<00:00, 64.38it/s, train_loss=0.00189, val_loss=0.00226]Epoch 37:   8%|▊         | 2/26 [00:00<00:00, 82.67it/s, train_loss=0.00189, val_loss=0.00226]Epoch 37:   8%|▊         | 2/26 [00:00<00:00, 61.66it/s, train_loss=0.00186, val_loss=0.00226]Epoch 37:  12%|█▏        | 3/26 [00:00<00:00, 70.65it/s, train_loss=0.00186, val_loss=0.00226]Epoch 37:  12%|█▏        | 3/26 [00:00<00:00, 63.38it/s, train_loss=0.00184, val_loss=0.00226]Epoch 37:  15%|█▌        | 4/26 [00:00<00:00, 71.10it/s, train_loss=0.00184, val_loss=0.00226]Epoch 37:  15%|█▌        | 4/26 [00:00<00:00, 62.26it/s, train_loss=0.00191, val_loss=0.00226]Epoch 37:  19%|█▉        | 5/26 [00:00<00:00, 67.48it/s, train_loss=0.00191, val_loss=0.00226]Epoch 37:  19%|█▉        | 5/26 [00:00<00:00, 63.25it/s, train_loss=0.00201, val_loss=0.00226]Epoch 37:  23%|██▎       | 6/26 [00:00<00:00, 67.01it/s, train_loss=0.00201, val_loss=0.00226]Epoch 37:  23%|██▎       | 6/26 [00:00<00:00, 62.52it/s, train_loss=0.00182, val_loss=0.00226]Epoch 37:  27%|██▋       | 7/26 [00:00<00:00, 66.72it/s, train_loss=0.00182, val_loss=0.00226]Epoch 37:  27%|██▋       | 7/26 [00:00<00:00, 63.20it/s, train_loss=0.00199, val_loss=0.00226]Epoch 37:  31%|███       | 8/26 [00:00<00:00, 65.92it/s, train_loss=0.00199, val_loss=0.00226]Epoch 37:  31%|███       | 8/26 [00:00<00:00, 63.22it/s, train_loss=0.00186, val_loss=0.00226]Epoch 37:  35%|███▍      | 9/26 [00:00<00:00, 66.44it/s, train_loss=0.00186, val_loss=0.00226]Epoch 37:  35%|███▍      | 9/26 [00:00<00:00, 63.67it/s, train_loss=0.00194, val_loss=0.00226]Epoch 37:  38%|███▊      | 10/26 [00:00<00:00, 65.86it/s, train_loss=0.00194, val_loss=0.00226]Epoch 37:  38%|███▊      | 10/26 [00:00<00:00, 63.74it/s, train_loss=0.00195, val_loss=0.00226]Epoch 37:  42%|████▏     | 11/26 [00:00<00:00, 66.38it/s, train_loss=0.00195, val_loss=0.00226]Epoch 37:  42%|████▏     | 11/26 [00:00<00:00, 64.03it/s, train_loss=0.00186, val_loss=0.00226]Epoch 37:  46%|████▌     | 12/26 [00:00<00:00, 65.85it/s, train_loss=0.00186, val_loss=0.00226]Epoch 37:  46%|████▌     | 12/26 [00:00<00:00, 64.05it/s, train_loss=0.00205, val_loss=0.00226]Epoch 37:  50%|█████     | 13/26 [00:00<00:00, 66.42it/s, train_loss=0.00205, val_loss=0.00226]Epoch 37:  50%|█████     | 13/26 [00:00<00:00, 64.42it/s, train_loss=0.00212, val_loss=0.00226]Epoch 37:  54%|█████▍    | 14/26 [00:00<00:00, 65.97it/s, train_loss=0.00212, val_loss=0.00226]Epoch 37:  54%|█████▍    | 14/26 [00:00<00:00, 64.22it/s, train_loss=0.00199, val_loss=0.00226]Epoch 37:  58%|█████▊    | 15/26 [00:00<00:00, 65.92it/s, train_loss=0.00199, val_loss=0.00226]Epoch 37:  58%|█████▊    | 15/26 [00:00<00:00, 64.28it/s, train_loss=0.00211, val_loss=0.00226]Epoch 37:  62%|██████▏   | 16/26 [00:00<00:00, 65.61it/s, train_loss=0.00211, val_loss=0.00226]Epoch 37:  62%|██████▏   | 16/26 [00:00<00:00, 64.32it/s, train_loss=0.00201, val_loss=0.00226]Epoch 37:  65%|██████▌   | 17/26 [00:00<00:00, 66.08it/s, train_loss=0.00201, val_loss=0.00226]Epoch 37:  65%|██████▌   | 17/26 [00:00<00:00, 64.54it/s, train_loss=0.00188, val_loss=0.00226]Epoch 37:  69%|██████▉   | 18/26 [00:00<00:00, 65.67it/s, train_loss=0.00188, val_loss=0.00226]Epoch 37:  69%|██████▉   | 18/26 [00:00<00:00, 64.39it/s, train_loss=0.00184, val_loss=0.00226]Epoch 37:  73%|███████▎  | 19/26 [00:00<00:00, 65.94it/s, train_loss=0.00184, val_loss=0.00226]Epoch 37:  73%|███████▎  | 19/26 [00:00<00:00, 64.58it/s, train_loss=0.00211, val_loss=0.00226]Epoch 37:  77%|███████▋  | 20/26 [00:00<00:00, 65.54it/s, train_loss=0.00211, val_loss=0.00226]Epoch 37:  77%|███████▋  | 20/26 [00:00<00:00, 64.46it/s, train_loss=0.00204, val_loss=0.00226]Epoch 37:  81%|████████  | 21/26 [00:00<00:00, 65.85it/s, train_loss=0.00204, val_loss=0.00226]Epoch 37:  81%|████████  | 21/26 [00:00<00:00, 64.61it/s, train_loss=0.00196, val_loss=0.00226]Epoch 37:  85%|████████▍ | 22/26 [00:00<00:00, 65.58it/s, train_loss=0.00196, val_loss=0.00226]Epoch 37:  85%|████████▍ | 22/26 [00:00<00:00, 64.44it/s, train_loss=0.00195, val_loss=0.00226]Epoch 37:  88%|████████▊ | 23/26 [00:00<00:00, 65.73it/s, train_loss=0.00195, val_loss=0.00226]Epoch 37:  88%|████████▊ | 23/26 [00:00<00:00, 64.60it/s, train_loss=0.0019, val_loss=0.00226] Epoch 37:  92%|█████████▏| 24/26 [00:00<00:00, 65.47it/s, train_loss=0.0019, val_loss=0.00226]Epoch 37:  92%|█████████▏| 24/26 [00:00<00:00, 64.44it/s, train_loss=0.00198, val_loss=0.00226]Epoch 37:  96%|█████████▌| 25/26 [00:00<00:00, 65.48it/s, train_loss=0.00198, val_loss=0.00226]Epoch 37:  96%|█████████▌| 25/26 [00:00<00:00, 64.50it/s, train_loss=0.0017, val_loss=0.00226] Epoch 37: 100%|██████████| 26/26 [00:00<00:00, 65.21it/s, train_loss=0.0017, val_loss=0.00226]Epoch 37: 100%|██████████| 26/26 [00:00<00:00, 64.45it/s, train_loss=0.002, val_loss=0.00226] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 116.25it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 135.12it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 139.43it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 144.03it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 146.87it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 149.03it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 151.77it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 153.72it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 155.24it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 159.38it/s][A
                                                                         [AEpoch 37: 100%|██████████| 26/26 [00:00<00:00, 54.91it/s, train_loss=0.002, val_loss=0.00227]Epoch 37: 100%|██████████| 26/26 [00:00<00:00, 54.82it/s, train_loss=0.002, val_loss=0.00227]Epoch 37:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.002, val_loss=0.00227]         Epoch 38:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.002, val_loss=0.00227]Epoch 38:   4%|▍         | 1/26 [00:00<00:00, 86.74it/s, train_loss=0.002, val_loss=0.00227]Epoch 38:   4%|▍         | 1/26 [00:00<00:00, 65.41it/s, train_loss=0.00196, val_loss=0.00227]Epoch 38:   8%|▊         | 2/26 [00:00<00:00, 84.25it/s, train_loss=0.00196, val_loss=0.00227]Epoch 38:   8%|▊         | 2/26 [00:00<00:00, 67.01it/s, train_loss=0.00213, val_loss=0.00227]Epoch 38:  12%|█▏        | 3/26 [00:00<00:00, 73.81it/s, train_loss=0.00213, val_loss=0.00227]Epoch 38:  12%|█▏        | 3/26 [00:00<00:00, 65.53it/s, train_loss=0.00185, val_loss=0.00227]Epoch 38:  15%|█▌        | 4/26 [00:00<00:00, 73.29it/s, train_loss=0.00185, val_loss=0.00227]Epoch 38:  15%|█▌        | 4/26 [00:00<00:00, 66.09it/s, train_loss=0.00178, val_loss=0.00227]Epoch 38:  19%|█▉        | 5/26 [00:00<00:00, 69.98it/s, train_loss=0.00178, val_loss=0.00227]Epoch 38:  19%|█▉        | 5/26 [00:00<00:00, 65.73it/s, train_loss=0.00191, val_loss=0.00227]Epoch 38:  23%|██▎       | 6/26 [00:00<00:00, 70.52it/s, train_loss=0.00191, val_loss=0.00227]Epoch 38:  23%|██▎       | 6/26 [00:00<00:00, 65.97it/s, train_loss=0.00217, val_loss=0.00227]Epoch 38:  27%|██▋       | 7/26 [00:00<00:00, 68.57it/s, train_loss=0.00217, val_loss=0.00227]Epoch 38:  27%|██▋       | 7/26 [00:00<00:00, 65.75it/s, train_loss=0.00183, val_loss=0.00227]Epoch 38:  31%|███       | 8/26 [00:00<00:00, 69.52it/s, train_loss=0.00183, val_loss=0.00227]Epoch 38:  31%|███       | 8/26 [00:00<00:00, 65.92it/s, train_loss=0.00195, val_loss=0.00227]Epoch 38:  35%|███▍      | 9/26 [00:00<00:00, 68.07it/s, train_loss=0.00195, val_loss=0.00227]Epoch 38:  35%|███▍      | 9/26 [00:00<00:00, 65.73it/s, train_loss=0.00188, val_loss=0.00227]Epoch 38:  38%|███▊      | 10/26 [00:00<00:00, 66.46it/s, train_loss=0.00188, val_loss=0.00227]Epoch 38:  38%|███▊      | 10/26 [00:00<00:00, 64.42it/s, train_loss=0.0022, val_loss=0.00227] Epoch 38:  42%|████▏     | 11/26 [00:00<00:00, 66.98it/s, train_loss=0.0022, val_loss=0.00227]Epoch 38:  42%|████▏     | 11/26 [00:00<00:00, 64.65it/s, train_loss=0.00199, val_loss=0.00227]Epoch 38:  46%|████▌     | 12/26 [00:00<00:00, 66.22it/s, train_loss=0.00199, val_loss=0.00227]Epoch 38:  46%|████▌     | 12/26 [00:00<00:00, 64.62it/s, train_loss=0.00187, val_loss=0.00227]Epoch 38:  50%|█████     | 13/26 [00:00<00:00, 66.80it/s, train_loss=0.00187, val_loss=0.00227]Epoch 38:  50%|█████     | 13/26 [00:00<00:00, 64.83it/s, train_loss=0.00201, val_loss=0.00227]Epoch 38:  54%|█████▍    | 14/26 [00:00<00:00, 66.22it/s, train_loss=0.00201, val_loss=0.00227]Epoch 38:  54%|█████▍    | 14/26 [00:00<00:00, 64.79it/s, train_loss=0.00192, val_loss=0.00227]Epoch 38:  58%|█████▊    | 15/26 [00:00<00:00, 66.68it/s, train_loss=0.00192, val_loss=0.00227]Epoch 38:  58%|█████▊    | 15/26 [00:00<00:00, 64.94it/s, train_loss=0.00201, val_loss=0.00227]Epoch 38:  62%|██████▏   | 16/26 [00:00<00:00, 66.08it/s, train_loss=0.00201, val_loss=0.00227]Epoch 38:  62%|██████▏   | 16/26 [00:00<00:00, 64.91it/s, train_loss=0.0019, val_loss=0.00227] Epoch 38:  65%|██████▌   | 17/26 [00:00<00:00, 66.57it/s, train_loss=0.0019, val_loss=0.00227]Epoch 38:  65%|██████▌   | 17/26 [00:00<00:00, 65.04it/s, train_loss=0.0019, val_loss=0.00227]Epoch 38:  69%|██████▉   | 18/26 [00:00<00:00, 66.19it/s, train_loss=0.0019, val_loss=0.00227]Epoch 38:  69%|██████▉   | 18/26 [00:00<00:00, 64.99it/s, train_loss=0.00194, val_loss=0.00227]Epoch 38:  73%|███████▎  | 19/26 [00:00<00:00, 66.55it/s, train_loss=0.00194, val_loss=0.00227]Epoch 38:  73%|███████▎  | 19/26 [00:00<00:00, 65.19it/s, train_loss=0.00175, val_loss=0.00227]Epoch 38:  77%|███████▋  | 20/26 [00:00<00:00, 66.13it/s, train_loss=0.00175, val_loss=0.00227]Epoch 38:  77%|███████▋  | 20/26 [00:00<00:00, 65.01it/s, train_loss=0.00207, val_loss=0.00227]Epoch 38:  81%|████████  | 21/26 [00:00<00:00, 66.18it/s, train_loss=0.00207, val_loss=0.00227]Epoch 38:  81%|████████  | 21/26 [00:00<00:00, 64.98it/s, train_loss=0.00193, val_loss=0.00227]Epoch 38:  85%|████████▍ | 22/26 [00:00<00:00, 65.86it/s, train_loss=0.00193, val_loss=0.00227]Epoch 38:  85%|████████▍ | 22/26 [00:00<00:00, 64.90it/s, train_loss=0.00189, val_loss=0.00227]Epoch 38:  88%|████████▊ | 23/26 [00:00<00:00, 66.13it/s, train_loss=0.00189, val_loss=0.00227]Epoch 38:  88%|████████▊ | 23/26 [00:00<00:00, 65.02it/s, train_loss=0.00195, val_loss=0.00227]Epoch 38:  92%|█████████▏| 24/26 [00:00<00:00, 65.81it/s, train_loss=0.00195, val_loss=0.00227]Epoch 38:  92%|█████████▏| 24/26 [00:00<00:00, 65.00it/s, train_loss=0.0019, val_loss=0.00227] Epoch 38:  96%|█████████▌| 25/26 [00:00<00:00, 66.20it/s, train_loss=0.0019, val_loss=0.00227]Epoch 38:  96%|█████████▌| 25/26 [00:00<00:00, 65.12it/s, train_loss=0.0021, val_loss=0.00227]Epoch 38: 100%|██████████| 26/26 [00:00<00:00, 65.88it/s, train_loss=0.0021, val_loss=0.00227]Epoch 38: 100%|██████████| 26/26 [00:00<00:00, 65.09it/s, train_loss=0.00186, val_loss=0.00227]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 126.56it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 142.94it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 147.73it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 152.71it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 158.11it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 161.25it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 161.61it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 162.39it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 163.64it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 165.21it/s][A
                                                                         [AEpoch 38: 100%|██████████| 26/26 [00:00<00:00, 55.39it/s, train_loss=0.00186, val_loss=0.00226]Epoch 38: 100%|██████████| 26/26 [00:00<00:00, 55.27it/s, train_loss=0.00186, val_loss=0.00226]Epoch 38:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00186, val_loss=0.00226]         Epoch 39:   0%|          | 0/26 [00:00<?, ?it/s, train_loss=0.00186, val_loss=0.00226]Epoch 39:   4%|▍         | 1/26 [00:00<00:00, 84.31it/s, train_loss=0.00186, val_loss=0.00226]Epoch 39:   4%|▍         | 1/26 [00:00<00:00, 63.54it/s, train_loss=0.00204, val_loss=0.00226]Epoch 39:   8%|▊         | 2/26 [00:00<00:00, 75.73it/s, train_loss=0.00204, val_loss=0.00226]Epoch 39:   8%|▊         | 2/26 [00:00<00:00, 61.42it/s, train_loss=0.002, val_loss=0.00226]  Epoch 39:  12%|█▏        | 3/26 [00:00<00:00, 72.17it/s, train_loss=0.002, val_loss=0.00226]Epoch 39:  12%|█▏        | 3/26 [00:00<00:00, 63.13it/s, train_loss=0.00197, val_loss=0.00226]Epoch 39:  15%|█▌        | 4/26 [00:00<00:00, 68.60it/s, train_loss=0.00197, val_loss=0.00226]Epoch 39:  15%|█▌        | 4/26 [00:00<00:00, 63.50it/s, train_loss=0.00189, val_loss=0.00226]Epoch 39:  19%|█▉        | 5/26 [00:00<00:00, 69.88it/s, train_loss=0.00189, val_loss=0.00226]Epoch 39:  19%|█▉        | 5/26 [00:00<00:00, 64.54it/s, train_loss=0.00206, val_loss=0.00226]Epoch 39:  23%|██▎       | 6/26 [00:00<00:00, 68.18it/s, train_loss=0.00206, val_loss=0.00226]Epoch 39:  23%|██▎       | 6/26 [00:00<00:00, 64.19it/s, train_loss=0.00188, val_loss=0.00226]Epoch 39:  27%|██▋       | 7/26 [00:00<00:00, 68.59it/s, train_loss=0.00188, val_loss=0.00226]Epoch 39:  27%|██▋       | 7/26 [00:00<00:00, 64.77it/s, train_loss=0.00185, val_loss=0.00226]Epoch 39:  31%|███       | 8/26 [00:00<00:00, 67.28it/s, train_loss=0.00185, val_loss=0.00226]Epoch 39:  31%|███       | 8/26 [00:00<00:00, 64.57it/s, train_loss=0.00203, val_loss=0.00226]Epoch 39:  35%|███▍      | 9/26 [00:00<00:00, 67.93it/s, train_loss=0.00203, val_loss=0.00226]Epoch 39:  35%|███▍      | 9/26 [00:00<00:00, 64.97it/s, train_loss=0.00202, val_loss=0.00226]Epoch 39:  38%|███▊      | 10/26 [00:00<00:00, 66.94it/s, train_loss=0.00202, val_loss=0.00226]Epoch 39:  38%|███▊      | 10/26 [00:00<00:00, 64.75it/s, train_loss=0.00191, val_loss=0.00226]Epoch 39:  42%|████▏     | 11/26 [00:00<00:00, 67.50it/s, train_loss=0.00191, val_loss=0.00226]Epoch 39:  42%|████▏     | 11/26 [00:00<00:00, 65.05it/s, train_loss=0.00203, val_loss=0.00226]Epoch 39:  46%|████▌     | 12/26 [00:00<00:00, 66.59it/s, train_loss=0.00203, val_loss=0.00226]Epoch 39:  46%|████▌     | 12/26 [00:00<00:00, 64.99it/s, train_loss=0.00191, val_loss=0.00226]Epoch 39:  50%|█████     | 13/26 [00:00<00:00, 67.22it/s, train_loss=0.00191, val_loss=0.00226]Epoch 39:  50%|█████     | 13/26 [00:00<00:00, 65.16it/s, train_loss=0.00171, val_loss=0.00226]Epoch 39:  54%|█████▍    | 14/26 [00:00<00:00, 65.66it/s, train_loss=0.00171, val_loss=0.00226]Epoch 39:  54%|█████▍    | 14/26 [00:00<00:00, 64.47it/s, train_loss=0.00185, val_loss=0.00226]Epoch 39:  58%|█████▊    | 15/26 [00:00<00:00, 66.40it/s, train_loss=0.00185, val_loss=0.00226]Epoch 39:  58%|█████▊    | 15/26 [00:00<00:00, 64.71it/s, train_loss=0.00197, val_loss=0.00226]Epoch 39:  62%|██████▏   | 16/26 [00:00<00:00, 65.91it/s, train_loss=0.00197, val_loss=0.00226]Epoch 39:  62%|██████▏   | 16/26 [00:00<00:00, 64.70it/s, train_loss=0.00199, val_loss=0.00226]Epoch 39:  65%|██████▌   | 17/26 [00:00<00:00, 66.40it/s, train_loss=0.00199, val_loss=0.00226]Epoch 39:  65%|██████▌   | 17/26 [00:00<00:00, 64.87it/s, train_loss=0.00205, val_loss=0.00226]Epoch 39:  69%|██████▉   | 18/26 [00:00<00:00, 65.90it/s, train_loss=0.00205, val_loss=0.00226]Epoch 39:  69%|██████▉   | 18/26 [00:00<00:00, 64.85it/s, train_loss=0.00187, val_loss=0.00226]Epoch 39:  73%|███████▎  | 19/26 [00:00<00:00, 66.37it/s, train_loss=0.00187, val_loss=0.00226]Epoch 39:  73%|███████▎  | 19/26 [00:00<00:00, 64.98it/s, train_loss=0.00176, val_loss=0.00226]Epoch 39:  77%|███████▋  | 20/26 [00:00<00:00, 65.87it/s, train_loss=0.00176, val_loss=0.00226]Epoch 39:  77%|███████▋  | 20/26 [00:00<00:00, 64.95it/s, train_loss=0.00202, val_loss=0.00226]Epoch 39:  81%|████████  | 21/26 [00:00<00:00, 66.29it/s, train_loss=0.00202, val_loss=0.00226]Epoch 39:  81%|████████  | 21/26 [00:00<00:00, 65.06it/s, train_loss=0.00183, val_loss=0.00226]Epoch 39:  85%|████████▍ | 22/26 [00:00<00:00, 65.92it/s, train_loss=0.00183, val_loss=0.00226]Epoch 39:  85%|████████▍ | 22/26 [00:00<00:00, 65.03it/s, train_loss=0.00186, val_loss=0.00226]Epoch 39:  88%|████████▊ | 23/26 [00:00<00:00, 66.31it/s, train_loss=0.00186, val_loss=0.00226]Epoch 39:  88%|████████▊ | 23/26 [00:00<00:00, 65.18it/s, train_loss=0.0022, val_loss=0.00226] Epoch 39:  92%|█████████▏| 24/26 [00:00<00:00, 66.05it/s, train_loss=0.0022, val_loss=0.00226]Epoch 39:  92%|█████████▏| 24/26 [00:00<00:00, 65.04it/s, train_loss=0.00201, val_loss=0.00226]Epoch 39:  96%|█████████▌| 25/26 [00:00<00:00, 66.10it/s, train_loss=0.00201, val_loss=0.00226]Epoch 39:  96%|█████████▌| 25/26 [00:00<00:00, 65.11it/s, train_loss=0.00186, val_loss=0.00226]Epoch 39: 100%|██████████| 26/26 [00:00<00:00, 65.81it/s, train_loss=0.00186, val_loss=0.00226]Epoch 39: 100%|██████████| 26/26 [00:00<00:00, 65.13it/s, train_loss=0.00193, val_loss=0.00226]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 137.72it/s][A
Validation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 155.24it/s][A
Validation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 167.00it/s][A
Validation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 172.82it/s][A
Validation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 173.02it/s][A
Validation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 173.91it/s][A
Validation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 176.15it/s][A
Validation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 178.24it/s][A
Validation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 180.07it/s][A
Validation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 178.69it/s][A
                                                                         [AEpoch 39: 100%|██████████| 26/26 [00:00<00:00, 56.17it/s, train_loss=0.00193, val_loss=0.00226]Epoch 39: 100%|██████████| 26/26 [00:00<00:00, 56.06it/s, train_loss=0.00193, val_loss=0.00226]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 26/26 [00:00<00:00, 55.60it/s, train_loss=0.00193, val_loss=0.00226]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/26 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▍         | 1/26 [00:00<00:00, 93.12it/s]Predicting DataLoader 0:   8%|▊         | 2/26 [00:00<00:00, 84.65it/s]Predicting DataLoader 0:  12%|█▏        | 3/26 [00:00<00:00, 82.88it/s]Predicting DataLoader 0:  15%|█▌        | 4/26 [00:00<00:00, 81.38it/s]Predicting DataLoader 0:  19%|█▉        | 5/26 [00:00<00:00, 80.46it/s]Predicting DataLoader 0:  23%|██▎       | 6/26 [00:00<00:00, 80.26it/s]Predicting DataLoader 0:  27%|██▋       | 7/26 [00:00<00:00, 80.10it/s]Predicting DataLoader 0:  31%|███       | 8/26 [00:00<00:00, 79.88it/s]Predicting DataLoader 0:  35%|███▍      | 9/26 [00:00<00:00, 79.62it/s]Predicting DataLoader 0:  38%|███▊      | 10/26 [00:00<00:00, 79.52it/s]Predicting DataLoader 0:  42%|████▏     | 11/26 [00:00<00:00, 79.42it/s]Predicting DataLoader 0:  46%|████▌     | 12/26 [00:00<00:00, 79.30it/s]Predicting DataLoader 0:  50%|█████     | 13/26 [00:00<00:00, 79.17it/s]Predicting DataLoader 0:  54%|█████▍    | 14/26 [00:00<00:00, 79.00it/s]Predicting DataLoader 0:  58%|█████▊    | 15/26 [00:00<00:00, 78.86it/s]Predicting DataLoader 0:  62%|██████▏   | 16/26 [00:00<00:00, 78.73it/s]Predicting DataLoader 0:  65%|██████▌   | 17/26 [00:00<00:00, 78.70it/s]Predicting DataLoader 0:  69%|██████▉   | 18/26 [00:00<00:00, 78.62it/s]Predicting DataLoader 0:  73%|███████▎  | 19/26 [00:00<00:00, 78.56it/s]Predicting DataLoader 0:  77%|███████▋  | 20/26 [00:00<00:00, 78.42it/s]Predicting DataLoader 0:  81%|████████  | 21/26 [00:00<00:00, 78.16it/s]Predicting DataLoader 0:  85%|████████▍ | 22/26 [00:00<00:00, 78.03it/s]Predicting DataLoader 0:  88%|████████▊ | 23/26 [00:00<00:00, 77.90it/s]Predicting DataLoader 0:  92%|█████████▏| 24/26 [00:00<00:00, 77.82it/s]Predicting DataLoader 0:  96%|█████████▌| 25/26 [00:00<00:00, 77.68it/s]Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 77.80it/s]Predicting DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 77.55it/s][I 2025-08-18 02:44:16,146] A new study created in memory with name: no-name-2779e4a1-0d79-4b82-965d-37131e606af2
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 160, Horizon length: 1
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.43it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.70it/s][I 2025-08-18 02:44:47,686] Trial 0 finished with value: 15.08051495854862 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 4, 'dropout': 0.25267873300774274}. Best is trial 0 with value: 15.08051495854862.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25742893352345153 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 293.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.36it/s][I 2025-08-18 02:45:13,132] Trial 1 finished with value: 10.939881801213085 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 1, 'dropout': 0.25742893352345153}. Best is trial 1 with value: 10.939881801213085.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 244.81it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.01it/s][I 2025-08-18 02:45:38,126] Trial 2 finished with value: 15.829796002100252 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 2, 'dropout': 0.41343599250608604}. Best is trial 1 with value: 10.939881801213085.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17937276723250162 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.17it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.45it/s][I 2025-08-18 02:46:05,324] Trial 3 finished with value: 12.44677233035551 and parameters: {'hidden_dim': 38, 'n_rnn_layers': 1, 'dropout': 0.17937276723250162}. Best is trial 1 with value: 10.939881801213085.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3452659051032006 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 295.10it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.17it/s][I 2025-08-18 02:46:31,637] Trial 4 finished with value: 10.533163115707676 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 1, 'dropout': 0.3452659051032006}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3012654018600898 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 291.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.00it/s][I 2025-08-18 02:46:52,384] Trial 5 finished with value: 20.67701327685171 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 1, 'dropout': 0.3012654018600898}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.05it/s][I 2025-08-18 02:47:39,591] Trial 6 finished with value: 20.552805958759333 and parameters: {'hidden_dim': 112, 'n_rnn_layers': 3, 'dropout': 0.15339248493576135}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.25it/s][I 2025-08-18 02:48:09,921] Trial 7 finished with value: 12.307506166164083 and parameters: {'hidden_dim': 33, 'n_rnn_layers': 2, 'dropout': 0.3953358283052214}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24446294821286468 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.18it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.52it/s][I 2025-08-18 02:48:32,423] Trial 8 finished with value: 13.642517236625954 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 1, 'dropout': 0.24446294821286468}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.44it/s][I 2025-08-18 02:49:00,221] Trial 9 finished with value: 13.71425688819194 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.49303139636023025}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.15it/s][I 2025-08-18 02:49:53,091] Trial 10 finished with value: 21.724563394702844 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 3, 'dropout': 0.03899288236320897}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.51it/s][I 2025-08-18 02:50:31,595] Trial 11 finished with value: 18.32110243433019 and parameters: {'hidden_dim': 55, 'n_rnn_layers': 2, 'dropout': 0.34497532842465195}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1463674114334382 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 253.10it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.07it/s][I 2025-08-18 02:51:04,365] Trial 12 finished with value: 15.051463740708064 and parameters: {'hidden_dim': 51, 'n_rnn_layers': 1, 'dropout': 0.1463674114334382}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33020083744603224 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 353.41it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 286.38it/s][I 2025-08-18 02:51:30,573] Trial 13 finished with value: 13.604658880886559 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 1, 'dropout': 0.33020083744603224}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.09it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.11it/s][I 2025-08-18 02:52:03,194] Trial 14 finished with value: 17.72579447734242 and parameters: {'hidden_dim': 41, 'n_rnn_layers': 2, 'dropout': 0.45813693178389314}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23248356271653625 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 344.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.04it/s][I 2025-08-18 02:52:39,594] Trial 15 finished with value: 15.769836920493805 and parameters: {'hidden_dim': 64, 'n_rnn_layers': 1, 'dropout': 0.23248356271653625}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.20it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.81it/s][I 2025-08-18 02:53:07,622] Trial 16 finished with value: 19.453917400151287 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 3, 'dropout': 0.04369495107804555}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.31it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.06it/s][I 2025-08-18 02:54:02,845] Trial 17 finished with value: 18.940303889547835 and parameters: {'hidden_dim': 99, 'n_rnn_layers': 2, 'dropout': 0.37685863275825837}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29756843923697024 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 312.31it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.22it/s][I 2025-08-18 02:54:32,176] Trial 18 finished with value: 14.862775939878798 and parameters: {'hidden_dim': 46, 'n_rnn_layers': 1, 'dropout': 0.29756843923697024}. Best is trial 4 with value: 10.533163115707676.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.36it/s][I 2025-08-18 02:55:01,824] Trial 19 finished with value: 13.491749265689583 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 2, 'dropout': 0.0815397016605311}. Best is trial 4 with value: 10.533163115707676.
[I 2025-08-18 02:55:01,825] A new study created in memory with name: no-name-a8e7bcc0-1c1e-4fbe-9030-25c25450bf96
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 39, 'n_rnn_layers': 1, 'dropout': 0.3452659051032006}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.36it/s][I 2025-08-18 02:55:32,846] Trial 0 finished with value: 15.669487827303515 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 4, 'dropout': 0.3391125130613955}. Best is trial 0 with value: 15.669487827303515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36823487516078673 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.76it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.07it/s][I 2025-08-18 02:56:01,677] Trial 1 finished with value: 17.100070998436937 and parameters: {'hidden_dim': 42, 'n_rnn_layers': 1, 'dropout': 0.36823487516078673}. Best is trial 0 with value: 15.669487827303515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.33it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.08it/s][I 2025-08-18 02:56:36,434] Trial 2 finished with value: 20.95024504588758 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 3, 'dropout': 0.2370416907619452}. Best is trial 0 with value: 15.669487827303515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.12it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.36it/s][I 2025-08-18 02:57:26,796] Trial 3 finished with value: 17.079409385447416 and parameters: {'hidden_dim': 94, 'n_rnn_layers': 3, 'dropout': 0.4833481689713928}. Best is trial 0 with value: 15.669487827303515.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.09it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.32it/s][I 2025-08-18 02:57:58,630] Trial 4 finished with value: 14.405524652980592 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 4, 'dropout': 0.4219440650464208}. Best is trial 4 with value: 14.405524652980592.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s][I 2025-08-18 02:58:30,535] Trial 5 finished with value: 21.114196522926093 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 4, 'dropout': 0.06342688658374424}. Best is trial 4 with value: 14.405524652980592.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.83it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.26it/s][I 2025-08-18 02:59:14,065] Trial 6 finished with value: 20.145252008436454 and parameters: {'hidden_dim': 55, 'n_rnn_layers': 3, 'dropout': 0.26588582787865467}. Best is trial 4 with value: 14.405524652980592.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.77it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.80it/s][I 2025-08-18 02:59:45,774] Trial 7 finished with value: 15.893653795511359 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 2, 'dropout': 0.09939535543715816}. Best is trial 4 with value: 14.405524652980592.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.15it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.09it/s][I 2025-08-18 03:00:17,596] Trial 8 finished with value: 15.711701587706154 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 4, 'dropout': 0.2723409774903048}. Best is trial 4 with value: 14.405524652980592.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.41it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.80it/s][I 2025-08-18 03:00:47,163] Trial 9 finished with value: 11.160704779041037 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 2, 'dropout': 0.12136438712104597}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1484147875304271 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 347.35it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 268.71it/s][I 2025-08-18 03:01:13,257] Trial 10 finished with value: 15.215269085634144 and parameters: {'hidden_dim': 79, 'n_rnn_layers': 1, 'dropout': 0.1484147875304271}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.70it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.75it/s][I 2025-08-18 03:01:40,689] Trial 11 finished with value: 16.74615101503045 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 2, 'dropout': 0.4840507835007332}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.33it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.40it/s][I 2025-08-18 03:02:06,703] Trial 12 finished with value: 18.048129028462615 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 2, 'dropout': 0.020538236368210006}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.99it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.77it/s][I 2025-08-18 03:02:46,186] Trial 13 finished with value: 19.198615545839296 and parameters: {'hidden_dim': 60, 'n_rnn_layers': 2, 'dropout': 0.16522647088692866}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.29it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.02it/s] [I 2025-08-18 03:03:16,589] Trial 14 finished with value: 14.9991529616514 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 3, 'dropout': 0.4064424037066339}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1949926530491276 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.61it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.25it/s][I 2025-08-18 03:03:35,920] Trial 15 finished with value: 17.986707725772973 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 1, 'dropout': 0.1949926530491276}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.71it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.47it/s][I 2025-08-18 03:04:22,986] Trial 16 finished with value: 22.369621906909337 and parameters: {'hidden_dim': 55, 'n_rnn_layers': 4, 'dropout': 0.10710017363964518}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.17it/s][I 2025-08-18 03:04:47,865] Trial 17 finished with value: 16.204243064739394 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 3, 'dropout': 0.337548502777646}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.81it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.83it/s][I 2025-08-18 03:05:12,883] Trial 18 finished with value: 15.543391519257032 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 2, 'dropout': 0.4228751555512888}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21811534519648895 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 406.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 319.88it/s][I 2025-08-18 03:05:47,062] Trial 19 finished with value: 16.497867332828324 and parameters: {'hidden_dim': 115, 'n_rnn_layers': 1, 'dropout': 0.21811534519648895}. Best is trial 9 with value: 11.160704779041037.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 16.3 K | train
6 | V               | Linear           | 37     | train
-------------------------------------------------------------
16.3 K    Trainable params
0         Non-trainable params
16.3 K    Total params
0.065     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 36, 'n_rnn_layers': 2, 'dropout': 0.12136438712104597}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 143.70it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 150.93it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/22 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/22 [00:00<?, ?it/s] Epoch 0:   5%|▍         | 1/22 [00:00<00:00, 64.66it/s]Epoch 0:   5%|▍         | 1/22 [00:00<00:00, 31.61it/s, train_loss=0.244]Epoch 0:   9%|▉         | 2/22 [00:00<00:00, 44.19it/s, train_loss=0.244]Epoch 0:   9%|▉         | 2/22 [00:00<00:00, 31.11it/s, train_loss=0.230]Epoch 0:  14%|█▎        | 3/22 [00:00<00:00, 38.95it/s, train_loss=0.230]Epoch 0:  14%|█▎        | 3/22 [00:00<00:00, 30.86it/s, train_loss=0.240]Epoch 0:  18%|█▊        | 4/22 [00:00<00:00, 35.92it/s, train_loss=0.240]Epoch 0:  18%|█▊        | 4/22 [00:00<00:00, 30.83it/s, train_loss=0.241]Epoch 0:  23%|██▎       | 5/22 [00:00<00:00, 34.80it/s, train_loss=0.241]Epoch 0:  23%|██▎       | 5/22 [00:00<00:00, 30.76it/s, train_loss=0.228]Epoch 0:  27%|██▋       | 6/22 [00:00<00:00, 34.14it/s, train_loss=0.228]Epoch 0:  27%|██▋       | 6/22 [00:00<00:00, 30.72it/s, train_loss=0.209]Epoch 0:  32%|███▏      | 7/22 [00:00<00:00, 33.50it/s, train_loss=0.209]Epoch 0:  32%|███▏      | 7/22 [00:00<00:00, 30.71it/s, train_loss=0.216]Epoch 0:  36%|███▋      | 8/22 [00:00<00:00, 33.11it/s, train_loss=0.216]Epoch 0:  36%|███▋      | 8/22 [00:00<00:00, 30.71it/s, train_loss=0.222]Epoch 0:  41%|████      | 9/22 [00:00<00:00, 32.84it/s, train_loss=0.222]Epoch 0:  41%|████      | 9/22 [00:00<00:00, 30.69it/s, train_loss=0.223]Epoch 0:  45%|████▌     | 10/22 [00:00<00:00, 32.55it/s, train_loss=0.223]Epoch 0:  45%|████▌     | 10/22 [00:00<00:00, 30.67it/s, train_loss=0.231]Epoch 0:  50%|█████     | 11/22 [00:00<00:00, 32.36it/s, train_loss=0.231]Epoch 0:  50%|█████     | 11/22 [00:00<00:00, 30.66it/s, train_loss=0.206]Epoch 0:  55%|█████▍    | 12/22 [00:00<00:00, 32.33it/s, train_loss=0.206]Epoch 0:  55%|█████▍    | 12/22 [00:00<00:00, 30.65it/s, train_loss=0.213]Epoch 0:  59%|█████▉    | 13/22 [00:00<00:00, 32.24it/s, train_loss=0.213]Epoch 0:  59%|█████▉    | 13/22 [00:00<00:00, 30.68it/s, train_loss=0.223]Epoch 0:  64%|██████▎   | 14/22 [00:00<00:00, 32.16it/s, train_loss=0.223]Epoch 0:  64%|██████▎   | 14/22 [00:00<00:00, 30.70it/s, train_loss=0.217]Epoch 0:  68%|██████▊   | 15/22 [00:00<00:00, 32.03it/s, train_loss=0.217]Epoch 0:  68%|██████▊   | 15/22 [00:00<00:00, 30.69it/s, train_loss=0.215]Epoch 0:  73%|███████▎  | 16/22 [00:00<00:00, 31.93it/s, train_loss=0.215]Epoch 0:  73%|███████▎  | 16/22 [00:00<00:00, 30.68it/s, train_loss=0.207]Epoch 0:  77%|███████▋  | 17/22 [00:00<00:00, 31.87it/s, train_loss=0.207]Epoch 0:  77%|███████▋  | 17/22 [00:00<00:00, 30.67it/s, train_loss=0.222]Epoch 0:  82%|████████▏ | 18/22 [00:00<00:00, 31.74it/s, train_loss=0.222]Epoch 0:  82%|████████▏ | 18/22 [00:00<00:00, 30.64it/s, train_loss=0.199]Epoch 0:  86%|████████▋ | 19/22 [00:00<00:00, 31.65it/s, train_loss=0.199]Epoch 0:  86%|████████▋ | 19/22 [00:00<00:00, 30.63it/s, train_loss=0.201]Epoch 0:  91%|█████████ | 20/22 [00:00<00:00, 31.63it/s, train_loss=0.201]Epoch 0:  91%|█████████ | 20/22 [00:00<00:00, 30.63it/s, train_loss=0.216]Epoch 0:  95%|█████████▌| 21/22 [00:00<00:00, 31.58it/s, train_loss=0.216]Epoch 0:  95%|█████████▌| 21/22 [00:00<00:00, 30.63it/s, train_loss=0.216]Epoch 0: 100%|██████████| 22/22 [00:00<00:00, 31.55it/s, train_loss=0.216]Epoch 0: 100%|██████████| 22/22 [00:00<00:00, 30.73it/s, train_loss=0.195]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 104.66it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 121.70it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 128.81it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 132.70it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 135.04it/s][A
                                                                       [AEpoch 0: 100%|██████████| 22/22 [00:00<00:00, 28.35it/s, train_loss=0.195, val_loss=0.172]Epoch 0: 100%|██████████| 22/22 [00:00<00:00, 28.31it/s, train_loss=0.195, val_loss=0.172]Epoch 0:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.195, val_loss=0.172]         Epoch 1:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.195, val_loss=0.172]Epoch 1:   5%|▍         | 1/22 [00:00<00:00, 70.63it/s, train_loss=0.195, val_loss=0.172]Epoch 1:   5%|▍         | 1/22 [00:00<00:00, 32.01it/s, train_loss=0.185, val_loss=0.172]Epoch 1:   9%|▉         | 2/22 [00:00<00:00, 43.85it/s, train_loss=0.185, val_loss=0.172]Epoch 1:   9%|▉         | 2/22 [00:00<00:00, 32.46it/s, train_loss=0.201, val_loss=0.172]Epoch 1:  14%|█▎        | 3/22 [00:00<00:00, 39.93it/s, train_loss=0.201, val_loss=0.172]Epoch 1:  14%|█▎        | 3/22 [00:00<00:00, 31.88it/s, train_loss=0.194, val_loss=0.172]Epoch 1:  18%|█▊        | 4/22 [00:00<00:00, 37.15it/s, train_loss=0.194, val_loss=0.172]Epoch 1:  18%|█▊        | 4/22 [00:00<00:00, 31.56it/s, train_loss=0.199, val_loss=0.172]Epoch 1:  23%|██▎       | 5/22 [00:00<00:00, 35.58it/s, train_loss=0.199, val_loss=0.172]Epoch 1:  23%|██▎       | 5/22 [00:00<00:00, 31.28it/s, train_loss=0.198, val_loss=0.172]Epoch 1:  27%|██▋       | 6/22 [00:00<00:00, 35.05it/s, train_loss=0.198, val_loss=0.172]Epoch 1:  27%|██▋       | 6/22 [00:00<00:00, 31.26it/s, train_loss=0.178, val_loss=0.172]Epoch 1:  32%|███▏      | 7/22 [00:00<00:00, 34.39it/s, train_loss=0.178, val_loss=0.172]Epoch 1:  32%|███▏      | 7/22 [00:00<00:00, 31.20it/s, train_loss=0.170, val_loss=0.172]Epoch 1:  36%|███▋      | 8/22 [00:00<00:00, 33.89it/s, train_loss=0.170, val_loss=0.172]Epoch 1:  36%|███▋      | 8/22 [00:00<00:00, 31.12it/s, train_loss=0.166, val_loss=0.172]Epoch 1:  41%|████      | 9/22 [00:00<00:00, 33.50it/s, train_loss=0.166, val_loss=0.172]Epoch 1:  41%|████      | 9/22 [00:00<00:00, 31.11it/s, train_loss=0.169, val_loss=0.172]Epoch 1:  45%|████▌     | 10/22 [00:00<00:00, 33.22it/s, train_loss=0.169, val_loss=0.172]Epoch 1:  45%|████▌     | 10/22 [00:00<00:00, 31.07it/s, train_loss=0.149, val_loss=0.172]Epoch 1:  50%|█████     | 11/22 [00:00<00:00, 32.95it/s, train_loss=0.149, val_loss=0.172]Epoch 1:  50%|█████     | 11/22 [00:00<00:00, 30.98it/s, train_loss=0.151, val_loss=0.172]Epoch 1:  55%|█████▍    | 12/22 [00:00<00:00, 32.73it/s, train_loss=0.151, val_loss=0.172]Epoch 1:  55%|█████▍    | 12/22 [00:00<00:00, 30.97it/s, train_loss=0.153, val_loss=0.172]Epoch 1:  59%|█████▉    | 13/22 [00:00<00:00, 32.52it/s, train_loss=0.153, val_loss=0.172]Epoch 1:  59%|█████▉    | 13/22 [00:00<00:00, 30.94it/s, train_loss=0.134, val_loss=0.172]Epoch 1:  64%|██████▎   | 14/22 [00:00<00:00, 32.37it/s, train_loss=0.134, val_loss=0.172]Epoch 1:  64%|██████▎   | 14/22 [00:00<00:00, 30.88it/s, train_loss=0.144, val_loss=0.172]Epoch 1:  68%|██████▊   | 15/22 [00:00<00:00, 32.25it/s, train_loss=0.144, val_loss=0.172]Epoch 1:  68%|██████▊   | 15/22 [00:00<00:00, 30.88it/s, train_loss=0.147, val_loss=0.172]Epoch 1:  73%|███████▎  | 16/22 [00:00<00:00, 32.15it/s, train_loss=0.147, val_loss=0.172]Epoch 1:  73%|███████▎  | 16/22 [00:00<00:00, 30.88it/s, train_loss=0.140, val_loss=0.172]Epoch 1:  77%|███████▋  | 17/22 [00:00<00:00, 32.08it/s, train_loss=0.140, val_loss=0.172]Epoch 1:  77%|███████▋  | 17/22 [00:00<00:00, 30.85it/s, train_loss=0.128, val_loss=0.172]Epoch 1:  82%|████████▏ | 18/22 [00:00<00:00, 31.98it/s, train_loss=0.128, val_loss=0.172]Epoch 1:  82%|████████▏ | 18/22 [00:00<00:00, 30.85it/s, train_loss=0.126, val_loss=0.172]Epoch 1:  86%|████████▋ | 19/22 [00:00<00:00, 31.90it/s, train_loss=0.126, val_loss=0.172]Epoch 1:  86%|████████▋ | 19/22 [00:00<00:00, 30.84it/s, train_loss=0.132, val_loss=0.172]Epoch 1:  91%|█████████ | 20/22 [00:00<00:00, 31.86it/s, train_loss=0.132, val_loss=0.172]Epoch 1:  91%|█████████ | 20/22 [00:00<00:00, 30.82it/s, train_loss=0.126, val_loss=0.172]Epoch 1:  95%|█████████▌| 21/22 [00:00<00:00, 31.78it/s, train_loss=0.126, val_loss=0.172]Epoch 1:  95%|█████████▌| 21/22 [00:00<00:00, 30.81it/s, train_loss=0.125, val_loss=0.172]Epoch 1: 100%|██████████| 22/22 [00:00<00:00, 31.74it/s, train_loss=0.125, val_loss=0.172]Epoch 1: 100%|██████████| 22/22 [00:00<00:00, 30.91it/s, train_loss=0.134, val_loss=0.172]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 95.13it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 113.74it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 121.21it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 127.64it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 135.68it/s][A
                                                                       [AEpoch 1: 100%|██████████| 22/22 [00:00<00:00, 28.50it/s, train_loss=0.134, val_loss=0.0831]Epoch 1: 100%|██████████| 22/22 [00:00<00:00, 28.47it/s, train_loss=0.134, val_loss=0.0831]Epoch 1:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.134, val_loss=0.0831]         Epoch 2:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.134, val_loss=0.0831]Epoch 2:   5%|▍         | 1/22 [00:00<00:00, 76.69it/s, train_loss=0.134, val_loss=0.0831]Epoch 2:   5%|▍         | 1/22 [00:00<00:00, 32.61it/s, train_loss=0.101, val_loss=0.0831]Epoch 2:   9%|▉         | 2/22 [00:00<00:00, 45.77it/s, train_loss=0.101, val_loss=0.0831]Epoch 2:   9%|▉         | 2/22 [00:00<00:00, 32.14it/s, train_loss=0.107, val_loss=0.0831]Epoch 2:  14%|█▎        | 3/22 [00:00<00:00, 39.55it/s, train_loss=0.107, val_loss=0.0831]Epoch 2:  14%|█▎        | 3/22 [00:00<00:00, 31.55it/s, train_loss=0.0847, val_loss=0.0831]Epoch 2:  18%|█▊        | 4/22 [00:00<00:00, 36.29it/s, train_loss=0.0847, val_loss=0.0831]Epoch 2:  18%|█▊        | 4/22 [00:00<00:00, 31.40it/s, train_loss=0.0821, val_loss=0.0831]Epoch 2:  23%|██▎       | 5/22 [00:00<00:00, 35.50it/s, train_loss=0.0821, val_loss=0.0831]Epoch 2:  23%|██▎       | 5/22 [00:00<00:00, 31.20it/s, train_loss=0.0766, val_loss=0.0831]Epoch 2:  27%|██▋       | 6/22 [00:00<00:00, 34.35it/s, train_loss=0.0766, val_loss=0.0831]Epoch 2:  27%|██▋       | 6/22 [00:00<00:00, 31.16it/s, train_loss=0.052, val_loss=0.0831] Epoch 2:  32%|███▏      | 7/22 [00:00<00:00, 33.97it/s, train_loss=0.052, val_loss=0.0831]Epoch 2:  32%|███▏      | 7/22 [00:00<00:00, 31.09it/s, train_loss=0.068, val_loss=0.0831]Epoch 2:  36%|███▋      | 8/22 [00:00<00:00, 33.50it/s, train_loss=0.068, val_loss=0.0831]Epoch 2:  36%|███▋      | 8/22 [00:00<00:00, 31.02it/s, train_loss=0.0513, val_loss=0.0831]Epoch 2:  41%|████      | 9/22 [00:00<00:00, 33.20it/s, train_loss=0.0513, val_loss=0.0831]Epoch 2:  41%|████      | 9/22 [00:00<00:00, 30.99it/s, train_loss=0.037, val_loss=0.0831] Epoch 2:  45%|████▌     | 10/22 [00:00<00:00, 32.95it/s, train_loss=0.037, val_loss=0.0831]Epoch 2:  45%|████▌     | 10/22 [00:00<00:00, 30.86it/s, train_loss=0.0358, val_loss=0.0831]Epoch 2:  50%|█████     | 11/22 [00:00<00:00, 32.61it/s, train_loss=0.0358, val_loss=0.0831]Epoch 2:  50%|█████     | 11/22 [00:00<00:00, 30.92it/s, train_loss=0.0352, val_loss=0.0831]Epoch 2:  55%|█████▍    | 12/22 [00:00<00:00, 32.39it/s, train_loss=0.0352, val_loss=0.0831]Epoch 2:  55%|█████▍    | 12/22 [00:00<00:00, 30.93it/s, train_loss=0.0269, val_loss=0.0831]Epoch 2:  59%|█████▉    | 13/22 [00:00<00:00, 32.38it/s, train_loss=0.0269, val_loss=0.0831]Epoch 2:  59%|█████▉    | 13/22 [00:00<00:00, 30.84it/s, train_loss=0.0218, val_loss=0.0831]Epoch 2:  64%|██████▎   | 14/22 [00:00<00:00, 32.19it/s, train_loss=0.0218, val_loss=0.0831]Epoch 2:  64%|██████▎   | 14/22 [00:00<00:00, 30.73it/s, train_loss=0.0265, val_loss=0.0831]Epoch 2:  68%|██████▊   | 15/22 [00:00<00:00, 31.96it/s, train_loss=0.0265, val_loss=0.0831]Epoch 2:  68%|██████▊   | 15/22 [00:00<00:00, 30.63it/s, train_loss=0.0281, val_loss=0.0831]Epoch 2:  73%|███████▎  | 16/22 [00:00<00:00, 31.74it/s, train_loss=0.0281, val_loss=0.0831]Epoch 2:  73%|███████▎  | 16/22 [00:00<00:00, 30.54it/s, train_loss=0.032, val_loss=0.0831] Epoch 2:  77%|███████▋  | 17/22 [00:00<00:00, 31.61it/s, train_loss=0.032, val_loss=0.0831]Epoch 2:  77%|███████▋  | 17/22 [00:00<00:00, 30.44it/s, train_loss=0.0305, val_loss=0.0831]Epoch 2:  82%|████████▏ | 18/22 [00:00<00:00, 31.40it/s, train_loss=0.0305, val_loss=0.0831]Epoch 2:  82%|████████▏ | 18/22 [00:00<00:00, 30.39it/s, train_loss=0.0366, val_loss=0.0831]Epoch 2:  86%|████████▋ | 19/22 [00:00<00:00, 31.45it/s, train_loss=0.0366, val_loss=0.0831]Epoch 2:  86%|████████▋ | 19/22 [00:00<00:00, 30.34it/s, train_loss=0.0333, val_loss=0.0831]Epoch 2:  91%|█████████ | 20/22 [00:00<00:00, 31.36it/s, train_loss=0.0333, val_loss=0.0831]Epoch 2:  91%|█████████ | 20/22 [00:00<00:00, 30.30it/s, train_loss=0.0305, val_loss=0.0831]Epoch 2:  95%|█████████▌| 21/22 [00:00<00:00, 31.26it/s, train_loss=0.0305, val_loss=0.0831]Epoch 2:  95%|█████████▌| 21/22 [00:00<00:00, 30.24it/s, train_loss=0.0266, val_loss=0.0831]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 22/22 [00:00<00:00, 31.10it/s, train_loss=0.0266, val_loss=0.0831]Epoch 2: 100%|██████████| 22/22 [00:00<00:00, 30.29it/s, train_loss=0.0239, val_loss=0.0831]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 105.40it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 123.04it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 130.44it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 134.91it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 137.61it/s][A
                                                                       [AEpoch 2: 100%|██████████| 22/22 [00:00<00:00, 27.86it/s, train_loss=0.0239, val_loss=0.0307]Epoch 2: 100%|██████████| 22/22 [00:00<00:00, 27.82it/s, train_loss=0.0239, val_loss=0.0307]Epoch 2:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0239, val_loss=0.0307]         Epoch 3:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0239, val_loss=0.0307]Epoch 3:   5%|▍         | 1/22 [00:00<00:00, 70.01it/s, train_loss=0.0239, val_loss=0.0307]Epoch 3:   5%|▍         | 1/22 [00:00<00:00, 30.76it/s, train_loss=0.0232, val_loss=0.0307]Epoch 3:   9%|▉         | 2/22 [00:00<00:00, 43.14it/s, train_loss=0.0232, val_loss=0.0307]Epoch 3:   9%|▉         | 2/22 [00:00<00:00, 31.14it/s, train_loss=0.0202, val_loss=0.0307]Epoch 3:  14%|█▎        | 3/22 [00:00<00:00, 38.58it/s, train_loss=0.0202, val_loss=0.0307]Epoch 3:  14%|█▎        | 3/22 [00:00<00:00, 30.55it/s, train_loss=0.0285, val_loss=0.0307]Epoch 3:  18%|█▊        | 4/22 [00:00<00:00, 35.81it/s, train_loss=0.0285, val_loss=0.0307]Epoch 3:  18%|█▊        | 4/22 [00:00<00:00, 30.30it/s, train_loss=0.0223, val_loss=0.0307]Epoch 3:  23%|██▎       | 5/22 [00:00<00:00, 34.43it/s, train_loss=0.0223, val_loss=0.0307]Epoch 3:  23%|██▎       | 5/22 [00:00<00:00, 30.17it/s, train_loss=0.028, val_loss=0.0307] Epoch 3:  27%|██▋       | 6/22 [00:00<00:00, 33.37it/s, train_loss=0.028, val_loss=0.0307]Epoch 3:  27%|██▋       | 6/22 [00:00<00:00, 30.03it/s, train_loss=0.0251, val_loss=0.0307]Epoch 3:  32%|███▏      | 7/22 [00:00<00:00, 32.73it/s, train_loss=0.0251, val_loss=0.0307]Epoch 3:  32%|███▏      | 7/22 [00:00<00:00, 30.00it/s, train_loss=0.0251, val_loss=0.0307]Epoch 3:  36%|███▋      | 8/22 [00:00<00:00, 32.72it/s, train_loss=0.0251, val_loss=0.0307]Epoch 3:  36%|███▋      | 8/22 [00:00<00:00, 30.02it/s, train_loss=0.0188, val_loss=0.0307]Epoch 3:  41%|████      | 9/22 [00:00<00:00, 32.37it/s, train_loss=0.0188, val_loss=0.0307]Epoch 3:  41%|████      | 9/22 [00:00<00:00, 29.98it/s, train_loss=0.0233, val_loss=0.0307]Epoch 3:  45%|████▌     | 10/22 [00:00<00:00, 32.07it/s, train_loss=0.0233, val_loss=0.0307]Epoch 3:  45%|████▌     | 10/22 [00:00<00:00, 29.99it/s, train_loss=0.0273, val_loss=0.0307]Epoch 3:  50%|█████     | 11/22 [00:00<00:00, 31.88it/s, train_loss=0.0273, val_loss=0.0307]Epoch 3:  50%|█████     | 11/22 [00:00<00:00, 29.98it/s, train_loss=0.0253, val_loss=0.0307]Epoch 3:  55%|█████▍    | 12/22 [00:00<00:00, 31.71it/s, train_loss=0.0253, val_loss=0.0307]Epoch 3:  55%|█████▍    | 12/22 [00:00<00:00, 29.98it/s, train_loss=0.0299, val_loss=0.0307]Epoch 3:  59%|█████▉    | 13/22 [00:00<00:00, 31.52it/s, train_loss=0.0299, val_loss=0.0307]Epoch 3:  59%|█████▉    | 13/22 [00:00<00:00, 29.95it/s, train_loss=0.0249, val_loss=0.0307]Epoch 3:  64%|██████▎   | 14/22 [00:00<00:00, 31.38it/s, train_loss=0.0249, val_loss=0.0307]Epoch 3:  64%|██████▎   | 14/22 [00:00<00:00, 29.92it/s, train_loss=0.0261, val_loss=0.0307]Epoch 3:  68%|██████▊   | 15/22 [00:00<00:00, 31.26it/s, train_loss=0.0261, val_loss=0.0307]Epoch 3:  68%|██████▊   | 15/22 [00:00<00:00, 29.89it/s, train_loss=0.0263, val_loss=0.0307]Epoch 3:  73%|███████▎  | 16/22 [00:00<00:00, 31.16it/s, train_loss=0.0263, val_loss=0.0307]Epoch 3:  73%|███████▎  | 16/22 [00:00<00:00, 29.88it/s, train_loss=0.0203, val_loss=0.0307]Epoch 3:  77%|███████▋  | 17/22 [00:00<00:00, 31.07it/s, train_loss=0.0203, val_loss=0.0307]Epoch 3:  77%|███████▋  | 17/22 [00:00<00:00, 29.87it/s, train_loss=0.0235, val_loss=0.0307]Epoch 3:  82%|████████▏ | 18/22 [00:00<00:00, 30.99it/s, train_loss=0.0235, val_loss=0.0307]Epoch 3:  82%|████████▏ | 18/22 [00:00<00:00, 29.86it/s, train_loss=0.0203, val_loss=0.0307]Epoch 3:  86%|████████▋ | 19/22 [00:00<00:00, 30.91it/s, train_loss=0.0203, val_loss=0.0307]Epoch 3:  86%|████████▋ | 19/22 [00:00<00:00, 29.85it/s, train_loss=0.0244, val_loss=0.0307]Epoch 3:  91%|█████████ | 20/22 [00:00<00:00, 30.84it/s, train_loss=0.0244, val_loss=0.0307]Epoch 3:  91%|█████████ | 20/22 [00:00<00:00, 29.84it/s, train_loss=0.0238, val_loss=0.0307]Epoch 3:  95%|█████████▌| 21/22 [00:00<00:00, 30.79it/s, train_loss=0.0238, val_loss=0.0307]Epoch 3:  95%|█████████▌| 21/22 [00:00<00:00, 29.83it/s, train_loss=0.0207, val_loss=0.0307]Epoch 3: 100%|██████████| 22/22 [00:00<00:00, 30.75it/s, train_loss=0.0207, val_loss=0.0307]Epoch 3: 100%|██████████| 22/22 [00:00<00:00, 29.91it/s, train_loss=0.0167, val_loss=0.0307]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 98.26it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 116.14it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 123.11it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 127.71it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 130.67it/s][A
                                                                       [AEpoch 3: 100%|██████████| 22/22 [00:00<00:00, 27.48it/s, train_loss=0.0167, val_loss=0.0255]Epoch 3: 100%|██████████| 22/22 [00:00<00:00, 27.44it/s, train_loss=0.0167, val_loss=0.0255]Epoch 3:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0167, val_loss=0.0255]         Epoch 4:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0167, val_loss=0.0255]Epoch 4:   5%|▍         | 1/22 [00:00<00:00, 71.78it/s, train_loss=0.0167, val_loss=0.0255]Epoch 4:   5%|▍         | 1/22 [00:00<00:00, 31.20it/s, train_loss=0.0208, val_loss=0.0255]Epoch 4:   9%|▉         | 2/22 [00:00<00:00, 43.02it/s, train_loss=0.0208, val_loss=0.0255]Epoch 4:   9%|▉         | 2/22 [00:00<00:00, 30.94it/s, train_loss=0.0217, val_loss=0.0255]Epoch 4:  14%|█▎        | 3/22 [00:00<00:00, 37.87it/s, train_loss=0.0217, val_loss=0.0255]Epoch 4:  14%|█▎        | 3/22 [00:00<00:00, 30.47it/s, train_loss=0.0234, val_loss=0.0255]Epoch 4:  18%|█▊        | 4/22 [00:00<00:00, 35.68it/s, train_loss=0.0234, val_loss=0.0255]Epoch 4:  18%|█▊        | 4/22 [00:00<00:00, 30.23it/s, train_loss=0.0182, val_loss=0.0255]Epoch 4:  23%|██▎       | 5/22 [00:00<00:00, 34.47it/s, train_loss=0.0182, val_loss=0.0255]Epoch 4:  23%|██▎       | 5/22 [00:00<00:00, 30.05it/s, train_loss=0.0194, val_loss=0.0255]Epoch 4:  27%|██▋       | 6/22 [00:00<00:00, 33.69it/s, train_loss=0.0194, val_loss=0.0255]Epoch 4:  27%|██▋       | 6/22 [00:00<00:00, 29.98it/s, train_loss=0.0214, val_loss=0.0255]Epoch 4:  32%|███▏      | 7/22 [00:00<00:00, 32.99it/s, train_loss=0.0214, val_loss=0.0255]Epoch 4:  32%|███▏      | 7/22 [00:00<00:00, 29.93it/s, train_loss=0.0172, val_loss=0.0255]Epoch 4:  36%|███▋      | 8/22 [00:00<00:00, 32.55it/s, train_loss=0.0172, val_loss=0.0255]Epoch 4:  36%|███▋      | 8/22 [00:00<00:00, 29.87it/s, train_loss=0.0219, val_loss=0.0255]Epoch 4:  41%|████      | 9/22 [00:00<00:00, 32.20it/s, train_loss=0.0219, val_loss=0.0255]Epoch 4:  41%|████      | 9/22 [00:00<00:00, 29.84it/s, train_loss=0.0183, val_loss=0.0255]Epoch 4:  45%|████▌     | 10/22 [00:00<00:00, 31.90it/s, train_loss=0.0183, val_loss=0.0255]Epoch 4:  45%|████▌     | 10/22 [00:00<00:00, 29.82it/s, train_loss=0.0234, val_loss=0.0255]Epoch 4:  50%|█████     | 11/22 [00:00<00:00, 31.60it/s, train_loss=0.0234, val_loss=0.0255]Epoch 4:  50%|█████     | 11/22 [00:00<00:00, 29.89it/s, train_loss=0.0193, val_loss=0.0255]Epoch 4:  55%|█████▍    | 12/22 [00:00<00:00, 31.46it/s, train_loss=0.0193, val_loss=0.0255]Epoch 4:  55%|█████▍    | 12/22 [00:00<00:00, 29.94it/s, train_loss=0.0227, val_loss=0.0255]Epoch 4:  59%|█████▉    | 13/22 [00:00<00:00, 31.32it/s, train_loss=0.0227, val_loss=0.0255]Epoch 4:  59%|█████▉    | 13/22 [00:00<00:00, 29.99it/s, train_loss=0.0203, val_loss=0.0255]Epoch 4:  64%|██████▎   | 14/22 [00:00<00:00, 31.25it/s, train_loss=0.0203, val_loss=0.0255]Epoch 4:  64%|██████▎   | 14/22 [00:00<00:00, 30.06it/s, train_loss=0.0229, val_loss=0.0255]Epoch 4:  68%|██████▊   | 15/22 [00:00<00:00, 31.17it/s, train_loss=0.0229, val_loss=0.0255]Epoch 4:  68%|██████▊   | 15/22 [00:00<00:00, 30.12it/s, train_loss=0.0208, val_loss=0.0255]Epoch 4:  73%|███████▎  | 16/22 [00:00<00:00, 31.22it/s, train_loss=0.0208, val_loss=0.0255]Epoch 4:  73%|███████▎  | 16/22 [00:00<00:00, 30.17it/s, train_loss=0.0216, val_loss=0.0255]Epoch 4:  77%|███████▋  | 17/22 [00:00<00:00, 31.18it/s, train_loss=0.0216, val_loss=0.0255]Epoch 4:  77%|███████▋  | 17/22 [00:00<00:00, 30.23it/s, train_loss=0.0215, val_loss=0.0255]Epoch 4:  82%|████████▏ | 18/22 [00:00<00:00, 31.21it/s, train_loss=0.0215, val_loss=0.0255]Epoch 4:  82%|████████▏ | 18/22 [00:00<00:00, 30.28it/s, train_loss=0.0209, val_loss=0.0255]Epoch 4:  86%|████████▋ | 19/22 [00:00<00:00, 31.20it/s, train_loss=0.0209, val_loss=0.0255]Epoch 4:  86%|████████▋ | 19/22 [00:00<00:00, 30.32it/s, train_loss=0.0201, val_loss=0.0255]Epoch 4:  91%|█████████ | 20/22 [00:00<00:00, 31.18it/s, train_loss=0.0201, val_loss=0.0255]Epoch 4:  91%|█████████ | 20/22 [00:00<00:00, 30.34it/s, train_loss=0.0226, val_loss=0.0255]Epoch 4:  95%|█████████▌| 21/22 [00:00<00:00, 31.20it/s, train_loss=0.0226, val_loss=0.0255]Epoch 4:  95%|█████████▌| 21/22 [00:00<00:00, 30.37it/s, train_loss=0.022, val_loss=0.0255] Epoch 4: 100%|██████████| 22/22 [00:00<00:00, 31.28it/s, train_loss=0.022, val_loss=0.0255]Epoch 4: 100%|██████████| 22/22 [00:00<00:00, 30.49it/s, train_loss=0.0198, val_loss=0.0255]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 118.10it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 133.48it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 140.59it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 143.73it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 146.08it/s][A
                                                                       [AEpoch 4: 100%|██████████| 22/22 [00:00<00:00, 28.18it/s, train_loss=0.0198, val_loss=0.0216]Epoch 4: 100%|██████████| 22/22 [00:00<00:00, 28.14it/s, train_loss=0.0198, val_loss=0.0216]Epoch 4:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0198, val_loss=0.0216]         Epoch 5:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0198, val_loss=0.0216]Epoch 5:   5%|▍         | 1/22 [00:00<00:00, 71.48it/s, train_loss=0.0198, val_loss=0.0216]Epoch 5:   5%|▍         | 1/22 [00:00<00:00, 31.19it/s, train_loss=0.0194, val_loss=0.0216]Epoch 5:   9%|▉         | 2/22 [00:00<00:00, 43.05it/s, train_loss=0.0194, val_loss=0.0216]Epoch 5:   9%|▉         | 2/22 [00:00<00:00, 31.39it/s, train_loss=0.018, val_loss=0.0216] Epoch 5:  14%|█▎        | 3/22 [00:00<00:00, 38.38it/s, train_loss=0.018, val_loss=0.0216]Epoch 5:  14%|█▎        | 3/22 [00:00<00:00, 31.19it/s, train_loss=0.0221, val_loss=0.0216]Epoch 5:  18%|█▊        | 4/22 [00:00<00:00, 36.43it/s, train_loss=0.0221, val_loss=0.0216]Epoch 5:  18%|█▊        | 4/22 [00:00<00:00, 31.12it/s, train_loss=0.019, val_loss=0.0216] Epoch 5:  23%|██▎       | 5/22 [00:00<00:00, 35.00it/s, train_loss=0.019, val_loss=0.0216]Epoch 5:  23%|██▎       | 5/22 [00:00<00:00, 31.01it/s, train_loss=0.0182, val_loss=0.0216]Epoch 5:  27%|██▋       | 6/22 [00:00<00:00, 34.09it/s, train_loss=0.0182, val_loss=0.0216]Epoch 5:  27%|██▋       | 6/22 [00:00<00:00, 30.99it/s, train_loss=0.0185, val_loss=0.0216]Epoch 5:  32%|███▏      | 7/22 [00:00<00:00, 33.63it/s, train_loss=0.0185, val_loss=0.0216]Epoch 5:  32%|███▏      | 7/22 [00:00<00:00, 30.99it/s, train_loss=0.0168, val_loss=0.0216]Epoch 5:  36%|███▋      | 8/22 [00:00<00:00, 33.24it/s, train_loss=0.0168, val_loss=0.0216]Epoch 5:  36%|███▋      | 8/22 [00:00<00:00, 30.98it/s, train_loss=0.0182, val_loss=0.0216]Epoch 5:  41%|████      | 9/22 [00:00<00:00, 33.06it/s, train_loss=0.0182, val_loss=0.0216]Epoch 5:  41%|████      | 9/22 [00:00<00:00, 30.97it/s, train_loss=0.0194, val_loss=0.0216]Epoch 5:  45%|████▌     | 10/22 [00:00<00:00, 32.83it/s, train_loss=0.0194, val_loss=0.0216]Epoch 5:  45%|████▌     | 10/22 [00:00<00:00, 30.96it/s, train_loss=0.0194, val_loss=0.0216]Epoch 5:  50%|█████     | 11/22 [00:00<00:00, 32.59it/s, train_loss=0.0194, val_loss=0.0216]Epoch 5:  50%|█████     | 11/22 [00:00<00:00, 30.96it/s, train_loss=0.0176, val_loss=0.0216]Epoch 5:  55%|█████▍    | 12/22 [00:00<00:00, 32.45it/s, train_loss=0.0176, val_loss=0.0216]Epoch 5:  55%|█████▍    | 12/22 [00:00<00:00, 30.96it/s, train_loss=0.0198, val_loss=0.0216]Epoch 5:  59%|█████▉    | 13/22 [00:00<00:00, 32.43it/s, train_loss=0.0198, val_loss=0.0216]Epoch 5:  59%|█████▉    | 13/22 [00:00<00:00, 30.95it/s, train_loss=0.018, val_loss=0.0216] Epoch 5:  64%|██████▎   | 14/22 [00:00<00:00, 32.42it/s, train_loss=0.018, val_loss=0.0216]Epoch 5:  64%|██████▎   | 14/22 [00:00<00:00, 30.96it/s, train_loss=0.0159, val_loss=0.0216]Epoch 5:  68%|██████▊   | 15/22 [00:00<00:00, 32.35it/s, train_loss=0.0159, val_loss=0.0216]Epoch 5:  68%|██████▊   | 15/22 [00:00<00:00, 30.96it/s, train_loss=0.0164, val_loss=0.0216]Epoch 5:  73%|███████▎  | 16/22 [00:00<00:00, 32.26it/s, train_loss=0.0164, val_loss=0.0216]Epoch 5:  73%|███████▎  | 16/22 [00:00<00:00, 30.96it/s, train_loss=0.0152, val_loss=0.0216]Epoch 5:  77%|███████▋  | 17/22 [00:00<00:00, 32.17it/s, train_loss=0.0152, val_loss=0.0216]Epoch 5:  77%|███████▋  | 17/22 [00:00<00:00, 30.94it/s, train_loss=0.0164, val_loss=0.0216]Epoch 5:  82%|████████▏ | 18/22 [00:00<00:00, 32.04it/s, train_loss=0.0164, val_loss=0.0216]Epoch 5:  82%|████████▏ | 18/22 [00:00<00:00, 30.92it/s, train_loss=0.0173, val_loss=0.0216]Epoch 5:  86%|████████▋ | 19/22 [00:00<00:00, 31.95it/s, train_loss=0.0173, val_loss=0.0216]Epoch 5:  86%|████████▋ | 19/22 [00:00<00:00, 30.90it/s, train_loss=0.0152, val_loss=0.0216]Epoch 5:  91%|█████████ | 20/22 [00:00<00:00, 31.88it/s, train_loss=0.0152, val_loss=0.0216]Epoch 5:  91%|█████████ | 20/22 [00:00<00:00, 30.89it/s, train_loss=0.0153, val_loss=0.0216]Epoch 5:  95%|█████████▌| 21/22 [00:00<00:00, 31.78it/s, train_loss=0.0153, val_loss=0.0216]Epoch 5:  95%|█████████▌| 21/22 [00:00<00:00, 30.87it/s, train_loss=0.0148, val_loss=0.0216]Epoch 5: 100%|██████████| 22/22 [00:00<00:00, 31.78it/s, train_loss=0.0148, val_loss=0.0216]Epoch 5: 100%|██████████| 22/22 [00:00<00:00, 30.97it/s, train_loss=0.0122, val_loss=0.0216]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 99.37it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 112.23it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 120.82it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 126.02it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 129.25it/s][A
                                                                       [AEpoch 5: 100%|██████████| 22/22 [00:00<00:00, 28.50it/s, train_loss=0.0122, val_loss=0.0159]Epoch 5: 100%|██████████| 22/22 [00:00<00:00, 28.45it/s, train_loss=0.0122, val_loss=0.0159]Epoch 5:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0122, val_loss=0.0159]         Epoch 6:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0122, val_loss=0.0159]Epoch 6:   5%|▍         | 1/22 [00:00<00:00, 56.73it/s, train_loss=0.0122, val_loss=0.0159]Epoch 6:   5%|▍         | 1/22 [00:00<00:00, 28.25it/s, train_loss=0.0141, val_loss=0.0159]Epoch 6:   9%|▉         | 2/22 [00:00<00:00, 40.10it/s, train_loss=0.0141, val_loss=0.0159]Epoch 6:   9%|▉         | 2/22 [00:00<00:00, 29.79it/s, train_loss=0.0134, val_loss=0.0159]Epoch 6:  14%|█▎        | 3/22 [00:00<00:00, 36.29it/s, train_loss=0.0134, val_loss=0.0159]Epoch 6:  14%|█▎        | 3/22 [00:00<00:00, 30.13it/s, train_loss=0.0139, val_loss=0.0159]Epoch 6:  18%|█▊        | 4/22 [00:00<00:00, 35.18it/s, train_loss=0.0139, val_loss=0.0159]Epoch 6:  18%|█▊        | 4/22 [00:00<00:00, 30.28it/s, train_loss=0.0136, val_loss=0.0159]Epoch 6:  23%|██▎       | 5/22 [00:00<00:00, 34.08it/s, train_loss=0.0136, val_loss=0.0159]Epoch 6:  23%|██▎       | 5/22 [00:00<00:00, 30.42it/s, train_loss=0.0137, val_loss=0.0159]Epoch 6:  27%|██▋       | 6/22 [00:00<00:00, 33.67it/s, train_loss=0.0137, val_loss=0.0159]Epoch 6:  27%|██▋       | 6/22 [00:00<00:00, 30.50it/s, train_loss=0.011, val_loss=0.0159] Epoch 6:  32%|███▏      | 7/22 [00:00<00:00, 33.19it/s, train_loss=0.011, val_loss=0.0159]Epoch 6:  32%|███▏      | 7/22 [00:00<00:00, 30.50it/s, train_loss=0.0141, val_loss=0.0159]Epoch 6:  36%|███▋      | 8/22 [00:00<00:00, 32.82it/s, train_loss=0.0141, val_loss=0.0159]Epoch 6:  36%|███▋      | 8/22 [00:00<00:00, 30.53it/s, train_loss=0.0126, val_loss=0.0159]Epoch 6:  41%|████      | 9/22 [00:00<00:00, 32.61it/s, train_loss=0.0126, val_loss=0.0159]Epoch 6:  41%|████      | 9/22 [00:00<00:00, 30.57it/s, train_loss=0.0132, val_loss=0.0159]Epoch 6:  45%|████▌     | 10/22 [00:00<00:00, 32.39it/s, train_loss=0.0132, val_loss=0.0159]Epoch 6:  45%|████▌     | 10/22 [00:00<00:00, 30.60it/s, train_loss=0.0124, val_loss=0.0159]Epoch 6:  50%|█████     | 11/22 [00:00<00:00, 32.25it/s, train_loss=0.0124, val_loss=0.0159]Epoch 6:  50%|█████     | 11/22 [00:00<00:00, 30.64it/s, train_loss=0.0112, val_loss=0.0159]Epoch 6:  55%|█████▍    | 12/22 [00:00<00:00, 32.16it/s, train_loss=0.0112, val_loss=0.0159]Epoch 6:  55%|█████▍    | 12/22 [00:00<00:00, 30.65it/s, train_loss=0.0121, val_loss=0.0159]Epoch 6:  59%|█████▉    | 13/22 [00:00<00:00, 32.10it/s, train_loss=0.0121, val_loss=0.0159]Epoch 6:  59%|█████▉    | 13/22 [00:00<00:00, 30.66it/s, train_loss=0.012, val_loss=0.0159] Epoch 6:  64%|██████▎   | 14/22 [00:00<00:00, 31.93it/s, train_loss=0.012, val_loss=0.0159]Epoch 6:  64%|██████▎   | 14/22 [00:00<00:00, 30.67it/s, train_loss=0.0137, val_loss=0.0159]Epoch 6:  68%|██████▊   | 15/22 [00:00<00:00, 31.84it/s, train_loss=0.0137, val_loss=0.0159]Epoch 6:  68%|██████▊   | 15/22 [00:00<00:00, 30.70it/s, train_loss=0.0125, val_loss=0.0159]Epoch 6:  73%|███████▎  | 16/22 [00:00<00:00, 31.82it/s, train_loss=0.0125, val_loss=0.0159]Epoch 6:  73%|███████▎  | 16/22 [00:00<00:00, 30.72it/s, train_loss=0.0117, val_loss=0.0159]Epoch 6:  77%|███████▋  | 17/22 [00:00<00:00, 31.77it/s, train_loss=0.0117, val_loss=0.0159]Epoch 6:  77%|███████▋  | 17/22 [00:00<00:00, 30.74it/s, train_loss=0.0114, val_loss=0.0159]Epoch 6:  82%|████████▏ | 18/22 [00:00<00:00, 31.73it/s, train_loss=0.0114, val_loss=0.0159]Epoch 6:  82%|████████▏ | 18/22 [00:00<00:00, 30.75it/s, train_loss=0.0121, val_loss=0.0159]Epoch 6:  86%|████████▋ | 19/22 [00:00<00:00, 31.65it/s, train_loss=0.0121, val_loss=0.0159]Epoch 6:  86%|████████▋ | 19/22 [00:00<00:00, 30.76it/s, train_loss=0.0122, val_loss=0.0159]Epoch 6:  91%|█████████ | 20/22 [00:00<00:00, 31.65it/s, train_loss=0.0122, val_loss=0.0159]Epoch 6:  91%|█████████ | 20/22 [00:00<00:00, 30.77it/s, train_loss=0.00989, val_loss=0.0159]Epoch 6:  95%|█████████▌| 21/22 [00:00<00:00, 31.61it/s, train_loss=0.00989, val_loss=0.0159]Epoch 6:  95%|█████████▌| 21/22 [00:00<00:00, 30.78it/s, train_loss=0.0113, val_loss=0.0159] Epoch 6: 100%|██████████| 22/22 [00:00<00:00, 31.60it/s, train_loss=0.0113, val_loss=0.0159]Epoch 6: 100%|██████████| 22/22 [00:00<00:00, 30.88it/s, train_loss=0.0119, val_loss=0.0159]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 92.66it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 112.54it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 126.60it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 135.16it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 140.99it/s][A
                                                                       [AEpoch 6: 100%|██████████| 22/22 [00:00<00:00, 28.46it/s, train_loss=0.0119, val_loss=0.0108]Epoch 6: 100%|██████████| 22/22 [00:00<00:00, 28.43it/s, train_loss=0.0119, val_loss=0.0108]Epoch 6:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0119, val_loss=0.0108]         Epoch 7:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0119, val_loss=0.0108]Epoch 7:   5%|▍         | 1/22 [00:00<00:00, 74.16it/s, train_loss=0.0119, val_loss=0.0108]Epoch 7:   5%|▍         | 1/22 [00:00<00:00, 30.37it/s, train_loss=0.0122, val_loss=0.0108]Epoch 7:   9%|▉         | 2/22 [00:00<00:00, 44.49it/s, train_loss=0.0122, val_loss=0.0108]Epoch 7:   9%|▉         | 2/22 [00:00<00:00, 30.46it/s, train_loss=0.0101, val_loss=0.0108]Epoch 7:  14%|█▎        | 3/22 [00:00<00:00, 38.71it/s, train_loss=0.0101, val_loss=0.0108]Epoch 7:  14%|█▎        | 3/22 [00:00<00:00, 30.49it/s, train_loss=0.0105, val_loss=0.0108]Epoch 7:  18%|█▊        | 4/22 [00:00<00:00, 36.33it/s, train_loss=0.0105, val_loss=0.0108]Epoch 7:  18%|█▊        | 4/22 [00:00<00:00, 30.54it/s, train_loss=0.0112, val_loss=0.0108]Epoch 7:  23%|██▎       | 5/22 [00:00<00:00, 35.04it/s, train_loss=0.0112, val_loss=0.0108]Epoch 7:  23%|██▎       | 5/22 [00:00<00:00, 30.60it/s, train_loss=0.010, val_loss=0.0108] Epoch 7:  27%|██▋       | 6/22 [00:00<00:00, 34.25it/s, train_loss=0.010, val_loss=0.0108]Epoch 7:  27%|██▋       | 6/22 [00:00<00:00, 30.63it/s, train_loss=0.0109, val_loss=0.0108]Epoch 7:  32%|███▏      | 7/22 [00:00<00:00, 33.58it/s, train_loss=0.0109, val_loss=0.0108]Epoch 7:  32%|███▏      | 7/22 [00:00<00:00, 30.66it/s, train_loss=0.00967, val_loss=0.0108]Epoch 7:  36%|███▋      | 8/22 [00:00<00:00, 32.99it/s, train_loss=0.00967, val_loss=0.0108]Epoch 7:  36%|███▋      | 8/22 [00:00<00:00, 30.69it/s, train_loss=0.00944, val_loss=0.0108]Epoch 7:  41%|████      | 9/22 [00:00<00:00, 32.85it/s, train_loss=0.00944, val_loss=0.0108]Epoch 7:  41%|████      | 9/22 [00:00<00:00, 30.68it/s, train_loss=0.0106, val_loss=0.0108] Epoch 7:  45%|████▌     | 10/22 [00:00<00:00, 32.50it/s, train_loss=0.0106, val_loss=0.0108]Epoch 7:  45%|████▌     | 10/22 [00:00<00:00, 30.69it/s, train_loss=0.00922, val_loss=0.0108]Epoch 7:  50%|█████     | 11/22 [00:00<00:00, 32.31it/s, train_loss=0.00922, val_loss=0.0108]Epoch 7:  50%|█████     | 11/22 [00:00<00:00, 30.74it/s, train_loss=0.00914, val_loss=0.0108]Epoch 7:  55%|█████▍    | 12/22 [00:00<00:00, 32.25it/s, train_loss=0.00914, val_loss=0.0108]Epoch 7:  55%|█████▍    | 12/22 [00:00<00:00, 30.76it/s, train_loss=0.00964, val_loss=0.0108]Epoch 7:  59%|█████▉    | 13/22 [00:00<00:00, 32.13it/s, train_loss=0.00964, val_loss=0.0108]Epoch 7:  59%|█████▉    | 13/22 [00:00<00:00, 30.77it/s, train_loss=0.00946, val_loss=0.0108]Epoch 7:  64%|██████▎   | 14/22 [00:00<00:00, 32.06it/s, train_loss=0.00946, val_loss=0.0108]Epoch 7:  64%|██████▎   | 14/22 [00:00<00:00, 30.81it/s, train_loss=0.00933, val_loss=0.0108]Epoch 7:  68%|██████▊   | 15/22 [00:00<00:00, 32.02it/s, train_loss=0.00933, val_loss=0.0108]Epoch 7:  68%|██████▊   | 15/22 [00:00<00:00, 30.82it/s, train_loss=0.00929, val_loss=0.0108]Epoch 7:  73%|███████▎  | 16/22 [00:00<00:00, 31.94it/s, train_loss=0.00929, val_loss=0.0108]Epoch 7:  73%|███████▎  | 16/22 [00:00<00:00, 30.85it/s, train_loss=0.00812, val_loss=0.0108]Epoch 7:  77%|███████▋  | 17/22 [00:00<00:00, 31.94it/s, train_loss=0.00812, val_loss=0.0108]Epoch 7:  77%|███████▋  | 17/22 [00:00<00:00, 30.86it/s, train_loss=0.00894, val_loss=0.0108]Epoch 7:  82%|████████▏ | 18/22 [00:00<00:00, 31.91it/s, train_loss=0.00894, val_loss=0.0108]Epoch 7:  82%|████████▏ | 18/22 [00:00<00:00, 30.88it/s, train_loss=0.00989, val_loss=0.0108]Epoch 7:  86%|████████▋ | 19/22 [00:00<00:00, 31.87it/s, train_loss=0.00989, val_loss=0.0108]Epoch 7:  86%|████████▋ | 19/22 [00:00<00:00, 30.90it/s, train_loss=0.0092, val_loss=0.0108] Epoch 7:  91%|█████████ | 20/22 [00:00<00:00, 31.84it/s, train_loss=0.0092, val_loss=0.0108]Epoch 7:  91%|█████████ | 20/22 [00:00<00:00, 30.90it/s, train_loss=0.0085, val_loss=0.0108]Epoch 7:  95%|█████████▌| 21/22 [00:00<00:00, 31.77it/s, train_loss=0.0085, val_loss=0.0108]Epoch 7:  95%|█████████▌| 21/22 [00:00<00:00, 30.92it/s, train_loss=0.00811, val_loss=0.0108]Epoch 7: 100%|██████████| 22/22 [00:00<00:00, 31.78it/s, train_loss=0.00811, val_loss=0.0108]Epoch 7: 100%|██████████| 22/22 [00:00<00:00, 31.03it/s, train_loss=0.00891, val_loss=0.0108]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 124.69it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 133.06it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 133.47it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 138.34it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 140.89it/s][A
                                                                       [AEpoch 7: 100%|██████████| 22/22 [00:00<00:00, 28.64it/s, train_loss=0.00891, val_loss=0.00836]Epoch 7: 100%|██████████| 22/22 [00:00<00:00, 28.60it/s, train_loss=0.00891, val_loss=0.00836]Epoch 7:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00891, val_loss=0.00836]         Epoch 8:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00891, val_loss=0.00836]Epoch 8:   5%|▍         | 1/22 [00:00<00:00, 77.30it/s, train_loss=0.00891, val_loss=0.00836]Epoch 8:   5%|▍         | 1/22 [00:00<00:00, 30.19it/s, train_loss=0.00822, val_loss=0.00836]Epoch 8:   9%|▉         | 2/22 [00:00<00:00, 44.03it/s, train_loss=0.00822, val_loss=0.00836]Epoch 8:   9%|▉         | 2/22 [00:00<00:00, 30.57it/s, train_loss=0.00791, val_loss=0.00836]Epoch 8:  14%|█▎        | 3/22 [00:00<00:00, 38.88it/s, train_loss=0.00791, val_loss=0.00836]Epoch 8:  14%|█▎        | 3/22 [00:00<00:00, 30.74it/s, train_loss=0.00819, val_loss=0.00836]Epoch 8:  18%|█▊        | 4/22 [00:00<00:00, 36.32it/s, train_loss=0.00819, val_loss=0.00836]Epoch 8:  18%|█▊        | 4/22 [00:00<00:00, 30.71it/s, train_loss=0.00876, val_loss=0.00836]Epoch 8:  23%|██▎       | 5/22 [00:00<00:00, 34.92it/s, train_loss=0.00876, val_loss=0.00836]Epoch 8:  23%|██▎       | 5/22 [00:00<00:00, 30.79it/s, train_loss=0.00843, val_loss=0.00836]Epoch 8:  27%|██▋       | 6/22 [00:00<00:00, 34.12it/s, train_loss=0.00843, val_loss=0.00836]Epoch 8:  27%|██▋       | 6/22 [00:00<00:00, 30.84it/s, train_loss=0.00841, val_loss=0.00836]Epoch 8:  32%|███▏      | 7/22 [00:00<00:00, 33.71it/s, train_loss=0.00841, val_loss=0.00836]Epoch 8:  32%|███▏      | 7/22 [00:00<00:00, 30.89it/s, train_loss=0.00789, val_loss=0.00836]Epoch 8:  36%|███▋      | 8/22 [00:00<00:00, 33.31it/s, train_loss=0.00789, val_loss=0.00836]Epoch 8:  36%|███▋      | 8/22 [00:00<00:00, 30.95it/s, train_loss=0.00795, val_loss=0.00836]Epoch 8:  41%|████      | 9/22 [00:00<00:00, 33.10it/s, train_loss=0.00795, val_loss=0.00836]Epoch 8:  41%|████      | 9/22 [00:00<00:00, 30.97it/s, train_loss=0.00757, val_loss=0.00836]Epoch 8:  45%|████▌     | 10/22 [00:00<00:00, 32.97it/s, train_loss=0.00757, val_loss=0.00836]Epoch 8:  45%|████▌     | 10/22 [00:00<00:00, 30.99it/s, train_loss=0.00755, val_loss=0.00836]Epoch 8:  50%|█████     | 11/22 [00:00<00:00, 32.87it/s, train_loss=0.00755, val_loss=0.00836]Epoch 8:  50%|█████     | 11/22 [00:00<00:00, 31.02it/s, train_loss=0.00814, val_loss=0.00836]Epoch 8:  55%|█████▍    | 12/22 [00:00<00:00, 32.79it/s, train_loss=0.00814, val_loss=0.00836]Epoch 8:  55%|█████▍    | 12/22 [00:00<00:00, 31.06it/s, train_loss=0.00742, val_loss=0.00836]Epoch 8:  59%|█████▉    | 13/22 [00:00<00:00, 32.68it/s, train_loss=0.00742, val_loss=0.00836]Epoch 8:  59%|█████▉    | 13/22 [00:00<00:00, 31.08it/s, train_loss=0.00779, val_loss=0.00836]Epoch 8:  64%|██████▎   | 14/22 [00:00<00:00, 32.57it/s, train_loss=0.00779, val_loss=0.00836]Epoch 8:  64%|██████▎   | 14/22 [00:00<00:00, 31.08it/s, train_loss=0.00746, val_loss=0.00836]Epoch 8:  68%|██████▊   | 15/22 [00:00<00:00, 32.46it/s, train_loss=0.00746, val_loss=0.00836]Epoch 8:  68%|██████▊   | 15/22 [00:00<00:00, 31.09it/s, train_loss=0.00772, val_loss=0.00836]Epoch 8:  73%|███████▎  | 16/22 [00:00<00:00, 32.20it/s, train_loss=0.00772, val_loss=0.00836]Epoch 8:  73%|███████▎  | 16/22 [00:00<00:00, 31.06it/s, train_loss=0.00738, val_loss=0.00836]Epoch 8:  77%|███████▋  | 17/22 [00:00<00:00, 32.14it/s, train_loss=0.00738, val_loss=0.00836]Epoch 8:  77%|███████▋  | 17/22 [00:00<00:00, 31.08it/s, train_loss=0.00784, val_loss=0.00836]Epoch 8:  82%|████████▏ | 18/22 [00:00<00:00, 32.07it/s, train_loss=0.00784, val_loss=0.00836]Epoch 8:  82%|████████▏ | 18/22 [00:00<00:00, 31.09it/s, train_loss=0.00755, val_loss=0.00836]Epoch 8:  86%|████████▋ | 19/22 [00:00<00:00, 32.07it/s, train_loss=0.00755, val_loss=0.00836]Epoch 8:  86%|████████▋ | 19/22 [00:00<00:00, 31.10it/s, train_loss=0.00711, val_loss=0.00836]Epoch 8:  91%|█████████ | 20/22 [00:00<00:00, 32.02it/s, train_loss=0.00711, val_loss=0.00836]Epoch 8:  91%|█████████ | 20/22 [00:00<00:00, 31.11it/s, train_loss=0.00652, val_loss=0.00836]Epoch 8:  95%|█████████▌| 21/22 [00:00<00:00, 32.00it/s, train_loss=0.00652, val_loss=0.00836]Epoch 8:  95%|█████████▌| 21/22 [00:00<00:00, 31.12it/s, train_loss=0.00769, val_loss=0.00836]Epoch 8: 100%|██████████| 22/22 [00:00<00:00, 31.99it/s, train_loss=0.00769, val_loss=0.00836]Epoch 8: 100%|██████████| 22/22 [00:00<00:00, 31.24it/s, train_loss=0.0081, val_loss=0.00836] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 107.57it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 122.57it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 127.41it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 131.29it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 133.64it/s][A
                                                                       [AEpoch 8: 100%|██████████| 22/22 [00:00<00:00, 28.77it/s, train_loss=0.0081, val_loss=0.00716]Epoch 8: 100%|██████████| 22/22 [00:00<00:00, 28.73it/s, train_loss=0.0081, val_loss=0.00716]Epoch 8:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0081, val_loss=0.00716]         Epoch 9:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0081, val_loss=0.00716]Epoch 9:   5%|▍         | 1/22 [00:00<00:00, 70.21it/s, train_loss=0.0081, val_loss=0.00716]Epoch 9:   5%|▍         | 1/22 [00:00<00:00, 31.26it/s, train_loss=0.00775, val_loss=0.00716]Epoch 9:   9%|▉         | 2/22 [00:00<00:00, 44.16it/s, train_loss=0.00775, val_loss=0.00716]Epoch 9:   9%|▉         | 2/22 [00:00<00:00, 31.39it/s, train_loss=0.00653, val_loss=0.00716]Epoch 9:  14%|█▎        | 3/22 [00:00<00:00, 39.00it/s, train_loss=0.00653, val_loss=0.00716]Epoch 9:  14%|█▎        | 3/22 [00:00<00:00, 31.34it/s, train_loss=0.00729, val_loss=0.00716]Epoch 9:  18%|█▊        | 4/22 [00:00<00:00, 36.73it/s, train_loss=0.00729, val_loss=0.00716]Epoch 9:  18%|█▊        | 4/22 [00:00<00:00, 31.33it/s, train_loss=0.00706, val_loss=0.00716]Epoch 9:  23%|██▎       | 5/22 [00:00<00:00, 35.49it/s, train_loss=0.00706, val_loss=0.00716]Epoch 9:  23%|██▎       | 5/22 [00:00<00:00, 31.34it/s, train_loss=0.00684, val_loss=0.00716]Epoch 9:  27%|██▋       | 6/22 [00:00<00:00, 34.74it/s, train_loss=0.00684, val_loss=0.00716]Epoch 9:  27%|██▋       | 6/22 [00:00<00:00, 31.34it/s, train_loss=0.00694, val_loss=0.00716]Epoch 9:  32%|███▏      | 7/22 [00:00<00:00, 34.10it/s, train_loss=0.00694, val_loss=0.00716]Epoch 9:  32%|███▏      | 7/22 [00:00<00:00, 31.31it/s, train_loss=0.0074, val_loss=0.00716] Epoch 9:  36%|███▋      | 8/22 [00:00<00:00, 33.68it/s, train_loss=0.0074, val_loss=0.00716]Epoch 9:  36%|███▋      | 8/22 [00:00<00:00, 31.30it/s, train_loss=0.00675, val_loss=0.00716]Epoch 9:  41%|████      | 9/22 [00:00<00:00, 33.39it/s, train_loss=0.00675, val_loss=0.00716]Epoch 9:  41%|████      | 9/22 [00:00<00:00, 31.33it/s, train_loss=0.0076, val_loss=0.00716] Epoch 9:  45%|████▌     | 10/22 [00:00<00:00, 33.27it/s, train_loss=0.0076, val_loss=0.00716]Epoch 9:  45%|████▌     | 10/22 [00:00<00:00, 31.32it/s, train_loss=0.00676, val_loss=0.00716]Epoch 9:  50%|█████     | 11/22 [00:00<00:00, 33.07it/s, train_loss=0.00676, val_loss=0.00716]Epoch 9:  50%|█████     | 11/22 [00:00<00:00, 31.31it/s, train_loss=0.00683, val_loss=0.00716]Epoch 9:  55%|█████▍    | 12/22 [00:00<00:00, 32.90it/s, train_loss=0.00683, val_loss=0.00716]Epoch 9:  55%|█████▍    | 12/22 [00:00<00:00, 31.30it/s, train_loss=0.00719, val_loss=0.00716]Epoch 9:  59%|█████▉    | 13/22 [00:00<00:00, 32.73it/s, train_loss=0.00719, val_loss=0.00716]Epoch 9:  59%|█████▉    | 13/22 [00:00<00:00, 31.31it/s, train_loss=0.00673, val_loss=0.00716]Epoch 9:  64%|██████▎   | 14/22 [00:00<00:00, 32.66it/s, train_loss=0.00673, val_loss=0.00716]Epoch 9:  64%|██████▎   | 14/22 [00:00<00:00, 31.31it/s, train_loss=0.00701, val_loss=0.00716]Epoch 9:  68%|██████▊   | 15/22 [00:00<00:00, 32.56it/s, train_loss=0.00701, val_loss=0.00716]Epoch 9:  68%|██████▊   | 15/22 [00:00<00:00, 31.31it/s, train_loss=0.00722, val_loss=0.00716]Epoch 9:  73%|███████▎  | 16/22 [00:00<00:00, 32.47it/s, train_loss=0.00722, val_loss=0.00716]Epoch 9:  73%|███████▎  | 16/22 [00:00<00:00, 31.32it/s, train_loss=0.00685, val_loss=0.00716]Epoch 9:  77%|███████▋  | 17/22 [00:00<00:00, 32.42it/s, train_loss=0.00685, val_loss=0.00716]Epoch 9:  77%|███████▋  | 17/22 [00:00<00:00, 31.32it/s, train_loss=0.00711, val_loss=0.00716]Epoch 9:  82%|████████▏ | 18/22 [00:00<00:00, 32.36it/s, train_loss=0.00711, val_loss=0.00716]Epoch 9:  82%|████████▏ | 18/22 [00:00<00:00, 31.32it/s, train_loss=0.00711, val_loss=0.00716]Epoch 9:  86%|████████▋ | 19/22 [00:00<00:00, 32.29it/s, train_loss=0.00711, val_loss=0.00716]Epoch 9:  86%|████████▋ | 19/22 [00:00<00:00, 31.33it/s, train_loss=0.00687, val_loss=0.00716]Epoch 9:  91%|█████████ | 20/22 [00:00<00:00, 32.25it/s, train_loss=0.00687, val_loss=0.00716]Epoch 9:  91%|█████████ | 20/22 [00:00<00:00, 31.33it/s, train_loss=0.00705, val_loss=0.00716]Epoch 9:  95%|█████████▌| 21/22 [00:00<00:00, 32.22it/s, train_loss=0.00705, val_loss=0.00716]Epoch 9:  95%|█████████▌| 21/22 [00:00<00:00, 31.32it/s, train_loss=0.0071, val_loss=0.00716] Epoch 9: 100%|██████████| 22/22 [00:00<00:00, 32.25it/s, train_loss=0.0071, val_loss=0.00716]Epoch 9: 100%|██████████| 22/22 [00:00<00:00, 31.42it/s, train_loss=0.00661, val_loss=0.00716]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 117.43it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 132.92it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 140.90it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 145.14it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 145.34it/s][A
                                                                       [AEpoch 9: 100%|██████████| 22/22 [00:00<00:00, 29.05it/s, train_loss=0.00661, val_loss=0.00679]Epoch 9: 100%|██████████| 22/22 [00:00<00:00, 29.02it/s, train_loss=0.00661, val_loss=0.00679]Epoch 9:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00661, val_loss=0.00679]         Epoch 10:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00661, val_loss=0.00679]Epoch 10:   5%|▍         | 1/22 [00:00<00:00, 71.58it/s, train_loss=0.00661, val_loss=0.00679]Epoch 10:   5%|▍         | 1/22 [00:00<00:00, 31.79it/s, train_loss=0.00662, val_loss=0.00679]Epoch 10:   9%|▉         | 2/22 [00:00<00:00, 43.74it/s, train_loss=0.00662, val_loss=0.00679]Epoch 10:   9%|▉         | 2/22 [00:00<00:00, 32.09it/s, train_loss=0.00668, val_loss=0.00679]Epoch 10:  14%|█▎        | 3/22 [00:00<00:00, 39.49it/s, train_loss=0.00668, val_loss=0.00679]Epoch 10:  14%|█▎        | 3/22 [00:00<00:00, 31.86it/s, train_loss=0.0069, val_loss=0.00679] Epoch 10:  18%|█▊        | 4/22 [00:00<00:00, 36.98it/s, train_loss=0.0069, val_loss=0.00679]Epoch 10:  18%|█▊        | 4/22 [00:00<00:00, 31.68it/s, train_loss=0.00711, val_loss=0.00679]Epoch 10:  23%|██▎       | 5/22 [00:00<00:00, 35.53it/s, train_loss=0.00711, val_loss=0.00679]Epoch 10:  23%|██▎       | 5/22 [00:00<00:00, 31.62it/s, train_loss=0.0069, val_loss=0.00679] Epoch 10:  27%|██▋       | 6/22 [00:00<00:00, 34.77it/s, train_loss=0.0069, val_loss=0.00679]Epoch 10:  27%|██▋       | 6/22 [00:00<00:00, 31.62it/s, train_loss=0.00674, val_loss=0.00679]Epoch 10:  32%|███▏      | 7/22 [00:00<00:00, 34.31it/s, train_loss=0.00674, val_loss=0.00679]Epoch 10:  32%|███▏      | 7/22 [00:00<00:00, 31.61it/s, train_loss=0.00626, val_loss=0.00679]Epoch 10:  36%|███▋      | 8/22 [00:00<00:00, 33.95it/s, train_loss=0.00626, val_loss=0.00679]Epoch 10:  36%|███▋      | 8/22 [00:00<00:00, 31.60it/s, train_loss=0.00643, val_loss=0.00679]Epoch 10:  41%|████      | 9/22 [00:00<00:00, 33.67it/s, train_loss=0.00643, val_loss=0.00679]Epoch 10:  41%|████      | 9/22 [00:00<00:00, 31.59it/s, train_loss=0.00659, val_loss=0.00679]Epoch 10:  45%|████▌     | 10/22 [00:00<00:00, 33.43it/s, train_loss=0.00659, val_loss=0.00679]Epoch 10:  45%|████▌     | 10/22 [00:00<00:00, 31.57it/s, train_loss=0.00618, val_loss=0.00679]Epoch 10:  50%|█████     | 11/22 [00:00<00:00, 33.13it/s, train_loss=0.00618, val_loss=0.00679]Epoch 10:  50%|█████     | 11/22 [00:00<00:00, 31.57it/s, train_loss=0.00624, val_loss=0.00679]Epoch 10:  55%|█████▍    | 12/22 [00:00<00:00, 33.07it/s, train_loss=0.00624, val_loss=0.00679]Epoch 10:  55%|█████▍    | 12/22 [00:00<00:00, 31.56it/s, train_loss=0.0063, val_loss=0.00679] Epoch 10:  59%|█████▉    | 13/22 [00:00<00:00, 32.84it/s, train_loss=0.0063, val_loss=0.00679]Epoch 10:  59%|█████▉    | 13/22 [00:00<00:00, 31.54it/s, train_loss=0.00679, val_loss=0.00679]Epoch 10:  64%|██████▎   | 14/22 [00:00<00:00, 32.84it/s, train_loss=0.00679, val_loss=0.00679]Epoch 10:  64%|██████▎   | 14/22 [00:00<00:00, 31.53it/s, train_loss=0.00657, val_loss=0.00679]Epoch 10:  68%|██████▊   | 15/22 [00:00<00:00, 32.75it/s, train_loss=0.00657, val_loss=0.00679]Epoch 10:  68%|██████▊   | 15/22 [00:00<00:00, 31.52it/s, train_loss=0.00631, val_loss=0.00679]Epoch 10:  73%|███████▎  | 16/22 [00:00<00:00, 32.75it/s, train_loss=0.00631, val_loss=0.00679]Epoch 10:  73%|███████▎  | 16/22 [00:00<00:00, 31.50it/s, train_loss=0.0071, val_loss=0.00679] Epoch 10:  77%|███████▋  | 17/22 [00:00<00:00, 32.65it/s, train_loss=0.0071, val_loss=0.00679]Epoch 10:  77%|███████▋  | 17/22 [00:00<00:00, 31.49it/s, train_loss=0.00662, val_loss=0.00679]Epoch 10:  82%|████████▏ | 18/22 [00:00<00:00, 32.57it/s, train_loss=0.00662, val_loss=0.00679]Epoch 10:  82%|████████▏ | 18/22 [00:00<00:00, 31.48it/s, train_loss=0.00622, val_loss=0.00679]Epoch 10:  86%|████████▋ | 19/22 [00:00<00:00, 32.51it/s, train_loss=0.00622, val_loss=0.00679]Epoch 10:  86%|████████▋ | 19/22 [00:00<00:00, 31.47it/s, train_loss=0.00637, val_loss=0.00679]Epoch 10:  91%|█████████ | 20/22 [00:00<00:00, 32.34it/s, train_loss=0.00637, val_loss=0.00679]Epoch 10:  91%|█████████ | 20/22 [00:00<00:00, 31.45it/s, train_loss=0.00656, val_loss=0.00679]Epoch 10:  95%|█████████▌| 21/22 [00:00<00:00, 32.30it/s, train_loss=0.00656, val_loss=0.00679]Epoch 10:  95%|█████████▌| 21/22 [00:00<00:00, 31.44it/s, train_loss=0.00628, val_loss=0.00679]Epoch 10: 100%|██████████| 22/22 [00:00<00:00, 32.28it/s, train_loss=0.00628, val_loss=0.00679]Epoch 10: 100%|██████████| 22/22 [00:00<00:00, 31.54it/s, train_loss=0.00649, val_loss=0.00679]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 102.33it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 113.75it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 122.29it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 127.61it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 131.15it/s][A
                                                                       [AEpoch 10: 100%|██████████| 22/22 [00:00<00:00, 29.05it/s, train_loss=0.00649, val_loss=0.00628]Epoch 10: 100%|██████████| 22/22 [00:00<00:00, 29.01it/s, train_loss=0.00649, val_loss=0.00628]Epoch 10:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00649, val_loss=0.00628]         Epoch 11:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00649, val_loss=0.00628]Epoch 11:   5%|▍         | 1/22 [00:00<00:00, 65.85it/s, train_loss=0.00649, val_loss=0.00628]Epoch 11:   5%|▍         | 1/22 [00:00<00:00, 30.86it/s, train_loss=0.00671, val_loss=0.00628]Epoch 11:   9%|▉         | 2/22 [00:00<00:00, 42.80it/s, train_loss=0.00671, val_loss=0.00628]Epoch 11:   9%|▉         | 2/22 [00:00<00:00, 31.14it/s, train_loss=0.00588, val_loss=0.00628]Epoch 11:  14%|█▎        | 3/22 [00:00<00:00, 38.25it/s, train_loss=0.00588, val_loss=0.00628]Epoch 11:  14%|█▎        | 3/22 [00:00<00:00, 31.19it/s, train_loss=0.00659, val_loss=0.00628]Epoch 11:  18%|█▊        | 4/22 [00:00<00:00, 36.17it/s, train_loss=0.00659, val_loss=0.00628]Epoch 11:  18%|█▊        | 4/22 [00:00<00:00, 31.20it/s, train_loss=0.00645, val_loss=0.00628]Epoch 11:  23%|██▎       | 5/22 [00:00<00:00, 35.08it/s, train_loss=0.00645, val_loss=0.00628]Epoch 11:  23%|██▎       | 5/22 [00:00<00:00, 31.21it/s, train_loss=0.0062, val_loss=0.00628] Epoch 11:  27%|██▋       | 6/22 [00:00<00:00, 34.72it/s, train_loss=0.0062, val_loss=0.00628]Epoch 11:  27%|██▋       | 6/22 [00:00<00:00, 31.25it/s, train_loss=0.00632, val_loss=0.00628]Epoch 11:  32%|███▏      | 7/22 [00:00<00:00, 34.34it/s, train_loss=0.00632, val_loss=0.00628]Epoch 11:  32%|███▏      | 7/22 [00:00<00:00, 31.20it/s, train_loss=0.00645, val_loss=0.00628]Epoch 11:  36%|███▋      | 8/22 [00:00<00:00, 33.91it/s, train_loss=0.00645, val_loss=0.00628]Epoch 11:  36%|███▋      | 8/22 [00:00<00:00, 31.21it/s, train_loss=0.00624, val_loss=0.00628]Epoch 11:  41%|████      | 9/22 [00:00<00:00, 33.62it/s, train_loss=0.00624, val_loss=0.00628]Epoch 11:  41%|████      | 9/22 [00:00<00:00, 31.40it/s, train_loss=0.00603, val_loss=0.00628]Epoch 11:  45%|████▌     | 10/22 [00:00<00:00, 33.53it/s, train_loss=0.00603, val_loss=0.00628]Epoch 11:  45%|████▌     | 10/22 [00:00<00:00, 31.76it/s, train_loss=0.00615, val_loss=0.00628]Epoch 11:  50%|█████     | 11/22 [00:00<00:00, 33.18it/s, train_loss=0.00615, val_loss=0.00628]Epoch 11:  50%|█████     | 11/22 [00:00<00:00, 31.61it/s, train_loss=0.00582, val_loss=0.00628]Epoch 11:  55%|█████▍    | 12/22 [00:00<00:00, 32.02it/s, train_loss=0.00582, val_loss=0.00628]Epoch 11:  55%|█████▍    | 12/22 [00:00<00:00, 30.59it/s, train_loss=0.00573, val_loss=0.00628]Epoch 11:  59%|█████▉    | 13/22 [00:00<00:00, 32.08it/s, train_loss=0.00573, val_loss=0.00628]Epoch 11:  59%|█████▉    | 13/22 [00:00<00:00, 30.78it/s, train_loss=0.00585, val_loss=0.00628]Epoch 11:  64%|██████▎   | 14/22 [00:00<00:00, 32.23it/s, train_loss=0.00585, val_loss=0.00628]Epoch 11:  64%|██████▎   | 14/22 [00:00<00:00, 30.72it/s, train_loss=0.00627, val_loss=0.00628]Epoch 11:  68%|██████▊   | 15/22 [00:00<00:00, 32.03it/s, train_loss=0.00627, val_loss=0.00628]Epoch 11:  68%|██████▊   | 15/22 [00:00<00:00, 30.66it/s, train_loss=0.00582, val_loss=0.00628]Epoch 11:  73%|███████▎  | 16/22 [00:00<00:00, 31.72it/s, train_loss=0.00582, val_loss=0.00628]Epoch 11:  73%|███████▎  | 16/22 [00:00<00:00, 30.60it/s, train_loss=0.00617, val_loss=0.00628]Epoch 11:  77%|███████▋  | 17/22 [00:00<00:00, 31.70it/s, train_loss=0.00617, val_loss=0.00628]Epoch 11:  77%|███████▋  | 17/22 [00:00<00:00, 30.66it/s, train_loss=0.00644, val_loss=0.00628]Epoch 11:  82%|████████▏ | 18/22 [00:00<00:00, 31.63it/s, train_loss=0.00644, val_loss=0.00628]Epoch 11:  82%|████████▏ | 18/22 [00:00<00:00, 30.74it/s, train_loss=0.00599, val_loss=0.00628]Epoch 11:  86%|████████▋ | 19/22 [00:00<00:00, 31.70it/s, train_loss=0.00599, val_loss=0.00628]Epoch 11:  86%|████████▋ | 19/22 [00:00<00:00, 30.70it/s, train_loss=0.00602, val_loss=0.00628]Epoch 11:  91%|█████████ | 20/22 [00:00<00:00, 31.62it/s, train_loss=0.00602, val_loss=0.00628]Epoch 11:  91%|█████████ | 20/22 [00:00<00:00, 30.66it/s, train_loss=0.00599, val_loss=0.00628]Epoch 11:  95%|█████████▌| 21/22 [00:00<00:00, 31.50it/s, train_loss=0.00599, val_loss=0.00628]Epoch 11:  95%|█████████▌| 21/22 [00:00<00:00, 30.62it/s, train_loss=0.00587, val_loss=0.00628]Epoch 11: 100%|██████████| 22/22 [00:00<00:00, 31.46it/s, train_loss=0.00587, val_loss=0.00628]Epoch 11: 100%|██████████| 22/22 [00:00<00:00, 30.69it/s, train_loss=0.00625, val_loss=0.00628]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 111.22it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 135.78it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 147.48it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 150.87it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 146.07it/s][A
                                                                       [AEpoch 11: 100%|██████████| 22/22 [00:00<00:00, 28.32it/s, train_loss=0.00625, val_loss=0.00582]Epoch 11: 100%|██████████| 22/22 [00:00<00:00, 28.29it/s, train_loss=0.00625, val_loss=0.00582]Epoch 11:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00625, val_loss=0.00582]         Epoch 12:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00625, val_loss=0.00582]Epoch 12:   5%|▍         | 1/22 [00:00<00:00, 71.90it/s, train_loss=0.00625, val_loss=0.00582]Epoch 12:   5%|▍         | 1/22 [00:00<00:00, 31.61it/s, train_loss=0.00661, val_loss=0.00582]Epoch 12:   9%|▉         | 2/22 [00:00<00:00, 43.56it/s, train_loss=0.00661, val_loss=0.00582]Epoch 12:   9%|▉         | 2/22 [00:00<00:00, 31.53it/s, train_loss=0.00607, val_loss=0.00582]Epoch 12:  14%|█▎        | 3/22 [00:00<00:00, 38.68it/s, train_loss=0.00607, val_loss=0.00582]Epoch 12:  14%|█▎        | 3/22 [00:00<00:00, 31.06it/s, train_loss=0.00542, val_loss=0.00582]Epoch 12:  18%|█▊        | 4/22 [00:00<00:00, 36.30it/s, train_loss=0.00542, val_loss=0.00582]Epoch 12:  18%|█▊        | 4/22 [00:00<00:00, 30.80it/s, train_loss=0.00561, val_loss=0.00582]Epoch 12:  23%|██▎       | 5/22 [00:00<00:00, 35.08it/s, train_loss=0.00561, val_loss=0.00582]Epoch 12:  23%|██▎       | 5/22 [00:00<00:00, 30.64it/s, train_loss=0.00616, val_loss=0.00582]Epoch 12:  27%|██▋       | 6/22 [00:00<00:00, 34.08it/s, train_loss=0.00616, val_loss=0.00582]Epoch 12:  27%|██▋       | 6/22 [00:00<00:00, 30.52it/s, train_loss=0.00577, val_loss=0.00582]Epoch 12:  32%|███▏      | 7/22 [00:00<00:00, 33.57it/s, train_loss=0.00577, val_loss=0.00582]Epoch 12:  32%|███▏      | 7/22 [00:00<00:00, 30.46it/s, train_loss=0.00561, val_loss=0.00582]Epoch 12:  36%|███▋      | 8/22 [00:00<00:00, 33.15it/s, train_loss=0.00561, val_loss=0.00582]Epoch 12:  36%|███▋      | 8/22 [00:00<00:00, 30.41it/s, train_loss=0.00609, val_loss=0.00582]Epoch 12:  41%|████      | 9/22 [00:00<00:00, 32.73it/s, train_loss=0.00609, val_loss=0.00582]Epoch 12:  41%|████      | 9/22 [00:00<00:00, 30.36it/s, train_loss=0.00588, val_loss=0.00582]Epoch 12:  45%|████▌     | 10/22 [00:00<00:00, 32.43it/s, train_loss=0.00588, val_loss=0.00582]Epoch 12:  45%|████▌     | 10/22 [00:00<00:00, 30.32it/s, train_loss=0.00577, val_loss=0.00582]Epoch 12:  50%|█████     | 11/22 [00:00<00:00, 32.20it/s, train_loss=0.00577, val_loss=0.00582]Epoch 12:  50%|█████     | 11/22 [00:00<00:00, 30.31it/s, train_loss=0.00563, val_loss=0.00582]Epoch 12:  55%|█████▍    | 12/22 [00:00<00:00, 32.00it/s, train_loss=0.00563, val_loss=0.00582]Epoch 12:  55%|█████▍    | 12/22 [00:00<00:00, 30.27it/s, train_loss=0.00563, val_loss=0.00582]Epoch 12:  59%|█████▉    | 13/22 [00:00<00:00, 31.82it/s, train_loss=0.00563, val_loss=0.00582]Epoch 12:  59%|█████▉    | 13/22 [00:00<00:00, 30.23it/s, train_loss=0.00622, val_loss=0.00582]Epoch 12:  64%|██████▎   | 14/22 [00:00<00:00, 31.55it/s, train_loss=0.00622, val_loss=0.00582]Epoch 12:  64%|██████▎   | 14/22 [00:00<00:00, 30.15it/s, train_loss=0.00585, val_loss=0.00582]Epoch 12:  68%|██████▊   | 15/22 [00:00<00:00, 31.38it/s, train_loss=0.00585, val_loss=0.00582]Epoch 12:  68%|██████▊   | 15/22 [00:00<00:00, 30.14it/s, train_loss=0.00525, val_loss=0.00582]Epoch 12:  73%|███████▎  | 16/22 [00:00<00:00, 31.26it/s, train_loss=0.00525, val_loss=0.00582]Epoch 12:  73%|███████▎  | 16/22 [00:00<00:00, 30.13it/s, train_loss=0.00549, val_loss=0.00582]Epoch 12:  77%|███████▋  | 17/22 [00:00<00:00, 31.34it/s, train_loss=0.00549, val_loss=0.00582]Epoch 12:  77%|███████▋  | 17/22 [00:00<00:00, 30.13it/s, train_loss=0.00543, val_loss=0.00582]Epoch 12:  82%|████████▏ | 18/22 [00:00<00:00, 31.27it/s, train_loss=0.00543, val_loss=0.00582]Epoch 12:  82%|████████▏ | 18/22 [00:00<00:00, 30.14it/s, train_loss=0.00571, val_loss=0.00582]Epoch 12:  86%|████████▋ | 19/22 [00:00<00:00, 31.18it/s, train_loss=0.00571, val_loss=0.00582]Epoch 12:  86%|████████▋ | 19/22 [00:00<00:00, 30.13it/s, train_loss=0.00583, val_loss=0.00582]Epoch 12:  91%|█████████ | 20/22 [00:00<00:00, 31.14it/s, train_loss=0.00583, val_loss=0.00582]Epoch 12:  91%|█████████ | 20/22 [00:00<00:00, 30.13it/s, train_loss=0.00597, val_loss=0.00582]Epoch 12:  95%|█████████▌| 21/22 [00:00<00:00, 31.07it/s, train_loss=0.00597, val_loss=0.00582]Epoch 12:  95%|█████████▌| 21/22 [00:00<00:00, 30.11it/s, train_loss=0.00548, val_loss=0.00582]Epoch 12: 100%|██████████| 22/22 [00:00<00:00, 31.03it/s, train_loss=0.00548, val_loss=0.00582]Epoch 12: 100%|██████████| 22/22 [00:00<00:00, 30.21it/s, train_loss=0.00549, val_loss=0.00582]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 110.64it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 126.31it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 133.72it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 137.62it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 140.45it/s][A
                                                                       [AEpoch 12: 100%|██████████| 22/22 [00:00<00:00, 27.91it/s, train_loss=0.00549, val_loss=0.00555]Epoch 12: 100%|██████████| 22/22 [00:00<00:00, 27.88it/s, train_loss=0.00549, val_loss=0.00555]Epoch 12:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00549, val_loss=0.00555]         Epoch 13:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00549, val_loss=0.00555]Epoch 13:   5%|▍         | 1/22 [00:00<00:00, 71.71it/s, train_loss=0.00549, val_loss=0.00555]Epoch 13:   5%|▍         | 1/22 [00:00<00:00, 31.61it/s, train_loss=0.00538, val_loss=0.00555]Epoch 13:   9%|▉         | 2/22 [00:00<00:00, 43.65it/s, train_loss=0.00538, val_loss=0.00555]Epoch 13:   9%|▉         | 2/22 [00:00<00:00, 31.80it/s, train_loss=0.00577, val_loss=0.00555]Epoch 13:  14%|█▎        | 3/22 [00:00<00:00, 39.28it/s, train_loss=0.00577, val_loss=0.00555]Epoch 13:  14%|█▎        | 3/22 [00:00<00:00, 31.19it/s, train_loss=0.00548, val_loss=0.00555]Epoch 13:  18%|█▊        | 4/22 [00:00<00:00, 36.42it/s, train_loss=0.00548, val_loss=0.00555]Epoch 13:  18%|█▊        | 4/22 [00:00<00:00, 30.79it/s, train_loss=0.0057, val_loss=0.00555] Epoch 13:  23%|██▎       | 5/22 [00:00<00:00, 35.07it/s, train_loss=0.0057, val_loss=0.00555]Epoch 13:  23%|██▎       | 5/22 [00:00<00:00, 30.55it/s, train_loss=0.00582, val_loss=0.00555]Epoch 13:  27%|██▋       | 6/22 [00:00<00:00, 33.50it/s, train_loss=0.00582, val_loss=0.00555]Epoch 13:  27%|██▋       | 6/22 [00:00<00:00, 30.47it/s, train_loss=0.00494, val_loss=0.00555]Epoch 13:  32%|███▏      | 7/22 [00:00<00:00, 33.04it/s, train_loss=0.00494, val_loss=0.00555]Epoch 13:  32%|███▏      | 7/22 [00:00<00:00, 30.44it/s, train_loss=0.00515, val_loss=0.00555]Epoch 13:  36%|███▋      | 8/22 [00:00<00:00, 32.63it/s, train_loss=0.00515, val_loss=0.00555]Epoch 13:  36%|███▋      | 8/22 [00:00<00:00, 30.38it/s, train_loss=0.0054, val_loss=0.00555] Epoch 13:  41%|████      | 9/22 [00:00<00:00, 32.38it/s, train_loss=0.0054, val_loss=0.00555]Epoch 13:  41%|████      | 9/22 [00:00<00:00, 30.39it/s, train_loss=0.00564, val_loss=0.00555]Epoch 13:  45%|████▌     | 10/22 [00:00<00:00, 32.27it/s, train_loss=0.00564, val_loss=0.00555]Epoch 13:  45%|████▌     | 10/22 [00:00<00:00, 30.39it/s, train_loss=0.00546, val_loss=0.00555]Epoch 13:  50%|█████     | 11/22 [00:00<00:00, 32.03it/s, train_loss=0.00546, val_loss=0.00555]Epoch 13:  50%|█████     | 11/22 [00:00<00:00, 30.39it/s, train_loss=0.00547, val_loss=0.00555]Epoch 13:  55%|█████▍    | 12/22 [00:00<00:00, 31.91it/s, train_loss=0.00547, val_loss=0.00555]Epoch 13:  55%|█████▍    | 12/22 [00:00<00:00, 30.35it/s, train_loss=0.00544, val_loss=0.00555]Epoch 13:  59%|█████▉    | 13/22 [00:00<00:00, 31.74it/s, train_loss=0.00544, val_loss=0.00555]Epoch 13:  59%|█████▉    | 13/22 [00:00<00:00, 30.31it/s, train_loss=0.00615, val_loss=0.00555]Epoch 13:  64%|██████▎   | 14/22 [00:00<00:00, 31.60it/s, train_loss=0.00615, val_loss=0.00555]Epoch 13:  64%|██████▎   | 14/22 [00:00<00:00, 30.31it/s, train_loss=0.00566, val_loss=0.00555]Epoch 13:  68%|██████▊   | 15/22 [00:00<00:00, 31.50it/s, train_loss=0.00566, val_loss=0.00555]Epoch 13:  68%|██████▊   | 15/22 [00:00<00:00, 30.27it/s, train_loss=0.00514, val_loss=0.00555]Epoch 13:  73%|███████▎  | 16/22 [00:00<00:00, 31.38it/s, train_loss=0.00514, val_loss=0.00555]Epoch 13:  73%|███████▎  | 16/22 [00:00<00:00, 30.40it/s, train_loss=0.00525, val_loss=0.00555]Epoch 13:  77%|███████▋  | 17/22 [00:00<00:00, 31.43it/s, train_loss=0.00525, val_loss=0.00555]Epoch 13:  77%|███████▋  | 17/22 [00:00<00:00, 30.48it/s, train_loss=0.00568, val_loss=0.00555]Epoch 13:  82%|████████▏ | 18/22 [00:00<00:00, 31.44it/s, train_loss=0.00568, val_loss=0.00555]Epoch 13:  82%|████████▏ | 18/22 [00:00<00:00, 30.46it/s, train_loss=0.00526, val_loss=0.00555]Epoch 13:  86%|████████▋ | 19/22 [00:00<00:00, 31.38it/s, train_loss=0.00526, val_loss=0.00555]Epoch 13:  86%|████████▋ | 19/22 [00:00<00:00, 30.44it/s, train_loss=0.00505, val_loss=0.00555]Epoch 13:  91%|█████████ | 20/22 [00:00<00:00, 31.29it/s, train_loss=0.00505, val_loss=0.00555]Epoch 13:  91%|█████████ | 20/22 [00:00<00:00, 30.40it/s, train_loss=0.00585, val_loss=0.00555]Epoch 13:  95%|█████████▌| 21/22 [00:00<00:00, 31.18it/s, train_loss=0.00585, val_loss=0.00555]Epoch 13:  95%|█████████▌| 21/22 [00:00<00:00, 30.36it/s, train_loss=0.00506, val_loss=0.00555]Epoch 13: 100%|██████████| 22/22 [00:00<00:00, 31.16it/s, train_loss=0.00506, val_loss=0.00555]Epoch 13: 100%|██████████| 22/22 [00:00<00:00, 30.45it/s, train_loss=0.00514, val_loss=0.00555]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 107.87it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 120.78it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 121.70it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 125.81it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 128.41it/s][A
                                                                       [AEpoch 13: 100%|██████████| 22/22 [00:00<00:00, 28.01it/s, train_loss=0.00514, val_loss=0.00521]Epoch 13: 100%|██████████| 22/22 [00:00<00:00, 27.97it/s, train_loss=0.00514, val_loss=0.00521]Epoch 13:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00514, val_loss=0.00521]         Epoch 14:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00514, val_loss=0.00521]Epoch 14:   5%|▍         | 1/22 [00:00<00:00, 69.75it/s, train_loss=0.00514, val_loss=0.00521]Epoch 14:   5%|▍         | 1/22 [00:00<00:00, 32.38it/s, train_loss=0.00521, val_loss=0.00521]Epoch 14:   9%|▉         | 2/22 [00:00<00:00, 43.60it/s, train_loss=0.00521, val_loss=0.00521]Epoch 14:   9%|▉         | 2/22 [00:00<00:00, 32.14it/s, train_loss=0.0052, val_loss=0.00521] Epoch 14:  14%|█▎        | 3/22 [00:00<00:00, 39.10it/s, train_loss=0.0052, val_loss=0.00521]Epoch 14:  14%|█▎        | 3/22 [00:00<00:00, 31.44it/s, train_loss=0.00521, val_loss=0.00521]Epoch 14:  18%|█▊        | 4/22 [00:00<00:00, 36.36it/s, train_loss=0.00521, val_loss=0.00521]Epoch 14:  18%|█▊        | 4/22 [00:00<00:00, 31.17it/s, train_loss=0.00519, val_loss=0.00521]Epoch 14:  23%|██▎       | 5/22 [00:00<00:00, 35.19it/s, train_loss=0.00519, val_loss=0.00521]Epoch 14:  23%|██▎       | 5/22 [00:00<00:00, 30.95it/s, train_loss=0.00527, val_loss=0.00521]Epoch 14:  27%|██▋       | 6/22 [00:00<00:00, 34.21it/s, train_loss=0.00527, val_loss=0.00521]Epoch 14:  27%|██▋       | 6/22 [00:00<00:00, 30.79it/s, train_loss=0.00483, val_loss=0.00521]Epoch 14:  32%|███▏      | 7/22 [00:00<00:00, 33.53it/s, train_loss=0.00483, val_loss=0.00521]Epoch 14:  32%|███▏      | 7/22 [00:00<00:00, 30.68it/s, train_loss=0.0054, val_loss=0.00521] Epoch 14:  36%|███▋      | 8/22 [00:00<00:00, 33.01it/s, train_loss=0.0054, val_loss=0.00521]Epoch 14:  36%|███▋      | 8/22 [00:00<00:00, 30.56it/s, train_loss=0.00521, val_loss=0.00521]Epoch 14:  41%|████      | 9/22 [00:00<00:00, 32.20it/s, train_loss=0.00521, val_loss=0.00521]Epoch 14:  41%|████      | 9/22 [00:00<00:00, 30.41it/s, train_loss=0.00519, val_loss=0.00521]Epoch 14:  45%|████▌     | 10/22 [00:00<00:00, 32.09it/s, train_loss=0.00519, val_loss=0.00521]Epoch 14:  45%|████▌     | 10/22 [00:00<00:00, 30.39it/s, train_loss=0.00524, val_loss=0.00521]Epoch 14:  50%|█████     | 11/22 [00:00<00:00, 31.90it/s, train_loss=0.00524, val_loss=0.00521]Epoch 14:  50%|█████     | 11/22 [00:00<00:00, 30.36it/s, train_loss=0.00587, val_loss=0.00521]Epoch 14:  55%|█████▍    | 12/22 [00:00<00:00, 31.77it/s, train_loss=0.00587, val_loss=0.00521]Epoch 14:  55%|█████▍    | 12/22 [00:00<00:00, 30.34it/s, train_loss=0.00481, val_loss=0.00521]Epoch 14:  59%|█████▉    | 13/22 [00:00<00:00, 31.63it/s, train_loss=0.00481, val_loss=0.00521]Epoch 14:  59%|█████▉    | 13/22 [00:00<00:00, 30.33it/s, train_loss=0.00512, val_loss=0.00521]Epoch 14:  64%|██████▎   | 14/22 [00:00<00:00, 31.50it/s, train_loss=0.00512, val_loss=0.00521]Epoch 14:  64%|██████▎   | 14/22 [00:00<00:00, 30.32it/s, train_loss=0.00489, val_loss=0.00521]Epoch 14:  68%|██████▊   | 15/22 [00:00<00:00, 31.44it/s, train_loss=0.00489, val_loss=0.00521]Epoch 14:  68%|██████▊   | 15/22 [00:00<00:00, 30.29it/s, train_loss=0.00578, val_loss=0.00521]Epoch 14:  73%|███████▎  | 16/22 [00:00<00:00, 31.36it/s, train_loss=0.00578, val_loss=0.00521]Epoch 14:  73%|███████▎  | 16/22 [00:00<00:00, 30.28it/s, train_loss=0.0049, val_loss=0.00521] Epoch 14:  77%|███████▋  | 17/22 [00:00<00:00, 31.29it/s, train_loss=0.0049, val_loss=0.00521]Epoch 14:  77%|███████▋  | 17/22 [00:00<00:00, 30.27it/s, train_loss=0.005, val_loss=0.00521] Epoch 14:  82%|████████▏ | 18/22 [00:00<00:00, 31.22it/s, train_loss=0.005, val_loss=0.00521]Epoch 14:  82%|████████▏ | 18/22 [00:00<00:00, 30.25it/s, train_loss=0.00482, val_loss=0.00521]Epoch 14:  86%|████████▋ | 19/22 [00:00<00:00, 31.14it/s, train_loss=0.00482, val_loss=0.00521]Epoch 14:  86%|████████▋ | 19/22 [00:00<00:00, 30.24it/s, train_loss=0.00537, val_loss=0.00521]Epoch 14:  91%|█████████ | 20/22 [00:00<00:00, 31.16it/s, train_loss=0.00537, val_loss=0.00521]Epoch 14:  91%|█████████ | 20/22 [00:00<00:00, 30.24it/s, train_loss=0.00493, val_loss=0.00521]Epoch 14:  95%|█████████▌| 21/22 [00:00<00:00, 31.11it/s, train_loss=0.00493, val_loss=0.00521]Epoch 14:  95%|█████████▌| 21/22 [00:00<00:00, 30.23it/s, train_loss=0.00532, val_loss=0.00521]Epoch 14: 100%|██████████| 22/22 [00:00<00:00, 31.06it/s, train_loss=0.00532, val_loss=0.00521]Epoch 14: 100%|██████████| 22/22 [00:00<00:00, 30.33it/s, train_loss=0.00531, val_loss=0.00521]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 110.69it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 126.32it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 135.94it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 140.60it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 144.46it/s][A
                                                                       [AEpoch 14: 100%|██████████| 22/22 [00:00<00:00, 28.13it/s, train_loss=0.00531, val_loss=0.00508]Epoch 14: 100%|██████████| 22/22 [00:00<00:00, 28.10it/s, train_loss=0.00531, val_loss=0.00508]Epoch 14:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00531, val_loss=0.00508]         Epoch 15:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00531, val_loss=0.00508]Epoch 15:   5%|▍         | 1/22 [00:00<00:00, 62.96it/s, train_loss=0.00531, val_loss=0.00508]Epoch 15:   5%|▍         | 1/22 [00:00<00:00, 29.21it/s, train_loss=0.00537, val_loss=0.00508]Epoch 15:   9%|▉         | 2/22 [00:00<00:00, 40.27it/s, train_loss=0.00537, val_loss=0.00508]Epoch 15:   9%|▉         | 2/22 [00:00<00:00, 30.53it/s, train_loss=0.00504, val_loss=0.00508]Epoch 15:  14%|█▎        | 3/22 [00:00<00:00, 37.02it/s, train_loss=0.00504, val_loss=0.00508]Epoch 15:  14%|█▎        | 3/22 [00:00<00:00, 31.01it/s, train_loss=0.00491, val_loss=0.00508]Epoch 15:  18%|█▊        | 4/22 [00:00<00:00, 35.77it/s, train_loss=0.00491, val_loss=0.00508]Epoch 15:  18%|█▊        | 4/22 [00:00<00:00, 30.76it/s, train_loss=0.00486, val_loss=0.00508]Epoch 15:  23%|██▎       | 5/22 [00:00<00:00, 34.08it/s, train_loss=0.00486, val_loss=0.00508]Epoch 15:  23%|██▎       | 5/22 [00:00<00:00, 30.62it/s, train_loss=0.00474, val_loss=0.00508]Epoch 15:  27%|██▋       | 6/22 [00:00<00:00, 33.56it/s, train_loss=0.00474, val_loss=0.00508]Epoch 15:  27%|██▋       | 6/22 [00:00<00:00, 30.51it/s, train_loss=0.00489, val_loss=0.00508]Epoch 15:  32%|███▏      | 7/22 [00:00<00:00, 32.99it/s, train_loss=0.00489, val_loss=0.00508]Epoch 15:  32%|███▏      | 7/22 [00:00<00:00, 30.46it/s, train_loss=0.0045, val_loss=0.00508] Epoch 15:  36%|███▋      | 8/22 [00:00<00:00, 32.68it/s, train_loss=0.0045, val_loss=0.00508]Epoch 15:  36%|███▋      | 8/22 [00:00<00:00, 30.42it/s, train_loss=0.00501, val_loss=0.00508]Epoch 15:  41%|████      | 9/22 [00:00<00:00, 32.40it/s, train_loss=0.00501, val_loss=0.00508]Epoch 15:  41%|████      | 9/22 [00:00<00:00, 30.38it/s, train_loss=0.00498, val_loss=0.00508]Epoch 15:  45%|████▌     | 10/22 [00:00<00:00, 32.09it/s, train_loss=0.00498, val_loss=0.00508]Epoch 15:  45%|████▌     | 10/22 [00:00<00:00, 30.23it/s, train_loss=0.0057, val_loss=0.00508] Epoch 15:  50%|█████     | 11/22 [00:00<00:00, 31.79it/s, train_loss=0.0057, val_loss=0.00508]Epoch 15:  50%|█████     | 11/22 [00:00<00:00, 30.21it/s, train_loss=0.00538, val_loss=0.00508]Epoch 15:  55%|█████▍    | 12/22 [00:00<00:00, 31.80it/s, train_loss=0.00538, val_loss=0.00508]Epoch 15:  55%|█████▍    | 12/22 [00:00<00:00, 30.21it/s, train_loss=0.00495, val_loss=0.00508]Epoch 15:  59%|█████▉    | 13/22 [00:00<00:00, 31.64it/s, train_loss=0.00495, val_loss=0.00508]Epoch 15:  59%|█████▉    | 13/22 [00:00<00:00, 30.20it/s, train_loss=0.00482, val_loss=0.00508]Epoch 15:  64%|██████▎   | 14/22 [00:00<00:00, 31.52it/s, train_loss=0.00482, val_loss=0.00508]Epoch 15:  64%|██████▎   | 14/22 [00:00<00:00, 30.19it/s, train_loss=0.00494, val_loss=0.00508]Epoch 15:  68%|██████▊   | 15/22 [00:00<00:00, 31.41it/s, train_loss=0.00494, val_loss=0.00508]Epoch 15:  68%|██████▊   | 15/22 [00:00<00:00, 30.18it/s, train_loss=0.00463, val_loss=0.00508]Epoch 15:  73%|███████▎  | 16/22 [00:00<00:00, 31.30it/s, train_loss=0.00463, val_loss=0.00508]Epoch 15:  73%|███████▎  | 16/22 [00:00<00:00, 30.17it/s, train_loss=0.00471, val_loss=0.00508]Epoch 15:  77%|███████▋  | 17/22 [00:00<00:00, 31.23it/s, train_loss=0.00471, val_loss=0.00508]Epoch 15:  77%|███████▋  | 17/22 [00:00<00:00, 30.15it/s, train_loss=0.00473, val_loss=0.00508]Epoch 15:  82%|████████▏ | 18/22 [00:00<00:00, 31.16it/s, train_loss=0.00473, val_loss=0.00508]Epoch 15:  82%|████████▏ | 18/22 [00:00<00:00, 30.14it/s, train_loss=0.00505, val_loss=0.00508]Epoch 15:  86%|████████▋ | 19/22 [00:00<00:00, 31.09it/s, train_loss=0.00505, val_loss=0.00508]Epoch 15:  86%|████████▋ | 19/22 [00:00<00:00, 30.13it/s, train_loss=0.00475, val_loss=0.00508]Epoch 15:  91%|█████████ | 20/22 [00:00<00:00, 31.03it/s, train_loss=0.00475, val_loss=0.00508]Epoch 15:  91%|█████████ | 20/22 [00:00<00:00, 30.11it/s, train_loss=0.00488, val_loss=0.00508]Epoch 15:  95%|█████████▌| 21/22 [00:00<00:00, 30.96it/s, train_loss=0.00488, val_loss=0.00508]Epoch 15:  95%|█████████▌| 21/22 [00:00<00:00, 30.10it/s, train_loss=0.00486, val_loss=0.00508]Epoch 15: 100%|██████████| 22/22 [00:00<00:00, 30.94it/s, train_loss=0.00486, val_loss=0.00508]Epoch 15: 100%|██████████| 22/22 [00:00<00:00, 30.20it/s, train_loss=0.00492, val_loss=0.00508]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 101.70it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 118.69it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 126.59it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 130.64it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 131.32it/s][A
                                                                       [AEpoch 15: 100%|██████████| 22/22 [00:00<00:00, 27.84it/s, train_loss=0.00492, val_loss=0.00487]Epoch 15: 100%|██████████| 22/22 [00:00<00:00, 27.81it/s, train_loss=0.00492, val_loss=0.00487]Epoch 15:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00492, val_loss=0.00487]         Epoch 16:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00492, val_loss=0.00487]Epoch 16:   5%|▍         | 1/22 [00:00<00:00, 61.80it/s, train_loss=0.00492, val_loss=0.00487]Epoch 16:   5%|▍         | 1/22 [00:00<00:00, 31.38it/s, train_loss=0.00481, val_loss=0.00487]Epoch 16:   9%|▉         | 2/22 [00:00<00:00, 42.12it/s, train_loss=0.00481, val_loss=0.00487]Epoch 16:   9%|▉         | 2/22 [00:00<00:00, 31.65it/s, train_loss=0.00512, val_loss=0.00487]Epoch 16:  14%|█▎        | 3/22 [00:00<00:00, 38.02it/s, train_loss=0.00512, val_loss=0.00487]Epoch 16:  14%|█▎        | 3/22 [00:00<00:00, 31.12it/s, train_loss=0.0052, val_loss=0.00487] Epoch 16:  18%|█▊        | 4/22 [00:00<00:00, 36.05it/s, train_loss=0.0052, val_loss=0.00487]Epoch 16:  18%|█▊        | 4/22 [00:00<00:00, 30.99it/s, train_loss=0.00448, val_loss=0.00487]Epoch 16:  23%|██▎       | 5/22 [00:00<00:00, 34.99it/s, train_loss=0.00448, val_loss=0.00487]Epoch 16:  23%|██▎       | 5/22 [00:00<00:00, 30.88it/s, train_loss=0.00523, val_loss=0.00487]Epoch 16:  27%|██▋       | 6/22 [00:00<00:00, 34.12it/s, train_loss=0.00523, val_loss=0.00487]Epoch 16:  27%|██▋       | 6/22 [00:00<00:00, 30.78it/s, train_loss=0.00504, val_loss=0.00487]Epoch 16:  32%|███▏      | 7/22 [00:00<00:00, 33.41it/s, train_loss=0.00504, val_loss=0.00487]Epoch 16:  32%|███▏      | 7/22 [00:00<00:00, 30.68it/s, train_loss=0.00467, val_loss=0.00487]Epoch 16:  36%|███▋      | 8/22 [00:00<00:00, 32.95it/s, train_loss=0.00467, val_loss=0.00487]Epoch 16:  36%|███▋      | 8/22 [00:00<00:00, 30.58it/s, train_loss=0.00469, val_loss=0.00487]Epoch 16:  41%|████      | 9/22 [00:00<00:00, 32.63it/s, train_loss=0.00469, val_loss=0.00487]Epoch 16:  41%|████      | 9/22 [00:00<00:00, 30.52it/s, train_loss=0.00473, val_loss=0.00487]Epoch 16:  45%|████▌     | 10/22 [00:00<00:00, 32.36it/s, train_loss=0.00473, val_loss=0.00487]Epoch 16:  45%|████▌     | 10/22 [00:00<00:00, 30.47it/s, train_loss=0.00485, val_loss=0.00487]Epoch 16:  50%|█████     | 11/22 [00:00<00:00, 32.12it/s, train_loss=0.00485, val_loss=0.00487]Epoch 16:  50%|█████     | 11/22 [00:00<00:00, 30.39it/s, train_loss=0.00501, val_loss=0.00487]Epoch 16:  55%|█████▍    | 12/22 [00:00<00:00, 31.91it/s, train_loss=0.00501, val_loss=0.00487]Epoch 16:  55%|█████▍    | 12/22 [00:00<00:00, 30.33it/s, train_loss=0.00457, val_loss=0.00487]Epoch 16:  59%|█████▉    | 13/22 [00:00<00:00, 31.74it/s, train_loss=0.00457, val_loss=0.00487]Epoch 16:  59%|█████▉    | 13/22 [00:00<00:00, 30.27it/s, train_loss=0.00454, val_loss=0.00487]Epoch 16:  64%|██████▎   | 14/22 [00:00<00:00, 31.57it/s, train_loss=0.00454, val_loss=0.00487]Epoch 16:  64%|██████▎   | 14/22 [00:00<00:00, 30.25it/s, train_loss=0.00472, val_loss=0.00487]Epoch 16:  68%|██████▊   | 15/22 [00:00<00:00, 31.45it/s, train_loss=0.00472, val_loss=0.00487]Epoch 16:  68%|██████▊   | 15/22 [00:00<00:00, 30.23it/s, train_loss=0.00452, val_loss=0.00487]Epoch 16:  73%|███████▎  | 16/22 [00:00<00:00, 31.36it/s, train_loss=0.00452, val_loss=0.00487]Epoch 16:  73%|███████▎  | 16/22 [00:00<00:00, 30.22it/s, train_loss=0.00484, val_loss=0.00487]Epoch 16:  77%|███████▋  | 17/22 [00:00<00:00, 31.28it/s, train_loss=0.00484, val_loss=0.00487]Epoch 16:  77%|███████▋  | 17/22 [00:00<00:00, 30.20it/s, train_loss=0.00448, val_loss=0.00487]Epoch 16:  82%|████████▏ | 18/22 [00:00<00:00, 31.18it/s, train_loss=0.00448, val_loss=0.00487]Epoch 16:  82%|████████▏ | 18/22 [00:00<00:00, 30.18it/s, train_loss=0.00475, val_loss=0.00487]Epoch 16:  86%|████████▋ | 19/22 [00:00<00:00, 31.12it/s, train_loss=0.00475, val_loss=0.00487]Epoch 16:  86%|████████▋ | 19/22 [00:00<00:00, 30.16it/s, train_loss=0.00445, val_loss=0.00487]Epoch 16:  91%|█████████ | 20/22 [00:00<00:00, 31.06it/s, train_loss=0.00445, val_loss=0.00487]Epoch 16:  91%|█████████ | 20/22 [00:00<00:00, 30.15it/s, train_loss=0.00453, val_loss=0.00487]Epoch 16:  95%|█████████▌| 21/22 [00:00<00:00, 31.00it/s, train_loss=0.00453, val_loss=0.00487]Epoch 16:  95%|█████████▌| 21/22 [00:00<00:00, 30.14it/s, train_loss=0.0049, val_loss=0.00487] Epoch 16: 100%|██████████| 22/22 [00:00<00:00, 30.97it/s, train_loss=0.0049, val_loss=0.00487]Epoch 16: 100%|██████████| 22/22 [00:00<00:00, 30.23it/s, train_loss=0.00438, val_loss=0.00487]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 118.65it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 130.81it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 140.36it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 143.97it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 143.00it/s][A
                                                                       [AEpoch 16: 100%|██████████| 22/22 [00:00<00:00, 28.08it/s, train_loss=0.00438, val_loss=0.00467]Epoch 16: 100%|██████████| 22/22 [00:00<00:00, 28.04it/s, train_loss=0.00438, val_loss=0.00467]Epoch 16:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00438, val_loss=0.00467]         Epoch 17:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00438, val_loss=0.00467]Epoch 17:   5%|▍         | 1/22 [00:00<00:00, 59.64it/s, train_loss=0.00438, val_loss=0.00467]Epoch 17:   5%|▍         | 1/22 [00:00<00:00, 28.79it/s, train_loss=0.00474, val_loss=0.00467]Epoch 17:   9%|▉         | 2/22 [00:00<00:00, 40.82it/s, train_loss=0.00474, val_loss=0.00467]Epoch 17:   9%|▉         | 2/22 [00:00<00:00, 29.42it/s, train_loss=0.00477, val_loss=0.00467]Epoch 17:  14%|█▎        | 3/22 [00:00<00:00, 36.64it/s, train_loss=0.00477, val_loss=0.00467]Epoch 17:  14%|█▎        | 3/22 [00:00<00:00, 29.69it/s, train_loss=0.00473, val_loss=0.00467]Epoch 17:  18%|█▊        | 4/22 [00:00<00:00, 34.65it/s, train_loss=0.00473, val_loss=0.00467]Epoch 17:  18%|█▊        | 4/22 [00:00<00:00, 29.79it/s, train_loss=0.00466, val_loss=0.00467]Epoch 17:  23%|██▎       | 5/22 [00:00<00:00, 33.61it/s, train_loss=0.00466, val_loss=0.00467]Epoch 17:  23%|██▎       | 5/22 [00:00<00:00, 29.82it/s, train_loss=0.00456, val_loss=0.00467]Epoch 17:  27%|██▋       | 6/22 [00:00<00:00, 32.89it/s, train_loss=0.00456, val_loss=0.00467]Epoch 17:  27%|██▋       | 6/22 [00:00<00:00, 29.82it/s, train_loss=0.00491, val_loss=0.00467]Epoch 17:  32%|███▏      | 7/22 [00:00<00:00, 32.50it/s, train_loss=0.00491, val_loss=0.00467]Epoch 17:  32%|███▏      | 7/22 [00:00<00:00, 29.84it/s, train_loss=0.00443, val_loss=0.00467]Epoch 17:  36%|███▋      | 8/22 [00:00<00:00, 32.16it/s, train_loss=0.00443, val_loss=0.00467]Epoch 17:  36%|███▋      | 8/22 [00:00<00:00, 29.81it/s, train_loss=0.00476, val_loss=0.00467]Epoch 17:  41%|████      | 9/22 [00:00<00:00, 31.87it/s, train_loss=0.00476, val_loss=0.00467]Epoch 17:  41%|████      | 9/22 [00:00<00:00, 29.84it/s, train_loss=0.00447, val_loss=0.00467]Epoch 17:  45%|████▌     | 10/22 [00:00<00:00, 31.67it/s, train_loss=0.00447, val_loss=0.00467]Epoch 17:  45%|████▌     | 10/22 [00:00<00:00, 29.84it/s, train_loss=0.00457, val_loss=0.00467]Epoch 17:  50%|█████     | 11/22 [00:00<00:00, 31.40it/s, train_loss=0.00457, val_loss=0.00467]Epoch 17:  50%|█████     | 11/22 [00:00<00:00, 29.85it/s, train_loss=0.00454, val_loss=0.00467]Epoch 17:  55%|█████▍    | 12/22 [00:00<00:00, 31.31it/s, train_loss=0.00454, val_loss=0.00467]Epoch 17:  55%|█████▍    | 12/22 [00:00<00:00, 29.85it/s, train_loss=0.00482, val_loss=0.00467]Epoch 17:  59%|█████▉    | 13/22 [00:00<00:00, 31.17it/s, train_loss=0.00482, val_loss=0.00467]Epoch 17:  59%|█████▉    | 13/22 [00:00<00:00, 29.86it/s, train_loss=0.00477, val_loss=0.00467]Epoch 17:  64%|██████▎   | 14/22 [00:00<00:00, 31.15it/s, train_loss=0.00477, val_loss=0.00467]Epoch 17:  64%|██████▎   | 14/22 [00:00<00:00, 29.86it/s, train_loss=0.0043, val_loss=0.00467] Epoch 17:  68%|██████▊   | 15/22 [00:00<00:00, 31.00it/s, train_loss=0.0043, val_loss=0.00467]Epoch 17:  68%|██████▊   | 15/22 [00:00<00:00, 29.86it/s, train_loss=0.00457, val_loss=0.00467]Epoch 17:  73%|███████▎  | 16/22 [00:00<00:00, 30.92it/s, train_loss=0.00457, val_loss=0.00467]Epoch 17:  73%|███████▎  | 16/22 [00:00<00:00, 29.88it/s, train_loss=0.00438, val_loss=0.00467]Epoch 17:  77%|███████▋  | 17/22 [00:00<00:00, 30.93it/s, train_loss=0.00438, val_loss=0.00467]Epoch 17:  77%|███████▋  | 17/22 [00:00<00:00, 29.89it/s, train_loss=0.00456, val_loss=0.00467]Epoch 17:  82%|████████▏ | 18/22 [00:00<00:00, 30.88it/s, train_loss=0.00456, val_loss=0.00467]Epoch 17:  82%|████████▏ | 18/22 [00:00<00:00, 29.89it/s, train_loss=0.00431, val_loss=0.00467]Epoch 17:  86%|████████▋ | 19/22 [00:00<00:00, 30.83it/s, train_loss=0.00431, val_loss=0.00467]Epoch 17:  86%|████████▋ | 19/22 [00:00<00:00, 29.91it/s, train_loss=0.00447, val_loss=0.00467]Epoch 17:  91%|█████████ | 20/22 [00:00<00:00, 30.77it/s, train_loss=0.00447, val_loss=0.00467]Epoch 17:  91%|█████████ | 20/22 [00:00<00:00, 29.91it/s, train_loss=0.00448, val_loss=0.00467]Epoch 17:  95%|█████████▌| 21/22 [00:00<00:00, 30.76it/s, train_loss=0.00448, val_loss=0.00467]Epoch 17:  95%|█████████▌| 21/22 [00:00<00:00, 29.91it/s, train_loss=0.00464, val_loss=0.00467]Epoch 17: 100%|██████████| 22/22 [00:00<00:00, 30.73it/s, train_loss=0.00464, val_loss=0.00467]Epoch 17: 100%|██████████| 22/22 [00:00<00:00, 30.02it/s, train_loss=0.0041, val_loss=0.00467] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 105.36it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 121.23it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 128.23it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 131.83it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 134.31it/s][A
                                                                       [AEpoch 17: 100%|██████████| 22/22 [00:00<00:00, 27.74it/s, train_loss=0.0041, val_loss=0.00449]Epoch 17: 100%|██████████| 22/22 [00:00<00:00, 27.70it/s, train_loss=0.0041, val_loss=0.00449]Epoch 17:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0041, val_loss=0.00449]         Epoch 18:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0041, val_loss=0.00449]Epoch 18:   5%|▍         | 1/22 [00:00<00:00, 61.10it/s, train_loss=0.0041, val_loss=0.00449]Epoch 18:   5%|▍         | 1/22 [00:00<00:00, 31.09it/s, train_loss=0.00466, val_loss=0.00449]Epoch 18:   9%|▉         | 2/22 [00:00<00:00, 41.57it/s, train_loss=0.00466, val_loss=0.00449]Epoch 18:   9%|▉         | 2/22 [00:00<00:00, 31.23it/s, train_loss=0.0047, val_loss=0.00449] Epoch 18:  14%|█▎        | 3/22 [00:00<00:00, 37.57it/s, train_loss=0.0047, val_loss=0.00449]Epoch 18:  14%|█▎        | 3/22 [00:00<00:00, 30.92it/s, train_loss=0.00443, val_loss=0.00449]Epoch 18:  18%|█▊        | 4/22 [00:00<00:00, 35.50it/s, train_loss=0.00443, val_loss=0.00449]Epoch 18:  18%|█▊        | 4/22 [00:00<00:00, 30.73it/s, train_loss=0.00437, val_loss=0.00449]Epoch 18:  23%|██▎       | 5/22 [00:00<00:00, 34.43it/s, train_loss=0.00437, val_loss=0.00449]Epoch 18:  23%|██▎       | 5/22 [00:00<00:00, 30.60it/s, train_loss=0.00469, val_loss=0.00449]Epoch 18:  27%|██▋       | 6/22 [00:00<00:00, 33.59it/s, train_loss=0.00469, val_loss=0.00449]Epoch 18:  27%|██▋       | 6/22 [00:00<00:00, 30.48it/s, train_loss=0.00449, val_loss=0.00449]Epoch 18:  32%|███▏      | 7/22 [00:00<00:00, 33.30it/s, train_loss=0.00449, val_loss=0.00449]Epoch 18:  32%|███▏      | 7/22 [00:00<00:00, 30.45it/s, train_loss=0.00437, val_loss=0.00449]Epoch 18:  36%|███▋      | 8/22 [00:00<00:00, 32.82it/s, train_loss=0.00437, val_loss=0.00449]Epoch 18:  36%|███▋      | 8/22 [00:00<00:00, 30.39it/s, train_loss=0.00459, val_loss=0.00449]Epoch 18:  41%|████      | 9/22 [00:00<00:00, 32.45it/s, train_loss=0.00459, val_loss=0.00449]Epoch 18:  41%|████      | 9/22 [00:00<00:00, 30.37it/s, train_loss=0.00447, val_loss=0.00449]Epoch 18:  45%|████▌     | 10/22 [00:00<00:00, 32.21it/s, train_loss=0.00447, val_loss=0.00449]Epoch 18:  45%|████▌     | 10/22 [00:00<00:00, 30.34it/s, train_loss=0.00427, val_loss=0.00449]Epoch 18:  50%|█████     | 11/22 [00:00<00:00, 32.00it/s, train_loss=0.00427, val_loss=0.00449]Epoch 18:  50%|█████     | 11/22 [00:00<00:00, 30.30it/s, train_loss=0.00449, val_loss=0.00449]Epoch 18:  55%|█████▍    | 12/22 [00:00<00:00, 31.81it/s, train_loss=0.00449, val_loss=0.00449]Epoch 18:  55%|█████▍    | 12/22 [00:00<00:00, 30.28it/s, train_loss=0.00456, val_loss=0.00449]Epoch 18:  59%|█████▉    | 13/22 [00:00<00:00, 31.66it/s, train_loss=0.00456, val_loss=0.00449]Epoch 18:  59%|█████▉    | 13/22 [00:00<00:00, 30.25it/s, train_loss=0.00415, val_loss=0.00449]Epoch 18:  64%|██████▎   | 14/22 [00:00<00:00, 31.53it/s, train_loss=0.00415, val_loss=0.00449]Epoch 18:  64%|██████▎   | 14/22 [00:00<00:00, 30.24it/s, train_loss=0.00441, val_loss=0.00449]Epoch 18:  68%|██████▊   | 15/22 [00:00<00:00, 31.43it/s, train_loss=0.00441, val_loss=0.00449]Epoch 18:  68%|██████▊   | 15/22 [00:00<00:00, 30.22it/s, train_loss=0.0042, val_loss=0.00449] Epoch 18:  73%|███████▎  | 16/22 [00:00<00:00, 31.25it/s, train_loss=0.0042, val_loss=0.00449]Epoch 18:  73%|███████▎  | 16/22 [00:00<00:00, 30.21it/s, train_loss=0.00407, val_loss=0.00449]Epoch 18:  77%|███████▋  | 17/22 [00:00<00:00, 31.26it/s, train_loss=0.00407, val_loss=0.00449]Epoch 18:  77%|███████▋  | 17/22 [00:00<00:00, 30.20it/s, train_loss=0.00443, val_loss=0.00449]Epoch 18:  82%|████████▏ | 18/22 [00:00<00:00, 31.18it/s, train_loss=0.00443, val_loss=0.00449]Epoch 18:  82%|████████▏ | 18/22 [00:00<00:00, 30.20it/s, train_loss=0.00445, val_loss=0.00449]Epoch 18:  86%|████████▋ | 19/22 [00:00<00:00, 31.13it/s, train_loss=0.00445, val_loss=0.00449]Epoch 18:  86%|████████▋ | 19/22 [00:00<00:00, 30.19it/s, train_loss=0.00449, val_loss=0.00449]Epoch 18:  91%|█████████ | 20/22 [00:00<00:00, 31.07it/s, train_loss=0.00449, val_loss=0.00449]Epoch 18:  91%|█████████ | 20/22 [00:00<00:00, 30.18it/s, train_loss=0.0047, val_loss=0.00449] Epoch 18:  95%|█████████▌| 21/22 [00:00<00:00, 31.02it/s, train_loss=0.0047, val_loss=0.00449]Epoch 18:  95%|█████████▌| 21/22 [00:00<00:00, 30.16it/s, train_loss=0.0043, val_loss=0.00449]Epoch 18: 100%|██████████| 22/22 [00:00<00:00, 30.98it/s, train_loss=0.0043, val_loss=0.00449]Epoch 18: 100%|██████████| 22/22 [00:00<00:00, 30.25it/s, train_loss=0.00385, val_loss=0.00449]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 85.35it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 101.25it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 106.69it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 112.86it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 119.59it/s][A
                                                                       [AEpoch 18: 100%|██████████| 22/22 [00:00<00:00, 27.86it/s, train_loss=0.00385, val_loss=0.00442]Epoch 18: 100%|██████████| 22/22 [00:00<00:00, 27.83it/s, train_loss=0.00385, val_loss=0.00442]Epoch 18:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00385, val_loss=0.00442]         Epoch 19:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00385, val_loss=0.00442]Epoch 19:   5%|▍         | 1/22 [00:00<00:00, 63.13it/s, train_loss=0.00385, val_loss=0.00442]Epoch 19:   5%|▍         | 1/22 [00:00<00:00, 31.61it/s, train_loss=0.00471, val_loss=0.00442]Epoch 19:   9%|▉         | 2/22 [00:00<00:00, 43.18it/s, train_loss=0.00471, val_loss=0.00442]Epoch 19:   9%|▉         | 2/22 [00:00<00:00, 31.51it/s, train_loss=0.00404, val_loss=0.00442]Epoch 19:  14%|█▎        | 3/22 [00:00<00:00, 38.91it/s, train_loss=0.00404, val_loss=0.00442]Epoch 19:  14%|█▎        | 3/22 [00:00<00:00, 31.09it/s, train_loss=0.00436, val_loss=0.00442]Epoch 19:  18%|█▊        | 4/22 [00:00<00:00, 36.55it/s, train_loss=0.00436, val_loss=0.00442]Epoch 19:  18%|█▊        | 4/22 [00:00<00:00, 30.95it/s, train_loss=0.00413, val_loss=0.00442]Epoch 19:  23%|██▎       | 5/22 [00:00<00:00, 35.00it/s, train_loss=0.00413, val_loss=0.00442]Epoch 19:  23%|██▎       | 5/22 [00:00<00:00, 30.80it/s, train_loss=0.00455, val_loss=0.00442]Epoch 19:  27%|██▋       | 6/22 [00:00<00:00, 34.13it/s, train_loss=0.00455, val_loss=0.00442]Epoch 19:  27%|██▋       | 6/22 [00:00<00:00, 30.68it/s, train_loss=0.00448, val_loss=0.00442]Epoch 19:  32%|███▏      | 7/22 [00:00<00:00, 33.35it/s, train_loss=0.00448, val_loss=0.00442]Epoch 19:  32%|███▏      | 7/22 [00:00<00:00, 30.63it/s, train_loss=0.00439, val_loss=0.00442]Epoch 19:  36%|███▋      | 8/22 [00:00<00:00, 32.84it/s, train_loss=0.00439, val_loss=0.00442]Epoch 19:  36%|███▋      | 8/22 [00:00<00:00, 30.85it/s, train_loss=0.00442, val_loss=0.00442]Epoch 19:  41%|████      | 9/22 [00:00<00:00, 32.75it/s, train_loss=0.00442, val_loss=0.00442]Epoch 19:  41%|████      | 9/22 [00:00<00:00, 30.92it/s, train_loss=0.00418, val_loss=0.00442]Epoch 19:  45%|████▌     | 10/22 [00:00<00:00, 32.78it/s, train_loss=0.00418, val_loss=0.00442]Epoch 19:  45%|████▌     | 10/22 [00:00<00:00, 30.84it/s, train_loss=0.00397, val_loss=0.00442]Epoch 19:  50%|█████     | 11/22 [00:00<00:00, 32.56it/s, train_loss=0.00397, val_loss=0.00442]Epoch 19:  50%|█████     | 11/22 [00:00<00:00, 30.75it/s, train_loss=0.00435, val_loss=0.00442]Epoch 19:  55%|█████▍    | 12/22 [00:00<00:00, 32.35it/s, train_loss=0.00435, val_loss=0.00442]Epoch 19:  55%|█████▍    | 12/22 [00:00<00:00, 30.70it/s, train_loss=0.00416, val_loss=0.00442]Epoch 19:  59%|█████▉    | 13/22 [00:00<00:00, 32.14it/s, train_loss=0.00416, val_loss=0.00442]Epoch 19:  59%|█████▉    | 13/22 [00:00<00:00, 30.66it/s, train_loss=0.00424, val_loss=0.00442]Epoch 19:  64%|██████▎   | 14/22 [00:00<00:00, 31.90it/s, train_loss=0.00424, val_loss=0.00442]Epoch 19:  64%|██████▎   | 14/22 [00:00<00:00, 30.63it/s, train_loss=0.00462, val_loss=0.00442]Epoch 19:  68%|██████▊   | 15/22 [00:00<00:00, 31.72it/s, train_loss=0.00462, val_loss=0.00442]Epoch 19:  68%|██████▊   | 15/22 [00:00<00:00, 30.52it/s, train_loss=0.0042, val_loss=0.00442] Epoch 19:  73%|███████▎  | 16/22 [00:00<00:00, 31.65it/s, train_loss=0.0042, val_loss=0.00442]Epoch 19:  73%|███████▎  | 16/22 [00:00<00:00, 30.49it/s, train_loss=0.00435, val_loss=0.00442]Epoch 19:  77%|███████▋  | 17/22 [00:00<00:00, 31.60it/s, train_loss=0.00435, val_loss=0.00442]Epoch 19:  77%|███████▋  | 17/22 [00:00<00:00, 30.48it/s, train_loss=0.00418, val_loss=0.00442]Epoch 19:  82%|████████▏ | 18/22 [00:00<00:00, 31.52it/s, train_loss=0.00418, val_loss=0.00442]Epoch 19:  82%|████████▏ | 18/22 [00:00<00:00, 30.45it/s, train_loss=0.00447, val_loss=0.00442]Epoch 19:  86%|████████▋ | 19/22 [00:00<00:00, 31.44it/s, train_loss=0.00447, val_loss=0.00442]Epoch 19:  86%|████████▋ | 19/22 [00:00<00:00, 30.46it/s, train_loss=0.00432, val_loss=0.00442]Epoch 19:  91%|█████████ | 20/22 [00:00<00:00, 31.37it/s, train_loss=0.00432, val_loss=0.00442]Epoch 19:  91%|█████████ | 20/22 [00:00<00:00, 30.46it/s, train_loss=0.00407, val_loss=0.00442]Epoch 19:  95%|█████████▌| 21/22 [00:00<00:00, 31.28it/s, train_loss=0.00407, val_loss=0.00442]Epoch 19:  95%|█████████▌| 21/22 [00:00<00:00, 30.55it/s, train_loss=0.00443, val_loss=0.00442]Epoch 19: 100%|██████████| 22/22 [00:00<00:00, 31.33it/s, train_loss=0.00443, val_loss=0.00442]Epoch 19: 100%|██████████| 22/22 [00:00<00:00, 30.69it/s, train_loss=0.00419, val_loss=0.00442]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 113.17it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 129.87it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 137.46it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 141.82it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 144.49it/s][A
                                                                       [AEpoch 19: 100%|██████████| 22/22 [00:00<00:00, 28.35it/s, train_loss=0.00419, val_loss=0.00426]Epoch 19: 100%|██████████| 22/22 [00:00<00:00, 28.32it/s, train_loss=0.00419, val_loss=0.00426]Epoch 19:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00419, val_loss=0.00426]         Epoch 20:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00419, val_loss=0.00426]Epoch 20:   5%|▍         | 1/22 [00:00<00:00, 63.98it/s, train_loss=0.00419, val_loss=0.00426]Epoch 20:   5%|▍         | 1/22 [00:00<00:00, 31.60it/s, train_loss=0.00413, val_loss=0.00426]Epoch 20:   9%|▉         | 2/22 [00:00<00:00, 42.98it/s, train_loss=0.00413, val_loss=0.00426]Epoch 20:   9%|▉         | 2/22 [00:00<00:00, 31.79it/s, train_loss=0.00417, val_loss=0.00426]Epoch 20:  14%|█▎        | 3/22 [00:00<00:00, 38.95it/s, train_loss=0.00417, val_loss=0.00426]Epoch 20:  14%|█▎        | 3/22 [00:00<00:00, 31.16it/s, train_loss=0.00426, val_loss=0.00426]Epoch 20:  18%|█▊        | 4/22 [00:00<00:00, 36.32it/s, train_loss=0.00426, val_loss=0.00426]Epoch 20:  18%|█▊        | 4/22 [00:00<00:00, 30.91it/s, train_loss=0.00426, val_loss=0.00426]Epoch 20:  23%|██▎       | 5/22 [00:00<00:00, 35.06it/s, train_loss=0.00426, val_loss=0.00426]Epoch 20:  23%|██▎       | 5/22 [00:00<00:00, 30.74it/s, train_loss=0.00442, val_loss=0.00426]Epoch 20:  27%|██▋       | 6/22 [00:00<00:00, 34.05it/s, train_loss=0.00442, val_loss=0.00426]Epoch 20:  27%|██▋       | 6/22 [00:00<00:00, 30.63it/s, train_loss=0.00427, val_loss=0.00426]Epoch 20:  32%|███▏      | 7/22 [00:00<00:00, 33.46it/s, train_loss=0.00427, val_loss=0.00426]Epoch 20:  32%|███▏      | 7/22 [00:00<00:00, 30.57it/s, train_loss=0.00421, val_loss=0.00426]Epoch 20:  36%|███▋      | 8/22 [00:00<00:00, 33.18it/s, train_loss=0.00421, val_loss=0.00426]Epoch 20:  36%|███▋      | 8/22 [00:00<00:00, 30.49it/s, train_loss=0.0041, val_loss=0.00426] Epoch 20:  41%|████      | 9/22 [00:00<00:00, 32.82it/s, train_loss=0.0041, val_loss=0.00426]Epoch 20:  41%|████      | 9/22 [00:00<00:00, 30.43it/s, train_loss=0.00416, val_loss=0.00426]Epoch 20:  45%|████▌     | 10/22 [00:00<00:00, 32.55it/s, train_loss=0.00416, val_loss=0.00426]Epoch 20:  45%|████▌     | 10/22 [00:00<00:00, 30.37it/s, train_loss=0.00429, val_loss=0.00426]Epoch 20:  50%|█████     | 11/22 [00:00<00:00, 32.33it/s, train_loss=0.00429, val_loss=0.00426]Epoch 20:  50%|█████     | 11/22 [00:00<00:00, 30.38it/s, train_loss=0.00407, val_loss=0.00426]Epoch 20:  55%|█████▍    | 12/22 [00:00<00:00, 32.16it/s, train_loss=0.00407, val_loss=0.00426]Epoch 20:  55%|█████▍    | 12/22 [00:00<00:00, 30.38it/s, train_loss=0.00427, val_loss=0.00426]Epoch 20:  59%|█████▉    | 13/22 [00:00<00:00, 31.87it/s, train_loss=0.00427, val_loss=0.00426]Epoch 20:  59%|█████▉    | 13/22 [00:00<00:00, 30.33it/s, train_loss=0.0043, val_loss=0.00426] Epoch 20:  64%|██████▎   | 14/22 [00:00<00:00, 31.70it/s, train_loss=0.0043, val_loss=0.00426]Epoch 20:  64%|██████▎   | 14/22 [00:00<00:00, 30.30it/s, train_loss=0.00436, val_loss=0.00426]Epoch 20:  68%|██████▊   | 15/22 [00:00<00:00, 31.56it/s, train_loss=0.00436, val_loss=0.00426]Epoch 20:  68%|██████▊   | 15/22 [00:00<00:00, 30.26it/s, train_loss=0.00411, val_loss=0.00426]Epoch 20:  73%|███████▎  | 16/22 [00:00<00:00, 31.44it/s, train_loss=0.00411, val_loss=0.00426]Epoch 20:  73%|███████▎  | 16/22 [00:00<00:00, 30.22it/s, train_loss=0.00427, val_loss=0.00426]Epoch 20:  77%|███████▋  | 17/22 [00:00<00:00, 31.31it/s, train_loss=0.00427, val_loss=0.00426]Epoch 20:  77%|███████▋  | 17/22 [00:00<00:00, 30.19it/s, train_loss=0.00404, val_loss=0.00426]Epoch 20:  82%|████████▏ | 18/22 [00:00<00:00, 31.24it/s, train_loss=0.00404, val_loss=0.00426]Epoch 20:  82%|████████▏ | 18/22 [00:00<00:00, 30.16it/s, train_loss=0.00395, val_loss=0.00426]Epoch 20:  86%|████████▋ | 19/22 [00:00<00:00, 31.20it/s, train_loss=0.00395, val_loss=0.00426]Epoch 20:  86%|████████▋ | 19/22 [00:00<00:00, 30.14it/s, train_loss=0.00413, val_loss=0.00426]Epoch 20:  91%|█████████ | 20/22 [00:00<00:00, 31.12it/s, train_loss=0.00413, val_loss=0.00426]Epoch 20:  91%|█████████ | 20/22 [00:00<00:00, 30.12it/s, train_loss=0.00417, val_loss=0.00426]Epoch 20:  95%|█████████▌| 21/22 [00:00<00:00, 31.06it/s, train_loss=0.00417, val_loss=0.00426]Epoch 20:  95%|█████████▌| 21/22 [00:00<00:00, 30.11it/s, train_loss=0.00415, val_loss=0.00426]Epoch 20: 100%|██████████| 22/22 [00:00<00:00, 31.02it/s, train_loss=0.00415, val_loss=0.00426]Epoch 20: 100%|██████████| 22/22 [00:00<00:00, 30.20it/s, train_loss=0.00389, val_loss=0.00426]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 96.65it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 113.80it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 113.90it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 119.74it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 122.32it/s][A
                                                                       [AEpoch 20: 100%|██████████| 22/22 [00:00<00:00, 27.77it/s, train_loss=0.00389, val_loss=0.00417]Epoch 20: 100%|██████████| 22/22 [00:00<00:00, 27.73it/s, train_loss=0.00389, val_loss=0.00417]Epoch 20:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00389, val_loss=0.00417]         Epoch 21:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00389, val_loss=0.00417]Epoch 21:   5%|▍         | 1/22 [00:00<00:00, 73.21it/s, train_loss=0.00389, val_loss=0.00417]Epoch 21:   5%|▍         | 1/22 [00:00<00:00, 29.32it/s, train_loss=0.00397, val_loss=0.00417]Epoch 21:   9%|▉         | 2/22 [00:00<00:00, 43.68it/s, train_loss=0.00397, val_loss=0.00417]Epoch 21:   9%|▉         | 2/22 [00:00<00:00, 30.73it/s, train_loss=0.00398, val_loss=0.00417]Epoch 21:  14%|█▎        | 3/22 [00:00<00:00, 38.89it/s, train_loss=0.00398, val_loss=0.00417]Epoch 21:  14%|█▎        | 3/22 [00:00<00:00, 31.04it/s, train_loss=0.00384, val_loss=0.00417]Epoch 21:  18%|█▊        | 4/22 [00:00<00:00, 36.81it/s, train_loss=0.00384, val_loss=0.00417]Epoch 21:  18%|█▊        | 4/22 [00:00<00:00, 30.89it/s, train_loss=0.00418, val_loss=0.00417]Epoch 21:  23%|██▎       | 5/22 [00:00<00:00, 35.45it/s, train_loss=0.00418, val_loss=0.00417]Epoch 21:  23%|██▎       | 5/22 [00:00<00:00, 30.73it/s, train_loss=0.00402, val_loss=0.00417]Epoch 21:  27%|██▋       | 6/22 [00:00<00:00, 34.37it/s, train_loss=0.00402, val_loss=0.00417]Epoch 21:  27%|██▋       | 6/22 [00:00<00:00, 30.58it/s, train_loss=0.00403, val_loss=0.00417]Epoch 21:  32%|███▏      | 7/22 [00:00<00:00, 33.13it/s, train_loss=0.00403, val_loss=0.00417]Epoch 21:  32%|███▏      | 7/22 [00:00<00:00, 30.44it/s, train_loss=0.00396, val_loss=0.00417]Epoch 21:  36%|███▋      | 8/22 [00:00<00:00, 32.73it/s, train_loss=0.00396, val_loss=0.00417]Epoch 21:  36%|███▋      | 8/22 [00:00<00:00, 30.36it/s, train_loss=0.00406, val_loss=0.00417]Epoch 21:  41%|████      | 9/22 [00:00<00:00, 32.56it/s, train_loss=0.00406, val_loss=0.00417]Epoch 21:  41%|████      | 9/22 [00:00<00:00, 30.28it/s, train_loss=0.00422, val_loss=0.00417]Epoch 21:  45%|████▌     | 10/22 [00:00<00:00, 32.23it/s, train_loss=0.00422, val_loss=0.00417]Epoch 21:  45%|████▌     | 10/22 [00:00<00:00, 30.22it/s, train_loss=0.00434, val_loss=0.00417]Epoch 21:  50%|█████     | 11/22 [00:00<00:00, 31.95it/s, train_loss=0.00434, val_loss=0.00417]Epoch 21:  50%|█████     | 11/22 [00:00<00:00, 30.18it/s, train_loss=0.00404, val_loss=0.00417]Epoch 21:  55%|█████▍    | 12/22 [00:00<00:00, 31.76it/s, train_loss=0.00404, val_loss=0.00417]Epoch 21:  55%|█████▍    | 12/22 [00:00<00:00, 30.10it/s, train_loss=0.00387, val_loss=0.00417]Epoch 21:  59%|█████▉    | 13/22 [00:00<00:00, 31.62it/s, train_loss=0.00387, val_loss=0.00417]Epoch 21:  59%|█████▉    | 13/22 [00:00<00:00, 30.10it/s, train_loss=0.00412, val_loss=0.00417]Epoch 21:  64%|██████▎   | 14/22 [00:00<00:00, 31.35it/s, train_loss=0.00412, val_loss=0.00417]Epoch 21:  64%|██████▎   | 14/22 [00:00<00:00, 30.05it/s, train_loss=0.00409, val_loss=0.00417]Epoch 21:  68%|██████▊   | 15/22 [00:00<00:00, 31.28it/s, train_loss=0.00409, val_loss=0.00417]Epoch 21:  68%|██████▊   | 15/22 [00:00<00:00, 30.03it/s, train_loss=0.00405, val_loss=0.00417]Epoch 21:  73%|███████▎  | 16/22 [00:00<00:00, 31.16it/s, train_loss=0.00405, val_loss=0.00417]Epoch 21:  73%|███████▎  | 16/22 [00:00<00:00, 30.01it/s, train_loss=0.00423, val_loss=0.00417]Epoch 21:  77%|███████▋  | 17/22 [00:00<00:00, 31.06it/s, train_loss=0.00423, val_loss=0.00417]Epoch 21:  77%|███████▋  | 17/22 [00:00<00:00, 30.01it/s, train_loss=0.00386, val_loss=0.00417]Epoch 21:  82%|████████▏ | 18/22 [00:00<00:00, 31.02it/s, train_loss=0.00386, val_loss=0.00417]Epoch 21:  82%|████████▏ | 18/22 [00:00<00:00, 29.99it/s, train_loss=0.00443, val_loss=0.00417]Epoch 21:  86%|████████▋ | 19/22 [00:00<00:00, 30.93it/s, train_loss=0.00443, val_loss=0.00417]Epoch 21:  86%|████████▋ | 19/22 [00:00<00:00, 29.97it/s, train_loss=0.00429, val_loss=0.00417]Epoch 21:  91%|█████████ | 20/22 [00:00<00:00, 30.88it/s, train_loss=0.00429, val_loss=0.00417]Epoch 21:  91%|█████████ | 20/22 [00:00<00:00, 29.97it/s, train_loss=0.00419, val_loss=0.00417]Epoch 21:  95%|█████████▌| 21/22 [00:00<00:00, 30.80it/s, train_loss=0.00419, val_loss=0.00417]Epoch 21:  95%|█████████▌| 21/22 [00:00<00:00, 29.96it/s, train_loss=0.00419, val_loss=0.00417]Epoch 21: 100%|██████████| 22/22 [00:00<00:00, 30.87it/s, train_loss=0.00419, val_loss=0.00417]Epoch 21: 100%|██████████| 22/22 [00:00<00:00, 30.07it/s, train_loss=0.00412, val_loss=0.00417]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 116.47it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 129.97it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 138.94it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 143.65it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 146.53it/s][A
                                                                       [AEpoch 21: 100%|██████████| 22/22 [00:00<00:00, 27.92it/s, train_loss=0.00412, val_loss=0.0041] Epoch 21: 100%|██████████| 22/22 [00:00<00:00, 27.89it/s, train_loss=0.00412, val_loss=0.0041]Epoch 21:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00412, val_loss=0.0041]         Epoch 22:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00412, val_loss=0.0041]Epoch 22:   5%|▍         | 1/22 [00:00<00:00, 70.58it/s, train_loss=0.00412, val_loss=0.0041]Epoch 22:   5%|▍         | 1/22 [00:00<00:00, 29.15it/s, train_loss=0.004, val_loss=0.0041]  Epoch 22:   9%|▉         | 2/22 [00:00<00:00, 41.65it/s, train_loss=0.004, val_loss=0.0041]Epoch 22:   9%|▉         | 2/22 [00:00<00:00, 30.45it/s, train_loss=0.0041, val_loss=0.0041]Epoch 22:  14%|█▎        | 3/22 [00:00<00:00, 37.53it/s, train_loss=0.0041, val_loss=0.0041]Epoch 22:  14%|█▎        | 3/22 [00:00<00:00, 30.94it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  18%|█▊        | 4/22 [00:00<00:00, 36.62it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  18%|█▊        | 4/22 [00:00<00:00, 30.70it/s, train_loss=0.00421, val_loss=0.0041]Epoch 22:  23%|██▎       | 5/22 [00:00<00:00, 34.89it/s, train_loss=0.00421, val_loss=0.0041]Epoch 22:  23%|██▎       | 5/22 [00:00<00:00, 30.48it/s, train_loss=0.00396, val_loss=0.0041]Epoch 22:  27%|██▋       | 6/22 [00:00<00:00, 34.01it/s, train_loss=0.00396, val_loss=0.0041]Epoch 22:  27%|██▋       | 6/22 [00:00<00:00, 30.40it/s, train_loss=0.00407, val_loss=0.0041]Epoch 22:  32%|███▏      | 7/22 [00:00<00:00, 33.36it/s, train_loss=0.00407, val_loss=0.0041]Epoch 22:  32%|███▏      | 7/22 [00:00<00:00, 30.36it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  36%|███▋      | 8/22 [00:00<00:00, 32.91it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  36%|███▋      | 8/22 [00:00<00:00, 30.28it/s, train_loss=0.00389, val_loss=0.0041]Epoch 22:  41%|████      | 9/22 [00:00<00:00, 32.51it/s, train_loss=0.00389, val_loss=0.0041]Epoch 22:  41%|████      | 9/22 [00:00<00:00, 30.24it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  45%|████▌     | 10/22 [00:00<00:00, 32.23it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  45%|████▌     | 10/22 [00:00<00:00, 30.19it/s, train_loss=0.00423, val_loss=0.0041]Epoch 22:  50%|█████     | 11/22 [00:00<00:00, 31.97it/s, train_loss=0.00423, val_loss=0.0041]Epoch 22:  50%|█████     | 11/22 [00:00<00:00, 30.16it/s, train_loss=0.00393, val_loss=0.0041]Epoch 22:  55%|█████▍    | 12/22 [00:00<00:00, 31.84it/s, train_loss=0.00393, val_loss=0.0041]Epoch 22:  55%|█████▍    | 12/22 [00:00<00:00, 30.12it/s, train_loss=0.00393, val_loss=0.0041]Epoch 22:  59%|█████▉    | 13/22 [00:00<00:00, 31.62it/s, train_loss=0.00393, val_loss=0.0041]Epoch 22:  59%|█████▉    | 13/22 [00:00<00:00, 30.09it/s, train_loss=0.00405, val_loss=0.0041]Epoch 22:  64%|██████▎   | 14/22 [00:00<00:00, 31.57it/s, train_loss=0.00405, val_loss=0.0041]Epoch 22:  64%|██████▎   | 14/22 [00:00<00:00, 30.09it/s, train_loss=0.0039, val_loss=0.0041] Epoch 22:  68%|██████▊   | 15/22 [00:00<00:00, 31.45it/s, train_loss=0.0039, val_loss=0.0041]Epoch 22:  68%|██████▊   | 15/22 [00:00<00:00, 30.10it/s, train_loss=0.00407, val_loss=0.0041]Epoch 22:  73%|███████▎  | 16/22 [00:00<00:00, 31.36it/s, train_loss=0.00407, val_loss=0.0041]Epoch 22:  73%|███████▎  | 16/22 [00:00<00:00, 30.08it/s, train_loss=0.00418, val_loss=0.0041]Epoch 22:  77%|███████▋  | 17/22 [00:00<00:00, 31.25it/s, train_loss=0.00418, val_loss=0.0041]Epoch 22:  77%|███████▋  | 17/22 [00:00<00:00, 30.05it/s, train_loss=0.00401, val_loss=0.0041]Epoch 22:  82%|████████▏ | 18/22 [00:00<00:00, 31.16it/s, train_loss=0.00401, val_loss=0.0041]Epoch 22:  82%|████████▏ | 18/22 [00:00<00:00, 30.05it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  86%|████████▋ | 19/22 [00:00<00:00, 31.07it/s, train_loss=0.00397, val_loss=0.0041]Epoch 22:  86%|████████▋ | 19/22 [00:00<00:00, 30.02it/s, train_loss=0.00381, val_loss=0.0041]Epoch 22:  91%|█████████ | 20/22 [00:00<00:00, 31.01it/s, train_loss=0.00381, val_loss=0.0041]Epoch 22:  91%|█████████ | 20/22 [00:00<00:00, 30.01it/s, train_loss=0.00393, val_loss=0.0041]Epoch 22:  95%|█████████▌| 21/22 [00:00<00:00, 30.91it/s, train_loss=0.00393, val_loss=0.0041]Epoch 22:  95%|█████████▌| 21/22 [00:00<00:00, 30.00it/s, train_loss=0.0038, val_loss=0.0041] Epoch 22: 100%|██████████| 22/22 [00:00<00:00, 30.89it/s, train_loss=0.0038, val_loss=0.0041]Epoch 22: 100%|██████████| 22/22 [00:00<00:00, 30.10it/s, train_loss=0.00393, val_loss=0.0041]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 100.96it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 119.87it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 128.40it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 132.67it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 135.82it/s][A
                                                                       [AEpoch 22: 100%|██████████| 22/22 [00:00<00:00, 27.76it/s, train_loss=0.00393, val_loss=0.004] Epoch 22: 100%|██████████| 22/22 [00:00<00:00, 27.73it/s, train_loss=0.00393, val_loss=0.004]Epoch 22:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00393, val_loss=0.004]         Epoch 23:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00393, val_loss=0.004]Epoch 23:   5%|▍         | 1/22 [00:00<00:00, 67.48it/s, train_loss=0.00393, val_loss=0.004]Epoch 23:   5%|▍         | 1/22 [00:00<00:00, 31.01it/s, train_loss=0.00385, val_loss=0.004]Epoch 23:   9%|▉         | 2/22 [00:00<00:00, 42.55it/s, train_loss=0.00385, val_loss=0.004]Epoch 23:   9%|▉         | 2/22 [00:00<00:00, 31.31it/s, train_loss=0.00419, val_loss=0.004]Epoch 23:  14%|█▎        | 3/22 [00:00<00:00, 38.56it/s, train_loss=0.00419, val_loss=0.004]Epoch 23:  14%|█▎        | 3/22 [00:00<00:00, 30.83it/s, train_loss=0.00384, val_loss=0.004]Epoch 23:  18%|█▊        | 4/22 [00:00<00:00, 35.98it/s, train_loss=0.00384, val_loss=0.004]Epoch 23:  18%|█▊        | 4/22 [00:00<00:00, 30.60it/s, train_loss=0.00383, val_loss=0.004]Epoch 23:  23%|██▎       | 5/22 [00:00<00:00, 34.57it/s, train_loss=0.00383, val_loss=0.004]Epoch 23:  23%|██▎       | 5/22 [00:00<00:00, 30.38it/s, train_loss=0.00376, val_loss=0.004]Epoch 23:  27%|██▋       | 6/22 [00:00<00:00, 33.95it/s, train_loss=0.00376, val_loss=0.004]Epoch 23:  27%|██▋       | 6/22 [00:00<00:00, 30.34it/s, train_loss=0.00412, val_loss=0.004]Epoch 23:  32%|███▏      | 7/22 [00:00<00:00, 33.34it/s, train_loss=0.00412, val_loss=0.004]Epoch 23:  32%|███▏      | 7/22 [00:00<00:00, 30.30it/s, train_loss=0.00391, val_loss=0.004]Epoch 23:  36%|███▋      | 8/22 [00:00<00:00, 32.97it/s, train_loss=0.00391, val_loss=0.004]Epoch 23:  36%|███▋      | 8/22 [00:00<00:00, 30.28it/s, train_loss=0.00412, val_loss=0.004]Epoch 23:  41%|████      | 9/22 [00:00<00:00, 32.60it/s, train_loss=0.00412, val_loss=0.004]Epoch 23:  41%|████      | 9/22 [00:00<00:00, 30.26it/s, train_loss=0.00402, val_loss=0.004]Epoch 23:  45%|████▌     | 10/22 [00:00<00:00, 32.33it/s, train_loss=0.00402, val_loss=0.004]Epoch 23:  45%|████▌     | 10/22 [00:00<00:00, 30.25it/s, train_loss=0.00408, val_loss=0.004]Epoch 23:  50%|█████     | 11/22 [00:00<00:00, 32.01it/s, train_loss=0.00408, val_loss=0.004]Epoch 23:  50%|█████     | 11/22 [00:00<00:00, 30.14it/s, train_loss=0.00417, val_loss=0.004]Epoch 23:  55%|█████▍    | 12/22 [00:00<00:00, 31.84it/s, train_loss=0.00417, val_loss=0.004]Epoch 23:  55%|█████▍    | 12/22 [00:00<00:00, 30.13it/s, train_loss=0.00415, val_loss=0.004]Epoch 23:  59%|█████▉    | 13/22 [00:00<00:00, 31.68it/s, train_loss=0.00415, val_loss=0.004]Epoch 23:  59%|█████▉    | 13/22 [00:00<00:00, 30.11it/s, train_loss=0.00366, val_loss=0.004]Epoch 23:  64%|██████▎   | 14/22 [00:00<00:00, 31.56it/s, train_loss=0.00366, val_loss=0.004]Epoch 23:  64%|██████▎   | 14/22 [00:00<00:00, 30.09it/s, train_loss=0.00401, val_loss=0.004]Epoch 23:  68%|██████▊   | 15/22 [00:00<00:00, 31.43it/s, train_loss=0.00401, val_loss=0.004]Epoch 23:  68%|██████▊   | 15/22 [00:00<00:00, 30.09it/s, train_loss=0.00369, val_loss=0.004]Epoch 23:  73%|███████▎  | 16/22 [00:00<00:00, 31.29it/s, train_loss=0.00369, val_loss=0.004]Epoch 23:  73%|███████▎  | 16/22 [00:00<00:00, 30.05it/s, train_loss=0.00396, val_loss=0.004]Epoch 23:  77%|███████▋  | 17/22 [00:00<00:00, 31.23it/s, train_loss=0.00396, val_loss=0.004]Epoch 23:  77%|███████▋  | 17/22 [00:00<00:00, 30.05it/s, train_loss=0.00394, val_loss=0.004]Epoch 23:  82%|████████▏ | 18/22 [00:00<00:00, 31.16it/s, train_loss=0.00394, val_loss=0.004]Epoch 23:  82%|████████▏ | 18/22 [00:00<00:00, 30.04it/s, train_loss=0.00376, val_loss=0.004]Epoch 23:  86%|████████▋ | 19/22 [00:00<00:00, 31.08it/s, train_loss=0.00376, val_loss=0.004]Epoch 23:  86%|████████▋ | 19/22 [00:00<00:00, 30.02it/s, train_loss=0.00376, val_loss=0.004]Epoch 23:  91%|█████████ | 20/22 [00:00<00:00, 31.01it/s, train_loss=0.00376, val_loss=0.004]Epoch 23:  91%|█████████ | 20/22 [00:00<00:00, 30.01it/s, train_loss=0.00367, val_loss=0.004]Epoch 23:  95%|█████████▌| 21/22 [00:00<00:00, 30.96it/s, train_loss=0.00367, val_loss=0.004]Epoch 23:  95%|█████████▌| 21/22 [00:00<00:00, 30.02it/s, train_loss=0.00384, val_loss=0.004]Epoch 23: 100%|██████████| 22/22 [00:00<00:00, 30.93it/s, train_loss=0.00384, val_loss=0.004]Epoch 23: 100%|██████████| 22/22 [00:00<00:00, 30.12it/s, train_loss=0.00374, val_loss=0.004]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 94.32it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 111.40it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 123.81it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 133.92it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 138.03it/s][A
                                                                       [AEpoch 23: 100%|██████████| 22/22 [00:00<00:00, 27.78it/s, train_loss=0.00374, val_loss=0.00393]Epoch 23: 100%|██████████| 22/22 [00:00<00:00, 27.76it/s, train_loss=0.00374, val_loss=0.00393]Epoch 23:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00393]         Epoch 24:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00393]Epoch 24:   5%|▍         | 1/22 [00:00<00:00, 70.23it/s, train_loss=0.00374, val_loss=0.00393]Epoch 24:   5%|▍         | 1/22 [00:00<00:00, 31.21it/s, train_loss=0.00416, val_loss=0.00393]Epoch 24:   9%|▉         | 2/22 [00:00<00:00, 42.93it/s, train_loss=0.00416, val_loss=0.00393]Epoch 24:   9%|▉         | 2/22 [00:00<00:00, 31.23it/s, train_loss=0.00421, val_loss=0.00393]Epoch 24:  14%|█▎        | 3/22 [00:00<00:00, 38.25it/s, train_loss=0.00421, val_loss=0.00393]Epoch 24:  14%|█▎        | 3/22 [00:00<00:00, 30.87it/s, train_loss=0.00379, val_loss=0.00393]Epoch 24:  18%|█▊        | 4/22 [00:00<00:00, 36.11it/s, train_loss=0.00379, val_loss=0.00393]Epoch 24:  18%|█▊        | 4/22 [00:00<00:00, 30.62it/s, train_loss=0.00376, val_loss=0.00393]Epoch 24:  23%|██▎       | 5/22 [00:00<00:00, 34.49it/s, train_loss=0.00376, val_loss=0.00393]Epoch 24:  23%|██▎       | 5/22 [00:00<00:00, 30.45it/s, train_loss=0.00397, val_loss=0.00393]Epoch 24:  27%|██▋       | 6/22 [00:00<00:00, 33.72it/s, train_loss=0.00397, val_loss=0.00393]Epoch 24:  27%|██▋       | 6/22 [00:00<00:00, 30.37it/s, train_loss=0.00374, val_loss=0.00393]Epoch 24:  32%|███▏      | 7/22 [00:00<00:00, 33.19it/s, train_loss=0.00374, val_loss=0.00393]Epoch 24:  32%|███▏      | 7/22 [00:00<00:00, 30.29it/s, train_loss=0.00373, val_loss=0.00393]Epoch 24:  36%|███▋      | 8/22 [00:00<00:00, 32.63it/s, train_loss=0.00373, val_loss=0.00393]Epoch 24:  36%|███▋      | 8/22 [00:00<00:00, 30.13it/s, train_loss=0.00386, val_loss=0.00393]Epoch 24:  41%|████      | 9/22 [00:00<00:00, 32.21it/s, train_loss=0.00386, val_loss=0.00393]Epoch 24:  41%|████      | 9/22 [00:00<00:00, 30.09it/s, train_loss=0.00404, val_loss=0.00393]Epoch 24:  45%|████▌     | 10/22 [00:00<00:00, 31.94it/s, train_loss=0.00404, val_loss=0.00393]Epoch 24:  45%|████▌     | 10/22 [00:00<00:00, 30.06it/s, train_loss=0.0039, val_loss=0.00393] Epoch 24:  50%|█████     | 11/22 [00:00<00:00, 31.76it/s, train_loss=0.0039, val_loss=0.00393]Epoch 24:  50%|█████     | 11/22 [00:00<00:00, 30.04it/s, train_loss=0.00386, val_loss=0.00393]Epoch 24:  55%|█████▍    | 12/22 [00:00<00:00, 31.57it/s, train_loss=0.00386, val_loss=0.00393]Epoch 24:  55%|█████▍    | 12/22 [00:00<00:00, 30.02it/s, train_loss=0.00381, val_loss=0.00393]Epoch 24:  59%|█████▉    | 13/22 [00:00<00:00, 31.43it/s, train_loss=0.00381, val_loss=0.00393]Epoch 24:  59%|█████▉    | 13/22 [00:00<00:00, 30.01it/s, train_loss=0.00376, val_loss=0.00393]Epoch 24:  64%|██████▎   | 14/22 [00:00<00:00, 31.30it/s, train_loss=0.00376, val_loss=0.00393]Epoch 24:  64%|██████▎   | 14/22 [00:00<00:00, 29.99it/s, train_loss=0.00366, val_loss=0.00393]Epoch 24:  68%|██████▊   | 15/22 [00:00<00:00, 31.19it/s, train_loss=0.00366, val_loss=0.00393]Epoch 24:  68%|██████▊   | 15/22 [00:00<00:00, 29.97it/s, train_loss=0.00382, val_loss=0.00393]Epoch 24:  73%|███████▎  | 16/22 [00:00<00:00, 31.07it/s, train_loss=0.00382, val_loss=0.00393]Epoch 24:  73%|███████▎  | 16/22 [00:00<00:00, 29.96it/s, train_loss=0.00377, val_loss=0.00393]Epoch 24:  77%|███████▋  | 17/22 [00:00<00:00, 31.01it/s, train_loss=0.00377, val_loss=0.00393]Epoch 24:  77%|███████▋  | 17/22 [00:00<00:00, 29.93it/s, train_loss=0.00383, val_loss=0.00393]Epoch 24:  82%|████████▏ | 18/22 [00:00<00:00, 31.03it/s, train_loss=0.00383, val_loss=0.00393]Epoch 24:  82%|████████▏ | 18/22 [00:00<00:00, 29.94it/s, train_loss=0.00396, val_loss=0.00393]Epoch 24:  86%|████████▋ | 19/22 [00:00<00:00, 30.94it/s, train_loss=0.00396, val_loss=0.00393]Epoch 24:  86%|████████▋ | 19/22 [00:00<00:00, 29.94it/s, train_loss=0.00365, val_loss=0.00393]Epoch 24:  91%|█████████ | 20/22 [00:00<00:00, 30.95it/s, train_loss=0.00365, val_loss=0.00393]Epoch 24:  91%|█████████ | 20/22 [00:00<00:00, 29.94it/s, train_loss=0.004, val_loss=0.00393]  Epoch 24:  95%|█████████▌| 21/22 [00:00<00:00, 30.89it/s, train_loss=0.004, val_loss=0.00393]Epoch 24:  95%|█████████▌| 21/22 [00:00<00:00, 29.94it/s, train_loss=0.00371, val_loss=0.00393]Epoch 24: 100%|██████████| 22/22 [00:00<00:00, 30.86it/s, train_loss=0.00371, val_loss=0.00393]Epoch 24: 100%|██████████| 22/22 [00:00<00:00, 30.05it/s, train_loss=0.00327, val_loss=0.00393]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 105.34it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 121.19it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 130.80it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 135.16it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 138.90it/s][A
                                                                       [AEpoch 24: 100%|██████████| 22/22 [00:00<00:00, 27.85it/s, train_loss=0.00327, val_loss=0.0039] Epoch 24: 100%|██████████| 22/22 [00:00<00:00, 27.82it/s, train_loss=0.00327, val_loss=0.0039]Epoch 24:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00327, val_loss=0.0039]         Epoch 25:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00327, val_loss=0.0039]Epoch 25:   5%|▍         | 1/22 [00:00<00:00, 71.87it/s, train_loss=0.00327, val_loss=0.0039]Epoch 25:   5%|▍         | 1/22 [00:00<00:00, 29.34it/s, train_loss=0.00388, val_loss=0.0039]Epoch 25:   9%|▉         | 2/22 [00:00<00:00, 43.07it/s, train_loss=0.00388, val_loss=0.0039]Epoch 25:   9%|▉         | 2/22 [00:00<00:00, 29.50it/s, train_loss=0.00352, val_loss=0.0039]Epoch 25:  14%|█▎        | 3/22 [00:00<00:00, 37.53it/s, train_loss=0.00352, val_loss=0.0039]Epoch 25:  14%|█▎        | 3/22 [00:00<00:00, 29.60it/s, train_loss=0.00384, val_loss=0.0039]Epoch 25:  18%|█▊        | 4/22 [00:00<00:00, 35.30it/s, train_loss=0.00384, val_loss=0.0039]Epoch 25:  18%|█▊        | 4/22 [00:00<00:00, 29.65it/s, train_loss=0.00384, val_loss=0.0039]Epoch 25:  23%|██▎       | 5/22 [00:00<00:00, 34.11it/s, train_loss=0.00384, val_loss=0.0039]Epoch 25:  23%|██▎       | 5/22 [00:00<00:00, 29.73it/s, train_loss=0.00385, val_loss=0.0039]Epoch 25:  27%|██▋       | 6/22 [00:00<00:00, 33.33it/s, train_loss=0.00385, val_loss=0.0039]Epoch 25:  27%|██▋       | 6/22 [00:00<00:00, 29.76it/s, train_loss=0.00372, val_loss=0.0039]Epoch 25:  32%|███▏      | 7/22 [00:00<00:00, 32.74it/s, train_loss=0.00372, val_loss=0.0039]Epoch 25:  32%|███▏      | 7/22 [00:00<00:00, 29.76it/s, train_loss=0.00381, val_loss=0.0039]Epoch 25:  36%|███▋      | 8/22 [00:00<00:00, 32.38it/s, train_loss=0.00381, val_loss=0.0039]Epoch 25:  36%|███▋      | 8/22 [00:00<00:00, 29.76it/s, train_loss=0.00385, val_loss=0.0039]Epoch 25:  41%|████      | 9/22 [00:00<00:00, 32.02it/s, train_loss=0.00385, val_loss=0.0039]Epoch 25:  41%|████      | 9/22 [00:00<00:00, 29.75it/s, train_loss=0.00382, val_loss=0.0039]Epoch 25:  45%|████▌     | 10/22 [00:00<00:00, 31.85it/s, train_loss=0.00382, val_loss=0.0039]Epoch 25:  45%|████▌     | 10/22 [00:00<00:00, 29.79it/s, train_loss=0.00387, val_loss=0.0039]Epoch 25:  50%|█████     | 11/22 [00:00<00:00, 31.70it/s, train_loss=0.00387, val_loss=0.0039]Epoch 25:  50%|█████     | 11/22 [00:00<00:00, 29.83it/s, train_loss=0.00358, val_loss=0.0039]Epoch 25:  55%|█████▍    | 12/22 [00:00<00:00, 31.51it/s, train_loss=0.00358, val_loss=0.0039]Epoch 25:  55%|█████▍    | 12/22 [00:00<00:00, 29.80it/s, train_loss=0.00361, val_loss=0.0039]Epoch 25:  59%|█████▉    | 13/22 [00:00<00:00, 31.37it/s, train_loss=0.00361, val_loss=0.0039]Epoch 25:  59%|█████▉    | 13/22 [00:00<00:00, 29.81it/s, train_loss=0.00386, val_loss=0.0039]Epoch 25:  64%|██████▎   | 14/22 [00:00<00:00, 31.25it/s, train_loss=0.00386, val_loss=0.0039]Epoch 25:  64%|██████▎   | 14/22 [00:00<00:00, 29.82it/s, train_loss=0.00375, val_loss=0.0039]Epoch 25:  68%|██████▊   | 15/22 [00:00<00:00, 31.17it/s, train_loss=0.00375, val_loss=0.0039]Epoch 25:  68%|██████▊   | 15/22 [00:00<00:00, 29.82it/s, train_loss=0.00367, val_loss=0.0039]Epoch 25:  73%|███████▎  | 16/22 [00:00<00:00, 31.08it/s, train_loss=0.00367, val_loss=0.0039]Epoch 25:  73%|███████▎  | 16/22 [00:00<00:00, 29.83it/s, train_loss=0.00353, val_loss=0.0039]Epoch 25:  77%|███████▋  | 17/22 [00:00<00:00, 31.01it/s, train_loss=0.00353, val_loss=0.0039]Epoch 25:  77%|███████▋  | 17/22 [00:00<00:00, 29.83it/s, train_loss=0.00365, val_loss=0.0039]Epoch 25:  82%|████████▏ | 18/22 [00:00<00:00, 30.95it/s, train_loss=0.00365, val_loss=0.0039]Epoch 25:  82%|████████▏ | 18/22 [00:00<00:00, 29.84it/s, train_loss=0.00391, val_loss=0.0039]Epoch 25:  86%|████████▋ | 19/22 [00:00<00:00, 30.89it/s, train_loss=0.00391, val_loss=0.0039]Epoch 25:  86%|████████▋ | 19/22 [00:00<00:00, 29.83it/s, train_loss=0.00414, val_loss=0.0039]Epoch 25:  91%|█████████ | 20/22 [00:00<00:00, 30.83it/s, train_loss=0.00414, val_loss=0.0039]Epoch 25:  91%|█████████ | 20/22 [00:00<00:00, 29.84it/s, train_loss=0.00363, val_loss=0.0039]Epoch 25:  95%|█████████▌| 21/22 [00:00<00:00, 30.79it/s, train_loss=0.00363, val_loss=0.0039]Epoch 25:  95%|█████████▌| 21/22 [00:00<00:00, 29.84it/s, train_loss=0.00376, val_loss=0.0039]Epoch 25: 100%|██████████| 22/22 [00:00<00:00, 30.75it/s, train_loss=0.00376, val_loss=0.0039]Epoch 25: 100%|██████████| 22/22 [00:00<00:00, 29.94it/s, train_loss=0.00398, val_loss=0.0039]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 95.30it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 115.11it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 123.70it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 127.34it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 121.02it/s][A
                                                                       [AEpoch 25: 100%|██████████| 22/22 [00:00<00:00, 27.62it/s, train_loss=0.00398, val_loss=0.00384]Epoch 25: 100%|██████████| 22/22 [00:00<00:00, 27.58it/s, train_loss=0.00398, val_loss=0.00384]Epoch 25:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00398, val_loss=0.00384]         Epoch 26:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00398, val_loss=0.00384]Epoch 26:   5%|▍         | 1/22 [00:00<00:00, 59.22it/s, train_loss=0.00398, val_loss=0.00384]Epoch 26:   5%|▍         | 1/22 [00:00<00:00, 27.37it/s, train_loss=0.00386, val_loss=0.00384]Epoch 26:   9%|▉         | 2/22 [00:00<00:00, 41.79it/s, train_loss=0.00386, val_loss=0.00384]Epoch 26:   9%|▉         | 2/22 [00:00<00:00, 28.75it/s, train_loss=0.00379, val_loss=0.00384]Epoch 26:  14%|█▎        | 3/22 [00:00<00:00, 36.98it/s, train_loss=0.00379, val_loss=0.00384]Epoch 26:  14%|█▎        | 3/22 [00:00<00:00, 29.25it/s, train_loss=0.00384, val_loss=0.00384]Epoch 26:  18%|█▊        | 4/22 [00:00<00:00, 35.05it/s, train_loss=0.00384, val_loss=0.00384]Epoch 26:  18%|█▊        | 4/22 [00:00<00:00, 29.48it/s, train_loss=0.00371, val_loss=0.00384]Epoch 26:  23%|██▎       | 5/22 [00:00<00:00, 33.92it/s, train_loss=0.00371, val_loss=0.00384]Epoch 26:  23%|██▎       | 5/22 [00:00<00:00, 29.59it/s, train_loss=0.00353, val_loss=0.00384]Epoch 26:  27%|██▋       | 6/22 [00:00<00:00, 33.17it/s, train_loss=0.00353, val_loss=0.00384]Epoch 26:  27%|██▋       | 6/22 [00:00<00:00, 29.68it/s, train_loss=0.00366, val_loss=0.00384]Epoch 26:  32%|███▏      | 7/22 [00:00<00:00, 32.74it/s, train_loss=0.00366, val_loss=0.00384]Epoch 26:  32%|███▏      | 7/22 [00:00<00:00, 29.73it/s, train_loss=0.00366, val_loss=0.00384]Epoch 26:  36%|███▋      | 8/22 [00:00<00:00, 32.30it/s, train_loss=0.00366, val_loss=0.00384]Epoch 26:  36%|███▋      | 8/22 [00:00<00:00, 29.72it/s, train_loss=0.00382, val_loss=0.00384]Epoch 26:  41%|████      | 9/22 [00:00<00:00, 32.05it/s, train_loss=0.00382, val_loss=0.00384]Epoch 26:  41%|████      | 9/22 [00:00<00:00, 29.75it/s, train_loss=0.00377, val_loss=0.00384]Epoch 26:  45%|████▌     | 10/22 [00:00<00:00, 31.78it/s, train_loss=0.00377, val_loss=0.00384]Epoch 26:  45%|████▌     | 10/22 [00:00<00:00, 29.74it/s, train_loss=0.0036, val_loss=0.00384] Epoch 26:  50%|█████     | 11/22 [00:00<00:00, 31.59it/s, train_loss=0.0036, val_loss=0.00384]Epoch 26:  50%|█████     | 11/22 [00:00<00:00, 29.75it/s, train_loss=0.00381, val_loss=0.00384]Epoch 26:  55%|█████▍    | 12/22 [00:00<00:00, 31.45it/s, train_loss=0.00381, val_loss=0.00384]Epoch 26:  55%|█████▍    | 12/22 [00:00<00:00, 29.78it/s, train_loss=0.00383, val_loss=0.00384]Epoch 26:  59%|█████▉    | 13/22 [00:00<00:00, 31.35it/s, train_loss=0.00383, val_loss=0.00384]Epoch 26:  59%|█████▉    | 13/22 [00:00<00:00, 29.80it/s, train_loss=0.00347, val_loss=0.00384]Epoch 26:  64%|██████▎   | 14/22 [00:00<00:00, 31.23it/s, train_loss=0.00347, val_loss=0.00384]Epoch 26:  64%|██████▎   | 14/22 [00:00<00:00, 29.79it/s, train_loss=0.00346, val_loss=0.00384]Epoch 26:  68%|██████▊   | 15/22 [00:00<00:00, 31.13it/s, train_loss=0.00346, val_loss=0.00384]Epoch 26:  68%|██████▊   | 15/22 [00:00<00:00, 29.80it/s, train_loss=0.0039, val_loss=0.00384] Epoch 26:  73%|███████▎  | 16/22 [00:00<00:00, 31.06it/s, train_loss=0.0039, val_loss=0.00384]Epoch 26:  73%|███████▎  | 16/22 [00:00<00:00, 29.81it/s, train_loss=0.00346, val_loss=0.00384]Epoch 26:  77%|███████▋  | 17/22 [00:00<00:00, 30.98it/s, train_loss=0.00346, val_loss=0.00384]Epoch 26:  77%|███████▋  | 17/22 [00:00<00:00, 29.80it/s, train_loss=0.0039, val_loss=0.00384] Epoch 26:  82%|████████▏ | 18/22 [00:00<00:00, 30.90it/s, train_loss=0.0039, val_loss=0.00384]Epoch 26:  82%|████████▏ | 18/22 [00:00<00:00, 29.81it/s, train_loss=0.00348, val_loss=0.00384]Epoch 26:  86%|████████▋ | 19/22 [00:00<00:00, 30.86it/s, train_loss=0.00348, val_loss=0.00384]Epoch 26:  86%|████████▋ | 19/22 [00:00<00:00, 29.82it/s, train_loss=0.00376, val_loss=0.00384]Epoch 26:  91%|█████████ | 20/22 [00:00<00:00, 30.81it/s, train_loss=0.00376, val_loss=0.00384]Epoch 26:  91%|█████████ | 20/22 [00:00<00:00, 29.81it/s, train_loss=0.00379, val_loss=0.00384]Epoch 26:  95%|█████████▌| 21/22 [00:00<00:00, 30.77it/s, train_loss=0.00379, val_loss=0.00384]Epoch 26:  95%|█████████▌| 21/22 [00:00<00:00, 29.82it/s, train_loss=0.00403, val_loss=0.00384]Epoch 26: 100%|██████████| 22/22 [00:00<00:00, 30.74it/s, train_loss=0.00403, val_loss=0.00384]Epoch 26: 100%|██████████| 22/22 [00:00<00:00, 29.93it/s, train_loss=0.00374, val_loss=0.00384]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 117.09it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 129.47it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 137.98it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 143.35it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 146.50it/s][A
                                                                       [AEpoch 26: 100%|██████████| 22/22 [00:00<00:00, 27.81it/s, train_loss=0.00374, val_loss=0.00382]Epoch 26: 100%|██████████| 22/22 [00:00<00:00, 27.78it/s, train_loss=0.00374, val_loss=0.00382]Epoch 26:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00382]         Epoch 27:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:   5%|▍         | 1/22 [00:00<00:00, 73.61it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:   5%|▍         | 1/22 [00:00<00:00, 29.24it/s, train_loss=0.00372, val_loss=0.00382]Epoch 27:   9%|▉         | 2/22 [00:00<00:00, 42.02it/s, train_loss=0.00372, val_loss=0.00382]Epoch 27:   9%|▉         | 2/22 [00:00<00:00, 30.51it/s, train_loss=0.00356, val_loss=0.00382]Epoch 27:  14%|█▎        | 3/22 [00:00<00:00, 38.29it/s, train_loss=0.00356, val_loss=0.00382]Epoch 27:  14%|█▎        | 3/22 [00:00<00:00, 30.94it/s, train_loss=0.00369, val_loss=0.00382]Epoch 27:  18%|█▊        | 4/22 [00:00<00:00, 36.57it/s, train_loss=0.00369, val_loss=0.00382]Epoch 27:  18%|█▊        | 4/22 [00:00<00:00, 30.67it/s, train_loss=0.00352, val_loss=0.00382]Epoch 27:  23%|██▎       | 5/22 [00:00<00:00, 34.83it/s, train_loss=0.00352, val_loss=0.00382]Epoch 27:  23%|██▎       | 5/22 [00:00<00:00, 30.47it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:  27%|██▋       | 6/22 [00:00<00:00, 34.01it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:  27%|██▋       | 6/22 [00:00<00:00, 30.38it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:  32%|███▏      | 7/22 [00:00<00:00, 33.31it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:  32%|███▏      | 7/22 [00:00<00:00, 30.29it/s, train_loss=0.0037, val_loss=0.00382] Epoch 27:  36%|███▋      | 8/22 [00:00<00:00, 32.92it/s, train_loss=0.0037, val_loss=0.00382]Epoch 27:  36%|███▋      | 8/22 [00:00<00:00, 30.25it/s, train_loss=0.00364, val_loss=0.00382]Epoch 27:  41%|████      | 9/22 [00:00<00:00, 32.44it/s, train_loss=0.00364, val_loss=0.00382]Epoch 27:  41%|████      | 9/22 [00:00<00:00, 30.13it/s, train_loss=0.00355, val_loss=0.00382]Epoch 27:  45%|████▌     | 10/22 [00:00<00:00, 32.13it/s, train_loss=0.00355, val_loss=0.00382]Epoch 27:  45%|████▌     | 10/22 [00:00<00:00, 30.08it/s, train_loss=0.00369, val_loss=0.00382]Epoch 27:  50%|█████     | 11/22 [00:00<00:00, 31.89it/s, train_loss=0.00369, val_loss=0.00382]Epoch 27:  50%|█████     | 11/22 [00:00<00:00, 30.07it/s, train_loss=0.00395, val_loss=0.00382]Epoch 27:  55%|█████▍    | 12/22 [00:00<00:00, 31.69it/s, train_loss=0.00395, val_loss=0.00382]Epoch 27:  55%|█████▍    | 12/22 [00:00<00:00, 30.03it/s, train_loss=0.0037, val_loss=0.00382] Epoch 27:  59%|█████▉    | 13/22 [00:00<00:00, 31.57it/s, train_loss=0.0037, val_loss=0.00382]Epoch 27:  59%|█████▉    | 13/22 [00:00<00:00, 30.00it/s, train_loss=0.00327, val_loss=0.00382]Epoch 27:  64%|██████▎   | 14/22 [00:00<00:00, 31.47it/s, train_loss=0.00327, val_loss=0.00382]Epoch 27:  64%|██████▎   | 14/22 [00:00<00:00, 29.99it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:  68%|██████▊   | 15/22 [00:00<00:00, 31.36it/s, train_loss=0.00374, val_loss=0.00382]Epoch 27:  68%|██████▊   | 15/22 [00:00<00:00, 29.99it/s, train_loss=0.00375, val_loss=0.00382]Epoch 27:  73%|███████▎  | 16/22 [00:00<00:00, 31.25it/s, train_loss=0.00375, val_loss=0.00382]Epoch 27:  73%|███████▎  | 16/22 [00:00<00:00, 29.98it/s, train_loss=0.00384, val_loss=0.00382]Epoch 27:  77%|███████▋  | 17/22 [00:00<00:00, 31.17it/s, train_loss=0.00384, val_loss=0.00382]Epoch 27:  77%|███████▋  | 17/22 [00:00<00:00, 29.97it/s, train_loss=0.00352, val_loss=0.00382]Epoch 27:  82%|████████▏ | 18/22 [00:00<00:00, 31.10it/s, train_loss=0.00352, val_loss=0.00382]Epoch 27:  82%|████████▏ | 18/22 [00:00<00:00, 29.98it/s, train_loss=0.00359, val_loss=0.00382]Epoch 27:  86%|████████▋ | 19/22 [00:00<00:00, 31.02it/s, train_loss=0.00359, val_loss=0.00382]Epoch 27:  86%|████████▋ | 19/22 [00:00<00:00, 29.98it/s, train_loss=0.00373, val_loss=0.00382]Epoch 27:  91%|█████████ | 20/22 [00:00<00:00, 30.98it/s, train_loss=0.00373, val_loss=0.00382]Epoch 27:  91%|█████████ | 20/22 [00:00<00:00, 29.99it/s, train_loss=0.00371, val_loss=0.00382]Epoch 27:  95%|█████████▌| 21/22 [00:00<00:00, 30.92it/s, train_loss=0.00371, val_loss=0.00382]Epoch 27:  95%|█████████▌| 21/22 [00:00<00:00, 29.96it/s, train_loss=0.00373, val_loss=0.00382]Epoch 27: 100%|██████████| 22/22 [00:00<00:00, 30.87it/s, train_loss=0.00373, val_loss=0.00382]Epoch 27: 100%|██████████| 22/22 [00:00<00:00, 30.06it/s, train_loss=0.00374, val_loss=0.00382]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 103.56it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 119.39it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 127.53it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 132.22it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 135.60it/s][A
                                                                       [AEpoch 27: 100%|██████████| 22/22 [00:00<00:00, 27.76it/s, train_loss=0.00374, val_loss=0.00376]Epoch 27: 100%|██████████| 22/22 [00:00<00:00, 27.72it/s, train_loss=0.00374, val_loss=0.00376]Epoch 27:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00376]         Epoch 28:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00374, val_loss=0.00376]Epoch 28:   5%|▍         | 1/22 [00:00<00:00, 57.68it/s, train_loss=0.00374, val_loss=0.00376]Epoch 28:   5%|▍         | 1/22 [00:00<00:00, 31.14it/s, train_loss=0.00355, val_loss=0.00376]Epoch 28:   9%|▉         | 2/22 [00:00<00:00, 44.16it/s, train_loss=0.00355, val_loss=0.00376]Epoch 28:   9%|▉         | 2/22 [00:00<00:00, 31.39it/s, train_loss=0.00356, val_loss=0.00376]Epoch 28:  14%|█▎        | 3/22 [00:00<00:00, 39.16it/s, train_loss=0.00356, val_loss=0.00376]Epoch 28:  14%|█▎        | 3/22 [00:00<00:00, 30.88it/s, train_loss=0.00356, val_loss=0.00376]Epoch 28:  18%|█▊        | 4/22 [00:00<00:00, 36.23it/s, train_loss=0.00356, val_loss=0.00376]Epoch 28:  18%|█▊        | 4/22 [00:00<00:00, 30.66it/s, train_loss=0.00387, val_loss=0.00376]Epoch 28:  23%|██▎       | 5/22 [00:00<00:00, 35.09it/s, train_loss=0.00387, val_loss=0.00376]Epoch 28:  23%|██▎       | 5/22 [00:00<00:00, 30.49it/s, train_loss=0.00362, val_loss=0.00376]Epoch 28:  27%|██▋       | 6/22 [00:00<00:00, 34.16it/s, train_loss=0.00362, val_loss=0.00376]Epoch 28:  27%|██▋       | 6/22 [00:00<00:00, 30.45it/s, train_loss=0.0035, val_loss=0.00376] Epoch 28:  32%|███▏      | 7/22 [00:00<00:00, 33.47it/s, train_loss=0.0035, val_loss=0.00376]Epoch 28:  32%|███▏      | 7/22 [00:00<00:00, 30.34it/s, train_loss=0.0039, val_loss=0.00376]Epoch 28:  36%|███▋      | 8/22 [00:00<00:00, 33.00it/s, train_loss=0.0039, val_loss=0.00376]Epoch 28:  36%|███▋      | 8/22 [00:00<00:00, 30.31it/s, train_loss=0.0038, val_loss=0.00376]Epoch 28:  41%|████      | 9/22 [00:00<00:00, 32.65it/s, train_loss=0.0038, val_loss=0.00376]Epoch 28:  41%|████      | 9/22 [00:00<00:00, 30.28it/s, train_loss=0.00377, val_loss=0.00376]Epoch 28:  45%|████▌     | 10/22 [00:00<00:00, 32.37it/s, train_loss=0.00377, val_loss=0.00376]Epoch 28:  45%|████▌     | 10/22 [00:00<00:00, 30.25it/s, train_loss=0.00354, val_loss=0.00376]Epoch 28:  50%|█████     | 11/22 [00:00<00:00, 32.13it/s, train_loss=0.00354, val_loss=0.00376]Epoch 28:  50%|█████     | 11/22 [00:00<00:00, 30.23it/s, train_loss=0.00362, val_loss=0.00376]Epoch 28:  55%|█████▍    | 12/22 [00:00<00:00, 31.94it/s, train_loss=0.00362, val_loss=0.00376]Epoch 28:  55%|█████▍    | 12/22 [00:00<00:00, 30.19it/s, train_loss=0.00343, val_loss=0.00376]Epoch 28:  59%|█████▉    | 13/22 [00:00<00:00, 31.56it/s, train_loss=0.00343, val_loss=0.00376]Epoch 28:  59%|█████▉    | 13/22 [00:00<00:00, 30.17it/s, train_loss=0.00364, val_loss=0.00376]Epoch 28:  64%|██████▎   | 14/22 [00:00<00:00, 31.52it/s, train_loss=0.00364, val_loss=0.00376]Epoch 28:  64%|██████▎   | 14/22 [00:00<00:00, 30.11it/s, train_loss=0.00359, val_loss=0.00376]Epoch 28:  68%|██████▊   | 15/22 [00:00<00:00, 31.42it/s, train_loss=0.00359, val_loss=0.00376]Epoch 28:  68%|██████▊   | 15/22 [00:00<00:00, 30.08it/s, train_loss=0.00381, val_loss=0.00376]Epoch 28:  73%|███████▎  | 16/22 [00:00<00:00, 31.35it/s, train_loss=0.00381, val_loss=0.00376]Epoch 28:  73%|███████▎  | 16/22 [00:00<00:00, 30.08it/s, train_loss=0.0035, val_loss=0.00376] Epoch 28:  77%|███████▋  | 17/22 [00:00<00:00, 31.26it/s, train_loss=0.0035, val_loss=0.00376]Epoch 28:  77%|███████▋  | 17/22 [00:00<00:00, 30.07it/s, train_loss=0.00357, val_loss=0.00376]Epoch 28:  82%|████████▏ | 18/22 [00:00<00:00, 31.17it/s, train_loss=0.00357, val_loss=0.00376]Epoch 28:  82%|████████▏ | 18/22 [00:00<00:00, 30.06it/s, train_loss=0.00359, val_loss=0.00376]Epoch 28:  86%|████████▋ | 19/22 [00:00<00:00, 31.12it/s, train_loss=0.00359, val_loss=0.00376]Epoch 28:  86%|████████▋ | 19/22 [00:00<00:00, 30.05it/s, train_loss=0.00351, val_loss=0.00376]Epoch 28:  91%|█████████ | 20/22 [00:00<00:00, 31.05it/s, train_loss=0.00351, val_loss=0.00376]Epoch 28:  91%|█████████ | 20/22 [00:00<00:00, 30.05it/s, train_loss=0.00359, val_loss=0.00376]Epoch 28:  95%|█████████▌| 21/22 [00:00<00:00, 31.00it/s, train_loss=0.00359, val_loss=0.00376]Epoch 28:  95%|█████████▌| 21/22 [00:00<00:00, 30.04it/s, train_loss=0.00355, val_loss=0.00376]Epoch 28: 100%|██████████| 22/22 [00:00<00:00, 30.96it/s, train_loss=0.00355, val_loss=0.00376]Epoch 28: 100%|██████████| 22/22 [00:00<00:00, 30.14it/s, train_loss=0.00356, val_loss=0.00376]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 133.91it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 142.66it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 152.11it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 157.21it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 160.50it/s][A
                                                                       [AEpoch 28: 100%|██████████| 22/22 [00:00<00:00, 28.01it/s, train_loss=0.00356, val_loss=0.00373]Epoch 28: 100%|██████████| 22/22 [00:00<00:00, 27.98it/s, train_loss=0.00356, val_loss=0.00373]Epoch 28:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00356, val_loss=0.00373]         Epoch 29:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00356, val_loss=0.00373]Epoch 29:   5%|▍         | 1/22 [00:00<00:00, 73.81it/s, train_loss=0.00356, val_loss=0.00373]Epoch 29:   5%|▍         | 1/22 [00:00<00:00, 31.45it/s, train_loss=0.00349, val_loss=0.00373]Epoch 29:   9%|▉         | 2/22 [00:00<00:00, 44.52it/s, train_loss=0.00349, val_loss=0.00373]Epoch 29:   9%|▉         | 2/22 [00:00<00:00, 31.32it/s, train_loss=0.0037, val_loss=0.00373] Epoch 29:  14%|█▎        | 3/22 [00:00<00:00, 39.33it/s, train_loss=0.0037, val_loss=0.00373]Epoch 29:  14%|█▎        | 3/22 [00:00<00:00, 30.81it/s, train_loss=0.00371, val_loss=0.00373]Epoch 29:  18%|█▊        | 4/22 [00:00<00:00, 36.46it/s, train_loss=0.00371, val_loss=0.00373]Epoch 29:  18%|█▊        | 4/22 [00:00<00:00, 30.53it/s, train_loss=0.00374, val_loss=0.00373]Epoch 29:  23%|██▎       | 5/22 [00:00<00:00, 35.00it/s, train_loss=0.00374, val_loss=0.00373]Epoch 29:  23%|██▎       | 5/22 [00:00<00:00, 30.42it/s, train_loss=0.00347, val_loss=0.00373]Epoch 29:  27%|██▋       | 6/22 [00:00<00:00, 33.54it/s, train_loss=0.00347, val_loss=0.00373]Epoch 29:  27%|██▋       | 6/22 [00:00<00:00, 30.30it/s, train_loss=0.00377, val_loss=0.00373]Epoch 29:  32%|███▏      | 7/22 [00:00<00:00, 33.35it/s, train_loss=0.00377, val_loss=0.00373]Epoch 29:  32%|███▏      | 7/22 [00:00<00:00, 30.26it/s, train_loss=0.00351, val_loss=0.00373]Epoch 29:  36%|███▋      | 8/22 [00:00<00:00, 32.84it/s, train_loss=0.00351, val_loss=0.00373]Epoch 29:  36%|███▋      | 8/22 [00:00<00:00, 30.21it/s, train_loss=0.00352, val_loss=0.00373]Epoch 29:  41%|████      | 9/22 [00:00<00:00, 32.47it/s, train_loss=0.00352, val_loss=0.00373]Epoch 29:  41%|████      | 9/22 [00:00<00:00, 30.14it/s, train_loss=0.0036, val_loss=0.00373] Epoch 29:  45%|████▌     | 10/22 [00:00<00:00, 32.14it/s, train_loss=0.0036, val_loss=0.00373]Epoch 29:  45%|████▌     | 10/22 [00:00<00:00, 30.12it/s, train_loss=0.00347, val_loss=0.00373]Epoch 29:  50%|█████     | 11/22 [00:00<00:00, 31.92it/s, train_loss=0.00347, val_loss=0.00373]Epoch 29:  50%|█████     | 11/22 [00:00<00:00, 30.09it/s, train_loss=0.00369, val_loss=0.00373]Epoch 29:  55%|█████▍    | 12/22 [00:00<00:00, 31.73it/s, train_loss=0.00369, val_loss=0.00373]Epoch 29:  55%|█████▍    | 12/22 [00:00<00:00, 30.06it/s, train_loss=0.00336, val_loss=0.00373]Epoch 29:  59%|█████▉    | 13/22 [00:00<00:00, 31.58it/s, train_loss=0.00336, val_loss=0.00373]Epoch 29:  59%|█████▉    | 13/22 [00:00<00:00, 30.04it/s, train_loss=0.00387, val_loss=0.00373]Epoch 29:  64%|██████▎   | 14/22 [00:00<00:00, 31.45it/s, train_loss=0.00387, val_loss=0.00373]Epoch 29:  64%|██████▎   | 14/22 [00:00<00:00, 30.03it/s, train_loss=0.00351, val_loss=0.00373]Epoch 29:  68%|██████▊   | 15/22 [00:00<00:00, 31.34it/s, train_loss=0.00351, val_loss=0.00373]Epoch 29:  68%|██████▊   | 15/22 [00:00<00:00, 30.01it/s, train_loss=0.00381, val_loss=0.00373]Epoch 29:  73%|███████▎  | 16/22 [00:00<00:00, 31.20it/s, train_loss=0.00381, val_loss=0.00373]Epoch 29:  73%|███████▎  | 16/22 [00:00<00:00, 30.00it/s, train_loss=0.0035, val_loss=0.00373] Epoch 29:  77%|███████▋  | 17/22 [00:00<00:00, 31.18it/s, train_loss=0.0035, val_loss=0.00373]Epoch 29:  77%|███████▋  | 17/22 [00:00<00:00, 30.01it/s, train_loss=0.00351, val_loss=0.00373]Epoch 29:  82%|████████▏ | 18/22 [00:00<00:00, 31.10it/s, train_loss=0.00351, val_loss=0.00373]Epoch 29:  82%|████████▏ | 18/22 [00:00<00:00, 29.99it/s, train_loss=0.0038, val_loss=0.00373] Epoch 29:  86%|████████▋ | 19/22 [00:00<00:00, 31.05it/s, train_loss=0.0038, val_loss=0.00373]Epoch 29:  86%|████████▋ | 19/22 [00:00<00:00, 29.99it/s, train_loss=0.00362, val_loss=0.00373]Epoch 29:  91%|█████████ | 20/22 [00:00<00:00, 30.98it/s, train_loss=0.00362, val_loss=0.00373]Epoch 29:  91%|█████████ | 20/22 [00:00<00:00, 30.01it/s, train_loss=0.00347, val_loss=0.00373]Epoch 29:  95%|█████████▌| 21/22 [00:00<00:00, 30.97it/s, train_loss=0.00347, val_loss=0.00373]Epoch 29:  95%|█████████▌| 21/22 [00:00<00:00, 30.01it/s, train_loss=0.00341, val_loss=0.00373]Epoch 29: 100%|██████████| 22/22 [00:00<00:00, 30.93it/s, train_loss=0.00341, val_loss=0.00373]Epoch 29: 100%|██████████| 22/22 [00:00<00:00, 30.11it/s, train_loss=0.00341, val_loss=0.00373]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 88.88it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 111.79it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 122.66it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 126.35it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 127.06it/s][A
                                                                       [AEpoch 29: 100%|██████████| 22/22 [00:00<00:00, 27.76it/s, train_loss=0.00341, val_loss=0.00371]Epoch 29: 100%|██████████| 22/22 [00:00<00:00, 27.73it/s, train_loss=0.00341, val_loss=0.00371]Epoch 29:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00341, val_loss=0.00371]         Epoch 30:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00341, val_loss=0.00371]Epoch 30:   5%|▍         | 1/22 [00:00<00:00, 72.36it/s, train_loss=0.00341, val_loss=0.00371]Epoch 30:   5%|▍         | 1/22 [00:00<00:00, 31.39it/s, train_loss=0.00371, val_loss=0.00371]Epoch 30:   9%|▉         | 2/22 [00:00<00:00, 44.29it/s, train_loss=0.00371, val_loss=0.00371]Epoch 30:   9%|▉         | 2/22 [00:00<00:00, 31.56it/s, train_loss=0.00358, val_loss=0.00371]Epoch 30:  14%|█▎        | 3/22 [00:00<00:00, 39.12it/s, train_loss=0.00358, val_loss=0.00371]Epoch 30:  14%|█▎        | 3/22 [00:00<00:00, 31.03it/s, train_loss=0.00358, val_loss=0.00371]Epoch 30:  18%|█▊        | 4/22 [00:00<00:00, 36.37it/s, train_loss=0.00358, val_loss=0.00371]Epoch 30:  18%|█▊        | 4/22 [00:00<00:00, 30.75it/s, train_loss=0.00357, val_loss=0.00371]Epoch 30:  23%|██▎       | 5/22 [00:00<00:00, 35.08it/s, train_loss=0.00357, val_loss=0.00371]Epoch 30:  23%|██▎       | 5/22 [00:00<00:00, 30.56it/s, train_loss=0.00357, val_loss=0.00371]Epoch 30:  27%|██▋       | 6/22 [00:00<00:00, 33.91it/s, train_loss=0.00357, val_loss=0.00371]Epoch 30:  27%|██▋       | 6/22 [00:00<00:00, 30.41it/s, train_loss=0.00363, val_loss=0.00371]Epoch 30:  32%|███▏      | 7/22 [00:00<00:00, 33.26it/s, train_loss=0.00363, val_loss=0.00371]Epoch 30:  32%|███▏      | 7/22 [00:00<00:00, 30.36it/s, train_loss=0.00353, val_loss=0.00371]Epoch 30:  36%|███▋      | 8/22 [00:00<00:00, 32.90it/s, train_loss=0.00353, val_loss=0.00371]Epoch 30:  36%|███▋      | 8/22 [00:00<00:00, 30.31it/s, train_loss=0.00369, val_loss=0.00371]Epoch 30:  41%|████      | 9/22 [00:00<00:00, 32.70it/s, train_loss=0.00369, val_loss=0.00371]Epoch 30:  41%|████      | 9/22 [00:00<00:00, 30.30it/s, train_loss=0.00356, val_loss=0.00371]Epoch 30:  45%|████▌     | 10/22 [00:00<00:00, 32.37it/s, train_loss=0.00356, val_loss=0.00371]Epoch 30:  45%|████▌     | 10/22 [00:00<00:00, 30.30it/s, train_loss=0.00351, val_loss=0.00371]Epoch 30:  50%|█████     | 11/22 [00:00<00:00, 32.18it/s, train_loss=0.00351, val_loss=0.00371]Epoch 30:  50%|█████     | 11/22 [00:00<00:00, 30.26it/s, train_loss=0.00375, val_loss=0.00371]Epoch 30:  55%|█████▍    | 12/22 [00:00<00:00, 31.99it/s, train_loss=0.00375, val_loss=0.00371]Epoch 30:  55%|█████▍    | 12/22 [00:00<00:00, 30.25it/s, train_loss=0.00362, val_loss=0.00371]Epoch 30:  59%|█████▉    | 13/22 [00:00<00:00, 31.83it/s, train_loss=0.00362, val_loss=0.00371]Epoch 30:  59%|█████▉    | 13/22 [00:00<00:00, 30.23it/s, train_loss=0.00337, val_loss=0.00371]Epoch 30:  64%|██████▎   | 14/22 [00:00<00:00, 31.69it/s, train_loss=0.00337, val_loss=0.00371]Epoch 30:  64%|██████▎   | 14/22 [00:00<00:00, 30.21it/s, train_loss=0.00345, val_loss=0.00371]Epoch 30:  68%|██████▊   | 15/22 [00:00<00:00, 31.54it/s, train_loss=0.00345, val_loss=0.00371]Epoch 30:  68%|██████▊   | 15/22 [00:00<00:00, 30.18it/s, train_loss=0.00355, val_loss=0.00371]Epoch 30:  73%|███████▎  | 16/22 [00:00<00:00, 31.42it/s, train_loss=0.00355, val_loss=0.00371]Epoch 30:  73%|███████▎  | 16/22 [00:00<00:00, 30.15it/s, train_loss=0.00358, val_loss=0.00371]Epoch 30:  77%|███████▋  | 17/22 [00:00<00:00, 31.26it/s, train_loss=0.00358, val_loss=0.00371]Epoch 30:  77%|███████▋  | 17/22 [00:00<00:00, 30.14it/s, train_loss=0.00351, val_loss=0.00371]Epoch 30:  82%|████████▏ | 18/22 [00:00<00:00, 31.13it/s, train_loss=0.00351, val_loss=0.00371]Epoch 30:  82%|████████▏ | 18/22 [00:00<00:00, 30.23it/s, train_loss=0.00335, val_loss=0.00371]Epoch 30:  86%|████████▋ | 19/22 [00:00<00:00, 31.09it/s, train_loss=0.00335, val_loss=0.00371]Epoch 30:  86%|████████▋ | 19/22 [00:00<00:00, 30.32it/s, train_loss=0.00361, val_loss=0.00371]Epoch 30:  91%|█████████ | 20/22 [00:00<00:00, 31.22it/s, train_loss=0.00361, val_loss=0.00371]Epoch 30:  91%|█████████ | 20/22 [00:00<00:00, 30.30it/s, train_loss=0.00339, val_loss=0.00371]Epoch 30:  95%|█████████▌| 21/22 [00:00<00:00, 31.16it/s, train_loss=0.00339, val_loss=0.00371]Epoch 30:  95%|█████████▌| 21/22 [00:00<00:00, 30.27it/s, train_loss=0.00373, val_loss=0.00371]Epoch 30: 100%|██████████| 22/22 [00:00<00:00, 31.10it/s, train_loss=0.00373, val_loss=0.00371]Epoch 30: 100%|██████████| 22/22 [00:00<00:00, 30.36it/s, train_loss=0.00355, val_loss=0.00371]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 96.29it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 115.89it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 120.00it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 121.25it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 125.40it/s][A
                                                                       [AEpoch 30: 100%|██████████| 22/22 [00:00<00:00, 27.96it/s, train_loss=0.00355, val_loss=0.00369]Epoch 30: 100%|██████████| 22/22 [00:00<00:00, 27.91it/s, train_loss=0.00355, val_loss=0.00369]Epoch 30:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00355, val_loss=0.00369]         Epoch 31:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00355, val_loss=0.00369]Epoch 31:   5%|▍         | 1/22 [00:00<00:00, 72.92it/s, train_loss=0.00355, val_loss=0.00369]Epoch 31:   5%|▍         | 1/22 [00:00<00:00, 31.94it/s, train_loss=0.0034, val_loss=0.00369] Epoch 31:   9%|▉         | 2/22 [00:00<00:00, 43.84it/s, train_loss=0.0034, val_loss=0.00369]Epoch 31:   9%|▉         | 2/22 [00:00<00:00, 31.88it/s, train_loss=0.00344, val_loss=0.00369]Epoch 31:  14%|█▎        | 3/22 [00:00<00:00, 39.29it/s, train_loss=0.00344, val_loss=0.00369]Epoch 31:  14%|█▎        | 3/22 [00:00<00:00, 31.21it/s, train_loss=0.00352, val_loss=0.00369]Epoch 31:  18%|█▊        | 4/22 [00:00<00:00, 36.60it/s, train_loss=0.00352, val_loss=0.00369]Epoch 31:  18%|█▊        | 4/22 [00:00<00:00, 30.89it/s, train_loss=0.0035, val_loss=0.00369] Epoch 31:  23%|██▎       | 5/22 [00:00<00:00, 35.29it/s, train_loss=0.0035, val_loss=0.00369]Epoch 31:  23%|██▎       | 5/22 [00:00<00:00, 30.75it/s, train_loss=0.00349, val_loss=0.00369]Epoch 31:  27%|██▋       | 6/22 [00:00<00:00, 34.12it/s, train_loss=0.00349, val_loss=0.00369]Epoch 31:  27%|██▋       | 6/22 [00:00<00:00, 30.60it/s, train_loss=0.00364, val_loss=0.00369]Epoch 31:  32%|███▏      | 7/22 [00:00<00:00, 33.48it/s, train_loss=0.00364, val_loss=0.00369]Epoch 31:  32%|███▏      | 7/22 [00:00<00:00, 30.42it/s, train_loss=0.0035, val_loss=0.00369] Epoch 31:  36%|███▋      | 8/22 [00:00<00:00, 33.00it/s, train_loss=0.0035, val_loss=0.00369]Epoch 31:  36%|███▋      | 8/22 [00:00<00:00, 30.34it/s, train_loss=0.00339, val_loss=0.00369]Epoch 31:  41%|████      | 9/22 [00:00<00:00, 32.61it/s, train_loss=0.00339, val_loss=0.00369]Epoch 31:  41%|████      | 9/22 [00:00<00:00, 30.28it/s, train_loss=0.00342, val_loss=0.00369]Epoch 31:  45%|████▌     | 10/22 [00:00<00:00, 32.30it/s, train_loss=0.00342, val_loss=0.00369]Epoch 31:  45%|████▌     | 10/22 [00:00<00:00, 30.23it/s, train_loss=0.00321, val_loss=0.00369]Epoch 31:  50%|█████     | 11/22 [00:00<00:00, 32.06it/s, train_loss=0.00321, val_loss=0.00369]Epoch 31:  50%|█████     | 11/22 [00:00<00:00, 30.18it/s, train_loss=0.00358, val_loss=0.00369]Epoch 31:  55%|█████▍    | 12/22 [00:00<00:00, 31.82it/s, train_loss=0.00358, val_loss=0.00369]Epoch 31:  55%|█████▍    | 12/22 [00:00<00:00, 30.14it/s, train_loss=0.00344, val_loss=0.00369]Epoch 31:  59%|█████▉    | 13/22 [00:00<00:00, 31.59it/s, train_loss=0.00344, val_loss=0.00369]Epoch 31:  59%|█████▉    | 13/22 [00:00<00:00, 30.12it/s, train_loss=0.00374, val_loss=0.00369]Epoch 31:  64%|██████▎   | 14/22 [00:00<00:00, 31.54it/s, train_loss=0.00374, val_loss=0.00369]Epoch 31:  64%|██████▎   | 14/22 [00:00<00:00, 30.08it/s, train_loss=0.00359, val_loss=0.00369]Epoch 31:  68%|██████▊   | 15/22 [00:00<00:00, 31.39it/s, train_loss=0.00359, val_loss=0.00369]Epoch 31:  68%|██████▊   | 15/22 [00:00<00:00, 30.05it/s, train_loss=0.00378, val_loss=0.00369]Epoch 31:  73%|███████▎  | 16/22 [00:00<00:00, 31.27it/s, train_loss=0.00378, val_loss=0.00369]Epoch 31:  73%|███████▎  | 16/22 [00:00<00:00, 30.04it/s, train_loss=0.00365, val_loss=0.00369]Epoch 31:  77%|███████▋  | 17/22 [00:00<00:00, 31.18it/s, train_loss=0.00365, val_loss=0.00369]Epoch 31:  77%|███████▋  | 17/22 [00:00<00:00, 30.01it/s, train_loss=0.0037, val_loss=0.00369] Epoch 31:  82%|████████▏ | 18/22 [00:00<00:00, 31.09it/s, train_loss=0.0037, val_loss=0.00369]Epoch 31:  82%|████████▏ | 18/22 [00:00<00:00, 30.00it/s, train_loss=0.00331, val_loss=0.00369]Epoch 31:  86%|████████▋ | 19/22 [00:00<00:00, 30.98it/s, train_loss=0.00331, val_loss=0.00369]Epoch 31:  86%|████████▋ | 19/22 [00:00<00:00, 30.00it/s, train_loss=0.00358, val_loss=0.00369]Epoch 31:  91%|█████████ | 20/22 [00:00<00:00, 30.98it/s, train_loss=0.00358, val_loss=0.00369]Epoch 31:  91%|█████████ | 20/22 [00:00<00:00, 30.00it/s, train_loss=0.00334, val_loss=0.00369]Epoch 31:  95%|█████████▌| 21/22 [00:00<00:00, 30.95it/s, train_loss=0.00334, val_loss=0.00369]Epoch 31:  95%|█████████▌| 21/22 [00:00<00:00, 30.00it/s, train_loss=0.00347, val_loss=0.00369]Epoch 31: 100%|██████████| 22/22 [00:00<00:00, 30.91it/s, train_loss=0.00347, val_loss=0.00369]Epoch 31: 100%|██████████| 22/22 [00:00<00:00, 30.10it/s, train_loss=0.00345, val_loss=0.00369]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 112.18it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 126.96it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 135.34it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 140.22it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 143.02it/s][A
                                                                       [AEpoch 31: 100%|██████████| 22/22 [00:00<00:00, 27.90it/s, train_loss=0.00345, val_loss=0.00367]Epoch 31: 100%|██████████| 22/22 [00:00<00:00, 27.87it/s, train_loss=0.00345, val_loss=0.00367]Epoch 31:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00345, val_loss=0.00367]         Epoch 32:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00345, val_loss=0.00367]Epoch 32:   5%|▍         | 1/22 [00:00<00:00, 73.77it/s, train_loss=0.00345, val_loss=0.00367]Epoch 32:   5%|▍         | 1/22 [00:00<00:00, 29.09it/s, train_loss=0.00375, val_loss=0.00367]Epoch 32:   9%|▉         | 2/22 [00:00<00:00, 43.28it/s, train_loss=0.00375, val_loss=0.00367]Epoch 32:   9%|▉         | 2/22 [00:00<00:00, 29.53it/s, train_loss=0.00352, val_loss=0.00367]Epoch 32:  14%|█▎        | 3/22 [00:00<00:00, 37.69it/s, train_loss=0.00352, val_loss=0.00367]Epoch 32:  14%|█▎        | 3/22 [00:00<00:00, 29.63it/s, train_loss=0.00333, val_loss=0.00367]Epoch 32:  18%|█▊        | 4/22 [00:00<00:00, 35.37it/s, train_loss=0.00333, val_loss=0.00367]Epoch 32:  18%|█▊        | 4/22 [00:00<00:00, 29.72it/s, train_loss=0.00336, val_loss=0.00367]Epoch 32:  23%|██▎       | 5/22 [00:00<00:00, 34.14it/s, train_loss=0.00336, val_loss=0.00367]Epoch 32:  23%|██▎       | 5/22 [00:00<00:00, 29.73it/s, train_loss=0.00344, val_loss=0.00367]Epoch 32:  27%|██▋       | 6/22 [00:00<00:00, 33.31it/s, train_loss=0.00344, val_loss=0.00367]Epoch 32:  27%|██▋       | 6/22 [00:00<00:00, 29.76it/s, train_loss=0.00375, val_loss=0.00367]Epoch 32:  32%|███▏      | 7/22 [00:00<00:00, 32.75it/s, train_loss=0.00375, val_loss=0.00367]Epoch 32:  32%|███▏      | 7/22 [00:00<00:00, 29.74it/s, train_loss=0.00344, val_loss=0.00367]Epoch 32:  36%|███▋      | 8/22 [00:00<00:00, 32.35it/s, train_loss=0.00344, val_loss=0.00367]Epoch 32:  36%|███▋      | 8/22 [00:00<00:00, 29.77it/s, train_loss=0.00363, val_loss=0.00367]Epoch 32:  41%|████      | 9/22 [00:00<00:00, 32.05it/s, train_loss=0.00363, val_loss=0.00367]Epoch 32:  41%|████      | 9/22 [00:00<00:00, 29.79it/s, train_loss=0.00339, val_loss=0.00367]Epoch 32:  45%|████▌     | 10/22 [00:00<00:00, 31.82it/s, train_loss=0.00339, val_loss=0.00367]Epoch 32:  45%|████▌     | 10/22 [00:00<00:00, 29.78it/s, train_loss=0.00332, val_loss=0.00367]Epoch 32:  50%|█████     | 11/22 [00:00<00:00, 31.62it/s, train_loss=0.00332, val_loss=0.00367]Epoch 32:  50%|█████     | 11/22 [00:00<00:00, 29.78it/s, train_loss=0.00339, val_loss=0.00367]Epoch 32:  55%|█████▍    | 12/22 [00:00<00:00, 31.44it/s, train_loss=0.00339, val_loss=0.00367]Epoch 32:  55%|█████▍    | 12/22 [00:00<00:00, 29.80it/s, train_loss=0.00374, val_loss=0.00367]Epoch 32:  59%|█████▉    | 13/22 [00:00<00:00, 31.37it/s, train_loss=0.00374, val_loss=0.00367]Epoch 32:  59%|█████▉    | 13/22 [00:00<00:00, 29.80it/s, train_loss=0.00356, val_loss=0.00367]Epoch 32:  64%|██████▎   | 14/22 [00:00<00:00, 31.27it/s, train_loss=0.00356, val_loss=0.00367]Epoch 32:  64%|██████▎   | 14/22 [00:00<00:00, 29.83it/s, train_loss=0.00332, val_loss=0.00367]Epoch 32:  68%|██████▊   | 15/22 [00:00<00:00, 31.19it/s, train_loss=0.00332, val_loss=0.00367]Epoch 32:  68%|██████▊   | 15/22 [00:00<00:00, 29.84it/s, train_loss=0.00358, val_loss=0.00367]Epoch 32:  73%|███████▎  | 16/22 [00:00<00:00, 31.08it/s, train_loss=0.00358, val_loss=0.00367]Epoch 32:  73%|███████▎  | 16/22 [00:00<00:00, 29.84it/s, train_loss=0.0034, val_loss=0.00367] Epoch 32:  77%|███████▋  | 17/22 [00:00<00:00, 31.02it/s, train_loss=0.0034, val_loss=0.00367]Epoch 32:  77%|███████▋  | 17/22 [00:00<00:00, 29.84it/s, train_loss=0.0034, val_loss=0.00367]Epoch 32:  82%|████████▏ | 18/22 [00:00<00:00, 30.96it/s, train_loss=0.0034, val_loss=0.00367]Epoch 32:  82%|████████▏ | 18/22 [00:00<00:00, 29.84it/s, train_loss=0.00349, val_loss=0.00367]Epoch 32:  86%|████████▋ | 19/22 [00:00<00:00, 30.88it/s, train_loss=0.00349, val_loss=0.00367]Epoch 32:  86%|████████▋ | 19/22 [00:00<00:00, 29.84it/s, train_loss=0.00345, val_loss=0.00367]Epoch 32:  91%|█████████ | 20/22 [00:00<00:00, 30.83it/s, train_loss=0.00345, val_loss=0.00367]Epoch 32:  91%|█████████ | 20/22 [00:00<00:00, 29.84it/s, train_loss=0.00352, val_loss=0.00367]Epoch 32:  95%|█████████▌| 21/22 [00:00<00:00, 30.79it/s, train_loss=0.00352, val_loss=0.00367]Epoch 32:  95%|█████████▌| 21/22 [00:00<00:00, 29.85it/s, train_loss=0.00342, val_loss=0.00367]Epoch 32: 100%|██████████| 22/22 [00:00<00:00, 30.76it/s, train_loss=0.00342, val_loss=0.00367]Epoch 32: 100%|██████████| 22/22 [00:00<00:00, 29.95it/s, train_loss=0.00395, val_loss=0.00367]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 102.21it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 119.68it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 127.42it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 131.43it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 133.81it/s][A
                                                                       [AEpoch 32: 100%|██████████| 22/22 [00:00<00:00, 27.66it/s, train_loss=0.00395, val_loss=0.00364]Epoch 32: 100%|██████████| 22/22 [00:00<00:00, 27.62it/s, train_loss=0.00395, val_loss=0.00364]Epoch 32:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00395, val_loss=0.00364]         Epoch 33:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00395, val_loss=0.00364]Epoch 33:   5%|▍         | 1/22 [00:00<00:00, 67.93it/s, train_loss=0.00395, val_loss=0.00364]Epoch 33:   5%|▍         | 1/22 [00:00<00:00, 31.02it/s, train_loss=0.00343, val_loss=0.00364]Epoch 33:   9%|▉         | 2/22 [00:00<00:00, 42.84it/s, train_loss=0.00343, val_loss=0.00364]Epoch 33:   9%|▉         | 2/22 [00:00<00:00, 31.35it/s, train_loss=0.00361, val_loss=0.00364]Epoch 33:  14%|█▎        | 3/22 [00:00<00:00, 38.40it/s, train_loss=0.00361, val_loss=0.00364]Epoch 33:  14%|█▎        | 3/22 [00:00<00:00, 30.95it/s, train_loss=0.00372, val_loss=0.00364]Epoch 33:  18%|█▊        | 4/22 [00:00<00:00, 36.92it/s, train_loss=0.00372, val_loss=0.00364]Epoch 33:  18%|█▊        | 4/22 [00:00<00:00, 30.78it/s, train_loss=0.00352, val_loss=0.00364]Epoch 33:  23%|██▎       | 5/22 [00:00<00:00, 35.36it/s, train_loss=0.00352, val_loss=0.00364]Epoch 33:  23%|██▎       | 5/22 [00:00<00:00, 30.68it/s, train_loss=0.00363, val_loss=0.00364]Epoch 33:  27%|██▋       | 6/22 [00:00<00:00, 34.39it/s, train_loss=0.00363, val_loss=0.00364]Epoch 33:  27%|██▋       | 6/22 [00:00<00:00, 30.61it/s, train_loss=0.00338, val_loss=0.00364]Epoch 33:  32%|███▏      | 7/22 [00:00<00:00, 33.63it/s, train_loss=0.00338, val_loss=0.00364]Epoch 33:  32%|███▏      | 7/22 [00:00<00:00, 30.51it/s, train_loss=0.00379, val_loss=0.00364]Epoch 33:  36%|███▋      | 8/22 [00:00<00:00, 33.18it/s, train_loss=0.00379, val_loss=0.00364]Epoch 33:  36%|███▋      | 8/22 [00:00<00:00, 30.46it/s, train_loss=0.00346, val_loss=0.00364]Epoch 33:  41%|████      | 9/22 [00:00<00:00, 32.74it/s, train_loss=0.00346, val_loss=0.00364]Epoch 33:  41%|████      | 9/22 [00:00<00:00, 30.37it/s, train_loss=0.00357, val_loss=0.00364]Epoch 33:  45%|████▌     | 10/22 [00:00<00:00, 32.47it/s, train_loss=0.00357, val_loss=0.00364]Epoch 33:  45%|████▌     | 10/22 [00:00<00:00, 30.32it/s, train_loss=0.00355, val_loss=0.00364]Epoch 33:  50%|█████     | 11/22 [00:00<00:00, 32.20it/s, train_loss=0.00355, val_loss=0.00364]Epoch 33:  50%|█████     | 11/22 [00:00<00:00, 30.28it/s, train_loss=0.00334, val_loss=0.00364]Epoch 33:  55%|█████▍    | 12/22 [00:00<00:00, 32.01it/s, train_loss=0.00334, val_loss=0.00364]Epoch 33:  55%|█████▍    | 12/22 [00:00<00:00, 30.24it/s, train_loss=0.0034, val_loss=0.00364] Epoch 33:  59%|█████▉    | 13/22 [00:00<00:00, 31.80it/s, train_loss=0.0034, val_loss=0.00364]Epoch 33:  59%|█████▉    | 13/22 [00:00<00:00, 30.20it/s, train_loss=0.0035, val_loss=0.00364]Epoch 33:  64%|██████▎   | 14/22 [00:00<00:00, 31.66it/s, train_loss=0.0035, val_loss=0.00364]Epoch 33:  64%|██████▎   | 14/22 [00:00<00:00, 30.18it/s, train_loss=0.00363, val_loss=0.00364]Epoch 33:  68%|██████▊   | 15/22 [00:00<00:00, 31.53it/s, train_loss=0.00363, val_loss=0.00364]Epoch 33:  68%|██████▊   | 15/22 [00:00<00:00, 30.17it/s, train_loss=0.00326, val_loss=0.00364]Epoch 33:  73%|███████▎  | 16/22 [00:00<00:00, 31.42it/s, train_loss=0.00326, val_loss=0.00364]Epoch 33:  73%|███████▎  | 16/22 [00:00<00:00, 30.14it/s, train_loss=0.00353, val_loss=0.00364]Epoch 33:  77%|███████▋  | 17/22 [00:00<00:00, 31.32it/s, train_loss=0.00353, val_loss=0.00364]Epoch 33:  77%|███████▋  | 17/22 [00:00<00:00, 30.13it/s, train_loss=0.00343, val_loss=0.00364]Epoch 33:  82%|████████▏ | 18/22 [00:00<00:00, 31.00it/s, train_loss=0.00343, val_loss=0.00364]Epoch 33:  82%|████████▏ | 18/22 [00:00<00:00, 30.02it/s, train_loss=0.00343, val_loss=0.00364]Epoch 33:  86%|████████▋ | 19/22 [00:00<00:00, 30.99it/s, train_loss=0.00343, val_loss=0.00364]Epoch 33:  86%|████████▋ | 19/22 [00:00<00:00, 30.01it/s, train_loss=0.00355, val_loss=0.00364]Epoch 33:  91%|█████████ | 20/22 [00:00<00:00, 30.90it/s, train_loss=0.00355, val_loss=0.00364]Epoch 33:  91%|█████████ | 20/22 [00:00<00:00, 30.01it/s, train_loss=0.00342, val_loss=0.00364]Epoch 33:  95%|█████████▌| 21/22 [00:00<00:00, 30.86it/s, train_loss=0.00342, val_loss=0.00364]Epoch 33:  95%|█████████▌| 21/22 [00:00<00:00, 30.02it/s, train_loss=0.00324, val_loss=0.00364]Epoch 33: 100%|██████████| 22/22 [00:00<00:00, 30.79it/s, train_loss=0.00324, val_loss=0.00364]Epoch 33: 100%|██████████| 22/22 [00:00<00:00, 30.12it/s, train_loss=0.0036, val_loss=0.00364] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 123.80it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 136.43it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 145.26it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 149.89it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 152.87it/s][A
                                                                       [AEpoch 33: 100%|██████████| 22/22 [00:00<00:00, 28.00it/s, train_loss=0.0036, val_loss=0.00364]Epoch 33: 100%|██████████| 22/22 [00:00<00:00, 27.97it/s, train_loss=0.0036, val_loss=0.00364]Epoch 33:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0036, val_loss=0.00364]         Epoch 34:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.0036, val_loss=0.00364]Epoch 34:   5%|▍         | 1/22 [00:00<00:00, 71.25it/s, train_loss=0.0036, val_loss=0.00364]Epoch 34:   5%|▍         | 1/22 [00:00<00:00, 31.73it/s, train_loss=0.00332, val_loss=0.00364]Epoch 34:   9%|▉         | 2/22 [00:00<00:00, 43.40it/s, train_loss=0.00332, val_loss=0.00364]Epoch 34:   9%|▉         | 2/22 [00:00<00:00, 31.54it/s, train_loss=0.00354, val_loss=0.00364]Epoch 34:  14%|█▎        | 3/22 [00:00<00:00, 38.91it/s, train_loss=0.00354, val_loss=0.00364]Epoch 34:  14%|█▎        | 3/22 [00:00<00:00, 31.00it/s, train_loss=0.00342, val_loss=0.00364]Epoch 34:  18%|█▊        | 4/22 [00:00<00:00, 36.54it/s, train_loss=0.00342, val_loss=0.00364]Epoch 34:  18%|█▊        | 4/22 [00:00<00:00, 30.79it/s, train_loss=0.00341, val_loss=0.00364]Epoch 34:  23%|██▎       | 5/22 [00:00<00:00, 35.01it/s, train_loss=0.00341, val_loss=0.00364]Epoch 34:  23%|██▎       | 5/22 [00:00<00:00, 30.62it/s, train_loss=0.00349, val_loss=0.00364]Epoch 34:  27%|██▋       | 6/22 [00:00<00:00, 33.88it/s, train_loss=0.00349, val_loss=0.00364]Epoch 34:  27%|██▋       | 6/22 [00:00<00:00, 30.43it/s, train_loss=0.00347, val_loss=0.00364]Epoch 34:  32%|███▏      | 7/22 [00:00<00:00, 33.17it/s, train_loss=0.00347, val_loss=0.00364]Epoch 34:  32%|███▏      | 7/22 [00:00<00:00, 30.34it/s, train_loss=0.00351, val_loss=0.00364]Epoch 34:  36%|███▋      | 8/22 [00:00<00:00, 32.58it/s, train_loss=0.00351, val_loss=0.00364]Epoch 34:  36%|███▋      | 8/22 [00:00<00:00, 30.29it/s, train_loss=0.00354, val_loss=0.00364]Epoch 34:  41%|████      | 9/22 [00:00<00:00, 32.43it/s, train_loss=0.00354, val_loss=0.00364]Epoch 34:  41%|████      | 9/22 [00:00<00:00, 30.21it/s, train_loss=0.00364, val_loss=0.00364]Epoch 34:  45%|████▌     | 10/22 [00:00<00:00, 32.09it/s, train_loss=0.00364, val_loss=0.00364]Epoch 34:  45%|████▌     | 10/22 [00:00<00:00, 30.18it/s, train_loss=0.00347, val_loss=0.00364]Epoch 34:  50%|█████     | 11/22 [00:00<00:00, 31.85it/s, train_loss=0.00347, val_loss=0.00364]Epoch 34:  50%|█████     | 11/22 [00:00<00:00, 30.16it/s, train_loss=0.00334, val_loss=0.00364]Epoch 34:  55%|█████▍    | 12/22 [00:00<00:00, 31.74it/s, train_loss=0.00334, val_loss=0.00364]Epoch 34:  55%|█████▍    | 12/22 [00:00<00:00, 30.11it/s, train_loss=0.00349, val_loss=0.00364]Epoch 34:  59%|█████▉    | 13/22 [00:00<00:00, 31.53it/s, train_loss=0.00349, val_loss=0.00364]Epoch 34:  59%|█████▉    | 13/22 [00:00<00:00, 30.09it/s, train_loss=0.00327, val_loss=0.00364]Epoch 34:  64%|██████▎   | 14/22 [00:00<00:00, 31.40it/s, train_loss=0.00327, val_loss=0.00364]Epoch 34:  64%|██████▎   | 14/22 [00:00<00:00, 30.06it/s, train_loss=0.00357, val_loss=0.00364]Epoch 34:  68%|██████▊   | 15/22 [00:00<00:00, 31.32it/s, train_loss=0.00357, val_loss=0.00364]Epoch 34:  68%|██████▊   | 15/22 [00:00<00:00, 30.04it/s, train_loss=0.00353, val_loss=0.00364]Epoch 34:  73%|███████▎  | 16/22 [00:00<00:00, 31.32it/s, train_loss=0.00353, val_loss=0.00364]Epoch 34:  73%|███████▎  | 16/22 [00:00<00:00, 30.04it/s, train_loss=0.00328, val_loss=0.00364]Epoch 34:  77%|███████▋  | 17/22 [00:00<00:00, 31.25it/s, train_loss=0.00328, val_loss=0.00364]Epoch 34:  77%|███████▋  | 17/22 [00:00<00:00, 30.07it/s, train_loss=0.00331, val_loss=0.00364]Epoch 34:  82%|████████▏ | 18/22 [00:00<00:00, 31.19it/s, train_loss=0.00331, val_loss=0.00364]Epoch 34:  82%|████████▏ | 18/22 [00:00<00:00, 30.06it/s, train_loss=0.00357, val_loss=0.00364]Epoch 34:  86%|████████▋ | 19/22 [00:00<00:00, 31.13it/s, train_loss=0.00357, val_loss=0.00364]Epoch 34:  86%|████████▋ | 19/22 [00:00<00:00, 30.07it/s, train_loss=0.00341, val_loss=0.00364]Epoch 34:  91%|█████████ | 20/22 [00:00<00:00, 31.05it/s, train_loss=0.00341, val_loss=0.00364]Epoch 34:  91%|█████████ | 20/22 [00:00<00:00, 30.06it/s, train_loss=0.00359, val_loss=0.00364]Epoch 34:  95%|█████████▌| 21/22 [00:00<00:00, 31.01it/s, train_loss=0.00359, val_loss=0.00364]Epoch 34:  95%|█████████▌| 21/22 [00:00<00:00, 30.04it/s, train_loss=0.00358, val_loss=0.00364]Epoch 34: 100%|██████████| 22/22 [00:00<00:00, 30.96it/s, train_loss=0.00358, val_loss=0.00364]Epoch 34: 100%|██████████| 22/22 [00:00<00:00, 30.14it/s, train_loss=0.00369, val_loss=0.00364]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 90.13it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 109.80it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 120.26it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 124.65it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 126.18it/s][A
                                                                       [AEpoch 34: 100%|██████████| 22/22 [00:00<00:00, 27.86it/s, train_loss=0.00369, val_loss=0.00363]Epoch 34: 100%|██████████| 22/22 [00:00<00:00, 27.82it/s, train_loss=0.00369, val_loss=0.00363]Epoch 34:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00369, val_loss=0.00363]         Epoch 35:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00369, val_loss=0.00363]Epoch 35:   5%|▍         | 1/22 [00:00<00:00, 64.62it/s, train_loss=0.00369, val_loss=0.00363]Epoch 35:   5%|▍         | 1/22 [00:00<00:00, 30.20it/s, train_loss=0.00362, val_loss=0.00363]Epoch 35:   9%|▉         | 2/22 [00:00<00:00, 42.26it/s, train_loss=0.00362, val_loss=0.00363]Epoch 35:   9%|▉         | 2/22 [00:00<00:00, 30.14it/s, train_loss=0.00336, val_loss=0.00363]Epoch 35:  14%|█▎        | 3/22 [00:00<00:00, 37.46it/s, train_loss=0.00336, val_loss=0.00363]Epoch 35:  14%|█▎        | 3/22 [00:00<00:00, 30.12it/s, train_loss=0.00354, val_loss=0.00363]Epoch 35:  18%|█▊        | 4/22 [00:00<00:00, 35.23it/s, train_loss=0.00354, val_loss=0.00363]Epoch 35:  18%|█▊        | 4/22 [00:00<00:00, 29.99it/s, train_loss=0.00358, val_loss=0.00363]Epoch 35:  23%|██▎       | 5/22 [00:00<00:00, 33.96it/s, train_loss=0.00358, val_loss=0.00363]Epoch 35:  23%|██▎       | 5/22 [00:00<00:00, 29.96it/s, train_loss=0.00341, val_loss=0.00363]Epoch 35:  27%|██▋       | 6/22 [00:00<00:00, 33.13it/s, train_loss=0.00341, val_loss=0.00363]Epoch 35:  27%|██▋       | 6/22 [00:00<00:00, 29.91it/s, train_loss=0.00341, val_loss=0.00363]Epoch 35:  32%|███▏      | 7/22 [00:00<00:00, 32.98it/s, train_loss=0.00341, val_loss=0.00363]Epoch 35:  32%|███▏      | 7/22 [00:00<00:00, 29.94it/s, train_loss=0.00326, val_loss=0.00363]Epoch 35:  36%|███▋      | 8/22 [00:00<00:00, 32.60it/s, train_loss=0.00326, val_loss=0.00363]Epoch 35:  36%|███▋      | 8/22 [00:00<00:00, 29.99it/s, train_loss=0.00339, val_loss=0.00363]Epoch 35:  41%|████      | 9/22 [00:00<00:00, 32.32it/s, train_loss=0.00339, val_loss=0.00363]Epoch 35:  41%|████      | 9/22 [00:00<00:00, 30.00it/s, train_loss=0.00368, val_loss=0.00363]Epoch 35:  45%|████▌     | 10/22 [00:00<00:00, 32.10it/s, train_loss=0.00368, val_loss=0.00363]Epoch 35:  45%|████▌     | 10/22 [00:00<00:00, 30.02it/s, train_loss=0.0033, val_loss=0.00363] Epoch 35:  50%|█████     | 11/22 [00:00<00:00, 31.86it/s, train_loss=0.0033, val_loss=0.00363]Epoch 35:  50%|█████     | 11/22 [00:00<00:00, 30.00it/s, train_loss=0.00363, val_loss=0.00363]Epoch 35:  55%|█████▍    | 12/22 [00:00<00:00, 31.71it/s, train_loss=0.00363, val_loss=0.00363]Epoch 35:  55%|█████▍    | 12/22 [00:00<00:00, 29.99it/s, train_loss=0.00341, val_loss=0.00363]Epoch 35:  59%|█████▉    | 13/22 [00:00<00:00, 31.53it/s, train_loss=0.00341, val_loss=0.00363]Epoch 35:  59%|█████▉    | 13/22 [00:00<00:00, 29.97it/s, train_loss=0.00334, val_loss=0.00363]Epoch 35:  64%|██████▎   | 14/22 [00:00<00:00, 31.42it/s, train_loss=0.00334, val_loss=0.00363]Epoch 35:  64%|██████▎   | 14/22 [00:00<00:00, 29.97it/s, train_loss=0.00351, val_loss=0.00363]Epoch 35:  68%|██████▊   | 15/22 [00:00<00:00, 31.31it/s, train_loss=0.00351, val_loss=0.00363]Epoch 35:  68%|██████▊   | 15/22 [00:00<00:00, 29.96it/s, train_loss=0.00344, val_loss=0.00363]Epoch 35:  73%|███████▎  | 16/22 [00:00<00:00, 31.21it/s, train_loss=0.00344, val_loss=0.00363]Epoch 35:  73%|███████▎  | 16/22 [00:00<00:00, 29.95it/s, train_loss=0.00369, val_loss=0.00363]Epoch 35:  77%|███████▋  | 17/22 [00:00<00:00, 31.06it/s, train_loss=0.00369, val_loss=0.00363]Epoch 35:  77%|███████▋  | 17/22 [00:00<00:00, 29.94it/s, train_loss=0.00349, val_loss=0.00363]Epoch 35:  82%|████████▏ | 18/22 [00:00<00:00, 31.06it/s, train_loss=0.00349, val_loss=0.00363]Epoch 35:  82%|████████▏ | 18/22 [00:00<00:00, 29.95it/s, train_loss=0.00358, val_loss=0.00363]Epoch 35:  86%|████████▋ | 19/22 [00:00<00:00, 31.00it/s, train_loss=0.00358, val_loss=0.00363]Epoch 35:  86%|████████▋ | 19/22 [00:00<00:00, 29.94it/s, train_loss=0.00344, val_loss=0.00363]Epoch 35:  91%|█████████ | 20/22 [00:00<00:00, 30.94it/s, train_loss=0.00344, val_loss=0.00363]Epoch 35:  91%|█████████ | 20/22 [00:00<00:00, 29.94it/s, train_loss=0.00353, val_loss=0.00363]Epoch 35:  95%|█████████▌| 21/22 [00:00<00:00, 30.89it/s, train_loss=0.00353, val_loss=0.00363]Epoch 35:  95%|█████████▌| 21/22 [00:00<00:00, 29.94it/s, train_loss=0.00339, val_loss=0.00363]Epoch 35: 100%|██████████| 22/22 [00:00<00:00, 30.86it/s, train_loss=0.00339, val_loss=0.00363]Epoch 35: 100%|██████████| 22/22 [00:00<00:00, 30.04it/s, train_loss=0.00319, val_loss=0.00363]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 97.91it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 116.10it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 123.13it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 126.82it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 126.89it/s][A
                                                                       [AEpoch 35: 100%|██████████| 22/22 [00:00<00:00, 27.72it/s, train_loss=0.00319, val_loss=0.00363]Epoch 35: 100%|██████████| 22/22 [00:00<00:00, 27.69it/s, train_loss=0.00319, val_loss=0.00363]Epoch 35:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00319, val_loss=0.00363]         Epoch 36:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00319, val_loss=0.00363]Epoch 36:   5%|▍         | 1/22 [00:00<00:00, 71.78it/s, train_loss=0.00319, val_loss=0.00363]Epoch 36:   5%|▍         | 1/22 [00:00<00:00, 31.82it/s, train_loss=0.0032, val_loss=0.00363] Epoch 36:   9%|▉         | 2/22 [00:00<00:00, 44.15it/s, train_loss=0.0032, val_loss=0.00363]Epoch 36:   9%|▉         | 2/22 [00:00<00:00, 31.50it/s, train_loss=0.00329, val_loss=0.00363]Epoch 36:  14%|█▎        | 3/22 [00:00<00:00, 38.96it/s, train_loss=0.00329, val_loss=0.00363]Epoch 36:  14%|█▎        | 3/22 [00:00<00:00, 30.95it/s, train_loss=0.00348, val_loss=0.00363]Epoch 36:  18%|█▊        | 4/22 [00:00<00:00, 36.26it/s, train_loss=0.00348, val_loss=0.00363]Epoch 36:  18%|█▊        | 4/22 [00:00<00:00, 30.66it/s, train_loss=0.00347, val_loss=0.00363]Epoch 36:  23%|██▎       | 5/22 [00:00<00:00, 34.72it/s, train_loss=0.00347, val_loss=0.00363]Epoch 36:  23%|██▎       | 5/22 [00:00<00:00, 30.43it/s, train_loss=0.00342, val_loss=0.00363]Epoch 36:  27%|██▋       | 6/22 [00:00<00:00, 33.71it/s, train_loss=0.00342, val_loss=0.00363]Epoch 36:  27%|██▋       | 6/22 [00:00<00:00, 30.32it/s, train_loss=0.00325, val_loss=0.00363]Epoch 36:  32%|███▏      | 7/22 [00:00<00:00, 33.09it/s, train_loss=0.00325, val_loss=0.00363]Epoch 36:  32%|███▏      | 7/22 [00:00<00:00, 30.17it/s, train_loss=0.00361, val_loss=0.00363]Epoch 36:  36%|███▋      | 8/22 [00:00<00:00, 32.56it/s, train_loss=0.00361, val_loss=0.00363]Epoch 36:  36%|███▋      | 8/22 [00:00<00:00, 30.12it/s, train_loss=0.00355, val_loss=0.00363]Epoch 36:  41%|████      | 9/22 [00:00<00:00, 32.23it/s, train_loss=0.00355, val_loss=0.00363]Epoch 36:  41%|████      | 9/22 [00:00<00:00, 30.09it/s, train_loss=0.00359, val_loss=0.00363]Epoch 36:  45%|████▌     | 10/22 [00:00<00:00, 31.98it/s, train_loss=0.00359, val_loss=0.00363]Epoch 36:  45%|████▌     | 10/22 [00:00<00:00, 30.08it/s, train_loss=0.00336, val_loss=0.00363]Epoch 36:  50%|█████     | 11/22 [00:00<00:00, 31.79it/s, train_loss=0.00336, val_loss=0.00363]Epoch 36:  50%|█████     | 11/22 [00:00<00:00, 30.05it/s, train_loss=0.0034, val_loss=0.00363] Epoch 36:  55%|█████▍    | 12/22 [00:00<00:00, 31.61it/s, train_loss=0.0034, val_loss=0.00363]Epoch 36:  55%|█████▍    | 12/22 [00:00<00:00, 30.03it/s, train_loss=0.00344, val_loss=0.00363]Epoch 36:  59%|█████▉    | 13/22 [00:00<00:00, 31.46it/s, train_loss=0.00344, val_loss=0.00363]Epoch 36:  59%|█████▉    | 13/22 [00:00<00:00, 30.00it/s, train_loss=0.00364, val_loss=0.00363]Epoch 36:  64%|██████▎   | 14/22 [00:00<00:00, 31.32it/s, train_loss=0.00364, val_loss=0.00363]Epoch 36:  64%|██████▎   | 14/22 [00:00<00:00, 29.98it/s, train_loss=0.00376, val_loss=0.00363]Epoch 36:  68%|██████▊   | 15/22 [00:00<00:00, 31.19it/s, train_loss=0.00376, val_loss=0.00363]Epoch 36:  68%|██████▊   | 15/22 [00:00<00:00, 29.97it/s, train_loss=0.00331, val_loss=0.00363]Epoch 36:  73%|███████▎  | 16/22 [00:00<00:00, 31.11it/s, train_loss=0.00331, val_loss=0.00363]Epoch 36:  73%|███████▎  | 16/22 [00:00<00:00, 29.97it/s, train_loss=0.00351, val_loss=0.00363]Epoch 36:  77%|███████▋  | 17/22 [00:00<00:00, 31.05it/s, train_loss=0.00351, val_loss=0.00363]Epoch 36:  77%|███████▋  | 17/22 [00:00<00:00, 29.95it/s, train_loss=0.00341, val_loss=0.00363]Epoch 36:  82%|████████▏ | 18/22 [00:00<00:00, 31.08it/s, train_loss=0.00341, val_loss=0.00363]Epoch 36:  82%|████████▏ | 18/22 [00:00<00:00, 29.96it/s, train_loss=0.00362, val_loss=0.00363]Epoch 36:  86%|████████▋ | 19/22 [00:00<00:00, 31.04it/s, train_loss=0.00362, val_loss=0.00363]Epoch 36:  86%|████████▋ | 19/22 [00:00<00:00, 29.98it/s, train_loss=0.00354, val_loss=0.00363]Epoch 36:  91%|█████████ | 20/22 [00:00<00:00, 30.98it/s, train_loss=0.00354, val_loss=0.00363]Epoch 36:  91%|█████████ | 20/22 [00:00<00:00, 29.97it/s, train_loss=0.0033, val_loss=0.00363] Epoch 36:  95%|█████████▌| 21/22 [00:00<00:00, 30.93it/s, train_loss=0.0033, val_loss=0.00363]Epoch 36:  95%|█████████▌| 21/22 [00:00<00:00, 29.97it/s, train_loss=0.00331, val_loss=0.00363]Epoch 36: 100%|██████████| 22/22 [00:00<00:00, 30.91it/s, train_loss=0.00331, val_loss=0.00363]Epoch 36: 100%|██████████| 22/22 [00:00<00:00, 30.08it/s, train_loss=0.00316, val_loss=0.00363]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 108.78it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 125.58it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 134.55it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 140.35it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 140.62it/s][A
                                                                       [AEpoch 36: 100%|██████████| 22/22 [00:00<00:00, 27.87it/s, train_loss=0.00316, val_loss=0.00363]Epoch 36: 100%|██████████| 22/22 [00:00<00:00, 27.83it/s, train_loss=0.00316, val_loss=0.00363]Epoch 36:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00316, val_loss=0.00363]         Epoch 37:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00316, val_loss=0.00363]Epoch 37:   5%|▍         | 1/22 [00:00<00:00, 67.82it/s, train_loss=0.00316, val_loss=0.00363]Epoch 37:   5%|▍         | 1/22 [00:00<00:00, 29.15it/s, train_loss=0.00339, val_loss=0.00363]Epoch 37:   9%|▉         | 2/22 [00:00<00:00, 42.50it/s, train_loss=0.00339, val_loss=0.00363]Epoch 37:   9%|▉         | 2/22 [00:00<00:00, 29.48it/s, train_loss=0.00369, val_loss=0.00363]Epoch 37:  14%|█▎        | 3/22 [00:00<00:00, 36.79it/s, train_loss=0.00369, val_loss=0.00363]Epoch 37:  14%|█▎        | 3/22 [00:00<00:00, 29.57it/s, train_loss=0.00326, val_loss=0.00363]Epoch 37:  18%|█▊        | 4/22 [00:00<00:00, 34.80it/s, train_loss=0.00326, val_loss=0.00363]Epoch 37:  18%|█▊        | 4/22 [00:00<00:00, 29.60it/s, train_loss=0.00363, val_loss=0.00363]Epoch 37:  23%|██▎       | 5/22 [00:00<00:00, 33.60it/s, train_loss=0.00363, val_loss=0.00363]Epoch 37:  23%|██▎       | 5/22 [00:00<00:00, 29.63it/s, train_loss=0.00347, val_loss=0.00363]Epoch 37:  27%|██▋       | 6/22 [00:00<00:00, 33.03it/s, train_loss=0.00347, val_loss=0.00363]Epoch 37:  27%|██▋       | 6/22 [00:00<00:00, 29.64it/s, train_loss=0.0034, val_loss=0.00363] Epoch 37:  32%|███▏      | 7/22 [00:00<00:00, 32.32it/s, train_loss=0.0034, val_loss=0.00363]Epoch 37:  32%|███▏      | 7/22 [00:00<00:00, 29.67it/s, train_loss=0.00366, val_loss=0.00363]Epoch 37:  36%|███▋      | 8/22 [00:00<00:00, 32.04it/s, train_loss=0.00366, val_loss=0.00363]Epoch 37:  36%|███▋      | 8/22 [00:00<00:00, 29.69it/s, train_loss=0.0034, val_loss=0.00363] Epoch 37:  41%|████      | 9/22 [00:00<00:00, 31.78it/s, train_loss=0.0034, val_loss=0.00363]Epoch 37:  41%|████      | 9/22 [00:00<00:00, 29.70it/s, train_loss=0.00352, val_loss=0.00363]Epoch 37:  45%|████▌     | 10/22 [00:00<00:00, 31.52it/s, train_loss=0.00352, val_loss=0.00363]Epoch 37:  45%|████▌     | 10/22 [00:00<00:00, 29.71it/s, train_loss=0.00352, val_loss=0.00363]Epoch 37:  50%|█████     | 11/22 [00:00<00:00, 31.61it/s, train_loss=0.00352, val_loss=0.00363]Epoch 37:  50%|█████     | 11/22 [00:00<00:00, 29.77it/s, train_loss=0.00321, val_loss=0.00363]Epoch 37:  55%|█████▍    | 12/22 [00:00<00:00, 31.48it/s, train_loss=0.00321, val_loss=0.00363]Epoch 37:  55%|█████▍    | 12/22 [00:00<00:00, 29.79it/s, train_loss=0.00348, val_loss=0.00363]Epoch 37:  59%|█████▉    | 13/22 [00:00<00:00, 31.37it/s, train_loss=0.00348, val_loss=0.00363]Epoch 37:  59%|█████▉    | 13/22 [00:00<00:00, 29.81it/s, train_loss=0.00349, val_loss=0.00363]Epoch 37:  64%|██████▎   | 14/22 [00:00<00:00, 31.24it/s, train_loss=0.00349, val_loss=0.00363]Epoch 37:  64%|██████▎   | 14/22 [00:00<00:00, 29.82it/s, train_loss=0.00354, val_loss=0.00363]Epoch 37:  68%|██████▊   | 15/22 [00:00<00:00, 31.16it/s, train_loss=0.00354, val_loss=0.00363]Epoch 37:  68%|██████▊   | 15/22 [00:00<00:00, 29.83it/s, train_loss=0.00329, val_loss=0.00363]Epoch 37:  73%|███████▎  | 16/22 [00:00<00:00, 31.09it/s, train_loss=0.00329, val_loss=0.00363]Epoch 37:  73%|███████▎  | 16/22 [00:00<00:00, 29.83it/s, train_loss=0.00355, val_loss=0.00363]Epoch 37:  77%|███████▋  | 17/22 [00:00<00:00, 31.03it/s, train_loss=0.00355, val_loss=0.00363]Epoch 37:  77%|███████▋  | 17/22 [00:00<00:00, 29.86it/s, train_loss=0.00344, val_loss=0.00363]Epoch 37:  82%|████████▏ | 18/22 [00:00<00:00, 30.97it/s, train_loss=0.00344, val_loss=0.00363]Epoch 37:  82%|████████▏ | 18/22 [00:00<00:00, 29.86it/s, train_loss=0.00336, val_loss=0.00363]Epoch 37:  86%|████████▋ | 19/22 [00:00<00:00, 30.91it/s, train_loss=0.00336, val_loss=0.00363]Epoch 37:  86%|████████▋ | 19/22 [00:00<00:00, 29.85it/s, train_loss=0.00343, val_loss=0.00363]Epoch 37:  91%|█████████ | 20/22 [00:00<00:00, 30.84it/s, train_loss=0.00343, val_loss=0.00363]Epoch 37:  91%|█████████ | 20/22 [00:00<00:00, 29.85it/s, train_loss=0.00349, val_loss=0.00363]Epoch 37:  95%|█████████▌| 21/22 [00:00<00:00, 30.78it/s, train_loss=0.00349, val_loss=0.00363]Epoch 37:  95%|█████████▌| 21/22 [00:00<00:00, 29.84it/s, train_loss=0.0034, val_loss=0.00363] Epoch 37: 100%|██████████| 22/22 [00:00<00:00, 30.75it/s, train_loss=0.0034, val_loss=0.00363]Epoch 37: 100%|██████████| 22/22 [00:00<00:00, 29.95it/s, train_loss=0.00313, val_loss=0.00363]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 99.16it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 117.70it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 125.81it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 130.32it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 128.65it/s][A
                                                                       [AEpoch 37: 100%|██████████| 22/22 [00:00<00:00, 27.64it/s, train_loss=0.00313, val_loss=0.00362]Epoch 37: 100%|██████████| 22/22 [00:00<00:00, 27.60it/s, train_loss=0.00313, val_loss=0.00362]Epoch 37:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00313, val_loss=0.00362]         Epoch 38:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00313, val_loss=0.00362]Epoch 38:   5%|▍         | 1/22 [00:00<00:00, 69.38it/s, train_loss=0.00313, val_loss=0.00362]Epoch 38:   5%|▍         | 1/22 [00:00<00:00, 31.17it/s, train_loss=0.00333, val_loss=0.00362]Epoch 38:   9%|▉         | 2/22 [00:00<00:00, 43.74it/s, train_loss=0.00333, val_loss=0.00362]Epoch 38:   9%|▉         | 2/22 [00:00<00:00, 31.57it/s, train_loss=0.00357, val_loss=0.00362]Epoch 38:  14%|█▎        | 3/22 [00:00<00:00, 40.09it/s, train_loss=0.00357, val_loss=0.00362]Epoch 38:  14%|█▎        | 3/22 [00:00<00:00, 31.14it/s, train_loss=0.00379, val_loss=0.00362]Epoch 38:  18%|█▊        | 4/22 [00:00<00:00, 37.04it/s, train_loss=0.00379, val_loss=0.00362]Epoch 38:  18%|█▊        | 4/22 [00:00<00:00, 30.90it/s, train_loss=0.00321, val_loss=0.00362]Epoch 38:  23%|██▎       | 5/22 [00:00<00:00, 35.43it/s, train_loss=0.00321, val_loss=0.00362]Epoch 38:  23%|██▎       | 5/22 [00:00<00:00, 30.72it/s, train_loss=0.0036, val_loss=0.00362] Epoch 38:  27%|██▋       | 6/22 [00:00<00:00, 34.00it/s, train_loss=0.0036, val_loss=0.00362]Epoch 38:  27%|██▋       | 6/22 [00:00<00:00, 30.62it/s, train_loss=0.00361, val_loss=0.00362]Epoch 38:  32%|███▏      | 7/22 [00:00<00:00, 33.68it/s, train_loss=0.00361, val_loss=0.00362]Epoch 38:  32%|███▏      | 7/22 [00:00<00:00, 30.51it/s, train_loss=0.00351, val_loss=0.00362]Epoch 38:  36%|███▋      | 8/22 [00:00<00:00, 33.19it/s, train_loss=0.00351, val_loss=0.00362]Epoch 38:  36%|███▋      | 8/22 [00:00<00:00, 30.47it/s, train_loss=0.00327, val_loss=0.00362]Epoch 38:  41%|████      | 9/22 [00:00<00:00, 32.80it/s, train_loss=0.00327, val_loss=0.00362]Epoch 38:  41%|████      | 9/22 [00:00<00:00, 30.39it/s, train_loss=0.00332, val_loss=0.00362]Epoch 38:  45%|████▌     | 10/22 [00:00<00:00, 32.47it/s, train_loss=0.00332, val_loss=0.00362]Epoch 38:  45%|████▌     | 10/22 [00:00<00:00, 30.34it/s, train_loss=0.0034, val_loss=0.00362] Epoch 38:  50%|█████     | 11/22 [00:00<00:00, 32.22it/s, train_loss=0.0034, val_loss=0.00362]Epoch 38:  50%|█████     | 11/22 [00:00<00:00, 30.30it/s, train_loss=0.00328, val_loss=0.00362]Epoch 38:  55%|█████▍    | 12/22 [00:00<00:00, 32.03it/s, train_loss=0.00328, val_loss=0.00362]Epoch 38:  55%|█████▍    | 12/22 [00:00<00:00, 30.28it/s, train_loss=0.00361, val_loss=0.00362]Epoch 38:  59%|█████▉    | 13/22 [00:00<00:00, 31.83it/s, train_loss=0.00361, val_loss=0.00362]Epoch 38:  59%|█████▉    | 13/22 [00:00<00:00, 30.25it/s, train_loss=0.00357, val_loss=0.00362]Epoch 38:  64%|██████▎   | 14/22 [00:00<00:00, 31.67it/s, train_loss=0.00357, val_loss=0.00362]Epoch 38:  64%|██████▎   | 14/22 [00:00<00:00, 30.21it/s, train_loss=0.0034, val_loss=0.00362] Epoch 38:  68%|██████▊   | 15/22 [00:00<00:00, 31.55it/s, train_loss=0.0034, val_loss=0.00362]Epoch 38:  68%|██████▊   | 15/22 [00:00<00:00, 30.17it/s, train_loss=0.00361, val_loss=0.00362]Epoch 38:  73%|███████▎  | 16/22 [00:00<00:00, 31.44it/s, train_loss=0.00361, val_loss=0.00362]Epoch 38:  73%|███████▎  | 16/22 [00:00<00:00, 30.16it/s, train_loss=0.00336, val_loss=0.00362]Epoch 38:  77%|███████▋  | 17/22 [00:00<00:00, 31.33it/s, train_loss=0.00336, val_loss=0.00362]Epoch 38:  77%|███████▋  | 17/22 [00:00<00:00, 30.12it/s, train_loss=0.00345, val_loss=0.00362]Epoch 38:  82%|████████▏ | 18/22 [00:00<00:00, 31.20it/s, train_loss=0.00345, val_loss=0.00362]Epoch 38:  82%|████████▏ | 18/22 [00:00<00:00, 30.11it/s, train_loss=0.00345, val_loss=0.00362]Epoch 38:  86%|████████▋ | 19/22 [00:00<00:00, 31.14it/s, train_loss=0.00345, val_loss=0.00362]Epoch 38:  86%|████████▋ | 19/22 [00:00<00:00, 30.08it/s, train_loss=0.00363, val_loss=0.00362]Epoch 38:  91%|█████████ | 20/22 [00:00<00:00, 30.97it/s, train_loss=0.00363, val_loss=0.00362]Epoch 38:  91%|█████████ | 20/22 [00:00<00:00, 30.05it/s, train_loss=0.00354, val_loss=0.00362]Epoch 38:  95%|█████████▌| 21/22 [00:00<00:00, 30.91it/s, train_loss=0.00354, val_loss=0.00362]Epoch 38:  95%|█████████▌| 21/22 [00:00<00:00, 30.03it/s, train_loss=0.00358, val_loss=0.00362]Epoch 38: 100%|██████████| 22/22 [00:00<00:00, 30.96it/s, train_loss=0.00358, val_loss=0.00362]Epoch 38: 100%|██████████| 22/22 [00:00<00:00, 30.15it/s, train_loss=0.00402, val_loss=0.00362]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 20.69it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 21.61it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 25.85it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 28.72it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 30.25it/s][A
                                                                      [AEpoch 38: 100%|██████████| 22/22 [00:00<00:00, 22.78it/s, train_loss=0.00402, val_loss=0.00362]Epoch 38: 100%|██████████| 22/22 [00:00<00:00, 22.75it/s, train_loss=0.00402, val_loss=0.00362]Epoch 38:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00402, val_loss=0.00362]         Epoch 39:   0%|          | 0/22 [00:00<?, ?it/s, train_loss=0.00402, val_loss=0.00362]Epoch 39:   5%|▍         | 1/22 [00:00<00:00, 70.81it/s, train_loss=0.00402, val_loss=0.00362]Epoch 39:   5%|▍         | 1/22 [00:00<00:00, 31.34it/s, train_loss=0.0034, val_loss=0.00362] Epoch 39:   9%|▉         | 2/22 [00:00<00:00, 34.19it/s, train_loss=0.0034, val_loss=0.00362]Epoch 39:   9%|▉         | 2/22 [00:00<00:00, 25.25it/s, train_loss=0.00368, val_loss=0.00362]Epoch 39:  14%|█▎        | 3/22 [00:00<00:00, 27.48it/s, train_loss=0.00368, val_loss=0.00362]Epoch 39:  14%|█▎        | 3/22 [00:00<00:00, 23.45it/s, train_loss=0.00359, val_loss=0.00362]Epoch 39:  18%|█▊        | 4/22 [00:00<00:00, 25.22it/s, train_loss=0.00359, val_loss=0.00362]Epoch 39:  18%|█▊        | 4/22 [00:00<00:00, 22.71it/s, train_loss=0.00338, val_loss=0.00362]Epoch 39:  23%|██▎       | 5/22 [00:00<00:00, 24.16it/s, train_loss=0.00338, val_loss=0.00362]Epoch 39:  23%|██▎       | 5/22 [00:00<00:00, 22.30it/s, train_loss=0.00327, val_loss=0.00362]Epoch 39:  27%|██▋       | 6/22 [00:00<00:00, 23.58it/s, train_loss=0.00327, val_loss=0.00362]Epoch 39:  27%|██▋       | 6/22 [00:00<00:00, 22.06it/s, train_loss=0.00366, val_loss=0.00362]Epoch 39:  32%|███▏      | 7/22 [00:00<00:00, 22.99it/s, train_loss=0.00366, val_loss=0.00362]Epoch 39:  32%|███▏      | 7/22 [00:00<00:00, 21.75it/s, train_loss=0.00334, val_loss=0.00362]Epoch 39:  36%|███▋      | 8/22 [00:00<00:00, 22.61it/s, train_loss=0.00334, val_loss=0.00362]Epoch 39:  36%|███▋      | 8/22 [00:00<00:00, 21.55it/s, train_loss=0.00352, val_loss=0.00362]Epoch 39:  41%|████      | 9/22 [00:00<00:00, 22.59it/s, train_loss=0.00352, val_loss=0.00362]Epoch 39:  41%|████      | 9/22 [00:00<00:00, 21.65it/s, train_loss=0.00349, val_loss=0.00362]Epoch 39:  45%|████▌     | 10/22 [00:00<00:00, 22.45it/s, train_loss=0.00349, val_loss=0.00362]Epoch 39:  45%|████▌     | 10/22 [00:00<00:00, 21.60it/s, train_loss=0.00335, val_loss=0.00362]Epoch 39:  50%|█████     | 11/22 [00:00<00:00, 22.23it/s, train_loss=0.00335, val_loss=0.00362]Epoch 39:  50%|█████     | 11/22 [00:00<00:00, 21.46it/s, train_loss=0.00364, val_loss=0.00362]Epoch 39:  55%|█████▍    | 12/22 [00:00<00:00, 22.10it/s, train_loss=0.00364, val_loss=0.00362]Epoch 39:  55%|█████▍    | 12/22 [00:00<00:00, 21.36it/s, train_loss=0.00326, val_loss=0.00362]Epoch 39:  59%|█████▉    | 13/22 [00:00<00:00, 22.50it/s, train_loss=0.00326, val_loss=0.00362]Epoch 39:  59%|█████▉    | 13/22 [00:00<00:00, 21.82it/s, train_loss=0.00342, val_loss=0.00362]Epoch 39:  64%|██████▎   | 14/22 [00:00<00:00, 22.33it/s, train_loss=0.00342, val_loss=0.00362]Epoch 39:  64%|██████▎   | 14/22 [00:00<00:00, 21.74it/s, train_loss=0.00328, val_loss=0.00362]Epoch 39:  68%|██████▊   | 15/22 [00:00<00:00, 22.28it/s, train_loss=0.00328, val_loss=0.00362]Epoch 39:  68%|██████▊   | 15/22 [00:00<00:00, 21.71it/s, train_loss=0.00349, val_loss=0.00362]Epoch 39:  73%|███████▎  | 16/22 [00:00<00:00, 22.18it/s, train_loss=0.00349, val_loss=0.00362]Epoch 39:  73%|███████▎  | 16/22 [00:00<00:00, 21.65it/s, train_loss=0.0035, val_loss=0.00362] Epoch 39:  77%|███████▋  | 17/22 [00:00<00:00, 22.08it/s, train_loss=0.0035, val_loss=0.00362]Epoch 39:  77%|███████▋  | 17/22 [00:00<00:00, 21.57it/s, train_loss=0.00325, val_loss=0.00362]Epoch 39:  82%|████████▏ | 18/22 [00:00<00:00, 21.97it/s, train_loss=0.00325, val_loss=0.00362]Epoch 39:  82%|████████▏ | 18/22 [00:00<00:00, 21.48it/s, train_loss=0.00347, val_loss=0.00362]Epoch 39:  86%|████████▋ | 19/22 [00:00<00:00, 21.86it/s, train_loss=0.00347, val_loss=0.00362]Epoch 39:  86%|████████▋ | 19/22 [00:00<00:00, 21.43it/s, train_loss=0.00351, val_loss=0.00362]Epoch 39:  91%|█████████ | 20/22 [00:00<00:00, 22.10it/s, train_loss=0.00351, val_loss=0.00362]Epoch 39:  91%|█████████ | 20/22 [00:00<00:00, 21.66it/s, train_loss=0.00359, val_loss=0.00362]Epoch 39:  95%|█████████▌| 21/22 [00:00<00:00, 22.01it/s, train_loss=0.00359, val_loss=0.00362]Epoch 39:  95%|█████████▌| 21/22 [00:00<00:00, 21.58it/s, train_loss=0.0034, val_loss=0.00362] Epoch 39: 100%|██████████| 22/22 [00:01<00:00, 21.93it/s, train_loss=0.0034, val_loss=0.00362]Epoch 39: 100%|██████████| 22/22 [00:01<00:00, 21.56it/s, train_loss=0.00292, val_loss=0.00362]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 37.79it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 23.69it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 21.08it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 19.97it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 21.43it/s][A
                                                                      [AEpoch 39: 100%|██████████| 22/22 [00:01<00:00, 15.69it/s, train_loss=0.00292, val_loss=0.00362]Epoch 39: 100%|██████████| 22/22 [00:01<00:00, 15.68it/s, train_loss=0.00292, val_loss=0.00362]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 22/22 [00:01<00:00, 15.64it/s, train_loss=0.00292, val_loss=0.00362]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/23 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/23 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▍         | 1/23 [00:00<00:00, 25.67it/s]Predicting DataLoader 0:   9%|▊         | 2/23 [00:00<00:00, 31.94it/s]Predicting DataLoader 0:  13%|█▎        | 3/23 [00:00<00:00, 38.06it/s]Predicting DataLoader 0:  17%|█▋        | 4/23 [00:00<00:00, 43.93it/s]Predicting DataLoader 0:  22%|██▏       | 5/23 [00:00<00:00, 43.38it/s]Predicting DataLoader 0:  26%|██▌       | 6/23 [00:00<00:00, 42.81it/s]Predicting DataLoader 0:  30%|███       | 7/23 [00:00<00:00, 42.40it/s]Predicting DataLoader 0:  35%|███▍      | 8/23 [00:00<00:00, 43.97it/s]Predicting DataLoader 0:  39%|███▉      | 9/23 [00:00<00:00, 47.29it/s]Predicting DataLoader 0:  43%|████▎     | 10/23 [00:00<00:00, 47.00it/s]Predicting DataLoader 0:  48%|████▊     | 11/23 [00:00<00:00, 45.67it/s]Predicting DataLoader 0:  52%|█████▏    | 12/23 [00:00<00:00, 45.44it/s]Predicting DataLoader 0:  57%|█████▋    | 13/23 [00:00<00:00, 45.43it/s]Predicting DataLoader 0:  61%|██████    | 14/23 [00:00<00:00, 45.42it/s]Predicting DataLoader 0:  65%|██████▌   | 15/23 [00:00<00:00, 47.13it/s]Predicting DataLoader 0:  70%|██████▉   | 16/23 [00:00<00:00, 46.79it/s]Predicting DataLoader 0:  74%|███████▍  | 17/23 [00:00<00:00, 45.38it/s]Predicting DataLoader 0:  78%|███████▊  | 18/23 [00:00<00:00, 45.31it/s]Predicting DataLoader 0:  83%|████████▎ | 19/23 [00:00<00:00, 45.24it/s]Predicting DataLoader 0:  87%|████████▋ | 20/23 [00:00<00:00, 45.14it/s]Predicting DataLoader 0:  91%|█████████▏| 21/23 [00:00<00:00, 45.08it/s]Predicting DataLoader 0:  96%|█████████▌| 22/23 [00:00<00:00, 44.90it/s]Predicting DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 44.82it/s]Predicting DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 43.36it/s][I 2025-08-18 03:06:20,203] A new study created in memory with name: no-name-5308c3d2-3fc2-4feb-9242-bcbb26e732f0
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 160, Horizon length: 7
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.64it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.82it/s][I 2025-08-18 03:06:51,044] Trial 0 finished with value: 25.762607958403414 and parameters: {'hidden_dim': 33, 'n_rnn_layers': 3, 'dropout': 0.1969323297066723}. Best is trial 0 with value: 25.762607958403414.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.48it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.78it/s][I 2025-08-18 03:07:27,259] Trial 1 finished with value: 25.75198646138099 and parameters: {'hidden_dim': 34, 'n_rnn_layers': 4, 'dropout': 0.4141998638644326}. Best is trial 1 with value: 25.75198646138099.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.00686667840160593 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 246.72it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.31it/s][I 2025-08-18 03:08:00,149] Trial 2 finished with value: 24.527379217596064 and parameters: {'hidden_dim': 97, 'n_rnn_layers': 1, 'dropout': 0.00686667840160593}. Best is trial 2 with value: 24.527379217596064.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.27it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.21it/s] [I 2025-08-18 03:08:49,940] Trial 3 finished with value: 27.269429059098293 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 3, 'dropout': 0.015425298218788186}. Best is trial 2 with value: 24.527379217596064.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.74it/s][I 2025-08-18 03:09:51,103] Trial 4 finished with value: 26.756546677771315 and parameters: {'hidden_dim': 109, 'n_rnn_layers': 2, 'dropout': 0.019072751936801857}. Best is trial 2 with value: 24.527379217596064.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s][I 2025-08-18 03:10:21,356] Trial 5 finished with value: 23.63563349177428 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 3, 'dropout': 0.48478497774290374}. Best is trial 5 with value: 23.63563349177428.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.33it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.69it/s][I 2025-08-18 03:10:56,491] Trial 6 finished with value: 22.238553861971308 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 4, 'dropout': 0.288240308761469}. Best is trial 6 with value: 22.238553861971308.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3857322067471565 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.30it/s][I 2025-08-18 03:11:21,817] Trial 7 finished with value: 23.656863781906594 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 1, 'dropout': 0.3857322067471565}. Best is trial 6 with value: 22.238553861971308.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05669850761344375 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.83it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.06it/s][I 2025-08-18 03:11:44,457] Trial 8 finished with value: 21.98487324027466 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 1, 'dropout': 0.05669850761344375}. Best is trial 8 with value: 21.98487324027466.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.39it/s][I 2025-08-18 03:12:37,295] Trial 9 finished with value: 26.343090291519072 and parameters: {'hidden_dim': 71, 'n_rnn_layers': 3, 'dropout': 0.24117809961540987}. Best is trial 8 with value: 21.98487324027466.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.73it/s][I 2025-08-18 03:12:56,748] Trial 10 finished with value: 23.25996113653527 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 2, 'dropout': 0.12662021042585012}. Best is trial 8 with value: 21.98487324027466.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.56it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.18it/s][I 2025-08-18 03:13:28,209] Trial 11 finished with value: 21.819025093240906 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 4, 'dropout': 0.3212212176200274}. Best is trial 11 with value: 21.819025093240906.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.322713006796702 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.29it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.57it/s][I 2025-08-18 03:13:46,717] Trial 12 finished with value: 25.22646646427896 and parameters: {'hidden_dim': 18, 'n_rnn_layers': 1, 'dropout': 0.322713006796702}. Best is trial 11 with value: 21.819025093240906.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.76it/s][I 2025-08-18 03:14:11,089] Trial 13 finished with value: 23.90060217388324 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 2, 'dropout': 0.14070968772849646}. Best is trial 11 with value: 21.819025093240906.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s][I 2025-08-18 03:14:43,829] Trial 14 finished with value: 25.97559292933143 and parameters: {'hidden_dim': 46, 'n_rnn_layers': 4, 'dropout': 0.10883999846843417}. Best is trial 11 with value: 21.819025093240906.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.07it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.39it/s][I 2025-08-18 03:15:17,431] Trial 15 finished with value: 26.212617164222856 and parameters: {'hidden_dim': 46, 'n_rnn_layers': 2, 'dropout': 0.34578981329929626}. Best is trial 11 with value: 21.819025093240906.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20016581715007264 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 228.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.74it/s][I 2025-08-18 03:15:35,602] Trial 16 finished with value: 21.65197542889315 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 1, 'dropout': 0.20016581715007264}. Best is trial 16 with value: 21.65197542889315.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.87it/s][I 2025-08-18 03:16:07,285] Trial 17 finished with value: 27.060748752590793 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 4, 'dropout': 0.22747500112545765}. Best is trial 16 with value: 21.65197542889315.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.48it/s][I 2025-08-18 03:16:34,498] Trial 18 finished with value: 23.203841844107586 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 3, 'dropout': 0.1785341637058262}. Best is trial 16 with value: 21.65197542889315.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.80it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.76it/s] [I 2025-08-18 03:17:05,565] Trial 19 finished with value: 24.280294796792113 and parameters: {'hidden_dim': 38, 'n_rnn_layers': 2, 'dropout': 0.2693475534245608}. Best is trial 16 with value: 21.65197542889315.
[I 2025-08-18 03:17:05,566] A new study created in memory with name: no-name-88ab004f-36f0-43c6-95b4-0bd88d7b73d4
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 20, 'n_rnn_layers': 1, 'dropout': 0.20016581715007264}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.32it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.23it/s] [I 2025-08-18 03:17:55,062] Trial 0 finished with value: 27.198966333904103 and parameters: {'hidden_dim': 77, 'n_rnn_layers': 3, 'dropout': 0.02616070837448936}. Best is trial 0 with value: 27.198966333904103.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.64it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.09it/s][I 2025-08-18 03:18:26,352] Trial 1 finished with value: 22.557568932241942 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 4, 'dropout': 0.2921404350628224}. Best is trial 1 with value: 22.557568932241942.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.80it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.85it/s][I 2025-08-18 03:18:48,789] Trial 2 finished with value: 21.496976686290626 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 2, 'dropout': 0.14967726902250827}. Best is trial 2 with value: 21.496976686290626.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.23it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.50it/s][I 2025-08-18 03:19:54,476] Trial 3 finished with value: 26.183995696963702 and parameters: {'hidden_dim': 106, 'n_rnn_layers': 2, 'dropout': 0.16938746927907045}. Best is trial 2 with value: 21.496976686290626.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.57it/s][I 2025-08-18 03:20:36,301] Trial 4 finished with value: 27.038899771531533 and parameters: {'hidden_dim': 102, 'n_rnn_layers': 3, 'dropout': 0.16046082114213034}. Best is trial 2 with value: 21.496976686290626.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4523811475297867 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 244.45it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.12it/s][I 2025-08-18 03:21:02,201] Trial 5 finished with value: 21.16291809205656 and parameters: {'hidden_dim': 76, 'n_rnn_layers': 1, 'dropout': 0.4523811475297867}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.80it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s][I 2025-08-18 03:21:39,300] Trial 6 finished with value: 26.166674976890867 and parameters: {'hidden_dim': 49, 'n_rnn_layers': 2, 'dropout': 0.008638469893964995}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.92it/s][I 2025-08-18 03:22:32,255] Trial 7 finished with value: 25.544359007882772 and parameters: {'hidden_dim': 81, 'n_rnn_layers': 2, 'dropout': 0.4062976153326322}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.25it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.91it/s][I 2025-08-18 03:23:18,308] Trial 8 finished with value: 26.00673470947402 and parameters: {'hidden_dim': 67, 'n_rnn_layers': 3, 'dropout': 0.2887034997450735}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05335187031399824 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 248.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.89it/s][I 2025-08-18 03:23:46,549] Trial 9 finished with value: 23.675825989701167 and parameters: {'hidden_dim': 42, 'n_rnn_layers': 1, 'dropout': 0.05335187031399824}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48064269413671723 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.38it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.76it/s][I 2025-08-18 03:24:09,258] Trial 10 finished with value: 22.639473971432263 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 1, 'dropout': 0.48064269413671723}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18157662555373805 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.50it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.31it/s][I 2025-08-18 03:24:28,279] Trial 11 finished with value: 23.38303315128375 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.18157662555373805}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.38468577592707953 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 238.49it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.96it/s][I 2025-08-18 03:24:51,718] Trial 12 finished with value: 22.476827884007815 and parameters: {'hidden_dim': 31, 'n_rnn_layers': 1, 'dropout': 0.38468577592707953}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.13it/s][I 2025-08-18 03:25:15,913] Trial 13 finished with value: 22.552782246201836 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 2, 'dropout': 0.09142990454852312}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49957900994973525 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.37it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.75it/s][I 2025-08-18 03:25:47,372] Trial 14 finished with value: 21.568874421909275 and parameters: {'hidden_dim': 52, 'n_rnn_layers': 1, 'dropout': 0.49957900994973525}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.64it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.50it/s][I 2025-08-18 03:26:52,908] Trial 15 finished with value: 25.423857418357034 and parameters: {'hidden_dim': 125, 'n_rnn_layers': 2, 'dropout': 0.22512890050852152}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.89it/s][I 2025-08-18 03:27:23,057] Trial 16 finished with value: 22.491222474010353 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 4, 'dropout': 0.3497634200296411}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10032863471053488 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.87it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.17it/s][I 2025-08-18 03:27:58,227] Trial 17 finished with value: 23.14597520503566 and parameters: {'hidden_dim': 59, 'n_rnn_layers': 1, 'dropout': 0.10032863471053488}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.51it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.94it/s][I 2025-08-18 03:28:22,874] Trial 18 finished with value: 22.8958588432239 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 2, 'dropout': 0.435356353980119}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.67it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.43it/s][I 2025-08-18 03:28:46,254] Trial 19 finished with value: 22.844806310041513 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 3, 'dropout': 0.32741570069074627}. Best is trial 5 with value: 21.16291809205656.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4523811475297867 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 24.0 K | train
6 | V               | Linear           | 77     | train
-------------------------------------------------------------
24.1 K    Trainable params
0         Non-trainable params
24.1 K    Total params
0.096     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 76, 'n_rnn_layers': 1, 'dropout': 0.4523811475297867}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 190.97it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 206.47it/s]                                                                            Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/21 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s] Epoch 0:   5%|▍         | 1/21 [00:00<00:00, 86.51it/s]Epoch 0:   5%|▍         | 1/21 [00:00<00:00, 36.14it/s, train_loss=0.201]Epoch 0:  10%|▉         | 2/21 [00:00<00:00, 54.39it/s, train_loss=0.201]Epoch 0:  10%|▉         | 2/21 [00:00<00:00, 35.60it/s, train_loss=0.171]Epoch 0:  14%|█▍        | 3/21 [00:00<00:00, 46.23it/s, train_loss=0.171]Epoch 0:  14%|█▍        | 3/21 [00:00<00:00, 35.35it/s, train_loss=0.191]Epoch 0:  19%|█▉        | 4/21 [00:00<00:00, 42.89it/s, train_loss=0.191]Epoch 0:  19%|█▉        | 4/21 [00:00<00:00, 35.27it/s, train_loss=0.177]Epoch 0:  24%|██▍       | 5/21 [00:00<00:00, 41.03it/s, train_loss=0.177]Epoch 0:  24%|██▍       | 5/21 [00:00<00:00, 35.21it/s, train_loss=0.187]Epoch 0:  29%|██▊       | 6/21 [00:00<00:00, 39.91it/s, train_loss=0.187]Epoch 0:  29%|██▊       | 6/21 [00:00<00:00, 35.18it/s, train_loss=0.185]Epoch 0:  33%|███▎      | 7/21 [00:00<00:00, 39.04it/s, train_loss=0.185]Epoch 0:  33%|███▎      | 7/21 [00:00<00:00, 35.09it/s, train_loss=0.190]Epoch 0:  38%|███▊      | 8/21 [00:00<00:00, 38.42it/s, train_loss=0.190]Epoch 0:  38%|███▊      | 8/21 [00:00<00:00, 35.04it/s, train_loss=0.170]Epoch 0:  43%|████▎     | 9/21 [00:00<00:00, 37.99it/s, train_loss=0.170]Epoch 0:  43%|████▎     | 9/21 [00:00<00:00, 34.98it/s, train_loss=0.173]Epoch 0:  48%|████▊     | 10/21 [00:00<00:00, 37.63it/s, train_loss=0.173]Epoch 0:  48%|████▊     | 10/21 [00:00<00:00, 34.97it/s, train_loss=0.173]Epoch 0:  52%|█████▏    | 11/21 [00:00<00:00, 37.26it/s, train_loss=0.173]Epoch 0:  52%|█████▏    | 11/21 [00:00<00:00, 35.24it/s, train_loss=0.180]Epoch 0:  57%|█████▋    | 12/21 [00:00<00:00, 37.36it/s, train_loss=0.180]Epoch 0:  57%|█████▋    | 12/21 [00:00<00:00, 35.44it/s, train_loss=0.171]Epoch 0:  62%|██████▏   | 13/21 [00:00<00:00, 37.52it/s, train_loss=0.171]Epoch 0:  62%|██████▏   | 13/21 [00:00<00:00, 35.42it/s, train_loss=0.171]Epoch 0:  67%|██████▋   | 14/21 [00:00<00:00, 37.33it/s, train_loss=0.171]Epoch 0:  67%|██████▋   | 14/21 [00:00<00:00, 35.41it/s, train_loss=0.177]Epoch 0:  71%|███████▏  | 15/21 [00:00<00:00, 37.11it/s, train_loss=0.177]Epoch 0:  71%|███████▏  | 15/21 [00:00<00:00, 35.38it/s, train_loss=0.162]Epoch 0:  76%|███████▌  | 16/21 [00:00<00:00, 36.92it/s, train_loss=0.162]Epoch 0:  76%|███████▌  | 16/21 [00:00<00:00, 35.36it/s, train_loss=0.171]Epoch 0:  81%|████████  | 17/21 [00:00<00:00, 36.76it/s, train_loss=0.171]Epoch 0:  81%|████████  | 17/21 [00:00<00:00, 35.48it/s, train_loss=0.156]Epoch 0:  86%|████████▌ | 18/21 [00:00<00:00, 36.90it/s, train_loss=0.156]Epoch 0:  86%|████████▌ | 18/21 [00:00<00:00, 35.48it/s, train_loss=0.159]Epoch 0:  90%|█████████ | 19/21 [00:00<00:00, 36.86it/s, train_loss=0.159]Epoch 0:  90%|█████████ | 19/21 [00:00<00:00, 35.46it/s, train_loss=0.173]Epoch 0:  95%|█████████▌| 20/21 [00:00<00:00, 36.75it/s, train_loss=0.173]Epoch 0:  95%|█████████▌| 20/21 [00:00<00:00, 35.43it/s, train_loss=0.158]Epoch 0: 100%|██████████| 21/21 [00:00<00:00, 36.67it/s, train_loss=0.158]Epoch 0: 100%|██████████| 21/21 [00:00<00:00, 35.41it/s, train_loss=0.167]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 126.99it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 141.97it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 149.79it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 144.77it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 128.45it/s][A
                                                                       [AEpoch 0: 100%|██████████| 21/21 [00:00<00:00, 31.71it/s, train_loss=0.167, val_loss=0.134]Epoch 0: 100%|██████████| 21/21 [00:00<00:00, 31.66it/s, train_loss=0.167, val_loss=0.134]Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.167, val_loss=0.134]         Epoch 1:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.167, val_loss=0.134]Epoch 1:   5%|▍         | 1/21 [00:00<00:00, 96.30it/s, train_loss=0.167, val_loss=0.134]Epoch 1:   5%|▍         | 1/21 [00:00<00:00, 36.80it/s, train_loss=0.159, val_loss=0.134]Epoch 1:  10%|▉         | 2/21 [00:00<00:00, 54.10it/s, train_loss=0.159, val_loss=0.134]Epoch 1:  10%|▉         | 2/21 [00:00<00:00, 37.19it/s, train_loss=0.154, val_loss=0.134]Epoch 1:  14%|█▍        | 3/21 [00:00<00:00, 47.15it/s, train_loss=0.154, val_loss=0.134]Epoch 1:  14%|█▍        | 3/21 [00:00<00:00, 36.42it/s, train_loss=0.159, val_loss=0.134]Epoch 1:  19%|█▉        | 4/21 [00:00<00:00, 43.81it/s, train_loss=0.159, val_loss=0.134]Epoch 1:  19%|█▉        | 4/21 [00:00<00:00, 36.02it/s, train_loss=0.147, val_loss=0.134]Epoch 1:  24%|██▍       | 5/21 [00:00<00:00, 41.85it/s, train_loss=0.147, val_loss=0.134]Epoch 1:  24%|██▍       | 5/21 [00:00<00:00, 35.77it/s, train_loss=0.143, val_loss=0.134]Epoch 1:  29%|██▊       | 6/21 [00:00<00:00, 40.59it/s, train_loss=0.143, val_loss=0.134]Epoch 1:  29%|██▊       | 6/21 [00:00<00:00, 35.70it/s, train_loss=0.119, val_loss=0.134]Epoch 1:  33%|███▎      | 7/21 [00:00<00:00, 39.67it/s, train_loss=0.119, val_loss=0.134]Epoch 1:  33%|███▎      | 7/21 [00:00<00:00, 35.56it/s, train_loss=0.142, val_loss=0.134]Epoch 1:  38%|███▊      | 8/21 [00:00<00:00, 38.81it/s, train_loss=0.142, val_loss=0.134]Epoch 1:  38%|███▊      | 8/21 [00:00<00:00, 35.85it/s, train_loss=0.130, val_loss=0.134]Epoch 1:  43%|████▎     | 9/21 [00:00<00:00, 38.73it/s, train_loss=0.130, val_loss=0.134]Epoch 1:  43%|████▎     | 9/21 [00:00<00:00, 36.06it/s, train_loss=0.133, val_loss=0.134]Epoch 1:  48%|████▊     | 10/21 [00:00<00:00, 38.83it/s, train_loss=0.133, val_loss=0.134]Epoch 1:  48%|████▊     | 10/21 [00:00<00:00, 35.98it/s, train_loss=0.118, val_loss=0.134]Epoch 1:  52%|█████▏    | 11/21 [00:00<00:00, 38.32it/s, train_loss=0.118, val_loss=0.134]Epoch 1:  52%|█████▏    | 11/21 [00:00<00:00, 35.88it/s, train_loss=0.123, val_loss=0.134]Epoch 1:  57%|█████▋    | 12/21 [00:00<00:00, 37.98it/s, train_loss=0.123, val_loss=0.134]Epoch 1:  57%|█████▋    | 12/21 [00:00<00:00, 35.81it/s, train_loss=0.111, val_loss=0.134]Epoch 1:  62%|██████▏   | 13/21 [00:00<00:00, 37.82it/s, train_loss=0.111, val_loss=0.134]Epoch 1:  62%|██████▏   | 13/21 [00:00<00:00, 35.96it/s, train_loss=0.101, val_loss=0.134]Epoch 1:  67%|██████▋   | 14/21 [00:00<00:00, 37.78it/s, train_loss=0.101, val_loss=0.134]Epoch 1:  67%|██████▋   | 14/21 [00:00<00:00, 36.08it/s, train_loss=0.103, val_loss=0.134]Epoch 1:  71%|███████▏  | 15/21 [00:00<00:00, 37.70it/s, train_loss=0.103, val_loss=0.134]Epoch 1:  71%|███████▏  | 15/21 [00:00<00:00, 36.00it/s, train_loss=0.0976, val_loss=0.134]Epoch 1:  76%|███████▌  | 16/21 [00:00<00:00, 37.65it/s, train_loss=0.0976, val_loss=0.134]Epoch 1:  76%|███████▌  | 16/21 [00:00<00:00, 35.96it/s, train_loss=0.0958, val_loss=0.134]Epoch 1:  81%|████████  | 17/21 [00:00<00:00, 37.50it/s, train_loss=0.0958, val_loss=0.134]Epoch 1:  81%|████████  | 17/21 [00:00<00:00, 35.91it/s, train_loss=0.113, val_loss=0.134] Epoch 1:  86%|████████▌ | 18/21 [00:00<00:00, 37.39it/s, train_loss=0.113, val_loss=0.134]Epoch 1:  86%|████████▌ | 18/21 [00:00<00:00, 36.04it/s, train_loss=0.0833, val_loss=0.134]Epoch 1:  90%|█████████ | 19/21 [00:00<00:00, 37.31it/s, train_loss=0.0833, val_loss=0.134]Epoch 1:  90%|█████████ | 19/21 [00:00<00:00, 36.13it/s, train_loss=0.0874, val_loss=0.134]Epoch 1:  95%|█████████▌| 20/21 [00:00<00:00, 37.44it/s, train_loss=0.0874, val_loss=0.134]Epoch 1:  95%|█████████▌| 20/21 [00:00<00:00, 36.08it/s, train_loss=0.0832, val_loss=0.134]Epoch 1: 100%|██████████| 21/21 [00:00<00:00, 37.32it/s, train_loss=0.0832, val_loss=0.134]Epoch 1: 100%|██████████| 21/21 [00:00<00:00, 36.03it/s, train_loss=0.0711, val_loss=0.134]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 118.40it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 136.50it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 149.08it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 140.93it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 120.11it/s][A
                                                                       [AEpoch 1: 100%|██████████| 21/21 [00:00<00:00, 32.20it/s, train_loss=0.0711, val_loss=0.058]Epoch 1: 100%|██████████| 21/21 [00:00<00:00, 32.17it/s, train_loss=0.0711, val_loss=0.058]Epoch 1:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0711, val_loss=0.058]         Epoch 2:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0711, val_loss=0.058]Epoch 2:   5%|▍         | 1/21 [00:00<00:00, 116.99it/s, train_loss=0.0711, val_loss=0.058]Epoch 2:   5%|▍         | 1/21 [00:00<00:00, 37.66it/s, train_loss=0.0651, val_loss=0.058] Epoch 2:  10%|▉         | 2/21 [00:00<00:00, 57.74it/s, train_loss=0.0651, val_loss=0.058]Epoch 2:  10%|▉         | 2/21 [00:00<00:00, 36.59it/s, train_loss=0.0736, val_loss=0.058]Epoch 2:  14%|█▍        | 3/21 [00:00<00:00, 47.87it/s, train_loss=0.0736, val_loss=0.058]Epoch 2:  14%|█▍        | 3/21 [00:00<00:00, 36.18it/s, train_loss=0.0483, val_loss=0.058]Epoch 2:  19%|█▉        | 4/21 [00:00<00:00, 44.01it/s, train_loss=0.0483, val_loss=0.058]Epoch 2:  19%|█▉        | 4/21 [00:00<00:00, 35.95it/s, train_loss=0.0464, val_loss=0.058]Epoch 2:  24%|██▍       | 5/21 [00:00<00:00, 41.90it/s, train_loss=0.0464, val_loss=0.058]Epoch 2:  24%|██▍       | 5/21 [00:00<00:00, 36.42it/s, train_loss=0.0401, val_loss=0.058]Epoch 2:  29%|██▊       | 6/21 [00:00<00:00, 41.20it/s, train_loss=0.0401, val_loss=0.058]Epoch 2:  29%|██▊       | 6/21 [00:00<00:00, 36.66it/s, train_loss=0.0278, val_loss=0.058]Epoch 2:  33%|███▎      | 7/21 [00:00<00:00, 40.79it/s, train_loss=0.0278, val_loss=0.058]Epoch 2:  33%|███▎      | 7/21 [00:00<00:00, 36.47it/s, train_loss=0.0332, val_loss=0.058]Epoch 2:  38%|███▊      | 8/21 [00:00<00:00, 40.02it/s, train_loss=0.0332, val_loss=0.058]Epoch 2:  38%|███▊      | 8/21 [00:00<00:00, 36.33it/s, train_loss=0.0292, val_loss=0.058]Epoch 2:  43%|████▎     | 9/21 [00:00<00:00, 39.41it/s, train_loss=0.0292, val_loss=0.058]Epoch 2:  43%|████▎     | 9/21 [00:00<00:00, 36.21it/s, train_loss=0.0244, val_loss=0.058]Epoch 2:  48%|████▊     | 10/21 [00:00<00:00, 38.78it/s, train_loss=0.0244, val_loss=0.058]Epoch 2:  48%|████▊     | 10/21 [00:00<00:00, 36.32it/s, train_loss=0.0208, val_loss=0.058]Epoch 2:  52%|█████▏    | 11/21 [00:00<00:00, 38.68it/s, train_loss=0.0208, val_loss=0.058]Epoch 2:  52%|█████▏    | 11/21 [00:00<00:00, 36.21it/s, train_loss=0.0178, val_loss=0.058]Epoch 2:  57%|█████▋    | 12/21 [00:00<00:00, 38.47it/s, train_loss=0.0178, val_loss=0.058]Epoch 2:  57%|█████▋    | 12/21 [00:00<00:00, 36.12it/s, train_loss=0.0212, val_loss=0.058]Epoch 2:  62%|██████▏   | 13/21 [00:00<00:00, 38.02it/s, train_loss=0.0212, val_loss=0.058]Epoch 2:  62%|██████▏   | 13/21 [00:00<00:00, 35.93it/s, train_loss=0.0265, val_loss=0.058]Epoch 2:  67%|██████▋   | 14/21 [00:00<00:00, 37.84it/s, train_loss=0.0265, val_loss=0.058]Epoch 2:  67%|██████▋   | 14/21 [00:00<00:00, 35.86it/s, train_loss=0.0273, val_loss=0.058]Epoch 2:  71%|███████▏  | 15/21 [00:00<00:00, 37.67it/s, train_loss=0.0273, val_loss=0.058]Epoch 2:  71%|███████▏  | 15/21 [00:00<00:00, 35.80it/s, train_loss=0.0275, val_loss=0.058]Epoch 2:  76%|███████▌  | 16/21 [00:00<00:00, 37.48it/s, train_loss=0.0275, val_loss=0.058]Epoch 2:  76%|███████▌  | 16/21 [00:00<00:00, 35.77it/s, train_loss=0.0236, val_loss=0.058]Epoch 2:  81%|████████  | 17/21 [00:00<00:00, 37.26it/s, train_loss=0.0236, val_loss=0.058]Epoch 2:  81%|████████  | 17/21 [00:00<00:00, 35.89it/s, train_loss=0.0204, val_loss=0.058]Epoch 2:  86%|████████▌ | 18/21 [00:00<00:00, 37.26it/s, train_loss=0.0204, val_loss=0.058]Epoch 2:  86%|████████▌ | 18/21 [00:00<00:00, 35.99it/s, train_loss=0.0192, val_loss=0.058]Epoch 2:  90%|█████████ | 19/21 [00:00<00:00, 37.42it/s, train_loss=0.0192, val_loss=0.058]Epoch 2:  90%|█████████ | 19/21 [00:00<00:00, 35.98it/s, train_loss=0.0201, val_loss=0.058]Epoch 2:  95%|█████████▌| 20/21 [00:00<00:00, 37.33it/s, train_loss=0.0201, val_loss=0.058]Epoch 2:  95%|█████████▌| 20/21 [00:00<00:00, 35.95it/s, train_loss=0.0145, val_loss=0.058]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 21/21 [00:00<00:00, 37.13it/s, train_loss=0.0145, val_loss=0.058]Epoch 2: 100%|██████████| 21/21 [00:00<00:00, 36.07it/s, train_loss=0.0138, val_loss=0.058]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 148.36it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 172.68it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 184.86it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 149.51it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 124.31it/s][A
                                                                       [AEpoch 2: 100%|██████████| 21/21 [00:00<00:00, 32.28it/s, train_loss=0.0138, val_loss=0.0176]Epoch 2: 100%|██████████| 21/21 [00:00<00:00, 32.23it/s, train_loss=0.0138, val_loss=0.0176]Epoch 2:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0138, val_loss=0.0176]         Epoch 3:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0138, val_loss=0.0176]Epoch 3:   5%|▍         | 1/21 [00:00<00:00, 106.07it/s, train_loss=0.0138, val_loss=0.0176]Epoch 3:   5%|▍         | 1/21 [00:00<00:00, 37.36it/s, train_loss=0.018, val_loss=0.0176]  Epoch 3:  10%|▉         | 2/21 [00:00<00:00, 55.91it/s, train_loss=0.018, val_loss=0.0176]Epoch 3:  10%|▉         | 2/21 [00:00<00:00, 36.69it/s, train_loss=0.0166, val_loss=0.0176]Epoch 3:  14%|█▍        | 3/21 [00:00<00:00, 48.13it/s, train_loss=0.0166, val_loss=0.0176]Epoch 3:  14%|█▍        | 3/21 [00:00<00:00, 36.27it/s, train_loss=0.0172, val_loss=0.0176]Epoch 3:  19%|█▉        | 4/21 [00:00<00:00, 44.08it/s, train_loss=0.0172, val_loss=0.0176]Epoch 3:  19%|█▉        | 4/21 [00:00<00:00, 36.01it/s, train_loss=0.0217, val_loss=0.0176]Epoch 3:  24%|██▍       | 5/21 [00:00<00:00, 41.95it/s, train_loss=0.0217, val_loss=0.0176]Epoch 3:  24%|██▍       | 5/21 [00:00<00:00, 35.87it/s, train_loss=0.0183, val_loss=0.0176]Epoch 3:  29%|██▊       | 6/21 [00:00<00:00, 40.63it/s, train_loss=0.0183, val_loss=0.0176]Epoch 3:  29%|██▊       | 6/21 [00:00<00:00, 35.75it/s, train_loss=0.0195, val_loss=0.0176]Epoch 3:  33%|███▎      | 7/21 [00:00<00:00, 39.55it/s, train_loss=0.0195, val_loss=0.0176]Epoch 3:  33%|███▎      | 7/21 [00:00<00:00, 36.01it/s, train_loss=0.0185, val_loss=0.0176]Epoch 3:  38%|███▊      | 8/21 [00:00<00:00, 39.39it/s, train_loss=0.0185, val_loss=0.0176]Epoch 3:  38%|███▊      | 8/21 [00:00<00:00, 35.91it/s, train_loss=0.0179, val_loss=0.0176]Epoch 3:  43%|████▎     | 9/21 [00:00<00:00, 39.00it/s, train_loss=0.0179, val_loss=0.0176]Epoch 3:  43%|████▎     | 9/21 [00:00<00:00, 35.84it/s, train_loss=0.0152, val_loss=0.0176]Epoch 3:  48%|████▊     | 10/21 [00:00<00:00, 38.65it/s, train_loss=0.0152, val_loss=0.0176]Epoch 3:  48%|████▊     | 10/21 [00:00<00:00, 35.83it/s, train_loss=0.0186, val_loss=0.0176]Epoch 3:  52%|█████▏    | 11/21 [00:00<00:00, 38.19it/s, train_loss=0.0186, val_loss=0.0176]Epoch 3:  52%|█████▏    | 11/21 [00:00<00:00, 36.01it/s, train_loss=0.0169, val_loss=0.0176]Epoch 3:  57%|█████▋    | 12/21 [00:00<00:00, 38.14it/s, train_loss=0.0169, val_loss=0.0176]Epoch 3:  57%|█████▋    | 12/21 [00:00<00:00, 36.13it/s, train_loss=0.020, val_loss=0.0176] Epoch 3:  62%|██████▏   | 13/21 [00:00<00:00, 38.24it/s, train_loss=0.020, val_loss=0.0176]Epoch 3:  62%|██████▏   | 13/21 [00:00<00:00, 36.08it/s, train_loss=0.0147, val_loss=0.0176]Epoch 3:  67%|██████▋   | 14/21 [00:00<00:00, 38.02it/s, train_loss=0.0147, val_loss=0.0176]Epoch 3:  67%|██████▋   | 14/21 [00:00<00:00, 36.03it/s, train_loss=0.0155, val_loss=0.0176]Epoch 3:  71%|███████▏  | 15/21 [00:00<00:00, 37.82it/s, train_loss=0.0155, val_loss=0.0176]Epoch 3:  71%|███████▏  | 15/21 [00:00<00:00, 35.96it/s, train_loss=0.0137, val_loss=0.0176]Epoch 3:  76%|███████▌  | 16/21 [00:00<00:00, 37.52it/s, train_loss=0.0137, val_loss=0.0176]Epoch 3:  76%|███████▌  | 16/21 [00:00<00:00, 36.07it/s, train_loss=0.016, val_loss=0.0176] Epoch 3:  81%|████████  | 17/21 [00:00<00:00, 37.56it/s, train_loss=0.016, val_loss=0.0176]Epoch 3:  81%|████████  | 17/21 [00:00<00:00, 36.16it/s, train_loss=0.015, val_loss=0.0176]Epoch 3:  86%|████████▌ | 18/21 [00:00<00:00, 37.64it/s, train_loss=0.015, val_loss=0.0176]Epoch 3:  86%|████████▌ | 18/21 [00:00<00:00, 36.11it/s, train_loss=0.0128, val_loss=0.0176]Epoch 3:  90%|█████████ | 19/21 [00:00<00:00, 37.51it/s, train_loss=0.0128, val_loss=0.0176]Epoch 3:  90%|█████████ | 19/21 [00:00<00:00, 36.05it/s, train_loss=0.0133, val_loss=0.0176]Epoch 3:  95%|█████████▌| 20/21 [00:00<00:00, 37.33it/s, train_loss=0.0133, val_loss=0.0176]Epoch 3:  95%|█████████▌| 20/21 [00:00<00:00, 35.98it/s, train_loss=0.015, val_loss=0.0176] Epoch 3: 100%|██████████| 21/21 [00:00<00:00, 37.17it/s, train_loss=0.015, val_loss=0.0176]Epoch 3: 100%|██████████| 21/21 [00:00<00:00, 35.92it/s, train_loss=0.0144, val_loss=0.0176]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 129.17it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 148.51it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 160.35it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 145.90it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 128.94it/s][A
                                                                       [AEpoch 3: 100%|██████████| 21/21 [00:00<00:00, 32.11it/s, train_loss=0.0144, val_loss=0.0174]Epoch 3: 100%|██████████| 21/21 [00:00<00:00, 32.06it/s, train_loss=0.0144, val_loss=0.0174]Epoch 3:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0144, val_loss=0.0174]         Epoch 4:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0144, val_loss=0.0174]Epoch 4:   5%|▍         | 1/21 [00:00<00:00, 95.67it/s, train_loss=0.0144, val_loss=0.0174]Epoch 4:   5%|▍         | 1/21 [00:00<00:00, 36.71it/s, train_loss=0.0154, val_loss=0.0174]Epoch 4:  10%|▉         | 2/21 [00:00<00:00, 54.28it/s, train_loss=0.0154, val_loss=0.0174]Epoch 4:  10%|▉         | 2/21 [00:00<00:00, 36.90it/s, train_loss=0.0136, val_loss=0.0174]Epoch 4:  14%|█▍        | 3/21 [00:00<00:00, 47.05it/s, train_loss=0.0136, val_loss=0.0174]Epoch 4:  14%|█▍        | 3/21 [00:00<00:00, 36.27it/s, train_loss=0.0145, val_loss=0.0174]Epoch 4:  19%|█▉        | 4/21 [00:00<00:00, 44.24it/s, train_loss=0.0145, val_loss=0.0174]Epoch 4:  19%|█▉        | 4/21 [00:00<00:00, 36.08it/s, train_loss=0.0148, val_loss=0.0174]Epoch 4:  24%|██▍       | 5/21 [00:00<00:00, 42.13it/s, train_loss=0.0148, val_loss=0.0174]Epoch 4:  24%|██▍       | 5/21 [00:00<00:00, 35.93it/s, train_loss=0.0121, val_loss=0.0174]Epoch 4:  29%|██▊       | 6/21 [00:00<00:00, 40.75it/s, train_loss=0.0121, val_loss=0.0174]Epoch 4:  29%|██▊       | 6/21 [00:00<00:00, 36.33it/s, train_loss=0.0127, val_loss=0.0174]Epoch 4:  33%|███▎      | 7/21 [00:00<00:00, 40.35it/s, train_loss=0.0127, val_loss=0.0174]Epoch 4:  33%|███▎      | 7/21 [00:00<00:00, 36.42it/s, train_loss=0.013, val_loss=0.0174] Epoch 4:  38%|███▊      | 8/21 [00:00<00:00, 40.01it/s, train_loss=0.013, val_loss=0.0174]Epoch 4:  38%|███▊      | 8/21 [00:00<00:00, 36.29it/s, train_loss=0.013, val_loss=0.0174]Epoch 4:  43%|████▎     | 9/21 [00:00<00:00, 39.41it/s, train_loss=0.013, val_loss=0.0174]Epoch 4:  43%|████▎     | 9/21 [00:00<00:00, 36.18it/s, train_loss=0.0118, val_loss=0.0174]Epoch 4:  48%|████▊     | 10/21 [00:00<00:00, 38.92it/s, train_loss=0.0118, val_loss=0.0174]Epoch 4:  48%|████▊     | 10/21 [00:00<00:00, 36.07it/s, train_loss=0.0129, val_loss=0.0174]Epoch 4:  52%|█████▏    | 11/21 [00:00<00:00, 38.50it/s, train_loss=0.0129, val_loss=0.0174]Epoch 4:  52%|█████▏    | 11/21 [00:00<00:00, 36.21it/s, train_loss=0.0118, val_loss=0.0174]Epoch 4:  57%|█████▋    | 12/21 [00:00<00:00, 38.35it/s, train_loss=0.0118, val_loss=0.0174]Epoch 4:  57%|█████▋    | 12/21 [00:00<00:00, 36.35it/s, train_loss=0.0125, val_loss=0.0174]Epoch 4:  62%|██████▏   | 13/21 [00:00<00:00, 38.38it/s, train_loss=0.0125, val_loss=0.0174]Epoch 4:  62%|██████▏   | 13/21 [00:00<00:00, 36.24it/s, train_loss=0.0125, val_loss=0.0174]Epoch 4:  67%|██████▋   | 14/21 [00:00<00:00, 38.09it/s, train_loss=0.0125, val_loss=0.0174]Epoch 4:  67%|██████▋   | 14/21 [00:00<00:00, 36.35it/s, train_loss=0.0121, val_loss=0.0174]Epoch 4:  71%|███████▏  | 15/21 [00:00<00:00, 38.03it/s, train_loss=0.0121, val_loss=0.0174]Epoch 4:  71%|███████▏  | 15/21 [00:00<00:00, 36.46it/s, train_loss=0.0135, val_loss=0.0174]Epoch 4:  76%|███████▌  | 16/21 [00:00<00:00, 38.14it/s, train_loss=0.0135, val_loss=0.0174]Epoch 4:  76%|███████▌  | 16/21 [00:00<00:00, 36.38it/s, train_loss=0.0114, val_loss=0.0174]Epoch 4:  81%|████████  | 17/21 [00:00<00:00, 37.95it/s, train_loss=0.0114, val_loss=0.0174]Epoch 4:  81%|████████  | 17/21 [00:00<00:00, 36.30it/s, train_loss=0.012, val_loss=0.0174] Epoch 4:  86%|████████▌ | 18/21 [00:00<00:00, 37.75it/s, train_loss=0.012, val_loss=0.0174]Epoch 4:  86%|████████▌ | 18/21 [00:00<00:00, 36.22it/s, train_loss=0.0104, val_loss=0.0174]Epoch 4:  90%|█████████ | 19/21 [00:00<00:00, 37.59it/s, train_loss=0.0104, val_loss=0.0174]Epoch 4:  90%|█████████ | 19/21 [00:00<00:00, 36.13it/s, train_loss=0.0124, val_loss=0.0174]Epoch 4:  95%|█████████▌| 20/21 [00:00<00:00, 37.44it/s, train_loss=0.0124, val_loss=0.0174]Epoch 4:  95%|█████████▌| 20/21 [00:00<00:00, 36.08it/s, train_loss=0.0115, val_loss=0.0174]Epoch 4: 100%|██████████| 21/21 [00:00<00:00, 37.14it/s, train_loss=0.0115, val_loss=0.0174]Epoch 4: 100%|██████████| 21/21 [00:00<00:00, 35.97it/s, train_loss=0.00979, val_loss=0.0174]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 182.45it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 204.62it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 213.12it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 156.96it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 136.30it/s][A
                                                                       [AEpoch 4: 100%|██████████| 21/21 [00:00<00:00, 32.41it/s, train_loss=0.00979, val_loss=0.0124]Epoch 4: 100%|██████████| 21/21 [00:00<00:00, 32.34it/s, train_loss=0.00979, val_loss=0.0124]Epoch 4:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00979, val_loss=0.0124]         Epoch 5:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00979, val_loss=0.0124]Epoch 5:   5%|▍         | 1/21 [00:00<00:00, 110.07it/s, train_loss=0.00979, val_loss=0.0124]Epoch 5:   5%|▍         | 1/21 [00:00<00:00, 34.79it/s, train_loss=0.0108, val_loss=0.0124]  Epoch 5:  10%|▉         | 2/21 [00:00<00:00, 54.23it/s, train_loss=0.0108, val_loss=0.0124]Epoch 5:  10%|▉         | 2/21 [00:00<00:00, 34.98it/s, train_loss=0.0104, val_loss=0.0124]Epoch 5:  14%|█▍        | 3/21 [00:00<00:00, 45.84it/s, train_loss=0.0104, val_loss=0.0124]Epoch 5:  14%|█▍        | 3/21 [00:00<00:00, 34.97it/s, train_loss=0.011, val_loss=0.0124] Epoch 5:  19%|█▉        | 4/21 [00:00<00:00, 42.27it/s, train_loss=0.011, val_loss=0.0124]Epoch 5:  19%|█▉        | 4/21 [00:00<00:00, 35.68it/s, train_loss=0.00999, val_loss=0.0124]Epoch 5:  24%|██▍       | 5/21 [00:00<00:00, 41.19it/s, train_loss=0.00999, val_loss=0.0124]Epoch 5:  24%|██▍       | 5/21 [00:00<00:00, 36.08it/s, train_loss=0.00888, val_loss=0.0124]Epoch 5:  29%|██▊       | 6/21 [00:00<00:00, 40.94it/s, train_loss=0.00888, val_loss=0.0124]Epoch 5:  29%|██▊       | 6/21 [00:00<00:00, 35.96it/s, train_loss=0.0106, val_loss=0.0124] Epoch 5:  33%|███▎      | 7/21 [00:00<00:00, 40.04it/s, train_loss=0.0106, val_loss=0.0124]Epoch 5:  33%|███▎      | 7/21 [00:00<00:00, 35.85it/s, train_loss=0.0102, val_loss=0.0124]Epoch 5:  38%|███▊      | 8/21 [00:00<00:00, 39.36it/s, train_loss=0.0102, val_loss=0.0124]Epoch 5:  38%|███▊      | 8/21 [00:00<00:00, 35.77it/s, train_loss=0.00903, val_loss=0.0124]Epoch 5:  43%|████▎     | 9/21 [00:00<00:00, 38.77it/s, train_loss=0.00903, val_loss=0.0124]Epoch 5:  43%|████▎     | 9/21 [00:00<00:00, 35.66it/s, train_loss=0.00994, val_loss=0.0124]Epoch 5:  48%|████▊     | 10/21 [00:00<00:00, 38.29it/s, train_loss=0.00994, val_loss=0.0124]Epoch 5:  48%|████▊     | 10/21 [00:00<00:00, 35.90it/s, train_loss=0.0102, val_loss=0.0124] Epoch 5:  52%|█████▏    | 11/21 [00:00<00:00, 38.25it/s, train_loss=0.0102, val_loss=0.0124]Epoch 5:  52%|█████▏    | 11/21 [00:00<00:00, 36.05it/s, train_loss=0.00964, val_loss=0.0124]Epoch 5:  57%|█████▋    | 12/21 [00:00<00:00, 38.30it/s, train_loss=0.00964, val_loss=0.0124]Epoch 5:  57%|█████▋    | 12/21 [00:00<00:00, 35.99it/s, train_loss=0.00908, val_loss=0.0124]Epoch 5:  62%|██████▏   | 13/21 [00:00<00:00, 38.04it/s, train_loss=0.00908, val_loss=0.0124]Epoch 5:  62%|██████▏   | 13/21 [00:00<00:00, 35.91it/s, train_loss=0.00883, val_loss=0.0124]Epoch 5:  67%|██████▋   | 14/21 [00:00<00:00, 37.79it/s, train_loss=0.00883, val_loss=0.0124]Epoch 5:  67%|██████▋   | 14/21 [00:00<00:00, 35.83it/s, train_loss=0.00799, val_loss=0.0124]Epoch 5:  71%|███████▏  | 15/21 [00:00<00:00, 37.59it/s, train_loss=0.00799, val_loss=0.0124]Epoch 5:  71%|███████▏  | 15/21 [00:00<00:00, 35.76it/s, train_loss=0.00881, val_loss=0.0124]Epoch 5:  76%|███████▌  | 16/21 [00:00<00:00, 37.40it/s, train_loss=0.00881, val_loss=0.0124]Epoch 5:  76%|███████▌  | 16/21 [00:00<00:00, 35.70it/s, train_loss=0.00965, val_loss=0.0124]Epoch 5:  81%|████████  | 17/21 [00:00<00:00, 37.25it/s, train_loss=0.00965, val_loss=0.0124]Epoch 5:  81%|████████  | 17/21 [00:00<00:00, 35.69it/s, train_loss=0.00871, val_loss=0.0124]Epoch 5:  86%|████████▌ | 18/21 [00:00<00:00, 37.07it/s, train_loss=0.00871, val_loss=0.0124]Epoch 5:  86%|████████▌ | 18/21 [00:00<00:00, 35.79it/s, train_loss=0.00853, val_loss=0.0124]Epoch 5:  90%|█████████ | 19/21 [00:00<00:00, 37.20it/s, train_loss=0.00853, val_loss=0.0124]Epoch 5:  90%|█████████ | 19/21 [00:00<00:00, 35.77it/s, train_loss=0.00752, val_loss=0.0124]Epoch 5:  95%|█████████▌| 20/21 [00:00<00:00, 37.10it/s, train_loss=0.00752, val_loss=0.0124]Epoch 5:  95%|█████████▌| 20/21 [00:00<00:00, 35.74it/s, train_loss=0.00788, val_loss=0.0124]Epoch 5: 100%|██████████| 21/21 [00:00<00:00, 37.00it/s, train_loss=0.00788, val_loss=0.0124]Epoch 5: 100%|██████████| 21/21 [00:00<00:00, 35.73it/s, train_loss=0.00898, val_loss=0.0124]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 147.14it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 171.58it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 181.40it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 145.77it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 129.38it/s][A
                                                                       [AEpoch 5: 100%|██████████| 21/21 [00:00<00:00, 32.09it/s, train_loss=0.00898, val_loss=0.00832]Epoch 5: 100%|██████████| 21/21 [00:00<00:00, 32.04it/s, train_loss=0.00898, val_loss=0.00832]Epoch 5:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00898, val_loss=0.00832]         Epoch 6:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00898, val_loss=0.00832]Epoch 6:   5%|▍         | 1/21 [00:00<00:00, 107.04it/s, train_loss=0.00898, val_loss=0.00832]Epoch 6:   5%|▍         | 1/21 [00:00<00:00, 34.39it/s, train_loss=0.00783, val_loss=0.00832] Epoch 6:  10%|▉         | 2/21 [00:00<00:00, 53.49it/s, train_loss=0.00783, val_loss=0.00832]Epoch 6:  10%|▉         | 2/21 [00:00<00:00, 34.63it/s, train_loss=0.00846, val_loss=0.00832]Epoch 6:  14%|█▍        | 3/21 [00:00<00:00, 45.47it/s, train_loss=0.00846, val_loss=0.00832]Epoch 6:  14%|█▍        | 3/21 [00:00<00:00, 34.67it/s, train_loss=0.00791, val_loss=0.00832]Epoch 6:  19%|█▉        | 4/21 [00:00<00:00, 41.94it/s, train_loss=0.00791, val_loss=0.00832]Epoch 6:  19%|█▉        | 4/21 [00:00<00:00, 35.44it/s, train_loss=0.00769, val_loss=0.00832]Epoch 6:  24%|██▍       | 5/21 [00:00<00:00, 40.90it/s, train_loss=0.00769, val_loss=0.00832]Epoch 6:  24%|██▍       | 5/21 [00:00<00:00, 35.91it/s, train_loss=0.00861, val_loss=0.00832]Epoch 6:  29%|██▊       | 6/21 [00:00<00:00, 40.61it/s, train_loss=0.00861, val_loss=0.00832]Epoch 6:  29%|██▊       | 6/21 [00:00<00:00, 35.75it/s, train_loss=0.0078, val_loss=0.00832] Epoch 6:  33%|███▎      | 7/21 [00:00<00:00, 39.85it/s, train_loss=0.0078, val_loss=0.00832]Epoch 6:  33%|███▎      | 7/21 [00:00<00:00, 35.66it/s, train_loss=0.00791, val_loss=0.00832]Epoch 6:  38%|███▊      | 8/21 [00:00<00:00, 39.15it/s, train_loss=0.00791, val_loss=0.00832]Epoch 6:  38%|███▊      | 8/21 [00:00<00:00, 35.57it/s, train_loss=0.00751, val_loss=0.00832]Epoch 6:  43%|████▎     | 9/21 [00:00<00:00, 38.60it/s, train_loss=0.00751, val_loss=0.00832]Epoch 6:  43%|████▎     | 9/21 [00:00<00:00, 35.48it/s, train_loss=0.00792, val_loss=0.00832]Epoch 6:  48%|████▊     | 10/21 [00:00<00:00, 38.23it/s, train_loss=0.00792, val_loss=0.00832]Epoch 6:  48%|████▊     | 10/21 [00:00<00:00, 35.74it/s, train_loss=0.00712, val_loss=0.00832]Epoch 6:  52%|█████▏    | 11/21 [00:00<00:00, 38.06it/s, train_loss=0.00712, val_loss=0.00832]Epoch 6:  52%|█████▏    | 11/21 [00:00<00:00, 35.93it/s, train_loss=0.00802, val_loss=0.00832]Epoch 6:  57%|█████▋    | 12/21 [00:00<00:00, 38.24it/s, train_loss=0.00802, val_loss=0.00832]Epoch 6:  57%|█████▋    | 12/21 [00:00<00:00, 35.88it/s, train_loss=0.00744, val_loss=0.00832]Epoch 6:  62%|██████▏   | 13/21 [00:00<00:00, 37.97it/s, train_loss=0.00744, val_loss=0.00832]Epoch 6:  62%|██████▏   | 13/21 [00:00<00:00, 35.82it/s, train_loss=0.00831, val_loss=0.00832]Epoch 6:  67%|██████▋   | 14/21 [00:00<00:00, 37.67it/s, train_loss=0.00831, val_loss=0.00832]Epoch 6:  67%|██████▋   | 14/21 [00:00<00:00, 35.98it/s, train_loss=0.00657, val_loss=0.00832]Epoch 6:  71%|███████▏  | 15/21 [00:00<00:00, 37.68it/s, train_loss=0.00657, val_loss=0.00832]Epoch 6:  71%|███████▏  | 15/21 [00:00<00:00, 36.09it/s, train_loss=0.00762, val_loss=0.00832]Epoch 6:  76%|███████▌  | 16/21 [00:00<00:00, 37.77it/s, train_loss=0.00762, val_loss=0.00832]Epoch 6:  76%|███████▌  | 16/21 [00:00<00:00, 36.03it/s, train_loss=0.00724, val_loss=0.00832]Epoch 6:  81%|████████  | 17/21 [00:00<00:00, 37.59it/s, train_loss=0.00724, val_loss=0.00832]Epoch 6:  81%|████████  | 17/21 [00:00<00:00, 35.94it/s, train_loss=0.0074, val_loss=0.00832] Epoch 6:  86%|████████▌ | 18/21 [00:00<00:00, 37.41it/s, train_loss=0.0074, val_loss=0.00832]Epoch 6:  86%|████████▌ | 18/21 [00:00<00:00, 35.87it/s, train_loss=0.0072, val_loss=0.00832]Epoch 6:  90%|█████████ | 19/21 [00:00<00:00, 37.22it/s, train_loss=0.0072, val_loss=0.00832]Epoch 6:  90%|█████████ | 19/21 [00:00<00:00, 35.82it/s, train_loss=0.0071, val_loss=0.00832]Epoch 6:  95%|█████████▌| 20/21 [00:00<00:00, 37.12it/s, train_loss=0.0071, val_loss=0.00832]Epoch 6:  95%|█████████▌| 20/21 [00:00<00:00, 35.75it/s, train_loss=0.0074, val_loss=0.00832]Epoch 6: 100%|██████████| 21/21 [00:00<00:00, 36.94it/s, train_loss=0.0074, val_loss=0.00832]Epoch 6: 100%|██████████| 21/21 [00:00<00:00, 35.84it/s, train_loss=0.00632, val_loss=0.00832]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 131.57it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 154.80it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 165.89it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 135.48it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 122.55it/s][A
                                                                       [AEpoch 6: 100%|██████████| 21/21 [00:00<00:00, 32.03it/s, train_loss=0.00632, val_loss=0.00728]Epoch 6: 100%|██████████| 21/21 [00:00<00:00, 31.98it/s, train_loss=0.00632, val_loss=0.00728]Epoch 6:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00632, val_loss=0.00728]         Epoch 7:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00632, val_loss=0.00728]Epoch 7:   5%|▍         | 1/21 [00:00<00:00, 104.04it/s, train_loss=0.00632, val_loss=0.00728]Epoch 7:   5%|▍         | 1/21 [00:00<00:00, 34.02it/s, train_loss=0.00702, val_loss=0.00728] Epoch 7:  10%|▉         | 2/21 [00:00<00:00, 53.04it/s, train_loss=0.00702, val_loss=0.00728]Epoch 7:  10%|▉         | 2/21 [00:00<00:00, 34.48it/s, train_loss=0.00738, val_loss=0.00728]Epoch 7:  14%|█▍        | 3/21 [00:00<00:00, 45.61it/s, train_loss=0.00738, val_loss=0.00728]Epoch 7:  14%|█▍        | 3/21 [00:00<00:00, 34.79it/s, train_loss=0.00753, val_loss=0.00728]Epoch 7:  19%|█▉        | 4/21 [00:00<00:00, 42.35it/s, train_loss=0.00753, val_loss=0.00728]Epoch 7:  19%|█▉        | 4/21 [00:00<00:00, 35.68it/s, train_loss=0.00701, val_loss=0.00728]Epoch 7:  24%|██▍       | 5/21 [00:00<00:00, 41.19it/s, train_loss=0.00701, val_loss=0.00728]Epoch 7:  24%|██▍       | 5/21 [00:00<00:00, 36.14it/s, train_loss=0.00691, val_loss=0.00728]Epoch 7:  29%|██▊       | 6/21 [00:00<00:00, 41.00it/s, train_loss=0.00691, val_loss=0.00728]Epoch 7:  29%|██▊       | 6/21 [00:00<00:00, 35.99it/s, train_loss=0.0068, val_loss=0.00728] Epoch 7:  33%|███▎      | 7/21 [00:00<00:00, 39.88it/s, train_loss=0.0068, val_loss=0.00728]Epoch 7:  33%|███▎      | 7/21 [00:00<00:00, 35.75it/s, train_loss=0.00676, val_loss=0.00728]Epoch 7:  38%|███▊      | 8/21 [00:00<00:00, 39.26it/s, train_loss=0.00676, val_loss=0.00728]Epoch 7:  38%|███▊      | 8/21 [00:00<00:00, 35.67it/s, train_loss=0.00637, val_loss=0.00728]Epoch 7:  43%|████▎     | 9/21 [00:00<00:00, 38.74it/s, train_loss=0.00637, val_loss=0.00728]Epoch 7:  43%|████▎     | 9/21 [00:00<00:00, 35.59it/s, train_loss=0.00614, val_loss=0.00728]Epoch 7:  48%|████▊     | 10/21 [00:00<00:00, 38.19it/s, train_loss=0.00614, val_loss=0.00728]Epoch 7:  48%|████▊     | 10/21 [00:00<00:00, 35.83it/s, train_loss=0.00673, val_loss=0.00728]Epoch 7:  52%|█████▏    | 11/21 [00:00<00:00, 38.17it/s, train_loss=0.00673, val_loss=0.00728]Epoch 7:  52%|█████▏    | 11/21 [00:00<00:00, 35.89it/s, train_loss=0.00678, val_loss=0.00728]Epoch 7:  57%|█████▋    | 12/21 [00:00<00:00, 38.15it/s, train_loss=0.00678, val_loss=0.00728]Epoch 7:  57%|█████▋    | 12/21 [00:00<00:00, 35.81it/s, train_loss=0.00706, val_loss=0.00728]Epoch 7:  62%|██████▏   | 13/21 [00:00<00:00, 37.88it/s, train_loss=0.00706, val_loss=0.00728]Epoch 7:  62%|██████▏   | 13/21 [00:00<00:00, 35.74it/s, train_loss=0.00585, val_loss=0.00728]Epoch 7:  67%|██████▋   | 14/21 [00:00<00:00, 37.64it/s, train_loss=0.00585, val_loss=0.00728]Epoch 7:  67%|██████▋   | 14/21 [00:00<00:00, 35.68it/s, train_loss=0.00729, val_loss=0.00728]Epoch 7:  71%|███████▏  | 15/21 [00:00<00:00, 37.41it/s, train_loss=0.00729, val_loss=0.00728]Epoch 7:  71%|███████▏  | 15/21 [00:00<00:00, 35.61it/s, train_loss=0.00675, val_loss=0.00728]Epoch 7:  76%|███████▌  | 16/21 [00:00<00:00, 37.18it/s, train_loss=0.00675, val_loss=0.00728]Epoch 7:  76%|███████▌  | 16/21 [00:00<00:00, 35.75it/s, train_loss=0.00621, val_loss=0.00728]Epoch 7:  81%|████████  | 17/21 [00:00<00:00, 37.21it/s, train_loss=0.00621, val_loss=0.00728]Epoch 7:  81%|████████  | 17/21 [00:00<00:00, 35.80it/s, train_loss=0.00631, val_loss=0.00728]Epoch 7:  86%|████████▌ | 18/21 [00:00<00:00, 37.27it/s, train_loss=0.00631, val_loss=0.00728]Epoch 7:  86%|████████▌ | 18/21 [00:00<00:00, 35.76it/s, train_loss=0.00625, val_loss=0.00728]Epoch 7:  90%|█████████ | 19/21 [00:00<00:00, 37.13it/s, train_loss=0.00625, val_loss=0.00728]Epoch 7:  90%|█████████ | 19/21 [00:00<00:00, 35.71it/s, train_loss=0.006, val_loss=0.00728]  Epoch 7:  95%|█████████▌| 20/21 [00:00<00:00, 37.02it/s, train_loss=0.006, val_loss=0.00728]Epoch 7:  95%|█████████▌| 20/21 [00:00<00:00, 35.67it/s, train_loss=0.00585, val_loss=0.00728]Epoch 7: 100%|██████████| 21/21 [00:00<00:00, 36.89it/s, train_loss=0.00585, val_loss=0.00728]Epoch 7: 100%|██████████| 21/21 [00:00<00:00, 35.61it/s, train_loss=0.00662, val_loss=0.00728]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 172.83it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 168.05it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 172.34it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 155.04it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 134.65it/s][A
                                                                       [AEpoch 7: 100%|██████████| 21/21 [00:00<00:00, 32.11it/s, train_loss=0.00662, val_loss=0.00679]Epoch 7: 100%|██████████| 21/21 [00:00<00:00, 32.07it/s, train_loss=0.00662, val_loss=0.00679]Epoch 7:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00662, val_loss=0.00679]         Epoch 8:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00662, val_loss=0.00679]Epoch 8:   5%|▍         | 1/21 [00:00<00:00, 106.95it/s, train_loss=0.00662, val_loss=0.00679]Epoch 8:   5%|▍         | 1/21 [00:00<00:00, 37.33it/s, train_loss=0.00672, val_loss=0.00679] Epoch 8:  10%|▉         | 2/21 [00:00<00:00, 55.51it/s, train_loss=0.00672, val_loss=0.00679]Epoch 8:  10%|▉         | 2/21 [00:00<00:00, 37.49it/s, train_loss=0.00642, val_loss=0.00679]Epoch 8:  14%|█▍        | 3/21 [00:00<00:00, 49.07it/s, train_loss=0.00642, val_loss=0.00679]Epoch 8:  14%|█▍        | 3/21 [00:00<00:00, 36.70it/s, train_loss=0.00657, val_loss=0.00679]Epoch 8:  19%|█▉        | 4/21 [00:00<00:00, 44.41it/s, train_loss=0.00657, val_loss=0.00679]Epoch 8:  19%|█▉        | 4/21 [00:00<00:00, 36.25it/s, train_loss=0.00688, val_loss=0.00679]Epoch 8:  24%|██▍       | 5/21 [00:00<00:00, 42.25it/s, train_loss=0.00688, val_loss=0.00679]Epoch 8:  24%|██▍       | 5/21 [00:00<00:00, 35.99it/s, train_loss=0.00635, val_loss=0.00679]Epoch 8:  29%|██▊       | 6/21 [00:00<00:00, 40.84it/s, train_loss=0.00635, val_loss=0.00679]Epoch 8:  29%|██▊       | 6/21 [00:00<00:00, 35.80it/s, train_loss=0.00655, val_loss=0.00679]Epoch 8:  33%|███▎      | 7/21 [00:00<00:00, 39.63it/s, train_loss=0.00655, val_loss=0.00679]Epoch 8:  33%|███▎      | 7/21 [00:00<00:00, 35.66it/s, train_loss=0.00689, val_loss=0.00679]Epoch 8:  38%|███▊      | 8/21 [00:00<00:00, 37.11it/s, train_loss=0.00689, val_loss=0.00679]Epoch 8:  38%|███▊      | 8/21 [00:00<00:00, 34.05it/s, train_loss=0.00593, val_loss=0.00679]Epoch 8:  43%|████▎     | 9/21 [00:00<00:00, 34.93it/s, train_loss=0.00593, val_loss=0.00679]Epoch 8:  43%|████▎     | 9/21 [00:00<00:00, 32.71it/s, train_loss=0.00597, val_loss=0.00679]Epoch 8:  48%|████▊     | 10/21 [00:00<00:00, 33.54it/s, train_loss=0.00597, val_loss=0.00679]Epoch 8:  48%|████▊     | 10/21 [00:00<00:00, 31.50it/s, train_loss=0.00626, val_loss=0.00679]Epoch 8:  52%|█████▏    | 11/21 [00:00<00:00, 33.32it/s, train_loss=0.00626, val_loss=0.00679]Epoch 8:  52%|█████▏    | 11/21 [00:00<00:00, 31.58it/s, train_loss=0.0061, val_loss=0.00679] Epoch 8:  57%|█████▋    | 12/21 [00:00<00:00, 32.13it/s, train_loss=0.0061, val_loss=0.00679]Epoch 8:  57%|█████▋    | 12/21 [00:00<00:00, 30.71it/s, train_loss=0.00613, val_loss=0.00679]Epoch 8:  62%|██████▏   | 13/21 [00:00<00:00, 31.76it/s, train_loss=0.00613, val_loss=0.00679]Epoch 8:  62%|██████▏   | 13/21 [00:00<00:00, 30.41it/s, train_loss=0.00607, val_loss=0.00679]Epoch 8:  67%|██████▋   | 14/21 [00:00<00:00, 30.83it/s, train_loss=0.00607, val_loss=0.00679]Epoch 8:  67%|██████▋   | 14/21 [00:00<00:00, 29.75it/s, train_loss=0.00628, val_loss=0.00679]Epoch 8:  71%|███████▏  | 15/21 [00:00<00:00, 30.09it/s, train_loss=0.00628, val_loss=0.00679]Epoch 8:  71%|███████▏  | 15/21 [00:00<00:00, 29.06it/s, train_loss=0.00619, val_loss=0.00679]Epoch 8:  76%|███████▌  | 16/21 [00:00<00:00, 29.47it/s, train_loss=0.00619, val_loss=0.00679]Epoch 8:  76%|███████▌  | 16/21 [00:00<00:00, 28.53it/s, train_loss=0.00598, val_loss=0.00679]Epoch 8:  81%|████████  | 17/21 [00:00<00:00, 29.03it/s, train_loss=0.00598, val_loss=0.00679]Epoch 8:  81%|████████  | 17/21 [00:00<00:00, 28.15it/s, train_loss=0.00603, val_loss=0.00679]Epoch 8:  86%|████████▌ | 18/21 [00:00<00:00, 28.63it/s, train_loss=0.00603, val_loss=0.00679]Epoch 8:  86%|████████▌ | 18/21 [00:00<00:00, 27.83it/s, train_loss=0.00566, val_loss=0.00679]Epoch 8:  90%|█████████ | 19/21 [00:00<00:00, 28.29it/s, train_loss=0.00566, val_loss=0.00679]Epoch 8:  90%|█████████ | 19/21 [00:00<00:00, 27.57it/s, train_loss=0.00606, val_loss=0.00679]Epoch 8:  95%|█████████▌| 20/21 [00:00<00:00, 27.99it/s, train_loss=0.00606, val_loss=0.00679]Epoch 8:  95%|█████████▌| 20/21 [00:00<00:00, 27.31it/s, train_loss=0.00568, val_loss=0.00679]Epoch 8: 100%|██████████| 21/21 [00:00<00:00, 27.70it/s, train_loss=0.00568, val_loss=0.00679]Epoch 8: 100%|██████████| 21/21 [00:00<00:00, 27.06it/s, train_loss=0.00553, val_loss=0.00679]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.05it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 14.52it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 18.19it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 18.23it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 21.02it/s][A
                                                                      [AEpoch 8: 100%|██████████| 21/21 [00:01<00:00, 19.39it/s, train_loss=0.00553, val_loss=0.00636]Epoch 8: 100%|██████████| 21/21 [00:01<00:00, 19.13it/s, train_loss=0.00553, val_loss=0.00636]Epoch 8:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00553, val_loss=0.00636]         Epoch 9:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00553, val_loss=0.00636]Epoch 9:   5%|▍         | 1/21 [00:00<00:00, 22.50it/s, train_loss=0.00553, val_loss=0.00636]Epoch 9:   5%|▍         | 1/21 [00:00<00:01, 16.20it/s, train_loss=0.0063, val_loss=0.00636] Epoch 9:  10%|▉         | 2/21 [00:00<00:00, 22.52it/s, train_loss=0.0063, val_loss=0.00636]Epoch 9:  10%|▉         | 2/21 [00:00<00:01, 18.73it/s, train_loss=0.00606, val_loss=0.00636]Epoch 9:  14%|█▍        | 3/21 [00:00<00:00, 22.66it/s, train_loss=0.00606, val_loss=0.00636]Epoch 9:  14%|█▍        | 3/21 [00:00<00:00, 20.04it/s, train_loss=0.0061, val_loss=0.00636] Epoch 9:  19%|█▉        | 4/21 [00:00<00:00, 22.73it/s, train_loss=0.0061, val_loss=0.00636]Epoch 9:  19%|█▉        | 4/21 [00:00<00:00, 20.71it/s, train_loss=0.00537, val_loss=0.00636]Epoch 9:  24%|██▍       | 5/21 [00:00<00:00, 24.69it/s, train_loss=0.00537, val_loss=0.00636]Epoch 9:  24%|██▍       | 5/21 [00:00<00:00, 22.68it/s, train_loss=0.00545, val_loss=0.00636]Epoch 9:  29%|██▊       | 6/21 [00:00<00:00, 24.33it/s, train_loss=0.00545, val_loss=0.00636]Epoch 9:  29%|██▊       | 6/21 [00:00<00:00, 22.72it/s, train_loss=0.00602, val_loss=0.00636]Epoch 9:  33%|███▎      | 7/21 [00:00<00:00, 24.17it/s, train_loss=0.00602, val_loss=0.00636]Epoch 9:  33%|███▎      | 7/21 [00:00<00:00, 22.74it/s, train_loss=0.00588, val_loss=0.00636]Epoch 9:  38%|███▊      | 8/21 [00:00<00:00, 23.90it/s, train_loss=0.00588, val_loss=0.00636]Epoch 9:  38%|███▊      | 8/21 [00:00<00:00, 22.74it/s, train_loss=0.00615, val_loss=0.00636]Epoch 9:  43%|████▎     | 9/21 [00:00<00:00, 23.86it/s, train_loss=0.00615, val_loss=0.00636]Epoch 9:  43%|████▎     | 9/21 [00:00<00:00, 22.76it/s, train_loss=0.0067, val_loss=0.00636] Epoch 9:  48%|████▊     | 10/21 [00:00<00:00, 24.76it/s, train_loss=0.0067, val_loss=0.00636]Epoch 9:  48%|████▊     | 10/21 [00:00<00:00, 23.62it/s, train_loss=0.00588, val_loss=0.00636]Epoch 9:  52%|█████▏    | 11/21 [00:00<00:00, 24.45it/s, train_loss=0.00588, val_loss=0.00636]Epoch 9:  52%|█████▏    | 11/21 [00:00<00:00, 23.54it/s, train_loss=0.0058, val_loss=0.00636] Epoch 9:  57%|█████▋    | 12/21 [00:00<00:00, 24.35it/s, train_loss=0.0058, val_loss=0.00636]Epoch 9:  57%|█████▋    | 12/21 [00:00<00:00, 23.50it/s, train_loss=0.00579, val_loss=0.00636]Epoch 9:  62%|██████▏   | 13/21 [00:00<00:00, 24.19it/s, train_loss=0.00579, val_loss=0.00636]Epoch 9:  62%|██████▏   | 13/21 [00:00<00:00, 23.44it/s, train_loss=0.00549, val_loss=0.00636]Epoch 9:  67%|██████▋   | 14/21 [00:00<00:00, 24.08it/s, train_loss=0.00549, val_loss=0.00636]Epoch 9:  67%|██████▋   | 14/21 [00:00<00:00, 23.35it/s, train_loss=0.00562, val_loss=0.00636]Epoch 9:  71%|███████▏  | 15/21 [00:00<00:00, 24.09it/s, train_loss=0.00562, val_loss=0.00636]Epoch 9:  71%|███████▏  | 15/21 [00:00<00:00, 23.40it/s, train_loss=0.00599, val_loss=0.00636]Epoch 9:  76%|███████▌  | 16/21 [00:00<00:00, 23.96it/s, train_loss=0.00599, val_loss=0.00636]Epoch 9:  76%|███████▌  | 16/21 [00:00<00:00, 23.32it/s, train_loss=0.00595, val_loss=0.00636]Epoch 9:  81%|████████  | 17/21 [00:00<00:00, 23.84it/s, train_loss=0.00595, val_loss=0.00636]Epoch 9:  81%|████████  | 17/21 [00:00<00:00, 23.25it/s, train_loss=0.00615, val_loss=0.00636]Epoch 9:  86%|████████▌ | 18/21 [00:00<00:00, 23.74it/s, train_loss=0.00615, val_loss=0.00636]Epoch 9:  86%|████████▌ | 18/21 [00:00<00:00, 23.20it/s, train_loss=0.00627, val_loss=0.00636]Epoch 9:  90%|█████████ | 19/21 [00:00<00:00, 23.67it/s, train_loss=0.00627, val_loss=0.00636]Epoch 9:  90%|█████████ | 19/21 [00:00<00:00, 23.16it/s, train_loss=0.00589, val_loss=0.00636]Epoch 9:  95%|█████████▌| 20/21 [00:00<00:00, 24.01it/s, train_loss=0.00589, val_loss=0.00636]Epoch 9:  95%|█████████▌| 20/21 [00:00<00:00, 23.51it/s, train_loss=0.00529, val_loss=0.00636]Epoch 9: 100%|██████████| 21/21 [00:00<00:00, 23.96it/s, train_loss=0.00529, val_loss=0.00636]Epoch 9: 100%|██████████| 21/21 [00:00<00:00, 23.48it/s, train_loss=0.00556, val_loss=0.00636]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 12.99it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 21.58it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 19.99it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 21.83it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 24.34it/s][A
                                                                      [AEpoch 9: 100%|██████████| 21/21 [00:01<00:00, 16.83it/s, train_loss=0.00556, val_loss=0.00609]Epoch 9: 100%|██████████| 21/21 [00:01<00:00, 16.79it/s, train_loss=0.00556, val_loss=0.00609]Epoch 9:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00556, val_loss=0.00609]         Epoch 10:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00556, val_loss=0.00609]Epoch 10:   5%|▍         | 1/21 [00:00<00:00, 90.57it/s, train_loss=0.00556, val_loss=0.00609]Epoch 10:   5%|▍         | 1/21 [00:00<00:00, 34.47it/s, train_loss=0.00557, val_loss=0.00609]Epoch 10:  10%|▉         | 2/21 [00:00<00:00, 35.99it/s, train_loss=0.00557, val_loss=0.00609]Epoch 10:  10%|▉         | 2/21 [00:00<00:00, 27.56it/s, train_loss=0.00585, val_loss=0.00609]Epoch 10:  14%|█▍        | 3/21 [00:00<00:00, 30.57it/s, train_loss=0.00585, val_loss=0.00609]Epoch 10:  14%|█▍        | 3/21 [00:00<00:00, 25.94it/s, train_loss=0.00561, val_loss=0.00609]Epoch 10:  19%|█▉        | 4/21 [00:00<00:00, 28.26it/s, train_loss=0.00561, val_loss=0.00609]Epoch 10:  19%|█▉        | 4/21 [00:00<00:00, 25.11it/s, train_loss=0.00526, val_loss=0.00609]Epoch 10:  24%|██▍       | 5/21 [00:00<00:00, 27.14it/s, train_loss=0.00526, val_loss=0.00609]Epoch 10:  24%|██▍       | 5/21 [00:00<00:00, 24.75it/s, train_loss=0.00595, val_loss=0.00609]Epoch 10:  29%|██▊       | 6/21 [00:00<00:00, 26.52it/s, train_loss=0.00595, val_loss=0.00609]Epoch 10:  29%|██▊       | 6/21 [00:00<00:00, 24.69it/s, train_loss=0.00577, val_loss=0.00609]Epoch 10:  33%|███▎      | 7/21 [00:00<00:00, 26.15it/s, train_loss=0.00577, val_loss=0.00609]Epoch 10:  33%|███▎      | 7/21 [00:00<00:00, 24.54it/s, train_loss=0.00543, val_loss=0.00609]Epoch 10:  38%|███▊      | 8/21 [00:00<00:00, 25.68it/s, train_loss=0.00543, val_loss=0.00609]Epoch 10:  38%|███▊      | 8/21 [00:00<00:00, 24.16it/s, train_loss=0.00594, val_loss=0.00609]Epoch 10:  43%|████▎     | 9/21 [00:00<00:00, 25.86it/s, train_loss=0.00594, val_loss=0.00609]Epoch 10:  43%|████▎     | 9/21 [00:00<00:00, 24.34it/s, train_loss=0.00573, val_loss=0.00609]Epoch 10:  48%|████▊     | 10/21 [00:00<00:00, 25.94it/s, train_loss=0.00573, val_loss=0.00609]Epoch 10:  48%|████▊     | 10/21 [00:00<00:00, 24.75it/s, train_loss=0.00579, val_loss=0.00609]Epoch 10:  52%|█████▏    | 11/21 [00:00<00:00, 25.64it/s, train_loss=0.00579, val_loss=0.00609]Epoch 10:  52%|█████▏    | 11/21 [00:00<00:00, 23.80it/s, train_loss=0.00582, val_loss=0.00609]Epoch 10:  57%|█████▋    | 12/21 [00:00<00:00, 24.51it/s, train_loss=0.00582, val_loss=0.00609]Epoch 10:  57%|█████▋    | 12/21 [00:00<00:00, 23.74it/s, train_loss=0.00638, val_loss=0.00609]Epoch 10:  62%|██████▏   | 13/21 [00:00<00:00, 25.20it/s, train_loss=0.00638, val_loss=0.00609]Epoch 10:  62%|██████▏   | 13/21 [00:00<00:00, 24.39it/s, train_loss=0.00567, val_loss=0.00609]Epoch 10:  67%|██████▋   | 14/21 [00:00<00:00, 25.01it/s, train_loss=0.00567, val_loss=0.00609]Epoch 10:  67%|██████▋   | 14/21 [00:00<00:00, 24.28it/s, train_loss=0.00534, val_loss=0.00609]Epoch 10:  71%|███████▏  | 15/21 [00:00<00:00, 24.88it/s, train_loss=0.00534, val_loss=0.00609]Epoch 10:  71%|███████▏  | 15/21 [00:00<00:00, 24.14it/s, train_loss=0.00531, val_loss=0.00609]Epoch 10:  76%|███████▌  | 16/21 [00:00<00:00, 24.70it/s, train_loss=0.00531, val_loss=0.00609]Epoch 10:  76%|███████▌  | 16/21 [00:00<00:00, 24.04it/s, train_loss=0.00543, val_loss=0.00609]Epoch 10:  81%|████████  | 17/21 [00:00<00:00, 24.60it/s, train_loss=0.00543, val_loss=0.00609]Epoch 10:  81%|████████  | 17/21 [00:00<00:00, 23.98it/s, train_loss=0.0053, val_loss=0.00609] Epoch 10:  86%|████████▌ | 18/21 [00:00<00:00, 24.51it/s, train_loss=0.0053, val_loss=0.00609]Epoch 10:  86%|████████▌ | 18/21 [00:00<00:00, 23.94it/s, train_loss=0.00526, val_loss=0.00609]Epoch 10:  90%|█████████ | 19/21 [00:00<00:00, 24.44it/s, train_loss=0.00526, val_loss=0.00609]Epoch 10:  90%|█████████ | 19/21 [00:00<00:00, 23.89it/s, train_loss=0.00565, val_loss=0.00609]Epoch 10:  95%|█████████▌| 20/21 [00:00<00:00, 24.37it/s, train_loss=0.00565, val_loss=0.00609]Epoch 10:  95%|█████████▌| 20/21 [00:00<00:00, 23.87it/s, train_loss=0.00532, val_loss=0.00609]Epoch 10: 100%|██████████| 21/21 [00:00<00:00, 24.83it/s, train_loss=0.00532, val_loss=0.00609]Epoch 10: 100%|██████████| 21/21 [00:00<00:00, 24.25it/s, train_loss=0.00522, val_loss=0.00609]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  9.47it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 17.85it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 25.71it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 31.94it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 32.57it/s][A
                                                                      [AEpoch 10: 100%|██████████| 21/21 [00:01<00:00, 17.92it/s, train_loss=0.00522, val_loss=0.00582]Epoch 10: 100%|██████████| 21/21 [00:01<00:00, 17.66it/s, train_loss=0.00522, val_loss=0.00582]Epoch 10:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00522, val_loss=0.00582]         Epoch 11:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00522, val_loss=0.00582]Epoch 11:   5%|▍         | 1/21 [00:00<00:00, 22.89it/s, train_loss=0.00522, val_loss=0.00582]Epoch 11:   5%|▍         | 1/21 [00:00<00:01, 16.39it/s, train_loss=0.00568, val_loss=0.00582]Epoch 11:  10%|▉         | 2/21 [00:00<00:00, 23.17it/s, train_loss=0.00568, val_loss=0.00582]Epoch 11:  10%|▉         | 2/21 [00:00<00:01, 18.92it/s, train_loss=0.00507, val_loss=0.00582]Epoch 11:  14%|█▍        | 3/21 [00:00<00:00, 22.68it/s, train_loss=0.00507, val_loss=0.00582]Epoch 11:  14%|█▍        | 3/21 [00:00<00:00, 20.09it/s, train_loss=0.00506, val_loss=0.00582]Epoch 11:  19%|█▉        | 4/21 [00:00<00:00, 22.85it/s, train_loss=0.00506, val_loss=0.00582]Epoch 11:  19%|█▉        | 4/21 [00:00<00:00, 20.77it/s, train_loss=0.00572, val_loss=0.00582]Epoch 11:  24%|██▍       | 5/21 [00:00<00:00, 22.88it/s, train_loss=0.00572, val_loss=0.00582]Epoch 11:  24%|██▍       | 5/21 [00:00<00:00, 21.01it/s, train_loss=0.00543, val_loss=0.00582]Epoch 11:  29%|██▊       | 6/21 [00:00<00:00, 22.77it/s, train_loss=0.00543, val_loss=0.00582]Epoch 11:  29%|██▊       | 6/21 [00:00<00:00, 21.21it/s, train_loss=0.00526, val_loss=0.00582]Epoch 11:  33%|███▎      | 7/21 [00:00<00:00, 22.66it/s, train_loss=0.00526, val_loss=0.00582]Epoch 11:  33%|███▎      | 7/21 [00:00<00:00, 21.39it/s, train_loss=0.00504, val_loss=0.00582]Epoch 11:  38%|███▊      | 8/21 [00:00<00:00, 22.62it/s, train_loss=0.00504, val_loss=0.00582]Epoch 11:  38%|███▊      | 8/21 [00:00<00:00, 21.55it/s, train_loss=0.00556, val_loss=0.00582]Epoch 11:  43%|████▎     | 9/21 [00:00<00:00, 22.70it/s, train_loss=0.00556, val_loss=0.00582]Epoch 11:  43%|████▎     | 9/21 [00:00<00:00, 21.66it/s, train_loss=0.00551, val_loss=0.00582]Epoch 11:  48%|████▊     | 10/21 [00:00<00:00, 22.62it/s, train_loss=0.00551, val_loss=0.00582]Epoch 11:  48%|████▊     | 10/21 [00:00<00:00, 21.69it/s, train_loss=0.00567, val_loss=0.00582]Epoch 11:  52%|█████▏    | 11/21 [00:00<00:00, 22.60it/s, train_loss=0.00567, val_loss=0.00582]Epoch 11:  52%|█████▏    | 11/21 [00:00<00:00, 21.82it/s, train_loss=0.00507, val_loss=0.00582]Epoch 11:  57%|█████▋    | 12/21 [00:00<00:00, 22.67it/s, train_loss=0.00507, val_loss=0.00582]Epoch 11:  57%|█████▋    | 12/21 [00:00<00:00, 21.86it/s, train_loss=0.00532, val_loss=0.00582]Epoch 11:  62%|██████▏   | 13/21 [00:00<00:00, 22.60it/s, train_loss=0.00532, val_loss=0.00582]Epoch 11:  62%|██████▏   | 13/21 [00:00<00:00, 21.88it/s, train_loss=0.00555, val_loss=0.00582]Epoch 11:  67%|██████▋   | 14/21 [00:00<00:00, 22.56it/s, train_loss=0.00555, val_loss=0.00582]Epoch 11:  67%|██████▋   | 14/21 [00:00<00:00, 21.96it/s, train_loss=0.00505, val_loss=0.00582]Epoch 11:  71%|███████▏  | 15/21 [00:00<00:00, 22.63it/s, train_loss=0.00505, val_loss=0.00582]Epoch 11:  71%|███████▏  | 15/21 [00:00<00:00, 22.02it/s, train_loss=0.00542, val_loss=0.00582]Epoch 11:  76%|███████▌  | 16/21 [00:00<00:00, 22.62it/s, train_loss=0.00542, val_loss=0.00582]Epoch 11:  76%|███████▌  | 16/21 [00:00<00:00, 22.02it/s, train_loss=0.00499, val_loss=0.00582]Epoch 11:  81%|████████  | 17/21 [00:00<00:00, 23.16it/s, train_loss=0.00499, val_loss=0.00582]Epoch 11:  81%|████████  | 17/21 [00:00<00:00, 22.53it/s, train_loss=0.0055, val_loss=0.00582] Epoch 11:  86%|████████▌ | 18/21 [00:00<00:00, 23.07it/s, train_loss=0.0055, val_loss=0.00582]Epoch 11:  86%|████████▌ | 18/21 [00:00<00:00, 22.56it/s, train_loss=0.00502, val_loss=0.00582]Epoch 11:  90%|█████████ | 19/21 [00:00<00:00, 23.10it/s, train_loss=0.00502, val_loss=0.00582]Epoch 11:  90%|█████████ | 19/21 [00:00<00:00, 22.57it/s, train_loss=0.00537, val_loss=0.00582]Epoch 11:  95%|█████████▌| 20/21 [00:00<00:00, 23.05it/s, train_loss=0.00537, val_loss=0.00582]Epoch 11:  95%|█████████▌| 20/21 [00:00<00:00, 22.54it/s, train_loss=0.00524, val_loss=0.00582]Epoch 11: 100%|██████████| 21/21 [00:00<00:00, 22.99it/s, train_loss=0.00524, val_loss=0.00582]Epoch 11: 100%|██████████| 21/21 [00:00<00:00, 22.58it/s, train_loss=0.00521, val_loss=0.00582]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  9.87it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 18.58it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 26.64it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 32.96it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 33.47it/s][A
                                                                      [AEpoch 11: 100%|██████████| 21/21 [00:01<00:00, 17.00it/s, train_loss=0.00521, val_loss=0.00551]Epoch 11: 100%|██████████| 21/21 [00:01<00:00, 16.76it/s, train_loss=0.00521, val_loss=0.00551]Epoch 11:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00521, val_loss=0.00551]         Epoch 12:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00521, val_loss=0.00551]Epoch 12:   5%|▍         | 1/21 [00:00<00:00, 22.39it/s, train_loss=0.00521, val_loss=0.00551]Epoch 12:   5%|▍         | 1/21 [00:00<00:01, 16.15it/s, train_loss=0.00514, val_loss=0.00551]Epoch 12:  10%|▉         | 2/21 [00:00<00:00, 22.63it/s, train_loss=0.00514, val_loss=0.00551]Epoch 12:  10%|▉         | 2/21 [00:00<00:01, 18.90it/s, train_loss=0.00524, val_loss=0.00551]Epoch 12:  14%|█▍        | 3/21 [00:00<00:00, 22.67it/s, train_loss=0.00524, val_loss=0.00551]Epoch 12:  14%|█▍        | 3/21 [00:00<00:00, 19.92it/s, train_loss=0.00528, val_loss=0.00551]Epoch 12:  19%|█▉        | 4/21 [00:00<00:00, 22.51it/s, train_loss=0.00528, val_loss=0.00551]Epoch 12:  19%|█▉        | 4/21 [00:00<00:00, 20.40it/s, train_loss=0.00494, val_loss=0.00551]Epoch 12:  24%|██▍       | 5/21 [00:00<00:00, 22.37it/s, train_loss=0.00494, val_loss=0.00551]Epoch 12:  24%|██▍       | 5/21 [00:00<00:00, 20.70it/s, train_loss=0.00502, val_loss=0.00551]Epoch 12:  29%|██▊       | 6/21 [00:00<00:00, 22.38it/s, train_loss=0.00502, val_loss=0.00551]Epoch 12:  29%|██▊       | 6/21 [00:00<00:00, 20.86it/s, train_loss=0.00508, val_loss=0.00551]Epoch 12:  33%|███▎      | 7/21 [00:00<00:00, 22.33it/s, train_loss=0.00508, val_loss=0.00551]Epoch 12:  33%|███▎      | 7/21 [00:00<00:00, 21.19it/s, train_loss=0.00537, val_loss=0.00551]Epoch 12:  38%|███▊      | 8/21 [00:00<00:00, 22.30it/s, train_loss=0.00537, val_loss=0.00551]Epoch 12:  38%|███▊      | 8/21 [00:00<00:00, 21.26it/s, train_loss=0.00519, val_loss=0.00551]Epoch 12:  43%|████▎     | 9/21 [00:00<00:00, 22.26it/s, train_loss=0.00519, val_loss=0.00551]Epoch 12:  43%|████▎     | 9/21 [00:00<00:00, 21.29it/s, train_loss=0.00523, val_loss=0.00551]Epoch 12:  48%|████▊     | 10/21 [00:00<00:00, 22.29it/s, train_loss=0.00523, val_loss=0.00551]Epoch 12:  48%|████▊     | 10/21 [00:00<00:00, 21.47it/s, train_loss=0.00468, val_loss=0.00551]Epoch 12:  52%|█████▏    | 11/21 [00:00<00:00, 22.31it/s, train_loss=0.00468, val_loss=0.00551]Epoch 12:  52%|█████▏    | 11/21 [00:00<00:00, 21.56it/s, train_loss=0.0051, val_loss=0.00551] Epoch 12:  57%|█████▋    | 12/21 [00:00<00:00, 22.37it/s, train_loss=0.0051, val_loss=0.00551]Epoch 12:  57%|█████▋    | 12/21 [00:00<00:00, 21.67it/s, train_loss=0.00493, val_loss=0.00551]Epoch 12:  62%|██████▏   | 13/21 [00:00<00:00, 22.41it/s, train_loss=0.00493, val_loss=0.00551]Epoch 12:  62%|██████▏   | 13/21 [00:00<00:00, 21.77it/s, train_loss=0.00537, val_loss=0.00551]Epoch 12:  67%|██████▋   | 14/21 [00:00<00:00, 22.43it/s, train_loss=0.00537, val_loss=0.00551]Epoch 12:  67%|██████▋   | 14/21 [00:00<00:00, 21.84it/s, train_loss=0.00496, val_loss=0.00551]Epoch 12:  71%|███████▏  | 15/21 [00:00<00:00, 22.43it/s, train_loss=0.00496, val_loss=0.00551]Epoch 12:  71%|███████▏  | 15/21 [00:00<00:00, 21.86it/s, train_loss=0.00517, val_loss=0.00551]Epoch 12:  76%|███████▌  | 16/21 [00:00<00:00, 22.41it/s, train_loss=0.00517, val_loss=0.00551]Epoch 12:  76%|███████▌  | 16/21 [00:00<00:00, 21.90it/s, train_loss=0.00465, val_loss=0.00551]Epoch 12:  81%|████████  | 17/21 [00:00<00:00, 22.46it/s, train_loss=0.00465, val_loss=0.00551]Epoch 12:  81%|████████  | 17/21 [00:00<00:00, 21.92it/s, train_loss=0.00526, val_loss=0.00551]Epoch 12:  86%|████████▌ | 18/21 [00:00<00:00, 22.47it/s, train_loss=0.00526, val_loss=0.00551]Epoch 12:  86%|████████▌ | 18/21 [00:00<00:00, 22.00it/s, train_loss=0.00526, val_loss=0.00551]Epoch 12:  90%|█████████ | 19/21 [00:00<00:00, 22.49it/s, train_loss=0.00526, val_loss=0.00551]Epoch 12:  90%|█████████ | 19/21 [00:00<00:00, 22.02it/s, train_loss=0.00491, val_loss=0.00551]Epoch 12:  95%|█████████▌| 20/21 [00:00<00:00, 22.47it/s, train_loss=0.00491, val_loss=0.00551]Epoch 12:  95%|█████████▌| 20/21 [00:00<00:00, 22.03it/s, train_loss=0.00467, val_loss=0.00551]Epoch 12: 100%|██████████| 21/21 [00:00<00:00, 22.48it/s, train_loss=0.00467, val_loss=0.00551]Epoch 12: 100%|██████████| 21/21 [00:00<00:00, 22.05it/s, train_loss=0.00502, val_loss=0.00551]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 110.97it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 134.18it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 142.76it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 83.26it/s] [A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 47.35it/s][A
                                                                      [AEpoch 12: 100%|██████████| 21/21 [00:01<00:00, 17.34it/s, train_loss=0.00502, val_loss=0.00533]Epoch 12: 100%|██████████| 21/21 [00:01<00:00, 17.10it/s, train_loss=0.00502, val_loss=0.00533]Epoch 12:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00502, val_loss=0.00533]         Epoch 13:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00502, val_loss=0.00533]Epoch 13:   5%|▍         | 1/21 [00:00<00:00, 22.64it/s, train_loss=0.00502, val_loss=0.00533]Epoch 13:   5%|▍         | 1/21 [00:00<00:01, 16.11it/s, train_loss=0.00507, val_loss=0.00533]Epoch 13:  10%|▉         | 2/21 [00:00<00:00, 22.60it/s, train_loss=0.00507, val_loss=0.00533]Epoch 13:  10%|▉         | 2/21 [00:00<00:01, 18.94it/s, train_loss=0.0051, val_loss=0.00533] Epoch 13:  14%|█▍        | 3/21 [00:00<00:00, 22.63it/s, train_loss=0.0051, val_loss=0.00533]Epoch 13:  14%|█▍        | 3/21 [00:00<00:00, 20.11it/s, train_loss=0.00498, val_loss=0.00533]Epoch 13:  19%|█▉        | 4/21 [00:00<00:00, 22.63it/s, train_loss=0.00498, val_loss=0.00533]Epoch 13:  19%|█▉        | 4/21 [00:00<00:00, 20.58it/s, train_loss=0.00485, val_loss=0.00533]Epoch 13:  24%|██▍       | 5/21 [00:00<00:00, 22.69it/s, train_loss=0.00485, val_loss=0.00533]Epoch 13:  24%|██▍       | 5/21 [00:00<00:00, 20.95it/s, train_loss=0.00465, val_loss=0.00533]Epoch 13:  29%|██▊       | 6/21 [00:00<00:00, 22.67it/s, train_loss=0.00465, val_loss=0.00533]Epoch 13:  29%|██▊       | 6/21 [00:00<00:00, 21.30it/s, train_loss=0.00492, val_loss=0.00533]Epoch 13:  33%|███▎      | 7/21 [00:00<00:00, 22.74it/s, train_loss=0.00492, val_loss=0.00533]Epoch 13:  33%|███▎      | 7/21 [00:00<00:00, 21.51it/s, train_loss=0.00473, val_loss=0.00533]Epoch 13:  38%|███▊      | 8/21 [00:00<00:00, 22.75it/s, train_loss=0.00473, val_loss=0.00533]Epoch 13:  38%|███▊      | 8/21 [00:00<00:00, 21.68it/s, train_loss=0.00471, val_loss=0.00533]Epoch 13:  43%|████▎     | 9/21 [00:00<00:00, 22.76it/s, train_loss=0.00471, val_loss=0.00533]Epoch 13:  43%|████▎     | 9/21 [00:00<00:00, 21.81it/s, train_loss=0.00509, val_loss=0.00533]Epoch 13:  48%|████▊     | 10/21 [00:00<00:00, 22.74it/s, train_loss=0.00509, val_loss=0.00533]Epoch 13:  48%|████▊     | 10/21 [00:00<00:00, 21.90it/s, train_loss=0.00466, val_loss=0.00533]Epoch 13:  52%|█████▏    | 11/21 [00:00<00:00, 22.79it/s, train_loss=0.00466, val_loss=0.00533]Epoch 13:  52%|█████▏    | 11/21 [00:00<00:00, 21.97it/s, train_loss=0.00482, val_loss=0.00533]Epoch 13:  57%|█████▋    | 12/21 [00:00<00:00, 22.74it/s, train_loss=0.00482, val_loss=0.00533]Epoch 13:  57%|█████▋    | 12/21 [00:00<00:00, 21.98it/s, train_loss=0.00481, val_loss=0.00533]Epoch 13:  62%|██████▏   | 13/21 [00:00<00:00, 22.73it/s, train_loss=0.00481, val_loss=0.00533]Epoch 13:  62%|██████▏   | 13/21 [00:00<00:00, 22.07it/s, train_loss=0.0048, val_loss=0.00533] Epoch 13:  67%|██████▋   | 14/21 [00:00<00:00, 22.75it/s, train_loss=0.0048, val_loss=0.00533]Epoch 13:  67%|██████▋   | 14/21 [00:00<00:00, 22.11it/s, train_loss=0.00475, val_loss=0.00533]Epoch 13:  71%|███████▏  | 15/21 [00:00<00:00, 23.04it/s, train_loss=0.00475, val_loss=0.00533]Epoch 13:  71%|███████▏  | 15/21 [00:00<00:00, 22.39it/s, train_loss=0.00534, val_loss=0.00533]Epoch 13:  76%|███████▌  | 16/21 [00:00<00:00, 22.96it/s, train_loss=0.00534, val_loss=0.00533]Epoch 13:  76%|███████▌  | 16/21 [00:00<00:00, 22.40it/s, train_loss=0.00479, val_loss=0.00533]Epoch 13:  81%|████████  | 17/21 [00:00<00:00, 22.92it/s, train_loss=0.00479, val_loss=0.00533]Epoch 13:  81%|████████  | 17/21 [00:00<00:00, 22.37it/s, train_loss=0.00473, val_loss=0.00533]Epoch 13:  86%|████████▌ | 18/21 [00:00<00:00, 22.88it/s, train_loss=0.00473, val_loss=0.00533]Epoch 13:  86%|████████▌ | 18/21 [00:00<00:00, 22.36it/s, train_loss=0.00488, val_loss=0.00533]Epoch 13:  90%|█████████ | 19/21 [00:00<00:00, 22.87it/s, train_loss=0.00488, val_loss=0.00533]Epoch 13:  90%|█████████ | 19/21 [00:00<00:00, 22.41it/s, train_loss=0.00479, val_loss=0.00533]Epoch 13:  95%|█████████▌| 20/21 [00:00<00:00, 22.89it/s, train_loss=0.00479, val_loss=0.00533]Epoch 13:  95%|█████████▌| 20/21 [00:00<00:00, 22.45it/s, train_loss=0.00456, val_loss=0.00533]Epoch 13: 100%|██████████| 21/21 [00:00<00:00, 22.91it/s, train_loss=0.00456, val_loss=0.00533]Epoch 13: 100%|██████████| 21/21 [00:00<00:00, 22.47it/s, train_loss=0.0047, val_loss=0.00533] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 26.87it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 43.43it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 58.28it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 48.53it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 36.52it/s][A
                                                                      [AEpoch 13: 100%|██████████| 21/21 [00:01<00:00, 17.10it/s, train_loss=0.0047, val_loss=0.00502]Epoch 13: 100%|██████████| 21/21 [00:01<00:00, 16.87it/s, train_loss=0.0047, val_loss=0.00502]Epoch 13:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0047, val_loss=0.00502]         Epoch 14:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0047, val_loss=0.00502]Epoch 14:   5%|▍         | 1/21 [00:00<00:00, 22.06it/s, train_loss=0.0047, val_loss=0.00502]Epoch 14:   5%|▍         | 1/21 [00:00<00:01, 15.74it/s, train_loss=0.0048, val_loss=0.00502]Epoch 14:  10%|▉         | 2/21 [00:00<00:00, 22.22it/s, train_loss=0.0048, val_loss=0.00502]Epoch 14:  10%|▉         | 2/21 [00:00<00:01, 18.66it/s, train_loss=0.00499, val_loss=0.00502]Epoch 14:  14%|█▍        | 3/21 [00:00<00:00, 22.41it/s, train_loss=0.00499, val_loss=0.00502]Epoch 14:  14%|█▍        | 3/21 [00:00<00:00, 19.71it/s, train_loss=0.0049, val_loss=0.00502] Epoch 14:  19%|█▉        | 4/21 [00:00<00:00, 22.43it/s, train_loss=0.0049, val_loss=0.00502]Epoch 14:  19%|█▉        | 4/21 [00:00<00:00, 20.55it/s, train_loss=0.00475, val_loss=0.00502]Epoch 14:  24%|██▍       | 5/21 [00:00<00:00, 24.53it/s, train_loss=0.00475, val_loss=0.00502]Epoch 14:  24%|██▍       | 5/21 [00:00<00:00, 22.40it/s, train_loss=0.00459, val_loss=0.00502]Epoch 14:  29%|██▊       | 6/21 [00:00<00:00, 23.93it/s, train_loss=0.00459, val_loss=0.00502]Epoch 14:  29%|██▊       | 6/21 [00:00<00:00, 22.39it/s, train_loss=0.00462, val_loss=0.00502]Epoch 14:  33%|███▎      | 7/21 [00:00<00:00, 23.69it/s, train_loss=0.00462, val_loss=0.00502]Epoch 14:  33%|███▎      | 7/21 [00:00<00:00, 22.33it/s, train_loss=0.00459, val_loss=0.00502]Epoch 14:  38%|███▊      | 8/21 [00:00<00:00, 23.55it/s, train_loss=0.00459, val_loss=0.00502]Epoch 14:  38%|███▊      | 8/21 [00:00<00:00, 22.38it/s, train_loss=0.00463, val_loss=0.00502]Epoch 14:  43%|████▎     | 9/21 [00:00<00:00, 23.46it/s, train_loss=0.00463, val_loss=0.00502]Epoch 14:  43%|████▎     | 9/21 [00:00<00:00, 22.47it/s, train_loss=0.00507, val_loss=0.00502]Epoch 14:  48%|████▊     | 10/21 [00:00<00:00, 23.41it/s, train_loss=0.00507, val_loss=0.00502]Epoch 14:  48%|████▊     | 10/21 [00:00<00:00, 22.50it/s, train_loss=0.00456, val_loss=0.00502]Epoch 14:  52%|█████▏    | 11/21 [00:00<00:00, 23.32it/s, train_loss=0.00456, val_loss=0.00502]Epoch 14:  52%|█████▏    | 11/21 [00:00<00:00, 22.51it/s, train_loss=0.00431, val_loss=0.00502]Epoch 14:  57%|█████▋    | 12/21 [00:00<00:00, 23.30it/s, train_loss=0.00431, val_loss=0.00502]Epoch 14:  57%|█████▋    | 12/21 [00:00<00:00, 22.55it/s, train_loss=0.0045, val_loss=0.00502] Epoch 14:  62%|██████▏   | 13/21 [00:00<00:00, 23.24it/s, train_loss=0.0045, val_loss=0.00502]Epoch 14:  62%|██████▏   | 13/21 [00:00<00:00, 22.57it/s, train_loss=0.00465, val_loss=0.00502]Epoch 14:  67%|██████▋   | 14/21 [00:00<00:00, 23.25it/s, train_loss=0.00465, val_loss=0.00502]Epoch 14:  67%|██████▋   | 14/21 [00:00<00:00, 22.55it/s, train_loss=0.00462, val_loss=0.00502]Epoch 14:  71%|███████▏  | 15/21 [00:00<00:00, 23.16it/s, train_loss=0.00462, val_loss=0.00502]Epoch 14:  71%|███████▏  | 15/21 [00:00<00:00, 22.55it/s, train_loss=0.00452, val_loss=0.00502]Epoch 14:  76%|███████▌  | 16/21 [00:00<00:00, 23.14it/s, train_loss=0.00452, val_loss=0.00502]Epoch 14:  76%|███████▌  | 16/21 [00:00<00:00, 22.57it/s, train_loss=0.00455, val_loss=0.00502]Epoch 14:  81%|████████  | 17/21 [00:00<00:00, 23.11it/s, train_loss=0.00455, val_loss=0.00502]Epoch 14:  81%|████████  | 17/21 [00:00<00:00, 22.59it/s, train_loss=0.0046, val_loss=0.00502] Epoch 14:  86%|████████▌ | 18/21 [00:00<00:00, 23.09it/s, train_loss=0.0046, val_loss=0.00502]Epoch 14:  86%|████████▌ | 18/21 [00:00<00:00, 22.56it/s, train_loss=0.0046, val_loss=0.00502]Epoch 14:  90%|█████████ | 19/21 [00:00<00:00, 23.06it/s, train_loss=0.0046, val_loss=0.00502]Epoch 14:  90%|█████████ | 19/21 [00:00<00:00, 22.55it/s, train_loss=0.00431, val_loss=0.00502]Epoch 14:  95%|█████████▌| 20/21 [00:00<00:00, 23.02it/s, train_loss=0.00431, val_loss=0.00502]Epoch 14:  95%|█████████▌| 20/21 [00:00<00:00, 22.56it/s, train_loss=0.00467, val_loss=0.00502]Epoch 14: 100%|██████████| 21/21 [00:00<00:00, 23.01it/s, train_loss=0.00467, val_loss=0.00502]Epoch 14: 100%|██████████| 21/21 [00:00<00:00, 22.60it/s, train_loss=0.00453, val_loss=0.00502]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 16.48it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 30.02it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 33.64it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 27.35it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 24.56it/s][A
                                                                      [AEpoch 14: 100%|██████████| 21/21 [00:01<00:00, 16.30it/s, train_loss=0.00453, val_loss=0.00484]Epoch 14: 100%|██████████| 21/21 [00:01<00:00, 16.09it/s, train_loss=0.00453, val_loss=0.00484]Epoch 14:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00453, val_loss=0.00484]         Epoch 15:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00453, val_loss=0.00484]Epoch 15:   5%|▍         | 1/21 [00:00<00:00, 22.08it/s, train_loss=0.00453, val_loss=0.00484]Epoch 15:   5%|▍         | 1/21 [00:00<00:01, 15.83it/s, train_loss=0.00466, val_loss=0.00484]Epoch 15:  10%|▉         | 2/21 [00:00<00:00, 22.35it/s, train_loss=0.00466, val_loss=0.00484]Epoch 15:  10%|▉         | 2/21 [00:00<00:01, 18.83it/s, train_loss=0.00456, val_loss=0.00484]Epoch 15:  14%|█▍        | 3/21 [00:00<00:00, 22.64it/s, train_loss=0.00456, val_loss=0.00484]Epoch 15:  14%|█▍        | 3/21 [00:00<00:00, 20.02it/s, train_loss=0.00444, val_loss=0.00484]Epoch 15:  19%|█▉        | 4/21 [00:00<00:00, 22.70it/s, train_loss=0.00444, val_loss=0.00484]Epoch 15:  19%|█▉        | 4/21 [00:00<00:00, 20.61it/s, train_loss=0.00461, val_loss=0.00484]Epoch 15:  24%|██▍       | 5/21 [00:00<00:00, 22.59it/s, train_loss=0.00461, val_loss=0.00484]Epoch 15:  24%|██▍       | 5/21 [00:00<00:00, 20.95it/s, train_loss=0.00463, val_loss=0.00484]Epoch 15:  29%|██▊       | 6/21 [00:00<00:00, 22.68it/s, train_loss=0.00463, val_loss=0.00484]Epoch 15:  29%|██▊       | 6/21 [00:00<00:00, 21.26it/s, train_loss=0.00453, val_loss=0.00484]Epoch 15:  33%|███▎      | 7/21 [00:00<00:00, 22.65it/s, train_loss=0.00453, val_loss=0.00484]Epoch 15:  33%|███▎      | 7/21 [00:00<00:00, 21.44it/s, train_loss=0.0043, val_loss=0.00484] Epoch 15:  38%|███▊      | 8/21 [00:00<00:00, 22.70it/s, train_loss=0.0043, val_loss=0.00484]Epoch 15:  38%|███▊      | 8/21 [00:00<00:00, 21.63it/s, train_loss=0.00424, val_loss=0.00484]Epoch 15:  43%|████▎     | 9/21 [00:00<00:00, 22.72it/s, train_loss=0.00424, val_loss=0.00484]Epoch 15:  43%|████▎     | 9/21 [00:00<00:00, 21.74it/s, train_loss=0.0044, val_loss=0.00484] Epoch 15:  48%|████▊     | 10/21 [00:00<00:00, 22.69it/s, train_loss=0.0044, val_loss=0.00484]Epoch 15:  48%|████▊     | 10/21 [00:00<00:00, 21.83it/s, train_loss=0.00431, val_loss=0.00484]Epoch 15:  52%|█████▏    | 11/21 [00:00<00:00, 22.69it/s, train_loss=0.00431, val_loss=0.00484]Epoch 15:  52%|█████▏    | 11/21 [00:00<00:00, 21.92it/s, train_loss=0.00431, val_loss=0.00484]Epoch 15:  57%|█████▋    | 12/21 [00:00<00:00, 22.75it/s, train_loss=0.00431, val_loss=0.00484]Epoch 15:  57%|█████▋    | 12/21 [00:00<00:00, 21.98it/s, train_loss=0.00421, val_loss=0.00484]Epoch 15:  62%|██████▏   | 13/21 [00:00<00:00, 23.19it/s, train_loss=0.00421, val_loss=0.00484]Epoch 15:  62%|██████▏   | 13/21 [00:00<00:00, 22.52it/s, train_loss=0.00455, val_loss=0.00484]Epoch 15:  67%|██████▋   | 14/21 [00:00<00:00, 23.85it/s, train_loss=0.00455, val_loss=0.00484]Epoch 15:  67%|██████▋   | 14/21 [00:00<00:00, 23.13it/s, train_loss=0.00457, val_loss=0.00484]Epoch 15:  71%|███████▏  | 15/21 [00:00<00:00, 24.20it/s, train_loss=0.00457, val_loss=0.00484]Epoch 15:  71%|███████▏  | 15/21 [00:00<00:00, 23.56it/s, train_loss=0.00477, val_loss=0.00484]Epoch 15:  76%|███████▌  | 16/21 [00:00<00:00, 24.72it/s, train_loss=0.00477, val_loss=0.00484]Epoch 15:  76%|███████▌  | 16/21 [00:00<00:00, 24.08it/s, train_loss=0.00458, val_loss=0.00484]Epoch 15:  81%|████████  | 17/21 [00:00<00:00, 24.79it/s, train_loss=0.00458, val_loss=0.00484]Epoch 15:  81%|████████  | 17/21 [00:00<00:00, 24.21it/s, train_loss=0.00464, val_loss=0.00484]Epoch 15:  86%|████████▌ | 18/21 [00:00<00:00, 25.28it/s, train_loss=0.00464, val_loss=0.00484]Epoch 15:  86%|████████▌ | 18/21 [00:00<00:00, 24.62it/s, train_loss=0.00437, val_loss=0.00484]Epoch 15:  90%|█████████ | 19/21 [00:00<00:00, 25.33it/s, train_loss=0.00437, val_loss=0.00484]Epoch 15:  90%|█████████ | 19/21 [00:00<00:00, 24.75it/s, train_loss=0.00458, val_loss=0.00484]Epoch 15:  95%|█████████▌| 20/21 [00:00<00:00, 25.43it/s, train_loss=0.00458, val_loss=0.00484]Epoch 15:  95%|█████████▌| 20/21 [00:00<00:00, 24.87it/s, train_loss=0.00414, val_loss=0.00484]Epoch 15: 100%|██████████| 21/21 [00:00<00:00, 25.28it/s, train_loss=0.00414, val_loss=0.00484]Epoch 15: 100%|██████████| 21/21 [00:00<00:00, 24.75it/s, train_loss=0.00444, val_loss=0.00484]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 13.51it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 20.32it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 27.02it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 23.08it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 24.08it/s][A
                                                                      [AEpoch 15: 100%|██████████| 21/21 [00:01<00:00, 19.26it/s, train_loss=0.00444, val_loss=0.00467]Epoch 15: 100%|██████████| 21/21 [00:01<00:00, 19.24it/s, train_loss=0.00444, val_loss=0.00467]Epoch 15:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00444, val_loss=0.00467]         Epoch 16:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00444, val_loss=0.00467]Epoch 16:   5%|▍         | 1/21 [00:00<00:00, 32.73it/s, train_loss=0.00444, val_loss=0.00467]Epoch 16:   5%|▍         | 1/21 [00:00<00:00, 20.71it/s, train_loss=0.00447, val_loss=0.00467]Epoch 16:  10%|▉         | 2/21 [00:00<00:00, 26.36it/s, train_loss=0.00447, val_loss=0.00467]Epoch 16:  10%|▉         | 2/21 [00:00<00:00, 21.64it/s, train_loss=0.00418, val_loss=0.00467]Epoch 16:  14%|█▍        | 3/21 [00:00<00:00, 25.06it/s, train_loss=0.00418, val_loss=0.00467]Epoch 16:  14%|█▍        | 3/21 [00:00<00:00, 22.01it/s, train_loss=0.00445, val_loss=0.00467]Epoch 16:  19%|█▉        | 4/21 [00:00<00:00, 26.88it/s, train_loss=0.00445, val_loss=0.00467]Epoch 16:  19%|█▉        | 4/21 [00:00<00:00, 24.21it/s, train_loss=0.00424, val_loss=0.00467]Epoch 16:  24%|██▍       | 5/21 [00:00<00:00, 26.04it/s, train_loss=0.00424, val_loss=0.00467]Epoch 16:  24%|██▍       | 5/21 [00:00<00:00, 23.90it/s, train_loss=0.0044, val_loss=0.00467] Epoch 16:  29%|██▊       | 6/21 [00:00<00:00, 25.96it/s, train_loss=0.0044, val_loss=0.00467]Epoch 16:  29%|██▊       | 6/21 [00:00<00:00, 24.19it/s, train_loss=0.00419, val_loss=0.00467]Epoch 16:  33%|███▎      | 7/21 [00:00<00:00, 26.53it/s, train_loss=0.00419, val_loss=0.00467]Epoch 16:  33%|███▎      | 7/21 [00:00<00:00, 24.75it/s, train_loss=0.00478, val_loss=0.00467]Epoch 16:  38%|███▊      | 8/21 [00:00<00:00, 25.94it/s, train_loss=0.00478, val_loss=0.00467]Epoch 16:  38%|███▊      | 8/21 [00:00<00:00, 24.41it/s, train_loss=0.00404, val_loss=0.00467]Epoch 16:  43%|████▎     | 9/21 [00:00<00:00, 25.43it/s, train_loss=0.00404, val_loss=0.00467]Epoch 16:  43%|████▎     | 9/21 [00:00<00:00, 24.13it/s, train_loss=0.00443, val_loss=0.00467]Epoch 16:  48%|████▊     | 10/21 [00:00<00:00, 25.88it/s, train_loss=0.00443, val_loss=0.00467]Epoch 16:  48%|████▊     | 10/21 [00:00<00:00, 24.80it/s, train_loss=0.00447, val_loss=0.00467]Epoch 16:  52%|█████▏    | 11/21 [00:00<00:00, 26.69it/s, train_loss=0.00447, val_loss=0.00467]Epoch 16:  52%|█████▏    | 11/21 [00:00<00:00, 25.45it/s, train_loss=0.00414, val_loss=0.00467]Epoch 16:  57%|█████▋    | 12/21 [00:00<00:00, 27.16it/s, train_loss=0.00414, val_loss=0.00467]Epoch 16:  57%|█████▋    | 12/21 [00:00<00:00, 26.02it/s, train_loss=0.00445, val_loss=0.00467]Epoch 16:  62%|██████▏   | 13/21 [00:00<00:00, 26.61it/s, train_loss=0.00445, val_loss=0.00467]Epoch 16:  62%|██████▏   | 13/21 [00:00<00:00, 25.70it/s, train_loss=0.00451, val_loss=0.00467]Epoch 16:  67%|██████▋   | 14/21 [00:00<00:00, 26.77it/s, train_loss=0.00451, val_loss=0.00467]Epoch 16:  67%|██████▋   | 14/21 [00:00<00:00, 25.81it/s, train_loss=0.00405, val_loss=0.00467]Epoch 16:  71%|███████▏  | 15/21 [00:00<00:00, 26.35it/s, train_loss=0.00405, val_loss=0.00467]Epoch 16:  71%|███████▏  | 15/21 [00:00<00:00, 25.56it/s, train_loss=0.00428, val_loss=0.00467]Epoch 16:  76%|███████▌  | 16/21 [00:00<00:00, 26.32it/s, train_loss=0.00428, val_loss=0.00467]Epoch 16:  76%|███████▌  | 16/21 [00:00<00:00, 25.63it/s, train_loss=0.00434, val_loss=0.00467]Epoch 16:  81%|████████  | 17/21 [00:00<00:00, 26.73it/s, train_loss=0.00434, val_loss=0.00467]Epoch 16:  81%|████████  | 17/21 [00:00<00:00, 26.02it/s, train_loss=0.00418, val_loss=0.00467]Epoch 16:  86%|████████▌ | 18/21 [00:00<00:00, 26.47it/s, train_loss=0.00418, val_loss=0.00467]Epoch 16:  86%|████████▌ | 18/21 [00:00<00:00, 25.85it/s, train_loss=0.00436, val_loss=0.00467]Epoch 16:  90%|█████████ | 19/21 [00:00<00:00, 26.28it/s, train_loss=0.00436, val_loss=0.00467]Epoch 16:  90%|█████████ | 19/21 [00:00<00:00, 25.67it/s, train_loss=0.00449, val_loss=0.00467]Epoch 16:  95%|█████████▌| 20/21 [00:00<00:00, 26.46it/s, train_loss=0.00449, val_loss=0.00467]Epoch 16:  95%|█████████▌| 20/21 [00:00<00:00, 25.81it/s, train_loss=0.00427, val_loss=0.00467]Epoch 16: 100%|██████████| 21/21 [00:00<00:00, 26.20it/s, train_loss=0.00427, val_loss=0.00467]Epoch 16: 100%|██████████| 21/21 [00:00<00:00, 25.66it/s, train_loss=0.00413, val_loss=0.00467]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.57it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 13.87it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 14.95it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 15.59it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 16.83it/s][A
                                                                      [AEpoch 16: 100%|██████████| 21/21 [00:01<00:00, 16.95it/s, train_loss=0.00413, val_loss=0.00454]Epoch 16: 100%|██████████| 21/21 [00:01<00:00, 16.71it/s, train_loss=0.00413, val_loss=0.00454]Epoch 16:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00413, val_loss=0.00454]         Epoch 17:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00413, val_loss=0.00454]Epoch 17:   5%|▍         | 1/21 [00:00<00:00, 42.49it/s, train_loss=0.00413, val_loss=0.00454]Epoch 17:   5%|▍         | 1/21 [00:00<00:00, 24.88it/s, train_loss=0.00419, val_loss=0.00454]Epoch 17:  10%|▉         | 2/21 [00:00<00:00, 29.86it/s, train_loss=0.00419, val_loss=0.00454]Epoch 17:  10%|▉         | 2/21 [00:00<00:00, 23.54it/s, train_loss=0.00446, val_loss=0.00454]Epoch 17:  14%|█▍        | 3/21 [00:00<00:00, 27.01it/s, train_loss=0.00446, val_loss=0.00454]Epoch 17:  14%|█▍        | 3/21 [00:00<00:00, 23.37it/s, train_loss=0.00407, val_loss=0.00454]Epoch 17:  19%|█▉        | 4/21 [00:00<00:00, 25.84it/s, train_loss=0.00407, val_loss=0.00454]Epoch 17:  19%|█▉        | 4/21 [00:00<00:00, 23.21it/s, train_loss=0.00412, val_loss=0.00454]Epoch 17:  24%|██▍       | 5/21 [00:00<00:00, 25.05it/s, train_loss=0.00412, val_loss=0.00454]Epoch 17:  24%|██▍       | 5/21 [00:00<00:00, 23.00it/s, train_loss=0.00396, val_loss=0.00454]Epoch 17:  29%|██▊       | 6/21 [00:00<00:00, 24.64it/s, train_loss=0.00396, val_loss=0.00454]Epoch 17:  29%|██▊       | 6/21 [00:00<00:00, 23.00it/s, train_loss=0.00436, val_loss=0.00454]Epoch 17:  33%|███▎      | 7/21 [00:00<00:00, 24.32it/s, train_loss=0.00436, val_loss=0.00454]Epoch 17:  33%|███▎      | 7/21 [00:00<00:00, 22.94it/s, train_loss=0.00431, val_loss=0.00454]Epoch 17:  38%|███▊      | 8/21 [00:00<00:00, 24.95it/s, train_loss=0.00431, val_loss=0.00454]Epoch 17:  38%|███▊      | 8/21 [00:00<00:00, 23.62it/s, train_loss=0.0042, val_loss=0.00454] Epoch 17:  43%|████▎     | 9/21 [00:00<00:00, 24.63it/s, train_loss=0.0042, val_loss=0.00454]Epoch 17:  43%|████▎     | 9/21 [00:00<00:00, 23.54it/s, train_loss=0.00431, val_loss=0.00454]Epoch 17:  48%|████▊     | 10/21 [00:00<00:00, 24.40it/s, train_loss=0.00431, val_loss=0.00454]Epoch 17:  48%|████▊     | 10/21 [00:00<00:00, 23.37it/s, train_loss=0.00408, val_loss=0.00454]Epoch 17:  52%|█████▏    | 11/21 [00:00<00:00, 24.24it/s, train_loss=0.00408, val_loss=0.00454]Epoch 17:  52%|█████▏    | 11/21 [00:00<00:00, 23.38it/s, train_loss=0.00453, val_loss=0.00454]Epoch 17:  57%|█████▋    | 12/21 [00:00<00:00, 24.17it/s, train_loss=0.00453, val_loss=0.00454]Epoch 17:  57%|█████▋    | 12/21 [00:00<00:00, 23.31it/s, train_loss=0.00406, val_loss=0.00454]Epoch 17:  62%|██████▏   | 13/21 [00:00<00:00, 24.01it/s, train_loss=0.00406, val_loss=0.00454]Epoch 17:  62%|██████▏   | 13/21 [00:00<00:00, 23.26it/s, train_loss=0.00429, val_loss=0.00454]Epoch 17:  67%|██████▋   | 14/21 [00:00<00:00, 23.89it/s, train_loss=0.00429, val_loss=0.00454]Epoch 17:  67%|██████▋   | 14/21 [00:00<00:00, 23.22it/s, train_loss=0.00413, val_loss=0.00454]Epoch 17:  71%|███████▏  | 15/21 [00:00<00:00, 24.55it/s, train_loss=0.00413, val_loss=0.00454]Epoch 17:  71%|███████▏  | 15/21 [00:00<00:00, 23.76it/s, train_loss=0.00433, val_loss=0.00454]Epoch 17:  76%|███████▌  | 16/21 [00:00<00:00, 24.32it/s, train_loss=0.00433, val_loss=0.00454]Epoch 17:  76%|███████▌  | 16/21 [00:00<00:00, 23.67it/s, train_loss=0.00394, val_loss=0.00454]Epoch 17:  81%|████████  | 17/21 [00:00<00:00, 24.18it/s, train_loss=0.00394, val_loss=0.00454]Epoch 17:  81%|████████  | 17/21 [00:00<00:00, 23.61it/s, train_loss=0.00403, val_loss=0.00454]Epoch 17:  86%|████████▌ | 18/21 [00:00<00:00, 24.10it/s, train_loss=0.00403, val_loss=0.00454]Epoch 17:  86%|████████▌ | 18/21 [00:00<00:00, 23.55it/s, train_loss=0.00426, val_loss=0.00454]Epoch 17:  90%|█████████ | 19/21 [00:00<00:00, 24.01it/s, train_loss=0.00426, val_loss=0.00454]Epoch 17:  90%|█████████ | 19/21 [00:00<00:00, 23.48it/s, train_loss=0.00432, val_loss=0.00454]Epoch 17:  95%|█████████▌| 20/21 [00:00<00:00, 23.90it/s, train_loss=0.00432, val_loss=0.00454]Epoch 17:  95%|█████████▌| 20/21 [00:00<00:00, 23.40it/s, train_loss=0.00409, val_loss=0.00454]Epoch 17: 100%|██████████| 21/21 [00:00<00:00, 23.83it/s, train_loss=0.00409, val_loss=0.00454]Epoch 17: 100%|██████████| 21/21 [00:00<00:00, 23.35it/s, train_loss=0.00423, val_loss=0.00454]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 25.52it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 21.00it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 19.81it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 19.31it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 23.38it/s][A
                                                                      [AEpoch 17: 100%|██████████| 21/21 [00:01<00:00, 17.38it/s, train_loss=0.00423, val_loss=0.00445]Epoch 17: 100%|██████████| 21/21 [00:01<00:00, 17.14it/s, train_loss=0.00423, val_loss=0.00445]Epoch 17:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00423, val_loss=0.00445]         Epoch 18:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00423, val_loss=0.00445]Epoch 18:   5%|▍         | 1/21 [00:00<00:00, 51.56it/s, train_loss=0.00423, val_loss=0.00445]Epoch 18:   5%|▍         | 1/21 [00:00<00:00, 27.44it/s, train_loss=0.00419, val_loss=0.00445]Epoch 18:  10%|▉         | 2/21 [00:00<00:00, 31.38it/s, train_loss=0.00419, val_loss=0.00445]Epoch 18:  10%|▉         | 2/21 [00:00<00:00, 24.52it/s, train_loss=0.00384, val_loss=0.00445]Epoch 18:  14%|█▍        | 3/21 [00:00<00:00, 27.56it/s, train_loss=0.00384, val_loss=0.00445]Epoch 18:  14%|█▍        | 3/21 [00:00<00:00, 23.91it/s, train_loss=0.0038, val_loss=0.00445] Epoch 18:  19%|█▉        | 4/21 [00:00<00:00, 29.03it/s, train_loss=0.0038, val_loss=0.00445]Epoch 18:  19%|█▉        | 4/21 [00:00<00:00, 25.82it/s, train_loss=0.00392, val_loss=0.00445]Epoch 18:  24%|██▍       | 5/21 [00:00<00:00, 27.64it/s, train_loss=0.00392, val_loss=0.00445]Epoch 18:  24%|██▍       | 5/21 [00:00<00:00, 25.28it/s, train_loss=0.00439, val_loss=0.00445]Epoch 18:  29%|██▊       | 6/21 [00:00<00:00, 26.82it/s, train_loss=0.00439, val_loss=0.00445]Epoch 18:  29%|██▊       | 6/21 [00:00<00:00, 24.96it/s, train_loss=0.00428, val_loss=0.00445]Epoch 18:  33%|███▎      | 7/21 [00:00<00:00, 26.26it/s, train_loss=0.00428, val_loss=0.00445]Epoch 18:  33%|███▎      | 7/21 [00:00<00:00, 24.69it/s, train_loss=0.00439, val_loss=0.00445]Epoch 18:  38%|███▊      | 8/21 [00:00<00:00, 25.87it/s, train_loss=0.00439, val_loss=0.00445]Epoch 18:  38%|███▊      | 8/21 [00:00<00:00, 24.45it/s, train_loss=0.00409, val_loss=0.00445]Epoch 18:  43%|████▎     | 9/21 [00:00<00:00, 26.72it/s, train_loss=0.00409, val_loss=0.00445]Epoch 18:  43%|████▎     | 9/21 [00:00<00:00, 25.42it/s, train_loss=0.00409, val_loss=0.00445]Epoch 18:  48%|████▊     | 10/21 [00:00<00:00, 26.33it/s, train_loss=0.00409, val_loss=0.00445]Epoch 18:  48%|████▊     | 10/21 [00:00<00:00, 25.20it/s, train_loss=0.0042, val_loss=0.00445] Epoch 18:  52%|█████▏    | 11/21 [00:00<00:00, 26.03it/s, train_loss=0.0042, val_loss=0.00445]Epoch 18:  52%|█████▏    | 11/21 [00:00<00:00, 24.96it/s, train_loss=0.004, val_loss=0.00445] Epoch 18:  57%|█████▋    | 12/21 [00:00<00:00, 25.66it/s, train_loss=0.004, val_loss=0.00445]Epoch 18:  57%|█████▋    | 12/21 [00:00<00:00, 24.77it/s, train_loss=0.00425, val_loss=0.00445]Epoch 18:  62%|██████▏   | 13/21 [00:00<00:00, 25.45it/s, train_loss=0.00425, val_loss=0.00445]Epoch 18:  62%|██████▏   | 13/21 [00:00<00:00, 24.51it/s, train_loss=0.00426, val_loss=0.00445]Epoch 18:  67%|██████▋   | 14/21 [00:00<00:00, 25.63it/s, train_loss=0.00426, val_loss=0.00445]Epoch 18:  67%|██████▋   | 14/21 [00:00<00:00, 24.81it/s, train_loss=0.00388, val_loss=0.00445]Epoch 18:  71%|███████▏  | 15/21 [00:00<00:00, 25.34it/s, train_loss=0.00388, val_loss=0.00445]Epoch 18:  71%|███████▏  | 15/21 [00:00<00:00, 24.61it/s, train_loss=0.0041, val_loss=0.00445] Epoch 18:  76%|███████▌  | 16/21 [00:00<00:00, 25.12it/s, train_loss=0.0041, val_loss=0.00445]Epoch 18:  76%|███████▌  | 16/21 [00:00<00:00, 24.42it/s, train_loss=0.00401, val_loss=0.00445]Epoch 18:  81%|████████  | 17/21 [00:00<00:00, 24.92it/s, train_loss=0.00401, val_loss=0.00445]Epoch 18:  81%|████████  | 17/21 [00:00<00:00, 24.31it/s, train_loss=0.00415, val_loss=0.00445]Epoch 18:  86%|████████▌ | 18/21 [00:00<00:00, 24.79it/s, train_loss=0.00415, val_loss=0.00445]Epoch 18:  86%|████████▌ | 18/21 [00:00<00:00, 24.21it/s, train_loss=0.00413, val_loss=0.00445]Epoch 18:  90%|█████████ | 19/21 [00:00<00:00, 24.70it/s, train_loss=0.00413, val_loss=0.00445]Epoch 18:  90%|█████████ | 19/21 [00:00<00:00, 24.13it/s, train_loss=0.00384, val_loss=0.00445]Epoch 18:  95%|█████████▌| 20/21 [00:00<00:00, 24.55it/s, train_loss=0.00384, val_loss=0.00445]Epoch 18:  95%|█████████▌| 20/21 [00:00<00:00, 24.05it/s, train_loss=0.00404, val_loss=0.00445]Epoch 18: 100%|██████████| 21/21 [00:00<00:00, 24.48it/s, train_loss=0.00404, val_loss=0.00445]Epoch 18: 100%|██████████| 21/21 [00:00<00:00, 24.01it/s, train_loss=0.00408, val_loss=0.00445]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 11.24it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 18.07it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 18.15it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 19.65it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 19.16it/s][A
                                                                      [AEpoch 18: 100%|██████████| 21/21 [00:01<00:00, 17.74it/s, train_loss=0.00408, val_loss=0.00437]Epoch 18: 100%|██████████| 21/21 [00:01<00:00, 17.73it/s, train_loss=0.00408, val_loss=0.00437]Epoch 18:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00408, val_loss=0.00437]         Epoch 19:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00408, val_loss=0.00437]Epoch 19:   5%|▍         | 1/21 [00:00<00:00, 95.37it/s, train_loss=0.00408, val_loss=0.00437]Epoch 19:   5%|▍         | 1/21 [00:00<00:00, 35.50it/s, train_loss=0.00405, val_loss=0.00437]Epoch 19:  10%|▉         | 2/21 [00:00<00:00, 36.07it/s, train_loss=0.00405, val_loss=0.00437]Epoch 19:  10%|▉         | 2/21 [00:00<00:00, 27.23it/s, train_loss=0.00377, val_loss=0.00437]Epoch 19:  14%|█▍        | 3/21 [00:00<00:00, 30.18it/s, train_loss=0.00377, val_loss=0.00437]Epoch 19:  14%|█▍        | 3/21 [00:00<00:00, 25.82it/s, train_loss=0.00403, val_loss=0.00437]Epoch 19:  19%|█▉        | 4/21 [00:00<00:00, 28.17it/s, train_loss=0.00403, val_loss=0.00437]Epoch 19:  19%|█▉        | 4/21 [00:00<00:00, 25.17it/s, train_loss=0.00439, val_loss=0.00437]Epoch 19:  24%|██▍       | 5/21 [00:00<00:00, 27.06it/s, train_loss=0.00439, val_loss=0.00437]Epoch 19:  24%|██▍       | 5/21 [00:00<00:00, 24.65it/s, train_loss=0.00402, val_loss=0.00437]Epoch 19:  29%|██▊       | 6/21 [00:00<00:00, 27.39it/s, train_loss=0.00402, val_loss=0.00437]Epoch 19:  29%|██▊       | 6/21 [00:00<00:00, 25.30it/s, train_loss=0.00437, val_loss=0.00437]Epoch 19:  33%|███▎      | 7/21 [00:00<00:00, 26.56it/s, train_loss=0.00437, val_loss=0.00437]Epoch 19:  33%|███▎      | 7/21 [00:00<00:00, 24.97it/s, train_loss=0.00417, val_loss=0.00437]Epoch 19:  38%|███▊      | 8/21 [00:00<00:00, 26.11it/s, train_loss=0.00417, val_loss=0.00437]Epoch 19:  38%|███▊      | 8/21 [00:00<00:00, 24.75it/s, train_loss=0.00387, val_loss=0.00437]Epoch 19:  43%|████▎     | 9/21 [00:00<00:00, 25.91it/s, train_loss=0.00387, val_loss=0.00437]Epoch 19:  43%|████▎     | 9/21 [00:00<00:00, 24.72it/s, train_loss=0.00376, val_loss=0.00437]Epoch 19:  48%|████▊     | 10/21 [00:00<00:00, 25.70it/s, train_loss=0.00376, val_loss=0.00437]Epoch 19:  48%|████▊     | 10/21 [00:00<00:00, 24.53it/s, train_loss=0.00394, val_loss=0.00437]Epoch 19:  52%|█████▏    | 11/21 [00:00<00:00, 25.44it/s, train_loss=0.00394, val_loss=0.00437]Epoch 19:  52%|█████▏    | 11/21 [00:00<00:00, 24.55it/s, train_loss=0.0038, val_loss=0.00437] Epoch 19:  57%|█████▋    | 12/21 [00:00<00:00, 25.85it/s, train_loss=0.0038, val_loss=0.00437]Epoch 19:  57%|█████▋    | 12/21 [00:00<00:00, 24.94it/s, train_loss=0.00376, val_loss=0.00437]Epoch 19:  62%|██████▏   | 13/21 [00:00<00:00, 25.69it/s, train_loss=0.00376, val_loss=0.00437]Epoch 19:  62%|██████▏   | 13/21 [00:00<00:00, 24.12it/s, train_loss=0.00432, val_loss=0.00437]Epoch 19:  67%|██████▋   | 14/21 [00:00<00:00, 24.63it/s, train_loss=0.00432, val_loss=0.00437]Epoch 19:  67%|██████▋   | 14/21 [00:00<00:00, 23.87it/s, train_loss=0.00399, val_loss=0.00437]Epoch 19:  71%|███████▏  | 15/21 [00:00<00:00, 25.21it/s, train_loss=0.00399, val_loss=0.00437]Epoch 19:  71%|███████▏  | 15/21 [00:00<00:00, 24.02it/s, train_loss=0.00417, val_loss=0.00437]Epoch 19:  76%|███████▌  | 16/21 [00:00<00:00, 24.54it/s, train_loss=0.00417, val_loss=0.00437]Epoch 19:  76%|███████▌  | 16/21 [00:00<00:00, 23.91it/s, train_loss=0.0043, val_loss=0.00437] Epoch 19:  81%|████████  | 17/21 [00:00<00:00, 24.50it/s, train_loss=0.0043, val_loss=0.00437]Epoch 19:  81%|████████  | 17/21 [00:00<00:00, 23.96it/s, train_loss=0.00375, val_loss=0.00437]Epoch 19:  86%|████████▌ | 18/21 [00:00<00:00, 25.04it/s, train_loss=0.00375, val_loss=0.00437]Epoch 19:  86%|████████▌ | 18/21 [00:00<00:00, 24.45it/s, train_loss=0.00392, val_loss=0.00437]Epoch 19:  90%|█████████ | 19/21 [00:00<00:00, 24.92it/s, train_loss=0.00392, val_loss=0.00437]Epoch 19:  90%|█████████ | 19/21 [00:00<00:00, 24.35it/s, train_loss=0.00379, val_loss=0.00437]Epoch 19:  95%|█████████▌| 20/21 [00:00<00:00, 24.77it/s, train_loss=0.00379, val_loss=0.00437]Epoch 19:  95%|█████████▌| 20/21 [00:00<00:00, 24.28it/s, train_loss=0.00388, val_loss=0.00437]Epoch 19: 100%|██████████| 21/21 [00:00<00:00, 24.68it/s, train_loss=0.00388, val_loss=0.00437]Epoch 19: 100%|██████████| 21/21 [00:00<00:00, 24.15it/s, train_loss=0.00379, val_loss=0.00437]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 59.24it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 52.68it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 31.37it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 26.41it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 24.12it/s][A
                                                                      [AEpoch 19: 100%|██████████| 21/21 [00:01<00:00, 18.05it/s, train_loss=0.00379, val_loss=0.00425]Epoch 19: 100%|██████████| 21/21 [00:01<00:00, 17.77it/s, train_loss=0.00379, val_loss=0.00425]Epoch 19:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00379, val_loss=0.00425]         Epoch 20:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00379, val_loss=0.00425]Epoch 20:   5%|▍         | 1/21 [00:00<00:00, 23.00it/s, train_loss=0.00379, val_loss=0.00425]Epoch 20:   5%|▍         | 1/21 [00:00<00:01, 16.08it/s, train_loss=0.0042, val_loss=0.00425] Epoch 20:  10%|▉         | 2/21 [00:00<00:00, 22.67it/s, train_loss=0.0042, val_loss=0.00425]Epoch 20:  10%|▉         | 2/21 [00:00<00:01, 18.78it/s, train_loss=0.00384, val_loss=0.00425]Epoch 20:  14%|█▍        | 3/21 [00:00<00:00, 22.47it/s, train_loss=0.00384, val_loss=0.00425]Epoch 20:  14%|█▍        | 3/21 [00:00<00:00, 19.84it/s, train_loss=0.0038, val_loss=0.00425] Epoch 20:  19%|█▉        | 4/21 [00:00<00:00, 24.83it/s, train_loss=0.0038, val_loss=0.00425]Epoch 20:  19%|█▉        | 4/21 [00:00<00:00, 22.23it/s, train_loss=0.00387, val_loss=0.00425]Epoch 20:  24%|██▍       | 5/21 [00:00<00:00, 24.16it/s, train_loss=0.00387, val_loss=0.00425]Epoch 20:  24%|██▍       | 5/21 [00:00<00:00, 22.25it/s, train_loss=0.00403, val_loss=0.00425]Epoch 20:  29%|██▊       | 6/21 [00:00<00:00, 23.84it/s, train_loss=0.00403, val_loss=0.00425]Epoch 20:  29%|██▊       | 6/21 [00:00<00:00, 22.35it/s, train_loss=0.00407, val_loss=0.00425]Epoch 20:  33%|███▎      | 7/21 [00:00<00:00, 25.23it/s, train_loss=0.00407, val_loss=0.00425]Epoch 20:  33%|███▎      | 7/21 [00:00<00:00, 23.53it/s, train_loss=0.0041, val_loss=0.00425] Epoch 20:  38%|███▊      | 8/21 [00:00<00:00, 24.67it/s, train_loss=0.0041, val_loss=0.00425]Epoch 20:  38%|███▊      | 8/21 [00:00<00:00, 23.38it/s, train_loss=0.00398, val_loss=0.00425]Epoch 20:  43%|████▎     | 9/21 [00:00<00:00, 24.43it/s, train_loss=0.00398, val_loss=0.00425]Epoch 20:  43%|████▎     | 9/21 [00:00<00:00, 23.31it/s, train_loss=0.00394, val_loss=0.00425]Epoch 20:  48%|████▊     | 10/21 [00:00<00:00, 24.20it/s, train_loss=0.00394, val_loss=0.00425]Epoch 20:  48%|████▊     | 10/21 [00:00<00:00, 23.25it/s, train_loss=0.00402, val_loss=0.00425]Epoch 20:  52%|█████▏    | 11/21 [00:00<00:00, 24.15it/s, train_loss=0.00402, val_loss=0.00425]Epoch 20:  52%|█████▏    | 11/21 [00:00<00:00, 23.18it/s, train_loss=0.00404, val_loss=0.00425]Epoch 20:  57%|█████▋    | 12/21 [00:00<00:00, 24.00it/s, train_loss=0.00404, val_loss=0.00425]Epoch 20:  57%|█████▋    | 12/21 [00:00<00:00, 23.11it/s, train_loss=0.00421, val_loss=0.00425]Epoch 20:  62%|██████▏   | 13/21 [00:00<00:00, 23.87it/s, train_loss=0.00421, val_loss=0.00425]Epoch 20:  62%|██████▏   | 13/21 [00:00<00:00, 23.06it/s, train_loss=0.00374, val_loss=0.00425]Epoch 20:  67%|██████▋   | 14/21 [00:00<00:00, 24.49it/s, train_loss=0.00374, val_loss=0.00425]Epoch 20:  67%|██████▋   | 14/21 [00:00<00:00, 23.64it/s, train_loss=0.00387, val_loss=0.00425]Epoch 20:  71%|███████▏  | 15/21 [00:00<00:00, 24.21it/s, train_loss=0.00387, val_loss=0.00425]Epoch 20:  71%|███████▏  | 15/21 [00:00<00:00, 23.52it/s, train_loss=0.00393, val_loss=0.00425]Epoch 20:  76%|███████▌  | 16/21 [00:00<00:00, 24.08it/s, train_loss=0.00393, val_loss=0.00425]Epoch 20:  76%|███████▌  | 16/21 [00:00<00:00, 23.44it/s, train_loss=0.00373, val_loss=0.00425]Epoch 20:  81%|████████  | 17/21 [00:00<00:00, 23.98it/s, train_loss=0.00373, val_loss=0.00425]Epoch 20:  81%|████████  | 17/21 [00:00<00:00, 23.40it/s, train_loss=0.00386, val_loss=0.00425]Epoch 20:  86%|████████▌ | 18/21 [00:00<00:00, 23.90it/s, train_loss=0.00386, val_loss=0.00425]Epoch 20:  86%|████████▌ | 18/21 [00:00<00:00, 23.37it/s, train_loss=0.00345, val_loss=0.00425]Epoch 20:  90%|█████████ | 19/21 [00:00<00:00, 23.86it/s, train_loss=0.00345, val_loss=0.00425]Epoch 20:  90%|█████████ | 19/21 [00:00<00:00, 23.33it/s, train_loss=0.0037, val_loss=0.00425] Epoch 20:  95%|█████████▌| 20/21 [00:00<00:00, 23.78it/s, train_loss=0.0037, val_loss=0.00425]Epoch 20:  95%|█████████▌| 20/21 [00:00<00:00, 23.30it/s, train_loss=0.00376, val_loss=0.00425]Epoch 20: 100%|██████████| 21/21 [00:00<00:00, 23.69it/s, train_loss=0.00376, val_loss=0.00425]Epoch 20: 100%|██████████| 21/21 [00:00<00:00, 23.26it/s, train_loss=0.00379, val_loss=0.00425]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 25.50it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 20.72it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 19.86it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 19.24it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 21.05it/s][A
                                                                      [AEpoch 20: 100%|██████████| 21/21 [00:01<00:00, 16.52it/s, train_loss=0.00379, val_loss=0.00419]Epoch 20: 100%|██████████| 21/21 [00:01<00:00, 16.28it/s, train_loss=0.00379, val_loss=0.00419]Epoch 20:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00379, val_loss=0.00419]         Epoch 21:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00379, val_loss=0.00419]Epoch 21:   5%|▍         | 1/21 [00:00<00:00, 22.33it/s, train_loss=0.00379, val_loss=0.00419]Epoch 21:   5%|▍         | 1/21 [00:00<00:01, 16.07it/s, train_loss=0.00392, val_loss=0.00419]Epoch 21:  10%|▉         | 2/21 [00:00<00:00, 22.65it/s, train_loss=0.00392, val_loss=0.00419]Epoch 21:  10%|▉         | 2/21 [00:00<00:00, 19.14it/s, train_loss=0.00378, val_loss=0.00419]Epoch 21:  14%|█▍        | 3/21 [00:00<00:00, 22.70it/s, train_loss=0.00378, val_loss=0.00419]Epoch 21:  14%|█▍        | 3/21 [00:00<00:00, 19.98it/s, train_loss=0.00392, val_loss=0.00419]Epoch 21:  19%|█▉        | 4/21 [00:00<00:00, 22.71it/s, train_loss=0.00392, val_loss=0.00419]Epoch 21:  19%|█▉        | 4/21 [00:00<00:00, 20.70it/s, train_loss=0.00371, val_loss=0.00419]Epoch 21:  24%|██▍       | 5/21 [00:00<00:00, 22.67it/s, train_loss=0.00371, val_loss=0.00419]Epoch 21:  24%|██▍       | 5/21 [00:00<00:00, 21.07it/s, train_loss=0.00364, val_loss=0.00419]Epoch 21:  29%|██▊       | 6/21 [00:00<00:00, 22.78it/s, train_loss=0.00364, val_loss=0.00419]Epoch 21:  29%|██▊       | 6/21 [00:00<00:00, 21.30it/s, train_loss=0.00385, val_loss=0.00419]Epoch 21:  33%|███▎      | 7/21 [00:00<00:00, 24.07it/s, train_loss=0.00385, val_loss=0.00419]Epoch 21:  33%|███▎      | 7/21 [00:00<00:00, 22.56it/s, train_loss=0.00392, val_loss=0.00419]Epoch 21:  38%|███▊      | 8/21 [00:00<00:00, 23.75it/s, train_loss=0.00392, val_loss=0.00419]Epoch 21:  38%|███▊      | 8/21 [00:00<00:00, 22.56it/s, train_loss=0.00371, val_loss=0.00419]Epoch 21:  43%|████▎     | 9/21 [00:00<00:00, 23.59it/s, train_loss=0.00371, val_loss=0.00419]Epoch 21:  43%|████▎     | 9/21 [00:00<00:00, 22.56it/s, train_loss=0.00391, val_loss=0.00419]Epoch 21:  48%|████▊     | 10/21 [00:00<00:00, 23.37it/s, train_loss=0.00391, val_loss=0.00419]Epoch 21:  48%|████▊     | 10/21 [00:00<00:00, 22.42it/s, train_loss=0.00382, val_loss=0.00419]Epoch 21:  52%|█████▏    | 11/21 [00:00<00:00, 23.28it/s, train_loss=0.00382, val_loss=0.00419]Epoch 21:  52%|█████▏    | 11/21 [00:00<00:00, 22.44it/s, train_loss=0.00378, val_loss=0.00419]Epoch 21:  57%|█████▋    | 12/21 [00:00<00:00, 22.74it/s, train_loss=0.00378, val_loss=0.00419]Epoch 21:  57%|█████▋    | 12/21 [00:00<00:00, 21.95it/s, train_loss=0.00376, val_loss=0.00419]Epoch 21:  62%|██████▏   | 13/21 [00:00<00:00, 22.64it/s, train_loss=0.00376, val_loss=0.00419]Epoch 21:  62%|██████▏   | 13/21 [00:00<00:00, 21.92it/s, train_loss=0.00376, val_loss=0.00419]Epoch 21:  67%|██████▋   | 14/21 [00:00<00:00, 22.59it/s, train_loss=0.00376, val_loss=0.00419]Epoch 21:  67%|██████▋   | 14/21 [00:00<00:00, 21.98it/s, train_loss=0.00393, val_loss=0.00419]Epoch 21:  71%|███████▏  | 15/21 [00:00<00:00, 22.59it/s, train_loss=0.00393, val_loss=0.00419]Epoch 21:  71%|███████▏  | 15/21 [00:00<00:00, 22.04it/s, train_loss=0.00406, val_loss=0.00419]Epoch 21:  76%|███████▌  | 16/21 [00:00<00:00, 22.64it/s, train_loss=0.00406, val_loss=0.00419]Epoch 21:  76%|███████▌  | 16/21 [00:00<00:00, 22.09it/s, train_loss=0.00385, val_loss=0.00419]Epoch 21:  81%|████████  | 17/21 [00:00<00:00, 22.61it/s, train_loss=0.00385, val_loss=0.00419]Epoch 21:  81%|████████  | 17/21 [00:00<00:00, 22.11it/s, train_loss=0.00357, val_loss=0.00419]Epoch 21:  86%|████████▌ | 18/21 [00:00<00:00, 22.64it/s, train_loss=0.00357, val_loss=0.00419]Epoch 21:  86%|████████▌ | 18/21 [00:00<00:00, 22.14it/s, train_loss=0.00376, val_loss=0.00419]Epoch 21:  90%|█████████ | 19/21 [00:00<00:00, 22.60it/s, train_loss=0.00376, val_loss=0.00419]Epoch 21:  90%|█████████ | 19/21 [00:00<00:00, 22.14it/s, train_loss=0.00361, val_loss=0.00419]Epoch 21:  95%|█████████▌| 20/21 [00:00<00:00, 22.60it/s, train_loss=0.00361, val_loss=0.00419]Epoch 21:  95%|█████████▌| 20/21 [00:00<00:00, 22.15it/s, train_loss=0.00402, val_loss=0.00419]Epoch 21: 100%|██████████| 21/21 [00:00<00:00, 22.59it/s, train_loss=0.00402, val_loss=0.00419]Epoch 21: 100%|██████████| 21/21 [00:00<00:00, 22.17it/s, train_loss=0.00393, val_loss=0.00419]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.12it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.96it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 18.77it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 24.21it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 26.19it/s][A
                                                                      [AEpoch 21: 100%|██████████| 21/21 [00:01<00:00, 16.23it/s, train_loss=0.00393, val_loss=0.00412]Epoch 21: 100%|██████████| 21/21 [00:01<00:00, 16.01it/s, train_loss=0.00393, val_loss=0.00412]Epoch 21:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00393, val_loss=0.00412]         Epoch 22:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00393, val_loss=0.00412]Epoch 22:   5%|▍         | 1/21 [00:00<00:00, 22.16it/s, train_loss=0.00393, val_loss=0.00412]Epoch 22:   5%|▍         | 1/21 [00:00<00:01, 15.86it/s, train_loss=0.00364, val_loss=0.00412]Epoch 22:  10%|▉         | 2/21 [00:00<00:00, 22.23it/s, train_loss=0.00364, val_loss=0.00412]Epoch 22:  10%|▉         | 2/21 [00:00<00:01, 18.48it/s, train_loss=0.00346, val_loss=0.00412]Epoch 22:  14%|█▍        | 3/21 [00:00<00:00, 22.34it/s, train_loss=0.00346, val_loss=0.00412]Epoch 22:  14%|█▍        | 3/21 [00:00<00:00, 19.71it/s, train_loss=0.00383, val_loss=0.00412]Epoch 22:  19%|█▉        | 4/21 [00:00<00:00, 22.39it/s, train_loss=0.00383, val_loss=0.00412]Epoch 22:  19%|█▉        | 4/21 [00:00<00:00, 20.43it/s, train_loss=0.00388, val_loss=0.00412]Epoch 22:  24%|██▍       | 5/21 [00:00<00:00, 22.47it/s, train_loss=0.00388, val_loss=0.00412]Epoch 22:  24%|██▍       | 5/21 [00:00<00:00, 20.84it/s, train_loss=0.00379, val_loss=0.00412]Epoch 22:  29%|██▊       | 6/21 [00:00<00:00, 22.48it/s, train_loss=0.00379, val_loss=0.00412]Epoch 22:  29%|██▊       | 6/21 [00:00<00:00, 21.14it/s, train_loss=0.00369, val_loss=0.00412]Epoch 22:  33%|███▎      | 7/21 [00:00<00:00, 22.54it/s, train_loss=0.00369, val_loss=0.00412]Epoch 22:  33%|███▎      | 7/21 [00:00<00:00, 21.32it/s, train_loss=0.00385, val_loss=0.00412]Epoch 22:  38%|███▊      | 8/21 [00:00<00:00, 22.50it/s, train_loss=0.00385, val_loss=0.00412]Epoch 22:  38%|███▊      | 8/21 [00:00<00:00, 21.43it/s, train_loss=0.00394, val_loss=0.00412]Epoch 22:  43%|████▎     | 9/21 [00:00<00:00, 22.54it/s, train_loss=0.00394, val_loss=0.00412]Epoch 22:  43%|████▎     | 9/21 [00:00<00:00, 21.61it/s, train_loss=0.00409, val_loss=0.00412]Epoch 22:  48%|████▊     | 10/21 [00:00<00:00, 22.58it/s, train_loss=0.00409, val_loss=0.00412]Epoch 22:  48%|████▊     | 10/21 [00:00<00:00, 21.73it/s, train_loss=0.00394, val_loss=0.00412]Epoch 22:  52%|█████▏    | 11/21 [00:00<00:00, 22.55it/s, train_loss=0.00394, val_loss=0.00412]Epoch 22:  52%|█████▏    | 11/21 [00:00<00:00, 21.80it/s, train_loss=0.00377, val_loss=0.00412]Epoch 22:  57%|█████▋    | 12/21 [00:00<00:00, 22.61it/s, train_loss=0.00377, val_loss=0.00412]Epoch 22:  57%|█████▋    | 12/21 [00:00<00:00, 21.86it/s, train_loss=0.00389, val_loss=0.00412]Epoch 22:  62%|██████▏   | 13/21 [00:00<00:00, 22.58it/s, train_loss=0.00389, val_loss=0.00412]Epoch 22:  62%|██████▏   | 13/21 [00:00<00:00, 21.91it/s, train_loss=0.00354, val_loss=0.00412]Epoch 22:  67%|██████▋   | 14/21 [00:00<00:00, 22.59it/s, train_loss=0.00354, val_loss=0.00412]Epoch 22:  67%|██████▋   | 14/21 [00:00<00:00, 21.96it/s, train_loss=0.00376, val_loss=0.00412]Epoch 22:  71%|███████▏  | 15/21 [00:00<00:00, 22.57it/s, train_loss=0.00376, val_loss=0.00412]Epoch 22:  71%|███████▏  | 15/21 [00:00<00:00, 21.98it/s, train_loss=0.00381, val_loss=0.00412]Epoch 22:  76%|███████▌  | 16/21 [00:00<00:00, 22.59it/s, train_loss=0.00381, val_loss=0.00412]Epoch 22:  76%|███████▌  | 16/21 [00:00<00:00, 22.05it/s, train_loss=0.00344, val_loss=0.00412]Epoch 22:  81%|████████  | 17/21 [00:00<00:00, 22.59it/s, train_loss=0.00344, val_loss=0.00412]Epoch 22:  81%|████████  | 17/21 [00:00<00:00, 22.08it/s, train_loss=0.0039, val_loss=0.00412] Epoch 22:  86%|████████▌ | 18/21 [00:00<00:00, 22.67it/s, train_loss=0.0039, val_loss=0.00412]Epoch 22:  86%|████████▌ | 18/21 [00:00<00:00, 22.13it/s, train_loss=0.00354, val_loss=0.00412]Epoch 22:  90%|█████████ | 19/21 [00:00<00:00, 22.65it/s, train_loss=0.00354, val_loss=0.00412]Epoch 22:  90%|█████████ | 19/21 [00:00<00:00, 22.14it/s, train_loss=0.00343, val_loss=0.00412]Epoch 22:  95%|█████████▌| 20/21 [00:00<00:00, 22.59it/s, train_loss=0.00343, val_loss=0.00412]Epoch 22:  95%|█████████▌| 20/21 [00:00<00:00, 22.14it/s, train_loss=0.00371, val_loss=0.00412]Epoch 22: 100%|██████████| 21/21 [00:00<00:00, 22.57it/s, train_loss=0.00371, val_loss=0.00412]Epoch 22: 100%|██████████| 21/21 [00:00<00:00, 22.17it/s, train_loss=0.00377, val_loss=0.00412]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.11it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 15.04it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 16.99it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 17.15it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 17.31it/s][A
                                                                      [AEpoch 22: 100%|██████████| 21/21 [00:01<00:00, 15.06it/s, train_loss=0.00377, val_loss=0.00409]Epoch 22: 100%|██████████| 21/21 [00:01<00:00, 14.87it/s, train_loss=0.00377, val_loss=0.00409]Epoch 22:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00377, val_loss=0.00409]         Epoch 23:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00377, val_loss=0.00409]Epoch 23:   5%|▍         | 1/21 [00:00<00:00, 22.06it/s, train_loss=0.00377, val_loss=0.00409]Epoch 23:   5%|▍         | 1/21 [00:00<00:01, 15.68it/s, train_loss=0.0035, val_loss=0.00409] Epoch 23:  10%|▉         | 2/21 [00:00<00:00, 22.18it/s, train_loss=0.0035, val_loss=0.00409]Epoch 23:  10%|▉         | 2/21 [00:00<00:01, 18.78it/s, train_loss=0.00381, val_loss=0.00409]Epoch 23:  14%|█▍        | 3/21 [00:00<00:00, 25.90it/s, train_loss=0.00381, val_loss=0.00409]Epoch 23:  14%|█▍        | 3/21 [00:00<00:00, 22.13it/s, train_loss=0.00373, val_loss=0.00409]Epoch 23:  19%|█▉        | 4/21 [00:00<00:00, 24.49it/s, train_loss=0.00373, val_loss=0.00409]Epoch 23:  19%|█▉        | 4/21 [00:00<00:00, 22.15it/s, train_loss=0.00366, val_loss=0.00409]Epoch 23:  24%|██▍       | 5/21 [00:00<00:00, 24.02it/s, train_loss=0.00366, val_loss=0.00409]Epoch 23:  24%|██▍       | 5/21 [00:00<00:00, 22.23it/s, train_loss=0.00363, val_loss=0.00409]Epoch 23:  29%|██▊       | 6/21 [00:00<00:00, 23.86it/s, train_loss=0.00363, val_loss=0.00409]Epoch 23:  29%|██▊       | 6/21 [00:00<00:00, 22.30it/s, train_loss=0.00359, val_loss=0.00409]Epoch 23:  33%|███▎      | 7/21 [00:00<00:00, 23.58it/s, train_loss=0.00359, val_loss=0.00409]Epoch 23:  33%|███▎      | 7/21 [00:00<00:00, 22.33it/s, train_loss=0.00358, val_loss=0.00409]Epoch 23:  38%|███▊      | 8/21 [00:00<00:00, 23.51it/s, train_loss=0.00358, val_loss=0.00409]Epoch 23:  38%|███▊      | 8/21 [00:00<00:00, 22.37it/s, train_loss=0.00363, val_loss=0.00409]Epoch 23:  43%|████▎     | 9/21 [00:00<00:00, 23.47it/s, train_loss=0.00363, val_loss=0.00409]Epoch 23:  43%|████▎     | 9/21 [00:00<00:00, 22.39it/s, train_loss=0.00382, val_loss=0.00409]Epoch 23:  48%|████▊     | 10/21 [00:00<00:00, 23.30it/s, train_loss=0.00382, val_loss=0.00409]Epoch 23:  48%|████▊     | 10/21 [00:00<00:00, 22.41it/s, train_loss=0.00354, val_loss=0.00409]Epoch 23:  52%|█████▏    | 11/21 [00:00<00:00, 23.30it/s, train_loss=0.00354, val_loss=0.00409]Epoch 23:  52%|█████▏    | 11/21 [00:00<00:00, 22.42it/s, train_loss=0.00388, val_loss=0.00409]Epoch 23:  57%|█████▋    | 12/21 [00:00<00:00, 23.18it/s, train_loss=0.00388, val_loss=0.00409]Epoch 23:  57%|█████▋    | 12/21 [00:00<00:00, 22.43it/s, train_loss=0.0036, val_loss=0.00409] Epoch 23:  62%|██████▏   | 13/21 [00:00<00:00, 23.14it/s, train_loss=0.0036, val_loss=0.00409]Epoch 23:  62%|██████▏   | 13/21 [00:00<00:00, 22.45it/s, train_loss=0.00359, val_loss=0.00409]Epoch 23:  67%|██████▋   | 14/21 [00:00<00:00, 23.07it/s, train_loss=0.00359, val_loss=0.00409]Epoch 23:  67%|██████▋   | 14/21 [00:00<00:00, 22.46it/s, train_loss=0.00403, val_loss=0.00409]Epoch 23:  71%|███████▏  | 15/21 [00:00<00:00, 23.07it/s, train_loss=0.00403, val_loss=0.00409]Epoch 23:  71%|███████▏  | 15/21 [00:00<00:00, 22.45it/s, train_loss=0.0036, val_loss=0.00409] Epoch 23:  76%|███████▌  | 16/21 [00:00<00:00, 23.02it/s, train_loss=0.0036, val_loss=0.00409]Epoch 23:  76%|███████▌  | 16/21 [00:00<00:00, 22.44it/s, train_loss=0.00374, val_loss=0.00409]Epoch 23:  81%|████████  | 17/21 [00:00<00:00, 22.97it/s, train_loss=0.00374, val_loss=0.00409]Epoch 23:  81%|████████  | 17/21 [00:00<00:00, 22.43it/s, train_loss=0.00365, val_loss=0.00409]Epoch 23:  86%|████████▌ | 18/21 [00:00<00:00, 22.91it/s, train_loss=0.00365, val_loss=0.00409]Epoch 23:  86%|████████▌ | 18/21 [00:00<00:00, 22.41it/s, train_loss=0.00366, val_loss=0.00409]Epoch 23:  90%|█████████ | 19/21 [00:00<00:00, 22.89it/s, train_loss=0.00366, val_loss=0.00409]Epoch 23:  90%|█████████ | 19/21 [00:00<00:00, 22.40it/s, train_loss=0.00352, val_loss=0.00409]Epoch 23:  95%|█████████▌| 20/21 [00:00<00:00, 22.87it/s, train_loss=0.00352, val_loss=0.00409]Epoch 23:  95%|█████████▌| 20/21 [00:00<00:00, 22.46it/s, train_loss=0.00358, val_loss=0.00409]Epoch 23: 100%|██████████| 21/21 [00:00<00:00, 23.34it/s, train_loss=0.00358, val_loss=0.00409]Epoch 23: 100%|██████████| 21/21 [00:00<00:00, 22.41it/s, train_loss=0.0039, val_loss=0.00409] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.11it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.13it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.71it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 13.65it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 14.31it/s][A
                                                                      [AEpoch 23: 100%|██████████| 21/21 [00:01<00:00, 14.50it/s, train_loss=0.0039, val_loss=0.00401]Epoch 23: 100%|██████████| 21/21 [00:01<00:00, 14.32it/s, train_loss=0.0039, val_loss=0.00401]Epoch 23:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0039, val_loss=0.00401]         Epoch 24:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0039, val_loss=0.00401]Epoch 24:   5%|▍         | 1/21 [00:00<00:00, 22.39it/s, train_loss=0.0039, val_loss=0.00401]Epoch 24:   5%|▍         | 1/21 [00:00<00:01, 16.00it/s, train_loss=0.00367, val_loss=0.00401]Epoch 24:  10%|▉         | 2/21 [00:00<00:00, 22.46it/s, train_loss=0.00367, val_loss=0.00401]Epoch 24:  10%|▉         | 2/21 [00:00<00:01, 18.71it/s, train_loss=0.00375, val_loss=0.00401]Epoch 24:  14%|█▍        | 3/21 [00:00<00:00, 22.55it/s, train_loss=0.00375, val_loss=0.00401]Epoch 24:  14%|█▍        | 3/21 [00:00<00:00, 20.05it/s, train_loss=0.00373, val_loss=0.00401]Epoch 24:  19%|█▉        | 4/21 [00:00<00:00, 22.73it/s, train_loss=0.00373, val_loss=0.00401]Epoch 24:  19%|█▉        | 4/21 [00:00<00:00, 20.64it/s, train_loss=0.00359, val_loss=0.00401]Epoch 24:  24%|██▍       | 5/21 [00:00<00:00, 24.54it/s, train_loss=0.00359, val_loss=0.00401]Epoch 24:  24%|██▍       | 5/21 [00:00<00:00, 22.48it/s, train_loss=0.00349, val_loss=0.00401]Epoch 24:  29%|██▊       | 6/21 [00:00<00:00, 24.14it/s, train_loss=0.00349, val_loss=0.00401]Epoch 24:  29%|██▊       | 6/21 [00:00<00:00, 22.53it/s, train_loss=0.00349, val_loss=0.00401]Epoch 24:  33%|███▎      | 7/21 [00:00<00:00, 23.81it/s, train_loss=0.00349, val_loss=0.00401]Epoch 24:  33%|███▎      | 7/21 [00:00<00:00, 22.46it/s, train_loss=0.00389, val_loss=0.00401]Epoch 24:  38%|███▊      | 8/21 [00:00<00:00, 23.70it/s, train_loss=0.00389, val_loss=0.00401]Epoch 24:  38%|███▊      | 8/21 [00:00<00:00, 22.57it/s, train_loss=0.00355, val_loss=0.00401]Epoch 24:  43%|████▎     | 9/21 [00:00<00:00, 23.63it/s, train_loss=0.00355, val_loss=0.00401]Epoch 24:  43%|████▎     | 9/21 [00:00<00:00, 22.59it/s, train_loss=0.0036, val_loss=0.00401] Epoch 24:  48%|████▊     | 10/21 [00:00<00:00, 23.55it/s, train_loss=0.0036, val_loss=0.00401]Epoch 24:  48%|████▊     | 10/21 [00:00<00:00, 22.59it/s, train_loss=0.00374, val_loss=0.00401]Epoch 24:  52%|█████▏    | 11/21 [00:00<00:00, 23.45it/s, train_loss=0.00374, val_loss=0.00401]Epoch 24:  52%|█████▏    | 11/21 [00:00<00:00, 22.59it/s, train_loss=0.00354, val_loss=0.00401]Epoch 24:  57%|█████▋    | 12/21 [00:00<00:00, 23.39it/s, train_loss=0.00354, val_loss=0.00401]Epoch 24:  57%|█████▋    | 12/21 [00:00<00:00, 22.60it/s, train_loss=0.0036, val_loss=0.00401] Epoch 24:  62%|██████▏   | 13/21 [00:00<00:00, 23.30it/s, train_loss=0.0036, val_loss=0.00401]Epoch 24:  62%|██████▏   | 13/21 [00:00<00:00, 22.61it/s, train_loss=0.00339, val_loss=0.00401]Epoch 24:  67%|██████▋   | 14/21 [00:00<00:00, 23.62it/s, train_loss=0.00339, val_loss=0.00401]Epoch 24:  67%|██████▋   | 14/21 [00:00<00:00, 22.89it/s, train_loss=0.00363, val_loss=0.00401]Epoch 24:  71%|███████▏  | 15/21 [00:00<00:00, 23.51it/s, train_loss=0.00363, val_loss=0.00401]Epoch 24:  71%|███████▏  | 15/21 [00:00<00:00, 22.86it/s, train_loss=0.00365, val_loss=0.00401]Epoch 24:  76%|███████▌  | 16/21 [00:00<00:00, 23.44it/s, train_loss=0.00365, val_loss=0.00401]Epoch 24:  76%|███████▌  | 16/21 [00:00<00:00, 22.85it/s, train_loss=0.00341, val_loss=0.00401]Epoch 24:  81%|████████  | 17/21 [00:00<00:00, 23.37it/s, train_loss=0.00341, val_loss=0.00401]Epoch 24:  81%|████████  | 17/21 [00:00<00:00, 22.84it/s, train_loss=0.00355, val_loss=0.00401]Epoch 24:  86%|████████▌ | 18/21 [00:00<00:00, 23.35it/s, train_loss=0.00355, val_loss=0.00401]Epoch 24:  86%|████████▌ | 18/21 [00:00<00:00, 22.80it/s, train_loss=0.00381, val_loss=0.00401]Epoch 24:  90%|█████████ | 19/21 [00:00<00:00, 23.26it/s, train_loss=0.00381, val_loss=0.00401]Epoch 24:  90%|█████████ | 19/21 [00:00<00:00, 22.76it/s, train_loss=0.00351, val_loss=0.00401]Epoch 24:  95%|█████████▌| 20/21 [00:00<00:00, 23.23it/s, train_loss=0.00351, val_loss=0.00401]Epoch 24:  95%|█████████▌| 20/21 [00:00<00:00, 22.76it/s, train_loss=0.00369, val_loss=0.00401]Epoch 24: 100%|██████████| 21/21 [00:00<00:00, 23.17it/s, train_loss=0.00369, val_loss=0.00401]Epoch 24: 100%|██████████| 21/21 [00:00<00:00, 22.75it/s, train_loss=0.0036, val_loss=0.00401] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 135.41it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 158.42it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 172.33it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 91.22it/s] [A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 50.52it/s][A
                                                                      [AEpoch 24: 100%|██████████| 21/21 [00:01<00:00, 18.04it/s, train_loss=0.0036, val_loss=0.00399]Epoch 24: 100%|██████████| 21/21 [00:01<00:00, 17.78it/s, train_loss=0.0036, val_loss=0.00399]Epoch 24:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0036, val_loss=0.00399]         Epoch 25:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0036, val_loss=0.00399]Epoch 25:   5%|▍         | 1/21 [00:00<00:00, 22.92it/s, train_loss=0.0036, val_loss=0.00399]Epoch 25:   5%|▍         | 1/21 [00:00<00:01, 15.97it/s, train_loss=0.00355, val_loss=0.00399]Epoch 25:  10%|▉         | 2/21 [00:00<00:00, 22.26it/s, train_loss=0.00355, val_loss=0.00399]Epoch 25:  10%|▉         | 2/21 [00:00<00:01, 18.36it/s, train_loss=0.00348, val_loss=0.00399]Epoch 25:  14%|█▍        | 3/21 [00:00<00:00, 22.09it/s, train_loss=0.00348, val_loss=0.00399]Epoch 25:  14%|█▍        | 3/21 [00:00<00:00, 19.53it/s, train_loss=0.00356, val_loss=0.00399]Epoch 25:  19%|█▉        | 4/21 [00:00<00:00, 22.07it/s, train_loss=0.00356, val_loss=0.00399]Epoch 25:  19%|█▉        | 4/21 [00:00<00:00, 20.02it/s, train_loss=0.00357, val_loss=0.00399]Epoch 25:  24%|██▍       | 5/21 [00:00<00:00, 22.10it/s, train_loss=0.00357, val_loss=0.00399]Epoch 25:  24%|██▍       | 5/21 [00:00<00:00, 20.46it/s, train_loss=0.00358, val_loss=0.00399]Epoch 25:  29%|██▊       | 6/21 [00:00<00:00, 22.15it/s, train_loss=0.00358, val_loss=0.00399]Epoch 25:  29%|██▊       | 6/21 [00:00<00:00, 20.78it/s, train_loss=0.0037, val_loss=0.00399] Epoch 25:  33%|███▎      | 7/21 [00:00<00:00, 22.18it/s, train_loss=0.0037, val_loss=0.00399]Epoch 25:  33%|███▎      | 7/21 [00:00<00:00, 20.99it/s, train_loss=0.00365, val_loss=0.00399]Epoch 25:  38%|███▊      | 8/21 [00:00<00:00, 22.15it/s, train_loss=0.00365, val_loss=0.00399]Epoch 25:  38%|███▊      | 8/21 [00:00<00:00, 21.12it/s, train_loss=0.00367, val_loss=0.00399]Epoch 25:  43%|████▎     | 9/21 [00:00<00:00, 22.23it/s, train_loss=0.00367, val_loss=0.00399]Epoch 25:  43%|████▎     | 9/21 [00:00<00:00, 21.33it/s, train_loss=0.00346, val_loss=0.00399]Epoch 25:  48%|████▊     | 10/21 [00:00<00:00, 22.30it/s, train_loss=0.00346, val_loss=0.00399]Epoch 25:  48%|████▊     | 10/21 [00:00<00:00, 21.43it/s, train_loss=0.00363, val_loss=0.00399]Epoch 25:  52%|█████▏    | 11/21 [00:00<00:00, 22.31it/s, train_loss=0.00363, val_loss=0.00399]Epoch 25:  52%|█████▏    | 11/21 [00:00<00:00, 21.54it/s, train_loss=0.00349, val_loss=0.00399]Epoch 25:  57%|█████▋    | 12/21 [00:00<00:00, 22.30it/s, train_loss=0.00349, val_loss=0.00399]Epoch 25:  57%|█████▋    | 12/21 [00:00<00:00, 21.62it/s, train_loss=0.00353, val_loss=0.00399]Epoch 25:  62%|██████▏   | 13/21 [00:00<00:00, 22.38it/s, train_loss=0.00353, val_loss=0.00399]Epoch 25:  62%|██████▏   | 13/21 [00:00<00:00, 21.72it/s, train_loss=0.00352, val_loss=0.00399]Epoch 25:  67%|██████▋   | 14/21 [00:00<00:00, 22.41it/s, train_loss=0.00352, val_loss=0.00399]Epoch 25:  67%|██████▋   | 14/21 [00:00<00:00, 21.77it/s, train_loss=0.00372, val_loss=0.00399]Epoch 25:  71%|███████▏  | 15/21 [00:00<00:00, 22.73it/s, train_loss=0.00372, val_loss=0.00399]Epoch 25:  71%|███████▏  | 15/21 [00:00<00:00, 22.09it/s, train_loss=0.00357, val_loss=0.00399]Epoch 25:  76%|███████▌  | 16/21 [00:00<00:00, 22.64it/s, train_loss=0.00357, val_loss=0.00399]Epoch 25:  76%|███████▌  | 16/21 [00:00<00:00, 22.09it/s, train_loss=0.00359, val_loss=0.00399]Epoch 25:  81%|████████  | 17/21 [00:00<00:00, 22.63it/s, train_loss=0.00359, val_loss=0.00399]Epoch 25:  81%|████████  | 17/21 [00:00<00:00, 22.11it/s, train_loss=0.00357, val_loss=0.00399]Epoch 25:  86%|████████▌ | 18/21 [00:00<00:00, 22.64it/s, train_loss=0.00357, val_loss=0.00399]Epoch 25:  86%|████████▌ | 18/21 [00:00<00:00, 22.15it/s, train_loss=0.0032, val_loss=0.00399] Epoch 25:  90%|█████████ | 19/21 [00:00<00:00, 22.66it/s, train_loss=0.0032, val_loss=0.00399]Epoch 25:  90%|█████████ | 19/21 [00:00<00:00, 22.18it/s, train_loss=0.00349, val_loss=0.00399]Epoch 25:  95%|█████████▌| 20/21 [00:00<00:00, 22.66it/s, train_loss=0.00349, val_loss=0.00399]Epoch 25:  95%|█████████▌| 20/21 [00:00<00:00, 22.20it/s, train_loss=0.00353, val_loss=0.00399]Epoch 25: 100%|██████████| 21/21 [00:00<00:00, 22.65it/s, train_loss=0.00353, val_loss=0.00399]Epoch 25: 100%|██████████| 21/21 [00:00<00:00, 22.23it/s, train_loss=0.00364, val_loss=0.00399]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.18it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.20it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 12.75it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 13.63it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 14.32it/s][A
                                                                      [AEpoch 25: 100%|██████████| 21/21 [00:01<00:00, 14.47it/s, train_loss=0.00364, val_loss=0.00394]Epoch 25: 100%|██████████| 21/21 [00:01<00:00, 14.30it/s, train_loss=0.00364, val_loss=0.00394]Epoch 25:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00364, val_loss=0.00394]         Epoch 26:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00364, val_loss=0.00394]Epoch 26:   5%|▍         | 1/21 [00:00<00:00, 22.48it/s, train_loss=0.00364, val_loss=0.00394]Epoch 26:   5%|▍         | 1/21 [00:00<00:01, 16.12it/s, train_loss=0.00373, val_loss=0.00394]Epoch 26:  10%|▉         | 2/21 [00:00<00:00, 22.56it/s, train_loss=0.00373, val_loss=0.00394]Epoch 26:  10%|▉         | 2/21 [00:00<00:01, 18.71it/s, train_loss=0.00337, val_loss=0.00394]Epoch 26:  14%|█▍        | 3/21 [00:00<00:00, 22.56it/s, train_loss=0.00337, val_loss=0.00394]Epoch 26:  14%|█▍        | 3/21 [00:00<00:00, 19.88it/s, train_loss=0.00351, val_loss=0.00394]Epoch 26:  19%|█▉        | 4/21 [00:00<00:00, 22.33it/s, train_loss=0.00351, val_loss=0.00394]Epoch 26:  19%|█▉        | 4/21 [00:00<00:00, 20.41it/s, train_loss=0.00339, val_loss=0.00394]Epoch 26:  24%|██▍       | 5/21 [00:00<00:00, 22.51it/s, train_loss=0.00339, val_loss=0.00394]Epoch 26:  24%|██▍       | 5/21 [00:00<00:00, 20.82it/s, train_loss=0.0035, val_loss=0.00394] Epoch 26:  29%|██▊       | 6/21 [00:00<00:00, 22.51it/s, train_loss=0.0035, val_loss=0.00394]Epoch 26:  29%|██▊       | 6/21 [00:00<00:00, 21.19it/s, train_loss=0.00359, val_loss=0.00394]Epoch 26:  33%|███▎      | 7/21 [00:00<00:00, 22.64it/s, train_loss=0.00359, val_loss=0.00394]Epoch 26:  33%|███▎      | 7/21 [00:00<00:00, 21.41it/s, train_loss=0.00378, val_loss=0.00394]Epoch 26:  38%|███▊      | 8/21 [00:00<00:00, 22.70it/s, train_loss=0.00378, val_loss=0.00394]Epoch 26:  38%|███▊      | 8/21 [00:00<00:00, 21.62it/s, train_loss=0.00346, val_loss=0.00394]Epoch 26:  43%|████▎     | 9/21 [00:00<00:00, 22.65it/s, train_loss=0.00346, val_loss=0.00394]Epoch 26:  43%|████▎     | 9/21 [00:00<00:00, 21.69it/s, train_loss=0.00341, val_loss=0.00394]Epoch 26:  48%|████▊     | 10/21 [00:00<00:00, 22.67it/s, train_loss=0.00341, val_loss=0.00394]Epoch 26:  48%|████▊     | 10/21 [00:00<00:00, 21.83it/s, train_loss=0.00353, val_loss=0.00394]Epoch 26:  52%|█████▏    | 11/21 [00:00<00:00, 22.73it/s, train_loss=0.00353, val_loss=0.00394]Epoch 26:  52%|█████▏    | 11/21 [00:00<00:00, 21.96it/s, train_loss=0.00346, val_loss=0.00394]Epoch 26:  57%|█████▋    | 12/21 [00:00<00:00, 22.77it/s, train_loss=0.00346, val_loss=0.00394]Epoch 26:  57%|█████▋    | 12/21 [00:00<00:00, 22.07it/s, train_loss=0.00363, val_loss=0.00394]Epoch 26:  62%|██████▏   | 13/21 [00:00<00:00, 22.83it/s, train_loss=0.00363, val_loss=0.00394]Epoch 26:  62%|██████▏   | 13/21 [00:00<00:00, 22.17it/s, train_loss=0.00351, val_loss=0.00394]Epoch 26:  67%|██████▋   | 14/21 [00:00<00:00, 22.87it/s, train_loss=0.00351, val_loss=0.00394]Epoch 26:  67%|██████▋   | 14/21 [00:00<00:00, 22.21it/s, train_loss=0.0037, val_loss=0.00394] Epoch 26:  71%|███████▏  | 15/21 [00:00<00:00, 22.81it/s, train_loss=0.0037, val_loss=0.00394]Epoch 26:  71%|███████▏  | 15/21 [00:00<00:00, 22.22it/s, train_loss=0.00368, val_loss=0.00394]Epoch 26:  76%|███████▌  | 16/21 [00:00<00:00, 22.83it/s, train_loss=0.00368, val_loss=0.00394]Epoch 26:  76%|███████▌  | 16/21 [00:00<00:00, 22.25it/s, train_loss=0.00333, val_loss=0.00394]Epoch 26:  81%|████████  | 17/21 [00:00<00:00, 22.78it/s, train_loss=0.00333, val_loss=0.00394]Epoch 26:  81%|████████  | 17/21 [00:00<00:00, 22.24it/s, train_loss=0.00343, val_loss=0.00394]Epoch 26:  86%|████████▌ | 18/21 [00:00<00:00, 22.77it/s, train_loss=0.00343, val_loss=0.00394]Epoch 26:  86%|████████▌ | 18/21 [00:00<00:00, 22.30it/s, train_loss=0.00355, val_loss=0.00394]Epoch 26:  90%|█████████ | 19/21 [00:00<00:00, 22.82it/s, train_loss=0.00355, val_loss=0.00394]Epoch 26:  90%|█████████ | 19/21 [00:00<00:00, 22.36it/s, train_loss=0.00347, val_loss=0.00394]Epoch 26:  95%|█████████▌| 20/21 [00:00<00:00, 22.83it/s, train_loss=0.00347, val_loss=0.00394]Epoch 26:  95%|█████████▌| 20/21 [00:00<00:00, 22.36it/s, train_loss=0.00336, val_loss=0.00394]Epoch 26: 100%|██████████| 21/21 [00:00<00:00, 22.79it/s, train_loss=0.00336, val_loss=0.00394]Epoch 26: 100%|██████████| 21/21 [00:00<00:00, 22.38it/s, train_loss=0.00329, val_loss=0.00394]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.13it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.14it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 14.32it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 17.32it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 17.47it/s][A
                                                                      [AEpoch 26: 100%|██████████| 21/21 [00:01<00:00, 15.20it/s, train_loss=0.00329, val_loss=0.00389]Epoch 26: 100%|██████████| 21/21 [00:01<00:00, 15.00it/s, train_loss=0.00329, val_loss=0.00389]Epoch 26:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00329, val_loss=0.00389]         Epoch 27:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00329, val_loss=0.00389]Epoch 27:   5%|▍         | 1/21 [00:00<00:00, 23.22it/s, train_loss=0.00329, val_loss=0.00389]Epoch 27:   5%|▍         | 1/21 [00:00<00:01, 16.39it/s, train_loss=0.0036, val_loss=0.00389] Epoch 27:  10%|▉         | 2/21 [00:00<00:00, 23.34it/s, train_loss=0.0036, val_loss=0.00389]Epoch 27:  10%|▉         | 2/21 [00:00<00:00, 19.38it/s, train_loss=0.00353, val_loss=0.00389]Epoch 27:  14%|█▍        | 3/21 [00:00<00:00, 23.44it/s, train_loss=0.00353, val_loss=0.00389]Epoch 27:  14%|█▍        | 3/21 [00:00<00:00, 20.63it/s, train_loss=0.00336, val_loss=0.00389]Epoch 27:  19%|█▉        | 4/21 [00:00<00:00, 23.66it/s, train_loss=0.00336, val_loss=0.00389]Epoch 27:  19%|█▉        | 4/21 [00:00<00:00, 21.45it/s, train_loss=0.00348, val_loss=0.00389]Epoch 27:  24%|██▍       | 5/21 [00:00<00:00, 23.70it/s, train_loss=0.00348, val_loss=0.00389]Epoch 27:  24%|██▍       | 5/21 [00:00<00:00, 21.56it/s, train_loss=0.00346, val_loss=0.00389]Epoch 27:  29%|██▊       | 6/21 [00:00<00:00, 24.23it/s, train_loss=0.00346, val_loss=0.00389]Epoch 27:  29%|██▊       | 6/21 [00:00<00:00, 22.05it/s, train_loss=0.00338, val_loss=0.00389]Epoch 27:  33%|███▎      | 7/21 [00:00<00:00, 23.62it/s, train_loss=0.00338, val_loss=0.00389]Epoch 27:  33%|███▎      | 7/21 [00:00<00:00, 22.34it/s, train_loss=0.00357, val_loss=0.00389]Epoch 27:  38%|███▊      | 8/21 [00:00<00:00, 24.87it/s, train_loss=0.00357, val_loss=0.00389]Epoch 27:  38%|███▊      | 8/21 [00:00<00:00, 23.39it/s, train_loss=0.0033, val_loss=0.00389] Epoch 27:  43%|████▎     | 9/21 [00:00<00:00, 24.41it/s, train_loss=0.0033, val_loss=0.00389]Epoch 27:  43%|████▎     | 9/21 [00:00<00:00, 23.19it/s, train_loss=0.00345, val_loss=0.00389]Epoch 27:  48%|████▊     | 10/21 [00:00<00:00, 24.06it/s, train_loss=0.00345, val_loss=0.00389]Epoch 27:  48%|████▊     | 10/21 [00:00<00:00, 23.07it/s, train_loss=0.00352, val_loss=0.00389]Epoch 27:  52%|█████▏    | 11/21 [00:00<00:00, 23.95it/s, train_loss=0.00352, val_loss=0.00389]Epoch 27:  52%|█████▏    | 11/21 [00:00<00:00, 23.08it/s, train_loss=0.00348, val_loss=0.00389]Epoch 27:  57%|█████▋    | 12/21 [00:00<00:00, 23.87it/s, train_loss=0.00348, val_loss=0.00389]Epoch 27:  57%|█████▋    | 12/21 [00:00<00:00, 23.03it/s, train_loss=0.00345, val_loss=0.00389]Epoch 27:  62%|██████▏   | 13/21 [00:00<00:00, 23.75it/s, train_loss=0.00345, val_loss=0.00389]Epoch 27:  62%|██████▏   | 13/21 [00:00<00:00, 23.00it/s, train_loss=0.00337, val_loss=0.00389]Epoch 27:  67%|██████▋   | 14/21 [00:00<00:00, 23.64it/s, train_loss=0.00337, val_loss=0.00389]Epoch 27:  67%|██████▋   | 14/21 [00:00<00:00, 22.97it/s, train_loss=0.0036, val_loss=0.00389] Epoch 27:  71%|███████▏  | 15/21 [00:00<00:00, 23.60it/s, train_loss=0.0036, val_loss=0.00389]Epoch 27:  71%|███████▏  | 15/21 [00:00<00:00, 22.94it/s, train_loss=0.00348, val_loss=0.00389]Epoch 27:  76%|███████▌  | 16/21 [00:00<00:00, 23.52it/s, train_loss=0.00348, val_loss=0.00389]Epoch 27:  76%|███████▌  | 16/21 [00:00<00:00, 22.93it/s, train_loss=0.00371, val_loss=0.00389]Epoch 27:  81%|████████  | 17/21 [00:00<00:00, 23.44it/s, train_loss=0.00371, val_loss=0.00389]Epoch 27:  81%|████████  | 17/21 [00:00<00:00, 22.90it/s, train_loss=0.00327, val_loss=0.00389]Epoch 27:  86%|████████▌ | 18/21 [00:00<00:00, 23.42it/s, train_loss=0.00327, val_loss=0.00389]Epoch 27:  86%|████████▌ | 18/21 [00:00<00:00, 22.88it/s, train_loss=0.00333, val_loss=0.00389]Epoch 27:  90%|█████████ | 19/21 [00:00<00:00, 23.36it/s, train_loss=0.00333, val_loss=0.00389]Epoch 27:  90%|█████████ | 19/21 [00:00<00:00, 22.85it/s, train_loss=0.00339, val_loss=0.00389]Epoch 27:  95%|█████████▌| 20/21 [00:00<00:00, 23.30it/s, train_loss=0.00339, val_loss=0.00389]Epoch 27:  95%|█████████▌| 20/21 [00:00<00:00, 22.83it/s, train_loss=0.0037, val_loss=0.00389] Epoch 27: 100%|██████████| 21/21 [00:00<00:00, 23.25it/s, train_loss=0.0037, val_loss=0.00389]Epoch 27: 100%|██████████| 21/21 [00:00<00:00, 22.84it/s, train_loss=0.00339, val_loss=0.00389]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.22it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 11.29it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 16.37it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 21.21it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 25.84it/s][A
                                                                      [AEpoch 27: 100%|██████████| 21/21 [00:01<00:00, 16.72it/s, train_loss=0.00339, val_loss=0.00389]Epoch 27: 100%|██████████| 21/21 [00:01<00:00, 16.48it/s, train_loss=0.00339, val_loss=0.00389]Epoch 27:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00339, val_loss=0.00389]         Epoch 28:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00339, val_loss=0.00389]Epoch 28:   5%|▍         | 1/21 [00:00<00:00, 22.41it/s, train_loss=0.00339, val_loss=0.00389]Epoch 28:   5%|▍         | 1/21 [00:00<00:01, 15.84it/s, train_loss=0.00331, val_loss=0.00389]Epoch 28:  10%|▉         | 2/21 [00:00<00:00, 22.42it/s, train_loss=0.00331, val_loss=0.00389]Epoch 28:  10%|▉         | 2/21 [00:00<00:01, 18.86it/s, train_loss=0.00328, val_loss=0.00389]Epoch 28:  14%|█▍        | 3/21 [00:00<00:00, 22.52it/s, train_loss=0.00328, val_loss=0.00389]Epoch 28:  14%|█▍        | 3/21 [00:00<00:00, 19.99it/s, train_loss=0.00361, val_loss=0.00389]Epoch 28:  19%|█▉        | 4/21 [00:00<00:00, 22.71it/s, train_loss=0.00361, val_loss=0.00389]Epoch 28:  19%|█▉        | 4/21 [00:00<00:00, 20.59it/s, train_loss=0.00339, val_loss=0.00389]Epoch 28:  24%|██▍       | 5/21 [00:00<00:00, 22.64it/s, train_loss=0.00339, val_loss=0.00389]Epoch 28:  24%|██▍       | 5/21 [00:00<00:00, 20.96it/s, train_loss=0.00335, val_loss=0.00389]Epoch 28:  29%|██▊       | 6/21 [00:00<00:00, 22.55it/s, train_loss=0.00335, val_loss=0.00389]Epoch 28:  29%|██▊       | 6/21 [00:00<00:00, 21.14it/s, train_loss=0.00348, val_loss=0.00389]Epoch 28:  33%|███▎      | 7/21 [00:00<00:00, 22.61it/s, train_loss=0.00348, val_loss=0.00389]Epoch 28:  33%|███▎      | 7/21 [00:00<00:00, 21.35it/s, train_loss=0.00337, val_loss=0.00389]Epoch 28:  38%|███▊      | 8/21 [00:00<00:00, 22.61it/s, train_loss=0.00337, val_loss=0.00389]Epoch 28:  38%|███▊      | 8/21 [00:00<00:00, 21.49it/s, train_loss=0.00357, val_loss=0.00389]Epoch 28:  43%|████▎     | 9/21 [00:00<00:00, 22.50it/s, train_loss=0.00357, val_loss=0.00389]Epoch 28:  43%|████▎     | 9/21 [00:00<00:00, 21.56it/s, train_loss=0.00361, val_loss=0.00389]Epoch 28:  48%|████▊     | 10/21 [00:00<00:00, 22.52it/s, train_loss=0.00361, val_loss=0.00389]Epoch 28:  48%|████▊     | 10/21 [00:00<00:00, 21.68it/s, train_loss=0.00373, val_loss=0.00389]Epoch 28:  52%|█████▏    | 11/21 [00:00<00:00, 22.59it/s, train_loss=0.00373, val_loss=0.00389]Epoch 28:  52%|█████▏    | 11/21 [00:00<00:00, 21.77it/s, train_loss=0.00322, val_loss=0.00389]Epoch 28:  57%|█████▋    | 12/21 [00:00<00:00, 22.59it/s, train_loss=0.00322, val_loss=0.00389]Epoch 28:  57%|█████▋    | 12/21 [00:00<00:00, 21.82it/s, train_loss=0.00341, val_loss=0.00389]Epoch 28:  62%|██████▏   | 13/21 [00:00<00:00, 22.58it/s, train_loss=0.00341, val_loss=0.00389]Epoch 28:  62%|██████▏   | 13/21 [00:00<00:00, 21.94it/s, train_loss=0.00351, val_loss=0.00389]Epoch 28:  67%|██████▋   | 14/21 [00:00<00:00, 22.60it/s, train_loss=0.00351, val_loss=0.00389]Epoch 28:  67%|██████▋   | 14/21 [00:00<00:00, 21.98it/s, train_loss=0.00337, val_loss=0.00389]Epoch 28:  71%|███████▏  | 15/21 [00:00<00:00, 22.63it/s, train_loss=0.00337, val_loss=0.00389]Epoch 28:  71%|███████▏  | 15/21 [00:00<00:00, 22.06it/s, train_loss=0.00331, val_loss=0.00389]Epoch 28:  76%|███████▌  | 16/21 [00:00<00:00, 22.62it/s, train_loss=0.00331, val_loss=0.00389]Epoch 28:  76%|███████▌  | 16/21 [00:00<00:00, 22.09it/s, train_loss=0.00347, val_loss=0.00389]Epoch 28:  81%|████████  | 17/21 [00:00<00:00, 22.67it/s, train_loss=0.00347, val_loss=0.00389]Epoch 28:  81%|████████  | 17/21 [00:00<00:00, 22.12it/s, train_loss=0.0034, val_loss=0.00389] Epoch 28:  86%|████████▌ | 18/21 [00:00<00:00, 23.14it/s, train_loss=0.0034, val_loss=0.00389]Epoch 28:  86%|████████▌ | 18/21 [00:00<00:00, 22.58it/s, train_loss=0.00341, val_loss=0.00389]Epoch 28:  90%|█████████ | 19/21 [00:00<00:00, 23.05it/s, train_loss=0.00341, val_loss=0.00389]Epoch 28:  90%|█████████ | 19/21 [00:00<00:00, 22.55it/s, train_loss=0.00334, val_loss=0.00389]Epoch 28:  95%|█████████▌| 20/21 [00:00<00:00, 22.98it/s, train_loss=0.00334, val_loss=0.00389]Epoch 28:  95%|█████████▌| 20/21 [00:00<00:00, 22.51it/s, train_loss=0.00357, val_loss=0.00389]Epoch 28: 100%|██████████| 21/21 [00:00<00:00, 22.95it/s, train_loss=0.00357, val_loss=0.00389]Epoch 28: 100%|██████████| 21/21 [00:00<00:00, 22.53it/s, train_loss=0.00333, val_loss=0.00389]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.16it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 12.72it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 18.39it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 21.70it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 20.77it/s][A
                                                                      [AEpoch 28: 100%|██████████| 21/21 [00:01<00:00, 15.77it/s, train_loss=0.00333, val_loss=0.00385]Epoch 28: 100%|██████████| 21/21 [00:01<00:00, 15.56it/s, train_loss=0.00333, val_loss=0.00385]Epoch 28:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00333, val_loss=0.00385]         Epoch 29:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00333, val_loss=0.00385]Epoch 29:   5%|▍         | 1/21 [00:00<00:00, 22.81it/s, train_loss=0.00333, val_loss=0.00385]Epoch 29:   5%|▍         | 1/21 [00:00<00:01, 16.35it/s, train_loss=0.00347, val_loss=0.00385]Epoch 29:  10%|▉         | 2/21 [00:00<00:00, 22.82it/s, train_loss=0.00347, val_loss=0.00385]Epoch 29:  10%|▉         | 2/21 [00:00<00:01, 17.89it/s, train_loss=0.00341, val_loss=0.00385]Epoch 29:  14%|█▍        | 3/21 [00:00<00:00, 21.69it/s, train_loss=0.00341, val_loss=0.00385]Epoch 29:  14%|█▍        | 3/21 [00:00<00:00, 19.08it/s, train_loss=0.00357, val_loss=0.00385]Epoch 29:  19%|█▉        | 4/21 [00:00<00:00, 21.90it/s, train_loss=0.00357, val_loss=0.00385]Epoch 29:  19%|█▉        | 4/21 [00:00<00:00, 19.86it/s, train_loss=0.00346, val_loss=0.00385]Epoch 29:  24%|██▍       | 5/21 [00:00<00:00, 22.75it/s, train_loss=0.00346, val_loss=0.00385]Epoch 29:  24%|██▍       | 5/21 [00:00<00:00, 21.01it/s, train_loss=0.00335, val_loss=0.00385]Epoch 29:  29%|██▊       | 6/21 [00:00<00:00, 22.68it/s, train_loss=0.00335, val_loss=0.00385]Epoch 29:  29%|██▊       | 6/21 [00:00<00:00, 21.28it/s, train_loss=0.00351, val_loss=0.00385]Epoch 29:  33%|███▎      | 7/21 [00:00<00:00, 22.68it/s, train_loss=0.00351, val_loss=0.00385]Epoch 29:  33%|███▎      | 7/21 [00:00<00:00, 21.47it/s, train_loss=0.00326, val_loss=0.00385]Epoch 29:  38%|███▊      | 8/21 [00:00<00:00, 22.73it/s, train_loss=0.00326, val_loss=0.00385]Epoch 29:  38%|███▊      | 8/21 [00:00<00:00, 21.62it/s, train_loss=0.0033, val_loss=0.00385] Epoch 29:  43%|████▎     | 9/21 [00:00<00:00, 22.70it/s, train_loss=0.0033, val_loss=0.00385]Epoch 29:  43%|████▎     | 9/21 [00:00<00:00, 21.71it/s, train_loss=0.00325, val_loss=0.00385]Epoch 29:  48%|████▊     | 10/21 [00:00<00:00, 22.65it/s, train_loss=0.00325, val_loss=0.00385]Epoch 29:  48%|████▊     | 10/21 [00:00<00:00, 21.75it/s, train_loss=0.00333, val_loss=0.00385]Epoch 29:  52%|█████▏    | 11/21 [00:00<00:00, 22.61it/s, train_loss=0.00333, val_loss=0.00385]Epoch 29:  52%|█████▏    | 11/21 [00:00<00:00, 21.82it/s, train_loss=0.00337, val_loss=0.00385]Epoch 29:  57%|█████▋    | 12/21 [00:00<00:00, 22.64it/s, train_loss=0.00337, val_loss=0.00385]Epoch 29:  57%|█████▋    | 12/21 [00:00<00:00, 21.92it/s, train_loss=0.00325, val_loss=0.00385]Epoch 29:  62%|██████▏   | 13/21 [00:00<00:00, 22.63it/s, train_loss=0.00325, val_loss=0.00385]Epoch 29:  62%|██████▏   | 13/21 [00:00<00:00, 21.98it/s, train_loss=0.0034, val_loss=0.00385] Epoch 29:  67%|██████▋   | 14/21 [00:00<00:00, 23.31it/s, train_loss=0.0034, val_loss=0.00385]Epoch 29:  67%|██████▋   | 14/21 [00:00<00:00, 22.57it/s, train_loss=0.00316, val_loss=0.00385]Epoch 29:  71%|███████▏  | 15/21 [00:00<00:00, 23.16it/s, train_loss=0.00316, val_loss=0.00385]Epoch 29:  71%|███████▏  | 15/21 [00:00<00:00, 22.57it/s, train_loss=0.0033, val_loss=0.00385] Epoch 29:  76%|███████▌  | 16/21 [00:00<00:00, 23.17it/s, train_loss=0.0033, val_loss=0.00385]Epoch 29:  76%|███████▌  | 16/21 [00:00<00:00, 22.57it/s, train_loss=0.00364, val_loss=0.00385]Epoch 29:  81%|████████  | 17/21 [00:00<00:00, 23.12it/s, train_loss=0.00364, val_loss=0.00385]Epoch 29:  81%|████████  | 17/21 [00:00<00:00, 22.58it/s, train_loss=0.00335, val_loss=0.00385]Epoch 29:  86%|████████▌ | 18/21 [00:00<00:00, 23.06it/s, train_loss=0.00335, val_loss=0.00385]Epoch 29:  86%|████████▌ | 18/21 [00:00<00:00, 22.58it/s, train_loss=0.00348, val_loss=0.00385]Epoch 29:  90%|█████████ | 19/21 [00:00<00:00, 23.08it/s, train_loss=0.00348, val_loss=0.00385]Epoch 29:  90%|█████████ | 19/21 [00:00<00:00, 22.58it/s, train_loss=0.00338, val_loss=0.00385]Epoch 29:  95%|█████████▌| 20/21 [00:00<00:00, 23.04it/s, train_loss=0.00338, val_loss=0.00385]Epoch 29:  95%|█████████▌| 20/21 [00:00<00:00, 22.59it/s, train_loss=0.00366, val_loss=0.00385]Epoch 29: 100%|██████████| 21/21 [00:00<00:00, 23.04it/s, train_loss=0.00366, val_loss=0.00385]Epoch 29: 100%|██████████| 21/21 [00:00<00:00, 22.60it/s, train_loss=0.00341, val_loss=0.00385]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 139.34it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 68.96it/s] [A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 46.60it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 38.07it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 45.20it/s][A
                                                                      [AEpoch 29: 100%|██████████| 21/21 [00:01<00:00, 19.07it/s, train_loss=0.00341, val_loss=0.00384]Epoch 29: 100%|██████████| 21/21 [00:01<00:00, 19.05it/s, train_loss=0.00341, val_loss=0.00384]Epoch 29:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00341, val_loss=0.00384]         Epoch 30:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00341, val_loss=0.00384]Epoch 30:   5%|▍         | 1/21 [00:00<00:00, 94.25it/s, train_loss=0.00341, val_loss=0.00384]Epoch 30:   5%|▍         | 1/21 [00:00<00:00, 34.10it/s, train_loss=0.00351, val_loss=0.00384]Epoch 30:  10%|▉         | 2/21 [00:00<00:00, 35.32it/s, train_loss=0.00351, val_loss=0.00384]Epoch 30:  10%|▉         | 2/21 [00:00<00:00, 27.09it/s, train_loss=0.00334, val_loss=0.00384]Epoch 30:  14%|█▍        | 3/21 [00:00<00:00, 36.65it/s, train_loss=0.00334, val_loss=0.00384]Epoch 30:  14%|█▍        | 3/21 [00:00<00:00, 29.35it/s, train_loss=0.00338, val_loss=0.00384]Epoch 30:  19%|█▉        | 4/21 [00:00<00:00, 36.20it/s, train_loss=0.00338, val_loss=0.00384]Epoch 30:  19%|█▉        | 4/21 [00:00<00:00, 30.53it/s, train_loss=0.0034, val_loss=0.00384] Epoch 30:  24%|██▍       | 5/21 [00:00<00:00, 35.95it/s, train_loss=0.0034, val_loss=0.00384]Epoch 30:  24%|██▍       | 5/21 [00:00<00:00, 31.34it/s, train_loss=0.00351, val_loss=0.00384]Epoch 30:  29%|██▊       | 6/21 [00:00<00:00, 35.71it/s, train_loss=0.00351, val_loss=0.00384]Epoch 30:  29%|██▊       | 6/21 [00:00<00:00, 31.82it/s, train_loss=0.00331, val_loss=0.00384]Epoch 30:  33%|███▎      | 7/21 [00:00<00:00, 35.37it/s, train_loss=0.00331, val_loss=0.00384]Epoch 30:  33%|███▎      | 7/21 [00:00<00:00, 32.19it/s, train_loss=0.00338, val_loss=0.00384]Epoch 30:  38%|███▊      | 8/21 [00:00<00:00, 35.14it/s, train_loss=0.00338, val_loss=0.00384]Epoch 30:  38%|███▊      | 8/21 [00:00<00:00, 32.71it/s, train_loss=0.0033, val_loss=0.00384] Epoch 30:  43%|████▎     | 9/21 [00:00<00:00, 35.45it/s, train_loss=0.0033, val_loss=0.00384]Epoch 30:  43%|████▎     | 9/21 [00:00<00:00, 32.97it/s, train_loss=0.00325, val_loss=0.00384]Epoch 30:  48%|████▊     | 10/21 [00:00<00:00, 35.60it/s, train_loss=0.00325, val_loss=0.00384]Epoch 30:  48%|████▊     | 10/21 [00:00<00:00, 33.15it/s, train_loss=0.0032, val_loss=0.00384] Epoch 30:  52%|█████▏    | 11/21 [00:00<00:00, 35.51it/s, train_loss=0.0032, val_loss=0.00384]Epoch 30:  52%|█████▏    | 11/21 [00:00<00:00, 33.30it/s, train_loss=0.00348, val_loss=0.00384]Epoch 30:  57%|█████▋    | 12/21 [00:00<00:00, 35.47it/s, train_loss=0.00348, val_loss=0.00384]Epoch 30:  57%|█████▋    | 12/21 [00:00<00:00, 33.43it/s, train_loss=0.00334, val_loss=0.00384]Epoch 30:  62%|██████▏   | 13/21 [00:00<00:00, 35.40it/s, train_loss=0.00334, val_loss=0.00384]Epoch 30:  62%|██████▏   | 13/21 [00:00<00:00, 33.50it/s, train_loss=0.00342, val_loss=0.00384]Epoch 30:  67%|██████▋   | 14/21 [00:00<00:00, 35.30it/s, train_loss=0.00342, val_loss=0.00384]Epoch 30:  67%|██████▋   | 14/21 [00:00<00:00, 33.56it/s, train_loss=0.00331, val_loss=0.00384]Epoch 30:  71%|███████▏  | 15/21 [00:00<00:00, 35.23it/s, train_loss=0.00331, val_loss=0.00384]Epoch 30:  71%|███████▏  | 15/21 [00:00<00:00, 33.60it/s, train_loss=0.00345, val_loss=0.00384]Epoch 30:  76%|███████▌  | 16/21 [00:00<00:00, 35.12it/s, train_loss=0.00345, val_loss=0.00384]Epoch 30:  76%|███████▌  | 16/21 [00:00<00:00, 33.63it/s, train_loss=0.00337, val_loss=0.00384]Epoch 30:  81%|████████  | 17/21 [00:00<00:00, 35.09it/s, train_loss=0.00337, val_loss=0.00384]Epoch 30:  81%|████████  | 17/21 [00:00<00:00, 33.68it/s, train_loss=0.00358, val_loss=0.00384]Epoch 30:  86%|████████▌ | 18/21 [00:00<00:00, 35.00it/s, train_loss=0.00358, val_loss=0.00384]Epoch 30:  86%|████████▌ | 18/21 [00:00<00:00, 33.89it/s, train_loss=0.00344, val_loss=0.00384]Epoch 30:  90%|█████████ | 19/21 [00:00<00:00, 35.16it/s, train_loss=0.00344, val_loss=0.00384]Epoch 30:  90%|█████████ | 19/21 [00:00<00:00, 34.02it/s, train_loss=0.00316, val_loss=0.00384]Epoch 30:  95%|█████████▌| 20/21 [00:00<00:00, 35.33it/s, train_loss=0.00316, val_loss=0.00384]Epoch 30:  95%|█████████▌| 20/21 [00:00<00:00, 34.09it/s, train_loss=0.00313, val_loss=0.00384]Epoch 30: 100%|██████████| 21/21 [00:00<00:00, 35.32it/s, train_loss=0.00313, val_loss=0.00384]Epoch 30: 100%|██████████| 21/21 [00:00<00:00, 34.13it/s, train_loss=0.00346, val_loss=0.00384]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 133.82it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 155.64it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 170.71it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 147.24it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 130.13it/s][A
                                                                       [AEpoch 30: 100%|██████████| 21/21 [00:00<00:00, 30.72it/s, train_loss=0.00346, val_loss=0.00382]Epoch 30: 100%|██████████| 21/21 [00:00<00:00, 30.67it/s, train_loss=0.00346, val_loss=0.00382]Epoch 30:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00346, val_loss=0.00382]         Epoch 31:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00346, val_loss=0.00382]Epoch 31:   5%|▍         | 1/21 [00:00<00:00, 97.23it/s, train_loss=0.00346, val_loss=0.00382]Epoch 31:   5%|▍         | 1/21 [00:00<00:00, 36.68it/s, train_loss=0.00339, val_loss=0.00382]Epoch 31:  10%|▉         | 2/21 [00:00<00:00, 54.42it/s, train_loss=0.00339, val_loss=0.00382]Epoch 31:  10%|▉         | 2/21 [00:00<00:00, 36.71it/s, train_loss=0.00361, val_loss=0.00382]Epoch 31:  14%|█▍        | 3/21 [00:00<00:00, 48.26it/s, train_loss=0.00361, val_loss=0.00382]Epoch 31:  14%|█▍        | 3/21 [00:00<00:00, 36.09it/s, train_loss=0.00355, val_loss=0.00382]Epoch 31:  19%|█▉        | 4/21 [00:00<00:00, 43.88it/s, train_loss=0.00355, val_loss=0.00382]Epoch 31:  19%|█▉        | 4/21 [00:00<00:00, 35.80it/s, train_loss=0.00352, val_loss=0.00382]Epoch 31:  24%|██▍       | 5/21 [00:00<00:00, 40.93it/s, train_loss=0.00352, val_loss=0.00382]Epoch 31:  24%|██▍       | 5/21 [00:00<00:00, 35.37it/s, train_loss=0.00341, val_loss=0.00382]Epoch 31:  29%|██▊       | 6/21 [00:00<00:00, 40.00it/s, train_loss=0.00341, val_loss=0.00382]Epoch 31:  29%|██▊       | 6/21 [00:00<00:00, 35.26it/s, train_loss=0.00333, val_loss=0.00382]Epoch 31:  33%|███▎      | 7/21 [00:00<00:00, 39.27it/s, train_loss=0.00333, val_loss=0.00382]Epoch 31:  33%|███▎      | 7/21 [00:00<00:00, 35.22it/s, train_loss=0.00346, val_loss=0.00382]Epoch 31:  38%|███▊      | 8/21 [00:00<00:00, 38.69it/s, train_loss=0.00346, val_loss=0.00382]Epoch 31:  38%|███▊      | 8/21 [00:00<00:00, 35.19it/s, train_loss=0.00332, val_loss=0.00382]Epoch 31:  43%|████▎     | 9/21 [00:00<00:00, 38.21it/s, train_loss=0.00332, val_loss=0.00382]Epoch 31:  43%|████▎     | 9/21 [00:00<00:00, 35.15it/s, train_loss=0.00336, val_loss=0.00382]Epoch 31:  48%|████▊     | 10/21 [00:00<00:00, 37.80it/s, train_loss=0.00336, val_loss=0.00382]Epoch 31:  48%|████▊     | 10/21 [00:00<00:00, 35.11it/s, train_loss=0.00317, val_loss=0.00382]Epoch 31:  52%|█████▏    | 11/21 [00:00<00:00, 37.48it/s, train_loss=0.00317, val_loss=0.00382]Epoch 31:  52%|█████▏    | 11/21 [00:00<00:00, 35.05it/s, train_loss=0.00317, val_loss=0.00382]Epoch 31:  57%|█████▋    | 12/21 [00:00<00:00, 37.11it/s, train_loss=0.00317, val_loss=0.00382]Epoch 31:  57%|█████▋    | 12/21 [00:00<00:00, 35.26it/s, train_loss=0.00328, val_loss=0.00382]Epoch 31:  62%|██████▏   | 13/21 [00:00<00:00, 37.19it/s, train_loss=0.00328, val_loss=0.00382]Epoch 31:  62%|██████▏   | 13/21 [00:00<00:00, 35.37it/s, train_loss=0.00352, val_loss=0.00382]Epoch 31:  67%|██████▋   | 14/21 [00:00<00:00, 37.29it/s, train_loss=0.00352, val_loss=0.00382]Epoch 31:  67%|██████▋   | 14/21 [00:00<00:00, 35.35it/s, train_loss=0.00316, val_loss=0.00382]Epoch 31:  71%|███████▏  | 15/21 [00:00<00:00, 37.12it/s, train_loss=0.00316, val_loss=0.00382]Epoch 31:  71%|███████▏  | 15/21 [00:00<00:00, 35.31it/s, train_loss=0.00325, val_loss=0.00382]Epoch 31:  76%|███████▌  | 16/21 [00:00<00:00, 36.97it/s, train_loss=0.00325, val_loss=0.00382]Epoch 31:  76%|███████▌  | 16/21 [00:00<00:00, 35.28it/s, train_loss=0.00337, val_loss=0.00382]Epoch 31:  81%|████████  | 17/21 [00:00<00:00, 36.76it/s, train_loss=0.00337, val_loss=0.00382]Epoch 31:  81%|████████  | 17/21 [00:00<00:00, 35.22it/s, train_loss=0.0033, val_loss=0.00382] Epoch 31:  86%|████████▌ | 18/21 [00:00<00:00, 36.56it/s, train_loss=0.0033, val_loss=0.00382]Epoch 31:  86%|████████▌ | 18/21 [00:00<00:00, 35.34it/s, train_loss=0.00309, val_loss=0.00382]Epoch 31:  90%|█████████ | 19/21 [00:00<00:00, 36.62it/s, train_loss=0.00309, val_loss=0.00382]Epoch 31:  90%|█████████ | 19/21 [00:00<00:00, 35.40it/s, train_loss=0.00345, val_loss=0.00382]Epoch 31:  95%|█████████▌| 20/21 [00:00<00:00, 36.69it/s, train_loss=0.00345, val_loss=0.00382]Epoch 31:  95%|█████████▌| 20/21 [00:00<00:00, 35.38it/s, train_loss=0.00314, val_loss=0.00382]Epoch 31: 100%|██████████| 21/21 [00:00<00:00, 36.62it/s, train_loss=0.00314, val_loss=0.00382]Epoch 31: 100%|██████████| 21/21 [00:00<00:00, 35.36it/s, train_loss=0.0034, val_loss=0.00382] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 124.34it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 151.53it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 154.18it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 131.98it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 120.15it/s][A
                                                                       [AEpoch 31: 100%|██████████| 21/21 [00:00<00:00, 31.58it/s, train_loss=0.0034, val_loss=0.00379]Epoch 31: 100%|██████████| 21/21 [00:00<00:00, 31.53it/s, train_loss=0.0034, val_loss=0.00379]Epoch 31:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0034, val_loss=0.00379]         Epoch 32:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0034, val_loss=0.00379]Epoch 32:   5%|▍         | 1/21 [00:00<00:00, 104.43it/s, train_loss=0.0034, val_loss=0.00379]Epoch 32:   5%|▍         | 1/21 [00:00<00:00, 34.08it/s, train_loss=0.00333, val_loss=0.00379]Epoch 32:  10%|▉         | 2/21 [00:00<00:00, 52.67it/s, train_loss=0.00333, val_loss=0.00379]Epoch 32:  10%|▉         | 2/21 [00:00<00:00, 36.06it/s, train_loss=0.00328, val_loss=0.00379]Epoch 32:  14%|█▍        | 3/21 [00:00<00:00, 46.49it/s, train_loss=0.00328, val_loss=0.00379]Epoch 32:  14%|█▍        | 3/21 [00:00<00:00, 36.36it/s, train_loss=0.00335, val_loss=0.00379]Epoch 32:  19%|█▉        | 4/21 [00:00<00:00, 44.29it/s, train_loss=0.00335, val_loss=0.00379]Epoch 32:  19%|█▉        | 4/21 [00:00<00:00, 36.08it/s, train_loss=0.00334, val_loss=0.00379]Epoch 32:  24%|██▍       | 5/21 [00:00<00:00, 42.10it/s, train_loss=0.00334, val_loss=0.00379]Epoch 32:  24%|██▍       | 5/21 [00:00<00:00, 35.88it/s, train_loss=0.00316, val_loss=0.00379]Epoch 32:  29%|██▊       | 6/21 [00:00<00:00, 40.70it/s, train_loss=0.00316, val_loss=0.00379]Epoch 32:  29%|██▊       | 6/21 [00:00<00:00, 35.68it/s, train_loss=0.00333, val_loss=0.00379]Epoch 32:  33%|███▎      | 7/21 [00:00<00:00, 39.58it/s, train_loss=0.00333, val_loss=0.00379]Epoch 32:  33%|███▎      | 7/21 [00:00<00:00, 35.96it/s, train_loss=0.00314, val_loss=0.00379]Epoch 32:  38%|███▊      | 8/21 [00:00<00:00, 39.34it/s, train_loss=0.00314, val_loss=0.00379]Epoch 32:  38%|███▊      | 8/21 [00:00<00:00, 36.12it/s, train_loss=0.00354, val_loss=0.00379]Epoch 32:  43%|████▎     | 9/21 [00:00<00:00, 39.30it/s, train_loss=0.00354, val_loss=0.00379]Epoch 32:  43%|████▎     | 9/21 [00:00<00:00, 36.00it/s, train_loss=0.00323, val_loss=0.00379]Epoch 32:  48%|████▊     | 10/21 [00:00<00:00, 38.79it/s, train_loss=0.00323, val_loss=0.00379]Epoch 32:  48%|████▊     | 10/21 [00:00<00:00, 35.91it/s, train_loss=0.00317, val_loss=0.00379]Epoch 32:  52%|█████▏    | 11/21 [00:00<00:00, 38.40it/s, train_loss=0.00317, val_loss=0.00379]Epoch 32:  52%|█████▏    | 11/21 [00:00<00:00, 35.81it/s, train_loss=0.00321, val_loss=0.00379]Epoch 32:  57%|█████▋    | 12/21 [00:00<00:00, 37.99it/s, train_loss=0.00321, val_loss=0.00379]Epoch 32:  57%|█████▋    | 12/21 [00:00<00:00, 35.99it/s, train_loss=0.00347, val_loss=0.00379]Epoch 32:  62%|██████▏   | 13/21 [00:00<00:00, 37.95it/s, train_loss=0.00347, val_loss=0.00379]Epoch 32:  62%|██████▏   | 13/21 [00:00<00:00, 36.09it/s, train_loss=0.0034, val_loss=0.00379] Epoch 32:  67%|██████▋   | 14/21 [00:00<00:00, 37.97it/s, train_loss=0.0034, val_loss=0.00379]Epoch 32:  67%|██████▋   | 14/21 [00:00<00:00, 35.98it/s, train_loss=0.00341, val_loss=0.00379]Epoch 32:  71%|███████▏  | 15/21 [00:00<00:00, 37.69it/s, train_loss=0.00341, val_loss=0.00379]Epoch 32:  71%|███████▏  | 15/21 [00:00<00:00, 35.91it/s, train_loss=0.00337, val_loss=0.00379]Epoch 32:  76%|███████▌  | 16/21 [00:00<00:00, 37.56it/s, train_loss=0.00337, val_loss=0.00379]Epoch 32:  76%|███████▌  | 16/21 [00:00<00:00, 35.82it/s, train_loss=0.00337, val_loss=0.00379]Epoch 32:  81%|████████  | 17/21 [00:00<00:00, 37.35it/s, train_loss=0.00337, val_loss=0.00379]Epoch 32:  81%|████████  | 17/21 [00:00<00:00, 35.73it/s, train_loss=0.00326, val_loss=0.00379]Epoch 32:  86%|████████▌ | 18/21 [00:00<00:00, 37.20it/s, train_loss=0.00326, val_loss=0.00379]Epoch 32:  86%|████████▌ | 18/21 [00:00<00:00, 35.68it/s, train_loss=0.00354, val_loss=0.00379]Epoch 32:  90%|█████████ | 19/21 [00:00<00:00, 37.06it/s, train_loss=0.00354, val_loss=0.00379]Epoch 32:  90%|█████████ | 19/21 [00:00<00:00, 35.63it/s, train_loss=0.00332, val_loss=0.00379]Epoch 32:  95%|█████████▌| 20/21 [00:00<00:00, 36.93it/s, train_loss=0.00332, val_loss=0.00379]Epoch 32:  95%|█████████▌| 20/21 [00:00<00:00, 35.57it/s, train_loss=0.00342, val_loss=0.00379]Epoch 32: 100%|██████████| 21/21 [00:00<00:00, 36.77it/s, train_loss=0.00342, val_loss=0.00379]Epoch 32: 100%|██████████| 21/21 [00:00<00:00, 35.52it/s, train_loss=0.00318, val_loss=0.00379]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 175.52it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 200.63it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 210.35it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 155.32it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 135.30it/s][A
                                                                       [AEpoch 32: 100%|██████████| 21/21 [00:00<00:00, 32.04it/s, train_loss=0.00318, val_loss=0.00379]Epoch 32: 100%|██████████| 21/21 [00:00<00:00, 31.99it/s, train_loss=0.00318, val_loss=0.00379]Epoch 32:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00318, val_loss=0.00379]         Epoch 33:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00318, val_loss=0.00379]Epoch 33:   5%|▍         | 1/21 [00:00<00:00, 110.02it/s, train_loss=0.00318, val_loss=0.00379]Epoch 33:   5%|▍         | 1/21 [00:00<00:00, 37.40it/s, train_loss=0.00325, val_loss=0.00379] Epoch 33:  10%|▉         | 2/21 [00:00<00:00, 56.68it/s, train_loss=0.00325, val_loss=0.00379]Epoch 33:  10%|▉         | 2/21 [00:00<00:00, 37.03it/s, train_loss=0.00326, val_loss=0.00379]Epoch 33:  14%|█▍        | 3/21 [00:00<00:00, 48.74it/s, train_loss=0.00326, val_loss=0.00379]Epoch 33:  14%|█▍        | 3/21 [00:00<00:00, 36.44it/s, train_loss=0.00318, val_loss=0.00379]Epoch 33:  19%|█▉        | 4/21 [00:00<00:00, 44.33it/s, train_loss=0.00318, val_loss=0.00379]Epoch 33:  19%|█▉        | 4/21 [00:00<00:00, 36.08it/s, train_loss=0.00319, val_loss=0.00379]Epoch 33:  24%|██▍       | 5/21 [00:00<00:00, 42.02it/s, train_loss=0.00319, val_loss=0.00379]Epoch 33:  24%|██▍       | 5/21 [00:00<00:00, 35.79it/s, train_loss=0.00303, val_loss=0.00379]Epoch 33:  29%|██▊       | 6/21 [00:00<00:00, 40.61it/s, train_loss=0.00303, val_loss=0.00379]Epoch 33:  29%|██▊       | 6/21 [00:00<00:00, 35.65it/s, train_loss=0.00336, val_loss=0.00379]Epoch 33:  33%|███▎      | 7/21 [00:00<00:00, 39.51it/s, train_loss=0.00336, val_loss=0.00379]Epoch 33:  33%|███▎      | 7/21 [00:00<00:00, 35.95it/s, train_loss=0.00329, val_loss=0.00379]Epoch 33:  38%|███▊      | 8/21 [00:00<00:00, 39.22it/s, train_loss=0.00329, val_loss=0.00379]Epoch 33:  38%|███▊      | 8/21 [00:00<00:00, 36.14it/s, train_loss=0.00325, val_loss=0.00379]Epoch 33:  43%|████▎     | 9/21 [00:00<00:00, 39.14it/s, train_loss=0.00325, val_loss=0.00379]Epoch 33:  43%|████▎     | 9/21 [00:00<00:00, 35.98it/s, train_loss=0.00345, val_loss=0.00379]Epoch 33:  48%|████▊     | 10/21 [00:00<00:00, 38.57it/s, train_loss=0.00345, val_loss=0.00379]Epoch 33:  48%|████▊     | 10/21 [00:00<00:00, 35.84it/s, train_loss=0.0033, val_loss=0.00379] Epoch 33:  52%|█████▏    | 11/21 [00:00<00:00, 38.07it/s, train_loss=0.0033, val_loss=0.00379]Epoch 33:  52%|█████▏    | 11/21 [00:00<00:00, 35.66it/s, train_loss=0.00325, val_loss=0.00379]Epoch 33:  57%|█████▋    | 12/21 [00:00<00:00, 37.86it/s, train_loss=0.00325, val_loss=0.00379]Epoch 33:  57%|█████▋    | 12/21 [00:00<00:00, 35.56it/s, train_loss=0.00337, val_loss=0.00379]Epoch 33:  62%|██████▏   | 13/21 [00:00<00:00, 37.64it/s, train_loss=0.00337, val_loss=0.00379]Epoch 33:  62%|██████▏   | 13/21 [00:00<00:00, 35.51it/s, train_loss=0.0035, val_loss=0.00379] Epoch 33:  67%|██████▋   | 14/21 [00:00<00:00, 37.40it/s, train_loss=0.0035, val_loss=0.00379]Epoch 33:  67%|██████▋   | 14/21 [00:00<00:00, 35.44it/s, train_loss=0.00313, val_loss=0.00379]Epoch 33:  71%|███████▏  | 15/21 [00:00<00:00, 37.27it/s, train_loss=0.00313, val_loss=0.00379]Epoch 33:  71%|███████▏  | 15/21 [00:00<00:00, 35.43it/s, train_loss=0.00372, val_loss=0.00379]Epoch 33:  76%|███████▌  | 16/21 [00:00<00:00, 37.03it/s, train_loss=0.00372, val_loss=0.00379]Epoch 33:  76%|███████▌  | 16/21 [00:00<00:00, 35.59it/s, train_loss=0.00313, val_loss=0.00379]Epoch 33:  81%|████████  | 17/21 [00:00<00:00, 37.06it/s, train_loss=0.00313, val_loss=0.00379]Epoch 33:  81%|████████  | 17/21 [00:00<00:00, 35.66it/s, train_loss=0.00349, val_loss=0.00379]Epoch 33:  86%|████████▌ | 18/21 [00:00<00:00, 37.17it/s, train_loss=0.00349, val_loss=0.00379]Epoch 33:  86%|████████▌ | 18/21 [00:00<00:00, 35.65it/s, train_loss=0.00332, val_loss=0.00379]Epoch 33:  90%|█████████ | 19/21 [00:00<00:00, 37.06it/s, train_loss=0.00332, val_loss=0.00379]Epoch 33:  90%|█████████ | 19/21 [00:00<00:00, 35.62it/s, train_loss=0.00333, val_loss=0.00379]Epoch 33:  95%|█████████▌| 20/21 [00:00<00:00, 36.94it/s, train_loss=0.00333, val_loss=0.00379]Epoch 33:  95%|█████████▌| 20/21 [00:00<00:00, 35.57it/s, train_loss=0.00332, val_loss=0.00379]Epoch 33: 100%|██████████| 21/21 [00:00<00:00, 36.76it/s, train_loss=0.00332, val_loss=0.00379]Epoch 33: 100%|██████████| 21/21 [00:00<00:00, 35.66it/s, train_loss=0.00343, val_loss=0.00379]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 151.25it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 175.56it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 169.71it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 137.46it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 123.30it/s][A
                                                                       [AEpoch 33: 100%|██████████| 21/21 [00:00<00:00, 31.92it/s, train_loss=0.00343, val_loss=0.00379]Epoch 33: 100%|██████████| 21/21 [00:00<00:00, 31.87it/s, train_loss=0.00343, val_loss=0.00379]Epoch 33:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00343, val_loss=0.00379]         Epoch 34:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00343, val_loss=0.00379]Epoch 34:   5%|▍         | 1/21 [00:00<00:00, 107.31it/s, train_loss=0.00343, val_loss=0.00379]Epoch 34:   5%|▍         | 1/21 [00:00<00:00, 37.13it/s, train_loss=0.00325, val_loss=0.00379] Epoch 34:  10%|▉         | 2/21 [00:00<00:00, 55.87it/s, train_loss=0.00325, val_loss=0.00379]Epoch 34:  10%|▉         | 2/21 [00:00<00:00, 37.18it/s, train_loss=0.00319, val_loss=0.00379]Epoch 34:  14%|█▍        | 3/21 [00:00<00:00, 48.84it/s, train_loss=0.00319, val_loss=0.00379]Epoch 34:  14%|█▍        | 3/21 [00:00<00:00, 36.42it/s, train_loss=0.00339, val_loss=0.00379]Epoch 34:  19%|█▉        | 4/21 [00:00<00:00, 44.29it/s, train_loss=0.00339, val_loss=0.00379]Epoch 34:  19%|█▉        | 4/21 [00:00<00:00, 36.04it/s, train_loss=0.00321, val_loss=0.00379]Epoch 34:  24%|██▍       | 5/21 [00:00<00:00, 41.94it/s, train_loss=0.00321, val_loss=0.00379]Epoch 34:  24%|██▍       | 5/21 [00:00<00:00, 35.68it/s, train_loss=0.00364, val_loss=0.00379]Epoch 34:  29%|██▊       | 6/21 [00:00<00:00, 40.47it/s, train_loss=0.00364, val_loss=0.00379]Epoch 34:  29%|██▊       | 6/21 [00:00<00:00, 35.50it/s, train_loss=0.00335, val_loss=0.00379]Epoch 34:  33%|███▎      | 7/21 [00:00<00:00, 39.39it/s, train_loss=0.00335, val_loss=0.00379]Epoch 34:  33%|███▎      | 7/21 [00:00<00:00, 35.30it/s, train_loss=0.00325, val_loss=0.00379]Epoch 34:  38%|███▊      | 8/21 [00:00<00:00, 38.78it/s, train_loss=0.00325, val_loss=0.00379]Epoch 34:  38%|███▊      | 8/21 [00:00<00:00, 35.64it/s, train_loss=0.00347, val_loss=0.00379]Epoch 34:  43%|████▎     | 9/21 [00:00<00:00, 38.59it/s, train_loss=0.00347, val_loss=0.00379]Epoch 34:  43%|████▎     | 9/21 [00:00<00:00, 35.83it/s, train_loss=0.00318, val_loss=0.00379]Epoch 34:  48%|████▊     | 10/21 [00:00<00:00, 38.63it/s, train_loss=0.00318, val_loss=0.00379]Epoch 34:  48%|████▊     | 10/21 [00:00<00:00, 35.78it/s, train_loss=0.00318, val_loss=0.00379]Epoch 34:  52%|█████▏    | 11/21 [00:00<00:00, 38.28it/s, train_loss=0.00318, val_loss=0.00379]Epoch 34:  52%|█████▏    | 11/21 [00:00<00:00, 35.69it/s, train_loss=0.0033, val_loss=0.00379] Epoch 34:  57%|█████▋    | 12/21 [00:00<00:00, 37.96it/s, train_loss=0.0033, val_loss=0.00379]Epoch 34:  57%|█████▋    | 12/21 [00:00<00:00, 35.64it/s, train_loss=0.00348, val_loss=0.00379]Epoch 34:  62%|██████▏   | 13/21 [00:00<00:00, 37.61it/s, train_loss=0.00348, val_loss=0.00379]Epoch 34:  62%|██████▏   | 13/21 [00:00<00:00, 35.53it/s, train_loss=0.00321, val_loss=0.00379]Epoch 34:  67%|██████▋   | 14/21 [00:00<00:00, 37.29it/s, train_loss=0.00321, val_loss=0.00379]Epoch 34:  67%|██████▋   | 14/21 [00:00<00:00, 35.67it/s, train_loss=0.00368, val_loss=0.00379]Epoch 34:  71%|███████▏  | 15/21 [00:00<00:00, 37.31it/s, train_loss=0.00368, val_loss=0.00379]Epoch 34:  71%|███████▏  | 15/21 [00:00<00:00, 35.78it/s, train_loss=0.0033, val_loss=0.00379] Epoch 34:  76%|███████▌  | 16/21 [00:00<00:00, 37.48it/s, train_loss=0.0033, val_loss=0.00379]Epoch 34:  76%|███████▌  | 16/21 [00:00<00:00, 35.75it/s, train_loss=0.00318, val_loss=0.00379]Epoch 34:  81%|████████  | 17/21 [00:00<00:00, 37.31it/s, train_loss=0.00318, val_loss=0.00379]Epoch 34:  81%|████████  | 17/21 [00:00<00:00, 35.70it/s, train_loss=0.00313, val_loss=0.00379]Epoch 34:  86%|████████▌ | 18/21 [00:00<00:00, 37.17it/s, train_loss=0.00313, val_loss=0.00379]Epoch 34:  86%|████████▌ | 18/21 [00:00<00:00, 35.66it/s, train_loss=0.0033, val_loss=0.00379] Epoch 34:  90%|█████████ | 19/21 [00:00<00:00, 37.05it/s, train_loss=0.0033, val_loss=0.00379]Epoch 34:  90%|█████████ | 19/21 [00:00<00:00, 35.61it/s, train_loss=0.0032, val_loss=0.00379]Epoch 34:  95%|█████████▌| 20/21 [00:00<00:00, 36.90it/s, train_loss=0.0032, val_loss=0.00379]Epoch 34:  95%|█████████▌| 20/21 [00:00<00:00, 35.54it/s, train_loss=0.00331, val_loss=0.00379]Epoch 34: 100%|██████████| 21/21 [00:00<00:00, 36.76it/s, train_loss=0.00331, val_loss=0.00379]Epoch 34: 100%|██████████| 21/21 [00:00<00:00, 35.49it/s, train_loss=0.0031, val_loss=0.00379] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 126.00it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 146.61it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 156.11it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 123.29it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 121.05it/s][A
                                                                       [AEpoch 34: 100%|██████████| 21/21 [00:00<00:00, 31.72it/s, train_loss=0.0031, val_loss=0.00376]Epoch 34: 100%|██████████| 21/21 [00:00<00:00, 31.67it/s, train_loss=0.0031, val_loss=0.00376]Epoch 34:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0031, val_loss=0.00376]         Epoch 35:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0031, val_loss=0.00376]Epoch 35:   5%|▍         | 1/21 [00:00<00:00, 103.73it/s, train_loss=0.0031, val_loss=0.00376]Epoch 35:   5%|▍         | 1/21 [00:00<00:00, 37.31it/s, train_loss=0.00337, val_loss=0.00376]Epoch 35:  10%|▉         | 2/21 [00:00<00:00, 55.70it/s, train_loss=0.00337, val_loss=0.00376]Epoch 35:  10%|▉         | 2/21 [00:00<00:00, 36.99it/s, train_loss=0.00312, val_loss=0.00376]Epoch 35:  14%|█▍        | 3/21 [00:00<00:00, 48.52it/s, train_loss=0.00312, val_loss=0.00376]Epoch 35:  14%|█▍        | 3/21 [00:00<00:00, 36.34it/s, train_loss=0.00334, val_loss=0.00376]Epoch 35:  19%|█▉        | 4/21 [00:00<00:00, 44.21it/s, train_loss=0.00334, val_loss=0.00376]Epoch 35:  19%|█▉        | 4/21 [00:00<00:00, 36.01it/s, train_loss=0.00315, val_loss=0.00376]Epoch 35:  24%|██▍       | 5/21 [00:00<00:00, 42.00it/s, train_loss=0.00315, val_loss=0.00376]Epoch 35:  24%|██▍       | 5/21 [00:00<00:00, 35.84it/s, train_loss=0.00323, val_loss=0.00376]Epoch 35:  29%|██▊       | 6/21 [00:00<00:00, 40.45it/s, train_loss=0.00323, val_loss=0.00376]Epoch 35:  29%|██▊       | 6/21 [00:00<00:00, 35.63it/s, train_loss=0.00317, val_loss=0.00376]Epoch 35:  33%|███▎      | 7/21 [00:00<00:00, 39.39it/s, train_loss=0.00317, val_loss=0.00376]Epoch 35:  33%|███▎      | 7/21 [00:00<00:00, 35.47it/s, train_loss=0.00337, val_loss=0.00376]Epoch 35:  38%|███▊      | 8/21 [00:00<00:00, 38.53it/s, train_loss=0.00337, val_loss=0.00376]Epoch 35:  38%|███▊      | 8/21 [00:00<00:00, 35.64it/s, train_loss=0.00324, val_loss=0.00376]Epoch 35:  43%|████▎     | 9/21 [00:00<00:00, 38.47it/s, train_loss=0.00324, val_loss=0.00376]Epoch 35:  43%|████▎     | 9/21 [00:00<00:00, 35.62it/s, train_loss=0.00324, val_loss=0.00376]Epoch 35:  48%|████▊     | 10/21 [00:00<00:00, 38.25it/s, train_loss=0.00324, val_loss=0.00376]Epoch 35:  48%|████▊     | 10/21 [00:00<00:00, 35.53it/s, train_loss=0.00313, val_loss=0.00376]Epoch 35:  52%|█████▏    | 11/21 [00:00<00:00, 38.00it/s, train_loss=0.00313, val_loss=0.00376]Epoch 35:  52%|█████▏    | 11/21 [00:00<00:00, 35.48it/s, train_loss=0.00337, val_loss=0.00376]Epoch 35:  57%|█████▋    | 12/21 [00:00<00:00, 37.71it/s, train_loss=0.00337, val_loss=0.00376]Epoch 35:  57%|█████▋    | 12/21 [00:00<00:00, 35.40it/s, train_loss=0.00335, val_loss=0.00376]Epoch 35:  62%|██████▏   | 13/21 [00:00<00:00, 37.45it/s, train_loss=0.00335, val_loss=0.00376]Epoch 35:  62%|██████▏   | 13/21 [00:00<00:00, 35.34it/s, train_loss=0.00342, val_loss=0.00376]Epoch 35:  67%|██████▋   | 14/21 [00:00<00:00, 37.23it/s, train_loss=0.00342, val_loss=0.00376]Epoch 35:  67%|██████▋   | 14/21 [00:00<00:00, 35.28it/s, train_loss=0.00332, val_loss=0.00376]Epoch 35:  71%|███████▏  | 15/21 [00:00<00:00, 37.00it/s, train_loss=0.00332, val_loss=0.00376]Epoch 35:  71%|███████▏  | 15/21 [00:00<00:00, 35.24it/s, train_loss=0.0033, val_loss=0.00376] Epoch 35:  76%|███████▌  | 16/21 [00:00<00:00, 36.81it/s, train_loss=0.0033, val_loss=0.00376]Epoch 35:  76%|███████▌  | 16/21 [00:00<00:00, 35.18it/s, train_loss=0.00334, val_loss=0.00376]Epoch 35:  81%|████████  | 17/21 [00:00<00:00, 36.69it/s, train_loss=0.00334, val_loss=0.00376]Epoch 35:  81%|████████  | 17/21 [00:00<00:00, 35.12it/s, train_loss=0.00333, val_loss=0.00376]Epoch 35:  86%|████████▌ | 18/21 [00:00<00:00, 36.44it/s, train_loss=0.00333, val_loss=0.00376]Epoch 35:  86%|████████▌ | 18/21 [00:00<00:00, 35.01it/s, train_loss=0.00344, val_loss=0.00376]Epoch 35:  90%|█████████ | 19/21 [00:00<00:00, 36.38it/s, train_loss=0.00344, val_loss=0.00376]Epoch 35:  90%|█████████ | 19/21 [00:00<00:00, 35.00it/s, train_loss=0.00331, val_loss=0.00376]Epoch 35:  95%|█████████▌| 20/21 [00:00<00:00, 36.32it/s, train_loss=0.00331, val_loss=0.00376]Epoch 35:  95%|█████████▌| 20/21 [00:00<00:00, 35.00it/s, train_loss=0.00336, val_loss=0.00376]Epoch 35: 100%|██████████| 21/21 [00:00<00:00, 36.22it/s, train_loss=0.00336, val_loss=0.00376]Epoch 35: 100%|██████████| 21/21 [00:00<00:00, 34.99it/s, train_loss=0.00321, val_loss=0.00376]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 149.21it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 165.88it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 174.09it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 151.29it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 132.24it/s][A
                                                                       [AEpoch 35: 100%|██████████| 21/21 [00:00<00:00, 31.55it/s, train_loss=0.00321, val_loss=0.00377]Epoch 35: 100%|██████████| 21/21 [00:00<00:00, 31.50it/s, train_loss=0.00321, val_loss=0.00377]Epoch 35:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00321, val_loss=0.00377]         Epoch 36:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00321, val_loss=0.00377]Epoch 36:   5%|▍         | 1/21 [00:00<00:00, 105.96it/s, train_loss=0.00321, val_loss=0.00377]Epoch 36:   5%|▍         | 1/21 [00:00<00:00, 33.77it/s, train_loss=0.00321, val_loss=0.00377] Epoch 36:  10%|▉         | 2/21 [00:00<00:00, 51.99it/s, train_loss=0.00321, val_loss=0.00377]Epoch 36:  10%|▉         | 2/21 [00:00<00:00, 34.06it/s, train_loss=0.00326, val_loss=0.00377]Epoch 36:  14%|█▍        | 3/21 [00:00<00:00, 44.27it/s, train_loss=0.00326, val_loss=0.00377]Epoch 36:  14%|█▍        | 3/21 [00:00<00:00, 34.18it/s, train_loss=0.00314, val_loss=0.00377]Epoch 36:  19%|█▉        | 4/21 [00:00<00:00, 41.43it/s, train_loss=0.00314, val_loss=0.00377]Epoch 36:  19%|█▉        | 4/21 [00:00<00:00, 34.28it/s, train_loss=0.00327, val_loss=0.00377]Epoch 36:  24%|██▍       | 5/21 [00:00<00:00, 39.77it/s, train_loss=0.00327, val_loss=0.00377]Epoch 36:  24%|██▍       | 5/21 [00:00<00:00, 34.29it/s, train_loss=0.00328, val_loss=0.00377]Epoch 36:  29%|██▊       | 6/21 [00:00<00:00, 38.72it/s, train_loss=0.00328, val_loss=0.00377]Epoch 36:  29%|██▊       | 6/21 [00:00<00:00, 34.76it/s, train_loss=0.00325, val_loss=0.00377]Epoch 36:  33%|███▎      | 7/21 [00:00<00:00, 38.51it/s, train_loss=0.00325, val_loss=0.00377]Epoch 36:  33%|███▎      | 7/21 [00:00<00:00, 35.10it/s, train_loss=0.00339, val_loss=0.00377]Epoch 36:  38%|███▊      | 8/21 [00:00<00:00, 38.58it/s, train_loss=0.00339, val_loss=0.00377]Epoch 36:  38%|███▊      | 8/21 [00:00<00:00, 35.09it/s, train_loss=0.00348, val_loss=0.00377]Epoch 36:  43%|████▎     | 9/21 [00:00<00:00, 38.11it/s, train_loss=0.00348, val_loss=0.00377]Epoch 36:  43%|████▎     | 9/21 [00:00<00:00, 35.00it/s, train_loss=0.00336, val_loss=0.00377]Epoch 36:  48%|████▊     | 10/21 [00:00<00:00, 37.36it/s, train_loss=0.00336, val_loss=0.00377]Epoch 36:  48%|████▊     | 10/21 [00:00<00:00, 34.87it/s, train_loss=0.00329, val_loss=0.00377]Epoch 36:  52%|█████▏    | 11/21 [00:00<00:00, 37.24it/s, train_loss=0.00329, val_loss=0.00377]Epoch 36:  52%|█████▏    | 11/21 [00:00<00:00, 34.82it/s, train_loss=0.00359, val_loss=0.00377]Epoch 36:  57%|█████▋    | 12/21 [00:00<00:00, 37.03it/s, train_loss=0.00359, val_loss=0.00377]Epoch 36:  57%|█████▋    | 12/21 [00:00<00:00, 34.81it/s, train_loss=0.00312, val_loss=0.00377]Epoch 36:  62%|██████▏   | 13/21 [00:00<00:00, 36.89it/s, train_loss=0.00312, val_loss=0.00377]Epoch 36:  62%|██████▏   | 13/21 [00:00<00:00, 34.83it/s, train_loss=0.00334, val_loss=0.00377]Epoch 36:  67%|██████▋   | 14/21 [00:00<00:00, 36.73it/s, train_loss=0.00334, val_loss=0.00377]Epoch 36:  67%|██████▋   | 14/21 [00:00<00:00, 34.86it/s, train_loss=0.00336, val_loss=0.00377]Epoch 36:  71%|███████▏  | 15/21 [00:00<00:00, 36.53it/s, train_loss=0.00336, val_loss=0.00377]Epoch 36:  71%|███████▏  | 15/21 [00:00<00:00, 35.03it/s, train_loss=0.00322, val_loss=0.00377]Epoch 36:  76%|███████▌  | 16/21 [00:00<00:00, 36.65it/s, train_loss=0.00322, val_loss=0.00377]Epoch 36:  76%|███████▌  | 16/21 [00:00<00:00, 35.01it/s, train_loss=0.00324, val_loss=0.00377]Epoch 36:  81%|████████  | 17/21 [00:00<00:00, 36.55it/s, train_loss=0.00324, val_loss=0.00377]Epoch 36:  81%|████████  | 17/21 [00:00<00:00, 35.00it/s, train_loss=0.00346, val_loss=0.00377]Epoch 36:  86%|████████▌ | 18/21 [00:00<00:00, 36.39it/s, train_loss=0.00346, val_loss=0.00377]Epoch 36:  86%|████████▌ | 18/21 [00:00<00:00, 34.97it/s, train_loss=0.00305, val_loss=0.00377]Epoch 36:  90%|█████████ | 19/21 [00:00<00:00, 36.24it/s, train_loss=0.00305, val_loss=0.00377]Epoch 36:  90%|█████████ | 19/21 [00:00<00:00, 35.07it/s, train_loss=0.00327, val_loss=0.00377]Epoch 36:  95%|█████████▌| 20/21 [00:00<00:00, 36.34it/s, train_loss=0.00327, val_loss=0.00377]Epoch 36:  95%|█████████▌| 20/21 [00:00<00:00, 35.06it/s, train_loss=0.00337, val_loss=0.00377]Epoch 36: 100%|██████████| 21/21 [00:00<00:00, 36.26it/s, train_loss=0.00337, val_loss=0.00377]Epoch 36: 100%|██████████| 21/21 [00:00<00:00, 35.04it/s, train_loss=0.00306, val_loss=0.00377]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 145.62it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 169.60it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 180.46it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 148.45it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 130.76it/s][A
                                                                       [AEpoch 36: 100%|██████████| 21/21 [00:00<00:00, 31.44it/s, train_loss=0.00306, val_loss=0.00377]Epoch 36: 100%|██████████| 21/21 [00:00<00:00, 31.40it/s, train_loss=0.00306, val_loss=0.00377]Epoch 36:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00306, val_loss=0.00377]         Epoch 37:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00306, val_loss=0.00377]Epoch 37:   5%|▍         | 1/21 [00:00<00:00, 102.91it/s, train_loss=0.00306, val_loss=0.00377]Epoch 37:   5%|▍         | 1/21 [00:00<00:00, 37.00it/s, train_loss=0.00331, val_loss=0.00377] Epoch 37:  10%|▉         | 2/21 [00:00<00:00, 57.24it/s, train_loss=0.00331, val_loss=0.00377]Epoch 37:  10%|▉         | 2/21 [00:00<00:00, 35.93it/s, train_loss=0.00333, val_loss=0.00377]Epoch 37:  14%|█▍        | 3/21 [00:00<00:00, 46.95it/s, train_loss=0.00333, val_loss=0.00377]Epoch 37:  14%|█▍        | 3/21 [00:00<00:00, 35.44it/s, train_loss=0.00329, val_loss=0.00377]Epoch 37:  19%|█▉        | 4/21 [00:00<00:00, 42.88it/s, train_loss=0.00329, val_loss=0.00377]Epoch 37:  19%|█▉        | 4/21 [00:00<00:00, 35.14it/s, train_loss=0.00317, val_loss=0.00377]Epoch 37:  24%|██▍       | 5/21 [00:00<00:00, 40.95it/s, train_loss=0.00317, val_loss=0.00377]Epoch 37:  24%|██▍       | 5/21 [00:00<00:00, 35.03it/s, train_loss=0.00319, val_loss=0.00377]Epoch 37:  29%|██▊       | 6/21 [00:00<00:00, 39.95it/s, train_loss=0.00319, val_loss=0.00377]Epoch 37:  29%|██▊       | 6/21 [00:00<00:00, 35.06it/s, train_loss=0.00316, val_loss=0.00377]Epoch 37:  33%|███▎      | 7/21 [00:00<00:00, 39.05it/s, train_loss=0.00316, val_loss=0.00377]Epoch 37:  33%|███▎      | 7/21 [00:00<00:00, 35.50it/s, train_loss=0.00328, val_loss=0.00377]Epoch 37:  38%|███▊      | 8/21 [00:00<00:00, 38.93it/s, train_loss=0.00328, val_loss=0.00377]Epoch 37:  38%|███▊      | 8/21 [00:00<00:00, 35.73it/s, train_loss=0.00338, val_loss=0.00377]Epoch 37:  43%|████▎     | 9/21 [00:00<00:00, 38.92it/s, train_loss=0.00338, val_loss=0.00377]Epoch 37:  43%|████▎     | 9/21 [00:00<00:00, 35.71it/s, train_loss=0.00315, val_loss=0.00377]Epoch 37:  48%|████▊     | 10/21 [00:00<00:00, 38.48it/s, train_loss=0.00315, val_loss=0.00377]Epoch 37:  48%|████▊     | 10/21 [00:00<00:00, 35.67it/s, train_loss=0.00322, val_loss=0.00377]Epoch 37:  52%|█████▏    | 11/21 [00:00<00:00, 38.01it/s, train_loss=0.00322, val_loss=0.00377]Epoch 37:  52%|█████▏    | 11/21 [00:00<00:00, 35.83it/s, train_loss=0.00343, val_loss=0.00377]Epoch 37:  57%|█████▋    | 12/21 [00:00<00:00, 38.04it/s, train_loss=0.00343, val_loss=0.00377]Epoch 37:  57%|█████▋    | 12/21 [00:00<00:00, 35.76it/s, train_loss=0.00346, val_loss=0.00377]Epoch 37:  62%|██████▏   | 13/21 [00:00<00:00, 37.84it/s, train_loss=0.00346, val_loss=0.00377]Epoch 37:  62%|██████▏   | 13/21 [00:00<00:00, 35.72it/s, train_loss=0.00324, val_loss=0.00377]Epoch 37:  67%|██████▋   | 14/21 [00:00<00:00, 37.65it/s, train_loss=0.00324, val_loss=0.00377]Epoch 37:  67%|██████▋   | 14/21 [00:00<00:00, 35.67it/s, train_loss=0.00318, val_loss=0.00377]Epoch 37:  71%|███████▏  | 15/21 [00:00<00:00, 37.42it/s, train_loss=0.00318, val_loss=0.00377]Epoch 37:  71%|███████▏  | 15/21 [00:00<00:00, 35.60it/s, train_loss=0.00328, val_loss=0.00377]Epoch 37:  76%|███████▌  | 16/21 [00:00<00:00, 37.25it/s, train_loss=0.00328, val_loss=0.00377]Epoch 37:  76%|███████▌  | 16/21 [00:00<00:00, 35.53it/s, train_loss=0.00338, val_loss=0.00377]Epoch 37:  81%|████████  | 17/21 [00:00<00:00, 37.03it/s, train_loss=0.00338, val_loss=0.00377]Epoch 37:  81%|████████  | 17/21 [00:00<00:00, 35.66it/s, train_loss=0.00324, val_loss=0.00377]Epoch 37:  86%|████████▌ | 18/21 [00:00<00:00, 37.05it/s, train_loss=0.00324, val_loss=0.00377]Epoch 37:  86%|████████▌ | 18/21 [00:00<00:00, 35.77it/s, train_loss=0.00337, val_loss=0.00377]Epoch 37:  90%|█████████ | 19/21 [00:00<00:00, 37.17it/s, train_loss=0.00337, val_loss=0.00377]Epoch 37:  90%|█████████ | 19/21 [00:00<00:00, 35.73it/s, train_loss=0.0033, val_loss=0.00377] Epoch 37:  95%|█████████▌| 20/21 [00:00<00:00, 37.05it/s, train_loss=0.0033, val_loss=0.00377]Epoch 37:  95%|█████████▌| 20/21 [00:00<00:00, 35.68it/s, train_loss=0.00312, val_loss=0.00377]Epoch 37: 100%|██████████| 21/21 [00:00<00:00, 36.93it/s, train_loss=0.00312, val_loss=0.00377]Epoch 37: 100%|██████████| 21/21 [00:00<00:00, 35.63it/s, train_loss=0.00347, val_loss=0.00377]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 130.36it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 152.70it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 155.55it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 145.30it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 121.11it/s][A
                                                                       [AEpoch 37: 100%|██████████| 21/21 [00:00<00:00, 31.89it/s, train_loss=0.00347, val_loss=0.00376]Epoch 37: 100%|██████████| 21/21 [00:00<00:00, 31.85it/s, train_loss=0.00347, val_loss=0.00376]Epoch 37:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00347, val_loss=0.00376]         Epoch 38:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00347, val_loss=0.00376]Epoch 38:   5%|▍         | 1/21 [00:00<00:00, 109.53it/s, train_loss=0.00347, val_loss=0.00376]Epoch 38:   5%|▍         | 1/21 [00:00<00:00, 37.39it/s, train_loss=0.0031, val_loss=0.00376]  Epoch 38:  10%|▉         | 2/21 [00:00<00:00, 56.23it/s, train_loss=0.0031, val_loss=0.00376]Epoch 38:  10%|▉         | 2/21 [00:00<00:00, 36.51it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:  14%|█▍        | 3/21 [00:00<00:00, 47.95it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:  14%|█▍        | 3/21 [00:00<00:00, 36.03it/s, train_loss=0.00332, val_loss=0.00376]Epoch 38:  19%|█▉        | 4/21 [00:00<00:00, 43.88it/s, train_loss=0.00332, val_loss=0.00376]Epoch 38:  19%|█▉        | 4/21 [00:00<00:00, 35.77it/s, train_loss=0.00324, val_loss=0.00376]Epoch 38:  24%|██▍       | 5/21 [00:00<00:00, 41.72it/s, train_loss=0.00324, val_loss=0.00376]Epoch 38:  24%|██▍       | 5/21 [00:00<00:00, 35.62it/s, train_loss=0.00326, val_loss=0.00376]Epoch 38:  29%|██▊       | 6/21 [00:00<00:00, 40.35it/s, train_loss=0.00326, val_loss=0.00376]Epoch 38:  29%|██▊       | 6/21 [00:00<00:00, 35.56it/s, train_loss=0.00334, val_loss=0.00376]Epoch 38:  33%|███▎      | 7/21 [00:00<00:00, 39.29it/s, train_loss=0.00334, val_loss=0.00376]Epoch 38:  33%|███▎      | 7/21 [00:00<00:00, 35.78it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:  38%|███▊      | 8/21 [00:00<00:00, 39.11it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:  38%|███▊      | 8/21 [00:00<00:00, 35.70it/s, train_loss=0.0032, val_loss=0.00376] Epoch 38:  43%|████▎     | 9/21 [00:00<00:00, 38.79it/s, train_loss=0.0032, val_loss=0.00376]Epoch 38:  43%|████▎     | 9/21 [00:00<00:00, 35.64it/s, train_loss=0.00323, val_loss=0.00376]Epoch 38:  48%|████▊     | 10/21 [00:00<00:00, 38.38it/s, train_loss=0.00323, val_loss=0.00376]Epoch 38:  48%|████▊     | 10/21 [00:00<00:00, 35.57it/s, train_loss=0.00328, val_loss=0.00376]Epoch 38:  52%|█████▏    | 11/21 [00:00<00:00, 38.04it/s, train_loss=0.00328, val_loss=0.00376]Epoch 38:  52%|█████▏    | 11/21 [00:00<00:00, 35.51it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:  57%|█████▋    | 12/21 [00:00<00:00, 37.72it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:  57%|█████▋    | 12/21 [00:00<00:00, 35.44it/s, train_loss=0.00312, val_loss=0.00376]Epoch 38:  62%|██████▏   | 13/21 [00:00<00:00, 37.49it/s, train_loss=0.00312, val_loss=0.00376]Epoch 38:  62%|██████▏   | 13/21 [00:00<00:00, 35.38it/s, train_loss=0.00337, val_loss=0.00376]Epoch 38:  67%|██████▋   | 14/21 [00:00<00:00, 37.22it/s, train_loss=0.00337, val_loss=0.00376]Epoch 38:  67%|██████▋   | 14/21 [00:00<00:00, 35.55it/s, train_loss=0.00339, val_loss=0.00376]Epoch 38:  71%|███████▏  | 15/21 [00:00<00:00, 37.23it/s, train_loss=0.00339, val_loss=0.00376]Epoch 38:  71%|███████▏  | 15/21 [00:00<00:00, 35.67it/s, train_loss=0.00335, val_loss=0.00376]Epoch 38:  76%|███████▌  | 16/21 [00:00<00:00, 37.35it/s, train_loss=0.00335, val_loss=0.00376]Epoch 38:  76%|███████▌  | 16/21 [00:00<00:00, 35.61it/s, train_loss=0.00324, val_loss=0.00376]Epoch 38:  81%|████████  | 17/21 [00:00<00:00, 37.17it/s, train_loss=0.00324, val_loss=0.00376]Epoch 38:  81%|████████  | 17/21 [00:00<00:00, 35.56it/s, train_loss=0.0035, val_loss=0.00376] Epoch 38:  86%|████████▌ | 18/21 [00:00<00:00, 37.06it/s, train_loss=0.0035, val_loss=0.00376]Epoch 38:  86%|████████▌ | 18/21 [00:00<00:00, 35.55it/s, train_loss=0.00343, val_loss=0.00376]Epoch 38:  90%|█████████ | 19/21 [00:00<00:00, 36.95it/s, train_loss=0.00343, val_loss=0.00376]Epoch 38:  90%|█████████ | 19/21 [00:00<00:00, 35.51it/s, train_loss=0.00329, val_loss=0.00376]Epoch 38:  95%|█████████▌| 20/21 [00:00<00:00, 36.75it/s, train_loss=0.00329, val_loss=0.00376]Epoch 38:  95%|█████████▌| 20/21 [00:00<00:00, 35.60it/s, train_loss=0.00339, val_loss=0.00376]Epoch 38: 100%|██████████| 21/21 [00:00<00:00, 36.83it/s, train_loss=0.00339, val_loss=0.00376]Epoch 38: 100%|██████████| 21/21 [00:00<00:00, 35.57it/s, train_loss=0.00321, val_loss=0.00376]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 155.03it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 182.00it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 192.47it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 150.15it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 131.85it/s][A
                                                                       [AEpoch 38: 100%|██████████| 21/21 [00:00<00:00, 31.92it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38: 100%|██████████| 21/21 [00:00<00:00, 31.88it/s, train_loss=0.00321, val_loss=0.00376]Epoch 38:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00321, val_loss=0.00376]         Epoch 39:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00321, val_loss=0.00376]Epoch 39:   5%|▍         | 1/21 [00:00<00:00, 105.83it/s, train_loss=0.00321, val_loss=0.00376]Epoch 39:   5%|▍         | 1/21 [00:00<00:00, 37.02it/s, train_loss=0.00323, val_loss=0.00376] Epoch 39:  10%|▉         | 2/21 [00:00<00:00, 55.45it/s, train_loss=0.00323, val_loss=0.00376]Epoch 39:  10%|▉         | 2/21 [00:00<00:00, 36.79it/s, train_loss=0.00318, val_loss=0.00376]Epoch 39:  14%|█▍        | 3/21 [00:00<00:00, 47.61it/s, train_loss=0.00318, val_loss=0.00376]Epoch 39:  14%|█▍        | 3/21 [00:00<00:00, 36.05it/s, train_loss=0.00318, val_loss=0.00376]Epoch 39:  19%|█▉        | 4/21 [00:00<00:00, 43.87it/s, train_loss=0.00318, val_loss=0.00376]Epoch 39:  19%|█▉        | 4/21 [00:00<00:00, 35.75it/s, train_loss=0.00353, val_loss=0.00376]Epoch 39:  24%|██▍       | 5/21 [00:00<00:00, 41.69it/s, train_loss=0.00353, val_loss=0.00376]Epoch 39:  24%|██▍       | 5/21 [00:00<00:00, 35.55it/s, train_loss=0.00334, val_loss=0.00376]Epoch 39:  29%|██▊       | 6/21 [00:00<00:00, 40.38it/s, train_loss=0.00334, val_loss=0.00376]Epoch 39:  29%|██▊       | 6/21 [00:00<00:00, 35.40it/s, train_loss=0.00336, val_loss=0.00376]Epoch 39:  33%|███▎      | 7/21 [00:00<00:00, 39.35it/s, train_loss=0.00336, val_loss=0.00376]Epoch 39:  33%|███▎      | 7/21 [00:00<00:00, 35.25it/s, train_loss=0.0032, val_loss=0.00376] Epoch 39:  38%|███▊      | 8/21 [00:00<00:00, 38.68it/s, train_loss=0.0032, val_loss=0.00376]Epoch 39:  38%|███▊      | 8/21 [00:00<00:00, 35.12it/s, train_loss=0.00318, val_loss=0.00376]Epoch 39:  43%|████▎     | 9/21 [00:00<00:00, 38.06it/s, train_loss=0.00318, val_loss=0.00376]Epoch 39:  43%|████▎     | 9/21 [00:00<00:00, 35.34it/s, train_loss=0.0035, val_loss=0.00376] Epoch 39:  48%|████▊     | 10/21 [00:00<00:00, 37.89it/s, train_loss=0.0035, val_loss=0.00376]Epoch 39:  48%|████▊     | 10/21 [00:00<00:00, 35.48it/s, train_loss=0.00331, val_loss=0.00376]Epoch 39:  52%|█████▏    | 11/21 [00:00<00:00, 38.00it/s, train_loss=0.00331, val_loss=0.00376]Epoch 39:  52%|█████▏    | 11/21 [00:00<00:00, 35.42it/s, train_loss=0.00308, val_loss=0.00376]Epoch 39:  57%|█████▋    | 12/21 [00:00<00:00, 37.69it/s, train_loss=0.00308, val_loss=0.00376]Epoch 39:  57%|█████▋    | 12/21 [00:00<00:00, 35.36it/s, train_loss=0.00329, val_loss=0.00376]Epoch 39:  62%|██████▏   | 13/21 [00:00<00:00, 37.39it/s, train_loss=0.00329, val_loss=0.00376]Epoch 39:  62%|██████▏   | 13/21 [00:00<00:00, 35.36it/s, train_loss=0.00346, val_loss=0.00376]Epoch 39:  67%|██████▋   | 14/21 [00:00<00:00, 37.17it/s, train_loss=0.00346, val_loss=0.00376]Epoch 39:  67%|██████▋   | 14/21 [00:00<00:00, 35.52it/s, train_loss=0.0036, val_loss=0.00376] Epoch 39:  71%|███████▏  | 15/21 [00:00<00:00, 37.30it/s, train_loss=0.0036, val_loss=0.00376]Epoch 39:  71%|███████▏  | 15/21 [00:00<00:00, 35.48it/s, train_loss=0.00327, val_loss=0.00376]Epoch 39:  76%|███████▌  | 16/21 [00:00<00:00, 37.15it/s, train_loss=0.00327, val_loss=0.00376]Epoch 39:  76%|███████▌  | 16/21 [00:00<00:00, 35.46it/s, train_loss=0.00314, val_loss=0.00376]Epoch 39:  81%|████████  | 17/21 [00:00<00:00, 37.04it/s, train_loss=0.00314, val_loss=0.00376]Epoch 39:  81%|████████  | 17/21 [00:00<00:00, 35.42it/s, train_loss=0.0032, val_loss=0.00376] Epoch 39:  86%|████████▌ | 18/21 [00:00<00:00, 36.84it/s, train_loss=0.0032, val_loss=0.00376]Epoch 39:  86%|████████▌ | 18/21 [00:00<00:00, 35.56it/s, train_loss=0.00326, val_loss=0.00376]Epoch 39:  90%|█████████ | 19/21 [00:00<00:00, 36.88it/s, train_loss=0.00326, val_loss=0.00376]Epoch 39:  90%|█████████ | 19/21 [00:00<00:00, 35.65it/s, train_loss=0.00308, val_loss=0.00376]Epoch 39:  95%|█████████▌| 20/21 [00:00<00:00, 36.99it/s, train_loss=0.00308, val_loss=0.00376]Epoch 39:  95%|█████████▌| 20/21 [00:00<00:00, 35.62it/s, train_loss=0.00328, val_loss=0.00376]Epoch 39: 100%|██████████| 21/21 [00:00<00:00, 36.86it/s, train_loss=0.00328, val_loss=0.00376]Epoch 39: 100%|██████████| 21/21 [00:00<00:00, 35.57it/s, train_loss=0.00319, val_loss=0.00376]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 136.25it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 159.96it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 167.99it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 144.03it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 121.00it/s][A
                                                                       [AEpoch 39: 100%|██████████| 21/21 [00:00<00:00, 31.81it/s, train_loss=0.00319, val_loss=0.00376]Epoch 39: 100%|██████████| 21/21 [00:00<00:00, 31.76it/s, train_loss=0.00319, val_loss=0.00376]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 21/21 [00:00<00:00, 31.67it/s, train_loss=0.00319, val_loss=0.00376]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/23 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/23 [00:00<?, ?it/s]Predicting DataLoader 0:   4%|▍         | 1/23 [00:00<00:00, 193.60it/s]Predicting DataLoader 0:   9%|▊         | 2/23 [00:00<00:00, 130.62it/s]Predicting DataLoader 0:  13%|█▎        | 3/23 [00:00<00:00, 102.50it/s]Predicting DataLoader 0:  17%|█▋        | 4/23 [00:00<00:00, 94.30it/s] Predicting DataLoader 0:  22%|██▏       | 5/23 [00:00<00:00, 95.20it/s]Predicting DataLoader 0:  26%|██▌       | 6/23 [00:00<00:00, 92.58it/s]Predicting DataLoader 0:  30%|███       | 7/23 [00:00<00:00, 89.50it/s]Predicting DataLoader 0:  35%|███▍      | 8/23 [00:00<00:00, 87.09it/s]Predicting DataLoader 0:  39%|███▉      | 9/23 [00:00<00:00, 85.42it/s]Predicting DataLoader 0:  43%|████▎     | 10/23 [00:00<00:00, 86.40it/s]Predicting DataLoader 0:  48%|████▊     | 11/23 [00:00<00:00, 86.14it/s]Predicting DataLoader 0:  52%|█████▏    | 12/23 [00:00<00:00, 84.99it/s]Predicting DataLoader 0:  57%|█████▋    | 13/23 [00:00<00:00, 85.75it/s]Predicting DataLoader 0:  61%|██████    | 14/23 [00:00<00:00, 86.63it/s]Predicting DataLoader 0:  65%|██████▌   | 15/23 [00:00<00:00, 85.49it/s]Predicting DataLoader 0:  70%|██████▉   | 16/23 [00:00<00:00, 86.06it/s]Predicting DataLoader 0:  74%|███████▍  | 17/23 [00:00<00:00, 86.43it/s]Predicting DataLoader 0:  78%|███████▊  | 18/23 [00:00<00:00, 85.52it/s]Predicting DataLoader 0:  83%|████████▎ | 19/23 [00:00<00:00, 86.01it/s]Predicting DataLoader 0:  87%|████████▋ | 20/23 [00:00<00:00, 86.43it/s]Predicting DataLoader 0:  91%|█████████▏| 21/23 [00:00<00:00, 85.72it/s]Predicting DataLoader 0:  96%|█████████▌| 22/23 [00:00<00:00, 86.19it/s]Predicting DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 86.82it/s]Predicting DataLoader 0: 100%|██████████| 23/23 [00:00<00:00, 86.35it/s][I 2025-08-18 03:29:26,647] A new study created in memory with name: no-name-c3deb5f1-fb71-463e-aff6-7f8a93c7929a
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 160, Horizon length: 15
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.98it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s][I 2025-08-18 03:30:08,870] Trial 0 finished with value: 37.83932649092506 and parameters: {'hidden_dim': 61, 'n_rnn_layers': 2, 'dropout': 0.28943961502793686}. Best is trial 0 with value: 37.83932649092506.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.11it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.05it/s][I 2025-08-18 03:31:00,580] Trial 1 finished with value: 24.599450661525978 and parameters: {'hidden_dim': 57, 'n_rnn_layers': 4, 'dropout': 0.13138241648172355}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.07it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.69it/s][I 2025-08-18 03:31:26,325] Trial 2 finished with value: 32.1172019320211 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 2, 'dropout': 0.4510840252275191}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.85it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.12it/s][I 2025-08-18 03:32:03,795] Trial 3 finished with value: 26.448555576999507 and parameters: {'hidden_dim': 73, 'n_rnn_layers': 3, 'dropout': 0.14552680186064054}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.54it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.80it/s] [I 2025-08-18 03:32:54,120] Trial 4 finished with value: 29.3461986571988 and parameters: {'hidden_dim': 87, 'n_rnn_layers': 4, 'dropout': 0.004463144733348912}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.38it/s][I 2025-08-18 03:33:27,394] Trial 5 finished with value: 36.74115041768728 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 4, 'dropout': 0.27526487944689354}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.96it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.72it/s] [I 2025-08-18 03:34:04,433] Trial 6 finished with value: 29.67211740415731 and parameters: {'hidden_dim': 47, 'n_rnn_layers': 4, 'dropout': 0.22897412296639563}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.38it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s][I 2025-08-18 03:34:28,498] Trial 7 finished with value: 31.414447439593474 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 2, 'dropout': 0.49822002182629654}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.27it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.04it/s] [I 2025-08-18 03:35:29,754] Trial 8 finished with value: 33.573338515778005 and parameters: {'hidden_dim': 110, 'n_rnn_layers': 4, 'dropout': 0.11813013382418275}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.69it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.87it/s] [I 2025-08-18 03:36:17,928] Trial 9 finished with value: 25.438109773803422 and parameters: {'hidden_dim': 99, 'n_rnn_layers': 3, 'dropout': 0.21477150874833506}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.013153106578013163 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.33it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.54it/s][I 2025-08-18 03:36:44,496] Trial 10 finished with value: 38.14608819200608 and parameters: {'hidden_dim': 35, 'n_rnn_layers': 1, 'dropout': 0.013153106578013163}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.69it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.75it/s] [I 2025-08-18 03:37:48,731] Trial 11 finished with value: 31.085734048895883 and parameters: {'hidden_dim': 114, 'n_rnn_layers': 3, 'dropout': 0.15605838870522237}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.10it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s][I 2025-08-18 03:38:20,532] Trial 12 finished with value: 30.7384724243965 and parameters: {'hidden_dim': 50, 'n_rnn_layers': 3, 'dropout': 0.3628068894601618}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.89it/s][I 2025-08-18 03:38:57,191] Trial 13 finished with value: 29.585750993310533 and parameters: {'hidden_dim': 81, 'n_rnn_layers': 3, 'dropout': 0.0872285095894976}. Best is trial 1 with value: 24.599450661525978.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.75it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.96it/s][I 2025-08-18 03:39:37,171] Trial 14 finished with value: 24.33526120213109 and parameters: {'hidden_dim': 37, 'n_rnn_layers': 4, 'dropout': 0.20235348396148212}. Best is trial 14 with value: 24.33526120213109.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.35it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.52it/s] [I 2025-08-18 03:40:17,312] Trial 15 finished with value: 32.28782026005847 and parameters: {'hidden_dim': 35, 'n_rnn_layers': 4, 'dropout': 0.33897126900708036}. Best is trial 14 with value: 24.33526120213109.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.07256175769799804 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.62it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.38it/s][I 2025-08-18 03:40:43,403] Trial 16 finished with value: 35.28004442932047 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 1, 'dropout': 0.07256175769799804}. Best is trial 14 with value: 24.33526120213109.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.29it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.33it/s] [I 2025-08-18 03:41:23,354] Trial 17 finished with value: 33.62169579113632 and parameters: {'hidden_dim': 58, 'n_rnn_layers': 4, 'dropout': 0.18416911593064092}. Best is trial 14 with value: 24.33526120213109.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.09it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.38it/s][I 2025-08-18 03:41:50,971] Trial 18 finished with value: 25.59817320752557 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.06618281200397846}. Best is trial 14 with value: 24.33526120213109.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.76it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.48it/s] [I 2025-08-18 03:42:28,136] Trial 19 finished with value: 31.723438092074748 and parameters: {'hidden_dim': 40, 'n_rnn_layers': 3, 'dropout': 0.33762487883489706}. Best is trial 14 with value: 24.33526120213109.
[I 2025-08-18 03:42:28,136] A new study created in memory with name: no-name-6a07c160-19d5-4cfa-890b-60c2e065746c
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 37, 'n_rnn_layers': 4, 'dropout': 0.20235348396148212}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.40it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.42it/s][I 2025-08-18 03:43:05,207] Trial 0 finished with value: 31.27440949081292 and parameters: {'hidden_dim': 57, 'n_rnn_layers': 2, 'dropout': 0.06187563187593015}. Best is trial 0 with value: 31.27440949081292.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.59it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.06it/s][I 2025-08-18 03:43:56,928] Trial 1 finished with value: 24.651557677275907 and parameters: {'hidden_dim': 57, 'n_rnn_layers': 4, 'dropout': 0.37539221586384885}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.49it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.61it/s][I 2025-08-18 03:44:32,738] Trial 2 finished with value: 37.24051686812286 and parameters: {'hidden_dim': 45, 'n_rnn_layers': 2, 'dropout': 0.24689281630949733}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.54it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.23it/s] [I 2025-08-18 03:45:03,939] Trial 3 finished with value: 34.837372636066085 and parameters: {'hidden_dim': 28, 'n_rnn_layers': 3, 'dropout': 0.45466569183442523}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.05it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.62it/s][I 2025-08-18 03:45:44,455] Trial 4 finished with value: 32.60696920692916 and parameters: {'hidden_dim': 97, 'n_rnn_layers': 3, 'dropout': 0.1584799804052519}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48498054288081727 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.41it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.81it/s][I 2025-08-18 03:46:17,092] Trial 5 finished with value: 36.29004691560597 and parameters: {'hidden_dim': 112, 'n_rnn_layers': 1, 'dropout': 0.48498054288081727}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.92it/s][I 2025-08-18 03:46:59,855] Trial 6 finished with value: 26.70657005370393 and parameters: {'hidden_dim': 68, 'n_rnn_layers': 4, 'dropout': 0.35962232813077727}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.95it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.48it/s][I 2025-08-18 03:48:00,176] Trial 7 finished with value: 27.6589649809681 and parameters: {'hidden_dim': 125, 'n_rnn_layers': 4, 'dropout': 0.3473563964522463}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 22.78it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s][I 2025-08-18 03:48:30,727] Trial 8 finished with value: 45.091712412447805 and parameters: {'hidden_dim': 33, 'n_rnn_layers': 3, 'dropout': 0.45057021388580837}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.62it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.32it/s] [I 2025-08-18 03:49:07,552] Trial 9 finished with value: 30.460670461835885 and parameters: {'hidden_dim': 36, 'n_rnn_layers': 3, 'dropout': 0.07733745104852041}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.16it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.65it/s][I 2025-08-18 03:49:36,539] Trial 10 finished with value: 31.55731078789863 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.30773866227797914}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.31it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.32it/s] [I 2025-08-18 03:50:15,417] Trial 11 finished with value: 30.349817852244037 and parameters: {'hidden_dim': 70, 'n_rnn_layers': 4, 'dropout': 0.36089055103827306}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 35.83it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.32it/s][I 2025-08-18 03:51:19,041] Trial 12 finished with value: 29.634708649942525 and parameters: {'hidden_dim': 75, 'n_rnn_layers': 4, 'dropout': 0.2346737805235605}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.17it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.52it/s][I 2025-08-18 03:51:58,808] Trial 13 finished with value: 26.05338475023433 and parameters: {'hidden_dim': 54, 'n_rnn_layers': 4, 'dropout': 0.3985911186285295}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40714947347133723 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.65it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.84it/s][I 2025-08-18 03:52:38,855] Trial 14 finished with value: 32.33244831569227 and parameters: {'hidden_dim': 49, 'n_rnn_layers': 1, 'dropout': 0.40714947347133723}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.90it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.15it/s][I 2025-08-18 03:53:28,784] Trial 15 finished with value: 26.285149929231714 and parameters: {'hidden_dim': 25, 'n_rnn_layers': 4, 'dropout': 0.2818030169026001}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.76it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.36it/s][I 2025-08-18 03:54:27,019] Trial 16 finished with value: 26.875693375436803 and parameters: {'hidden_dim': 85, 'n_rnn_layers': 2, 'dropout': 0.40222136732715924}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.59it/s][I 2025-08-18 03:54:58,273] Trial 17 finished with value: 39.0632879402758 and parameters: {'hidden_dim': 52, 'n_rnn_layers': 3, 'dropout': 0.1820181804025257}. Best is trial 1 with value: 24.651557677275907.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.30it/s][I 2025-08-18 03:55:50,338] Trial 18 finished with value: 23.632818834222437 and parameters: {'hidden_dim': 39, 'n_rnn_layers': 4, 'dropout': 0.42252264890543134}. Best is trial 18 with value: 23.632818834222437.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.49it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.68it/s][I 2025-08-18 03:56:29,089] Trial 19 finished with value: 31.73571444198077 and parameters: {'hidden_dim': 20, 'n_rnn_layers': 3, 'dropout': 0.4976708041574603}. Best is trial 18 with value: 23.632818834222437.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 44.0 K | train
6 | V               | Linear           | 40     | train
-------------------------------------------------------------
44.0 K    Trainable params
0         Non-trainable params
44.0 K    Total params
0.176     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 39, 'n_rnn_layers': 4, 'dropout': 0.42252264890543134}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 32.29it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 47.81it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/21 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s] Epoch 0:   5%|▍         | 1/21 [00:00<00:00, 24.56it/s]Epoch 0:   5%|▍         | 1/21 [00:00<00:01, 19.34it/s, train_loss=0.193]Epoch 0:  10%|▉         | 2/21 [00:00<00:00, 22.90it/s, train_loss=0.193]Epoch 0:  10%|▉         | 2/21 [00:00<00:00, 20.17it/s, train_loss=0.194]Epoch 0:  14%|█▍        | 3/21 [00:00<00:00, 18.57it/s, train_loss=0.194]Epoch 0:  14%|█▍        | 3/21 [00:00<00:01, 17.81it/s, train_loss=0.185]Epoch 0:  19%|█▉        | 4/21 [00:00<00:00, 18.68it/s, train_loss=0.185]Epoch 0:  19%|█▉        | 4/21 [00:00<00:00, 17.99it/s, train_loss=0.206]Epoch 0:  24%|██▍       | 5/21 [00:00<00:00, 17.51it/s, train_loss=0.206]Epoch 0:  24%|██▍       | 5/21 [00:00<00:00, 17.20it/s, train_loss=0.193]Epoch 0:  29%|██▊       | 6/21 [00:00<00:00, 17.59it/s, train_loss=0.193]Epoch 0:  29%|██▊       | 6/21 [00:00<00:00, 17.18it/s, train_loss=0.181]Epoch 0:  33%|███▎      | 7/21 [00:00<00:00, 16.72it/s, train_loss=0.181]Epoch 0:  33%|███▎      | 7/21 [00:00<00:00, 16.47it/s, train_loss=0.182]Epoch 0:  38%|███▊      | 8/21 [00:00<00:00, 16.76it/s, train_loss=0.182]Epoch 0:  38%|███▊      | 8/21 [00:00<00:00, 16.58it/s, train_loss=0.195]Epoch 0:  43%|████▎     | 9/21 [00:00<00:00, 16.93it/s, train_loss=0.195]Epoch 0:  43%|████▎     | 9/21 [00:00<00:00, 16.74it/s, train_loss=0.175]Epoch 0:  48%|████▊     | 10/21 [00:00<00:00, 16.73it/s, train_loss=0.175]Epoch 0:  48%|████▊     | 10/21 [00:00<00:00, 16.62it/s, train_loss=0.186]Epoch 0:  52%|█████▏    | 11/21 [00:00<00:00, 16.79it/s, train_loss=0.186]Epoch 0:  52%|█████▏    | 11/21 [00:00<00:00, 16.60it/s, train_loss=0.176]Epoch 0:  57%|█████▋    | 12/21 [00:00<00:00, 16.97it/s, train_loss=0.176]Epoch 0:  57%|█████▋    | 12/21 [00:00<00:00, 16.80it/s, train_loss=0.183]Epoch 0:  62%|██████▏   | 13/21 [00:00<00:00, 17.05it/s, train_loss=0.183]Epoch 0:  62%|██████▏   | 13/21 [00:00<00:00, 16.93it/s, train_loss=0.185]Epoch 0:  67%|██████▋   | 14/21 [00:00<00:00, 17.31it/s, train_loss=0.185]Epoch 0:  67%|██████▋   | 14/21 [00:00<00:00, 17.11it/s, train_loss=0.187]Epoch 0:  71%|███████▏  | 15/21 [00:00<00:00, 17.46it/s, train_loss=0.187]Epoch 0:  71%|███████▏  | 15/21 [00:00<00:00, 17.31it/s, train_loss=0.179]Epoch 0:  76%|███████▌  | 16/21 [00:00<00:00, 17.40it/s, train_loss=0.179]Epoch 0:  76%|███████▌  | 16/21 [00:00<00:00, 17.37it/s, train_loss=0.173]Epoch 0:  81%|████████  | 17/21 [00:00<00:00, 17.47it/s, train_loss=0.173]Epoch 0:  81%|████████  | 17/21 [00:00<00:00, 17.33it/s, train_loss=0.166]Epoch 0:  86%|████████▌ | 18/21 [00:01<00:00, 17.33it/s, train_loss=0.166]Epoch 0:  86%|████████▌ | 18/21 [00:01<00:00, 17.16it/s, train_loss=0.177]Epoch 0:  90%|█████████ | 19/21 [00:01<00:00, 17.42it/s, train_loss=0.177]Epoch 0:  90%|█████████ | 19/21 [00:01<00:00, 17.24it/s, train_loss=0.187]Epoch 0:  95%|█████████▌| 20/21 [00:01<00:00, 17.58it/s, train_loss=0.187]Epoch 0:  95%|█████████▌| 20/21 [00:01<00:00, 17.37it/s, train_loss=0.174]Epoch 0: 100%|██████████| 21/21 [00:01<00:00, 17.37it/s, train_loss=0.174]Epoch 0: 100%|██████████| 21/21 [00:01<00:00, 17.31it/s, train_loss=0.175]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 49.33it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 44.41it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 47.56it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 49.47it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 42.66it/s][A
                                                                      [AEpoch 0: 100%|██████████| 21/21 [00:01<00:00, 15.64it/s, train_loss=0.175, val_loss=0.138]Epoch 0: 100%|██████████| 21/21 [00:01<00:00, 15.62it/s, train_loss=0.175, val_loss=0.138]Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.175, val_loss=0.138]         Epoch 1:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.175, val_loss=0.138]Epoch 1:   5%|▍         | 1/21 [00:00<00:00, 20.33it/s, train_loss=0.175, val_loss=0.138]Epoch 1:   5%|▍         | 1/21 [00:00<00:01, 19.14it/s, train_loss=0.178, val_loss=0.138]Epoch 1:  10%|▉         | 2/21 [00:00<00:01, 18.16it/s, train_loss=0.178, val_loss=0.138]Epoch 1:  10%|▉         | 2/21 [00:00<00:01, 17.94it/s, train_loss=0.156, val_loss=0.138]Epoch 1:  14%|█▍        | 3/21 [00:00<00:00, 18.92it/s, train_loss=0.156, val_loss=0.138]Epoch 1:  14%|█▍        | 3/21 [00:00<00:00, 18.17it/s, train_loss=0.156, val_loss=0.138]Epoch 1:  19%|█▉        | 4/21 [00:00<00:00, 18.35it/s, train_loss=0.156, val_loss=0.138]Epoch 1:  19%|█▉        | 4/21 [00:00<00:00, 17.64it/s, train_loss=0.141, val_loss=0.138]Epoch 1:  24%|██▍       | 5/21 [00:00<00:00, 18.55it/s, train_loss=0.141, val_loss=0.138]Epoch 1:  24%|██▍       | 5/21 [00:00<00:00, 18.07it/s, train_loss=0.137, val_loss=0.138]Epoch 1:  29%|██▊       | 6/21 [00:00<00:00, 18.65it/s, train_loss=0.137, val_loss=0.138]Epoch 1:  29%|██▊       | 6/21 [00:00<00:00, 18.28it/s, train_loss=0.135, val_loss=0.138]Epoch 1:  33%|███▎      | 7/21 [00:00<00:00, 18.46it/s, train_loss=0.135, val_loss=0.138]Epoch 1:  33%|███▎      | 7/21 [00:00<00:00, 18.02it/s, train_loss=0.138, val_loss=0.138]Epoch 1:  38%|███▊      | 8/21 [00:00<00:00, 18.26it/s, train_loss=0.138, val_loss=0.138]Epoch 1:  38%|███▊      | 8/21 [00:00<00:00, 17.86it/s, train_loss=0.128, val_loss=0.138]Epoch 1:  43%|████▎     | 9/21 [00:00<00:00, 18.45it/s, train_loss=0.128, val_loss=0.138]Epoch 1:  43%|████▎     | 9/21 [00:00<00:00, 18.12it/s, train_loss=0.100, val_loss=0.138]Epoch 1:  48%|████▊     | 10/21 [00:00<00:00, 18.66it/s, train_loss=0.100, val_loss=0.138]Epoch 1:  48%|████▊     | 10/21 [00:00<00:00, 18.28it/s, train_loss=0.116, val_loss=0.138]Epoch 1:  52%|█████▏    | 11/21 [00:00<00:00, 18.51it/s, train_loss=0.116, val_loss=0.138]Epoch 1:  52%|█████▏    | 11/21 [00:00<00:00, 18.42it/s, train_loss=0.0927, val_loss=0.138]Epoch 1:  57%|█████▋    | 12/21 [00:00<00:00, 18.37it/s, train_loss=0.0927, val_loss=0.138]Epoch 1:  57%|█████▋    | 12/21 [00:00<00:00, 18.27it/s, train_loss=0.0928, val_loss=0.138]Epoch 1:  62%|██████▏   | 13/21 [00:00<00:00, 18.52it/s, train_loss=0.0928, val_loss=0.138]Epoch 1:  62%|██████▏   | 13/21 [00:00<00:00, 18.30it/s, train_loss=0.0891, val_loss=0.138]Epoch 1:  67%|██████▋   | 14/21 [00:00<00:00, 18.06it/s, train_loss=0.0891, val_loss=0.138]Epoch 1:  67%|██████▋   | 14/21 [00:00<00:00, 17.85it/s, train_loss=0.0727, val_loss=0.138]Epoch 1:  71%|███████▏  | 15/21 [00:00<00:00, 18.13it/s, train_loss=0.0727, val_loss=0.138]Epoch 1:  71%|███████▏  | 15/21 [00:00<00:00, 17.87it/s, train_loss=0.0687, val_loss=0.138]Epoch 1:  76%|███████▌  | 16/21 [00:00<00:00, 18.25it/s, train_loss=0.0687, val_loss=0.138]Epoch 1:  76%|███████▌  | 16/21 [00:00<00:00, 18.06it/s, train_loss=0.0662, val_loss=0.138]Epoch 1:  81%|████████  | 17/21 [00:00<00:00, 17.78it/s, train_loss=0.0662, val_loss=0.138]Epoch 1:  81%|████████  | 17/21 [00:00<00:00, 17.62it/s, train_loss=0.0651, val_loss=0.138]Epoch 1:  86%|████████▌ | 18/21 [00:01<00:00, 17.84it/s, train_loss=0.0651, val_loss=0.138]Epoch 1:  86%|████████▌ | 18/21 [00:01<00:00, 17.71it/s, train_loss=0.0634, val_loss=0.138]Epoch 1:  90%|█████████ | 19/21 [00:01<00:00, 17.79it/s, train_loss=0.0634, val_loss=0.138]Epoch 1:  90%|█████████ | 19/21 [00:01<00:00, 17.75it/s, train_loss=0.0545, val_loss=0.138]Epoch 1:  95%|█████████▌| 20/21 [00:01<00:00, 17.87it/s, train_loss=0.0545, val_loss=0.138]Epoch 1:  95%|█████████▌| 20/21 [00:01<00:00, 17.77it/s, train_loss=0.0561, val_loss=0.138]Epoch 1: 100%|██████████| 21/21 [00:01<00:00, 17.61it/s, train_loss=0.0561, val_loss=0.138]Epoch 1: 100%|██████████| 21/21 [00:01<00:00, 17.59it/s, train_loss=0.0407, val_loss=0.138]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 55.72it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 47.63it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 48.79it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 47.85it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 44.35it/s][A
                                                                      [AEpoch 1: 100%|██████████| 21/21 [00:01<00:00, 15.94it/s, train_loss=0.0407, val_loss=0.0325]Epoch 1: 100%|██████████| 21/21 [00:01<00:00, 15.92it/s, train_loss=0.0407, val_loss=0.0325]Epoch 1:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0407, val_loss=0.0325]         Epoch 2:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0407, val_loss=0.0325]Epoch 2:   5%|▍         | 1/21 [00:00<00:00, 21.31it/s, train_loss=0.0407, val_loss=0.0325]Epoch 2:   5%|▍         | 1/21 [00:00<00:01, 18.97it/s, train_loss=0.0398, val_loss=0.0325]Epoch 2:  10%|▉         | 2/21 [00:00<00:01, 18.44it/s, train_loss=0.0398, val_loss=0.0325]Epoch 2:  10%|▉         | 2/21 [00:00<00:01, 17.83it/s, train_loss=0.0354, val_loss=0.0325]Epoch 2:  14%|█▍        | 3/21 [00:00<00:00, 18.40it/s, train_loss=0.0354, val_loss=0.0325]Epoch 2:  14%|█▍        | 3/21 [00:00<00:01, 17.77it/s, train_loss=0.0263, val_loss=0.0325]Epoch 2:  19%|█▉        | 4/21 [00:00<00:00, 19.24it/s, train_loss=0.0263, val_loss=0.0325]Epoch 2:  19%|█▉        | 4/21 [00:00<00:00, 18.58it/s, train_loss=0.0254, val_loss=0.0325]Epoch 2:  24%|██▍       | 5/21 [00:00<00:00, 19.48it/s, train_loss=0.0254, val_loss=0.0325]Epoch 2:  24%|██▍       | 5/21 [00:00<00:00, 18.69it/s, train_loss=0.0244, val_loss=0.0325]Epoch 2:  29%|██▊       | 6/21 [00:00<00:00, 19.21it/s, train_loss=0.0244, val_loss=0.0325]Epoch 2:  29%|██▊       | 6/21 [00:00<00:00, 18.59it/s, train_loss=0.032, val_loss=0.0325] Epoch 2:  33%|███▎      | 7/21 [00:00<00:00, 18.31it/s, train_loss=0.032, val_loss=0.0325]Epoch 2:  33%|███▎      | 7/21 [00:00<00:00, 18.07it/s, train_loss=0.0351, val_loss=0.0325]Epoch 2:  38%|███▊      | 8/21 [00:00<00:00, 18.50it/s, train_loss=0.0351, val_loss=0.0325]Epoch 2:  38%|███▊      | 8/21 [00:00<00:00, 18.21it/s, train_loss=0.0411, val_loss=0.0325]Epoch 2:  43%|████▎     | 9/21 [00:00<00:00, 18.14it/s, train_loss=0.0411, val_loss=0.0325]Epoch 2:  43%|████▎     | 9/21 [00:00<00:00, 17.61it/s, train_loss=0.0405, val_loss=0.0325]Epoch 2:  48%|████▊     | 10/21 [00:00<00:00, 18.26it/s, train_loss=0.0405, val_loss=0.0325]Epoch 2:  48%|████▊     | 10/21 [00:00<00:00, 17.77it/s, train_loss=0.0348, val_loss=0.0325]Epoch 2:  52%|█████▏    | 11/21 [00:00<00:00, 18.44it/s, train_loss=0.0348, val_loss=0.0325]Epoch 2:  52%|█████▏    | 11/21 [00:00<00:00, 17.96it/s, train_loss=0.0329, val_loss=0.0325]Epoch 2:  57%|█████▋    | 12/21 [00:00<00:00, 17.75it/s, train_loss=0.0329, val_loss=0.0325]Epoch 2:  57%|█████▋    | 12/21 [00:00<00:00, 17.43it/s, train_loss=0.0265, val_loss=0.0325]Epoch 2:  62%|██████▏   | 13/21 [00:00<00:00, 17.63it/s, train_loss=0.0265, val_loss=0.0325]Epoch 2:  62%|██████▏   | 13/21 [00:00<00:00, 17.47it/s, train_loss=0.0252, val_loss=0.0325]Epoch 2:  67%|██████▋   | 14/21 [00:00<00:00, 17.39it/s, train_loss=0.0252, val_loss=0.0325]Epoch 2:  67%|██████▋   | 14/21 [00:00<00:00, 17.29it/s, train_loss=0.0253, val_loss=0.0325]Epoch 2:  71%|███████▏  | 15/21 [00:00<00:00, 17.46it/s, train_loss=0.0253, val_loss=0.0325]Epoch 2:  71%|███████▏  | 15/21 [00:00<00:00, 17.37it/s, train_loss=0.0261, val_loss=0.0325]Epoch 2:  76%|███████▌  | 16/21 [00:00<00:00, 17.30it/s, train_loss=0.0261, val_loss=0.0325]Epoch 2:  76%|███████▌  | 16/21 [00:00<00:00, 17.19it/s, train_loss=0.022, val_loss=0.0325] Epoch 2:  81%|████████  | 17/21 [00:00<00:00, 17.32it/s, train_loss=0.022, val_loss=0.0325]Epoch 2:  81%|████████  | 17/21 [00:00<00:00, 17.18it/s, train_loss=0.0211, val_loss=0.0325]Epoch 2:  86%|████████▌ | 18/21 [00:01<00:00, 17.32it/s, train_loss=0.0211, val_loss=0.0325]Epoch 2:  86%|████████▌ | 18/21 [00:01<00:00, 17.18it/s, train_loss=0.024, val_loss=0.0325] Epoch 2:  90%|█████████ | 19/21 [00:01<00:00, 17.11it/s, train_loss=0.024, val_loss=0.0325]Epoch 2:  90%|█████████ | 19/21 [00:01<00:00, 17.01it/s, train_loss=0.0284, val_loss=0.0325]Epoch 2:  95%|█████████▌| 20/21 [00:01<00:00, 17.19it/s, train_loss=0.0284, val_loss=0.0325]Epoch 2:  95%|█████████▌| 20/21 [00:01<00:00, 17.08it/s, train_loss=0.0299, val_loss=0.0325]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 21/21 [00:01<00:00, 17.26it/s, train_loss=0.0299, val_loss=0.0325]Epoch 2: 100%|██████████| 21/21 [00:01<00:00, 17.16it/s, train_loss=0.029, val_loss=0.0325] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 41.24it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 42.10it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 42.51it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 44.33it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 46.15it/s][A
                                                                      [AEpoch 2: 100%|██████████| 21/21 [00:01<00:00, 15.64it/s, train_loss=0.029, val_loss=0.0252]Epoch 2: 100%|██████████| 21/21 [00:01<00:00, 15.62it/s, train_loss=0.029, val_loss=0.0252]Epoch 2:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.029, val_loss=0.0252]         Epoch 3:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.029, val_loss=0.0252]Epoch 3:   5%|▍         | 1/21 [00:00<00:01, 19.73it/s, train_loss=0.029, val_loss=0.0252]Epoch 3:   5%|▍         | 1/21 [00:00<00:01, 18.50it/s, train_loss=0.0308, val_loss=0.0252]Epoch 3:  10%|▉         | 2/21 [00:00<00:01, 17.48it/s, train_loss=0.0308, val_loss=0.0252]Epoch 3:  10%|▉         | 2/21 [00:00<00:01, 16.87it/s, train_loss=0.0276, val_loss=0.0252]Epoch 3:  14%|█▍        | 3/21 [00:00<00:00, 18.48it/s, train_loss=0.0276, val_loss=0.0252]Epoch 3:  14%|█▍        | 3/21 [00:00<00:01, 17.14it/s, train_loss=0.0235, val_loss=0.0252]Epoch 3:  19%|█▉        | 4/21 [00:00<00:00, 17.08it/s, train_loss=0.0235, val_loss=0.0252]Epoch 3:  19%|█▉        | 4/21 [00:00<00:01, 16.28it/s, train_loss=0.0287, val_loss=0.0252]Epoch 3:  24%|██▍       | 5/21 [00:00<00:00, 17.75it/s, train_loss=0.0287, val_loss=0.0252]Epoch 3:  24%|██▍       | 5/21 [00:00<00:00, 16.92it/s, train_loss=0.0255, val_loss=0.0252]Epoch 3:  29%|██▊       | 6/21 [00:00<00:00, 17.24it/s, train_loss=0.0255, val_loss=0.0252]Epoch 3:  29%|██▊       | 6/21 [00:00<00:00, 17.05it/s, train_loss=0.0263, val_loss=0.0252]Epoch 3:  33%|███▎      | 7/21 [00:00<00:00, 17.02it/s, train_loss=0.0263, val_loss=0.0252]Epoch 3:  33%|███▎      | 7/21 [00:00<00:00, 16.71it/s, train_loss=0.0275, val_loss=0.0252]Epoch 3:  38%|███▊      | 8/21 [00:00<00:00, 17.15it/s, train_loss=0.0275, val_loss=0.0252]Epoch 3:  38%|███▊      | 8/21 [00:00<00:00, 16.90it/s, train_loss=0.0239, val_loss=0.0252]Epoch 3:  43%|████▎     | 9/21 [00:00<00:00, 16.89it/s, train_loss=0.0239, val_loss=0.0252]Epoch 3:  43%|████▎     | 9/21 [00:00<00:00, 16.74it/s, train_loss=0.0252, val_loss=0.0252]Epoch 3:  48%|████▊     | 10/21 [00:00<00:00, 17.15it/s, train_loss=0.0252, val_loss=0.0252]Epoch 3:  48%|████▊     | 10/21 [00:00<00:00, 16.95it/s, train_loss=0.022, val_loss=0.0252] Epoch 3:  52%|█████▏    | 11/21 [00:00<00:00, 17.08it/s, train_loss=0.022, val_loss=0.0252]Epoch 3:  52%|█████▏    | 11/21 [00:00<00:00, 16.92it/s, train_loss=0.0233, val_loss=0.0252]Epoch 3:  57%|█████▋    | 12/21 [00:00<00:00, 17.12it/s, train_loss=0.0233, val_loss=0.0252]Epoch 3:  57%|█████▋    | 12/21 [00:00<00:00, 16.87it/s, train_loss=0.0276, val_loss=0.0252]Epoch 3:  62%|██████▏   | 13/21 [00:00<00:00, 17.11it/s, train_loss=0.0276, val_loss=0.0252]Epoch 3:  62%|██████▏   | 13/21 [00:00<00:00, 17.03it/s, train_loss=0.0212, val_loss=0.0252]Epoch 3:  67%|██████▋   | 14/21 [00:00<00:00, 17.24it/s, train_loss=0.0212, val_loss=0.0252]Epoch 3:  67%|██████▋   | 14/21 [00:00<00:00, 17.08it/s, train_loss=0.0237, val_loss=0.0252]Epoch 3:  71%|███████▏  | 15/21 [00:00<00:00, 17.14it/s, train_loss=0.0237, val_loss=0.0252]Epoch 3:  71%|███████▏  | 15/21 [00:00<00:00, 16.95it/s, train_loss=0.0257, val_loss=0.0252]Epoch 3:  76%|███████▌  | 16/21 [00:00<00:00, 17.14it/s, train_loss=0.0257, val_loss=0.0252]Epoch 3:  76%|███████▌  | 16/21 [00:00<00:00, 16.99it/s, train_loss=0.0261, val_loss=0.0252]Epoch 3:  81%|████████  | 17/21 [00:00<00:00, 17.27it/s, train_loss=0.0261, val_loss=0.0252]Epoch 3:  81%|████████  | 17/21 [00:00<00:00, 17.14it/s, train_loss=0.0263, val_loss=0.0252]Epoch 3:  86%|████████▌ | 18/21 [00:01<00:00, 17.47it/s, train_loss=0.0263, val_loss=0.0252]Epoch 3:  86%|████████▌ | 18/21 [00:01<00:00, 17.28it/s, train_loss=0.0232, val_loss=0.0252]Epoch 3:  90%|█████████ | 19/21 [00:01<00:00, 17.22it/s, train_loss=0.0232, val_loss=0.0252]Epoch 3:  90%|█████████ | 19/21 [00:01<00:00, 17.18it/s, train_loss=0.0208, val_loss=0.0252]Epoch 3:  95%|█████████▌| 20/21 [00:01<00:00, 17.09it/s, train_loss=0.0208, val_loss=0.0252]Epoch 3:  95%|█████████▌| 20/21 [00:01<00:00, 17.02it/s, train_loss=0.0255, val_loss=0.0252]Epoch 3: 100%|██████████| 21/21 [00:01<00:00, 17.04it/s, train_loss=0.0255, val_loss=0.0252]Epoch 3: 100%|██████████| 21/21 [00:01<00:00, 17.00it/s, train_loss=0.0232, val_loss=0.0252]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 62.79it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 45.38it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 50.85it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 52.83it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 54.15it/s][A
                                                                      [AEpoch 3: 100%|██████████| 21/21 [00:01<00:00, 15.61it/s, train_loss=0.0232, val_loss=0.0278]Epoch 3: 100%|██████████| 21/21 [00:01<00:00, 15.60it/s, train_loss=0.0232, val_loss=0.0278]Epoch 3:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0232, val_loss=0.0278]         Epoch 4:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0232, val_loss=0.0278]Epoch 4:   5%|▍         | 1/21 [00:00<00:01, 17.43it/s, train_loss=0.0232, val_loss=0.0278]Epoch 4:   5%|▍         | 1/21 [00:00<00:01, 16.91it/s, train_loss=0.0262, val_loss=0.0278]Epoch 4:  10%|▉         | 2/21 [00:00<00:01, 18.36it/s, train_loss=0.0262, val_loss=0.0278]Epoch 4:  10%|▉         | 2/21 [00:00<00:01, 17.30it/s, train_loss=0.0236, val_loss=0.0278]Epoch 4:  14%|█▍        | 3/21 [00:00<00:00, 19.22it/s, train_loss=0.0236, val_loss=0.0278]Epoch 4:  14%|█▍        | 3/21 [00:00<00:00, 18.08it/s, train_loss=0.0252, val_loss=0.0278]Epoch 4:  19%|█▉        | 4/21 [00:00<00:00, 17.61it/s, train_loss=0.0252, val_loss=0.0278]Epoch 4:  19%|█▉        | 4/21 [00:00<00:00, 17.03it/s, train_loss=0.0231, val_loss=0.0278]Epoch 4:  24%|██▍       | 5/21 [00:00<00:00, 17.88it/s, train_loss=0.0231, val_loss=0.0278]Epoch 4:  24%|██▍       | 5/21 [00:00<00:00, 17.29it/s, train_loss=0.0233, val_loss=0.0278]Epoch 4:  29%|██▊       | 6/21 [00:00<00:00, 17.06it/s, train_loss=0.0233, val_loss=0.0278]Epoch 4:  29%|██▊       | 6/21 [00:00<00:00, 16.89it/s, train_loss=0.0251, val_loss=0.0278]Epoch 4:  33%|███▎      | 7/21 [00:00<00:00, 17.32it/s, train_loss=0.0251, val_loss=0.0278]Epoch 4:  33%|███▎      | 7/21 [00:00<00:00, 16.97it/s, train_loss=0.0219, val_loss=0.0278]Epoch 4:  38%|███▊      | 8/21 [00:00<00:00, 17.58it/s, train_loss=0.0219, val_loss=0.0278]Epoch 4:  38%|███▊      | 8/21 [00:00<00:00, 17.19it/s, train_loss=0.0252, val_loss=0.0278]Epoch 4:  43%|████▎     | 9/21 [00:00<00:00, 17.57it/s, train_loss=0.0252, val_loss=0.0278]Epoch 4:  43%|████▎     | 9/21 [00:00<00:00, 17.40it/s, train_loss=0.0257, val_loss=0.0278]Epoch 4:  48%|████▊     | 10/21 [00:00<00:00, 17.94it/s, train_loss=0.0257, val_loss=0.0278]Epoch 4:  48%|████▊     | 10/21 [00:00<00:00, 17.55it/s, train_loss=0.0251, val_loss=0.0278]Epoch 4:  52%|█████▏    | 11/21 [00:00<00:00, 17.68it/s, train_loss=0.0251, val_loss=0.0278]Epoch 4:  52%|█████▏    | 11/21 [00:00<00:00, 17.52it/s, train_loss=0.0227, val_loss=0.0278]Epoch 4:  57%|█████▋    | 12/21 [00:00<00:00, 17.83it/s, train_loss=0.0227, val_loss=0.0278]Epoch 4:  57%|█████▋    | 12/21 [00:00<00:00, 17.63it/s, train_loss=0.0243, val_loss=0.0278]Epoch 4:  62%|██████▏   | 13/21 [00:00<00:00, 17.93it/s, train_loss=0.0243, val_loss=0.0278]Epoch 4:  62%|██████▏   | 13/21 [00:00<00:00, 17.74it/s, train_loss=0.0279, val_loss=0.0278]Epoch 4:  67%|██████▋   | 14/21 [00:00<00:00, 17.90it/s, train_loss=0.0279, val_loss=0.0278]Epoch 4:  67%|██████▋   | 14/21 [00:00<00:00, 17.80it/s, train_loss=0.0218, val_loss=0.0278]Epoch 4:  71%|███████▏  | 15/21 [00:00<00:00, 17.83it/s, train_loss=0.0218, val_loss=0.0278]Epoch 4:  71%|███████▏  | 15/21 [00:00<00:00, 17.75it/s, train_loss=0.0268, val_loss=0.0278]Epoch 4:  76%|███████▌  | 16/21 [00:00<00:00, 17.92it/s, train_loss=0.0268, val_loss=0.0278]Epoch 4:  76%|███████▌  | 16/21 [00:00<00:00, 17.76it/s, train_loss=0.0222, val_loss=0.0278]Epoch 4:  81%|████████  | 17/21 [00:00<00:00, 17.70it/s, train_loss=0.0222, val_loss=0.0278]Epoch 4:  81%|████████  | 17/21 [00:00<00:00, 17.50it/s, train_loss=0.0249, val_loss=0.0278]Epoch 4:  86%|████████▌ | 18/21 [00:01<00:00, 17.78it/s, train_loss=0.0249, val_loss=0.0278]Epoch 4:  86%|████████▌ | 18/21 [00:01<00:00, 17.59it/s, train_loss=0.0264, val_loss=0.0278]Epoch 4:  90%|█████████ | 19/21 [00:01<00:00, 17.90it/s, train_loss=0.0264, val_loss=0.0278]Epoch 4:  90%|█████████ | 19/21 [00:01<00:00, 17.75it/s, train_loss=0.0187, val_loss=0.0278]Epoch 4:  95%|█████████▌| 20/21 [00:01<00:00, 18.03it/s, train_loss=0.0187, val_loss=0.0278]Epoch 4:  95%|█████████▌| 20/21 [00:01<00:00, 17.91it/s, train_loss=0.0191, val_loss=0.0278]Epoch 4: 100%|██████████| 21/21 [00:01<00:00, 17.80it/s, train_loss=0.0191, val_loss=0.0278]Epoch 4: 100%|██████████| 21/21 [00:01<00:00, 17.76it/s, train_loss=0.0259, val_loss=0.0278]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 47.46it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 45.70it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 43.29it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 43.42it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 42.01it/s][A
                                                                      [AEpoch 4: 100%|██████████| 21/21 [00:01<00:00, 15.88it/s, train_loss=0.0259, val_loss=0.0263]Epoch 4: 100%|██████████| 21/21 [00:01<00:00, 15.86it/s, train_loss=0.0259, val_loss=0.0263]Epoch 4:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0259, val_loss=0.0263]         Epoch 5:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0259, val_loss=0.0263]Epoch 5:   5%|▍         | 1/21 [00:00<00:00, 21.11it/s, train_loss=0.0259, val_loss=0.0263]Epoch 5:   5%|▍         | 1/21 [00:00<00:01, 18.26it/s, train_loss=0.0232, val_loss=0.0263]Epoch 5:  10%|▉         | 2/21 [00:00<00:01, 17.46it/s, train_loss=0.0232, val_loss=0.0263]Epoch 5:  10%|▉         | 2/21 [00:00<00:01, 16.63it/s, train_loss=0.0279, val_loss=0.0263]Epoch 5:  14%|█▍        | 3/21 [00:00<00:00, 18.06it/s, train_loss=0.0279, val_loss=0.0263]Epoch 5:  14%|█▍        | 3/21 [00:00<00:01, 17.49it/s, train_loss=0.0226, val_loss=0.0263]Epoch 5:  19%|█▉        | 4/21 [00:00<00:00, 18.40it/s, train_loss=0.0226, val_loss=0.0263]Epoch 5:  19%|█▉        | 4/21 [00:00<00:00, 17.93it/s, train_loss=0.0216, val_loss=0.0263]Epoch 5:  24%|██▍       | 5/21 [00:00<00:00, 18.31it/s, train_loss=0.0216, val_loss=0.0263]Epoch 5:  24%|██▍       | 5/21 [00:00<00:00, 18.01it/s, train_loss=0.0266, val_loss=0.0263]Epoch 5:  29%|██▊       | 6/21 [00:00<00:00, 18.12it/s, train_loss=0.0266, val_loss=0.0263]Epoch 5:  29%|██▊       | 6/21 [00:00<00:00, 17.79it/s, train_loss=0.0219, val_loss=0.0263]Epoch 5:  33%|███▎      | 7/21 [00:00<00:00, 18.18it/s, train_loss=0.0219, val_loss=0.0263]Epoch 5:  33%|███▎      | 7/21 [00:00<00:00, 17.88it/s, train_loss=0.0231, val_loss=0.0263]Epoch 5:  38%|███▊      | 8/21 [00:00<00:00, 18.40it/s, train_loss=0.0231, val_loss=0.0263]Epoch 5:  38%|███▊      | 8/21 [00:00<00:00, 18.02it/s, train_loss=0.0237, val_loss=0.0263]Epoch 5:  43%|████▎     | 9/21 [00:00<00:00, 18.42it/s, train_loss=0.0237, val_loss=0.0263]Epoch 5:  43%|████▎     | 9/21 [00:00<00:00, 18.14it/s, train_loss=0.0204, val_loss=0.0263]Epoch 5:  48%|████▊     | 10/21 [00:00<00:00, 18.26it/s, train_loss=0.0204, val_loss=0.0263]Epoch 5:  48%|████▊     | 10/21 [00:00<00:00, 18.01it/s, train_loss=0.0207, val_loss=0.0263]Epoch 5:  52%|█████▏    | 11/21 [00:00<00:00, 17.81it/s, train_loss=0.0207, val_loss=0.0263]Epoch 5:  52%|█████▏    | 11/21 [00:00<00:00, 17.67it/s, train_loss=0.0193, val_loss=0.0263]Epoch 5:  57%|█████▋    | 12/21 [00:00<00:00, 17.99it/s, train_loss=0.0193, val_loss=0.0263]Epoch 5:  57%|█████▋    | 12/21 [00:00<00:00, 17.77it/s, train_loss=0.0235, val_loss=0.0263]Epoch 5:  62%|██████▏   | 13/21 [00:00<00:00, 17.68it/s, train_loss=0.0235, val_loss=0.0263]Epoch 5:  62%|██████▏   | 13/21 [00:00<00:00, 17.38it/s, train_loss=0.0255, val_loss=0.0263]Epoch 5:  67%|██████▋   | 14/21 [00:00<00:00, 17.76it/s, train_loss=0.0255, val_loss=0.0263]Epoch 5:  67%|██████▋   | 14/21 [00:00<00:00, 17.52it/s, train_loss=0.0197, val_loss=0.0263]Epoch 5:  71%|███████▏  | 15/21 [00:00<00:00, 17.94it/s, train_loss=0.0197, val_loss=0.0263]Epoch 5:  71%|███████▏  | 15/21 [00:00<00:00, 17.68it/s, train_loss=0.0241, val_loss=0.0263]Epoch 5:  76%|███████▌  | 16/21 [00:00<00:00, 17.46it/s, train_loss=0.0241, val_loss=0.0263]Epoch 5:  76%|███████▌  | 16/21 [00:00<00:00, 17.34it/s, train_loss=0.0264, val_loss=0.0263]Epoch 5:  81%|████████  | 17/21 [00:00<00:00, 17.48it/s, train_loss=0.0264, val_loss=0.0263]Epoch 5:  81%|████████  | 17/21 [00:00<00:00, 17.44it/s, train_loss=0.024, val_loss=0.0263] Epoch 5:  86%|████████▌ | 18/21 [00:01<00:00, 17.35it/s, train_loss=0.024, val_loss=0.0263]Epoch 5:  86%|████████▌ | 18/21 [00:01<00:00, 17.27it/s, train_loss=0.026, val_loss=0.0263]Epoch 5:  90%|█████████ | 19/21 [00:01<00:00, 17.33it/s, train_loss=0.026, val_loss=0.0263]Epoch 5:  90%|█████████ | 19/21 [00:01<00:00, 17.18it/s, train_loss=0.0224, val_loss=0.0263]Epoch 5:  95%|█████████▌| 20/21 [00:01<00:00, 17.06it/s, train_loss=0.0224, val_loss=0.0263]Epoch 5:  95%|█████████▌| 20/21 [00:01<00:00, 16.99it/s, train_loss=0.0201, val_loss=0.0263]Epoch 5: 100%|██████████| 21/21 [00:01<00:00, 17.04it/s, train_loss=0.0201, val_loss=0.0263]Epoch 5: 100%|██████████| 21/21 [00:01<00:00, 17.02it/s, train_loss=0.0209, val_loss=0.0263]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 43.01it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 43.07it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 47.58it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 50.11it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 45.21it/s][A
                                                                      [AEpoch 5: 100%|██████████| 21/21 [00:01<00:00, 15.49it/s, train_loss=0.0209, val_loss=0.0237]Epoch 5: 100%|██████████| 21/21 [00:01<00:00, 15.48it/s, train_loss=0.0209, val_loss=0.0237]Epoch 5:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0209, val_loss=0.0237]         Epoch 6:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0209, val_loss=0.0237]Epoch 6:   5%|▍         | 1/21 [00:00<00:01, 18.03it/s, train_loss=0.0209, val_loss=0.0237]Epoch 6:   5%|▍         | 1/21 [00:00<00:01, 16.06it/s, train_loss=0.0227, val_loss=0.0237]Epoch 6:  10%|▉         | 2/21 [00:00<00:01, 18.33it/s, train_loss=0.0227, val_loss=0.0237]Epoch 6:  10%|▉         | 2/21 [00:00<00:01, 16.83it/s, train_loss=0.0238, val_loss=0.0237]Epoch 6:  14%|█▍        | 3/21 [00:00<00:00, 18.26it/s, train_loss=0.0238, val_loss=0.0237]Epoch 6:  14%|█▍        | 3/21 [00:00<00:01, 17.47it/s, train_loss=0.0215, val_loss=0.0237]Epoch 6:  19%|█▉        | 4/21 [00:00<00:00, 18.09it/s, train_loss=0.0215, val_loss=0.0237]Epoch 6:  19%|█▉        | 4/21 [00:00<00:00, 17.33it/s, train_loss=0.0196, val_loss=0.0237]Epoch 6:  24%|██▍       | 5/21 [00:00<00:00, 16.91it/s, train_loss=0.0196, val_loss=0.0237]Epoch 6:  24%|██▍       | 5/21 [00:00<00:00, 16.63it/s, train_loss=0.0212, val_loss=0.0237]Epoch 6:  29%|██▊       | 6/21 [00:00<00:00, 17.15it/s, train_loss=0.0212, val_loss=0.0237]Epoch 6:  29%|██▊       | 6/21 [00:00<00:00, 17.00it/s, train_loss=0.0203, val_loss=0.0237]Epoch 6:  33%|███▎      | 7/21 [00:00<00:00, 18.15it/s, train_loss=0.0203, val_loss=0.0237]Epoch 6:  33%|███▎      | 7/21 [00:00<00:00, 17.39it/s, train_loss=0.0203, val_loss=0.0237]Epoch 6:  38%|███▊      | 8/21 [00:00<00:00, 17.10it/s, train_loss=0.0203, val_loss=0.0237]Epoch 6:  38%|███▊      | 8/21 [00:00<00:00, 16.88it/s, train_loss=0.018, val_loss=0.0237] Epoch 6:  43%|████▎     | 9/21 [00:00<00:00, 17.57it/s, train_loss=0.018, val_loss=0.0237]Epoch 6:  43%|████▎     | 9/21 [00:00<00:00, 17.24it/s, train_loss=0.0245, val_loss=0.0237]Epoch 6:  48%|████▊     | 10/21 [00:00<00:00, 17.36it/s, train_loss=0.0245, val_loss=0.0237]Epoch 6:  48%|████▊     | 10/21 [00:00<00:00, 17.22it/s, train_loss=0.0187, val_loss=0.0237]Epoch 6:  52%|█████▏    | 11/21 [00:00<00:00, 17.59it/s, train_loss=0.0187, val_loss=0.0237]Epoch 6:  52%|█████▏    | 11/21 [00:00<00:00, 17.35it/s, train_loss=0.0176, val_loss=0.0237]Epoch 6:  57%|█████▋    | 12/21 [00:00<00:00, 17.57it/s, train_loss=0.0176, val_loss=0.0237]Epoch 6:  57%|█████▋    | 12/21 [00:00<00:00, 17.38it/s, train_loss=0.0185, val_loss=0.0237]Epoch 6:  62%|██████▏   | 13/21 [00:00<00:00, 17.28it/s, train_loss=0.0185, val_loss=0.0237]Epoch 6:  62%|██████▏   | 13/21 [00:00<00:00, 17.16it/s, train_loss=0.0203, val_loss=0.0237]Epoch 6:  67%|██████▋   | 14/21 [00:00<00:00, 17.37it/s, train_loss=0.0203, val_loss=0.0237]Epoch 6:  67%|██████▋   | 14/21 [00:00<00:00, 17.22it/s, train_loss=0.0193, val_loss=0.0237]Epoch 6:  71%|███████▏  | 15/21 [00:00<00:00, 17.18it/s, train_loss=0.0193, val_loss=0.0237]Epoch 6:  71%|███████▏  | 15/21 [00:00<00:00, 17.08it/s, train_loss=0.0168, val_loss=0.0237]Epoch 6:  76%|███████▌  | 16/21 [00:00<00:00, 17.20it/s, train_loss=0.0168, val_loss=0.0237]Epoch 6:  76%|███████▌  | 16/21 [00:00<00:00, 17.07it/s, train_loss=0.0197, val_loss=0.0237]Epoch 6:  81%|████████  | 17/21 [00:00<00:00, 17.37it/s, train_loss=0.0197, val_loss=0.0237]Epoch 6:  81%|████████  | 17/21 [00:00<00:00, 17.18it/s, train_loss=0.0174, val_loss=0.0237]Epoch 6:  86%|████████▌ | 18/21 [00:01<00:00, 17.21it/s, train_loss=0.0174, val_loss=0.0237]Epoch 6:  86%|████████▌ | 18/21 [00:01<00:00, 17.13it/s, train_loss=0.017, val_loss=0.0237] Epoch 6:  90%|█████████ | 19/21 [00:01<00:00, 17.14it/s, train_loss=0.017, val_loss=0.0237]Epoch 6:  90%|█████████ | 19/21 [00:01<00:00, 17.08it/s, train_loss=0.0159, val_loss=0.0237]Epoch 6:  95%|█████████▌| 20/21 [00:01<00:00, 17.31it/s, train_loss=0.0159, val_loss=0.0237]Epoch 6:  95%|█████████▌| 20/21 [00:01<00:00, 17.15it/s, train_loss=0.0173, val_loss=0.0237]Epoch 6: 100%|██████████| 21/21 [00:01<00:00, 17.37it/s, train_loss=0.0173, val_loss=0.0237]Epoch 6: 100%|██████████| 21/21 [00:01<00:00, 17.30it/s, train_loss=0.0137, val_loss=0.0237]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 37.85it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 43.16it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 45.48it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 47.42it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 47.26it/s][A
                                                                      [AEpoch 6: 100%|██████████| 21/21 [00:01<00:00, 15.74it/s, train_loss=0.0137, val_loss=0.0137]Epoch 6: 100%|██████████| 21/21 [00:01<00:00, 15.71it/s, train_loss=0.0137, val_loss=0.0137]Epoch 6:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0137, val_loss=0.0137]         Epoch 7:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0137, val_loss=0.0137]Epoch 7:   5%|▍         | 1/21 [00:00<00:01, 15.48it/s, train_loss=0.0137, val_loss=0.0137]Epoch 7:   5%|▍         | 1/21 [00:00<00:01, 13.87it/s, train_loss=0.0192, val_loss=0.0137]Epoch 7:  10%|▉         | 2/21 [00:00<00:01, 15.01it/s, train_loss=0.0192, val_loss=0.0137]Epoch 7:  10%|▉         | 2/21 [00:00<00:01, 14.36it/s, train_loss=0.0163, val_loss=0.0137]Epoch 7:  14%|█▍        | 3/21 [00:00<00:01, 16.48it/s, train_loss=0.0163, val_loss=0.0137]Epoch 7:  14%|█▍        | 3/21 [00:00<00:01, 15.65it/s, train_loss=0.0172, val_loss=0.0137]Epoch 7:  19%|█▉        | 4/21 [00:00<00:00, 17.70it/s, train_loss=0.0172, val_loss=0.0137]Epoch 7:  19%|█▉        | 4/21 [00:00<00:01, 16.61it/s, train_loss=0.0145, val_loss=0.0137]Epoch 7:  24%|██▍       | 5/21 [00:00<00:01, 15.52it/s, train_loss=0.0145, val_loss=0.0137]Epoch 7:  24%|██▍       | 5/21 [00:00<00:01, 15.32it/s, train_loss=0.0157, val_loss=0.0137]Epoch 7:  29%|██▊       | 6/21 [00:00<00:00, 16.07it/s, train_loss=0.0157, val_loss=0.0137]Epoch 7:  29%|██▊       | 6/21 [00:00<00:00, 15.80it/s, train_loss=0.0155, val_loss=0.0137]Epoch 7:  33%|███▎      | 7/21 [00:00<00:00, 16.00it/s, train_loss=0.0155, val_loss=0.0137]Epoch 7:  33%|███▎      | 7/21 [00:00<00:00, 15.86it/s, train_loss=0.0137, val_loss=0.0137]Epoch 7:  38%|███▊      | 8/21 [00:00<00:00, 16.22it/s, train_loss=0.0137, val_loss=0.0137]Epoch 7:  38%|███▊      | 8/21 [00:00<00:00, 16.04it/s, train_loss=0.0138, val_loss=0.0137]Epoch 7:  43%|████▎     | 9/21 [00:00<00:00, 16.15it/s, train_loss=0.0138, val_loss=0.0137]Epoch 7:  43%|████▎     | 9/21 [00:00<00:00, 16.09it/s, train_loss=0.0162, val_loss=0.0137]Epoch 7:  48%|████▊     | 10/21 [00:00<00:00, 16.39it/s, train_loss=0.0162, val_loss=0.0137]Epoch 7:  48%|████▊     | 10/21 [00:00<00:00, 16.26it/s, train_loss=0.0143, val_loss=0.0137]Epoch 7:  52%|█████▏    | 11/21 [00:00<00:00, 16.64it/s, train_loss=0.0143, val_loss=0.0137]Epoch 7:  52%|█████▏    | 11/21 [00:00<00:00, 16.46it/s, train_loss=0.0152, val_loss=0.0137]Epoch 7:  57%|█████▋    | 12/21 [00:00<00:00, 16.75it/s, train_loss=0.0152, val_loss=0.0137]Epoch 7:  57%|█████▋    | 12/21 [00:00<00:00, 16.63it/s, train_loss=0.014, val_loss=0.0137] Epoch 7:  62%|██████▏   | 13/21 [00:00<00:00, 16.80it/s, train_loss=0.014, val_loss=0.0137]Epoch 7:  62%|██████▏   | 13/21 [00:00<00:00, 16.65it/s, train_loss=0.0137, val_loss=0.0137]Epoch 7:  67%|██████▋   | 14/21 [00:00<00:00, 16.61it/s, train_loss=0.0137, val_loss=0.0137]Epoch 7:  67%|██████▋   | 14/21 [00:00<00:00, 16.46it/s, train_loss=0.0141, val_loss=0.0137]Epoch 7:  71%|███████▏  | 15/21 [00:00<00:00, 16.73it/s, train_loss=0.0141, val_loss=0.0137]Epoch 7:  71%|███████▏  | 15/21 [00:00<00:00, 16.57it/s, train_loss=0.0142, val_loss=0.0137]Epoch 7:  76%|███████▌  | 16/21 [00:00<00:00, 16.83it/s, train_loss=0.0142, val_loss=0.0137]Epoch 7:  76%|███████▌  | 16/21 [00:00<00:00, 16.73it/s, train_loss=0.0125, val_loss=0.0137]Epoch 7:  81%|████████  | 17/21 [00:01<00:00, 16.98it/s, train_loss=0.0125, val_loss=0.0137]Epoch 7:  81%|████████  | 17/21 [00:01<00:00, 16.87it/s, train_loss=0.0131, val_loss=0.0137]Epoch 7:  86%|████████▌ | 18/21 [00:01<00:00, 16.99it/s, train_loss=0.0131, val_loss=0.0137]Epoch 7:  86%|████████▌ | 18/21 [00:01<00:00, 16.94it/s, train_loss=0.0116, val_loss=0.0137]Epoch 7:  90%|█████████ | 19/21 [00:01<00:00, 17.00it/s, train_loss=0.0116, val_loss=0.0137]Epoch 7:  90%|█████████ | 19/21 [00:01<00:00, 16.94it/s, train_loss=0.012, val_loss=0.0137] Epoch 7:  95%|█████████▌| 20/21 [00:01<00:00, 17.25it/s, train_loss=0.012, val_loss=0.0137]Epoch 7:  95%|█████████▌| 20/21 [00:01<00:00, 17.04it/s, train_loss=0.0126, val_loss=0.0137]Epoch 7: 100%|██████████| 21/21 [00:01<00:00, 17.02it/s, train_loss=0.0126, val_loss=0.0137]Epoch 7: 100%|██████████| 21/21 [00:01<00:00, 16.97it/s, train_loss=0.0112, val_loss=0.0137]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 60.99it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 55.73it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 61.97it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 54.95it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 55.71it/s][A
                                                                      [AEpoch 7: 100%|██████████| 21/21 [00:01<00:00, 15.69it/s, train_loss=0.0112, val_loss=0.0115]Epoch 7: 100%|██████████| 21/21 [00:01<00:00, 15.67it/s, train_loss=0.0112, val_loss=0.0115]Epoch 7:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0112, val_loss=0.0115]         Epoch 8:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0112, val_loss=0.0115]Epoch 8:   5%|▍         | 1/21 [00:00<00:01, 14.79it/s, train_loss=0.0112, val_loss=0.0115]Epoch 8:   5%|▍         | 1/21 [00:00<00:01, 12.65it/s, train_loss=0.0117, val_loss=0.0115]Epoch 8:  10%|▉         | 2/21 [00:00<00:01, 15.51it/s, train_loss=0.0117, val_loss=0.0115]Epoch 8:  10%|▉         | 2/21 [00:00<00:01, 14.84it/s, train_loss=0.0115, val_loss=0.0115]Epoch 8:  14%|█▍        | 3/21 [00:00<00:01, 16.47it/s, train_loss=0.0115, val_loss=0.0115]Epoch 8:  14%|█▍        | 3/21 [00:00<00:01, 15.55it/s, train_loss=0.0111, val_loss=0.0115]Epoch 8:  19%|█▉        | 4/21 [00:00<00:01, 15.62it/s, train_loss=0.0111, val_loss=0.0115]Epoch 8:  19%|█▉        | 4/21 [00:00<00:01, 15.36it/s, train_loss=0.0124, val_loss=0.0115]Epoch 8:  24%|██▍       | 5/21 [00:00<00:00, 16.83it/s, train_loss=0.0124, val_loss=0.0115]Epoch 8:  24%|██▍       | 5/21 [00:00<00:00, 16.38it/s, train_loss=0.0114, val_loss=0.0115]Epoch 8:  29%|██▊       | 6/21 [00:00<00:00, 16.93it/s, train_loss=0.0114, val_loss=0.0115]Epoch 8:  29%|██▊       | 6/21 [00:00<00:00, 16.74it/s, train_loss=0.0115, val_loss=0.0115]Epoch 8:  33%|███▎      | 7/21 [00:00<00:00, 17.26it/s, train_loss=0.0115, val_loss=0.0115]Epoch 8:  33%|███▎      | 7/21 [00:00<00:00, 17.01it/s, train_loss=0.0119, val_loss=0.0115]Epoch 8:  38%|███▊      | 8/21 [00:00<00:00, 17.44it/s, train_loss=0.0119, val_loss=0.0115]Epoch 8:  38%|███▊      | 8/21 [00:00<00:00, 17.26it/s, train_loss=0.0114, val_loss=0.0115]Epoch 8:  43%|████▎     | 9/21 [00:00<00:00, 17.67it/s, train_loss=0.0114, val_loss=0.0115]Epoch 8:  43%|████▎     | 9/21 [00:00<00:00, 17.15it/s, train_loss=0.0101, val_loss=0.0115]Epoch 8:  48%|████▊     | 10/21 [00:00<00:00, 17.08it/s, train_loss=0.0101, val_loss=0.0115]Epoch 8:  48%|████▊     | 10/21 [00:00<00:00, 16.89it/s, train_loss=0.011, val_loss=0.0115] Epoch 8:  52%|█████▏    | 11/21 [00:00<00:00, 17.36it/s, train_loss=0.011, val_loss=0.0115]Epoch 8:  52%|█████▏    | 11/21 [00:00<00:00, 16.95it/s, train_loss=0.00968, val_loss=0.0115]Epoch 8:  57%|█████▋    | 12/21 [00:00<00:00, 17.25it/s, train_loss=0.00968, val_loss=0.0115]Epoch 8:  57%|█████▋    | 12/21 [00:00<00:00, 17.09it/s, train_loss=0.0114, val_loss=0.0115] Epoch 8:  62%|██████▏   | 13/21 [00:00<00:00, 17.04it/s, train_loss=0.0114, val_loss=0.0115]Epoch 8:  62%|██████▏   | 13/21 [00:00<00:00, 16.87it/s, train_loss=0.0116, val_loss=0.0115]Epoch 8:  67%|██████▋   | 14/21 [00:00<00:00, 17.18it/s, train_loss=0.0116, val_loss=0.0115]Epoch 8:  67%|██████▋   | 14/21 [00:00<00:00, 17.07it/s, train_loss=0.0103, val_loss=0.0115]Epoch 8:  71%|███████▏  | 15/21 [00:00<00:00, 17.22it/s, train_loss=0.0103, val_loss=0.0115]Epoch 8:  71%|███████▏  | 15/21 [00:00<00:00, 17.12it/s, train_loss=0.0101, val_loss=0.0115]Epoch 8:  76%|███████▌  | 16/21 [00:00<00:00, 17.36it/s, train_loss=0.0101, val_loss=0.0115]Epoch 8:  76%|███████▌  | 16/21 [00:00<00:00, 17.24it/s, train_loss=0.0105, val_loss=0.0115]Epoch 8:  81%|████████  | 17/21 [00:00<00:00, 17.64it/s, train_loss=0.0105, val_loss=0.0115]Epoch 8:  81%|████████  | 17/21 [00:00<00:00, 17.38it/s, train_loss=0.0103, val_loss=0.0115]Epoch 8:  86%|████████▌ | 18/21 [00:01<00:00, 17.36it/s, train_loss=0.0103, val_loss=0.0115]Epoch 8:  86%|████████▌ | 18/21 [00:01<00:00, 17.24it/s, train_loss=0.0115, val_loss=0.0115]Epoch 8:  90%|█████████ | 19/21 [00:01<00:00, 17.24it/s, train_loss=0.0115, val_loss=0.0115]Epoch 8:  90%|█████████ | 19/21 [00:01<00:00, 17.18it/s, train_loss=0.0104, val_loss=0.0115]Epoch 8:  95%|█████████▌| 20/21 [00:01<00:00, 17.41it/s, train_loss=0.0104, val_loss=0.0115]Epoch 8:  95%|█████████▌| 20/21 [00:01<00:00, 17.28it/s, train_loss=0.0102, val_loss=0.0115]Epoch 8: 100%|██████████| 21/21 [00:01<00:00, 17.47it/s, train_loss=0.0102, val_loss=0.0115]Epoch 8: 100%|██████████| 21/21 [00:01<00:00, 17.42it/s, train_loss=0.0086, val_loss=0.0115]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 40.23it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 41.30it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 41.42it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 41.49it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 41.73it/s][A
                                                                      [AEpoch 8: 100%|██████████| 21/21 [00:01<00:00, 15.57it/s, train_loss=0.0086, val_loss=0.00903]Epoch 8: 100%|██████████| 21/21 [00:01<00:00, 15.55it/s, train_loss=0.0086, val_loss=0.00903]Epoch 8:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0086, val_loss=0.00903]         Epoch 9:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0086, val_loss=0.00903]Epoch 9:   5%|▍         | 1/21 [00:00<00:00, 25.65it/s, train_loss=0.0086, val_loss=0.00903]Epoch 9:   5%|▍         | 1/21 [00:00<00:00, 20.71it/s, train_loss=0.0097, val_loss=0.00903]Epoch 9:  10%|▉         | 2/21 [00:00<00:00, 20.55it/s, train_loss=0.0097, val_loss=0.00903]Epoch 9:  10%|▉         | 2/21 [00:00<00:00, 19.91it/s, train_loss=0.00937, val_loss=0.00903]Epoch 9:  14%|█▍        | 3/21 [00:00<00:00, 19.88it/s, train_loss=0.00937, val_loss=0.00903]Epoch 9:  14%|█▍        | 3/21 [00:00<00:00, 18.93it/s, train_loss=0.0106, val_loss=0.00903] Epoch 9:  19%|█▉        | 4/21 [00:00<00:00, 18.99it/s, train_loss=0.0106, val_loss=0.00903]Epoch 9:  19%|█▉        | 4/21 [00:00<00:00, 18.49it/s, train_loss=0.00971, val_loss=0.00903]Epoch 9:  24%|██▍       | 5/21 [00:00<00:00, 18.68it/s, train_loss=0.00971, val_loss=0.00903]Epoch 9:  24%|██▍       | 5/21 [00:00<00:00, 18.05it/s, train_loss=0.00975, val_loss=0.00903]Epoch 9:  29%|██▊       | 6/21 [00:00<00:00, 18.65it/s, train_loss=0.00975, val_loss=0.00903]Epoch 9:  29%|██▊       | 6/21 [00:00<00:00, 18.29it/s, train_loss=0.0103, val_loss=0.00903] Epoch 9:  33%|███▎      | 7/21 [00:00<00:00, 18.50it/s, train_loss=0.0103, val_loss=0.00903]Epoch 9:  33%|███▎      | 7/21 [00:00<00:00, 18.28it/s, train_loss=0.00976, val_loss=0.00903]Epoch 9:  38%|███▊      | 8/21 [00:00<00:00, 18.81it/s, train_loss=0.00976, val_loss=0.00903]Epoch 9:  38%|███▊      | 8/21 [00:00<00:00, 18.48it/s, train_loss=0.0103, val_loss=0.00903] Epoch 9:  43%|████▎     | 9/21 [00:00<00:00, 18.96it/s, train_loss=0.0103, val_loss=0.00903]Epoch 9:  43%|████▎     | 9/21 [00:00<00:00, 18.58it/s, train_loss=0.00992, val_loss=0.00903]Epoch 9:  48%|████▊     | 10/21 [00:00<00:00, 18.63it/s, train_loss=0.00992, val_loss=0.00903]Epoch 9:  48%|████▊     | 10/21 [00:00<00:00, 18.29it/s, train_loss=0.00993, val_loss=0.00903]Epoch 9:  52%|█████▏    | 11/21 [00:00<00:00, 18.73it/s, train_loss=0.00993, val_loss=0.00903]Epoch 9:  52%|█████▏    | 11/21 [00:00<00:00, 18.46it/s, train_loss=0.00925, val_loss=0.00903]Epoch 9:  57%|█████▋    | 12/21 [00:00<00:00, 18.52it/s, train_loss=0.00925, val_loss=0.00903]Epoch 9:  57%|█████▋    | 12/21 [00:00<00:00, 18.45it/s, train_loss=0.00922, val_loss=0.00903]Epoch 9:  62%|██████▏   | 13/21 [00:00<00:00, 18.82it/s, train_loss=0.00922, val_loss=0.00903]Epoch 9:  62%|██████▏   | 13/21 [00:00<00:00, 18.41it/s, train_loss=0.00917, val_loss=0.00903]Epoch 9:  67%|██████▋   | 14/21 [00:00<00:00, 18.51it/s, train_loss=0.00917, val_loss=0.00903]Epoch 9:  67%|██████▋   | 14/21 [00:00<00:00, 18.35it/s, train_loss=0.00946, val_loss=0.00903]Epoch 9:  71%|███████▏  | 15/21 [00:00<00:00, 18.46it/s, train_loss=0.00946, val_loss=0.00903]Epoch 9:  71%|███████▏  | 15/21 [00:00<00:00, 18.30it/s, train_loss=0.00906, val_loss=0.00903]Epoch 9:  76%|███████▌  | 16/21 [00:00<00:00, 18.49it/s, train_loss=0.00906, val_loss=0.00903]Epoch 9:  76%|███████▌  | 16/21 [00:00<00:00, 18.32it/s, train_loss=0.00874, val_loss=0.00903]Epoch 9:  81%|████████  | 17/21 [00:00<00:00, 18.26it/s, train_loss=0.00874, val_loss=0.00903]Epoch 9:  81%|████████  | 17/21 [00:00<00:00, 18.11it/s, train_loss=0.00952, val_loss=0.00903]Epoch 9:  86%|████████▌ | 18/21 [00:00<00:00, 18.24it/s, train_loss=0.00952, val_loss=0.00903]Epoch 9:  86%|████████▌ | 18/21 [00:00<00:00, 18.14it/s, train_loss=0.00807, val_loss=0.00903]Epoch 9:  90%|█████████ | 19/21 [00:01<00:00, 18.17it/s, train_loss=0.00807, val_loss=0.00903]Epoch 9:  90%|█████████ | 19/21 [00:01<00:00, 18.01it/s, train_loss=0.00901, val_loss=0.00903]Epoch 9:  95%|█████████▌| 20/21 [00:01<00:00, 18.07it/s, train_loss=0.00901, val_loss=0.00903]Epoch 9:  95%|█████████▌| 20/21 [00:01<00:00, 17.97it/s, train_loss=0.00825, val_loss=0.00903]Epoch 9: 100%|██████████| 21/21 [00:01<00:00, 18.06it/s, train_loss=0.00825, val_loss=0.00903]Epoch 9: 100%|██████████| 21/21 [00:01<00:00, 18.00it/s, train_loss=0.00784, val_loss=0.00903]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 44.41it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 44.20it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 42.28it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 41.47it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 42.17it/s][A
                                                                      [AEpoch 9: 100%|██████████| 21/21 [00:01<00:00, 16.18it/s, train_loss=0.00784, val_loss=0.00778]Epoch 9: 100%|██████████| 21/21 [00:01<00:00, 16.17it/s, train_loss=0.00784, val_loss=0.00778]Epoch 9:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00784, val_loss=0.00778]         Epoch 10:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00784, val_loss=0.00778]Epoch 10:   5%|▍         | 1/21 [00:00<00:00, 22.47it/s, train_loss=0.00784, val_loss=0.00778]Epoch 10:   5%|▍         | 1/21 [00:00<00:01, 19.39it/s, train_loss=0.00967, val_loss=0.00778]Epoch 10:  10%|▉         | 2/21 [00:00<00:00, 19.03it/s, train_loss=0.00967, val_loss=0.00778]Epoch 10:  10%|▉         | 2/21 [00:00<00:01, 17.77it/s, train_loss=0.00863, val_loss=0.00778]Epoch 10:  14%|█▍        | 3/21 [00:00<00:00, 19.22it/s, train_loss=0.00863, val_loss=0.00778]Epoch 10:  14%|█▍        | 3/21 [00:00<00:00, 18.49it/s, train_loss=0.00782, val_loss=0.00778]Epoch 10:  19%|█▉        | 4/21 [00:00<00:00, 18.62it/s, train_loss=0.00782, val_loss=0.00778]Epoch 10:  19%|█▉        | 4/21 [00:00<00:00, 18.18it/s, train_loss=0.00847, val_loss=0.00778]Epoch 10:  24%|██▍       | 5/21 [00:00<00:00, 18.80it/s, train_loss=0.00847, val_loss=0.00778]Epoch 10:  24%|██▍       | 5/21 [00:00<00:00, 18.42it/s, train_loss=0.00845, val_loss=0.00778]Epoch 10:  29%|██▊       | 6/21 [00:00<00:00, 18.74it/s, train_loss=0.00845, val_loss=0.00778]Epoch 10:  29%|██▊       | 6/21 [00:00<00:00, 18.30it/s, train_loss=0.00929, val_loss=0.00778]Epoch 10:  33%|███▎      | 7/21 [00:00<00:00, 18.78it/s, train_loss=0.00929, val_loss=0.00778]Epoch 10:  33%|███▎      | 7/21 [00:00<00:00, 18.13it/s, train_loss=0.00837, val_loss=0.00778]Epoch 10:  38%|███▊      | 8/21 [00:00<00:00, 18.54it/s, train_loss=0.00837, val_loss=0.00778]Epoch 10:  38%|███▊      | 8/21 [00:00<00:00, 18.33it/s, train_loss=0.00875, val_loss=0.00778]Epoch 10:  43%|████▎     | 9/21 [00:00<00:00, 18.59it/s, train_loss=0.00875, val_loss=0.00778]Epoch 10:  43%|████▎     | 9/21 [00:00<00:00, 18.37it/s, train_loss=0.00879, val_loss=0.00778]Epoch 10:  48%|████▊     | 10/21 [00:00<00:00, 18.57it/s, train_loss=0.00879, val_loss=0.00778]Epoch 10:  48%|████▊     | 10/21 [00:00<00:00, 18.35it/s, train_loss=0.00838, val_loss=0.00778]Epoch 10:  52%|█████▏    | 11/21 [00:00<00:00, 18.13it/s, train_loss=0.00838, val_loss=0.00778]Epoch 10:  52%|█████▏    | 11/21 [00:00<00:00, 17.99it/s, train_loss=0.00891, val_loss=0.00778]Epoch 10:  57%|█████▋    | 12/21 [00:00<00:00, 18.58it/s, train_loss=0.00891, val_loss=0.00778]Epoch 10:  57%|█████▋    | 12/21 [00:00<00:00, 18.22it/s, train_loss=0.00836, val_loss=0.00778]Epoch 10:  62%|██████▏   | 13/21 [00:00<00:00, 18.28it/s, train_loss=0.00836, val_loss=0.00778]Epoch 10:  62%|██████▏   | 13/21 [00:00<00:00, 18.10it/s, train_loss=0.00775, val_loss=0.00778]Epoch 10:  67%|██████▋   | 14/21 [00:00<00:00, 18.36it/s, train_loss=0.00775, val_loss=0.00778]Epoch 10:  67%|██████▋   | 14/21 [00:00<00:00, 18.22it/s, train_loss=0.00733, val_loss=0.00778]Epoch 10:  71%|███████▏  | 15/21 [00:00<00:00, 18.30it/s, train_loss=0.00733, val_loss=0.00778]Epoch 10:  71%|███████▏  | 15/21 [00:00<00:00, 18.24it/s, train_loss=0.00799, val_loss=0.00778]Epoch 10:  76%|███████▌  | 16/21 [00:00<00:00, 18.51it/s, train_loss=0.00799, val_loss=0.00778]Epoch 10:  76%|███████▌  | 16/21 [00:00<00:00, 18.24it/s, train_loss=0.00741, val_loss=0.00778]Epoch 10:  81%|████████  | 17/21 [00:00<00:00, 18.27it/s, train_loss=0.00741, val_loss=0.00778]Epoch 10:  81%|████████  | 17/21 [00:00<00:00, 18.15it/s, train_loss=0.00755, val_loss=0.00778]Epoch 10:  86%|████████▌ | 18/21 [00:00<00:00, 18.34it/s, train_loss=0.00755, val_loss=0.00778]Epoch 10:  86%|████████▌ | 18/21 [00:00<00:00, 18.11it/s, train_loss=0.00773, val_loss=0.00778]Epoch 10:  90%|█████████ | 19/21 [00:01<00:00, 18.21it/s, train_loss=0.00773, val_loss=0.00778]Epoch 10:  90%|█████████ | 19/21 [00:01<00:00, 18.12it/s, train_loss=0.00769, val_loss=0.00778]Epoch 10:  95%|█████████▌| 20/21 [00:01<00:00, 18.20it/s, train_loss=0.00769, val_loss=0.00778]Epoch 10:  95%|█████████▌| 20/21 [00:01<00:00, 18.08it/s, train_loss=0.00795, val_loss=0.00778]Epoch 10: 100%|██████████| 21/21 [00:01<00:00, 18.31it/s, train_loss=0.00795, val_loss=0.00778]Epoch 10: 100%|██████████| 21/21 [00:01<00:00, 18.27it/s, train_loss=0.00792, val_loss=0.00778]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 36.72it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 37.90it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 41.34it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 40.42it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 42.14it/s][A
                                                                      [AEpoch 10: 100%|██████████| 21/21 [00:01<00:00, 16.44it/s, train_loss=0.00792, val_loss=0.00656]Epoch 10: 100%|██████████| 21/21 [00:01<00:00, 16.42it/s, train_loss=0.00792, val_loss=0.00656]Epoch 10:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00792, val_loss=0.00656]         Epoch 11:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00792, val_loss=0.00656]Epoch 11:   5%|▍         | 1/21 [00:00<00:01, 17.09it/s, train_loss=0.00792, val_loss=0.00656]Epoch 11:   5%|▍         | 1/21 [00:00<00:01, 15.42it/s, train_loss=0.0083, val_loss=0.00656] Epoch 11:  10%|▉         | 2/21 [00:00<00:01, 18.65it/s, train_loss=0.0083, val_loss=0.00656]Epoch 11:  10%|▉         | 2/21 [00:00<00:01, 17.27it/s, train_loss=0.00718, val_loss=0.00656]Epoch 11:  14%|█▍        | 3/21 [00:00<00:00, 18.94it/s, train_loss=0.00718, val_loss=0.00656]Epoch 11:  14%|█▍        | 3/21 [00:00<00:01, 17.78it/s, train_loss=0.00773, val_loss=0.00656]Epoch 11:  19%|█▉        | 4/21 [00:00<00:00, 18.15it/s, train_loss=0.00773, val_loss=0.00656]Epoch 11:  19%|█▉        | 4/21 [00:00<00:00, 17.66it/s, train_loss=0.0079, val_loss=0.00656] Epoch 11:  24%|██▍       | 5/21 [00:00<00:00, 18.57it/s, train_loss=0.0079, val_loss=0.00656]Epoch 11:  24%|██▍       | 5/21 [00:00<00:00, 18.10it/s, train_loss=0.0071, val_loss=0.00656]Epoch 11:  29%|██▊       | 6/21 [00:00<00:00, 18.57it/s, train_loss=0.0071, val_loss=0.00656]Epoch 11:  29%|██▊       | 6/21 [00:00<00:00, 17.81it/s, train_loss=0.00724, val_loss=0.00656]Epoch 11:  33%|███▎      | 7/21 [00:00<00:00, 18.50it/s, train_loss=0.00724, val_loss=0.00656]Epoch 11:  33%|███▎      | 7/21 [00:00<00:00, 18.16it/s, train_loss=0.00779, val_loss=0.00656]Epoch 11:  38%|███▊      | 8/21 [00:00<00:00, 18.22it/s, train_loss=0.00779, val_loss=0.00656]Epoch 11:  38%|███▊      | 8/21 [00:00<00:00, 17.82it/s, train_loss=0.00722, val_loss=0.00656]Epoch 11:  43%|████▎     | 9/21 [00:00<00:00, 18.27it/s, train_loss=0.00722, val_loss=0.00656]Epoch 11:  43%|████▎     | 9/21 [00:00<00:00, 18.03it/s, train_loss=0.00802, val_loss=0.00656]Epoch 11:  48%|████▊     | 10/21 [00:00<00:00, 18.01it/s, train_loss=0.00802, val_loss=0.00656]Epoch 11:  48%|████▊     | 10/21 [00:00<00:00, 17.88it/s, train_loss=0.00745, val_loss=0.00656]Epoch 11:  52%|█████▏    | 11/21 [00:00<00:00, 18.55it/s, train_loss=0.00745, val_loss=0.00656]Epoch 11:  52%|█████▏    | 11/21 [00:00<00:00, 18.14it/s, train_loss=0.00751, val_loss=0.00656]Epoch 11:  57%|█████▋    | 12/21 [00:00<00:00, 18.02it/s, train_loss=0.00751, val_loss=0.00656]Epoch 11:  57%|█████▋    | 12/21 [00:00<00:00, 17.92it/s, train_loss=0.0072, val_loss=0.00656] Epoch 11:  62%|██████▏   | 13/21 [00:00<00:00, 18.23it/s, train_loss=0.0072, val_loss=0.00656]Epoch 11:  62%|██████▏   | 13/21 [00:00<00:00, 18.07it/s, train_loss=0.00735, val_loss=0.00656]Epoch 11:  67%|██████▋   | 14/21 [00:00<00:00, 18.16it/s, train_loss=0.00735, val_loss=0.00656]Epoch 11:  67%|██████▋   | 14/21 [00:00<00:00, 18.09it/s, train_loss=0.00716, val_loss=0.00656]Epoch 11:  71%|███████▏  | 15/21 [00:00<00:00, 18.33it/s, train_loss=0.00716, val_loss=0.00656]Epoch 11:  71%|███████▏  | 15/21 [00:00<00:00, 18.05it/s, train_loss=0.00776, val_loss=0.00656]Epoch 11:  76%|███████▌  | 16/21 [00:00<00:00, 18.11it/s, train_loss=0.00776, val_loss=0.00656]Epoch 11:  76%|███████▌  | 16/21 [00:00<00:00, 18.00it/s, train_loss=0.00744, val_loss=0.00656]Epoch 11:  81%|████████  | 17/21 [00:00<00:00, 18.21it/s, train_loss=0.00744, val_loss=0.00656]Epoch 11:  81%|████████  | 17/21 [00:00<00:00, 17.96it/s, train_loss=0.00738, val_loss=0.00656]Epoch 11:  86%|████████▌ | 18/21 [00:00<00:00, 18.11it/s, train_loss=0.00738, val_loss=0.00656]Epoch 11:  86%|████████▌ | 18/21 [00:01<00:00, 17.99it/s, train_loss=0.00689, val_loss=0.00656]Epoch 11:  90%|█████████ | 19/21 [00:01<00:00, 18.09it/s, train_loss=0.00689, val_loss=0.00656]Epoch 11:  90%|█████████ | 19/21 [00:01<00:00, 17.90it/s, train_loss=0.00737, val_loss=0.00656]Epoch 11:  95%|█████████▌| 20/21 [00:01<00:00, 18.06it/s, train_loss=0.00737, val_loss=0.00656]Epoch 11:  95%|█████████▌| 20/21 [00:01<00:00, 17.98it/s, train_loss=0.00744, val_loss=0.00656]Epoch 11: 100%|██████████| 21/21 [00:01<00:00, 18.05it/s, train_loss=0.00744, val_loss=0.00656]Epoch 11: 100%|██████████| 21/21 [00:01<00:00, 18.02it/s, train_loss=0.00666, val_loss=0.00656]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 31.84it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 38.60it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 40.72it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 38.99it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 38.36it/s][A
                                                                      [AEpoch 11: 100%|██████████| 21/21 [00:01<00:00, 16.07it/s, train_loss=0.00666, val_loss=0.00598]Epoch 11: 100%|██████████| 21/21 [00:01<00:00, 16.05it/s, train_loss=0.00666, val_loss=0.00598]Epoch 11:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00666, val_loss=0.00598]         Epoch 12:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00666, val_loss=0.00598]Epoch 12:   5%|▍         | 1/21 [00:00<00:00, 22.59it/s, train_loss=0.00666, val_loss=0.00598]Epoch 12:   5%|▍         | 1/21 [00:00<00:00, 20.04it/s, train_loss=0.00772, val_loss=0.00598]Epoch 12:  10%|▉         | 2/21 [00:00<00:00, 19.20it/s, train_loss=0.00772, val_loss=0.00598]Epoch 12:  10%|▉         | 2/21 [00:00<00:01, 17.99it/s, train_loss=0.00679, val_loss=0.00598]Epoch 12:  14%|█▍        | 3/21 [00:00<00:00, 18.44it/s, train_loss=0.00679, val_loss=0.00598]Epoch 12:  14%|█▍        | 3/21 [00:00<00:01, 17.73it/s, train_loss=0.00674, val_loss=0.00598]Epoch 12:  19%|█▉        | 4/21 [00:00<00:00, 17.66it/s, train_loss=0.00674, val_loss=0.00598]Epoch 12:  19%|█▉        | 4/21 [00:00<00:00, 17.34it/s, train_loss=0.00675, val_loss=0.00598]Epoch 12:  24%|██▍       | 5/21 [00:00<00:00, 18.06it/s, train_loss=0.00675, val_loss=0.00598]Epoch 12:  24%|██▍       | 5/21 [00:00<00:00, 17.66it/s, train_loss=0.00699, val_loss=0.00598]Epoch 12:  29%|██▊       | 6/21 [00:00<00:00, 18.00it/s, train_loss=0.00699, val_loss=0.00598]Epoch 12:  29%|██▊       | 6/21 [00:00<00:00, 17.75it/s, train_loss=0.0066, val_loss=0.00598] Epoch 12:  33%|███▎      | 7/21 [00:00<00:00, 18.45it/s, train_loss=0.0066, val_loss=0.00598]Epoch 12:  33%|███▎      | 7/21 [00:00<00:00, 18.12it/s, train_loss=0.00693, val_loss=0.00598]Epoch 12:  38%|███▊      | 8/21 [00:00<00:00, 18.56it/s, train_loss=0.00693, val_loss=0.00598]Epoch 12:  38%|███▊      | 8/21 [00:00<00:00, 18.22it/s, train_loss=0.00704, val_loss=0.00598]Epoch 12:  43%|████▎     | 9/21 [00:00<00:00, 18.47it/s, train_loss=0.00704, val_loss=0.00598]Epoch 12:  43%|████▎     | 9/21 [00:00<00:00, 18.22it/s, train_loss=0.00682, val_loss=0.00598]Epoch 12:  48%|████▊     | 10/21 [00:00<00:00, 18.72it/s, train_loss=0.00682, val_loss=0.00598]Epoch 12:  48%|████▊     | 10/21 [00:00<00:00, 18.51it/s, train_loss=0.00672, val_loss=0.00598]Epoch 12:  52%|█████▏    | 11/21 [00:00<00:00, 18.55it/s, train_loss=0.00672, val_loss=0.00598]Epoch 12:  52%|█████▏    | 11/21 [00:00<00:00, 18.31it/s, train_loss=0.00674, val_loss=0.00598]Epoch 12:  57%|█████▋    | 12/21 [00:00<00:00, 18.56it/s, train_loss=0.00674, val_loss=0.00598]Epoch 12:  57%|█████▋    | 12/21 [00:00<00:00, 18.37it/s, train_loss=0.00655, val_loss=0.00598]Epoch 12:  62%|██████▏   | 13/21 [00:00<00:00, 18.31it/s, train_loss=0.00655, val_loss=0.00598]Epoch 12:  62%|██████▏   | 13/21 [00:00<00:00, 18.16it/s, train_loss=0.00707, val_loss=0.00598]Epoch 12:  67%|██████▋   | 14/21 [00:00<00:00, 18.51it/s, train_loss=0.00707, val_loss=0.00598]Epoch 12:  67%|██████▋   | 14/21 [00:00<00:00, 18.31it/s, train_loss=0.00657, val_loss=0.00598]Epoch 12:  71%|███████▏  | 15/21 [00:00<00:00, 18.54it/s, train_loss=0.00657, val_loss=0.00598]Epoch 12:  71%|███████▏  | 15/21 [00:00<00:00, 18.34it/s, train_loss=0.00597, val_loss=0.00598]Epoch 12:  76%|███████▌  | 16/21 [00:00<00:00, 18.46it/s, train_loss=0.00597, val_loss=0.00598]Epoch 12:  76%|███████▌  | 16/21 [00:00<00:00, 18.30it/s, train_loss=0.00669, val_loss=0.00598]Epoch 12:  81%|████████  | 17/21 [00:00<00:00, 18.47it/s, train_loss=0.00669, val_loss=0.00598]Epoch 12:  81%|████████  | 17/21 [00:00<00:00, 18.33it/s, train_loss=0.00678, val_loss=0.00598]Epoch 12:  86%|████████▌ | 18/21 [00:00<00:00, 18.38it/s, train_loss=0.00678, val_loss=0.00598]Epoch 12:  86%|████████▌ | 18/21 [00:00<00:00, 18.26it/s, train_loss=0.0067, val_loss=0.00598] Epoch 12:  90%|█████████ | 19/21 [00:01<00:00, 18.29it/s, train_loss=0.0067, val_loss=0.00598]Epoch 12:  90%|█████████ | 19/21 [00:01<00:00, 18.14it/s, train_loss=0.00633, val_loss=0.00598]Epoch 12:  95%|█████████▌| 20/21 [00:01<00:00, 18.26it/s, train_loss=0.00633, val_loss=0.00598]Epoch 12:  95%|█████████▌| 20/21 [00:01<00:00, 18.15it/s, train_loss=0.00629, val_loss=0.00598]Epoch 12: 100%|██████████| 21/21 [00:01<00:00, 18.28it/s, train_loss=0.00629, val_loss=0.00598]Epoch 12: 100%|██████████| 21/21 [00:01<00:00, 18.26it/s, train_loss=0.00703, val_loss=0.00598]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 46.79it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 47.51it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 40.82it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 43.81it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 45.03it/s][A
                                                                      [AEpoch 12: 100%|██████████| 21/21 [00:01<00:00, 16.54it/s, train_loss=0.00703, val_loss=0.00575]Epoch 12: 100%|██████████| 21/21 [00:01<00:00, 16.53it/s, train_loss=0.00703, val_loss=0.00575]Epoch 12:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00703, val_loss=0.00575]         Epoch 13:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00703, val_loss=0.00575]Epoch 13:   5%|▍         | 1/21 [00:00<00:00, 22.88it/s, train_loss=0.00703, val_loss=0.00575]Epoch 13:   5%|▍         | 1/21 [00:00<00:01, 18.70it/s, train_loss=0.0064, val_loss=0.00575] Epoch 13:  10%|▉         | 2/21 [00:00<00:01, 18.15it/s, train_loss=0.0064, val_loss=0.00575]Epoch 13:  10%|▉         | 2/21 [00:00<00:01, 16.79it/s, train_loss=0.00679, val_loss=0.00575]Epoch 13:  14%|█▍        | 3/21 [00:00<00:00, 18.14it/s, train_loss=0.00679, val_loss=0.00575]Epoch 13:  14%|█▍        | 3/21 [00:00<00:01, 17.28it/s, train_loss=0.00698, val_loss=0.00575]Epoch 13:  19%|█▉        | 4/21 [00:00<00:00, 17.01it/s, train_loss=0.00698, val_loss=0.00575]Epoch 13:  19%|█▉        | 4/21 [00:00<00:01, 16.52it/s, train_loss=0.00616, val_loss=0.00575]Epoch 13:  24%|██▍       | 5/21 [00:00<00:00, 17.48it/s, train_loss=0.00616, val_loss=0.00575]Epoch 13:  24%|██▍       | 5/21 [00:00<00:00, 17.01it/s, train_loss=0.00637, val_loss=0.00575]Epoch 13:  29%|██▊       | 6/21 [00:00<00:00, 17.22it/s, train_loss=0.00637, val_loss=0.00575]Epoch 13:  29%|██▊       | 6/21 [00:00<00:00, 16.89it/s, train_loss=0.00618, val_loss=0.00575]Epoch 13:  33%|███▎      | 7/21 [00:00<00:00, 17.28it/s, train_loss=0.00618, val_loss=0.00575]Epoch 13:  33%|███▎      | 7/21 [00:00<00:00, 16.99it/s, train_loss=0.00671, val_loss=0.00575]Epoch 13:  38%|███▊      | 8/21 [00:00<00:00, 17.41it/s, train_loss=0.00671, val_loss=0.00575]Epoch 13:  38%|███▊      | 8/21 [00:00<00:00, 17.27it/s, train_loss=0.00664, val_loss=0.00575]Epoch 13:  43%|████▎     | 9/21 [00:00<00:00, 17.58it/s, train_loss=0.00664, val_loss=0.00575]Epoch 13:  43%|████▎     | 9/21 [00:00<00:00, 17.34it/s, train_loss=0.00641, val_loss=0.00575]Epoch 13:  48%|████▊     | 10/21 [00:00<00:00, 17.61it/s, train_loss=0.00641, val_loss=0.00575]Epoch 13:  48%|████▊     | 10/21 [00:00<00:00, 17.34it/s, train_loss=0.00604, val_loss=0.00575]Epoch 13:  52%|█████▏    | 11/21 [00:00<00:00, 17.50it/s, train_loss=0.00604, val_loss=0.00575]Epoch 13:  52%|█████▏    | 11/21 [00:00<00:00, 17.30it/s, train_loss=0.00627, val_loss=0.00575]Epoch 13:  57%|█████▋    | 12/21 [00:00<00:00, 17.63it/s, train_loss=0.00627, val_loss=0.00575]Epoch 13:  57%|█████▋    | 12/21 [00:00<00:00, 17.48it/s, train_loss=0.00642, val_loss=0.00575]Epoch 13:  62%|██████▏   | 13/21 [00:00<00:00, 17.66it/s, train_loss=0.00642, val_loss=0.00575]Epoch 13:  62%|██████▏   | 13/21 [00:00<00:00, 17.40it/s, train_loss=0.00654, val_loss=0.00575]Epoch 13:  67%|██████▋   | 14/21 [00:00<00:00, 17.74it/s, train_loss=0.00654, val_loss=0.00575]Epoch 13:  67%|██████▋   | 14/21 [00:00<00:00, 17.58it/s, train_loss=0.00635, val_loss=0.00575]Epoch 13:  71%|███████▏  | 15/21 [00:00<00:00, 17.77it/s, train_loss=0.00635, val_loss=0.00575]Epoch 13:  71%|███████▏  | 15/21 [00:00<00:00, 17.63it/s, train_loss=0.00583, val_loss=0.00575]Epoch 13:  76%|███████▌  | 16/21 [00:00<00:00, 17.97it/s, train_loss=0.00583, val_loss=0.00575]Epoch 13:  76%|███████▌  | 16/21 [00:00<00:00, 17.78it/s, train_loss=0.0062, val_loss=0.00575] Epoch 13:  81%|████████  | 17/21 [00:00<00:00, 18.33it/s, train_loss=0.0062, val_loss=0.00575]Epoch 13:  81%|████████  | 17/21 [00:00<00:00, 17.98it/s, train_loss=0.006, val_loss=0.00575] Epoch 13:  86%|████████▌ | 18/21 [00:00<00:00, 18.55it/s, train_loss=0.006, val_loss=0.00575]Epoch 13:  86%|████████▌ | 18/21 [00:00<00:00, 18.16it/s, train_loss=0.00618, val_loss=0.00575]Epoch 13:  90%|█████████ | 19/21 [00:01<00:00, 18.71it/s, train_loss=0.00618, val_loss=0.00575]Epoch 13:  90%|█████████ | 19/21 [00:01<00:00, 18.33it/s, train_loss=0.00587, val_loss=0.00575]Epoch 13:  95%|█████████▌| 20/21 [00:01<00:00, 18.88it/s, train_loss=0.00587, val_loss=0.00575]Epoch 13:  95%|█████████▌| 20/21 [00:01<00:00, 18.49it/s, train_loss=0.00583, val_loss=0.00575]Epoch 13: 100%|██████████| 21/21 [00:01<00:00, 19.02it/s, train_loss=0.00583, val_loss=0.00575]Epoch 13: 100%|██████████| 21/21 [00:01<00:00, 18.71it/s, train_loss=0.00643, val_loss=0.00575]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 62.94it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 64.18it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 64.26it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 63.67it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 63.45it/s][A
                                                                      [AEpoch 13: 100%|██████████| 21/21 [00:01<00:00, 17.38it/s, train_loss=0.00643, val_loss=0.00552]Epoch 13: 100%|██████████| 21/21 [00:01<00:00, 17.36it/s, train_loss=0.00643, val_loss=0.00552]Epoch 13:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00643, val_loss=0.00552]         Epoch 14:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00643, val_loss=0.00552]Epoch 14:   5%|▍         | 1/21 [00:00<00:00, 31.89it/s, train_loss=0.00643, val_loss=0.00552]Epoch 14:   5%|▍         | 1/21 [00:00<00:00, 20.97it/s, train_loss=0.00611, val_loss=0.00552]Epoch 14:  10%|▉         | 2/21 [00:00<00:00, 27.40it/s, train_loss=0.00611, val_loss=0.00552]Epoch 14:  10%|▉         | 2/21 [00:00<00:00, 21.38it/s, train_loss=0.00641, val_loss=0.00552]Epoch 14:  14%|█▍        | 3/21 [00:00<00:00, 25.64it/s, train_loss=0.00641, val_loss=0.00552]Epoch 14:  14%|█▍        | 3/21 [00:00<00:00, 21.56it/s, train_loss=0.00623, val_loss=0.00552]Epoch 14:  19%|█▉        | 4/21 [00:00<00:00, 24.42it/s, train_loss=0.00623, val_loss=0.00552]Epoch 14:  19%|█▉        | 4/21 [00:00<00:00, 21.52it/s, train_loss=0.00564, val_loss=0.00552]Epoch 14:  24%|██▍       | 5/21 [00:00<00:00, 23.97it/s, train_loss=0.00564, val_loss=0.00552]Epoch 14:  24%|██▍       | 5/21 [00:00<00:00, 21.63it/s, train_loss=0.00592, val_loss=0.00552]Epoch 14:  29%|██▊       | 6/21 [00:00<00:00, 23.66it/s, train_loss=0.00592, val_loss=0.00552]Epoch 14:  29%|██▊       | 6/21 [00:00<00:00, 21.70it/s, train_loss=0.00595, val_loss=0.00552]Epoch 14:  33%|███▎      | 7/21 [00:00<00:00, 23.41it/s, train_loss=0.00595, val_loss=0.00552]Epoch 14:  33%|███▎      | 7/21 [00:00<00:00, 21.74it/s, train_loss=0.00556, val_loss=0.00552]Epoch 14:  38%|███▊      | 8/21 [00:00<00:00, 23.23it/s, train_loss=0.00556, val_loss=0.00552]Epoch 14:  38%|███▊      | 8/21 [00:00<00:00, 21.76it/s, train_loss=0.00582, val_loss=0.00552]Epoch 14:  43%|████▎     | 9/21 [00:00<00:00, 23.09it/s, train_loss=0.00582, val_loss=0.00552]Epoch 14:  43%|████▎     | 9/21 [00:00<00:00, 21.81it/s, train_loss=0.00541, val_loss=0.00552]Epoch 14:  48%|████▊     | 10/21 [00:00<00:00, 22.71it/s, train_loss=0.00541, val_loss=0.00552]Epoch 14:  48%|████▊     | 10/21 [00:00<00:00, 21.84it/s, train_loss=0.00572, val_loss=0.00552]Epoch 14:  52%|█████▏    | 11/21 [00:00<00:00, 22.10it/s, train_loss=0.00572, val_loss=0.00552]Epoch 14:  52%|█████▏    | 11/21 [00:00<00:00, 21.58it/s, train_loss=0.00582, val_loss=0.00552]Epoch 14:  57%|█████▋    | 12/21 [00:00<00:00, 22.25it/s, train_loss=0.00582, val_loss=0.00552]Epoch 14:  57%|█████▋    | 12/21 [00:00<00:00, 21.60it/s, train_loss=0.00562, val_loss=0.00552]Epoch 14:  62%|██████▏   | 13/21 [00:00<00:00, 22.40it/s, train_loss=0.00562, val_loss=0.00552]Epoch 14:  62%|██████▏   | 13/21 [00:00<00:00, 21.64it/s, train_loss=0.00612, val_loss=0.00552]Epoch 14:  67%|██████▋   | 14/21 [00:00<00:00, 22.40it/s, train_loss=0.00612, val_loss=0.00552]Epoch 14:  67%|██████▋   | 14/21 [00:00<00:00, 21.66it/s, train_loss=0.006, val_loss=0.00552]  Epoch 14:  71%|███████▏  | 15/21 [00:00<00:00, 22.41it/s, train_loss=0.006, val_loss=0.00552]Epoch 14:  71%|███████▏  | 15/21 [00:00<00:00, 21.69it/s, train_loss=0.006, val_loss=0.00552]Epoch 14:  76%|███████▌  | 16/21 [00:00<00:00, 22.39it/s, train_loss=0.006, val_loss=0.00552]Epoch 14:  76%|███████▌  | 16/21 [00:00<00:00, 21.71it/s, train_loss=0.00563, val_loss=0.00552]Epoch 14:  81%|████████  | 17/21 [00:00<00:00, 22.37it/s, train_loss=0.00563, val_loss=0.00552]Epoch 14:  81%|████████  | 17/21 [00:00<00:00, 21.72it/s, train_loss=0.00665, val_loss=0.00552]Epoch 14:  86%|████████▌ | 18/21 [00:00<00:00, 22.35it/s, train_loss=0.00665, val_loss=0.00552]Epoch 14:  86%|████████▌ | 18/21 [00:00<00:00, 21.74it/s, train_loss=0.00567, val_loss=0.00552]Epoch 14:  90%|█████████ | 19/21 [00:01<00:00, 18.69it/s, train_loss=0.00567, val_loss=0.00552]Epoch 14:  90%|█████████ | 19/21 [00:01<00:00, 18.33it/s, train_loss=0.00569, val_loss=0.00552]Epoch 14:  95%|█████████▌| 20/21 [00:01<00:00, 18.90it/s, train_loss=0.00569, val_loss=0.00552]Epoch 14:  95%|█████████▌| 20/21 [00:01<00:00, 18.45it/s, train_loss=0.00566, val_loss=0.00552]Epoch 14: 100%|██████████| 21/21 [00:01<00:00, 18.99it/s, train_loss=0.00566, val_loss=0.00552]Epoch 14: 100%|██████████| 21/21 [00:01<00:00, 18.66it/s, train_loss=0.00601, val_loss=0.00552]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 67.06it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 73.20it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 74.90it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 77.70it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 79.73it/s][A
                                                                      [AEpoch 14: 100%|██████████| 21/21 [00:01<00:00, 17.40it/s, train_loss=0.00601, val_loss=0.00521]Epoch 14: 100%|██████████| 21/21 [00:01<00:00, 17.38it/s, train_loss=0.00601, val_loss=0.00521]Epoch 14:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00601, val_loss=0.00521]         Epoch 15:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00601, val_loss=0.00521]Epoch 15:   5%|▍         | 1/21 [00:00<00:00, 39.21it/s, train_loss=0.00601, val_loss=0.00521]Epoch 15:   5%|▍         | 1/21 [00:00<00:00, 20.44it/s, train_loss=0.00598, val_loss=0.00521]Epoch 15:  10%|▉         | 2/21 [00:00<00:00, 27.43it/s, train_loss=0.00598, val_loss=0.00521]Epoch 15:  10%|▉         | 2/21 [00:00<00:00, 20.68it/s, train_loss=0.00564, val_loss=0.00521]Epoch 15:  14%|█▍        | 3/21 [00:00<00:00, 25.01it/s, train_loss=0.00564, val_loss=0.00521]Epoch 15:  14%|█▍        | 3/21 [00:00<00:00, 20.83it/s, train_loss=0.00543, val_loss=0.00521]Epoch 15:  19%|█▉        | 4/21 [00:00<00:00, 24.04it/s, train_loss=0.00543, val_loss=0.00521]Epoch 15:  19%|█▉        | 4/21 [00:00<00:00, 20.99it/s, train_loss=0.00551, val_loss=0.00521]Epoch 15:  24%|██▍       | 5/21 [00:00<00:00, 23.43it/s, train_loss=0.00551, val_loss=0.00521]Epoch 15:  24%|██▍       | 5/21 [00:00<00:00, 21.10it/s, train_loss=0.00514, val_loss=0.00521]Epoch 15:  29%|██▊       | 6/21 [00:00<00:00, 23.05it/s, train_loss=0.00514, val_loss=0.00521]Epoch 15:  29%|██▊       | 6/21 [00:00<00:00, 21.14it/s, train_loss=0.00543, val_loss=0.00521]Epoch 15:  33%|███▎      | 7/21 [00:00<00:00, 22.84it/s, train_loss=0.00543, val_loss=0.00521]Epoch 15:  33%|███▎      | 7/21 [00:00<00:00, 21.19it/s, train_loss=0.00551, val_loss=0.00521]Epoch 15:  38%|███▊      | 8/21 [00:00<00:00, 22.60it/s, train_loss=0.00551, val_loss=0.00521]Epoch 15:  38%|███▊      | 8/21 [00:00<00:00, 21.22it/s, train_loss=0.00558, val_loss=0.00521]Epoch 15:  43%|████▎     | 9/21 [00:00<00:00, 22.52it/s, train_loss=0.00558, val_loss=0.00521]Epoch 15:  43%|████▎     | 9/21 [00:00<00:00, 21.26it/s, train_loss=0.00574, val_loss=0.00521]Epoch 15:  48%|████▊     | 10/21 [00:00<00:00, 22.44it/s, train_loss=0.00574, val_loss=0.00521]Epoch 15:  48%|████▊     | 10/21 [00:00<00:00, 21.27it/s, train_loss=0.00596, val_loss=0.00521]Epoch 15:  52%|█████▏    | 11/21 [00:00<00:00, 22.33it/s, train_loss=0.00596, val_loss=0.00521]Epoch 15:  52%|█████▏    | 11/21 [00:00<00:00, 21.28it/s, train_loss=0.00594, val_loss=0.00521]Epoch 15:  57%|█████▋    | 12/21 [00:00<00:00, 22.25it/s, train_loss=0.00594, val_loss=0.00521]Epoch 15:  57%|█████▋    | 12/21 [00:00<00:00, 21.30it/s, train_loss=0.00565, val_loss=0.00521]Epoch 15:  62%|██████▏   | 13/21 [00:00<00:00, 22.18it/s, train_loss=0.00565, val_loss=0.00521]Epoch 15:  62%|██████▏   | 13/21 [00:00<00:00, 21.30it/s, train_loss=0.00548, val_loss=0.00521]Epoch 15:  67%|██████▋   | 14/21 [00:00<00:00, 22.12it/s, train_loss=0.00548, val_loss=0.00521]Epoch 15:  67%|██████▋   | 14/21 [00:00<00:00, 21.32it/s, train_loss=0.00565, val_loss=0.00521]Epoch 15:  71%|███████▏  | 15/21 [00:00<00:00, 21.99it/s, train_loss=0.00565, val_loss=0.00521]Epoch 15:  71%|███████▏  | 15/21 [00:00<00:00, 21.31it/s, train_loss=0.00522, val_loss=0.00521]Epoch 15:  76%|███████▌  | 16/21 [00:00<00:00, 22.03it/s, train_loss=0.00522, val_loss=0.00521]Epoch 15:  76%|███████▌  | 16/21 [00:00<00:00, 21.33it/s, train_loss=0.00604, val_loss=0.00521]Epoch 15:  81%|████████  | 17/21 [00:00<00:00, 22.00it/s, train_loss=0.00604, val_loss=0.00521]Epoch 15:  81%|████████  | 17/21 [00:00<00:00, 21.33it/s, train_loss=0.00556, val_loss=0.00521]Epoch 15:  86%|████████▌ | 18/21 [00:00<00:00, 21.96it/s, train_loss=0.00556, val_loss=0.00521]Epoch 15:  86%|████████▌ | 18/21 [00:00<00:00, 21.34it/s, train_loss=0.00558, val_loss=0.00521]Epoch 15:  90%|█████████ | 19/21 [00:00<00:00, 21.95it/s, train_loss=0.00558, val_loss=0.00521]Epoch 15:  90%|█████████ | 19/21 [00:00<00:00, 21.35it/s, train_loss=0.00605, val_loss=0.00521]Epoch 15:  95%|█████████▌| 20/21 [00:00<00:00, 21.92it/s, train_loss=0.00605, val_loss=0.00521]Epoch 15:  95%|█████████▌| 20/21 [00:00<00:00, 21.35it/s, train_loss=0.00562, val_loss=0.00521]Epoch 15: 100%|██████████| 21/21 [00:00<00:00, 21.91it/s, train_loss=0.00562, val_loss=0.00521]Epoch 15: 100%|██████████| 21/21 [00:00<00:00, 21.47it/s, train_loss=0.00546, val_loss=0.00521]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 78.48it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 83.20it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 83.87it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 87.84it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 90.84it/s][A
                                                                      [AEpoch 15: 100%|██████████| 21/21 [00:01<00:00, 19.80it/s, train_loss=0.00546, val_loss=0.00505]Epoch 15: 100%|██████████| 21/21 [00:01<00:00, 19.77it/s, train_loss=0.00546, val_loss=0.00505]Epoch 15:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00546, val_loss=0.00505]         Epoch 16:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00546, val_loss=0.00505]Epoch 16:   5%|▍         | 1/21 [00:00<00:00, 39.17it/s, train_loss=0.00546, val_loss=0.00505]Epoch 16:   5%|▍         | 1/21 [00:00<00:00, 20.72it/s, train_loss=0.00557, val_loss=0.00505]Epoch 16:  10%|▉         | 2/21 [00:00<00:00, 27.72it/s, train_loss=0.00557, val_loss=0.00505]Epoch 16:  10%|▉         | 2/21 [00:00<00:00, 20.88it/s, train_loss=0.00539, val_loss=0.00505]Epoch 16:  14%|█▍        | 3/21 [00:00<00:00, 25.11it/s, train_loss=0.00539, val_loss=0.00505]Epoch 16:  14%|█▍        | 3/21 [00:00<00:00, 21.03it/s, train_loss=0.00533, val_loss=0.00505]Epoch 16:  19%|█▉        | 4/21 [00:00<00:00, 23.98it/s, train_loss=0.00533, val_loss=0.00505]Epoch 16:  19%|█▉        | 4/21 [00:00<00:00, 21.14it/s, train_loss=0.00536, val_loss=0.00505]Epoch 16:  24%|██▍       | 5/21 [00:00<00:00, 23.50it/s, train_loss=0.00536, val_loss=0.00505]Epoch 16:  24%|██▍       | 5/21 [00:00<00:00, 21.18it/s, train_loss=0.00528, val_loss=0.00505]Epoch 16:  29%|██▊       | 6/21 [00:00<00:00, 23.12it/s, train_loss=0.00528, val_loss=0.00505]Epoch 16:  29%|██▊       | 6/21 [00:00<00:00, 21.24it/s, train_loss=0.00545, val_loss=0.00505]Epoch 16:  33%|███▎      | 7/21 [00:00<00:00, 22.86it/s, train_loss=0.00545, val_loss=0.00505]Epoch 16:  33%|███▎      | 7/21 [00:00<00:00, 21.29it/s, train_loss=0.00507, val_loss=0.00505]Epoch 16:  38%|███▊      | 8/21 [00:00<00:00, 22.70it/s, train_loss=0.00507, val_loss=0.00505]Epoch 16:  38%|███▊      | 8/21 [00:00<00:00, 21.31it/s, train_loss=0.00559, val_loss=0.00505]Epoch 16:  43%|████▎     | 9/21 [00:00<00:00, 22.62it/s, train_loss=0.00559, val_loss=0.00505]Epoch 16:  43%|████▎     | 9/21 [00:00<00:00, 21.33it/s, train_loss=0.0054, val_loss=0.00505] Epoch 16:  48%|████▊     | 10/21 [00:00<00:00, 22.48it/s, train_loss=0.0054, val_loss=0.00505]Epoch 16:  48%|████▊     | 10/21 [00:00<00:00, 21.33it/s, train_loss=0.00506, val_loss=0.00505]Epoch 16:  52%|█████▏    | 11/21 [00:00<00:00, 22.41it/s, train_loss=0.00506, val_loss=0.00505]Epoch 16:  52%|█████▏    | 11/21 [00:00<00:00, 21.34it/s, train_loss=0.00545, val_loss=0.00505]Epoch 16:  57%|█████▋    | 12/21 [00:00<00:00, 22.34it/s, train_loss=0.00545, val_loss=0.00505]Epoch 16:  57%|█████▋    | 12/21 [00:00<00:00, 21.34it/s, train_loss=0.00535, val_loss=0.00505]Epoch 16:  62%|██████▏   | 13/21 [00:00<00:00, 22.21it/s, train_loss=0.00535, val_loss=0.00505]Epoch 16:  62%|██████▏   | 13/21 [00:00<00:00, 21.34it/s, train_loss=0.00569, val_loss=0.00505]Epoch 16:  67%|██████▋   | 14/21 [00:00<00:00, 14.32it/s, train_loss=0.00569, val_loss=0.00505]Epoch 16:  67%|██████▋   | 14/21 [00:01<00:00, 10.59it/s, train_loss=0.00501, val_loss=0.00505]Epoch 16:  71%|███████▏  | 15/21 [00:01<00:00,  9.26it/s, train_loss=0.00501, val_loss=0.00505]Epoch 16:  71%|███████▏  | 15/21 [00:01<00:00,  7.68it/s, train_loss=0.0053, val_loss=0.00505] Epoch 16:  76%|███████▌  | 16/21 [00:02<00:00,  7.20it/s, train_loss=0.0053, val_loss=0.00505]Epoch 16:  76%|███████▌  | 16/21 [00:02<00:00,  6.17it/s, train_loss=0.00614, val_loss=0.00505]Epoch 16:  81%|████████  | 17/21 [00:02<00:00,  5.93it/s, train_loss=0.00614, val_loss=0.00505]Epoch 16:  81%|████████  | 17/21 [00:03<00:00,  5.30it/s, train_loss=0.0053, val_loss=0.00505] Epoch 16:  86%|████████▌ | 18/21 [00:03<00:00,  5.16it/s, train_loss=0.0053, val_loss=0.00505]Epoch 16:  86%|████████▌ | 18/21 [00:03<00:00,  4.69it/s, train_loss=0.00502, val_loss=0.00505]Epoch 16:  90%|█████████ | 19/21 [00:04<00:00,  4.62it/s, train_loss=0.00502, val_loss=0.00505]Epoch 16:  90%|█████████ | 19/21 [00:04<00:00,  4.25it/s, train_loss=0.00558, val_loss=0.00505]Epoch 16:  95%|█████████▌| 20/21 [00:04<00:00,  4.21it/s, train_loss=0.00558, val_loss=0.00505]Epoch 16:  95%|█████████▌| 20/21 [00:05<00:00,  3.93it/s, train_loss=0.00512, val_loss=0.00505]Epoch 16: 100%|██████████| 21/21 [00:05<00:00,  3.92it/s, train_loss=0.00512, val_loss=0.00505]Epoch 16: 100%|██████████| 21/21 [00:05<00:00,  3.67it/s, train_loss=0.00509, val_loss=0.00505]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 64.76it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 60.56it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 59.71it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 48.91it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 46.78it/s][A
                                                                      [AEpoch 16: 100%|██████████| 21/21 [00:06<00:00,  3.32it/s, train_loss=0.00509, val_loss=0.00486]Epoch 16: 100%|██████████| 21/21 [00:06<00:00,  3.32it/s, train_loss=0.00509, val_loss=0.00486]Epoch 16:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00509, val_loss=0.00486]         Epoch 17:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00509, val_loss=0.00486]Epoch 17:   5%|▍         | 1/21 [00:00<00:00, 24.35it/s, train_loss=0.00509, val_loss=0.00486]Epoch 17:   5%|▍         | 1/21 [00:00<00:01, 19.89it/s, train_loss=0.00545, val_loss=0.00486]Epoch 17:  10%|▉         | 2/21 [00:00<00:00, 22.48it/s, train_loss=0.00545, val_loss=0.00486]Epoch 17:  10%|▉         | 2/21 [00:00<00:00, 20.91it/s, train_loss=0.00487, val_loss=0.00486]Epoch 17:  14%|█▍        | 3/21 [00:00<00:00, 22.42it/s, train_loss=0.00487, val_loss=0.00486]Epoch 17:  14%|█▍        | 3/21 [00:00<00:00, 21.23it/s, train_loss=0.0051, val_loss=0.00486] Epoch 17:  19%|█▉        | 4/21 [00:00<00:00, 20.54it/s, train_loss=0.0051, val_loss=0.00486]Epoch 17:  19%|█▉        | 4/21 [00:00<00:00, 19.71it/s, train_loss=0.0053, val_loss=0.00486]Epoch 17:  24%|██▍       | 5/21 [00:00<00:00, 20.10it/s, train_loss=0.0053, val_loss=0.00486]Epoch 17:  24%|██▍       | 5/21 [00:00<00:00, 19.68it/s, train_loss=0.00544, val_loss=0.00486]Epoch 17:  29%|██▊       | 6/21 [00:00<00:00, 18.90it/s, train_loss=0.00544, val_loss=0.00486]Epoch 17:  29%|██▊       | 6/21 [00:00<00:00, 18.58it/s, train_loss=0.00521, val_loss=0.00486]Epoch 17:  33%|███▎      | 7/21 [00:00<00:00, 18.78it/s, train_loss=0.00521, val_loss=0.00486]Epoch 17:  33%|███▎      | 7/21 [00:00<00:00, 18.48it/s, train_loss=0.00567, val_loss=0.00486]Epoch 17:  38%|███▊      | 8/21 [00:00<00:00, 18.77it/s, train_loss=0.00567, val_loss=0.00486]Epoch 17:  38%|███▊      | 8/21 [00:00<00:00, 18.47it/s, train_loss=0.00499, val_loss=0.00486]Epoch 17:  43%|████▎     | 9/21 [00:00<00:00, 18.39it/s, train_loss=0.00499, val_loss=0.00486]Epoch 17:  43%|████▎     | 9/21 [00:00<00:00, 18.24it/s, train_loss=0.00561, val_loss=0.00486]Epoch 17:  48%|████▊     | 10/21 [00:00<00:00, 18.32it/s, train_loss=0.00561, val_loss=0.00486]Epoch 17:  48%|████▊     | 10/21 [00:00<00:00, 18.07it/s, train_loss=0.00514, val_loss=0.00486]Epoch 17:  52%|█████▏    | 11/21 [00:00<00:00, 18.01it/s, train_loss=0.00514, val_loss=0.00486]Epoch 17:  52%|█████▏    | 11/21 [00:00<00:00, 17.76it/s, train_loss=0.00512, val_loss=0.00486]Epoch 17:  57%|█████▋    | 12/21 [00:00<00:00, 18.09it/s, train_loss=0.00512, val_loss=0.00486]Epoch 17:  57%|█████▋    | 12/21 [00:00<00:00, 17.86it/s, train_loss=0.00506, val_loss=0.00486]Epoch 17:  62%|██████▏   | 13/21 [00:00<00:00, 18.12it/s, train_loss=0.00506, val_loss=0.00486]Epoch 17:  62%|██████▏   | 13/21 [00:00<00:00, 17.97it/s, train_loss=0.0051, val_loss=0.00486] Epoch 17:  67%|██████▋   | 14/21 [00:00<00:00, 18.24it/s, train_loss=0.0051, val_loss=0.00486]Epoch 17:  67%|██████▋   | 14/21 [00:00<00:00, 18.09it/s, train_loss=0.00538, val_loss=0.00486]Epoch 17:  71%|███████▏  | 15/21 [00:00<00:00, 18.05it/s, train_loss=0.00538, val_loss=0.00486]Epoch 17:  71%|███████▏  | 15/21 [00:00<00:00, 17.98it/s, train_loss=0.00507, val_loss=0.00486]Epoch 17:  76%|███████▌  | 16/21 [00:00<00:00, 17.88it/s, train_loss=0.00507, val_loss=0.00486]Epoch 17:  76%|███████▌  | 16/21 [00:00<00:00, 17.79it/s, train_loss=0.00526, val_loss=0.00486]Epoch 17:  81%|████████  | 17/21 [00:00<00:00, 18.02it/s, train_loss=0.00526, val_loss=0.00486]Epoch 17:  81%|████████  | 17/21 [00:00<00:00, 17.95it/s, train_loss=0.00485, val_loss=0.00486]Epoch 17:  86%|████████▌ | 18/21 [00:00<00:00, 18.01it/s, train_loss=0.00485, val_loss=0.00486]Epoch 17:  86%|████████▌ | 18/21 [00:01<00:00, 17.87it/s, train_loss=0.00465, val_loss=0.00486]Epoch 17:  90%|█████████ | 19/21 [00:01<00:00, 18.30it/s, train_loss=0.00465, val_loss=0.00486]Epoch 17:  90%|█████████ | 19/21 [00:01<00:00, 18.05it/s, train_loss=0.00531, val_loss=0.00486]Epoch 17:  95%|█████████▌| 20/21 [00:01<00:00, 18.13it/s, train_loss=0.00531, val_loss=0.00486]Epoch 17:  95%|█████████▌| 20/21 [00:01<00:00, 18.09it/s, train_loss=0.00535, val_loss=0.00486]Epoch 17: 100%|██████████| 21/21 [00:01<00:00, 18.18it/s, train_loss=0.00535, val_loss=0.00486]Epoch 17: 100%|██████████| 21/21 [00:01<00:00, 18.10it/s, train_loss=0.00442, val_loss=0.00486]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 38.88it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 37.77it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 33.14it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 33.37it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 35.29it/s][A
                                                                      [AEpoch 17: 100%|██████████| 21/21 [00:01<00:00, 15.95it/s, train_loss=0.00442, val_loss=0.00479]Epoch 17: 100%|██████████| 21/21 [00:01<00:00, 15.94it/s, train_loss=0.00442, val_loss=0.00479]Epoch 17:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00442, val_loss=0.00479]         Epoch 18:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00442, val_loss=0.00479]Epoch 18:   5%|▍         | 1/21 [00:00<00:00, 26.47it/s, train_loss=0.00442, val_loss=0.00479]Epoch 18:   5%|▍         | 1/21 [00:00<00:00, 21.16it/s, train_loss=0.00508, val_loss=0.00479]Epoch 18:  10%|▉         | 2/21 [00:00<00:01, 18.21it/s, train_loss=0.00508, val_loss=0.00479]Epoch 18:  10%|▉         | 2/21 [00:00<00:01, 17.32it/s, train_loss=0.00551, val_loss=0.00479]Epoch 18:  14%|█▍        | 3/21 [00:00<00:00, 18.12it/s, train_loss=0.00551, val_loss=0.00479]Epoch 18:  14%|█▍        | 3/21 [00:00<00:01, 17.73it/s, train_loss=0.00479, val_loss=0.00479]Epoch 18:  19%|█▉        | 4/21 [00:00<00:00, 18.74it/s, train_loss=0.00479, val_loss=0.00479]Epoch 18:  19%|█▉        | 4/21 [00:00<00:00, 18.18it/s, train_loss=0.00515, val_loss=0.00479]Epoch 18:  24%|██▍       | 5/21 [00:00<00:00, 18.41it/s, train_loss=0.00515, val_loss=0.00479]Epoch 18:  24%|██▍       | 5/21 [00:00<00:00, 17.86it/s, train_loss=0.00542, val_loss=0.00479]Epoch 18:  29%|██▊       | 6/21 [00:00<00:00, 18.93it/s, train_loss=0.00542, val_loss=0.00479]Epoch 18:  29%|██▊       | 6/21 [00:00<00:00, 18.35it/s, train_loss=0.00498, val_loss=0.00479]Epoch 18:  33%|███▎      | 7/21 [00:00<00:00, 19.06it/s, train_loss=0.00498, val_loss=0.00479]Epoch 18:  33%|███▎      | 7/21 [00:00<00:00, 18.64it/s, train_loss=0.00487, val_loss=0.00479]Epoch 18:  38%|███▊      | 8/21 [00:00<00:00, 19.15it/s, train_loss=0.00487, val_loss=0.00479]Epoch 18:  38%|███▊      | 8/21 [00:00<00:00, 18.83it/s, train_loss=0.005, val_loss=0.00479]  Epoch 18:  43%|████▎     | 9/21 [00:00<00:00, 19.19it/s, train_loss=0.005, val_loss=0.00479]Epoch 18:  43%|████▎     | 9/21 [00:00<00:00, 18.87it/s, train_loss=0.00469, val_loss=0.00479]Epoch 18:  48%|████▊     | 10/21 [00:00<00:00, 18.95it/s, train_loss=0.00469, val_loss=0.00479]Epoch 18:  48%|████▊     | 10/21 [00:00<00:00, 18.76it/s, train_loss=0.00493, val_loss=0.00479]Epoch 18:  52%|█████▏    | 11/21 [00:00<00:00, 18.96it/s, train_loss=0.00493, val_loss=0.00479]Epoch 18:  52%|█████▏    | 11/21 [00:00<00:00, 18.78it/s, train_loss=0.00517, val_loss=0.00479]Epoch 18:  57%|█████▋    | 12/21 [00:00<00:00, 18.72it/s, train_loss=0.00517, val_loss=0.00479]Epoch 18:  57%|█████▋    | 12/21 [00:00<00:00, 18.61it/s, train_loss=0.0046, val_loss=0.00479] Epoch 18:  62%|██████▏   | 13/21 [00:00<00:00, 18.35it/s, train_loss=0.0046, val_loss=0.00479]Epoch 18:  62%|██████▏   | 13/21 [00:00<00:00, 18.24it/s, train_loss=0.00505, val_loss=0.00479]Epoch 18:  67%|██████▋   | 14/21 [00:00<00:00, 17.93it/s, train_loss=0.00505, val_loss=0.00479]Epoch 18:  67%|██████▋   | 14/21 [00:00<00:00, 17.81it/s, train_loss=0.00492, val_loss=0.00479]Epoch 18:  71%|███████▏  | 15/21 [00:00<00:00, 17.98it/s, train_loss=0.00492, val_loss=0.00479]Epoch 18:  71%|███████▏  | 15/21 [00:00<00:00, 17.80it/s, train_loss=0.00485, val_loss=0.00479]Epoch 18:  76%|███████▌  | 16/21 [00:00<00:00, 18.06it/s, train_loss=0.00485, val_loss=0.00479]Epoch 18:  76%|███████▌  | 16/21 [00:00<00:00, 17.87it/s, train_loss=0.00471, val_loss=0.00479]Epoch 18:  81%|████████  | 17/21 [00:00<00:00, 17.94it/s, train_loss=0.00471, val_loss=0.00479]Epoch 18:  81%|████████  | 17/21 [00:00<00:00, 17.89it/s, train_loss=0.00514, val_loss=0.00479]Epoch 18:  86%|████████▌ | 18/21 [00:01<00:00, 17.78it/s, train_loss=0.00514, val_loss=0.00479]Epoch 18:  86%|████████▌ | 18/21 [00:01<00:00, 17.59it/s, train_loss=0.00454, val_loss=0.00479]Epoch 18:  90%|█████████ | 19/21 [00:01<00:00, 17.81it/s, train_loss=0.00454, val_loss=0.00479]Epoch 18:  90%|█████████ | 19/21 [00:01<00:00, 17.65it/s, train_loss=0.00485, val_loss=0.00479]Epoch 18:  95%|█████████▌| 20/21 [00:01<00:00, 17.62it/s, train_loss=0.00485, val_loss=0.00479]Epoch 18:  95%|█████████▌| 20/21 [00:01<00:00, 17.52it/s, train_loss=0.00465, val_loss=0.00479]Epoch 18: 100%|██████████| 21/21 [00:01<00:00, 17.68it/s, train_loss=0.00465, val_loss=0.00479]Epoch 18: 100%|██████████| 21/21 [00:01<00:00, 17.64it/s, train_loss=0.00504, val_loss=0.00479]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 40.14it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 34.82it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 37.93it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 41.77it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 41.02it/s][A
                                                                      [AEpoch 18: 100%|██████████| 21/21 [00:01<00:00, 15.87it/s, train_loss=0.00504, val_loss=0.00464]Epoch 18: 100%|██████████| 21/21 [00:01<00:00, 15.85it/s, train_loss=0.00504, val_loss=0.00464]Epoch 18:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00504, val_loss=0.00464]         Epoch 19:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00504, val_loss=0.00464]Epoch 19:   5%|▍         | 1/21 [00:00<00:00, 22.70it/s, train_loss=0.00504, val_loss=0.00464]Epoch 19:   5%|▍         | 1/21 [00:00<00:01, 18.69it/s, train_loss=0.00513, val_loss=0.00464]Epoch 19:  10%|▉         | 2/21 [00:00<00:00, 20.65it/s, train_loss=0.00513, val_loss=0.00464]Epoch 19:  10%|▉         | 2/21 [00:00<00:00, 19.38it/s, train_loss=0.00467, val_loss=0.00464]Epoch 19:  14%|█▍        | 3/21 [00:00<00:00, 19.23it/s, train_loss=0.00467, val_loss=0.00464]Epoch 19:  14%|█▍        | 3/21 [00:00<00:00, 18.75it/s, train_loss=0.00489, val_loss=0.00464]Epoch 19:  19%|█▉        | 4/21 [00:00<00:00, 19.02it/s, train_loss=0.00489, val_loss=0.00464]Epoch 19:  19%|█▉        | 4/21 [00:00<00:00, 18.46it/s, train_loss=0.00499, val_loss=0.00464]Epoch 19:  24%|██▍       | 5/21 [00:00<00:00, 19.28it/s, train_loss=0.00499, val_loss=0.00464]Epoch 19:  24%|██▍       | 5/21 [00:00<00:00, 18.57it/s, train_loss=0.0049, val_loss=0.00464] Epoch 19:  29%|██▊       | 6/21 [00:00<00:00, 19.13it/s, train_loss=0.0049, val_loss=0.00464]Epoch 19:  29%|██▊       | 6/21 [00:00<00:00, 18.75it/s, train_loss=0.00475, val_loss=0.00464]Epoch 19:  33%|███▎      | 7/21 [00:00<00:00, 19.39it/s, train_loss=0.00475, val_loss=0.00464]Epoch 19:  33%|███▎      | 7/21 [00:00<00:00, 18.97it/s, train_loss=0.00489, val_loss=0.00464]Epoch 19:  38%|███▊      | 8/21 [00:00<00:00, 18.94it/s, train_loss=0.00489, val_loss=0.00464]Epoch 19:  38%|███▊      | 8/21 [00:00<00:00, 18.69it/s, train_loss=0.00472, val_loss=0.00464]Epoch 19:  43%|████▎     | 9/21 [00:00<00:00, 18.59it/s, train_loss=0.00472, val_loss=0.00464]Epoch 19:  43%|████▎     | 9/21 [00:00<00:00, 18.42it/s, train_loss=0.00494, val_loss=0.00464]Epoch 19:  48%|████▊     | 10/21 [00:00<00:00, 18.80it/s, train_loss=0.00494, val_loss=0.00464]Epoch 19:  48%|████▊     | 10/21 [00:00<00:00, 18.55it/s, train_loss=0.00503, val_loss=0.00464]Epoch 19:  52%|█████▏    | 11/21 [00:00<00:00, 18.44it/s, train_loss=0.00503, val_loss=0.00464]Epoch 19:  52%|█████▏    | 11/21 [00:00<00:00, 18.29it/s, train_loss=0.005, val_loss=0.00464]  Epoch 19:  57%|█████▋    | 12/21 [00:00<00:00, 18.48it/s, train_loss=0.005, val_loss=0.00464]Epoch 19:  57%|█████▋    | 12/21 [00:00<00:00, 18.26it/s, train_loss=0.00488, val_loss=0.00464]Epoch 19:  62%|██████▏   | 13/21 [00:00<00:00, 18.88it/s, train_loss=0.00488, val_loss=0.00464]Epoch 19:  62%|██████▏   | 13/21 [00:00<00:00, 18.44it/s, train_loss=0.00468, val_loss=0.00464]Epoch 19:  67%|██████▋   | 14/21 [00:00<00:00, 18.13it/s, train_loss=0.00468, val_loss=0.00464]Epoch 19:  67%|██████▋   | 14/21 [00:00<00:00, 17.97it/s, train_loss=0.00481, val_loss=0.00464]Epoch 19:  71%|███████▏  | 15/21 [00:00<00:00, 18.39it/s, train_loss=0.00481, val_loss=0.00464]Epoch 19:  71%|███████▏  | 15/21 [00:00<00:00, 18.13it/s, train_loss=0.00471, val_loss=0.00464]Epoch 19:  76%|███████▌  | 16/21 [00:00<00:00, 18.42it/s, train_loss=0.00471, val_loss=0.00464]Epoch 19:  76%|███████▌  | 16/21 [00:00<00:00, 18.21it/s, train_loss=0.00437, val_loss=0.00464]Epoch 19:  81%|████████  | 17/21 [00:00<00:00, 18.55it/s, train_loss=0.00437, val_loss=0.00464]Epoch 19:  81%|████████  | 17/21 [00:00<00:00, 18.41it/s, train_loss=0.00473, val_loss=0.00464]Epoch 19:  86%|████████▌ | 18/21 [00:00<00:00, 18.42it/s, train_loss=0.00473, val_loss=0.00464]Epoch 19:  86%|████████▌ | 18/21 [00:00<00:00, 18.31it/s, train_loss=0.005, val_loss=0.00464]  Epoch 19:  90%|█████████ | 19/21 [00:01<00:00, 18.51it/s, train_loss=0.005, val_loss=0.00464]Epoch 19:  90%|█████████ | 19/21 [00:01<00:00, 18.36it/s, train_loss=0.005, val_loss=0.00464]Epoch 19:  95%|█████████▌| 20/21 [00:01<00:00, 18.39it/s, train_loss=0.005, val_loss=0.00464]Epoch 19:  95%|█████████▌| 20/21 [00:01<00:00, 18.29it/s, train_loss=0.00493, val_loss=0.00464]Epoch 19: 100%|██████████| 21/21 [00:01<00:00, 18.30it/s, train_loss=0.00493, val_loss=0.00464]Epoch 19: 100%|██████████| 21/21 [00:01<00:00, 18.28it/s, train_loss=0.00499, val_loss=0.00464]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 40.73it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 40.96it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 41.73it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 41.90it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 42.68it/s][A
                                                                      [AEpoch 19: 100%|██████████| 21/21 [00:01<00:00, 16.45it/s, train_loss=0.00499, val_loss=0.00447]Epoch 19: 100%|██████████| 21/21 [00:01<00:00, 16.43it/s, train_loss=0.00499, val_loss=0.00447]Epoch 19:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00499, val_loss=0.00447]         Epoch 20:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00499, val_loss=0.00447]Epoch 20:   5%|▍         | 1/21 [00:00<00:01, 19.75it/s, train_loss=0.00499, val_loss=0.00447]Epoch 20:   5%|▍         | 1/21 [00:00<00:01, 16.30it/s, train_loss=0.00449, val_loss=0.00447]Epoch 20:  10%|▉         | 2/21 [00:00<00:01, 17.43it/s, train_loss=0.00449, val_loss=0.00447]Epoch 20:  10%|▉         | 2/21 [00:00<00:01, 16.42it/s, train_loss=0.00432, val_loss=0.00447]Epoch 20:  14%|█▍        | 3/21 [00:00<00:01, 17.90it/s, train_loss=0.00432, val_loss=0.00447]Epoch 20:  14%|█▍        | 3/21 [00:00<00:01, 17.13it/s, train_loss=0.00505, val_loss=0.00447]Epoch 20:  19%|█▉        | 4/21 [00:00<00:00, 17.86it/s, train_loss=0.00505, val_loss=0.00447]Epoch 20:  19%|█▉        | 4/21 [00:00<00:00, 17.57it/s, train_loss=0.00464, val_loss=0.00447]Epoch 20:  24%|██▍       | 5/21 [00:00<00:00, 17.77it/s, train_loss=0.00464, val_loss=0.00447]Epoch 20:  24%|██▍       | 5/21 [00:00<00:00, 17.39it/s, train_loss=0.00495, val_loss=0.00447]Epoch 20:  29%|██▊       | 6/21 [00:00<00:00, 17.04it/s, train_loss=0.00495, val_loss=0.00447]Epoch 20:  29%|██▊       | 6/21 [00:00<00:00, 16.82it/s, train_loss=0.00481, val_loss=0.00447]Epoch 20:  33%|███▎      | 7/21 [00:00<00:00, 17.06it/s, train_loss=0.00481, val_loss=0.00447]Epoch 20:  33%|███▎      | 7/21 [00:00<00:00, 16.62it/s, train_loss=0.00481, val_loss=0.00447]Epoch 20:  38%|███▊      | 8/21 [00:00<00:00, 16.78it/s, train_loss=0.00481, val_loss=0.00447]Epoch 20:  38%|███▊      | 8/21 [00:00<00:00, 16.36it/s, train_loss=0.0047, val_loss=0.00447] Epoch 20:  43%|████▎     | 9/21 [00:00<00:00, 16.81it/s, train_loss=0.0047, val_loss=0.00447]Epoch 20:  43%|████▎     | 9/21 [00:00<00:00, 16.62it/s, train_loss=0.00463, val_loss=0.00447]Epoch 20:  48%|████▊     | 10/21 [00:00<00:00, 17.28it/s, train_loss=0.00463, val_loss=0.00447]Epoch 20:  48%|████▊     | 10/21 [00:00<00:00, 16.94it/s, train_loss=0.00461, val_loss=0.00447]Epoch 20:  52%|█████▏    | 11/21 [00:00<00:00, 17.06it/s, train_loss=0.00461, val_loss=0.00447]Epoch 20:  52%|█████▏    | 11/21 [00:00<00:00, 16.97it/s, train_loss=0.00469, val_loss=0.00447]Epoch 20:  57%|█████▋    | 12/21 [00:00<00:00, 17.17it/s, train_loss=0.00469, val_loss=0.00447]Epoch 20:  57%|█████▋    | 12/21 [00:00<00:00, 16.95it/s, train_loss=0.00447, val_loss=0.00447]Epoch 20:  62%|██████▏   | 13/21 [00:00<00:00, 17.24it/s, train_loss=0.00447, val_loss=0.00447]Epoch 20:  62%|██████▏   | 13/21 [00:00<00:00, 17.11it/s, train_loss=0.00472, val_loss=0.00447]Epoch 20:  67%|██████▋   | 14/21 [00:00<00:00, 17.12it/s, train_loss=0.00472, val_loss=0.00447]Epoch 20:  67%|██████▋   | 14/21 [00:00<00:00, 17.08it/s, train_loss=0.00477, val_loss=0.00447]Epoch 20:  71%|███████▏  | 15/21 [00:00<00:00, 17.25it/s, train_loss=0.00477, val_loss=0.00447]Epoch 20:  71%|███████▏  | 15/21 [00:00<00:00, 17.12it/s, train_loss=0.00448, val_loss=0.00447]Epoch 20:  76%|███████▌  | 16/21 [00:00<00:00, 17.04it/s, train_loss=0.00448, val_loss=0.00447]Epoch 20:  76%|███████▌  | 16/21 [00:00<00:00, 16.92it/s, train_loss=0.00468, val_loss=0.00447]Epoch 20:  81%|████████  | 17/21 [00:00<00:00, 17.14it/s, train_loss=0.00468, val_loss=0.00447]Epoch 20:  81%|████████  | 17/21 [00:01<00:00, 16.96it/s, train_loss=0.00502, val_loss=0.00447]Epoch 20:  86%|████████▌ | 18/21 [00:01<00:00, 17.27it/s, train_loss=0.00502, val_loss=0.00447]Epoch 20:  86%|████████▌ | 18/21 [00:01<00:00, 17.10it/s, train_loss=0.00498, val_loss=0.00447]Epoch 20:  90%|█████████ | 19/21 [00:01<00:00, 17.12it/s, train_loss=0.00498, val_loss=0.00447]Epoch 20:  90%|█████████ | 19/21 [00:01<00:00, 16.99it/s, train_loss=0.00427, val_loss=0.00447]Epoch 20:  95%|█████████▌| 20/21 [00:01<00:00, 17.10it/s, train_loss=0.00427, val_loss=0.00447]Epoch 20:  95%|█████████▌| 20/21 [00:01<00:00, 17.05it/s, train_loss=0.00469, val_loss=0.00447]Epoch 20: 100%|██████████| 21/21 [00:01<00:00, 17.03it/s, train_loss=0.00469, val_loss=0.00447]Epoch 20: 100%|██████████| 21/21 [00:01<00:00, 17.01it/s, train_loss=0.0042, val_loss=0.00447] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 45.18it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 40.52it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 41.15it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 43.70it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 44.61it/s][A
                                                                      [AEpoch 20: 100%|██████████| 21/21 [00:01<00:00, 15.27it/s, train_loss=0.0042, val_loss=0.00443]Epoch 20: 100%|██████████| 21/21 [00:01<00:00, 15.26it/s, train_loss=0.0042, val_loss=0.00443]Epoch 20:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0042, val_loss=0.00443]         Epoch 21:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0042, val_loss=0.00443]Epoch 21:   5%|▍         | 1/21 [00:00<00:01, 18.43it/s, train_loss=0.0042, val_loss=0.00443]Epoch 21:   5%|▍         | 1/21 [00:00<00:01, 16.36it/s, train_loss=0.00485, val_loss=0.00443]Epoch 21:  10%|▉         | 2/21 [00:00<00:01, 15.73it/s, train_loss=0.00485, val_loss=0.00443]Epoch 21:  10%|▉         | 2/21 [00:00<00:01, 15.06it/s, train_loss=0.00477, val_loss=0.00443]Epoch 21:  14%|█▍        | 3/21 [00:00<00:01, 16.26it/s, train_loss=0.00477, val_loss=0.00443]Epoch 21:  14%|█▍        | 3/21 [00:00<00:01, 15.36it/s, train_loss=0.00443, val_loss=0.00443]Epoch 21:  19%|█▉        | 4/21 [00:00<00:01, 16.02it/s, train_loss=0.00443, val_loss=0.00443]Epoch 21:  19%|█▉        | 4/21 [00:00<00:01, 15.22it/s, train_loss=0.00454, val_loss=0.00443]Epoch 21:  24%|██▍       | 5/21 [00:00<00:00, 16.64it/s, train_loss=0.00454, val_loss=0.00443]Epoch 21:  24%|██▍       | 5/21 [00:00<00:01, 15.99it/s, train_loss=0.00459, val_loss=0.00443]Epoch 21:  29%|██▊       | 6/21 [00:00<00:00, 17.22it/s, train_loss=0.00459, val_loss=0.00443]Epoch 21:  29%|██▊       | 6/21 [00:00<00:00, 16.57it/s, train_loss=0.00437, val_loss=0.00443]Epoch 21:  33%|███▎      | 7/21 [00:00<00:00, 16.47it/s, train_loss=0.00437, val_loss=0.00443]Epoch 21:  33%|███▎      | 7/21 [00:00<00:00, 16.17it/s, train_loss=0.00485, val_loss=0.00443]Epoch 21:  38%|███▊      | 8/21 [00:00<00:00, 16.49it/s, train_loss=0.00485, val_loss=0.00443]Epoch 21:  38%|███▊      | 8/21 [00:00<00:00, 16.16it/s, train_loss=0.00441, val_loss=0.00443]Epoch 21:  43%|████▎     | 9/21 [00:00<00:00, 16.23it/s, train_loss=0.00441, val_loss=0.00443]Epoch 21:  43%|████▎     | 9/21 [00:00<00:00, 16.20it/s, train_loss=0.00446, val_loss=0.00443]Epoch 21:  48%|████▊     | 10/21 [00:00<00:00, 16.33it/s, train_loss=0.00446, val_loss=0.00443]Epoch 21:  48%|████▊     | 10/21 [00:00<00:00, 16.19it/s, train_loss=0.00448, val_loss=0.00443]Epoch 21:  52%|█████▏    | 11/21 [00:00<00:00, 15.74it/s, train_loss=0.00448, val_loss=0.00443]Epoch 21:  52%|█████▏    | 11/21 [00:00<00:00, 15.52it/s, train_loss=0.00451, val_loss=0.00443]Epoch 21:  57%|█████▋    | 12/21 [00:00<00:00, 15.75it/s, train_loss=0.00451, val_loss=0.00443]Epoch 21:  57%|█████▋    | 12/21 [00:00<00:00, 15.61it/s, train_loss=0.00465, val_loss=0.00443]Epoch 21:  62%|██████▏   | 13/21 [00:00<00:00, 16.12it/s, train_loss=0.00465, val_loss=0.00443]Epoch 21:  62%|██████▏   | 13/21 [00:00<00:00, 15.91it/s, train_loss=0.00445, val_loss=0.00443]Epoch 21:  67%|██████▋   | 14/21 [00:00<00:00, 15.97it/s, train_loss=0.00445, val_loss=0.00443]Epoch 21:  67%|██████▋   | 14/21 [00:00<00:00, 15.92it/s, train_loss=0.00457, val_loss=0.00443]Epoch 21:  71%|███████▏  | 15/21 [00:00<00:00, 16.02it/s, train_loss=0.00457, val_loss=0.00443]Epoch 21:  71%|███████▏  | 15/21 [00:00<00:00, 15.84it/s, train_loss=0.00468, val_loss=0.00443]Epoch 21:  76%|███████▌  | 16/21 [00:00<00:00, 16.08it/s, train_loss=0.00468, val_loss=0.00443]Epoch 21:  76%|███████▌  | 16/21 [00:01<00:00, 15.94it/s, train_loss=0.00459, val_loss=0.00443]Epoch 21:  81%|████████  | 17/21 [00:01<00:00, 16.28it/s, train_loss=0.00459, val_loss=0.00443]Epoch 21:  81%|████████  | 17/21 [00:01<00:00, 16.15it/s, train_loss=0.0045, val_loss=0.00443] Epoch 21:  86%|████████▌ | 18/21 [00:01<00:00, 16.30it/s, train_loss=0.0045, val_loss=0.00443]Epoch 21:  86%|████████▌ | 18/21 [00:01<00:00, 16.18it/s, train_loss=0.00458, val_loss=0.00443]Epoch 21:  90%|█████████ | 19/21 [00:01<00:00, 16.37it/s, train_loss=0.00458, val_loss=0.00443]Epoch 21:  90%|█████████ | 19/21 [00:01<00:00, 16.26it/s, train_loss=0.00469, val_loss=0.00443]Epoch 21:  95%|█████████▌| 20/21 [00:01<00:00, 16.18it/s, train_loss=0.00469, val_loss=0.00443]Epoch 21:  95%|█████████▌| 20/21 [00:01<00:00, 16.13it/s, train_loss=0.00453, val_loss=0.00443]Epoch 21: 100%|██████████| 21/21 [00:01<00:00, 16.24it/s, train_loss=0.00453, val_loss=0.00443]Epoch 21: 100%|██████████| 21/21 [00:01<00:00, 16.23it/s, train_loss=0.00414, val_loss=0.00443]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 26.55it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 39.23it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 35.52it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 38.94it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 41.70it/s][A
                                                                      [AEpoch 21: 100%|██████████| 21/21 [00:01<00:00, 14.75it/s, train_loss=0.00414, val_loss=0.00429]Epoch 21: 100%|██████████| 21/21 [00:01<00:00, 14.74it/s, train_loss=0.00414, val_loss=0.00429]Epoch 21:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00414, val_loss=0.00429]         Epoch 22:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00414, val_loss=0.00429]Epoch 22:   5%|▍         | 1/21 [00:00<00:00, 24.59it/s, train_loss=0.00414, val_loss=0.00429]Epoch 22:   5%|▍         | 1/21 [00:00<00:01, 19.88it/s, train_loss=0.00456, val_loss=0.00429]Epoch 22:  10%|▉         | 2/21 [00:00<00:01, 17.54it/s, train_loss=0.00456, val_loss=0.00429]Epoch 22:  10%|▉         | 2/21 [00:00<00:01, 16.75it/s, train_loss=0.00407, val_loss=0.00429]Epoch 22:  14%|█▍        | 3/21 [00:00<00:00, 18.17it/s, train_loss=0.00407, val_loss=0.00429]Epoch 22:  14%|█▍        | 3/21 [00:00<00:01, 17.50it/s, train_loss=0.00452, val_loss=0.00429]Epoch 22:  19%|█▉        | 4/21 [00:00<00:00, 19.03it/s, train_loss=0.00452, val_loss=0.00429]Epoch 22:  19%|█▉        | 4/21 [00:00<00:00, 18.31it/s, train_loss=0.00465, val_loss=0.00429]Epoch 22:  24%|██▍       | 5/21 [00:00<00:00, 18.32it/s, train_loss=0.00465, val_loss=0.00429]Epoch 22:  24%|██▍       | 5/21 [00:00<00:00, 17.84it/s, train_loss=0.00443, val_loss=0.00429]Epoch 22:  29%|██▊       | 6/21 [00:00<00:00, 18.31it/s, train_loss=0.00443, val_loss=0.00429]Epoch 22:  29%|██▊       | 6/21 [00:00<00:00, 18.04it/s, train_loss=0.00459, val_loss=0.00429]Epoch 22:  33%|███▎      | 7/21 [00:00<00:00, 17.94it/s, train_loss=0.00459, val_loss=0.00429]Epoch 22:  33%|███▎      | 7/21 [00:00<00:00, 17.70it/s, train_loss=0.00429, val_loss=0.00429]Epoch 22:  38%|███▊      | 8/21 [00:00<00:00, 17.56it/s, train_loss=0.00429, val_loss=0.00429]Epoch 22:  38%|███▊      | 8/21 [00:00<00:00, 17.23it/s, train_loss=0.0047, val_loss=0.00429] Epoch 22:  43%|████▎     | 9/21 [00:00<00:00, 17.49it/s, train_loss=0.0047, val_loss=0.00429]Epoch 22:  43%|████▎     | 9/21 [00:00<00:00, 17.31it/s, train_loss=0.00411, val_loss=0.00429]Epoch 22:  48%|████▊     | 10/21 [00:00<00:00, 18.01it/s, train_loss=0.00411, val_loss=0.00429]Epoch 22:  48%|████▊     | 10/21 [00:00<00:00, 17.62it/s, train_loss=0.00476, val_loss=0.00429]Epoch 22:  52%|█████▏    | 11/21 [00:00<00:00, 17.67it/s, train_loss=0.00476, val_loss=0.00429]Epoch 22:  52%|█████▏    | 11/21 [00:00<00:00, 17.56it/s, train_loss=0.00435, val_loss=0.00429]Epoch 22:  57%|█████▋    | 12/21 [00:00<00:00, 17.75it/s, train_loss=0.00435, val_loss=0.00429]Epoch 22:  57%|█████▋    | 12/21 [00:00<00:00, 17.58it/s, train_loss=0.00455, val_loss=0.00429]Epoch 22:  62%|██████▏   | 13/21 [00:00<00:00, 17.97it/s, train_loss=0.00455, val_loss=0.00429]Epoch 22:  62%|██████▏   | 13/21 [00:00<00:00, 17.73it/s, train_loss=0.00458, val_loss=0.00429]Epoch 22:  67%|██████▋   | 14/21 [00:00<00:00, 18.01it/s, train_loss=0.00458, val_loss=0.00429]Epoch 22:  67%|██████▋   | 14/21 [00:00<00:00, 17.77it/s, train_loss=0.00453, val_loss=0.00429]Epoch 22:  71%|███████▏  | 15/21 [00:00<00:00, 18.03it/s, train_loss=0.00453, val_loss=0.00429]Epoch 22:  71%|███████▏  | 15/21 [00:00<00:00, 17.82it/s, train_loss=0.00426, val_loss=0.00429]Epoch 22:  76%|███████▌  | 16/21 [00:00<00:00, 17.70it/s, train_loss=0.00426, val_loss=0.00429]Epoch 22:  76%|███████▌  | 16/21 [00:00<00:00, 17.65it/s, train_loss=0.00435, val_loss=0.00429]Epoch 22:  81%|████████  | 17/21 [00:00<00:00, 17.81it/s, train_loss=0.00435, val_loss=0.00429]Epoch 22:  81%|████████  | 17/21 [00:00<00:00, 17.63it/s, train_loss=0.00454, val_loss=0.00429]Epoch 22:  86%|████████▌ | 18/21 [00:01<00:00, 17.69it/s, train_loss=0.00454, val_loss=0.00429]Epoch 22:  86%|████████▌ | 18/21 [00:01<00:00, 17.55it/s, train_loss=0.00439, val_loss=0.00429]Epoch 22:  90%|█████████ | 19/21 [00:01<00:00, 17.62it/s, train_loss=0.00439, val_loss=0.00429]Epoch 22:  90%|█████████ | 19/21 [00:01<00:00, 17.41it/s, train_loss=0.00415, val_loss=0.00429]Epoch 22:  95%|█████████▌| 20/21 [00:01<00:00, 17.71it/s, train_loss=0.00415, val_loss=0.00429]Epoch 22:  95%|█████████▌| 20/21 [00:01<00:00, 17.56it/s, train_loss=0.00425, val_loss=0.00429]Epoch 22: 100%|██████████| 21/21 [00:01<00:00, 17.44it/s, train_loss=0.00425, val_loss=0.00429]Epoch 22: 100%|██████████| 21/21 [00:01<00:00, 17.40it/s, train_loss=0.00458, val_loss=0.00429]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 43.26it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 47.10it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 43.10it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 39.37it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 39.56it/s][A
                                                                      [AEpoch 22: 100%|██████████| 21/21 [00:01<00:00, 15.60it/s, train_loss=0.00458, val_loss=0.00424]Epoch 22: 100%|██████████| 21/21 [00:01<00:00, 15.58it/s, train_loss=0.00458, val_loss=0.00424]Epoch 22:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00458, val_loss=0.00424]         Epoch 23:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00458, val_loss=0.00424]Epoch 23:   5%|▍         | 1/21 [00:00<00:01, 19.30it/s, train_loss=0.00458, val_loss=0.00424]Epoch 23:   5%|▍         | 1/21 [00:00<00:01, 17.42it/s, train_loss=0.0046, val_loss=0.00424] Epoch 23:  10%|▉         | 2/21 [00:00<00:00, 20.22it/s, train_loss=0.0046, val_loss=0.00424]Epoch 23:  10%|▉         | 2/21 [00:00<00:01, 18.56it/s, train_loss=0.00415, val_loss=0.00424]Epoch 23:  14%|█▍        | 3/21 [00:00<00:00, 19.23it/s, train_loss=0.00415, val_loss=0.00424]Epoch 23:  14%|█▍        | 3/21 [00:00<00:00, 18.58it/s, train_loss=0.00448, val_loss=0.00424]Epoch 23:  19%|█▉        | 4/21 [00:00<00:00, 18.39it/s, train_loss=0.00448, val_loss=0.00424]Epoch 23:  19%|█▉        | 4/21 [00:00<00:00, 17.88it/s, train_loss=0.00429, val_loss=0.00424]Epoch 23:  24%|██▍       | 5/21 [00:00<00:00, 17.50it/s, train_loss=0.00429, val_loss=0.00424]Epoch 23:  24%|██▍       | 5/21 [00:00<00:00, 17.11it/s, train_loss=0.00428, val_loss=0.00424]Epoch 23:  29%|██▊       | 6/21 [00:00<00:00, 17.03it/s, train_loss=0.00428, val_loss=0.00424]Epoch 23:  29%|██▊       | 6/21 [00:00<00:00, 16.78it/s, train_loss=0.00438, val_loss=0.00424]Epoch 23:  33%|███▎      | 7/21 [00:00<00:00, 16.94it/s, train_loss=0.00438, val_loss=0.00424]Epoch 23:  33%|███▎      | 7/21 [00:00<00:00, 16.80it/s, train_loss=0.00419, val_loss=0.00424]Epoch 23:  38%|███▊      | 8/21 [00:00<00:00, 17.45it/s, train_loss=0.00419, val_loss=0.00424]Epoch 23:  38%|███▊      | 8/21 [00:00<00:00, 17.06it/s, train_loss=0.00421, val_loss=0.00424]Epoch 23:  43%|████▎     | 9/21 [00:00<00:00, 17.53it/s, train_loss=0.00421, val_loss=0.00424]Epoch 23:  43%|████▎     | 9/21 [00:00<00:00, 17.33it/s, train_loss=0.00438, val_loss=0.00424]Epoch 23:  48%|████▊     | 10/21 [00:00<00:00, 17.72it/s, train_loss=0.00438, val_loss=0.00424]Epoch 23:  48%|████▊     | 10/21 [00:00<00:00, 17.55it/s, train_loss=0.00458, val_loss=0.00424]Epoch 23:  52%|█████▏    | 11/21 [00:00<00:00, 17.93it/s, train_loss=0.00458, val_loss=0.00424]Epoch 23:  52%|█████▏    | 11/21 [00:00<00:00, 17.66it/s, train_loss=0.00423, val_loss=0.00424]Epoch 23:  57%|█████▋    | 12/21 [00:00<00:00, 17.67it/s, train_loss=0.00423, val_loss=0.00424]Epoch 23:  57%|█████▋    | 12/21 [00:00<00:00, 17.52it/s, train_loss=0.00433, val_loss=0.00424]Epoch 23:  62%|██████▏   | 13/21 [00:00<00:00, 17.41it/s, train_loss=0.00433, val_loss=0.00424]Epoch 23:  62%|██████▏   | 13/21 [00:00<00:00, 17.32it/s, train_loss=0.00451, val_loss=0.00424]Epoch 23:  67%|██████▋   | 14/21 [00:00<00:00, 17.56it/s, train_loss=0.00451, val_loss=0.00424]Epoch 23:  67%|██████▋   | 14/21 [00:00<00:00, 17.29it/s, train_loss=0.00455, val_loss=0.00424]Epoch 23:  71%|███████▏  | 15/21 [00:00<00:00, 17.13it/s, train_loss=0.00455, val_loss=0.00424]Epoch 23:  71%|███████▏  | 15/21 [00:00<00:00, 17.00it/s, train_loss=0.00449, val_loss=0.00424]Epoch 23:  76%|███████▌  | 16/21 [00:00<00:00, 17.34it/s, train_loss=0.00449, val_loss=0.00424]Epoch 23:  76%|███████▌  | 16/21 [00:00<00:00, 17.17it/s, train_loss=0.00451, val_loss=0.00424]Epoch 23:  81%|████████  | 17/21 [00:00<00:00, 17.58it/s, train_loss=0.00451, val_loss=0.00424]Epoch 23:  81%|████████  | 17/21 [00:00<00:00, 17.34it/s, train_loss=0.00467, val_loss=0.00424]Epoch 23:  86%|████████▌ | 18/21 [00:01<00:00, 17.24it/s, train_loss=0.00467, val_loss=0.00424]Epoch 23:  86%|████████▌ | 18/21 [00:01<00:00, 17.18it/s, train_loss=0.00423, val_loss=0.00424]Epoch 23:  90%|█████████ | 19/21 [00:01<00:00, 17.31it/s, train_loss=0.00423, val_loss=0.00424]Epoch 23:  90%|█████████ | 19/21 [00:01<00:00, 17.26it/s, train_loss=0.00418, val_loss=0.00424]Epoch 23:  95%|█████████▌| 20/21 [00:01<00:00, 17.47it/s, train_loss=0.00418, val_loss=0.00424]Epoch 23:  95%|█████████▌| 20/21 [00:01<00:00, 17.38it/s, train_loss=0.00404, val_loss=0.00424]Epoch 23: 100%|██████████| 21/21 [00:01<00:00, 17.43it/s, train_loss=0.00404, val_loss=0.00424]Epoch 23: 100%|██████████| 21/21 [00:01<00:00, 17.38it/s, train_loss=0.00435, val_loss=0.00424]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 35.48it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 44.08it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 45.14it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 44.67it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 41.40it/s][A
                                                                      [AEpoch 23: 100%|██████████| 21/21 [00:01<00:00, 15.68it/s, train_loss=0.00435, val_loss=0.00421]Epoch 23: 100%|██████████| 21/21 [00:01<00:00, 15.67it/s, train_loss=0.00435, val_loss=0.00421]Epoch 23:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00435, val_loss=0.00421]         Epoch 24:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00435, val_loss=0.00421]Epoch 24:   5%|▍         | 1/21 [00:00<00:01, 19.56it/s, train_loss=0.00435, val_loss=0.00421]Epoch 24:   5%|▍         | 1/21 [00:00<00:01, 16.21it/s, train_loss=0.00451, val_loss=0.00421]Epoch 24:  10%|▉         | 2/21 [00:00<00:01, 17.94it/s, train_loss=0.00451, val_loss=0.00421]Epoch 24:  10%|▉         | 2/21 [00:00<00:01, 17.05it/s, train_loss=0.00425, val_loss=0.00421]Epoch 24:  14%|█▍        | 3/21 [00:00<00:00, 18.19it/s, train_loss=0.00425, val_loss=0.00421]Epoch 24:  14%|█▍        | 3/21 [00:00<00:01, 17.69it/s, train_loss=0.00438, val_loss=0.00421]Epoch 24:  19%|█▉        | 4/21 [00:00<00:00, 18.32it/s, train_loss=0.00438, val_loss=0.00421]Epoch 24:  19%|█▉        | 4/21 [00:00<00:00, 17.57it/s, train_loss=0.00436, val_loss=0.00421]Epoch 24:  24%|██▍       | 5/21 [00:00<00:00, 17.79it/s, train_loss=0.00436, val_loss=0.00421]Epoch 24:  24%|██▍       | 5/21 [00:00<00:00, 17.22it/s, train_loss=0.0042, val_loss=0.00421] Epoch 24:  29%|██▊       | 6/21 [00:00<00:00, 18.21it/s, train_loss=0.0042, val_loss=0.00421]Epoch 24:  29%|██▊       | 6/21 [00:00<00:00, 17.67it/s, train_loss=0.004, val_loss=0.00421] Epoch 24:  33%|███▎      | 7/21 [00:00<00:00, 17.94it/s, train_loss=0.004, val_loss=0.00421]Epoch 24:  33%|███▎      | 7/21 [00:00<00:00, 17.55it/s, train_loss=0.00418, val_loss=0.00421]Epoch 24:  38%|███▊      | 8/21 [00:00<00:00, 17.82it/s, train_loss=0.00418, val_loss=0.00421]Epoch 24:  38%|███▊      | 8/21 [00:00<00:00, 17.52it/s, train_loss=0.00432, val_loss=0.00421]Epoch 24:  43%|████▎     | 9/21 [00:00<00:00, 16.73it/s, train_loss=0.00432, val_loss=0.00421]Epoch 24:  43%|████▎     | 9/21 [00:00<00:00, 16.50it/s, train_loss=0.00458, val_loss=0.00421]Epoch 24:  48%|████▊     | 10/21 [00:00<00:00, 16.29it/s, train_loss=0.00458, val_loss=0.00421]Epoch 24:  48%|████▊     | 10/21 [00:00<00:00, 16.16it/s, train_loss=0.00424, val_loss=0.00421]Epoch 24:  52%|█████▏    | 11/21 [00:00<00:00, 16.35it/s, train_loss=0.00424, val_loss=0.00421]Epoch 24:  52%|█████▏    | 11/21 [00:00<00:00, 16.08it/s, train_loss=0.0043, val_loss=0.00421] Epoch 24:  57%|█████▋    | 12/21 [00:00<00:00, 16.61it/s, train_loss=0.0043, val_loss=0.00421]Epoch 24:  57%|█████▋    | 12/21 [00:00<00:00, 16.37it/s, train_loss=0.00437, val_loss=0.00421]Epoch 24:  62%|██████▏   | 13/21 [00:00<00:00, 16.41it/s, train_loss=0.00437, val_loss=0.00421]Epoch 24:  62%|██████▏   | 13/21 [00:00<00:00, 16.31it/s, train_loss=0.00406, val_loss=0.00421]Epoch 24:  67%|██████▋   | 14/21 [00:00<00:00, 16.58it/s, train_loss=0.00406, val_loss=0.00421]Epoch 24:  67%|██████▋   | 14/21 [00:00<00:00, 16.43it/s, train_loss=0.00441, val_loss=0.00421]Epoch 24:  71%|███████▏  | 15/21 [00:00<00:00, 16.45it/s, train_loss=0.00441, val_loss=0.00421]Epoch 24:  71%|███████▏  | 15/21 [00:00<00:00, 16.38it/s, train_loss=0.0043, val_loss=0.00421] Epoch 24:  76%|███████▌  | 16/21 [00:00<00:00, 16.44it/s, train_loss=0.0043, val_loss=0.00421]Epoch 24:  76%|███████▌  | 16/21 [00:00<00:00, 16.33it/s, train_loss=0.00427, val_loss=0.00421]Epoch 24:  81%|████████  | 17/21 [00:01<00:00, 16.41it/s, train_loss=0.00427, val_loss=0.00421]Epoch 24:  81%|████████  | 17/21 [00:01<00:00, 16.31it/s, train_loss=0.00409, val_loss=0.00421]Epoch 24:  86%|████████▌ | 18/21 [00:01<00:00, 16.24it/s, train_loss=0.00409, val_loss=0.00421]Epoch 24:  86%|████████▌ | 18/21 [00:01<00:00, 16.11it/s, train_loss=0.00433, val_loss=0.00421]Epoch 24:  90%|█████████ | 19/21 [00:01<00:00, 16.31it/s, train_loss=0.00433, val_loss=0.00421]Epoch 24:  90%|█████████ | 19/21 [00:01<00:00, 16.18it/s, train_loss=0.00416, val_loss=0.00421]Epoch 24:  95%|█████████▌| 20/21 [00:01<00:00, 16.39it/s, train_loss=0.00416, val_loss=0.00421]Epoch 24:  95%|█████████▌| 20/21 [00:01<00:00, 16.28it/s, train_loss=0.00434, val_loss=0.00421]Epoch 24: 100%|██████████| 21/21 [00:01<00:00, 16.27it/s, train_loss=0.00434, val_loss=0.00421]Epoch 24: 100%|██████████| 21/21 [00:01<00:00, 16.26it/s, train_loss=0.00408, val_loss=0.00421]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 31.75it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 37.19it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 40.87it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 44.18it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 45.07it/s][A
                                                                      [AEpoch 24: 100%|██████████| 21/21 [00:01<00:00, 14.87it/s, train_loss=0.00408, val_loss=0.00411]Epoch 24: 100%|██████████| 21/21 [00:01<00:00, 14.86it/s, train_loss=0.00408, val_loss=0.00411]Epoch 24:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00408, val_loss=0.00411]         Epoch 25:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00408, val_loss=0.00411]Epoch 25:   5%|▍         | 1/21 [00:00<00:00, 24.25it/s, train_loss=0.00408, val_loss=0.00411]Epoch 25:   5%|▍         | 1/21 [00:00<00:01, 18.88it/s, train_loss=0.00425, val_loss=0.00411]Epoch 25:  10%|▉         | 2/21 [00:00<00:00, 20.79it/s, train_loss=0.00425, val_loss=0.00411]Epoch 25:  10%|▉         | 2/21 [00:00<00:00, 19.35it/s, train_loss=0.00416, val_loss=0.00411]Epoch 25:  14%|█▍        | 3/21 [00:00<00:00, 18.76it/s, train_loss=0.00416, val_loss=0.00411]Epoch 25:  14%|█▍        | 3/21 [00:00<00:00, 18.02it/s, train_loss=0.00397, val_loss=0.00411]Epoch 25:  19%|█▉        | 4/21 [00:00<00:00, 17.86it/s, train_loss=0.00397, val_loss=0.00411]Epoch 25:  19%|█▉        | 4/21 [00:00<00:00, 17.40it/s, train_loss=0.00462, val_loss=0.00411]Epoch 25:  24%|██▍       | 5/21 [00:00<00:00, 17.13it/s, train_loss=0.00462, val_loss=0.00411]Epoch 25:  24%|██▍       | 5/21 [00:00<00:00, 16.85it/s, train_loss=0.0043, val_loss=0.00411] Epoch 25:  29%|██▊       | 6/21 [00:00<00:00, 17.17it/s, train_loss=0.0043, val_loss=0.00411]Epoch 25:  29%|██▊       | 6/21 [00:00<00:00, 16.85it/s, train_loss=0.0043, val_loss=0.00411]Epoch 25:  33%|███▎      | 7/21 [00:00<00:00, 17.51it/s, train_loss=0.0043, val_loss=0.00411]Epoch 25:  33%|███▎      | 7/21 [00:00<00:00, 16.93it/s, train_loss=0.00445, val_loss=0.00411]Epoch 25:  38%|███▊      | 8/21 [00:00<00:00, 16.60it/s, train_loss=0.00445, val_loss=0.00411]Epoch 25:  38%|███▊      | 8/21 [00:00<00:00, 16.51it/s, train_loss=0.00417, val_loss=0.00411]Epoch 25:  43%|████▎     | 9/21 [00:00<00:00, 16.90it/s, train_loss=0.00417, val_loss=0.00411]Epoch 25:  43%|████▎     | 9/21 [00:00<00:00, 16.52it/s, train_loss=0.00423, val_loss=0.00411]Epoch 25:  48%|████▊     | 10/21 [00:00<00:00, 17.18it/s, train_loss=0.00423, val_loss=0.00411]Epoch 25:  48%|████▊     | 10/21 [00:00<00:00, 16.92it/s, train_loss=0.00406, val_loss=0.00411]Epoch 25:  52%|█████▏    | 11/21 [00:00<00:00, 16.71it/s, train_loss=0.00406, val_loss=0.00411]Epoch 25:  52%|█████▏    | 11/21 [00:00<00:00, 16.59it/s, train_loss=0.00411, val_loss=0.00411]Epoch 25:  57%|█████▋    | 12/21 [00:00<00:00, 16.95it/s, train_loss=0.00411, val_loss=0.00411]Epoch 25:  57%|█████▋    | 12/21 [00:00<00:00, 16.78it/s, train_loss=0.00403, val_loss=0.00411]Epoch 25:  62%|██████▏   | 13/21 [00:00<00:00, 16.12it/s, train_loss=0.00403, val_loss=0.00411]Epoch 25:  62%|██████▏   | 13/21 [00:00<00:00, 15.90it/s, train_loss=0.00396, val_loss=0.00411]Epoch 25:  67%|██████▋   | 14/21 [00:00<00:00, 16.03it/s, train_loss=0.00396, val_loss=0.00411]Epoch 25:  67%|██████▋   | 14/21 [00:00<00:00, 15.87it/s, train_loss=0.00393, val_loss=0.00411]Epoch 25:  71%|███████▏  | 15/21 [00:00<00:00, 16.22it/s, train_loss=0.00393, val_loss=0.00411]Epoch 25:  71%|███████▏  | 15/21 [00:00<00:00, 16.10it/s, train_loss=0.00417, val_loss=0.00411]Epoch 25:  76%|███████▌  | 16/21 [00:00<00:00, 16.31it/s, train_loss=0.00417, val_loss=0.00411]Epoch 25:  76%|███████▌  | 16/21 [00:00<00:00, 16.26it/s, train_loss=0.00427, val_loss=0.00411]Epoch 25:  81%|████████  | 17/21 [00:01<00:00, 16.34it/s, train_loss=0.00427, val_loss=0.00411]Epoch 25:  81%|████████  | 17/21 [00:01<00:00, 16.19it/s, train_loss=0.00385, val_loss=0.00411]Epoch 25:  86%|████████▌ | 18/21 [00:01<00:00, 16.21it/s, train_loss=0.00385, val_loss=0.00411]Epoch 25:  86%|████████▌ | 18/21 [00:01<00:00, 16.19it/s, train_loss=0.00407, val_loss=0.00411]Epoch 25:  90%|█████████ | 19/21 [00:01<00:00, 16.50it/s, train_loss=0.00407, val_loss=0.00411]Epoch 25:  90%|█████████ | 19/21 [00:01<00:00, 16.38it/s, train_loss=0.00415, val_loss=0.00411]Epoch 25:  95%|█████████▌| 20/21 [00:01<00:00, 16.63it/s, train_loss=0.00415, val_loss=0.00411]Epoch 25:  95%|█████████▌| 20/21 [00:01<00:00, 16.55it/s, train_loss=0.0043, val_loss=0.00411] Epoch 25: 100%|██████████| 21/21 [00:01<00:00, 16.77it/s, train_loss=0.0043, val_loss=0.00411]Epoch 25: 100%|██████████| 21/21 [00:01<00:00, 16.75it/s, train_loss=0.00446, val_loss=0.00411]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 47.15it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 47.92it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 36.61it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 32.82it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 34.02it/s][A
                                                                      [AEpoch 25: 100%|██████████| 21/21 [00:01<00:00, 14.88it/s, train_loss=0.00446, val_loss=0.00406]Epoch 25: 100%|██████████| 21/21 [00:01<00:00, 14.87it/s, train_loss=0.00446, val_loss=0.00406]Epoch 25:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00446, val_loss=0.00406]         Epoch 26:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00446, val_loss=0.00406]Epoch 26:   5%|▍         | 1/21 [00:00<00:01, 16.94it/s, train_loss=0.00446, val_loss=0.00406]Epoch 26:   5%|▍         | 1/21 [00:00<00:01, 14.86it/s, train_loss=0.00407, val_loss=0.00406]Epoch 26:  10%|▉         | 2/21 [00:00<00:01, 17.07it/s, train_loss=0.00407, val_loss=0.00406]Epoch 26:  10%|▉         | 2/21 [00:00<00:01, 15.63it/s, train_loss=0.00421, val_loss=0.00406]Epoch 26:  14%|█▍        | 3/21 [00:00<00:00, 18.60it/s, train_loss=0.00421, val_loss=0.00406]Epoch 26:  14%|█▍        | 3/21 [00:00<00:01, 17.04it/s, train_loss=0.00427, val_loss=0.00406]Epoch 26:  19%|█▉        | 4/21 [00:00<00:01, 15.92it/s, train_loss=0.00427, val_loss=0.00406]Epoch 26:  19%|█▉        | 4/21 [00:00<00:01, 15.42it/s, train_loss=0.00424, val_loss=0.00406]Epoch 26:  24%|██▍       | 5/21 [00:00<00:00, 16.07it/s, train_loss=0.00424, val_loss=0.00406]Epoch 26:  24%|██▍       | 5/21 [00:00<00:01, 15.91it/s, train_loss=0.00383, val_loss=0.00406]Epoch 26:  29%|██▊       | 6/21 [00:00<00:00, 15.98it/s, train_loss=0.00383, val_loss=0.00406]Epoch 26:  29%|██▊       | 6/21 [00:00<00:00, 15.93it/s, train_loss=0.00445, val_loss=0.00406]Epoch 26:  33%|███▎      | 7/21 [00:00<00:00, 16.63it/s, train_loss=0.00445, val_loss=0.00406]Epoch 26:  33%|███▎      | 7/21 [00:00<00:00, 16.28it/s, train_loss=0.00413, val_loss=0.00406]Epoch 26:  38%|███▊      | 8/21 [00:00<00:00, 16.47it/s, train_loss=0.00413, val_loss=0.00406]Epoch 26:  38%|███▊      | 8/21 [00:00<00:00, 16.38it/s, train_loss=0.00372, val_loss=0.00406]Epoch 26:  43%|████▎     | 9/21 [00:00<00:00, 16.43it/s, train_loss=0.00372, val_loss=0.00406]Epoch 26:  43%|████▎     | 9/21 [00:00<00:00, 16.30it/s, train_loss=0.00411, val_loss=0.00406]Epoch 26:  48%|████▊     | 10/21 [00:00<00:00, 16.43it/s, train_loss=0.00411, val_loss=0.00406]Epoch 26:  48%|████▊     | 10/21 [00:00<00:00, 16.22it/s, train_loss=0.00405, val_loss=0.00406]Epoch 26:  52%|█████▏    | 11/21 [00:00<00:00, 16.75it/s, train_loss=0.00405, val_loss=0.00406]Epoch 26:  52%|█████▏    | 11/21 [00:00<00:00, 16.51it/s, train_loss=0.00427, val_loss=0.00406]Epoch 26:  57%|█████▋    | 12/21 [00:00<00:00, 16.56it/s, train_loss=0.00427, val_loss=0.00406]Epoch 26:  57%|█████▋    | 12/21 [00:00<00:00, 16.38it/s, train_loss=0.00412, val_loss=0.00406]Epoch 26:  62%|██████▏   | 13/21 [00:00<00:00, 16.21it/s, train_loss=0.00412, val_loss=0.00406]Epoch 26:  62%|██████▏   | 13/21 [00:00<00:00, 16.07it/s, train_loss=0.00438, val_loss=0.00406]Epoch 26:  67%|██████▋   | 14/21 [00:00<00:00, 16.49it/s, train_loss=0.00438, val_loss=0.00406]Epoch 26:  67%|██████▋   | 14/21 [00:00<00:00, 16.28it/s, train_loss=0.00398, val_loss=0.00406]Epoch 26:  71%|███████▏  | 15/21 [00:00<00:00, 16.49it/s, train_loss=0.00398, val_loss=0.00406]Epoch 26:  71%|███████▏  | 15/21 [00:00<00:00, 16.33it/s, train_loss=0.00387, val_loss=0.00406]Epoch 26:  76%|███████▌  | 16/21 [00:00<00:00, 16.67it/s, train_loss=0.00387, val_loss=0.00406]Epoch 26:  76%|███████▌  | 16/21 [00:00<00:00, 16.52it/s, train_loss=0.00432, val_loss=0.00406]Epoch 26:  81%|████████  | 17/21 [00:01<00:00, 16.66it/s, train_loss=0.00432, val_loss=0.00406]Epoch 26:  81%|████████  | 17/21 [00:01<00:00, 16.57it/s, train_loss=0.00425, val_loss=0.00406]Epoch 26:  86%|████████▌ | 18/21 [00:01<00:00, 16.59it/s, train_loss=0.00425, val_loss=0.00406]Epoch 26:  86%|████████▌ | 18/21 [00:01<00:00, 16.51it/s, train_loss=0.0039, val_loss=0.00406] Epoch 26:  90%|█████████ | 19/21 [00:01<00:00, 16.44it/s, train_loss=0.0039, val_loss=0.00406]Epoch 26:  90%|█████████ | 19/21 [00:01<00:00, 16.29it/s, train_loss=0.00427, val_loss=0.00406]Epoch 26:  95%|█████████▌| 20/21 [00:01<00:00, 16.48it/s, train_loss=0.00427, val_loss=0.00406]Epoch 26:  95%|█████████▌| 20/21 [00:01<00:00, 16.34it/s, train_loss=0.00414, val_loss=0.00406]Epoch 26: 100%|██████████| 21/21 [00:01<00:00, 16.70it/s, train_loss=0.00414, val_loss=0.00406]Epoch 26: 100%|██████████| 21/21 [00:01<00:00, 16.57it/s, train_loss=0.00385, val_loss=0.00406]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 35.63it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 36.13it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 35.83it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 38.44it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 41.15it/s][A
                                                                      [AEpoch 26: 100%|██████████| 21/21 [00:01<00:00, 15.02it/s, train_loss=0.00385, val_loss=0.00402]Epoch 26: 100%|██████████| 21/21 [00:01<00:00, 15.01it/s, train_loss=0.00385, val_loss=0.00402]Epoch 26:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00385, val_loss=0.00402]         Epoch 27:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00385, val_loss=0.00402]Epoch 27:   5%|▍         | 1/21 [00:00<00:00, 20.66it/s, train_loss=0.00385, val_loss=0.00402]Epoch 27:   5%|▍         | 1/21 [00:00<00:01, 17.87it/s, train_loss=0.00425, val_loss=0.00402]Epoch 27:  10%|▉         | 2/21 [00:00<00:01, 17.59it/s, train_loss=0.00425, val_loss=0.00402]Epoch 27:  10%|▉         | 2/21 [00:00<00:01, 16.44it/s, train_loss=0.00408, val_loss=0.00402]Epoch 27:  14%|█▍        | 3/21 [00:00<00:00, 18.82it/s, train_loss=0.00408, val_loss=0.00402]Epoch 27:  14%|█▍        | 3/21 [00:00<00:01, 17.61it/s, train_loss=0.00406, val_loss=0.00402]Epoch 27:  19%|█▉        | 4/21 [00:00<00:01, 16.90it/s, train_loss=0.00406, val_loss=0.00402]Epoch 27:  19%|█▉        | 4/21 [00:00<00:01, 16.79it/s, train_loss=0.00431, val_loss=0.00402]Epoch 27:  24%|██▍       | 5/21 [00:00<00:00, 16.69it/s, train_loss=0.00431, val_loss=0.00402]Epoch 27:  24%|██▍       | 5/21 [00:00<00:00, 16.38it/s, train_loss=0.0039, val_loss=0.00402] Epoch 27:  29%|██▊       | 6/21 [00:00<00:00, 17.58it/s, train_loss=0.0039, val_loss=0.00402]Epoch 27:  29%|██▊       | 6/21 [00:00<00:00, 17.18it/s, train_loss=0.00407, val_loss=0.00402]Epoch 27:  33%|███▎      | 7/21 [00:00<00:00, 17.77it/s, train_loss=0.00407, val_loss=0.00402]Epoch 27:  33%|███▎      | 7/21 [00:00<00:00, 17.44it/s, train_loss=0.00443, val_loss=0.00402]Epoch 27:  38%|███▊      | 8/21 [00:00<00:00, 17.37it/s, train_loss=0.00443, val_loss=0.00402]Epoch 27:  38%|███▊      | 8/21 [00:00<00:00, 17.28it/s, train_loss=0.00421, val_loss=0.00402]Epoch 27:  43%|████▎     | 9/21 [00:00<00:00, 17.48it/s, train_loss=0.00421, val_loss=0.00402]Epoch 27:  43%|████▎     | 9/21 [00:00<00:00, 17.23it/s, train_loss=0.00398, val_loss=0.00402]Epoch 27:  48%|████▊     | 10/21 [00:00<00:00, 17.45it/s, train_loss=0.00398, val_loss=0.00402]Epoch 27:  48%|████▊     | 10/21 [00:00<00:00, 17.21it/s, train_loss=0.00385, val_loss=0.00402]Epoch 27:  52%|█████▏    | 11/21 [00:00<00:00, 17.70it/s, train_loss=0.00385, val_loss=0.00402]Epoch 27:  52%|█████▏    | 11/21 [00:00<00:00, 17.44it/s, train_loss=0.00381, val_loss=0.00402]Epoch 27:  57%|█████▋    | 12/21 [00:00<00:00, 17.90it/s, train_loss=0.00381, val_loss=0.00402]Epoch 27:  57%|█████▋    | 12/21 [00:00<00:00, 17.62it/s, train_loss=0.00393, val_loss=0.00402]Epoch 27:  62%|██████▏   | 13/21 [00:00<00:00, 17.91it/s, train_loss=0.00393, val_loss=0.00402]Epoch 27:  62%|██████▏   | 13/21 [00:00<00:00, 17.71it/s, train_loss=0.00413, val_loss=0.00402]Epoch 27:  67%|██████▋   | 14/21 [00:00<00:00, 17.77it/s, train_loss=0.00413, val_loss=0.00402]Epoch 27:  67%|██████▋   | 14/21 [00:00<00:00, 17.69it/s, train_loss=0.004, val_loss=0.00402]  Epoch 27:  71%|███████▏  | 15/21 [00:00<00:00, 17.78it/s, train_loss=0.004, val_loss=0.00402]Epoch 27:  71%|███████▏  | 15/21 [00:00<00:00, 17.68it/s, train_loss=0.00441, val_loss=0.00402]Epoch 27:  76%|███████▌  | 16/21 [00:00<00:00, 17.75it/s, train_loss=0.00441, val_loss=0.00402]Epoch 27:  76%|███████▌  | 16/21 [00:00<00:00, 17.63it/s, train_loss=0.00404, val_loss=0.00402]Epoch 27:  81%|████████  | 17/21 [00:00<00:00, 17.60it/s, train_loss=0.00404, val_loss=0.00402]Epoch 27:  81%|████████  | 17/21 [00:00<00:00, 17.49it/s, train_loss=0.00401, val_loss=0.00402]Epoch 27:  86%|████████▌ | 18/21 [00:01<00:00, 17.72it/s, train_loss=0.00401, val_loss=0.00402]Epoch 27:  86%|████████▌ | 18/21 [00:01<00:00, 17.55it/s, train_loss=0.00386, val_loss=0.00402]Epoch 27:  90%|█████████ | 19/21 [00:01<00:00, 17.93it/s, train_loss=0.00386, val_loss=0.00402]Epoch 27:  90%|█████████ | 19/21 [00:01<00:00, 17.69it/s, train_loss=0.00404, val_loss=0.00402]Epoch 27:  95%|█████████▌| 20/21 [00:01<00:00, 17.59it/s, train_loss=0.00404, val_loss=0.00402]Epoch 27:  95%|█████████▌| 20/21 [00:01<00:00, 17.47it/s, train_loss=0.00395, val_loss=0.00402]Epoch 27: 100%|██████████| 21/21 [00:01<00:00, 17.67it/s, train_loss=0.00395, val_loss=0.00402]Epoch 27: 100%|██████████| 21/21 [00:01<00:00, 17.56it/s, train_loss=0.00437, val_loss=0.00402]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 49.84it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 44.70it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 39.51it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 39.88it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 41.03it/s][A
                                                                      [AEpoch 27: 100%|██████████| 21/21 [00:01<00:00, 15.82it/s, train_loss=0.00437, val_loss=0.00395]Epoch 27: 100%|██████████| 21/21 [00:01<00:00, 15.80it/s, train_loss=0.00437, val_loss=0.00395]Epoch 27:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00437, val_loss=0.00395]         Epoch 28:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00437, val_loss=0.00395]Epoch 28:   5%|▍         | 1/21 [00:00<00:00, 21.12it/s, train_loss=0.00437, val_loss=0.00395]Epoch 28:   5%|▍         | 1/21 [00:00<00:01, 19.44it/s, train_loss=0.00395, val_loss=0.00395]Epoch 28:  10%|▉         | 2/21 [00:00<00:00, 20.19it/s, train_loss=0.00395, val_loss=0.00395]Epoch 28:  10%|▉         | 2/21 [00:00<00:01, 19.00it/s, train_loss=0.00384, val_loss=0.00395]Epoch 28:  14%|█▍        | 3/21 [00:00<00:00, 18.51it/s, train_loss=0.00384, val_loss=0.00395]Epoch 28:  14%|█▍        | 3/21 [00:00<00:01, 17.87it/s, train_loss=0.0041, val_loss=0.00395] Epoch 28:  19%|█▉        | 4/21 [00:00<00:00, 18.49it/s, train_loss=0.0041, val_loss=0.00395]Epoch 28:  19%|█▉        | 4/21 [00:00<00:00, 17.93it/s, train_loss=0.00393, val_loss=0.00395]Epoch 28:  24%|██▍       | 5/21 [00:00<00:00, 18.36it/s, train_loss=0.00393, val_loss=0.00395]Epoch 28:  24%|██▍       | 5/21 [00:00<00:00, 18.12it/s, train_loss=0.00436, val_loss=0.00395]Epoch 28:  29%|██▊       | 6/21 [00:00<00:00, 18.30it/s, train_loss=0.00436, val_loss=0.00395]Epoch 28:  29%|██▊       | 6/21 [00:00<00:00, 17.90it/s, train_loss=0.00421, val_loss=0.00395]Epoch 28:  33%|███▎      | 7/21 [00:00<00:00, 18.20it/s, train_loss=0.00421, val_loss=0.00395]Epoch 28:  33%|███▎      | 7/21 [00:00<00:00, 17.88it/s, train_loss=0.00422, val_loss=0.00395]Epoch 28:  38%|███▊      | 8/21 [00:00<00:00, 18.42it/s, train_loss=0.00422, val_loss=0.00395]Epoch 28:  38%|███▊      | 8/21 [00:00<00:00, 18.05it/s, train_loss=0.004, val_loss=0.00395]  Epoch 28:  43%|████▎     | 9/21 [00:00<00:00, 18.53it/s, train_loss=0.004, val_loss=0.00395]Epoch 28:  43%|████▎     | 9/21 [00:00<00:00, 18.18it/s, train_loss=0.00405, val_loss=0.00395]Epoch 28:  48%|████▊     | 10/21 [00:00<00:00, 18.66it/s, train_loss=0.00405, val_loss=0.00395]Epoch 28:  48%|████▊     | 10/21 [00:00<00:00, 18.34it/s, train_loss=0.00393, val_loss=0.00395]Epoch 28:  52%|█████▏    | 11/21 [00:00<00:00, 18.14it/s, train_loss=0.00393, val_loss=0.00395]Epoch 28:  52%|█████▏    | 11/21 [00:00<00:00, 18.06it/s, train_loss=0.00404, val_loss=0.00395]Epoch 28:  57%|█████▋    | 12/21 [00:00<00:00, 18.33it/s, train_loss=0.00404, val_loss=0.00395]Epoch 28:  57%|█████▋    | 12/21 [00:00<00:00, 18.12it/s, train_loss=0.00392, val_loss=0.00395]Epoch 28:  62%|██████▏   | 13/21 [00:00<00:00, 17.97it/s, train_loss=0.00392, val_loss=0.00395]Epoch 28:  62%|██████▏   | 13/21 [00:00<00:00, 17.74it/s, train_loss=0.0041, val_loss=0.00395] Epoch 28:  67%|██████▋   | 14/21 [00:00<00:00, 18.03it/s, train_loss=0.0041, val_loss=0.00395]Epoch 28:  67%|██████▋   | 14/21 [00:00<00:00, 17.74it/s, train_loss=0.00395, val_loss=0.00395]Epoch 28:  71%|███████▏  | 15/21 [00:00<00:00, 18.21it/s, train_loss=0.00395, val_loss=0.00395]Epoch 28:  71%|███████▏  | 15/21 [00:00<00:00, 17.93it/s, train_loss=0.00395, val_loss=0.00395]Epoch 28:  76%|███████▌  | 16/21 [00:00<00:00, 17.94it/s, train_loss=0.00395, val_loss=0.00395]Epoch 28:  76%|███████▌  | 16/21 [00:00<00:00, 17.82it/s, train_loss=0.00419, val_loss=0.00395]Epoch 28:  81%|████████  | 17/21 [00:00<00:00, 17.89it/s, train_loss=0.00419, val_loss=0.00395]Epoch 28:  81%|████████  | 17/21 [00:00<00:00, 17.79it/s, train_loss=0.00389, val_loss=0.00395]Epoch 28:  86%|████████▌ | 18/21 [00:01<00:00, 17.55it/s, train_loss=0.00389, val_loss=0.00395]Epoch 28:  86%|████████▌ | 18/21 [00:01<00:00, 17.46it/s, train_loss=0.00403, val_loss=0.00395]Epoch 28:  90%|█████████ | 19/21 [00:01<00:00, 17.43it/s, train_loss=0.00403, val_loss=0.00395]Epoch 28:  90%|█████████ | 19/21 [00:01<00:00, 17.30it/s, train_loss=0.00397, val_loss=0.00395]Epoch 28:  95%|█████████▌| 20/21 [00:01<00:00, 17.44it/s, train_loss=0.00397, val_loss=0.00395]Epoch 28:  95%|█████████▌| 20/21 [00:01<00:00, 17.32it/s, train_loss=0.00389, val_loss=0.00395]Epoch 28: 100%|██████████| 21/21 [00:01<00:00, 17.11it/s, train_loss=0.00389, val_loss=0.00395]Epoch 28: 100%|██████████| 21/21 [00:01<00:00, 17.04it/s, train_loss=0.00396, val_loss=0.00395]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 39.19it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 40.44it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 41.02it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 41.95it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 43.07it/s][A
                                                                      [AEpoch 28: 100%|██████████| 21/21 [00:01<00:00, 15.40it/s, train_loss=0.00396, val_loss=0.0039] Epoch 28: 100%|██████████| 21/21 [00:01<00:00, 15.37it/s, train_loss=0.00396, val_loss=0.0039]Epoch 28:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00396, val_loss=0.0039]         Epoch 29:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00396, val_loss=0.0039]Epoch 29:   5%|▍         | 1/21 [00:00<00:00, 22.73it/s, train_loss=0.00396, val_loss=0.0039]Epoch 29:   5%|▍         | 1/21 [00:00<00:01, 17.65it/s, train_loss=0.00389, val_loss=0.0039]Epoch 29:  10%|▉         | 2/21 [00:00<00:01, 18.78it/s, train_loss=0.00389, val_loss=0.0039]Epoch 29:  10%|▉         | 2/21 [00:00<00:01, 17.26it/s, train_loss=0.00392, val_loss=0.0039]Epoch 29:  14%|█▍        | 3/21 [00:00<00:00, 18.98it/s, train_loss=0.00392, val_loss=0.0039]Epoch 29:  14%|█▍        | 3/21 [00:00<00:00, 18.09it/s, train_loss=0.00424, val_loss=0.0039]Epoch 29:  19%|█▉        | 4/21 [00:00<00:00, 19.17it/s, train_loss=0.00424, val_loss=0.0039]Epoch 29:  19%|█▉        | 4/21 [00:00<00:00, 18.52it/s, train_loss=0.0041, val_loss=0.0039] Epoch 29:  24%|██▍       | 5/21 [00:00<00:00, 19.46it/s, train_loss=0.0041, val_loss=0.0039]Epoch 29:  24%|██▍       | 5/21 [00:00<00:00, 18.82it/s, train_loss=0.00394, val_loss=0.0039]Epoch 29:  29%|██▊       | 6/21 [00:00<00:00, 17.76it/s, train_loss=0.00394, val_loss=0.0039]Epoch 29:  29%|██▊       | 6/21 [00:00<00:00, 17.48it/s, train_loss=0.00395, val_loss=0.0039]Epoch 29:  33%|███▎      | 7/21 [00:00<00:00, 18.42it/s, train_loss=0.00395, val_loss=0.0039]Epoch 29:  33%|███▎      | 7/21 [00:00<00:00, 17.70it/s, train_loss=0.00385, val_loss=0.0039]Epoch 29:  38%|███▊      | 8/21 [00:00<00:00, 17.23it/s, train_loss=0.00385, val_loss=0.0039]Epoch 29:  38%|███▊      | 8/21 [00:00<00:00, 17.08it/s, train_loss=0.00399, val_loss=0.0039]Epoch 29:  43%|████▎     | 9/21 [00:00<00:00, 17.51it/s, train_loss=0.00399, val_loss=0.0039]Epoch 29:  43%|████▎     | 9/21 [00:00<00:00, 17.19it/s, train_loss=0.00397, val_loss=0.0039]Epoch 29:  48%|████▊     | 10/21 [00:00<00:00, 17.70it/s, train_loss=0.00397, val_loss=0.0039]Epoch 29:  48%|████▊     | 10/21 [00:00<00:00, 17.33it/s, train_loss=0.00411, val_loss=0.0039]Epoch 29:  52%|█████▏    | 11/21 [00:00<00:00, 17.02it/s, train_loss=0.00411, val_loss=0.0039]Epoch 29:  52%|█████▏    | 11/21 [00:00<00:00, 16.90it/s, train_loss=0.00412, val_loss=0.0039]Epoch 29:  57%|█████▋    | 12/21 [00:00<00:00, 17.14it/s, train_loss=0.00412, val_loss=0.0039]Epoch 29:  57%|█████▋    | 12/21 [00:00<00:00, 16.93it/s, train_loss=0.00389, val_loss=0.0039]Epoch 29:  62%|██████▏   | 13/21 [00:00<00:00, 17.02it/s, train_loss=0.00389, val_loss=0.0039]Epoch 29:  62%|██████▏   | 13/21 [00:00<00:00, 16.86it/s, train_loss=0.00392, val_loss=0.0039]Epoch 29:  67%|██████▋   | 14/21 [00:00<00:00, 16.91it/s, train_loss=0.00392, val_loss=0.0039]Epoch 29:  67%|██████▋   | 14/21 [00:00<00:00, 16.77it/s, train_loss=0.00379, val_loss=0.0039]Epoch 29:  71%|███████▏  | 15/21 [00:00<00:00, 16.96it/s, train_loss=0.00379, val_loss=0.0039]Epoch 29:  71%|███████▏  | 15/21 [00:00<00:00, 16.82it/s, train_loss=0.00378, val_loss=0.0039]Epoch 29:  76%|███████▌  | 16/21 [00:00<00:00, 16.79it/s, train_loss=0.00378, val_loss=0.0039]Epoch 29:  76%|███████▌  | 16/21 [00:00<00:00, 16.66it/s, train_loss=0.00404, val_loss=0.0039]Epoch 29:  81%|████████  | 17/21 [00:01<00:00, 16.77it/s, train_loss=0.00404, val_loss=0.0039]Epoch 29:  81%|████████  | 17/21 [00:01<00:00, 16.67it/s, train_loss=0.00392, val_loss=0.0039]Epoch 29:  86%|████████▌ | 18/21 [00:01<00:00, 17.00it/s, train_loss=0.00392, val_loss=0.0039]Epoch 29:  86%|████████▌ | 18/21 [00:01<00:00, 16.86it/s, train_loss=0.00391, val_loss=0.0039]Epoch 29:  90%|█████████ | 19/21 [00:01<00:00, 17.03it/s, train_loss=0.00391, val_loss=0.0039]Epoch 29:  90%|█████████ | 19/21 [00:01<00:00, 16.95it/s, train_loss=0.00388, val_loss=0.0039]Epoch 29:  95%|█████████▌| 20/21 [00:01<00:00, 17.06it/s, train_loss=0.00388, val_loss=0.0039]Epoch 29:  95%|█████████▌| 20/21 [00:01<00:00, 16.89it/s, train_loss=0.00384, val_loss=0.0039]Epoch 29: 100%|██████████| 21/21 [00:01<00:00, 16.93it/s, train_loss=0.00384, val_loss=0.0039]Epoch 29: 100%|██████████| 21/21 [00:01<00:00, 16.84it/s, train_loss=0.00398, val_loss=0.0039]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 51.50it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 51.57it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 52.63it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 51.14it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 47.84it/s][A
                                                                      [AEpoch 29: 100%|██████████| 21/21 [00:01<00:00, 15.45it/s, train_loss=0.00398, val_loss=0.00387]Epoch 29: 100%|██████████| 21/21 [00:01<00:00, 15.43it/s, train_loss=0.00398, val_loss=0.00387]Epoch 29:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00398, val_loss=0.00387]         Epoch 30:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00398, val_loss=0.00387]Epoch 30:   5%|▍         | 1/21 [00:00<00:00, 20.04it/s, train_loss=0.00398, val_loss=0.00387]Epoch 30:   5%|▍         | 1/21 [00:00<00:01, 18.17it/s, train_loss=0.00385, val_loss=0.00387]Epoch 30:  10%|▉         | 2/21 [00:00<00:00, 19.96it/s, train_loss=0.00385, val_loss=0.00387]Epoch 30:  10%|▉         | 2/21 [00:00<00:01, 18.01it/s, train_loss=0.00404, val_loss=0.00387]Epoch 30:  14%|█▍        | 3/21 [00:00<00:01, 17.44it/s, train_loss=0.00404, val_loss=0.00387]Epoch 30:  14%|█▍        | 3/21 [00:00<00:01, 16.96it/s, train_loss=0.00379, val_loss=0.00387]Epoch 30:  19%|█▉        | 4/21 [00:00<00:00, 18.52it/s, train_loss=0.00379, val_loss=0.00387]Epoch 30:  19%|█▉        | 4/21 [00:00<00:00, 17.51it/s, train_loss=0.00396, val_loss=0.00387]Epoch 30:  24%|██▍       | 5/21 [00:00<00:00, 17.76it/s, train_loss=0.00396, val_loss=0.00387]Epoch 30:  24%|██▍       | 5/21 [00:00<00:00, 16.72it/s, train_loss=0.00405, val_loss=0.00387]Epoch 30:  29%|██▊       | 6/21 [00:00<00:00, 17.82it/s, train_loss=0.00405, val_loss=0.00387]Epoch 30:  29%|██▊       | 6/21 [00:00<00:00, 17.27it/s, train_loss=0.00399, val_loss=0.00387]Epoch 30:  33%|███▎      | 7/21 [00:00<00:00, 18.34it/s, train_loss=0.00399, val_loss=0.00387]Epoch 30:  33%|███▎      | 7/21 [00:00<00:00, 17.65it/s, train_loss=0.00383, val_loss=0.00387]Epoch 30:  38%|███▊      | 8/21 [00:00<00:00, 16.90it/s, train_loss=0.00383, val_loss=0.00387]Epoch 30:  38%|███▊      | 8/21 [00:00<00:00, 16.60it/s, train_loss=0.00412, val_loss=0.00387]Epoch 30:  43%|████▎     | 9/21 [00:00<00:00, 16.93it/s, train_loss=0.00412, val_loss=0.00387]Epoch 30:  43%|████▎     | 9/21 [00:00<00:00, 16.77it/s, train_loss=0.00376, val_loss=0.00387]Epoch 30:  48%|████▊     | 10/21 [00:00<00:00, 16.49it/s, train_loss=0.00376, val_loss=0.00387]Epoch 30:  48%|████▊     | 10/21 [00:00<00:00, 16.44it/s, train_loss=0.00438, val_loss=0.00387]Epoch 30:  52%|█████▏    | 11/21 [00:00<00:00, 16.66it/s, train_loss=0.00438, val_loss=0.00387]Epoch 30:  52%|█████▏    | 11/21 [00:00<00:00, 16.47it/s, train_loss=0.00369, val_loss=0.00387]Epoch 30:  57%|█████▋    | 12/21 [00:00<00:00, 16.73it/s, train_loss=0.00369, val_loss=0.00387]Epoch 30:  57%|█████▋    | 12/21 [00:00<00:00, 16.58it/s, train_loss=0.00383, val_loss=0.00387]Epoch 30:  62%|██████▏   | 13/21 [00:00<00:00, 16.55it/s, train_loss=0.00383, val_loss=0.00387]Epoch 30:  62%|██████▏   | 13/21 [00:00<00:00, 16.41it/s, train_loss=0.00386, val_loss=0.00387]Epoch 30:  67%|██████▋   | 14/21 [00:00<00:00, 16.67it/s, train_loss=0.00386, val_loss=0.00387]Epoch 30:  67%|██████▋   | 14/21 [00:00<00:00, 16.52it/s, train_loss=0.0039, val_loss=0.00387] Epoch 30:  71%|███████▏  | 15/21 [00:00<00:00, 16.53it/s, train_loss=0.0039, val_loss=0.00387]Epoch 30:  71%|███████▏  | 15/21 [00:00<00:00, 16.42it/s, train_loss=0.00363, val_loss=0.00387]Epoch 30:  76%|███████▌  | 16/21 [00:00<00:00, 16.48it/s, train_loss=0.00363, val_loss=0.00387]Epoch 30:  76%|███████▌  | 16/21 [00:00<00:00, 16.34it/s, train_loss=0.00393, val_loss=0.00387]Epoch 30:  81%|████████  | 17/21 [00:01<00:00, 16.53it/s, train_loss=0.00393, val_loss=0.00387]Epoch 30:  81%|████████  | 17/21 [00:01<00:00, 16.38it/s, train_loss=0.00383, val_loss=0.00387]Epoch 30:  86%|████████▌ | 18/21 [00:01<00:00, 16.62it/s, train_loss=0.00383, val_loss=0.00387]Epoch 30:  86%|████████▌ | 18/21 [00:01<00:00, 16.51it/s, train_loss=0.00435, val_loss=0.00387]Epoch 30:  90%|█████████ | 19/21 [00:01<00:00, 16.80it/s, train_loss=0.00435, val_loss=0.00387]Epoch 30:  90%|█████████ | 19/21 [00:01<00:00, 16.64it/s, train_loss=0.00377, val_loss=0.00387]Epoch 30:  95%|█████████▌| 20/21 [00:01<00:00, 16.76it/s, train_loss=0.00377, val_loss=0.00387]Epoch 30:  95%|█████████▌| 20/21 [00:01<00:00, 16.65it/s, train_loss=0.004, val_loss=0.00387]  Epoch 30: 100%|██████████| 21/21 [00:01<00:00, 16.88it/s, train_loss=0.004, val_loss=0.00387]Epoch 30: 100%|██████████| 21/21 [00:01<00:00, 16.78it/s, train_loss=0.004, val_loss=0.00387]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 30.98it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 36.01it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 32.81it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 36.01it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 37.91it/s][A
                                                                      [AEpoch 30: 100%|██████████| 21/21 [00:01<00:00, 15.05it/s, train_loss=0.004, val_loss=0.00388]Epoch 30: 100%|██████████| 21/21 [00:01<00:00, 15.03it/s, train_loss=0.004, val_loss=0.00388]Epoch 30:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.004, val_loss=0.00388]         Epoch 31:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.004, val_loss=0.00388]Epoch 31:   5%|▍         | 1/21 [00:00<00:01, 18.68it/s, train_loss=0.004, val_loss=0.00388]Epoch 31:   5%|▍         | 1/21 [00:00<00:01, 14.20it/s, train_loss=0.00377, val_loss=0.00388]Epoch 31:  10%|▉         | 2/21 [00:00<00:01, 18.54it/s, train_loss=0.00377, val_loss=0.00388]Epoch 31:  10%|▉         | 2/21 [00:00<00:01, 16.48it/s, train_loss=0.00369, val_loss=0.00388]Epoch 31:  14%|█▍        | 3/21 [00:00<00:00, 19.89it/s, train_loss=0.00369, val_loss=0.00388]Epoch 31:  14%|█▍        | 3/21 [00:00<00:01, 17.48it/s, train_loss=0.0041, val_loss=0.00388] Epoch 31:  19%|█▉        | 4/21 [00:00<00:01, 15.75it/s, train_loss=0.0041, val_loss=0.00388]Epoch 31:  19%|█▉        | 4/21 [00:00<00:01, 15.38it/s, train_loss=0.00382, val_loss=0.00388]Epoch 31:  24%|██▍       | 5/21 [00:00<00:01, 15.21it/s, train_loss=0.00382, val_loss=0.00388]Epoch 31:  24%|██▍       | 5/21 [00:00<00:01, 14.95it/s, train_loss=0.00382, val_loss=0.00388]Epoch 31:  29%|██▊       | 6/21 [00:00<00:00, 15.38it/s, train_loss=0.00382, val_loss=0.00388]Epoch 31:  29%|██▊       | 6/21 [00:00<00:00, 15.01it/s, train_loss=0.00391, val_loss=0.00388]Epoch 31:  33%|███▎      | 7/21 [00:00<00:00, 14.73it/s, train_loss=0.00391, val_loss=0.00388]Epoch 31:  33%|███▎      | 7/21 [00:00<00:00, 14.68it/s, train_loss=0.00394, val_loss=0.00388]Epoch 31:  38%|███▊      | 8/21 [00:00<00:00, 15.18it/s, train_loss=0.00394, val_loss=0.00388]Epoch 31:  38%|███▊      | 8/21 [00:00<00:00, 15.02it/s, train_loss=0.00385, val_loss=0.00388]Epoch 31:  43%|████▎     | 9/21 [00:00<00:00, 15.57it/s, train_loss=0.00385, val_loss=0.00388]Epoch 31:  43%|████▎     | 9/21 [00:00<00:00, 15.37it/s, train_loss=0.00383, val_loss=0.00388]Epoch 31:  48%|████▊     | 10/21 [00:00<00:00, 15.64it/s, train_loss=0.00383, val_loss=0.00388]Epoch 31:  48%|████▊     | 10/21 [00:00<00:00, 15.44it/s, train_loss=0.00368, val_loss=0.00388]Epoch 31:  52%|█████▏    | 11/21 [00:00<00:00, 15.52it/s, train_loss=0.00368, val_loss=0.00388]Epoch 31:  52%|█████▏    | 11/21 [00:00<00:00, 15.33it/s, train_loss=0.0041, val_loss=0.00388] Epoch 31:  57%|█████▋    | 12/21 [00:00<00:00, 15.76it/s, train_loss=0.0041, val_loss=0.00388]Epoch 31:  57%|█████▋    | 12/21 [00:00<00:00, 15.54it/s, train_loss=0.00382, val_loss=0.00388]Epoch 31:  62%|██████▏   | 13/21 [00:00<00:00, 15.98it/s, train_loss=0.00382, val_loss=0.00388]Epoch 31:  62%|██████▏   | 13/21 [00:00<00:00, 15.88it/s, train_loss=0.00408, val_loss=0.00388]Epoch 31:  67%|██████▋   | 14/21 [00:00<00:00, 16.35it/s, train_loss=0.00408, val_loss=0.00388]Epoch 31:  67%|██████▋   | 14/21 [00:00<00:00, 16.19it/s, train_loss=0.00418, val_loss=0.00388]Epoch 31:  71%|███████▏  | 15/21 [00:00<00:00, 16.48it/s, train_loss=0.00418, val_loss=0.00388]Epoch 31:  71%|███████▏  | 15/21 [00:00<00:00, 16.35it/s, train_loss=0.00401, val_loss=0.00388]Epoch 31:  76%|███████▌  | 16/21 [00:00<00:00, 16.30it/s, train_loss=0.00401, val_loss=0.00388]Epoch 31:  76%|███████▌  | 16/21 [00:00<00:00, 16.22it/s, train_loss=0.00406, val_loss=0.00388]Epoch 31:  81%|████████  | 17/21 [00:01<00:00, 16.51it/s, train_loss=0.00406, val_loss=0.00388]Epoch 31:  81%|████████  | 17/21 [00:01<00:00, 16.30it/s, train_loss=0.00386, val_loss=0.00388]Epoch 31:  86%|████████▌ | 18/21 [00:01<00:00, 16.33it/s, train_loss=0.00386, val_loss=0.00388]Epoch 31:  86%|████████▌ | 18/21 [00:01<00:00, 16.19it/s, train_loss=0.00391, val_loss=0.00388]Epoch 31:  90%|█████████ | 19/21 [00:01<00:00, 16.45it/s, train_loss=0.00391, val_loss=0.00388]Epoch 31:  90%|█████████ | 19/21 [00:01<00:00, 16.32it/s, train_loss=0.00396, val_loss=0.00388]Epoch 31:  95%|█████████▌| 20/21 [00:01<00:00, 16.72it/s, train_loss=0.00396, val_loss=0.00388]Epoch 31:  95%|█████████▌| 20/21 [00:01<00:00, 16.49it/s, train_loss=0.00378, val_loss=0.00388]Epoch 31: 100%|██████████| 21/21 [00:01<00:00, 16.43it/s, train_loss=0.00378, val_loss=0.00388]Epoch 31: 100%|██████████| 21/21 [00:01<00:00, 16.36it/s, train_loss=0.00369, val_loss=0.00388]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 47.76it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 50.45it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 46.40it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 46.26it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 43.57it/s][A
                                                                      [AEpoch 31: 100%|██████████| 21/21 [00:01<00:00, 14.91it/s, train_loss=0.00369, val_loss=0.00381]Epoch 31: 100%|██████████| 21/21 [00:01<00:00, 14.89it/s, train_loss=0.00369, val_loss=0.00381]Epoch 31:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00369, val_loss=0.00381]         Epoch 32:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00369, val_loss=0.00381]Epoch 32:   5%|▍         | 1/21 [00:00<00:00, 22.07it/s, train_loss=0.00369, val_loss=0.00381]Epoch 32:   5%|▍         | 1/21 [00:00<00:01, 18.81it/s, train_loss=0.00385, val_loss=0.00381]Epoch 32:  10%|▉         | 2/21 [00:00<00:00, 19.61it/s, train_loss=0.00385, val_loss=0.00381]Epoch 32:  10%|▉         | 2/21 [00:00<00:01, 18.50it/s, train_loss=0.00389, val_loss=0.00381]Epoch 32:  14%|█▍        | 3/21 [00:00<00:01, 16.90it/s, train_loss=0.00389, val_loss=0.00381]Epoch 32:  14%|█▍        | 3/21 [00:00<00:01, 16.52it/s, train_loss=0.00358, val_loss=0.00381]Epoch 32:  19%|█▉        | 4/21 [00:00<00:00, 17.55it/s, train_loss=0.00358, val_loss=0.00381]Epoch 32:  19%|█▉        | 4/21 [00:00<00:01, 16.93it/s, train_loss=0.00389, val_loss=0.00381]Epoch 32:  24%|██▍       | 5/21 [00:00<00:00, 18.06it/s, train_loss=0.00389, val_loss=0.00381]Epoch 32:  24%|██▍       | 5/21 [00:00<00:00, 17.56it/s, train_loss=0.00406, val_loss=0.00381]Epoch 32:  29%|██▊       | 6/21 [00:00<00:00, 17.83it/s, train_loss=0.00406, val_loss=0.00381]Epoch 32:  29%|██▊       | 6/21 [00:00<00:00, 17.54it/s, train_loss=0.00392, val_loss=0.00381]Epoch 32:  33%|███▎      | 7/21 [00:00<00:00, 18.48it/s, train_loss=0.00392, val_loss=0.00381]Epoch 32:  33%|███▎      | 7/21 [00:00<00:00, 17.67it/s, train_loss=0.00407, val_loss=0.00381]Epoch 32:  38%|███▊      | 8/21 [00:00<00:00, 18.23it/s, train_loss=0.00407, val_loss=0.00381]Epoch 32:  38%|███▊      | 8/21 [00:00<00:00, 17.84it/s, train_loss=0.00395, val_loss=0.00381]Epoch 32:  43%|████▎     | 9/21 [00:00<00:00, 18.44it/s, train_loss=0.00395, val_loss=0.00381]Epoch 32:  43%|████▎     | 9/21 [00:00<00:00, 18.06it/s, train_loss=0.00396, val_loss=0.00381]Epoch 32:  48%|████▊     | 10/21 [00:00<00:00, 18.27it/s, train_loss=0.00396, val_loss=0.00381]Epoch 32:  48%|████▊     | 10/21 [00:00<00:00, 18.00it/s, train_loss=0.00387, val_loss=0.00381]Epoch 32:  52%|█████▏    | 11/21 [00:00<00:00, 18.44it/s, train_loss=0.00387, val_loss=0.00381]Epoch 32:  52%|█████▏    | 11/21 [00:00<00:00, 18.18it/s, train_loss=0.00381, val_loss=0.00381]Epoch 32:  57%|█████▋    | 12/21 [00:00<00:00, 18.18it/s, train_loss=0.00381, val_loss=0.00381]Epoch 32:  57%|█████▋    | 12/21 [00:00<00:00, 18.06it/s, train_loss=0.00376, val_loss=0.00381]Epoch 32:  62%|██████▏   | 13/21 [00:00<00:00, 18.20it/s, train_loss=0.00376, val_loss=0.00381]Epoch 32:  62%|██████▏   | 13/21 [00:00<00:00, 17.97it/s, train_loss=0.00399, val_loss=0.00381]Epoch 32:  67%|██████▋   | 14/21 [00:00<00:00, 18.00it/s, train_loss=0.00399, val_loss=0.00381]Epoch 32:  67%|██████▋   | 14/21 [00:00<00:00, 17.72it/s, train_loss=0.00404, val_loss=0.00381]Epoch 32:  71%|███████▏  | 15/21 [00:00<00:00, 18.02it/s, train_loss=0.00404, val_loss=0.00381]Epoch 32:  71%|███████▏  | 15/21 [00:00<00:00, 17.79it/s, train_loss=0.00386, val_loss=0.00381]Epoch 32:  76%|███████▌  | 16/21 [00:00<00:00, 18.23it/s, train_loss=0.00386, val_loss=0.00381]Epoch 32:  76%|███████▌  | 16/21 [00:00<00:00, 17.93it/s, train_loss=0.00389, val_loss=0.00381]Epoch 32:  81%|████████  | 17/21 [00:00<00:00, 17.72it/s, train_loss=0.00389, val_loss=0.00381]Epoch 32:  81%|████████  | 17/21 [00:00<00:00, 17.61it/s, train_loss=0.0039, val_loss=0.00381] Epoch 32:  86%|████████▌ | 18/21 [00:01<00:00, 17.80it/s, train_loss=0.0039, val_loss=0.00381]Epoch 32:  86%|████████▌ | 18/21 [00:01<00:00, 17.70it/s, train_loss=0.00372, val_loss=0.00381]Epoch 32:  90%|█████████ | 19/21 [00:01<00:00, 17.63it/s, train_loss=0.00372, val_loss=0.00381]Epoch 32:  90%|█████████ | 19/21 [00:01<00:00, 17.59it/s, train_loss=0.00366, val_loss=0.00381]Epoch 32:  95%|█████████▌| 20/21 [00:01<00:00, 17.85it/s, train_loss=0.00366, val_loss=0.00381]Epoch 32:  95%|█████████▌| 20/21 [00:01<00:00, 17.73it/s, train_loss=0.00371, val_loss=0.00381]Epoch 32: 100%|██████████| 21/21 [00:01<00:00, 17.87it/s, train_loss=0.00371, val_loss=0.00381]Epoch 32: 100%|██████████| 21/21 [00:01<00:00, 17.82it/s, train_loss=0.00432, val_loss=0.00381]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 31.91it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 33.26it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 30.96it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 35.02it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 35.97it/s][A
                                                                      [AEpoch 32: 100%|██████████| 21/21 [00:01<00:00, 15.72it/s, train_loss=0.00432, val_loss=0.0038] Epoch 32: 100%|██████████| 21/21 [00:01<00:00, 15.70it/s, train_loss=0.00432, val_loss=0.0038]Epoch 32:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00432, val_loss=0.0038]         Epoch 33:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00432, val_loss=0.0038]Epoch 33:   5%|▍         | 1/21 [00:00<00:01, 19.38it/s, train_loss=0.00432, val_loss=0.0038]Epoch 33:   5%|▍         | 1/21 [00:00<00:01, 17.90it/s, train_loss=0.00391, val_loss=0.0038]Epoch 33:  10%|▉         | 2/21 [00:00<00:00, 19.75it/s, train_loss=0.00391, val_loss=0.0038]Epoch 33:  10%|▉         | 2/21 [00:00<00:01, 18.10it/s, train_loss=0.00369, val_loss=0.0038]Epoch 33:  14%|█▍        | 3/21 [00:00<00:00, 19.12it/s, train_loss=0.00369, val_loss=0.0038]Epoch 33:  14%|█▍        | 3/21 [00:00<00:00, 18.24it/s, train_loss=0.00397, val_loss=0.0038]Epoch 33:  19%|█▉        | 4/21 [00:00<00:00, 19.52it/s, train_loss=0.00397, val_loss=0.0038]Epoch 33:  19%|█▉        | 4/21 [00:00<00:00, 18.76it/s, train_loss=0.00414, val_loss=0.0038]Epoch 33:  24%|██▍       | 5/21 [00:00<00:00, 19.47it/s, train_loss=0.00414, val_loss=0.0038]Epoch 33:  24%|██▍       | 5/21 [00:00<00:00, 18.69it/s, train_loss=0.00389, val_loss=0.0038]Epoch 33:  29%|██▊       | 6/21 [00:00<00:00, 19.14it/s, train_loss=0.00389, val_loss=0.0038]Epoch 33:  29%|██▊       | 6/21 [00:00<00:00, 18.73it/s, train_loss=0.004, val_loss=0.0038]  Epoch 33:  33%|███▎      | 7/21 [00:00<00:00, 18.76it/s, train_loss=0.004, val_loss=0.0038]Epoch 33:  33%|███▎      | 7/21 [00:00<00:00, 18.57it/s, train_loss=0.00368, val_loss=0.0038]Epoch 33:  38%|███▊      | 8/21 [00:00<00:00, 19.00it/s, train_loss=0.00368, val_loss=0.0038]Epoch 33:  38%|███▊      | 8/21 [00:00<00:00, 18.61it/s, train_loss=0.00379, val_loss=0.0038]Epoch 33:  43%|████▎     | 9/21 [00:00<00:00, 18.55it/s, train_loss=0.00379, val_loss=0.0038]Epoch 33:  43%|████▎     | 9/21 [00:00<00:00, 18.46it/s, train_loss=0.00393, val_loss=0.0038]Epoch 33:  48%|████▊     | 10/21 [00:00<00:00, 18.62it/s, train_loss=0.00393, val_loss=0.0038]Epoch 33:  48%|████▊     | 10/21 [00:00<00:00, 18.25it/s, train_loss=0.0037, val_loss=0.0038] Epoch 33:  52%|█████▏    | 11/21 [00:00<00:00, 13.72it/s, train_loss=0.0037, val_loss=0.0038]Epoch 33:  52%|█████▏    | 11/21 [00:00<00:00, 13.59it/s, train_loss=0.00397, val_loss=0.0038]Epoch 33:  57%|█████▋    | 12/21 [00:00<00:00, 13.81it/s, train_loss=0.00397, val_loss=0.0038]Epoch 33:  57%|█████▋    | 12/21 [00:00<00:00, 13.78it/s, train_loss=0.00376, val_loss=0.0038]Epoch 33:  62%|██████▏   | 13/21 [00:00<00:00, 14.19it/s, train_loss=0.00376, val_loss=0.0038]Epoch 33:  62%|██████▏   | 13/21 [00:00<00:00, 14.11it/s, train_loss=0.00418, val_loss=0.0038]Epoch 33:  67%|██████▋   | 14/21 [00:00<00:00, 14.18it/s, train_loss=0.00418, val_loss=0.0038]Epoch 33:  67%|██████▋   | 14/21 [00:00<00:00, 14.09it/s, train_loss=0.00376, val_loss=0.0038]Epoch 33:  71%|███████▏  | 15/21 [00:01<00:00, 14.35it/s, train_loss=0.00376, val_loss=0.0038]Epoch 33:  71%|███████▏  | 15/21 [00:01<00:00, 14.23it/s, train_loss=0.00361, val_loss=0.0038]Epoch 33:  76%|███████▌  | 16/21 [00:01<00:00, 14.61it/s, train_loss=0.00361, val_loss=0.0038]Epoch 33:  76%|███████▌  | 16/21 [00:01<00:00, 14.47it/s, train_loss=0.00404, val_loss=0.0038]Epoch 33:  81%|████████  | 17/21 [00:01<00:00, 14.72it/s, train_loss=0.00404, val_loss=0.0038]Epoch 33:  81%|████████  | 17/21 [00:01<00:00, 14.67it/s, train_loss=0.00382, val_loss=0.0038]Epoch 33:  86%|████████▌ | 18/21 [00:01<00:00, 14.78it/s, train_loss=0.00382, val_loss=0.0038]Epoch 33:  86%|████████▌ | 18/21 [00:01<00:00, 14.68it/s, train_loss=0.00398, val_loss=0.0038]Epoch 33:  90%|█████████ | 19/21 [00:01<00:00, 14.85it/s, train_loss=0.00398, val_loss=0.0038]Epoch 33:  90%|█████████ | 19/21 [00:01<00:00, 14.76it/s, train_loss=0.00401, val_loss=0.0038]Epoch 33:  95%|█████████▌| 20/21 [00:01<00:00, 15.00it/s, train_loss=0.00401, val_loss=0.0038]Epoch 33:  95%|█████████▌| 20/21 [00:01<00:00, 14.91it/s, train_loss=0.00395, val_loss=0.0038]Epoch 33: 100%|██████████| 21/21 [00:01<00:00, 15.10it/s, train_loss=0.00395, val_loss=0.0038]Epoch 33: 100%|██████████| 21/21 [00:01<00:00, 15.04it/s, train_loss=0.00399, val_loss=0.0038]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 47.52it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 37.91it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 34.20it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 36.60it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 37.84it/s][A
                                                                      [AEpoch 33: 100%|██████████| 21/21 [00:01<00:00, 13.63it/s, train_loss=0.00399, val_loss=0.0038]Epoch 33: 100%|██████████| 21/21 [00:01<00:00, 13.62it/s, train_loss=0.00399, val_loss=0.0038]Epoch 33:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00399, val_loss=0.0038]         Epoch 34:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00399, val_loss=0.0038]Epoch 34:   5%|▍         | 1/21 [00:00<00:01, 15.86it/s, train_loss=0.00399, val_loss=0.0038]Epoch 34:   5%|▍         | 1/21 [00:00<00:01, 14.03it/s, train_loss=0.00385, val_loss=0.0038]Epoch 34:  10%|▉         | 2/21 [00:00<00:01, 17.26it/s, train_loss=0.00385, val_loss=0.0038]Epoch 34:  10%|▉         | 2/21 [00:00<00:01, 15.41it/s, train_loss=0.00393, val_loss=0.0038]Epoch 34:  14%|█▍        | 3/21 [00:00<00:01, 17.89it/s, train_loss=0.00393, val_loss=0.0038]Epoch 34:  14%|█▍        | 3/21 [00:00<00:01, 16.80it/s, train_loss=0.00377, val_loss=0.0038]Epoch 34:  19%|█▉        | 4/21 [00:00<00:01, 16.21it/s, train_loss=0.00377, val_loss=0.0038]Epoch 34:  19%|█▉        | 4/21 [00:00<00:01, 15.60it/s, train_loss=0.00422, val_loss=0.0038]Epoch 34:  24%|██▍       | 5/21 [00:00<00:00, 16.18it/s, train_loss=0.00422, val_loss=0.0038]Epoch 34:  24%|██▍       | 5/21 [00:00<00:00, 16.14it/s, train_loss=0.00389, val_loss=0.0038]Epoch 34:  29%|██▊       | 6/21 [00:00<00:00, 16.88it/s, train_loss=0.00389, val_loss=0.0038]Epoch 34:  29%|██▊       | 6/21 [00:00<00:00, 16.57it/s, train_loss=0.00357, val_loss=0.0038]Epoch 34:  33%|███▎      | 7/21 [00:00<00:00, 17.02it/s, train_loss=0.00357, val_loss=0.0038]Epoch 34:  33%|███▎      | 7/21 [00:00<00:00, 16.67it/s, train_loss=0.00376, val_loss=0.0038]Epoch 34:  38%|███▊      | 8/21 [00:00<00:00, 16.60it/s, train_loss=0.00376, val_loss=0.0038]Epoch 34:  38%|███▊      | 8/21 [00:00<00:00, 16.42it/s, train_loss=0.00397, val_loss=0.0038]Epoch 34:  43%|████▎     | 9/21 [00:00<00:00, 16.54it/s, train_loss=0.00397, val_loss=0.0038]Epoch 34:  43%|████▎     | 9/21 [00:00<00:00, 16.35it/s, train_loss=0.00368, val_loss=0.0038]Epoch 34:  48%|████▊     | 10/21 [00:00<00:00, 16.64it/s, train_loss=0.00368, val_loss=0.0038]Epoch 34:  48%|████▊     | 10/21 [00:00<00:00, 16.52it/s, train_loss=0.0041, val_loss=0.0038] Epoch 34:  52%|█████▏    | 11/21 [00:00<00:00, 16.84it/s, train_loss=0.0041, val_loss=0.0038]Epoch 34:  52%|█████▏    | 11/21 [00:00<00:00, 16.53it/s, train_loss=0.00391, val_loss=0.0038]Epoch 34:  57%|█████▋    | 12/21 [00:00<00:00, 16.91it/s, train_loss=0.00391, val_loss=0.0038]Epoch 34:  57%|█████▋    | 12/21 [00:00<00:00, 16.61it/s, train_loss=0.00378, val_loss=0.0038]Epoch 34:  62%|██████▏   | 13/21 [00:00<00:00, 16.94it/s, train_loss=0.00378, val_loss=0.0038]Epoch 34:  62%|██████▏   | 13/21 [00:00<00:00, 16.74it/s, train_loss=0.00389, val_loss=0.0038]Epoch 34:  67%|██████▋   | 14/21 [00:00<00:00, 17.09it/s, train_loss=0.00389, val_loss=0.0038]Epoch 34:  67%|██████▋   | 14/21 [00:00<00:00, 16.88it/s, train_loss=0.00381, val_loss=0.0038]Epoch 34:  71%|███████▏  | 15/21 [00:00<00:00, 17.18it/s, train_loss=0.00381, val_loss=0.0038]Epoch 34:  71%|███████▏  | 15/21 [00:00<00:00, 17.00it/s, train_loss=0.00381, val_loss=0.0038]Epoch 34:  76%|███████▌  | 16/21 [00:00<00:00, 17.24it/s, train_loss=0.00381, val_loss=0.0038]Epoch 34:  76%|███████▌  | 16/21 [00:00<00:00, 17.13it/s, train_loss=0.00385, val_loss=0.0038]Epoch 34:  81%|████████  | 17/21 [00:00<00:00, 17.17it/s, train_loss=0.00385, val_loss=0.0038]Epoch 34:  81%|████████  | 17/21 [00:00<00:00, 17.15it/s, train_loss=0.0037, val_loss=0.0038] Epoch 34:  86%|████████▌ | 18/21 [00:01<00:00, 17.30it/s, train_loss=0.0037, val_loss=0.0038]Epoch 34:  86%|████████▌ | 18/21 [00:01<00:00, 17.18it/s, train_loss=0.00386, val_loss=0.0038]Epoch 34:  90%|█████████ | 19/21 [00:01<00:00, 17.15it/s, train_loss=0.00386, val_loss=0.0038]Epoch 34:  90%|█████████ | 19/21 [00:01<00:00, 17.07it/s, train_loss=0.00382, val_loss=0.0038]Epoch 34:  95%|█████████▌| 20/21 [00:01<00:00, 17.33it/s, train_loss=0.00382, val_loss=0.0038]Epoch 34:  95%|█████████▌| 20/21 [00:01<00:00, 17.16it/s, train_loss=0.00373, val_loss=0.0038]Epoch 34: 100%|██████████| 21/21 [00:01<00:00, 17.53it/s, train_loss=0.00373, val_loss=0.0038]Epoch 34: 100%|██████████| 21/21 [00:01<00:00, 17.36it/s, train_loss=0.0037, val_loss=0.0038] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 26.11it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 32.90it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 33.36it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 36.08it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 38.58it/s][A
                                                                      [AEpoch 34: 100%|██████████| 21/21 [00:01<00:00, 15.55it/s, train_loss=0.0037, val_loss=0.00379]Epoch 34: 100%|██████████| 21/21 [00:01<00:00, 15.54it/s, train_loss=0.0037, val_loss=0.00379]Epoch 34:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0037, val_loss=0.00379]         Epoch 35:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.0037, val_loss=0.00379]Epoch 35:   5%|▍         | 1/21 [00:00<00:01, 16.42it/s, train_loss=0.0037, val_loss=0.00379]Epoch 35:   5%|▍         | 1/21 [00:00<00:01, 14.88it/s, train_loss=0.00376, val_loss=0.00379]Epoch 35:  10%|▉         | 2/21 [00:00<00:01, 17.23it/s, train_loss=0.00376, val_loss=0.00379]Epoch 35:  10%|▉         | 2/21 [00:00<00:01, 16.43it/s, train_loss=0.00396, val_loss=0.00379]Epoch 35:  14%|█▍        | 3/21 [00:00<00:01, 17.53it/s, train_loss=0.00396, val_loss=0.00379]Epoch 35:  14%|█▍        | 3/21 [00:00<00:01, 17.00it/s, train_loss=0.00371, val_loss=0.00379]Epoch 35:  19%|█▉        | 4/21 [00:00<00:00, 17.20it/s, train_loss=0.00371, val_loss=0.00379]Epoch 35:  19%|█▉        | 4/21 [00:00<00:01, 16.95it/s, train_loss=0.00376, val_loss=0.00379]Epoch 35:  24%|██▍       | 5/21 [00:00<00:00, 18.05it/s, train_loss=0.00376, val_loss=0.00379]Epoch 35:  24%|██▍       | 5/21 [00:00<00:00, 17.49it/s, train_loss=0.00402, val_loss=0.00379]Epoch 35:  29%|██▊       | 6/21 [00:00<00:00, 17.61it/s, train_loss=0.00402, val_loss=0.00379]Epoch 35:  29%|██▊       | 6/21 [00:00<00:00, 17.33it/s, train_loss=0.00383, val_loss=0.00379]Epoch 35:  33%|███▎      | 7/21 [00:00<00:00, 17.62it/s, train_loss=0.00383, val_loss=0.00379]Epoch 35:  33%|███▎      | 7/21 [00:00<00:00, 17.18it/s, train_loss=0.00384, val_loss=0.00379]Epoch 35:  38%|███▊      | 8/21 [00:00<00:00, 17.65it/s, train_loss=0.00384, val_loss=0.00379]Epoch 35:  38%|███▊      | 8/21 [00:00<00:00, 17.29it/s, train_loss=0.00404, val_loss=0.00379]Epoch 35:  43%|████▎     | 9/21 [00:00<00:00, 17.50it/s, train_loss=0.00404, val_loss=0.00379]Epoch 35:  43%|████▎     | 9/21 [00:00<00:00, 17.26it/s, train_loss=0.00427, val_loss=0.00379]Epoch 35:  48%|████▊     | 10/21 [00:00<00:00, 17.55it/s, train_loss=0.00427, val_loss=0.00379]Epoch 35:  48%|████▊     | 10/21 [00:00<00:00, 17.24it/s, train_loss=0.00373, val_loss=0.00379]Epoch 35:  52%|█████▏    | 11/21 [00:00<00:00, 17.40it/s, train_loss=0.00373, val_loss=0.00379]Epoch 35:  52%|█████▏    | 11/21 [00:00<00:00, 17.30it/s, train_loss=0.00366, val_loss=0.00379]Epoch 35:  57%|█████▋    | 12/21 [00:00<00:00, 17.21it/s, train_loss=0.00366, val_loss=0.00379]Epoch 35:  57%|█████▋    | 12/21 [00:00<00:00, 17.12it/s, train_loss=0.00351, val_loss=0.00379]Epoch 35:  62%|██████▏   | 13/21 [00:00<00:00, 17.00it/s, train_loss=0.00351, val_loss=0.00379]Epoch 35:  62%|██████▏   | 13/21 [00:00<00:00, 16.86it/s, train_loss=0.00385, val_loss=0.00379]Epoch 35:  67%|██████▋   | 14/21 [00:00<00:00, 17.05it/s, train_loss=0.00385, val_loss=0.00379]Epoch 35:  67%|██████▋   | 14/21 [00:00<00:00, 16.92it/s, train_loss=0.00394, val_loss=0.00379]Epoch 35:  71%|███████▏  | 15/21 [00:00<00:00, 17.28it/s, train_loss=0.00394, val_loss=0.00379]Epoch 35:  71%|███████▏  | 15/21 [00:00<00:00, 17.10it/s, train_loss=0.00373, val_loss=0.00379]Epoch 35:  76%|███████▌  | 16/21 [00:00<00:00, 17.14it/s, train_loss=0.00373, val_loss=0.00379]Epoch 35:  76%|███████▌  | 16/21 [00:00<00:00, 16.95it/s, train_loss=0.00382, val_loss=0.00379]Epoch 35:  81%|████████  | 17/21 [00:00<00:00, 17.15it/s, train_loss=0.00382, val_loss=0.00379]Epoch 35:  81%|████████  | 17/21 [00:01<00:00, 16.98it/s, train_loss=0.00381, val_loss=0.00379]Epoch 35:  86%|████████▌ | 18/21 [00:01<00:00, 17.24it/s, train_loss=0.00381, val_loss=0.00379]Epoch 35:  86%|████████▌ | 18/21 [00:01<00:00, 17.09it/s, train_loss=0.00374, val_loss=0.00379]Epoch 35:  90%|█████████ | 19/21 [00:01<00:00, 17.06it/s, train_loss=0.00374, val_loss=0.00379]Epoch 35:  90%|█████████ | 19/21 [00:01<00:00, 16.96it/s, train_loss=0.00371, val_loss=0.00379]Epoch 35:  95%|█████████▌| 20/21 [00:01<00:00, 16.99it/s, train_loss=0.00371, val_loss=0.00379]Epoch 35:  95%|█████████▌| 20/21 [00:01<00:00, 16.84it/s, train_loss=0.00401, val_loss=0.00379]Epoch 35: 100%|██████████| 21/21 [00:01<00:00, 16.82it/s, train_loss=0.00401, val_loss=0.00379]Epoch 35: 100%|██████████| 21/21 [00:01<00:00, 16.80it/s, train_loss=0.00391, val_loss=0.00379]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 43.31it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 43.21it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 44.03it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 43.43it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 45.64it/s][A
                                                                      [AEpoch 35: 100%|██████████| 21/21 [00:01<00:00, 15.33it/s, train_loss=0.00391, val_loss=0.00379]Epoch 35: 100%|██████████| 21/21 [00:01<00:00, 15.31it/s, train_loss=0.00391, val_loss=0.00379]Epoch 35:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00391, val_loss=0.00379]         Epoch 36:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00391, val_loss=0.00379]Epoch 36:   5%|▍         | 1/21 [00:00<00:01, 19.02it/s, train_loss=0.00391, val_loss=0.00379]Epoch 36:   5%|▍         | 1/21 [00:00<00:01, 16.47it/s, train_loss=0.00368, val_loss=0.00379]Epoch 36:  10%|▉         | 2/21 [00:00<00:01, 16.82it/s, train_loss=0.00368, val_loss=0.00379]Epoch 36:  10%|▉         | 2/21 [00:00<00:01, 15.51it/s, train_loss=0.00355, val_loss=0.00379]Epoch 36:  14%|█▍        | 3/21 [00:00<00:01, 17.05it/s, train_loss=0.00355, val_loss=0.00379]Epoch 36:  14%|█▍        | 3/21 [00:00<00:01, 16.49it/s, train_loss=0.00376, val_loss=0.00379]Epoch 36:  19%|█▉        | 4/21 [00:00<00:00, 17.38it/s, train_loss=0.00376, val_loss=0.00379]Epoch 36:  19%|█▉        | 4/21 [00:00<00:00, 17.02it/s, train_loss=0.00394, val_loss=0.00379]Epoch 36:  24%|██▍       | 5/21 [00:00<00:00, 17.42it/s, train_loss=0.00394, val_loss=0.00379]Epoch 36:  24%|██▍       | 5/21 [00:00<00:00, 17.12it/s, train_loss=0.00376, val_loss=0.00379]Epoch 36:  29%|██▊       | 6/21 [00:00<00:00, 16.92it/s, train_loss=0.00376, val_loss=0.00379]Epoch 36:  29%|██▊       | 6/21 [00:00<00:00, 16.59it/s, train_loss=0.0039, val_loss=0.00379] Epoch 36:  33%|███▎      | 7/21 [00:00<00:00, 16.39it/s, train_loss=0.0039, val_loss=0.00379]Epoch 36:  33%|███▎      | 7/21 [00:00<00:00, 16.14it/s, train_loss=0.00404, val_loss=0.00379]Epoch 36:  38%|███▊      | 8/21 [00:00<00:00, 16.19it/s, train_loss=0.00404, val_loss=0.00379]Epoch 36:  38%|███▊      | 8/21 [00:00<00:00, 15.89it/s, train_loss=0.00401, val_loss=0.00379]Epoch 36:  43%|████▎     | 9/21 [00:00<00:00, 16.57it/s, train_loss=0.00401, val_loss=0.00379]Epoch 36:  43%|████▎     | 9/21 [00:00<00:00, 16.32it/s, train_loss=0.00392, val_loss=0.00379]Epoch 36:  48%|████▊     | 10/21 [00:00<00:00, 16.99it/s, train_loss=0.00392, val_loss=0.00379]Epoch 36:  48%|████▊     | 10/21 [00:00<00:00, 16.70it/s, train_loss=0.00377, val_loss=0.00379]Epoch 36:  52%|█████▏    | 11/21 [00:00<00:00, 16.47it/s, train_loss=0.00377, val_loss=0.00379]Epoch 36:  52%|█████▏    | 11/21 [00:00<00:00, 16.29it/s, train_loss=0.00382, val_loss=0.00379]Epoch 36:  57%|█████▋    | 12/21 [00:00<00:00, 16.54it/s, train_loss=0.00382, val_loss=0.00379]Epoch 36:  57%|█████▋    | 12/21 [00:00<00:00, 16.45it/s, train_loss=0.00364, val_loss=0.00379]Epoch 36:  62%|██████▏   | 13/21 [00:00<00:00, 16.42it/s, train_loss=0.00364, val_loss=0.00379]Epoch 36:  62%|██████▏   | 13/21 [00:00<00:00, 16.25it/s, train_loss=0.00394, val_loss=0.00379]Epoch 36:  67%|██████▋   | 14/21 [00:00<00:00, 16.45it/s, train_loss=0.00394, val_loss=0.00379]Epoch 36:  67%|██████▋   | 14/21 [00:00<00:00, 16.34it/s, train_loss=0.00358, val_loss=0.00379]Epoch 36:  71%|███████▏  | 15/21 [00:00<00:00, 16.11it/s, train_loss=0.00358, val_loss=0.00379]Epoch 36:  71%|███████▏  | 15/21 [00:00<00:00, 15.95it/s, train_loss=0.00384, val_loss=0.00379]Epoch 36:  76%|███████▌  | 16/21 [00:00<00:00, 16.28it/s, train_loss=0.00384, val_loss=0.00379]Epoch 36:  76%|███████▌  | 16/21 [00:00<00:00, 16.14it/s, train_loss=0.00382, val_loss=0.00379]Epoch 36:  81%|████████  | 17/21 [00:01<00:00, 16.27it/s, train_loss=0.00382, val_loss=0.00379]Epoch 36:  81%|████████  | 17/21 [00:01<00:00, 16.20it/s, train_loss=0.00362, val_loss=0.00379]Epoch 36:  86%|████████▌ | 18/21 [00:01<00:00, 16.39it/s, train_loss=0.00362, val_loss=0.00379]Epoch 36:  86%|████████▌ | 18/21 [00:01<00:00, 16.34it/s, train_loss=0.00395, val_loss=0.00379]Epoch 36:  90%|█████████ | 19/21 [00:01<00:00, 16.52it/s, train_loss=0.00395, val_loss=0.00379]Epoch 36:  90%|█████████ | 19/21 [00:01<00:00, 16.42it/s, train_loss=0.004, val_loss=0.00379]  Epoch 36:  95%|█████████▌| 20/21 [00:01<00:00, 16.57it/s, train_loss=0.004, val_loss=0.00379]Epoch 36:  95%|█████████▌| 20/21 [00:01<00:00, 16.48it/s, train_loss=0.00381, val_loss=0.00379]Epoch 36: 100%|██████████| 21/21 [00:01<00:00, 16.68it/s, train_loss=0.00381, val_loss=0.00379]Epoch 36: 100%|██████████| 21/21 [00:01<00:00, 16.59it/s, train_loss=0.00425, val_loss=0.00379]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 14.14it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 20.45it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 24.61it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 27.56it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 28.92it/s][A
                                                                      [AEpoch 36: 100%|██████████| 21/21 [00:01<00:00, 14.49it/s, train_loss=0.00425, val_loss=0.00378]Epoch 36: 100%|██████████| 21/21 [00:01<00:00, 14.47it/s, train_loss=0.00425, val_loss=0.00378]Epoch 36:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00425, val_loss=0.00378]         Epoch 37:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00425, val_loss=0.00378]Epoch 37:   5%|▍         | 1/21 [00:00<00:01, 16.13it/s, train_loss=0.00425, val_loss=0.00378]Epoch 37:   5%|▍         | 1/21 [00:00<00:01, 15.74it/s, train_loss=0.0038, val_loss=0.00378] Epoch 37:  10%|▉         | 2/21 [00:00<00:00, 20.67it/s, train_loss=0.0038, val_loss=0.00378]Epoch 37:  10%|▉         | 2/21 [00:00<00:01, 17.74it/s, train_loss=0.00405, val_loss=0.00378]Epoch 37:  14%|█▍        | 3/21 [00:00<00:01, 17.33it/s, train_loss=0.00405, val_loss=0.00378]Epoch 37:  14%|█▍        | 3/21 [00:00<00:01, 16.55it/s, train_loss=0.00372, val_loss=0.00378]Epoch 37:  19%|█▉        | 4/21 [00:00<00:00, 18.62it/s, train_loss=0.00372, val_loss=0.00378]Epoch 37:  19%|█▉        | 4/21 [00:00<00:00, 17.56it/s, train_loss=0.00375, val_loss=0.00378]Epoch 37:  24%|██▍       | 5/21 [00:00<00:00, 17.48it/s, train_loss=0.00375, val_loss=0.00378]Epoch 37:  24%|██▍       | 5/21 [00:00<00:00, 17.32it/s, train_loss=0.00397, val_loss=0.00378]Epoch 37:  29%|██▊       | 6/21 [00:00<00:00, 17.60it/s, train_loss=0.00397, val_loss=0.00378]Epoch 37:  29%|██▊       | 6/21 [00:00<00:00, 17.13it/s, train_loss=0.00389, val_loss=0.00378]Epoch 37:  33%|███▎      | 7/21 [00:00<00:00, 17.50it/s, train_loss=0.00389, val_loss=0.00378]Epoch 37:  33%|███▎      | 7/21 [00:00<00:00, 17.37it/s, train_loss=0.00382, val_loss=0.00378]Epoch 37:  38%|███▊      | 8/21 [00:00<00:00, 17.32it/s, train_loss=0.00382, val_loss=0.00378]Epoch 37:  38%|███▊      | 8/21 [00:00<00:00, 17.13it/s, train_loss=0.0039, val_loss=0.00378] Epoch 37:  43%|████▎     | 9/21 [00:00<00:00, 17.59it/s, train_loss=0.0039, val_loss=0.00378]Epoch 37:  43%|████▎     | 9/21 [00:00<00:00, 17.36it/s, train_loss=0.00362, val_loss=0.00378]Epoch 37:  48%|████▊     | 10/21 [00:00<00:00, 17.24it/s, train_loss=0.00362, val_loss=0.00378]Epoch 37:  48%|████▊     | 10/21 [00:00<00:00, 17.13it/s, train_loss=0.00384, val_loss=0.00378]Epoch 37:  52%|█████▏    | 11/21 [00:00<00:00, 17.43it/s, train_loss=0.00384, val_loss=0.00378]Epoch 37:  52%|█████▏    | 11/21 [00:00<00:00, 17.13it/s, train_loss=0.00379, val_loss=0.00378]Epoch 37:  57%|█████▋    | 12/21 [00:00<00:00, 17.29it/s, train_loss=0.00379, val_loss=0.00378]Epoch 37:  57%|█████▋    | 12/21 [00:00<00:00, 17.04it/s, train_loss=0.0037, val_loss=0.00378] Epoch 37:  62%|██████▏   | 13/21 [00:00<00:00, 17.22it/s, train_loss=0.0037, val_loss=0.00378]Epoch 37:  62%|██████▏   | 13/21 [00:00<00:00, 17.05it/s, train_loss=0.00422, val_loss=0.00378]Epoch 37:  67%|██████▋   | 14/21 [00:00<00:00, 17.18it/s, train_loss=0.00422, val_loss=0.00378]Epoch 37:  67%|██████▋   | 14/21 [00:00<00:00, 17.05it/s, train_loss=0.00368, val_loss=0.00378]Epoch 37:  71%|███████▏  | 15/21 [00:00<00:00, 17.14it/s, train_loss=0.00368, val_loss=0.00378]Epoch 37:  71%|███████▏  | 15/21 [00:00<00:00, 17.02it/s, train_loss=0.00374, val_loss=0.00378]Epoch 37:  76%|███████▌  | 16/21 [00:00<00:00, 17.17it/s, train_loss=0.00374, val_loss=0.00378]Epoch 37:  76%|███████▌  | 16/21 [00:00<00:00, 17.06it/s, train_loss=0.00396, val_loss=0.00378]Epoch 37:  81%|████████  | 17/21 [00:00<00:00, 17.40it/s, train_loss=0.00396, val_loss=0.00378]Epoch 37:  81%|████████  | 17/21 [00:00<00:00, 17.18it/s, train_loss=0.0039, val_loss=0.00378] Epoch 37:  86%|████████▌ | 18/21 [00:01<00:00, 17.29it/s, train_loss=0.0039, val_loss=0.00378]Epoch 37:  86%|████████▌ | 18/21 [00:01<00:00, 17.14it/s, train_loss=0.0037, val_loss=0.00378]Epoch 37:  90%|█████████ | 19/21 [00:01<00:00, 17.25it/s, train_loss=0.0037, val_loss=0.00378]Epoch 37:  90%|█████████ | 19/21 [00:01<00:00, 17.10it/s, train_loss=0.0038, val_loss=0.00378]Epoch 37:  95%|█████████▌| 20/21 [00:01<00:00, 17.06it/s, train_loss=0.0038, val_loss=0.00378]Epoch 37:  95%|█████████▌| 20/21 [00:01<00:00, 16.95it/s, train_loss=0.00379, val_loss=0.00378]Epoch 37: 100%|██████████| 21/21 [00:01<00:00, 17.14it/s, train_loss=0.00379, val_loss=0.00378]Epoch 37: 100%|██████████| 21/21 [00:01<00:00, 17.02it/s, train_loss=0.00397, val_loss=0.00378]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 51.87it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 50.81it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 53.26it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 41.55it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 42.30it/s][A
                                                                      [AEpoch 37: 100%|██████████| 21/21 [00:01<00:00, 15.45it/s, train_loss=0.00397, val_loss=0.00378]Epoch 37: 100%|██████████| 21/21 [00:01<00:00, 15.39it/s, train_loss=0.00397, val_loss=0.00378]Epoch 37:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00397, val_loss=0.00378]         Epoch 38:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00397, val_loss=0.00378]Epoch 38:   5%|▍         | 1/21 [00:00<00:00, 22.58it/s, train_loss=0.00397, val_loss=0.00378]Epoch 38:   5%|▍         | 1/21 [00:00<00:01, 19.02it/s, train_loss=0.00398, val_loss=0.00378]Epoch 38:  10%|▉         | 2/21 [00:00<00:01, 17.76it/s, train_loss=0.00398, val_loss=0.00378]Epoch 38:  10%|▉         | 2/21 [00:00<00:01, 16.99it/s, train_loss=0.00364, val_loss=0.00378]Epoch 38:  14%|█▍        | 3/21 [00:00<00:00, 18.61it/s, train_loss=0.00364, val_loss=0.00378]Epoch 38:  14%|█▍        | 3/21 [00:00<00:00, 18.11it/s, train_loss=0.00396, val_loss=0.00378]Epoch 38:  19%|█▉        | 4/21 [00:00<00:00, 18.73it/s, train_loss=0.00396, val_loss=0.00378]Epoch 38:  19%|█▉        | 4/21 [00:00<00:00, 17.97it/s, train_loss=0.00371, val_loss=0.00378]Epoch 38:  24%|██▍       | 5/21 [00:00<00:00, 17.64it/s, train_loss=0.00371, val_loss=0.00378]Epoch 38:  24%|██▍       | 5/21 [00:00<00:00, 17.43it/s, train_loss=0.00388, val_loss=0.00378]Epoch 38:  29%|██▊       | 6/21 [00:00<00:00, 17.40it/s, train_loss=0.00388, val_loss=0.00378]Epoch 38:  29%|██▊       | 6/21 [00:00<00:00, 17.05it/s, train_loss=0.00397, val_loss=0.00378]Epoch 38:  33%|███▎      | 7/21 [00:00<00:00, 17.61it/s, train_loss=0.00397, val_loss=0.00378]Epoch 38:  33%|███▎      | 7/21 [00:00<00:00, 17.31it/s, train_loss=0.00404, val_loss=0.00378]Epoch 38:  38%|███▊      | 8/21 [00:00<00:00, 18.14it/s, train_loss=0.00404, val_loss=0.00378]Epoch 38:  38%|███▊      | 8/21 [00:00<00:00, 17.64it/s, train_loss=0.00384, val_loss=0.00378]Epoch 38:  43%|████▎     | 9/21 [00:00<00:00, 17.70it/s, train_loss=0.00384, val_loss=0.00378]Epoch 38:  43%|████▎     | 9/21 [00:00<00:00, 17.42it/s, train_loss=0.00381, val_loss=0.00378]Epoch 38:  48%|████▊     | 10/21 [00:00<00:00, 17.94it/s, train_loss=0.00381, val_loss=0.00378]Epoch 38:  48%|████▊     | 10/21 [00:00<00:00, 17.64it/s, train_loss=0.00373, val_loss=0.00378]Epoch 38:  52%|█████▏    | 11/21 [00:00<00:00, 18.00it/s, train_loss=0.00373, val_loss=0.00378]Epoch 38:  52%|█████▏    | 11/21 [00:00<00:00, 17.83it/s, train_loss=0.00373, val_loss=0.00378]Epoch 38:  57%|█████▋    | 12/21 [00:00<00:00, 18.13it/s, train_loss=0.00373, val_loss=0.00378]Epoch 38:  57%|█████▋    | 12/21 [00:00<00:00, 17.93it/s, train_loss=0.00379, val_loss=0.00378]Epoch 38:  62%|██████▏   | 13/21 [00:00<00:00, 17.83it/s, train_loss=0.00379, val_loss=0.00378]Epoch 38:  62%|██████▏   | 13/21 [00:00<00:00, 17.76it/s, train_loss=0.00379, val_loss=0.00378]Epoch 38:  67%|██████▋   | 14/21 [00:00<00:00, 17.56it/s, train_loss=0.00379, val_loss=0.00378]Epoch 38:  67%|██████▋   | 14/21 [00:00<00:00, 17.43it/s, train_loss=0.00389, val_loss=0.00378]Epoch 38:  71%|███████▏  | 15/21 [00:00<00:00, 17.23it/s, train_loss=0.00389, val_loss=0.00378]Epoch 38:  71%|███████▏  | 15/21 [00:00<00:00, 17.12it/s, train_loss=0.00368, val_loss=0.00378]Epoch 38:  76%|███████▌  | 16/21 [00:00<00:00, 17.40it/s, train_loss=0.00368, val_loss=0.00378]Epoch 38:  76%|███████▌  | 16/21 [00:00<00:00, 17.16it/s, train_loss=0.0038, val_loss=0.00378] Epoch 38:  81%|████████  | 17/21 [00:00<00:00, 17.62it/s, train_loss=0.0038, val_loss=0.00378]Epoch 38:  81%|████████  | 17/21 [00:00<00:00, 17.34it/s, train_loss=0.00396, val_loss=0.00378]Epoch 38:  86%|████████▌ | 18/21 [00:01<00:00, 17.52it/s, train_loss=0.00396, val_loss=0.00378]Epoch 38:  86%|████████▌ | 18/21 [00:01<00:00, 17.47it/s, train_loss=0.00372, val_loss=0.00378]Epoch 38:  90%|█████████ | 19/21 [00:01<00:00, 17.47it/s, train_loss=0.00372, val_loss=0.00378]Epoch 38:  90%|█████████ | 19/21 [00:01<00:00, 17.34it/s, train_loss=0.0037, val_loss=0.00378] Epoch 38:  95%|█████████▌| 20/21 [00:01<00:00, 17.29it/s, train_loss=0.0037, val_loss=0.00378]Epoch 38:  95%|█████████▌| 20/21 [00:01<00:00, 17.20it/s, train_loss=0.00382, val_loss=0.00378]Epoch 38: 100%|██████████| 21/21 [00:01<00:00, 17.15it/s, train_loss=0.00382, val_loss=0.00378]Epoch 38: 100%|██████████| 21/21 [00:01<00:00, 17.10it/s, train_loss=0.00368, val_loss=0.00378]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 41.69it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 44.63it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 39.71it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 38.18it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 39.42it/s][A
                                                                      [AEpoch 38: 100%|██████████| 21/21 [00:01<00:00, 15.34it/s, train_loss=0.00368, val_loss=0.00377]Epoch 38: 100%|██████████| 21/21 [00:01<00:00, 15.32it/s, train_loss=0.00368, val_loss=0.00377]Epoch 38:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00368, val_loss=0.00377]         Epoch 39:   0%|          | 0/21 [00:00<?, ?it/s, train_loss=0.00368, val_loss=0.00377]Epoch 39:   5%|▍         | 1/21 [00:00<00:00, 21.18it/s, train_loss=0.00368, val_loss=0.00377]Epoch 39:   5%|▍         | 1/21 [00:00<00:01, 18.54it/s, train_loss=0.00369, val_loss=0.00377]Epoch 39:  10%|▉         | 2/21 [00:00<00:00, 21.16it/s, train_loss=0.00369, val_loss=0.00377]Epoch 39:  10%|▉         | 2/21 [00:00<00:00, 19.04it/s, train_loss=0.00365, val_loss=0.00377]Epoch 39:  14%|█▍        | 3/21 [00:00<00:01, 17.71it/s, train_loss=0.00365, val_loss=0.00377]Epoch 39:  14%|█▍        | 3/21 [00:00<00:01, 16.76it/s, train_loss=0.00407, val_loss=0.00377]Epoch 39:  19%|█▉        | 4/21 [00:00<00:00, 17.61it/s, train_loss=0.00407, val_loss=0.00377]Epoch 39:  19%|█▉        | 4/21 [00:00<00:00, 17.04it/s, train_loss=0.00358, val_loss=0.00377]Epoch 39:  24%|██▍       | 5/21 [00:00<00:00, 18.19it/s, train_loss=0.00358, val_loss=0.00377]Epoch 39:  24%|██▍       | 5/21 [00:00<00:00, 17.64it/s, train_loss=0.00382, val_loss=0.00377]Epoch 39:  29%|██▊       | 6/21 [00:00<00:00, 18.42it/s, train_loss=0.00382, val_loss=0.00377]Epoch 39:  29%|██▊       | 6/21 [00:00<00:00, 17.84it/s, train_loss=0.00368, val_loss=0.00377]Epoch 39:  33%|███▎      | 7/21 [00:00<00:00, 17.99it/s, train_loss=0.00368, val_loss=0.00377]Epoch 39:  33%|███▎      | 7/21 [00:00<00:00, 17.83it/s, train_loss=0.0039, val_loss=0.00377] Epoch 39:  38%|███▊      | 8/21 [00:00<00:00, 17.63it/s, train_loss=0.0039, val_loss=0.00377]Epoch 39:  38%|███▊      | 8/21 [00:00<00:00, 17.48it/s, train_loss=0.00376, val_loss=0.00377]Epoch 39:  43%|████▎     | 9/21 [00:00<00:00, 17.94it/s, train_loss=0.00376, val_loss=0.00377]Epoch 39:  43%|████▎     | 9/21 [00:00<00:00, 17.70it/s, train_loss=0.00392, val_loss=0.00377]Epoch 39:  48%|████▊     | 10/21 [00:00<00:00, 17.99it/s, train_loss=0.00392, val_loss=0.00377]Epoch 39:  48%|████▊     | 10/21 [00:00<00:00, 17.62it/s, train_loss=0.00381, val_loss=0.00377]Epoch 39:  52%|█████▏    | 11/21 [00:00<00:00, 18.16it/s, train_loss=0.00381, val_loss=0.00377]Epoch 39:  52%|█████▏    | 11/21 [00:00<00:00, 17.76it/s, train_loss=0.00388, val_loss=0.00377]Epoch 39:  57%|█████▋    | 12/21 [00:00<00:00, 18.40it/s, train_loss=0.00388, val_loss=0.00377]Epoch 39:  57%|█████▋    | 12/21 [00:00<00:00, 17.93it/s, train_loss=0.00396, val_loss=0.00377]Epoch 39:  62%|██████▏   | 13/21 [00:00<00:00, 17.64it/s, train_loss=0.00396, val_loss=0.00377]Epoch 39:  62%|██████▏   | 13/21 [00:00<00:00, 17.47it/s, train_loss=0.00405, val_loss=0.00377]Epoch 39:  67%|██████▋   | 14/21 [00:00<00:00, 17.62it/s, train_loss=0.00405, val_loss=0.00377]Epoch 39:  67%|██████▋   | 14/21 [00:00<00:00, 17.45it/s, train_loss=0.00359, val_loss=0.00377]Epoch 39:  71%|███████▏  | 15/21 [00:00<00:00, 17.18it/s, train_loss=0.00359, val_loss=0.00377]Epoch 39:  71%|███████▏  | 15/21 [00:00<00:00, 17.06it/s, train_loss=0.00402, val_loss=0.00377]Epoch 39:  76%|███████▌  | 16/21 [00:00<00:00, 17.22it/s, train_loss=0.00402, val_loss=0.00377]Epoch 39:  76%|███████▌  | 16/21 [00:00<00:00, 17.10it/s, train_loss=0.00398, val_loss=0.00377]Epoch 39:  81%|████████  | 17/21 [00:00<00:00, 17.00it/s, train_loss=0.00398, val_loss=0.00377]Epoch 39:  81%|████████  | 17/21 [00:01<00:00, 16.91it/s, train_loss=0.00376, val_loss=0.00377]Epoch 39:  86%|████████▌ | 18/21 [00:01<00:00, 16.97it/s, train_loss=0.00376, val_loss=0.00377]Epoch 39:  86%|████████▌ | 18/21 [00:01<00:00, 16.85it/s, train_loss=0.00388, val_loss=0.00377]Epoch 39:  90%|█████████ | 19/21 [00:01<00:00, 17.10it/s, train_loss=0.00388, val_loss=0.00377]Epoch 39:  90%|█████████ | 19/21 [00:01<00:00, 16.95it/s, train_loss=0.00385, val_loss=0.00377]Epoch 39:  95%|█████████▌| 20/21 [00:01<00:00, 17.00it/s, train_loss=0.00385, val_loss=0.00377]Epoch 39:  95%|█████████▌| 20/21 [00:01<00:00, 16.94it/s, train_loss=0.00371, val_loss=0.00377]Epoch 39: 100%|██████████| 21/21 [00:01<00:00, 16.92it/s, train_loss=0.00371, val_loss=0.00377]Epoch 39: 100%|██████████| 21/21 [00:01<00:00, 16.90it/s, train_loss=0.00385, val_loss=0.00377]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s][A
Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00, 44.36it/s][A
Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00, 46.19it/s][A
Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00, 47.18it/s][A
Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00, 48.42it/s][A
Validation DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 48.89it/s][A
                                                                      [AEpoch 39: 100%|██████████| 21/21 [00:01<00:00, 15.45it/s, train_loss=0.00385, val_loss=0.00377]Epoch 39: 100%|██████████| 21/21 [00:01<00:00, 15.43it/s, train_loss=0.00385, val_loss=0.00377]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 21/21 [00:01<00:00, 15.40it/s, train_loss=0.00385, val_loss=0.00377]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/22 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s]Predicting DataLoader 0:   5%|▍         | 1/22 [00:00<00:00, 49.64it/s]Predicting DataLoader 0:   9%|▉         | 2/22 [00:00<00:00, 44.53it/s]Predicting DataLoader 0:  14%|█▎        | 3/22 [00:00<00:00, 42.39it/s]Predicting DataLoader 0:  18%|█▊        | 4/22 [00:00<00:00, 41.62it/s]Predicting DataLoader 0:  23%|██▎       | 5/22 [00:00<00:00, 42.96it/s]Predicting DataLoader 0:  27%|██▋       | 6/22 [00:00<00:00, 39.28it/s]Predicting DataLoader 0:  32%|███▏      | 7/22 [00:00<00:00, 38.81it/s]Predicting DataLoader 0:  36%|███▋      | 8/22 [00:00<00:00, 39.66it/s]Predicting DataLoader 0:  41%|████      | 9/22 [00:00<00:00, 39.21it/s]Predicting DataLoader 0:  45%|████▌     | 10/22 [00:00<00:00, 39.76it/s]Predicting DataLoader 0:  50%|█████     | 11/22 [00:00<00:00, 40.99it/s]Predicting DataLoader 0:  55%|█████▍    | 12/22 [00:00<00:00, 41.76it/s]Predicting DataLoader 0:  59%|█████▉    | 13/22 [00:00<00:00, 42.54it/s]Predicting DataLoader 0:  64%|██████▎   | 14/22 [00:00<00:00, 43.37it/s]Predicting DataLoader 0:  68%|██████▊   | 15/22 [00:00<00:00, 44.07it/s]Predicting DataLoader 0:  73%|███████▎  | 16/22 [00:00<00:00, 44.24it/s]Predicting DataLoader 0:  77%|███████▋  | 17/22 [00:00<00:00, 44.56it/s]Predicting DataLoader 0:  82%|████████▏ | 18/22 [00:00<00:00, 43.14it/s]Predicting DataLoader 0:  86%|████████▋ | 19/22 [00:00<00:00, 43.01it/s]Predicting DataLoader 0:  91%|█████████ | 20/22 [00:00<00:00, 43.27it/s]Predicting DataLoader 0:  95%|█████████▌| 21/22 [00:00<00:00, 42.96it/s]Predicting DataLoader 0: 100%|██████████| 22/22 [00:00<00:00, 42.94it/s]Predicting DataLoader 0: 100%|██████████| 22/22 [00:00<00:00, 42.76it/s][I 2025-08-18 03:57:28,523] A new study created in memory with name: no-name-5a1b83ca-c74b-4d4f-8821-ea6a9071bc08
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Context length: 160, Horizon length: 30
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.32it/s][I 2025-08-18 03:58:17,972] Trial 0 finished with value: 54.97689009309204 and parameters: {'hidden_dim': 35, 'n_rnn_layers': 4, 'dropout': 0.3904663104619482}. Best is trial 0 with value: 54.97689009309204.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20698881311476958 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.01it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.50it/s][I 2025-08-18 03:58:49,206] Trial 1 finished with value: 31.09357553371819 and parameters: {'hidden_dim': 86, 'n_rnn_layers': 1, 'dropout': 0.20698881311476958}. Best is trial 1 with value: 31.09357553371819.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.29it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.74it/s][I 2025-08-18 03:59:51,425] Trial 2 finished with value: 38.27817875084626 and parameters: {'hidden_dim': 86, 'n_rnn_layers': 4, 'dropout': 0.4228712861872424}. Best is trial 1 with value: 31.09357553371819.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.78it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.91it/s][I 2025-08-18 04:00:47,409] Trial 3 finished with value: 32.302440403799075 and parameters: {'hidden_dim': 86, 'n_rnn_layers': 4, 'dropout': 0.2032601469507464}. Best is trial 1 with value: 31.09357553371819.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28172145512985536 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.28it/s][I 2025-08-18 04:01:11,008] Trial 4 finished with value: 40.97452330592862 and parameters: {'hidden_dim': 23, 'n_rnn_layers': 1, 'dropout': 0.28172145512985536}. Best is trial 1 with value: 31.09357553371819.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.22it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.31it/s][I 2025-08-18 04:02:15,293] Trial 5 finished with value: 40.83637785384274 and parameters: {'hidden_dim': 96, 'n_rnn_layers': 4, 'dropout': 0.2454219779564653}. Best is trial 1 with value: 31.09357553371819.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.57it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.71it/s][I 2025-08-18 04:02:48,067] Trial 6 finished with value: 36.59294410237793 and parameters: {'hidden_dim': 48, 'n_rnn_layers': 3, 'dropout': 0.023196706686954505}. Best is trial 1 with value: 31.09357553371819.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.70it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.34it/s][I 2025-08-18 04:03:26,776] Trial 7 finished with value: 25.912565418420833 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 3, 'dropout': 0.41600312401079625}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30568337761449443 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.96it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.13it/s][I 2025-08-18 04:03:55,523] Trial 8 finished with value: 48.37709716054408 and parameters: {'hidden_dim': 79, 'n_rnn_layers': 1, 'dropout': 0.30568337761449443}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11433093685106605 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.03it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s][I 2025-08-18 04:04:25,871] Trial 9 finished with value: 37.338315558994516 and parameters: {'hidden_dim': 37, 'n_rnn_layers': 1, 'dropout': 0.11433093685106605}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.47it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.30it/s][I 2025-08-18 04:04:57,433] Trial 10 finished with value: 40.019923381686645 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 2, 'dropout': 0.4984079951028815}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.14it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s][I 2025-08-18 04:05:25,602] Trial 11 finished with value: 36.90404012346767 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 2, 'dropout': 0.16002020269643075}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.21it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.34it/s][I 2025-08-18 04:06:25,920] Trial 12 finished with value: 61.985941899432355 and parameters: {'hidden_dim': 127, 'n_rnn_layers': 3, 'dropout': 0.36595284407656226}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.89it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.26it/s][I 2025-08-18 04:07:08,633] Trial 13 finished with value: 49.13995341161353 and parameters: {'hidden_dim': 56, 'n_rnn_layers': 2, 'dropout': 0.10656422023087894}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.92it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.88it/s][I 2025-08-18 04:08:06,974] Trial 14 finished with value: 34.313325723244596 and parameters: {'hidden_dim': 65, 'n_rnn_layers': 3, 'dropout': 0.4882747911638136}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s][I 2025-08-18 04:08:40,207] Trial 15 finished with value: 37.305841834743305 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 2, 'dropout': 0.3304806886008907}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.35it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.70it/s][I 2025-08-18 04:09:39,357] Trial 16 finished with value: 38.07163148807361 and parameters: {'hidden_dim': 127, 'n_rnn_layers': 3, 'dropout': 0.23288403783336226}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.00957122261276011 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.51it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.80it/s][I 2025-08-18 04:10:02,190] Trial 17 finished with value: 36.34424460963782 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 1, 'dropout': 0.00957122261276011}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.53it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.52it/s][I 2025-08-18 04:10:38,028] Trial 18 finished with value: 30.691488592687172 and parameters: {'hidden_dim': 40, 'n_rnn_layers': 2, 'dropout': 0.4438858916648693}. Best is trial 7 with value: 25.912565418420833.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.77it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.32it/s][I 2025-08-18 04:11:19,073] Trial 19 finished with value: 35.28571174544934 and parameters: {'hidden_dim': 27, 'n_rnn_layers': 3, 'dropout': 0.45004387088956677}. Best is trial 7 with value: 25.912565418420833.
[I 2025-08-18 04:11:19,074] A new study created in memory with name: no-name-7bc8bdd2-4d2e-414f-8a7a-11f59cebae0b
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2145575383990122 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Melhores parâmetros: {'hidden_dim': 16, 'n_rnn_layers': 3, 'dropout': 0.41600312401079625}
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.28it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s][I 2025-08-18 04:11:49,595] Trial 0 finished with value: 43.35091782214342 and parameters: {'hidden_dim': 30, 'n_rnn_layers': 1, 'dropout': 0.2145575383990122}. Best is trial 0 with value: 43.35091782214342.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.26it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.17it/s][I 2025-08-18 04:12:26,416] Trial 1 finished with value: 34.72705763953829 and parameters: {'hidden_dim': 37, 'n_rnn_layers': 2, 'dropout': 0.46865699159416274}. Best is trial 1 with value: 34.72705763953829.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43325234366275833 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.04it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.47it/s][I 2025-08-18 04:12:51,099] Trial 2 finished with value: 35.343222359178576 and parameters: {'hidden_dim': 21, 'n_rnn_layers': 1, 'dropout': 0.43325234366275833}. Best is trial 1 with value: 34.72705763953829.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.08it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s][I 2025-08-18 04:13:37,905] Trial 3 finished with value: 48.33874584921576 and parameters: {'hidden_dim': 41, 'n_rnn_layers': 3, 'dropout': 0.024155757576663217}. Best is trial 1 with value: 34.72705763953829.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.34it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.50it/s][I 2025-08-18 04:14:25,952] Trial 4 finished with value: 32.018303982752954 and parameters: {'hidden_dim': 22, 'n_rnn_layers': 4, 'dropout': 0.046373999787211684}. Best is trial 4 with value: 32.018303982752954.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.42it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.91it/s][I 2025-08-18 04:15:27,480] Trial 5 finished with value: 40.289752679421326 and parameters: {'hidden_dim': 117, 'n_rnn_layers': 2, 'dropout': 0.11533282802852957}. Best is trial 4 with value: 32.018303982752954.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11688020465958848 and num_layers=1
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.56it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.03it/s] [I 2025-08-18 04:16:08,091] Trial 6 finished with value: 42.347629140850806 and parameters: {'hidden_dim': 50, 'n_rnn_layers': 1, 'dropout': 0.11688020465958848}. Best is trial 4 with value: 32.018303982752954.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.85it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.79it/s][I 2025-08-18 04:17:00,445] Trial 7 finished with value: 31.88570887530167 and parameters: {'hidden_dim': 124, 'n_rnn_layers': 3, 'dropout': 0.15789865762023886}. Best is trial 7 with value: 31.88570887530167.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.54it/s][I 2025-08-18 04:17:39,988] Trial 8 finished with value: 30.21988850046462 and parameters: {'hidden_dim': 19, 'n_rnn_layers': 3, 'dropout': 0.46771072413444037}. Best is trial 8 with value: 30.21988850046462.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.72it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.07it/s][I 2025-08-18 04:18:40,604] Trial 9 finished with value: 31.200896517956753 and parameters: {'hidden_dim': 90, 'n_rnn_layers': 2, 'dropout': 0.1567699596351559}. Best is trial 8 with value: 30.21988850046462.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.36it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.98it/s][I 2025-08-18 04:19:30,855] Trial 10 finished with value: 20.638075607454255 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.3721071067258187}. Best is trial 10 with value: 20.638075607454255.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.59it/s][I 2025-08-18 04:20:22,535] Trial 11 finished with value: 20.6012008535879 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.3500083544934052}. Best is trial 11 with value: 20.6012008535879.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.25it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.05it/s][I 2025-08-18 04:21:12,866] Trial 12 finished with value: 20.54609673340149 and parameters: {'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.34503240257945045}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.48it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.92it/s][I 2025-08-18 04:22:04,249] Trial 13 finished with value: 34.23561554080574 and parameters: {'hidden_dim': 26, 'n_rnn_layers': 4, 'dropout': 0.31883735293656323}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.93it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.70it/s][I 2025-08-18 04:23:10,996] Trial 14 finished with value: 21.848810005576926 and parameters: {'hidden_dim': 64, 'n_rnn_layers': 4, 'dropout': 0.3030786479125279}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 35.62it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.30it/s][I 2025-08-18 04:23:52,670] Trial 15 finished with value: 25.469960002476963 and parameters: {'hidden_dim': 29, 'n_rnn_layers': 3, 'dropout': 0.3861472475189645}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.15it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.55it/s][I 2025-08-18 04:24:42,993] Trial 16 finished with value: 38.92749809763356 and parameters: {'hidden_dim': 17, 'n_rnn_layers': 4, 'dropout': 0.2838417086215597}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.44it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.38it/s][I 2025-08-18 04:25:27,881] Trial 17 finished with value: 27.443046406279045 and parameters: {'hidden_dim': 58, 'n_rnn_layers': 4, 'dropout': 0.36347433160779286}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
`Trainer.fit` stopped: `max_epochs=40` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.34it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.64it/s][I 2025-08-18 04:26:07,977] Trial 18 finished with value: 40.710153491200664 and parameters: {'hidden_dim': 24, 'n_rnn_layers': 3, 'dropout': 0.2205276155724937}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.00it/s]Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 35.55it/s][I 2025-08-18 04:26:56,891] Trial 19 finished with value: 54.43443896398153 and parameters: {'hidden_dim': 35, 'n_rnn_layers': 4, 'dropout': 0.41554403598133677}. Best is trial 12 with value: 20.54609673340149.
ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'lr_scheduler_cls' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['lr_scheduler_cls'])`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | criterion       | MSELoss          | 0      | train
1 | train_criterion | MSELoss          | 0      | train
2 | val_criterion   | MSELoss          | 0      | train
3 | train_metrics   | MetricCollection | 0      | train
4 | val_metrics     | MetricCollection | 0      | train
5 | rnn             | LSTM             | 7.7 K  | train
6 | V               | Linear           | 17     | train
-------------------------------------------------------------
7.8 K     Trainable params
0         Non-trainable params
7.8 K     Total params
0.031     Total estimated model params size (MB)
7         Modules in train mode
0         Modules in eval mode

Melhores parâmetros encontrados:
{'hidden_dim': 16, 'n_rnn_layers': 4, 'dropout': 0.34503240257945045}
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 53.57it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 53.54it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/20 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s] Epoch 0:   5%|▌         | 1/20 [00:00<00:01, 16.80it/s]Epoch 0:   5%|▌         | 1/20 [00:00<00:01, 15.72it/s, train_loss=0.0724]Epoch 0:  10%|█         | 2/20 [00:00<00:00, 18.00it/s, train_loss=0.0724]Epoch 0:  10%|█         | 2/20 [00:00<00:01, 16.51it/s, train_loss=0.0655]Epoch 0:  15%|█▌        | 3/20 [00:00<00:01, 16.16it/s, train_loss=0.0655]Epoch 0:  15%|█▌        | 3/20 [00:00<00:01, 15.82it/s, train_loss=0.0684]Epoch 0:  20%|██        | 4/20 [00:00<00:00, 17.18it/s, train_loss=0.0684]Epoch 0:  20%|██        | 4/20 [00:00<00:00, 16.71it/s, train_loss=0.0654]Epoch 0:  25%|██▌       | 5/20 [00:00<00:00, 18.31it/s, train_loss=0.0654]Epoch 0:  25%|██▌       | 5/20 [00:00<00:00, 17.91it/s, train_loss=0.0672]Epoch 0:  30%|███       | 6/20 [00:00<00:00, 17.17it/s, train_loss=0.0672]Epoch 0:  30%|███       | 6/20 [00:00<00:00, 16.91it/s, train_loss=0.0696]Epoch 0:  35%|███▌      | 7/20 [00:00<00:00, 17.13it/s, train_loss=0.0696]Epoch 0:  35%|███▌      | 7/20 [00:00<00:00, 16.78it/s, train_loss=0.0599]Epoch 0:  40%|████      | 8/20 [00:00<00:00, 17.23it/s, train_loss=0.0599]Epoch 0:  40%|████      | 8/20 [00:00<00:00, 16.91it/s, train_loss=0.0688]Epoch 0:  45%|████▌     | 9/20 [00:00<00:00, 16.89it/s, train_loss=0.0688]Epoch 0:  45%|████▌     | 9/20 [00:00<00:00, 16.65it/s, train_loss=0.0667]Epoch 0:  50%|█████     | 10/20 [00:00<00:00, 16.52it/s, train_loss=0.0667]Epoch 0:  50%|█████     | 10/20 [00:00<00:00, 16.33it/s, train_loss=0.0669]Epoch 0:  55%|█████▌    | 11/20 [00:00<00:00, 16.31it/s, train_loss=0.0669]Epoch 0:  55%|█████▌    | 11/20 [00:00<00:00, 16.19it/s, train_loss=0.060] Epoch 0:  60%|██████    | 12/20 [00:00<00:00, 16.49it/s, train_loss=0.060]Epoch 0:  60%|██████    | 12/20 [00:00<00:00, 16.31it/s, train_loss=0.0634]Epoch 0:  65%|██████▌   | 13/20 [00:00<00:00, 16.46it/s, train_loss=0.0634]Epoch 0:  65%|██████▌   | 13/20 [00:00<00:00, 16.27it/s, train_loss=0.0604]Epoch 0:  70%|███████   | 14/20 [00:00<00:00, 16.37it/s, train_loss=0.0604]Epoch 0:  70%|███████   | 14/20 [00:00<00:00, 16.25it/s, train_loss=0.0593]Epoch 0:  75%|███████▌  | 15/20 [00:00<00:00, 16.51it/s, train_loss=0.0593]Epoch 0:  75%|███████▌  | 15/20 [00:00<00:00, 16.35it/s, train_loss=0.0543]Epoch 0:  80%|████████  | 16/20 [00:00<00:00, 16.40it/s, train_loss=0.0543]Epoch 0:  80%|████████  | 16/20 [00:00<00:00, 16.35it/s, train_loss=0.0612]Epoch 0:  85%|████████▌ | 17/20 [00:01<00:00, 16.38it/s, train_loss=0.0612]Epoch 0:  85%|████████▌ | 17/20 [00:01<00:00, 16.36it/s, train_loss=0.0629]Epoch 0:  90%|█████████ | 18/20 [00:01<00:00, 16.36it/s, train_loss=0.0629]Epoch 0:  90%|█████████ | 18/20 [00:01<00:00, 16.28it/s, train_loss=0.0695]Epoch 0:  95%|█████████▌| 19/20 [00:01<00:00, 16.25it/s, train_loss=0.0695]Epoch 0:  95%|█████████▌| 19/20 [00:01<00:00, 16.16it/s, train_loss=0.0516]Epoch 0: 100%|██████████| 20/20 [00:01<00:00, 16.37it/s, train_loss=0.0516]Epoch 0: 100%|██████████| 20/20 [00:01<00:00, 16.28it/s, train_loss=0.0698]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 55.44it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 53.35it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 45.75it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.53it/s][A
                                                                      [AEpoch 0: 100%|██████████| 20/20 [00:01<00:00, 14.91it/s, train_loss=0.0698, val_loss=0.0502]Epoch 0: 100%|██████████| 20/20 [00:01<00:00, 14.89it/s, train_loss=0.0698, val_loss=0.0502]Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0698, val_loss=0.0502]         Epoch 1:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0698, val_loss=0.0502]Epoch 1:   5%|▌         | 1/20 [00:00<00:00, 27.33it/s, train_loss=0.0698, val_loss=0.0502]Epoch 1:   5%|▌         | 1/20 [00:00<00:00, 22.45it/s, train_loss=0.0577, val_loss=0.0502]Epoch 1:  10%|█         | 2/20 [00:00<00:00, 21.16it/s, train_loss=0.0577, val_loss=0.0502]Epoch 1:  10%|█         | 2/20 [00:00<00:00, 19.42it/s, train_loss=0.0518, val_loss=0.0502]Epoch 1:  15%|█▌        | 3/20 [00:00<00:00, 18.12it/s, train_loss=0.0518, val_loss=0.0502]Epoch 1:  15%|█▌        | 3/20 [00:00<00:00, 17.41it/s, train_loss=0.0555, val_loss=0.0502]Epoch 1:  20%|██        | 4/20 [00:00<00:00, 17.49it/s, train_loss=0.0555, val_loss=0.0502]Epoch 1:  20%|██        | 4/20 [00:00<00:00, 17.23it/s, train_loss=0.055, val_loss=0.0502] Epoch 1:  25%|██▌       | 5/20 [00:00<00:00, 17.15it/s, train_loss=0.055, val_loss=0.0502]Epoch 1:  25%|██▌       | 5/20 [00:00<00:00, 16.69it/s, train_loss=0.0496, val_loss=0.0502]Epoch 1:  30%|███       | 6/20 [00:00<00:00, 17.68it/s, train_loss=0.0496, val_loss=0.0502]Epoch 1:  30%|███       | 6/20 [00:00<00:00, 17.33it/s, train_loss=0.048, val_loss=0.0502] Epoch 1:  35%|███▌      | 7/20 [00:00<00:00, 17.61it/s, train_loss=0.048, val_loss=0.0502]Epoch 1:  35%|███▌      | 7/20 [00:00<00:00, 17.29it/s, train_loss=0.0545, val_loss=0.0502]Epoch 1:  40%|████      | 8/20 [00:00<00:00, 17.25it/s, train_loss=0.0545, val_loss=0.0502]Epoch 1:  40%|████      | 8/20 [00:00<00:00, 17.13it/s, train_loss=0.0457, val_loss=0.0502]Epoch 1:  45%|████▌     | 9/20 [00:00<00:00, 17.39it/s, train_loss=0.0457, val_loss=0.0502]Epoch 1:  45%|████▌     | 9/20 [00:00<00:00, 17.11it/s, train_loss=0.0482, val_loss=0.0502]Epoch 1:  50%|█████     | 10/20 [00:00<00:00, 17.45it/s, train_loss=0.0482, val_loss=0.0502]Epoch 1:  50%|█████     | 10/20 [00:00<00:00, 17.31it/s, train_loss=0.0492, val_loss=0.0502]Epoch 1:  55%|█████▌    | 11/20 [00:00<00:00, 17.56it/s, train_loss=0.0492, val_loss=0.0502]Epoch 1:  55%|█████▌    | 11/20 [00:00<00:00, 17.48it/s, train_loss=0.0468, val_loss=0.0502]Epoch 1:  60%|██████    | 12/20 [00:00<00:00, 17.27it/s, train_loss=0.0468, val_loss=0.0502]Epoch 1:  60%|██████    | 12/20 [00:00<00:00, 17.16it/s, train_loss=0.0468, val_loss=0.0502]Epoch 1:  65%|██████▌   | 13/20 [00:00<00:00, 17.37it/s, train_loss=0.0468, val_loss=0.0502]Epoch 1:  65%|██████▌   | 13/20 [00:00<00:00, 17.26it/s, train_loss=0.0378, val_loss=0.0502]Epoch 1:  70%|███████   | 14/20 [00:00<00:00, 17.62it/s, train_loss=0.0378, val_loss=0.0502]Epoch 1:  70%|███████   | 14/20 [00:00<00:00, 17.43it/s, train_loss=0.0452, val_loss=0.0502]Epoch 1:  75%|███████▌  | 15/20 [00:00<00:00, 17.55it/s, train_loss=0.0452, val_loss=0.0502]Epoch 1:  75%|███████▌  | 15/20 [00:00<00:00, 17.39it/s, train_loss=0.0436, val_loss=0.0502]Epoch 1:  80%|████████  | 16/20 [00:00<00:00, 17.71it/s, train_loss=0.0436, val_loss=0.0502]Epoch 1:  80%|████████  | 16/20 [00:00<00:00, 17.56it/s, train_loss=0.0449, val_loss=0.0502]Epoch 1:  85%|████████▌ | 17/20 [00:00<00:00, 18.03it/s, train_loss=0.0449, val_loss=0.0502]Epoch 1:  85%|████████▌ | 17/20 [00:00<00:00, 17.88it/s, train_loss=0.0357, val_loss=0.0502]Epoch 1:  90%|█████████ | 18/20 [00:01<00:00, 17.66it/s, train_loss=0.0357, val_loss=0.0502]Epoch 1:  90%|█████████ | 18/20 [00:01<00:00, 17.54it/s, train_loss=0.0356, val_loss=0.0502]Epoch 1:  95%|█████████▌| 19/20 [00:01<00:00, 17.62it/s, train_loss=0.0356, val_loss=0.0502]Epoch 1:  95%|█████████▌| 19/20 [00:01<00:00, 17.53it/s, train_loss=0.0344, val_loss=0.0502]Epoch 1: 100%|██████████| 20/20 [00:01<00:00, 17.47it/s, train_loss=0.0344, val_loss=0.0502]Epoch 1: 100%|██████████| 20/20 [00:01<00:00, 17.44it/s, train_loss=0.0327, val_loss=0.0502]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 45.60it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 41.98it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 43.62it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 37.34it/s][A
                                                                      [AEpoch 1: 100%|██████████| 20/20 [00:01<00:00, 15.75it/s, train_loss=0.0327, val_loss=0.0302]Epoch 1: 100%|██████████| 20/20 [00:01<00:00, 15.74it/s, train_loss=0.0327, val_loss=0.0302]Epoch 1:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0327, val_loss=0.0302]         Epoch 2:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0327, val_loss=0.0302]Epoch 2:   5%|▌         | 1/20 [00:00<00:01, 16.36it/s, train_loss=0.0327, val_loss=0.0302]Epoch 2:   5%|▌         | 1/20 [00:00<00:01, 14.82it/s, train_loss=0.0357, val_loss=0.0302]Epoch 2:  10%|█         | 2/20 [00:00<00:01, 17.08it/s, train_loss=0.0357, val_loss=0.0302]Epoch 2:  10%|█         | 2/20 [00:00<00:01, 15.61it/s, train_loss=0.0341, val_loss=0.0302]Epoch 2:  15%|█▌        | 3/20 [00:00<00:01, 15.75it/s, train_loss=0.0341, val_loss=0.0302]Epoch 2:  15%|█▌        | 3/20 [00:00<00:01, 15.41it/s, train_loss=0.0348, val_loss=0.0302]Epoch 2:  20%|██        | 4/20 [00:00<00:00, 16.06it/s, train_loss=0.0348, val_loss=0.0302]Epoch 2:  20%|██        | 4/20 [00:00<00:01, 15.52it/s, train_loss=0.0298, val_loss=0.0302]Epoch 2:  25%|██▌       | 5/20 [00:00<00:00, 16.49it/s, train_loss=0.0298, val_loss=0.0302]Epoch 2:  25%|██▌       | 5/20 [00:00<00:00, 16.19it/s, train_loss=0.0261, val_loss=0.0302]Epoch 2:  30%|███       | 6/20 [00:00<00:00, 16.97it/s, train_loss=0.0261, val_loss=0.0302]Epoch 2:  30%|███       | 6/20 [00:00<00:00, 16.72it/s, train_loss=0.0261, val_loss=0.0302]Epoch 2:  35%|███▌      | 7/20 [00:00<00:00, 17.35it/s, train_loss=0.0261, val_loss=0.0302]Epoch 2:  35%|███▌      | 7/20 [00:00<00:00, 17.01it/s, train_loss=0.0254, val_loss=0.0302]Epoch 2:  40%|████      | 8/20 [00:00<00:00, 17.39it/s, train_loss=0.0254, val_loss=0.0302]Epoch 2:  40%|████      | 8/20 [00:00<00:00, 17.20it/s, train_loss=0.024, val_loss=0.0302] Epoch 2:  45%|████▌     | 9/20 [00:00<00:00, 17.62it/s, train_loss=0.024, val_loss=0.0302]Epoch 2:  45%|████▌     | 9/20 [00:00<00:00, 17.39it/s, train_loss=0.0261, val_loss=0.0302]Epoch 2:  50%|█████     | 10/20 [00:00<00:00, 17.23it/s, train_loss=0.0261, val_loss=0.0302]Epoch 2:  50%|█████     | 10/20 [00:00<00:00, 17.02it/s, train_loss=0.028, val_loss=0.0302] Epoch 2:  55%|█████▌    | 11/20 [00:00<00:00, 17.20it/s, train_loss=0.028, val_loss=0.0302]Epoch 2:  55%|█████▌    | 11/20 [00:00<00:00, 17.02it/s, train_loss=0.0289, val_loss=0.0302]Epoch 2:  60%|██████    | 12/20 [00:00<00:00, 17.61it/s, train_loss=0.0289, val_loss=0.0302]Epoch 2:  60%|██████    | 12/20 [00:00<00:00, 17.45it/s, train_loss=0.0223, val_loss=0.0302]Epoch 2:  65%|██████▌   | 13/20 [00:00<00:00, 17.26it/s, train_loss=0.0223, val_loss=0.0302]Epoch 2:  65%|██████▌   | 13/20 [00:00<00:00, 17.09it/s, train_loss=0.0197, val_loss=0.0302]Epoch 2:  70%|███████   | 14/20 [00:00<00:00, 17.25it/s, train_loss=0.0197, val_loss=0.0302]Epoch 2:  70%|███████   | 14/20 [00:00<00:00, 17.10it/s, train_loss=0.0219, val_loss=0.0302]Epoch 2:  75%|███████▌  | 15/20 [00:00<00:00, 16.95it/s, train_loss=0.0219, val_loss=0.0302]Epoch 2:  75%|███████▌  | 15/20 [00:00<00:00, 16.84it/s, train_loss=0.0237, val_loss=0.0302]Epoch 2:  80%|████████  | 16/20 [00:00<00:00, 16.95it/s, train_loss=0.0237, val_loss=0.0302]Epoch 2:  80%|████████  | 16/20 [00:00<00:00, 16.80it/s, train_loss=0.0238, val_loss=0.0302]Epoch 2:  85%|████████▌ | 17/20 [00:01<00:00, 16.74it/s, train_loss=0.0238, val_loss=0.0302]Epoch 2:  85%|████████▌ | 17/20 [00:01<00:00, 16.64it/s, train_loss=0.0252, val_loss=0.0302]Epoch 2:  90%|█████████ | 18/20 [00:01<00:00, 16.64it/s, train_loss=0.0252, val_loss=0.0302]Epoch 2:  90%|█████████ | 18/20 [00:01<00:00, 16.53it/s, train_loss=0.0247, val_loss=0.0302]Epoch 2:  95%|█████████▌| 19/20 [00:01<00:00, 16.64it/s, train_loss=0.0247, val_loss=0.0302]Epoch 2:  95%|█████████▌| 19/20 [00:01<00:00, 16.55it/s, train_loss=0.0233, val_loss=0.0302]/media/work/guisouza/Ic_TimeSeries_FM/darts/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2: 100%|██████████| 20/20 [00:01<00:00, 16.64it/s, train_loss=0.0233, val_loss=0.0302]Epoch 2: 100%|██████████| 20/20 [00:01<00:00, 16.56it/s, train_loss=0.026, val_loss=0.0302] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 40.57it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 45.23it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 44.69it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.92it/s][A
                                                                      [AEpoch 2: 100%|██████████| 20/20 [00:01<00:00, 15.25it/s, train_loss=0.026, val_loss=0.0305]Epoch 2: 100%|██████████| 20/20 [00:01<00:00, 15.24it/s, train_loss=0.026, val_loss=0.0305]Epoch 2:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.026, val_loss=0.0305]         Epoch 3:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.026, val_loss=0.0305]Epoch 3:   5%|▌         | 1/20 [00:00<00:00, 21.12it/s, train_loss=0.026, val_loss=0.0305]Epoch 3:   5%|▌         | 1/20 [00:00<00:01, 17.55it/s, train_loss=0.0283, val_loss=0.0305]Epoch 3:  10%|█         | 2/20 [00:00<00:01, 17.73it/s, train_loss=0.0283, val_loss=0.0305]Epoch 3:  10%|█         | 2/20 [00:00<00:01, 17.37it/s, train_loss=0.0236, val_loss=0.0305]Epoch 3:  15%|█▌        | 3/20 [00:00<00:01, 16.25it/s, train_loss=0.0236, val_loss=0.0305]Epoch 3:  15%|█▌        | 3/20 [00:00<00:01, 15.97it/s, train_loss=0.0267, val_loss=0.0305]Epoch 3:  20%|██        | 4/20 [00:00<00:00, 16.14it/s, train_loss=0.0267, val_loss=0.0305]Epoch 3:  20%|██        | 4/20 [00:00<00:01, 15.87it/s, train_loss=0.026, val_loss=0.0305] Epoch 3:  25%|██▌       | 5/20 [00:00<00:00, 16.79it/s, train_loss=0.026, val_loss=0.0305]Epoch 3:  25%|██▌       | 5/20 [00:00<00:00, 16.17it/s, train_loss=0.0243, val_loss=0.0305]Epoch 3:  30%|███       | 6/20 [00:00<00:00, 17.21it/s, train_loss=0.0243, val_loss=0.0305]Epoch 3:  30%|███       | 6/20 [00:00<00:00, 16.74it/s, train_loss=0.0255, val_loss=0.0305]Epoch 3:  35%|███▌      | 7/20 [00:00<00:00, 16.18it/s, train_loss=0.0255, val_loss=0.0305]Epoch 3:  35%|███▌      | 7/20 [00:00<00:00, 15.99it/s, train_loss=0.0221, val_loss=0.0305]Epoch 3:  40%|████      | 8/20 [00:00<00:00, 16.50it/s, train_loss=0.0221, val_loss=0.0305]Epoch 3:  40%|████      | 8/20 [00:00<00:00, 16.27it/s, train_loss=0.0234, val_loss=0.0305]Epoch 3:  45%|████▌     | 9/20 [00:00<00:00, 16.42it/s, train_loss=0.0234, val_loss=0.0305]Epoch 3:  45%|████▌     | 9/20 [00:00<00:00, 16.34it/s, train_loss=0.0265, val_loss=0.0305]Epoch 3:  50%|█████     | 10/20 [00:00<00:00, 16.69it/s, train_loss=0.0265, val_loss=0.0305]Epoch 3:  50%|█████     | 10/20 [00:00<00:00, 16.48it/s, train_loss=0.0231, val_loss=0.0305]Epoch 3:  55%|█████▌    | 11/20 [00:00<00:00, 16.69it/s, train_loss=0.0231, val_loss=0.0305]Epoch 3:  55%|█████▌    | 11/20 [00:00<00:00, 16.45it/s, train_loss=0.023, val_loss=0.0305] Epoch 3:  60%|██████    | 12/20 [00:00<00:00, 16.08it/s, train_loss=0.023, val_loss=0.0305]Epoch 3:  60%|██████    | 12/20 [00:00<00:00, 15.95it/s, train_loss=0.0256, val_loss=0.0305]Epoch 3:  65%|██████▌   | 13/20 [00:00<00:00, 16.34it/s, train_loss=0.0256, val_loss=0.0305]Epoch 3:  65%|██████▌   | 13/20 [00:00<00:00, 16.16it/s, train_loss=0.0229, val_loss=0.0305]Epoch 3:  70%|███████   | 14/20 [00:00<00:00, 16.46it/s, train_loss=0.0229, val_loss=0.0305]Epoch 3:  70%|███████   | 14/20 [00:00<00:00, 16.33it/s, train_loss=0.0215, val_loss=0.0305]Epoch 3:  75%|███████▌  | 15/20 [00:00<00:00, 16.46it/s, train_loss=0.0215, val_loss=0.0305]Epoch 3:  75%|███████▌  | 15/20 [00:00<00:00, 16.32it/s, train_loss=0.0238, val_loss=0.0305]Epoch 3:  80%|████████  | 16/20 [00:00<00:00, 16.45it/s, train_loss=0.0238, val_loss=0.0305]Epoch 3:  80%|████████  | 16/20 [00:00<00:00, 16.30it/s, train_loss=0.0206, val_loss=0.0305]Epoch 3:  85%|████████▌ | 17/20 [00:01<00:00, 16.46it/s, train_loss=0.0206, val_loss=0.0305]Epoch 3:  85%|████████▌ | 17/20 [00:01<00:00, 16.33it/s, train_loss=0.0243, val_loss=0.0305]Epoch 3:  90%|█████████ | 18/20 [00:01<00:00, 16.54it/s, train_loss=0.0243, val_loss=0.0305]Epoch 3:  90%|█████████ | 18/20 [00:01<00:00, 16.41it/s, train_loss=0.0256, val_loss=0.0305]Epoch 3:  95%|█████████▌| 19/20 [00:01<00:00, 16.49it/s, train_loss=0.0256, val_loss=0.0305]Epoch 3:  95%|█████████▌| 19/20 [00:01<00:00, 16.44it/s, train_loss=0.0207, val_loss=0.0305]Epoch 3: 100%|██████████| 20/20 [00:01<00:00, 16.62it/s, train_loss=0.0207, val_loss=0.0305]Epoch 3: 100%|██████████| 20/20 [00:01<00:00, 16.58it/s, train_loss=0.0218, val_loss=0.0305]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 35.58it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 43.73it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 45.00it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 40.62it/s][A
                                                                      [AEpoch 3: 100%|██████████| 20/20 [00:01<00:00, 15.21it/s, train_loss=0.0218, val_loss=0.0263]Epoch 3: 100%|██████████| 20/20 [00:01<00:00, 15.20it/s, train_loss=0.0218, val_loss=0.0263]Epoch 3:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0218, val_loss=0.0263]         Epoch 4:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0218, val_loss=0.0263]Epoch 4:   5%|▌         | 1/20 [00:00<00:00, 21.51it/s, train_loss=0.0218, val_loss=0.0263]Epoch 4:   5%|▌         | 1/20 [00:00<00:00, 19.06it/s, train_loss=0.026, val_loss=0.0263] Epoch 4:  10%|█         | 2/20 [00:00<00:00, 23.43it/s, train_loss=0.026, val_loss=0.0263]Epoch 4:  10%|█         | 2/20 [00:00<00:00, 21.49it/s, train_loss=0.0231, val_loss=0.0263]Epoch 4:  15%|█▌        | 3/20 [00:00<00:00, 17.86it/s, train_loss=0.0231, val_loss=0.0263]Epoch 4:  15%|█▌        | 3/20 [00:00<00:00, 17.33it/s, train_loss=0.0256, val_loss=0.0263]Epoch 4:  20%|██        | 4/20 [00:00<00:00, 17.77it/s, train_loss=0.0256, val_loss=0.0263]Epoch 4:  20%|██        | 4/20 [00:00<00:00, 17.24it/s, train_loss=0.0221, val_loss=0.0263]Epoch 4:  25%|██▌       | 5/20 [00:00<00:00, 16.73it/s, train_loss=0.0221, val_loss=0.0263]Epoch 4:  25%|██▌       | 5/20 [00:00<00:00, 16.46it/s, train_loss=0.0269, val_loss=0.0263]Epoch 4:  30%|███       | 6/20 [00:00<00:00, 16.86it/s, train_loss=0.0269, val_loss=0.0263]Epoch 4:  30%|███       | 6/20 [00:00<00:00, 16.59it/s, train_loss=0.0222, val_loss=0.0263]Epoch 4:  35%|███▌      | 7/20 [00:00<00:00, 16.49it/s, train_loss=0.0222, val_loss=0.0263]Epoch 4:  35%|███▌      | 7/20 [00:00<00:00, 16.19it/s, train_loss=0.0231, val_loss=0.0263]Epoch 4:  40%|████      | 8/20 [00:00<00:00, 16.32it/s, train_loss=0.0231, val_loss=0.0263]Epoch 4:  40%|████      | 8/20 [00:00<00:00, 16.08it/s, train_loss=0.0251, val_loss=0.0263]Epoch 4:  45%|████▌     | 9/20 [00:00<00:00, 16.47it/s, train_loss=0.0251, val_loss=0.0263]Epoch 4:  45%|████▌     | 9/20 [00:00<00:00, 16.18it/s, train_loss=0.0211, val_loss=0.0263]Epoch 4:  50%|█████     | 10/20 [00:00<00:00, 16.50it/s, train_loss=0.0211, val_loss=0.0263]Epoch 4:  50%|█████     | 10/20 [00:00<00:00, 16.28it/s, train_loss=0.0228, val_loss=0.0263]Epoch 4:  55%|█████▌    | 11/20 [00:00<00:00, 16.46it/s, train_loss=0.0228, val_loss=0.0263]Epoch 4:  55%|█████▌    | 11/20 [00:00<00:00, 16.25it/s, train_loss=0.0214, val_loss=0.0263]Epoch 4:  60%|██████    | 12/20 [00:00<00:00, 16.57it/s, train_loss=0.0214, val_loss=0.0263]Epoch 4:  60%|██████    | 12/20 [00:00<00:00, 16.44it/s, train_loss=0.0222, val_loss=0.0263]Epoch 4:  65%|██████▌   | 13/20 [00:00<00:00, 16.82it/s, train_loss=0.0222, val_loss=0.0263]Epoch 4:  65%|██████▌   | 13/20 [00:00<00:00, 16.63it/s, train_loss=0.0245, val_loss=0.0263]Epoch 4:  70%|███████   | 14/20 [00:00<00:00, 16.77it/s, train_loss=0.0245, val_loss=0.0263]Epoch 4:  70%|███████   | 14/20 [00:00<00:00, 16.63it/s, train_loss=0.0277, val_loss=0.0263]Epoch 4:  75%|███████▌  | 15/20 [00:00<00:00, 16.56it/s, train_loss=0.0277, val_loss=0.0263]Epoch 4:  75%|███████▌  | 15/20 [00:00<00:00, 16.48it/s, train_loss=0.0243, val_loss=0.0263]Epoch 4:  80%|████████  | 16/20 [00:00<00:00, 16.51it/s, train_loss=0.0243, val_loss=0.0263]Epoch 4:  80%|████████  | 16/20 [00:00<00:00, 16.45it/s, train_loss=0.0226, val_loss=0.0263]Epoch 4:  85%|████████▌ | 17/20 [00:01<00:00, 16.64it/s, train_loss=0.0226, val_loss=0.0263]Epoch 4:  85%|████████▌ | 17/20 [00:01<00:00, 16.55it/s, train_loss=0.0218, val_loss=0.0263]Epoch 4:  90%|█████████ | 18/20 [00:01<00:00, 16.92it/s, train_loss=0.0218, val_loss=0.0263]Epoch 4:  90%|█████████ | 18/20 [00:01<00:00, 16.82it/s, train_loss=0.0236, val_loss=0.0263]Epoch 4:  95%|█████████▌| 19/20 [00:01<00:00, 17.01it/s, train_loss=0.0236, val_loss=0.0263]Epoch 4:  95%|█████████▌| 19/20 [00:01<00:00, 16.97it/s, train_loss=0.0228, val_loss=0.0263]Epoch 4: 100%|██████████| 20/20 [00:01<00:00, 17.07it/s, train_loss=0.0228, val_loss=0.0263]Epoch 4: 100%|██████████| 20/20 [00:01<00:00, 16.99it/s, train_loss=0.0248, val_loss=0.0263]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 40.30it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 42.96it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 40.21it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 41.18it/s][A
                                                                      [AEpoch 4: 100%|██████████| 20/20 [00:01<00:00, 15.52it/s, train_loss=0.0248, val_loss=0.0268]Epoch 4: 100%|██████████| 20/20 [00:01<00:00, 15.50it/s, train_loss=0.0248, val_loss=0.0268]Epoch 4:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0248, val_loss=0.0268]         Epoch 5:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0248, val_loss=0.0268]Epoch 5:   5%|▌         | 1/20 [00:00<00:00, 19.43it/s, train_loss=0.0248, val_loss=0.0268]Epoch 5:   5%|▌         | 1/20 [00:00<00:01, 16.59it/s, train_loss=0.0245, val_loss=0.0268]Epoch 5:  10%|█         | 2/20 [00:00<00:01, 15.39it/s, train_loss=0.0245, val_loss=0.0268]Epoch 5:  10%|█         | 2/20 [00:00<00:01, 14.35it/s, train_loss=0.022, val_loss=0.0268] Epoch 5:  15%|█▌        | 3/20 [00:00<00:01, 15.20it/s, train_loss=0.022, val_loss=0.0268]Epoch 5:  15%|█▌        | 3/20 [00:00<00:01, 14.75it/s, train_loss=0.0222, val_loss=0.0268]Epoch 5:  20%|██        | 4/20 [00:00<00:01, 15.70it/s, train_loss=0.0222, val_loss=0.0268]Epoch 5:  20%|██        | 4/20 [00:00<00:01, 15.49it/s, train_loss=0.0256, val_loss=0.0268]Epoch 5:  25%|██▌       | 5/20 [00:00<00:00, 16.71it/s, train_loss=0.0256, val_loss=0.0268]Epoch 5:  25%|██▌       | 5/20 [00:00<00:00, 16.25it/s, train_loss=0.0207, val_loss=0.0268]Epoch 5:  30%|███       | 6/20 [00:00<00:00, 16.42it/s, train_loss=0.0207, val_loss=0.0268]Epoch 5:  30%|███       | 6/20 [00:00<00:00, 16.12it/s, train_loss=0.0253, val_loss=0.0268]Epoch 5:  35%|███▌      | 7/20 [00:00<00:00, 16.72it/s, train_loss=0.0253, val_loss=0.0268]Epoch 5:  35%|███▌      | 7/20 [00:00<00:00, 16.37it/s, train_loss=0.0239, val_loss=0.0268]Epoch 5:  40%|████      | 8/20 [00:00<00:00, 16.89it/s, train_loss=0.0239, val_loss=0.0268]Epoch 5:  40%|████      | 8/20 [00:00<00:00, 16.69it/s, train_loss=0.021, val_loss=0.0268] Epoch 5:  45%|████▌     | 9/20 [00:00<00:00, 17.17it/s, train_loss=0.021, val_loss=0.0268]Epoch 5:  45%|████▌     | 9/20 [00:00<00:00, 16.88it/s, train_loss=0.023, val_loss=0.0268]Epoch 5:  50%|█████     | 10/20 [00:00<00:00, 16.54it/s, train_loss=0.023, val_loss=0.0268]Epoch 5:  50%|█████     | 10/20 [00:00<00:00, 16.42it/s, train_loss=0.0234, val_loss=0.0268]Epoch 5:  55%|█████▌    | 11/20 [00:00<00:00, 16.76it/s, train_loss=0.0234, val_loss=0.0268]Epoch 5:  55%|█████▌    | 11/20 [00:00<00:00, 16.54it/s, train_loss=0.0221, val_loss=0.0268]Epoch 5:  60%|██████    | 12/20 [00:00<00:00, 16.61it/s, train_loss=0.0221, val_loss=0.0268]Epoch 5:  60%|██████    | 12/20 [00:00<00:00, 16.46it/s, train_loss=0.0219, val_loss=0.0268]Epoch 5:  65%|██████▌   | 13/20 [00:00<00:00, 16.93it/s, train_loss=0.0219, val_loss=0.0268]Epoch 5:  65%|██████▌   | 13/20 [00:00<00:00, 16.76it/s, train_loss=0.0235, val_loss=0.0268]Epoch 5:  70%|███████   | 14/20 [00:00<00:00, 17.26it/s, train_loss=0.0235, val_loss=0.0268]Epoch 5:  70%|███████   | 14/20 [00:00<00:00, 17.07it/s, train_loss=0.024, val_loss=0.0268] Epoch 5:  75%|███████▌  | 15/20 [00:00<00:00, 16.91it/s, train_loss=0.024, val_loss=0.0268]Epoch 5:  75%|███████▌  | 15/20 [00:00<00:00, 16.78it/s, train_loss=0.0246, val_loss=0.0268]Epoch 5:  80%|████████  | 16/20 [00:00<00:00, 17.09it/s, train_loss=0.0246, val_loss=0.0268]Epoch 5:  80%|████████  | 16/20 [00:00<00:00, 16.98it/s, train_loss=0.0213, val_loss=0.0268]Epoch 5:  85%|████████▌ | 17/20 [00:00<00:00, 17.04it/s, train_loss=0.0213, val_loss=0.0268]Epoch 5:  85%|████████▌ | 17/20 [00:01<00:00, 16.99it/s, train_loss=0.021, val_loss=0.0268] Epoch 5:  90%|█████████ | 18/20 [00:01<00:00, 17.01it/s, train_loss=0.021, val_loss=0.0268]Epoch 5:  90%|█████████ | 18/20 [00:01<00:00, 16.92it/s, train_loss=0.0209, val_loss=0.0268]Epoch 5:  95%|█████████▌| 19/20 [00:01<00:00, 16.89it/s, train_loss=0.0209, val_loss=0.0268]Epoch 5:  95%|█████████▌| 19/20 [00:01<00:00, 16.78it/s, train_loss=0.0218, val_loss=0.0268]Epoch 5: 100%|██████████| 20/20 [00:01<00:00, 16.78it/s, train_loss=0.0218, val_loss=0.0268]Epoch 5: 100%|██████████| 20/20 [00:01<00:00, 16.72it/s, train_loss=0.022, val_loss=0.0268] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 43.42it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 43.52it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 45.55it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.73it/s][A
                                                                      [AEpoch 5: 100%|██████████| 20/20 [00:01<00:00, 15.46it/s, train_loss=0.022, val_loss=0.0229]Epoch 5: 100%|██████████| 20/20 [00:01<00:00, 15.44it/s, train_loss=0.022, val_loss=0.0229]Epoch 5:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.022, val_loss=0.0229]         Epoch 6:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.022, val_loss=0.0229]Epoch 6:   5%|▌         | 1/20 [00:00<00:01, 16.14it/s, train_loss=0.022, val_loss=0.0229]Epoch 6:   5%|▌         | 1/20 [00:00<00:01, 14.67it/s, train_loss=0.020, val_loss=0.0229]Epoch 6:  10%|█         | 2/20 [00:00<00:00, 18.09it/s, train_loss=0.020, val_loss=0.0229]Epoch 6:  10%|█         | 2/20 [00:00<00:01, 16.70it/s, train_loss=0.0186, val_loss=0.0229]Epoch 6:  15%|█▌        | 3/20 [00:00<00:00, 17.95it/s, train_loss=0.0186, val_loss=0.0229]Epoch 6:  15%|█▌        | 3/20 [00:00<00:00, 17.06it/s, train_loss=0.0251, val_loss=0.0229]Epoch 6:  20%|██        | 4/20 [00:00<00:00, 18.12it/s, train_loss=0.0251, val_loss=0.0229]Epoch 6:  20%|██        | 4/20 [00:00<00:00, 17.40it/s, train_loss=0.0216, val_loss=0.0229]Epoch 6:  25%|██▌       | 5/20 [00:00<00:00, 17.42it/s, train_loss=0.0216, val_loss=0.0229]Epoch 6:  25%|██▌       | 5/20 [00:00<00:00, 17.12it/s, train_loss=0.0193, val_loss=0.0229]Epoch 6:  30%|███       | 6/20 [00:00<00:00, 17.07it/s, train_loss=0.0193, val_loss=0.0229]Epoch 6:  30%|███       | 6/20 [00:00<00:00, 16.76it/s, train_loss=0.0194, val_loss=0.0229]Epoch 6:  35%|███▌      | 7/20 [00:00<00:00, 16.81it/s, train_loss=0.0194, val_loss=0.0229]Epoch 6:  35%|███▌      | 7/20 [00:00<00:00, 16.55it/s, train_loss=0.0222, val_loss=0.0229]Epoch 6:  40%|████      | 8/20 [00:00<00:00, 17.18it/s, train_loss=0.0222, val_loss=0.0229]Epoch 6:  40%|████      | 8/20 [00:00<00:00, 16.96it/s, train_loss=0.0201, val_loss=0.0229]Epoch 6:  45%|████▌     | 9/20 [00:00<00:00, 17.71it/s, train_loss=0.0201, val_loss=0.0229]Epoch 6:  45%|████▌     | 9/20 [00:00<00:00, 17.45it/s, train_loss=0.0215, val_loss=0.0229]Epoch 6:  50%|█████     | 10/20 [00:00<00:00, 17.30it/s, train_loss=0.0215, val_loss=0.0229]Epoch 6:  50%|█████     | 10/20 [00:00<00:00, 17.21it/s, train_loss=0.0174, val_loss=0.0229]Epoch 6:  55%|█████▌    | 11/20 [00:00<00:00, 17.55it/s, train_loss=0.0174, val_loss=0.0229]Epoch 6:  55%|█████▌    | 11/20 [00:00<00:00, 17.41it/s, train_loss=0.0183, val_loss=0.0229]Epoch 6:  60%|██████    | 12/20 [00:00<00:00, 17.63it/s, train_loss=0.0183, val_loss=0.0229]Epoch 6:  60%|██████    | 12/20 [00:00<00:00, 17.41it/s, train_loss=0.0189, val_loss=0.0229]Epoch 6:  65%|██████▌   | 13/20 [00:00<00:00, 17.35it/s, train_loss=0.0189, val_loss=0.0229]Epoch 6:  65%|██████▌   | 13/20 [00:00<00:00, 17.20it/s, train_loss=0.0191, val_loss=0.0229]Epoch 6:  70%|███████   | 14/20 [00:00<00:00, 17.41it/s, train_loss=0.0191, val_loss=0.0229]Epoch 6:  70%|███████   | 14/20 [00:00<00:00, 17.27it/s, train_loss=0.0195, val_loss=0.0229]Epoch 6:  75%|███████▌  | 15/20 [00:00<00:00, 17.00it/s, train_loss=0.0195, val_loss=0.0229]Epoch 6:  75%|███████▌  | 15/20 [00:00<00:00, 16.93it/s, train_loss=0.0176, val_loss=0.0229]Epoch 6:  80%|████████  | 16/20 [00:00<00:00, 17.11it/s, train_loss=0.0176, val_loss=0.0229]Epoch 6:  80%|████████  | 16/20 [00:00<00:00, 16.95it/s, train_loss=0.0182, val_loss=0.0229]Epoch 6:  85%|████████▌ | 17/20 [00:01<00:00, 16.96it/s, train_loss=0.0182, val_loss=0.0229]Epoch 6:  85%|████████▌ | 17/20 [00:01<00:00, 16.93it/s, train_loss=0.0176, val_loss=0.0229]Epoch 6:  90%|█████████ | 18/20 [00:01<00:00, 16.91it/s, train_loss=0.0176, val_loss=0.0229]Epoch 6:  90%|█████████ | 18/20 [00:01<00:00, 16.84it/s, train_loss=0.0179, val_loss=0.0229]Epoch 6:  95%|█████████▌| 19/20 [00:01<00:00, 17.02it/s, train_loss=0.0179, val_loss=0.0229]Epoch 6:  95%|█████████▌| 19/20 [00:01<00:00, 16.92it/s, train_loss=0.0186, val_loss=0.0229]Epoch 6: 100%|██████████| 20/20 [00:01<00:00, 17.08it/s, train_loss=0.0186, val_loss=0.0229]Epoch 6: 100%|██████████| 20/20 [00:01<00:00, 16.97it/s, train_loss=0.0207, val_loss=0.0229]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 42.92it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 43.49it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 43.55it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 38.36it/s][A
                                                                      [AEpoch 6: 100%|██████████| 20/20 [00:01<00:00, 15.26it/s, train_loss=0.0207, val_loss=0.0146]Epoch 6: 100%|██████████| 20/20 [00:01<00:00, 15.20it/s, train_loss=0.0207, val_loss=0.0146]Epoch 6:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0207, val_loss=0.0146]         Epoch 7:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0207, val_loss=0.0146]Epoch 7:   5%|▌         | 1/20 [00:00<00:00, 23.89it/s, train_loss=0.0207, val_loss=0.0146]Epoch 7:   5%|▌         | 1/20 [00:00<00:00, 20.35it/s, train_loss=0.0175, val_loss=0.0146]Epoch 7:  10%|█         | 2/20 [00:00<00:00, 19.22it/s, train_loss=0.0175, val_loss=0.0146]Epoch 7:  10%|█         | 2/20 [00:00<00:01, 17.60it/s, train_loss=0.0188, val_loss=0.0146]Epoch 7:  15%|█▌        | 3/20 [00:00<00:00, 19.04it/s, train_loss=0.0188, val_loss=0.0146]Epoch 7:  15%|█▌        | 3/20 [00:00<00:00, 18.28it/s, train_loss=0.0165, val_loss=0.0146]Epoch 7:  20%|██        | 4/20 [00:00<00:00, 19.75it/s, train_loss=0.0165, val_loss=0.0146]Epoch 7:  20%|██        | 4/20 [00:00<00:00, 19.13it/s, train_loss=0.0164, val_loss=0.0146]Epoch 7:  25%|██▌       | 5/20 [00:00<00:00, 17.97it/s, train_loss=0.0164, val_loss=0.0146]Epoch 7:  25%|██▌       | 5/20 [00:00<00:00, 17.63it/s, train_loss=0.0164, val_loss=0.0146]Epoch 7:  30%|███       | 6/20 [00:00<00:00, 17.93it/s, train_loss=0.0164, val_loss=0.0146]Epoch 7:  30%|███       | 6/20 [00:00<00:00, 17.64it/s, train_loss=0.0153, val_loss=0.0146]Epoch 7:  35%|███▌      | 7/20 [00:00<00:00, 17.86it/s, train_loss=0.0153, val_loss=0.0146]Epoch 7:  35%|███▌      | 7/20 [00:00<00:00, 17.72it/s, train_loss=0.0141, val_loss=0.0146]Epoch 7:  40%|████      | 8/20 [00:00<00:00, 17.84it/s, train_loss=0.0141, val_loss=0.0146]Epoch 7:  40%|████      | 8/20 [00:00<00:00, 17.47it/s, train_loss=0.0134, val_loss=0.0146]Epoch 7:  45%|████▌     | 9/20 [00:00<00:00, 17.05it/s, train_loss=0.0134, val_loss=0.0146]Epoch 7:  45%|████▌     | 9/20 [00:00<00:00, 16.84it/s, train_loss=0.0132, val_loss=0.0146]Epoch 7:  50%|█████     | 10/20 [00:00<00:00, 16.90it/s, train_loss=0.0132, val_loss=0.0146]Epoch 7:  50%|█████     | 10/20 [00:00<00:00, 16.72it/s, train_loss=0.0133, val_loss=0.0146]Epoch 7:  55%|█████▌    | 11/20 [00:00<00:00, 17.07it/s, train_loss=0.0133, val_loss=0.0146]Epoch 7:  55%|█████▌    | 11/20 [00:00<00:00, 16.88it/s, train_loss=0.0158, val_loss=0.0146]Epoch 7:  60%|██████    | 12/20 [00:00<00:00, 16.89it/s, train_loss=0.0158, val_loss=0.0146]Epoch 7:  60%|██████    | 12/20 [00:00<00:00, 16.73it/s, train_loss=0.0161, val_loss=0.0146]Epoch 7:  65%|██████▌   | 13/20 [00:00<00:00, 16.71it/s, train_loss=0.0161, val_loss=0.0146]Epoch 7:  65%|██████▌   | 13/20 [00:00<00:00, 16.56it/s, train_loss=0.0145, val_loss=0.0146]Epoch 7:  70%|███████   | 14/20 [00:00<00:00, 16.70it/s, train_loss=0.0145, val_loss=0.0146]Epoch 7:  70%|███████   | 14/20 [00:00<00:00, 16.56it/s, train_loss=0.015, val_loss=0.0146] Epoch 7:  75%|███████▌  | 15/20 [00:00<00:00, 16.76it/s, train_loss=0.015, val_loss=0.0146]Epoch 7:  75%|███████▌  | 15/20 [00:00<00:00, 16.62it/s, train_loss=0.0134, val_loss=0.0146]Epoch 7:  80%|████████  | 16/20 [00:00<00:00, 16.80it/s, train_loss=0.0134, val_loss=0.0146]Epoch 7:  80%|████████  | 16/20 [00:00<00:00, 16.68it/s, train_loss=0.0134, val_loss=0.0146]Epoch 7:  85%|████████▌ | 17/20 [00:01<00:00, 16.64it/s, train_loss=0.0134, val_loss=0.0146]Epoch 7:  85%|████████▌ | 17/20 [00:01<00:00, 16.56it/s, train_loss=0.012, val_loss=0.0146] Epoch 7:  90%|█████████ | 18/20 [00:01<00:00, 16.81it/s, train_loss=0.012, val_loss=0.0146]Epoch 7:  90%|█████████ | 18/20 [00:01<00:00, 16.66it/s, train_loss=0.0128, val_loss=0.0146]Epoch 7:  95%|█████████▌| 19/20 [00:01<00:00, 16.63it/s, train_loss=0.0128, val_loss=0.0146]Epoch 7:  95%|█████████▌| 19/20 [00:01<00:00, 16.55it/s, train_loss=0.0136, val_loss=0.0146]Epoch 7: 100%|██████████| 20/20 [00:01<00:00, 16.85it/s, train_loss=0.0136, val_loss=0.0146]Epoch 7: 100%|██████████| 20/20 [00:01<00:00, 16.79it/s, train_loss=0.0134, val_loss=0.0146]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 51.29it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 52.21it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 45.11it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.85it/s][A
                                                                      [AEpoch 7: 100%|██████████| 20/20 [00:01<00:00, 15.57it/s, train_loss=0.0134, val_loss=0.0103]Epoch 7: 100%|██████████| 20/20 [00:01<00:00, 15.54it/s, train_loss=0.0134, val_loss=0.0103]Epoch 7:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0134, val_loss=0.0103]         Epoch 8:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0134, val_loss=0.0103]Epoch 8:   5%|▌         | 1/20 [00:00<00:01, 18.60it/s, train_loss=0.0134, val_loss=0.0103]Epoch 8:   5%|▌         | 1/20 [00:00<00:01, 16.15it/s, train_loss=0.0131, val_loss=0.0103]Epoch 8:  10%|█         | 2/20 [00:00<00:00, 18.47it/s, train_loss=0.0131, val_loss=0.0103]Epoch 8:  10%|█         | 2/20 [00:00<00:01, 17.28it/s, train_loss=0.012, val_loss=0.0103] Epoch 8:  15%|█▌        | 3/20 [00:00<00:00, 17.23it/s, train_loss=0.012, val_loss=0.0103]Epoch 8:  15%|█▌        | 3/20 [00:00<00:01, 16.44it/s, train_loss=0.0126, val_loss=0.0103]Epoch 8:  20%|██        | 4/20 [00:00<00:01, 15.57it/s, train_loss=0.0126, val_loss=0.0103]Epoch 8:  20%|██        | 4/20 [00:00<00:01, 15.23it/s, train_loss=0.0119, val_loss=0.0103]Epoch 8:  25%|██▌       | 5/20 [00:00<00:00, 15.93it/s, train_loss=0.0119, val_loss=0.0103]Epoch 8:  25%|██▌       | 5/20 [00:00<00:00, 15.63it/s, train_loss=0.0113, val_loss=0.0103]Epoch 8:  30%|███       | 6/20 [00:00<00:00, 16.43it/s, train_loss=0.0113, val_loss=0.0103]Epoch 8:  30%|███       | 6/20 [00:00<00:00, 16.15it/s, train_loss=0.0116, val_loss=0.0103]Epoch 8:  35%|███▌      | 7/20 [00:00<00:00, 16.55it/s, train_loss=0.0116, val_loss=0.0103]Epoch 8:  35%|███▌      | 7/20 [00:00<00:00, 16.30it/s, train_loss=0.0115, val_loss=0.0103]Epoch 8:  40%|████      | 8/20 [00:00<00:00, 16.63it/s, train_loss=0.0115, val_loss=0.0103]Epoch 8:  40%|████      | 8/20 [00:00<00:00, 16.35it/s, train_loss=0.0119, val_loss=0.0103]Epoch 8:  45%|████▌     | 9/20 [00:00<00:00, 16.70it/s, train_loss=0.0119, val_loss=0.0103]Epoch 8:  45%|████▌     | 9/20 [00:00<00:00, 16.50it/s, train_loss=0.0113, val_loss=0.0103]Epoch 8:  50%|█████     | 10/20 [00:00<00:00, 16.87it/s, train_loss=0.0113, val_loss=0.0103]Epoch 8:  50%|█████     | 10/20 [00:00<00:00, 16.69it/s, train_loss=0.010, val_loss=0.0103] Epoch 8:  55%|█████▌    | 11/20 [00:00<00:00, 16.94it/s, train_loss=0.010, val_loss=0.0103]Epoch 8:  55%|█████▌    | 11/20 [00:00<00:00, 16.76it/s, train_loss=0.00963, val_loss=0.0103]Epoch 8:  60%|██████    | 12/20 [00:00<00:00, 16.98it/s, train_loss=0.00963, val_loss=0.0103]Epoch 8:  60%|██████    | 12/20 [00:00<00:00, 16.81it/s, train_loss=0.0102, val_loss=0.0103] Epoch 8:  65%|██████▌   | 13/20 [00:00<00:00, 16.64it/s, train_loss=0.0102, val_loss=0.0103]Epoch 8:  65%|██████▌   | 13/20 [00:00<00:00, 16.51it/s, train_loss=0.0105, val_loss=0.0103]Epoch 8:  70%|███████   | 14/20 [00:00<00:00, 16.92it/s, train_loss=0.0105, val_loss=0.0103]Epoch 8:  70%|███████   | 14/20 [00:00<00:00, 16.76it/s, train_loss=0.00908, val_loss=0.0103]Epoch 8:  75%|███████▌  | 15/20 [00:00<00:00, 16.93it/s, train_loss=0.00908, val_loss=0.0103]Epoch 8:  75%|███████▌  | 15/20 [00:00<00:00, 16.78it/s, train_loss=0.0106, val_loss=0.0103] Epoch 8:  80%|████████  | 16/20 [00:00<00:00, 17.22it/s, train_loss=0.0106, val_loss=0.0103]Epoch 8:  80%|████████  | 16/20 [00:00<00:00, 17.11it/s, train_loss=0.00981, val_loss=0.0103]Epoch 8:  85%|████████▌ | 17/20 [00:00<00:00, 17.50it/s, train_loss=0.00981, val_loss=0.0103]Epoch 8:  85%|████████▌ | 17/20 [00:00<00:00, 17.36it/s, train_loss=0.00969, val_loss=0.0103]Epoch 8:  90%|█████████ | 18/20 [00:01<00:00, 17.28it/s, train_loss=0.00969, val_loss=0.0103]Epoch 8:  90%|█████████ | 18/20 [00:01<00:00, 17.20it/s, train_loss=0.0092, val_loss=0.0103] Epoch 8:  95%|█████████▌| 19/20 [00:01<00:00, 17.40it/s, train_loss=0.0092, val_loss=0.0103]Epoch 8:  95%|█████████▌| 19/20 [00:01<00:00, 17.30it/s, train_loss=0.00966, val_loss=0.0103]Epoch 8: 100%|██████████| 20/20 [00:01<00:00, 17.44it/s, train_loss=0.00966, val_loss=0.0103]Epoch 8: 100%|██████████| 20/20 [00:01<00:00, 17.35it/s, train_loss=0.0099, val_loss=0.0103] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 35.37it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 33.05it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 37.94it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 36.73it/s][A
                                                                      [AEpoch 8: 100%|██████████| 20/20 [00:01<00:00, 15.65it/s, train_loss=0.0099, val_loss=0.00961]Epoch 8: 100%|██████████| 20/20 [00:01<00:00, 15.62it/s, train_loss=0.0099, val_loss=0.00961]Epoch 8:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0099, val_loss=0.00961]         Epoch 9:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0099, val_loss=0.00961]Epoch 9:   5%|▌         | 1/20 [00:00<00:01, 15.97it/s, train_loss=0.0099, val_loss=0.00961]Epoch 9:   5%|▌         | 1/20 [00:00<00:01, 13.90it/s, train_loss=0.00954, val_loss=0.00961]Epoch 9:  10%|█         | 2/20 [00:00<00:01, 16.94it/s, train_loss=0.00954, val_loss=0.00961]Epoch 9:  10%|█         | 2/20 [00:00<00:01, 16.11it/s, train_loss=0.00895, val_loss=0.00961]Epoch 9:  15%|█▌        | 3/20 [00:00<00:01, 16.52it/s, train_loss=0.00895, val_loss=0.00961]Epoch 9:  15%|█▌        | 3/20 [00:00<00:01, 16.08it/s, train_loss=0.00944, val_loss=0.00961]Epoch 9:  20%|██        | 4/20 [00:00<00:01, 15.93it/s, train_loss=0.00944, val_loss=0.00961]Epoch 9:  20%|██        | 4/20 [00:00<00:01, 15.57it/s, train_loss=0.00932, val_loss=0.00961]Epoch 9:  25%|██▌       | 5/20 [00:00<00:00, 16.53it/s, train_loss=0.00932, val_loss=0.00961]Epoch 9:  25%|██▌       | 5/20 [00:00<00:00, 16.23it/s, train_loss=0.00888, val_loss=0.00961]Epoch 9:  30%|███       | 6/20 [00:00<00:00, 16.90it/s, train_loss=0.00888, val_loss=0.00961]Epoch 9:  30%|███       | 6/20 [00:00<00:00, 16.54it/s, train_loss=0.00829, val_loss=0.00961]Epoch 9:  35%|███▌      | 7/20 [00:00<00:00, 17.23it/s, train_loss=0.00829, val_loss=0.00961]Epoch 9:  35%|███▌      | 7/20 [00:00<00:00, 16.98it/s, train_loss=0.00901, val_loss=0.00961]Epoch 9:  40%|████      | 8/20 [00:00<00:00, 16.73it/s, train_loss=0.00901, val_loss=0.00961]Epoch 9:  40%|████      | 8/20 [00:00<00:00, 16.53it/s, train_loss=0.0092, val_loss=0.00961] Epoch 9:  45%|████▌     | 9/20 [00:00<00:00, 16.98it/s, train_loss=0.0092, val_loss=0.00961]Epoch 9:  45%|████▌     | 9/20 [00:00<00:00, 16.75it/s, train_loss=0.00993, val_loss=0.00961]Epoch 9:  50%|█████     | 10/20 [00:00<00:00, 16.74it/s, train_loss=0.00993, val_loss=0.00961]Epoch 9:  50%|█████     | 10/20 [00:00<00:00, 16.53it/s, train_loss=0.00926, val_loss=0.00961]Epoch 9:  55%|█████▌    | 11/20 [00:00<00:00, 16.91it/s, train_loss=0.00926, val_loss=0.00961]Epoch 9:  55%|█████▌    | 11/20 [00:00<00:00, 16.71it/s, train_loss=0.00854, val_loss=0.00961]Epoch 9:  60%|██████    | 12/20 [00:00<00:00, 17.34it/s, train_loss=0.00854, val_loss=0.00961]Epoch 9:  60%|██████    | 12/20 [00:00<00:00, 17.12it/s, train_loss=0.00904, val_loss=0.00961]Epoch 9:  65%|██████▌   | 13/20 [00:00<00:00, 16.94it/s, train_loss=0.00904, val_loss=0.00961]Epoch 9:  65%|██████▌   | 13/20 [00:00<00:00, 16.82it/s, train_loss=0.00825, val_loss=0.00961]Epoch 9:  70%|███████   | 14/20 [00:00<00:00, 17.13it/s, train_loss=0.00825, val_loss=0.00961]Epoch 9:  70%|███████   | 14/20 [00:00<00:00, 16.99it/s, train_loss=0.00896, val_loss=0.00961]Epoch 9:  75%|███████▌  | 15/20 [00:00<00:00, 17.25it/s, train_loss=0.00896, val_loss=0.00961]Epoch 9:  75%|███████▌  | 15/20 [00:00<00:00, 17.11it/s, train_loss=0.00949, val_loss=0.00961]Epoch 9:  80%|████████  | 16/20 [00:00<00:00, 17.09it/s, train_loss=0.00949, val_loss=0.00961]Epoch 9:  80%|████████  | 16/20 [00:00<00:00, 16.92it/s, train_loss=0.00834, val_loss=0.00961]Epoch 9:  85%|████████▌ | 17/20 [00:00<00:00, 17.13it/s, train_loss=0.00834, val_loss=0.00961]Epoch 9:  85%|████████▌ | 17/20 [00:01<00:00, 16.98it/s, train_loss=0.0081, val_loss=0.00961] Epoch 9:  90%|█████████ | 18/20 [00:01<00:00, 16.77it/s, train_loss=0.0081, val_loss=0.00961]Epoch 9:  90%|█████████ | 18/20 [00:01<00:00, 16.68it/s, train_loss=0.00904, val_loss=0.00961]Epoch 9:  95%|█████████▌| 19/20 [00:01<00:00, 16.76it/s, train_loss=0.00904, val_loss=0.00961]Epoch 9:  95%|█████████▌| 19/20 [00:01<00:00, 16.68it/s, train_loss=0.00853, val_loss=0.00961]Epoch 9: 100%|██████████| 20/20 [00:01<00:00, 16.68it/s, train_loss=0.00853, val_loss=0.00961]Epoch 9: 100%|██████████| 20/20 [00:01<00:00, 16.62it/s, train_loss=0.00886, val_loss=0.00961]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 35.16it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 31.51it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 34.67it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 35.96it/s][A
                                                                      [AEpoch 9: 100%|██████████| 20/20 [00:01<00:00, 15.08it/s, train_loss=0.00886, val_loss=0.00785]Epoch 9: 100%|██████████| 20/20 [00:01<00:00, 15.07it/s, train_loss=0.00886, val_loss=0.00785]Epoch 9:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00886, val_loss=0.00785]         Epoch 10:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00886, val_loss=0.00785]Epoch 10:   5%|▌         | 1/20 [00:00<00:01, 18.66it/s, train_loss=0.00886, val_loss=0.00785]Epoch 10:   5%|▌         | 1/20 [00:00<00:01, 16.09it/s, train_loss=0.00822, val_loss=0.00785]Epoch 10:  10%|█         | 2/20 [00:00<00:01, 16.37it/s, train_loss=0.00822, val_loss=0.00785]Epoch 10:  10%|█         | 2/20 [00:00<00:01, 15.51it/s, train_loss=0.00873, val_loss=0.00785]Epoch 10:  15%|█▌        | 3/20 [00:00<00:01, 14.97it/s, train_loss=0.00873, val_loss=0.00785]Epoch 10:  15%|█▌        | 3/20 [00:00<00:01, 14.59it/s, train_loss=0.00887, val_loss=0.00785]Epoch 10:  20%|██        | 4/20 [00:00<00:01, 15.06it/s, train_loss=0.00887, val_loss=0.00785]Epoch 10:  20%|██        | 4/20 [00:00<00:01, 14.83it/s, train_loss=0.0082, val_loss=0.00785] Epoch 10:  25%|██▌       | 5/20 [00:00<00:00, 16.67it/s, train_loss=0.0082, val_loss=0.00785]Epoch 10:  25%|██▌       | 5/20 [00:00<00:00, 16.20it/s, train_loss=0.00827, val_loss=0.00785]Epoch 10:  30%|███       | 6/20 [00:00<00:00, 17.28it/s, train_loss=0.00827, val_loss=0.00785]Epoch 10:  30%|███       | 6/20 [00:00<00:00, 16.91it/s, train_loss=0.00801, val_loss=0.00785]Epoch 10:  35%|███▌      | 7/20 [00:00<00:00, 18.16it/s, train_loss=0.00801, val_loss=0.00785]Epoch 10:  35%|███▌      | 7/20 [00:00<00:00, 17.77it/s, train_loss=0.00825, val_loss=0.00785]Epoch 10:  40%|████      | 8/20 [00:00<00:00, 17.10it/s, train_loss=0.00825, val_loss=0.00785]Epoch 10:  40%|████      | 8/20 [00:00<00:00, 16.91it/s, train_loss=0.00885, val_loss=0.00785]Epoch 10:  45%|████▌     | 9/20 [00:00<00:00, 17.27it/s, train_loss=0.00885, val_loss=0.00785]Epoch 10:  45%|████▌     | 9/20 [00:00<00:00, 17.06it/s, train_loss=0.00862, val_loss=0.00785]Epoch 10:  50%|█████     | 10/20 [00:00<00:00, 16.64it/s, train_loss=0.00862, val_loss=0.00785]Epoch 10:  50%|█████     | 10/20 [00:00<00:00, 16.45it/s, train_loss=0.00829, val_loss=0.00785]Epoch 10:  55%|█████▌    | 11/20 [00:00<00:00, 16.61it/s, train_loss=0.00829, val_loss=0.00785]Epoch 10:  55%|█████▌    | 11/20 [00:00<00:00, 16.39it/s, train_loss=0.00793, val_loss=0.00785]Epoch 10:  60%|██████    | 12/20 [00:00<00:00, 16.06it/s, train_loss=0.00793, val_loss=0.00785]Epoch 10:  60%|██████    | 12/20 [00:00<00:00, 15.97it/s, train_loss=0.00806, val_loss=0.00785]Epoch 10:  65%|██████▌   | 13/20 [00:00<00:00, 16.29it/s, train_loss=0.00806, val_loss=0.00785]Epoch 10:  65%|██████▌   | 13/20 [00:00<00:00, 16.20it/s, train_loss=0.00815, val_loss=0.00785]Epoch 10:  70%|███████   | 14/20 [00:00<00:00, 16.11it/s, train_loss=0.00815, val_loss=0.00785]Epoch 10:  70%|███████   | 14/20 [00:00<00:00, 16.02it/s, train_loss=0.00759, val_loss=0.00785]Epoch 10:  75%|███████▌  | 15/20 [00:00<00:00, 16.03it/s, train_loss=0.00759, val_loss=0.00785]Epoch 10:  75%|███████▌  | 15/20 [00:00<00:00, 15.92it/s, train_loss=0.00771, val_loss=0.00785]Epoch 10:  80%|████████  | 16/20 [00:00<00:00, 16.09it/s, train_loss=0.00771, val_loss=0.00785]Epoch 10:  80%|████████  | 16/20 [00:01<00:00, 15.99it/s, train_loss=0.00785, val_loss=0.00785]Epoch 10:  85%|████████▌ | 17/20 [00:01<00:00, 16.16it/s, train_loss=0.00785, val_loss=0.00785]Epoch 10:  85%|████████▌ | 17/20 [00:01<00:00, 16.05it/s, train_loss=0.0073, val_loss=0.00785] Epoch 10:  90%|█████████ | 18/20 [00:01<00:00, 16.30it/s, train_loss=0.0073, val_loss=0.00785]Epoch 10:  90%|█████████ | 18/20 [00:01<00:00, 16.19it/s, train_loss=0.00747, val_loss=0.00785]Epoch 10:  95%|█████████▌| 19/20 [00:01<00:00, 16.21it/s, train_loss=0.00747, val_loss=0.00785]Epoch 10:  95%|█████████▌| 19/20 [00:01<00:00, 16.14it/s, train_loss=0.00732, val_loss=0.00785]Epoch 10: 100%|██████████| 20/20 [00:01<00:00, 16.34it/s, train_loss=0.00732, val_loss=0.00785]Epoch 10: 100%|██████████| 20/20 [00:01<00:00, 16.30it/s, train_loss=0.0073, val_loss=0.00785] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 27.94it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 37.51it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 37.55it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 41.32it/s][A
                                                                      [AEpoch 10: 100%|██████████| 20/20 [00:01<00:00, 14.93it/s, train_loss=0.0073, val_loss=0.00728]Epoch 10: 100%|██████████| 20/20 [00:01<00:00, 14.92it/s, train_loss=0.0073, val_loss=0.00728]Epoch 10:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0073, val_loss=0.00728]         Epoch 11:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0073, val_loss=0.00728]Epoch 11:   5%|▌         | 1/20 [00:00<00:00, 23.98it/s, train_loss=0.0073, val_loss=0.00728]Epoch 11:   5%|▌         | 1/20 [00:00<00:00, 20.40it/s, train_loss=0.00786, val_loss=0.00728]Epoch 11:  10%|█         | 2/20 [00:00<00:01, 16.97it/s, train_loss=0.00786, val_loss=0.00728]Epoch 11:  10%|█         | 2/20 [00:00<00:01, 16.16it/s, train_loss=0.00797, val_loss=0.00728]Epoch 11:  15%|█▌        | 3/20 [00:00<00:00, 17.93it/s, train_loss=0.00797, val_loss=0.00728]Epoch 11:  15%|█▌        | 3/20 [00:00<00:00, 17.30it/s, train_loss=0.00717, val_loss=0.00728]Epoch 11:  20%|██        | 4/20 [00:00<00:00, 17.18it/s, train_loss=0.00717, val_loss=0.00728]Epoch 11:  20%|██        | 4/20 [00:00<00:00, 16.99it/s, train_loss=0.00777, val_loss=0.00728]Epoch 11:  25%|██▌       | 5/20 [00:00<00:00, 17.67it/s, train_loss=0.00777, val_loss=0.00728]Epoch 11:  25%|██▌       | 5/20 [00:00<00:00, 17.10it/s, train_loss=0.00769, val_loss=0.00728]Epoch 11:  30%|███       | 6/20 [00:00<00:00, 17.13it/s, train_loss=0.00769, val_loss=0.00728]Epoch 11:  30%|███       | 6/20 [00:00<00:00, 16.82it/s, train_loss=0.00733, val_loss=0.00728]Epoch 11:  35%|███▌      | 7/20 [00:00<00:00, 17.44it/s, train_loss=0.00733, val_loss=0.00728]Epoch 11:  35%|███▌      | 7/20 [00:00<00:00, 17.12it/s, train_loss=0.00733, val_loss=0.00728]Epoch 11:  40%|████      | 8/20 [00:00<00:00, 17.68it/s, train_loss=0.00733, val_loss=0.00728]Epoch 11:  40%|████      | 8/20 [00:00<00:00, 17.34it/s, train_loss=0.00694, val_loss=0.00728]Epoch 11:  45%|████▌     | 9/20 [00:00<00:00, 17.50it/s, train_loss=0.00694, val_loss=0.00728]Epoch 11:  45%|████▌     | 9/20 [00:00<00:00, 17.32it/s, train_loss=0.00768, val_loss=0.00728]Epoch 11:  50%|█████     | 10/20 [00:00<00:00, 17.61it/s, train_loss=0.00768, val_loss=0.00728]Epoch 11:  50%|█████     | 10/20 [00:00<00:00, 17.44it/s, train_loss=0.00672, val_loss=0.00728]Epoch 11:  55%|█████▌    | 11/20 [00:00<00:00, 17.47it/s, train_loss=0.00672, val_loss=0.00728]Epoch 11:  55%|█████▌    | 11/20 [00:00<00:00, 17.26it/s, train_loss=0.00703, val_loss=0.00728]Epoch 11:  60%|██████    | 12/20 [00:00<00:00, 17.69it/s, train_loss=0.00703, val_loss=0.00728]Epoch 11:  60%|██████    | 12/20 [00:00<00:00, 17.45it/s, train_loss=0.0073, val_loss=0.00728] Epoch 11:  65%|██████▌   | 13/20 [00:00<00:00, 17.62it/s, train_loss=0.0073, val_loss=0.00728]Epoch 11:  65%|██████▌   | 13/20 [00:00<00:00, 17.41it/s, train_loss=0.00696, val_loss=0.00728]Epoch 11:  70%|███████   | 14/20 [00:00<00:00, 17.50it/s, train_loss=0.00696, val_loss=0.00728]Epoch 11:  70%|███████   | 14/20 [00:00<00:00, 17.38it/s, train_loss=0.00754, val_loss=0.00728]Epoch 11:  75%|███████▌  | 15/20 [00:00<00:00, 17.25it/s, train_loss=0.00754, val_loss=0.00728]Epoch 11:  75%|███████▌  | 15/20 [00:00<00:00, 17.14it/s, train_loss=0.00754, val_loss=0.00728]Epoch 11:  80%|████████  | 16/20 [00:00<00:00, 17.12it/s, train_loss=0.00754, val_loss=0.00728]Epoch 11:  80%|████████  | 16/20 [00:00<00:00, 16.99it/s, train_loss=0.00683, val_loss=0.00728]Epoch 11:  85%|████████▌ | 17/20 [00:00<00:00, 17.18it/s, train_loss=0.00683, val_loss=0.00728]Epoch 11:  85%|████████▌ | 17/20 [00:00<00:00, 17.07it/s, train_loss=0.00772, val_loss=0.00728]Epoch 11:  90%|█████████ | 18/20 [00:01<00:00, 17.40it/s, train_loss=0.00772, val_loss=0.00728]Epoch 11:  90%|█████████ | 18/20 [00:01<00:00, 17.29it/s, train_loss=0.00653, val_loss=0.00728]Epoch 11:  95%|█████████▌| 19/20 [00:01<00:00, 17.49it/s, train_loss=0.00653, val_loss=0.00728]Epoch 11:  95%|█████████▌| 19/20 [00:01<00:00, 17.44it/s, train_loss=0.007, val_loss=0.00728]  Epoch 11: 100%|██████████| 20/20 [00:01<00:00, 17.41it/s, train_loss=0.007, val_loss=0.00728]Epoch 11: 100%|██████████| 20/20 [00:01<00:00, 17.33it/s, train_loss=0.00708, val_loss=0.00728]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 38.88it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 40.23it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 40.25it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.14it/s][A
                                                                      [AEpoch 11: 100%|██████████| 20/20 [00:01<00:00, 15.78it/s, train_loss=0.00708, val_loss=0.00682]Epoch 11: 100%|██████████| 20/20 [00:01<00:00, 15.76it/s, train_loss=0.00708, val_loss=0.00682]Epoch 11:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00708, val_loss=0.00682]         Epoch 12:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00708, val_loss=0.00682]Epoch 12:   5%|▌         | 1/20 [00:00<00:01, 15.21it/s, train_loss=0.00708, val_loss=0.00682]Epoch 12:   5%|▌         | 1/20 [00:00<00:01, 13.59it/s, train_loss=0.00692, val_loss=0.00682]Epoch 12:  10%|█         | 2/20 [00:00<00:01, 13.75it/s, train_loss=0.00692, val_loss=0.00682]Epoch 12:  10%|█         | 2/20 [00:00<00:01, 13.44it/s, train_loss=0.00678, val_loss=0.00682]Epoch 12:  15%|█▌        | 3/20 [00:00<00:01, 14.98it/s, train_loss=0.00678, val_loss=0.00682]Epoch 12:  15%|█▌        | 3/20 [00:00<00:01, 14.29it/s, train_loss=0.00718, val_loss=0.00682]Epoch 12:  20%|██        | 4/20 [00:00<00:01, 15.63it/s, train_loss=0.00718, val_loss=0.00682]Epoch 12:  20%|██        | 4/20 [00:00<00:01, 15.18it/s, train_loss=0.00692, val_loss=0.00682]Epoch 12:  25%|██▌       | 5/20 [00:00<00:00, 15.20it/s, train_loss=0.00692, val_loss=0.00682]Epoch 12:  25%|██▌       | 5/20 [00:00<00:01, 14.45it/s, train_loss=0.00738, val_loss=0.00682]Epoch 12:  30%|███       | 6/20 [00:00<00:00, 14.93it/s, train_loss=0.00738, val_loss=0.00682]Epoch 12:  30%|███       | 6/20 [00:00<00:00, 14.74it/s, train_loss=0.00694, val_loss=0.00682]Epoch 12:  35%|███▌      | 7/20 [00:00<00:00, 15.54it/s, train_loss=0.00694, val_loss=0.00682]Epoch 12:  35%|███▌      | 7/20 [00:00<00:00, 15.30it/s, train_loss=0.00732, val_loss=0.00682]Epoch 12:  40%|████      | 8/20 [00:00<00:00, 15.79it/s, train_loss=0.00732, val_loss=0.00682]Epoch 12:  40%|████      | 8/20 [00:00<00:00, 15.68it/s, train_loss=0.00683, val_loss=0.00682]Epoch 12:  45%|████▌     | 9/20 [00:00<00:00, 15.61it/s, train_loss=0.00683, val_loss=0.00682]Epoch 12:  45%|████▌     | 9/20 [00:00<00:00, 15.50it/s, train_loss=0.00667, val_loss=0.00682]Epoch 12:  50%|█████     | 10/20 [00:00<00:00, 16.05it/s, train_loss=0.00667, val_loss=0.00682]Epoch 12:  50%|█████     | 10/20 [00:00<00:00, 15.82it/s, train_loss=0.0066, val_loss=0.00682] Epoch 12:  55%|█████▌    | 11/20 [00:00<00:00, 15.99it/s, train_loss=0.0066, val_loss=0.00682]Epoch 12:  55%|█████▌    | 11/20 [00:00<00:00, 15.86it/s, train_loss=0.00715, val_loss=0.00682]Epoch 12:  60%|██████    | 12/20 [00:00<00:00, 16.29it/s, train_loss=0.00715, val_loss=0.00682]Epoch 12:  60%|██████    | 12/20 [00:00<00:00, 16.07it/s, train_loss=0.00693, val_loss=0.00682]Epoch 12:  65%|██████▌   | 13/20 [00:00<00:00, 16.65it/s, train_loss=0.00693, val_loss=0.00682]Epoch 12:  65%|██████▌   | 13/20 [00:00<00:00, 16.52it/s, train_loss=0.00698, val_loss=0.00682]Epoch 12:  70%|███████   | 14/20 [00:00<00:00, 16.44it/s, train_loss=0.00698, val_loss=0.00682]Epoch 12:  70%|███████   | 14/20 [00:00<00:00, 16.30it/s, train_loss=0.00615, val_loss=0.00682]Epoch 12:  75%|███████▌  | 15/20 [00:00<00:00, 16.49it/s, train_loss=0.00615, val_loss=0.00682]Epoch 12:  75%|███████▌  | 15/20 [00:00<00:00, 16.40it/s, train_loss=0.00644, val_loss=0.00682]Epoch 12:  80%|████████  | 16/20 [00:00<00:00, 16.42it/s, train_loss=0.00644, val_loss=0.00682]Epoch 12:  80%|████████  | 16/20 [00:00<00:00, 16.32it/s, train_loss=0.00652, val_loss=0.00682]Epoch 12:  85%|████████▌ | 17/20 [00:01<00:00, 16.45it/s, train_loss=0.00652, val_loss=0.00682]Epoch 12:  85%|████████▌ | 17/20 [00:01<00:00, 16.37it/s, train_loss=0.00616, val_loss=0.00682]Epoch 12:  90%|█████████ | 18/20 [00:01<00:00, 16.30it/s, train_loss=0.00616, val_loss=0.00682]Epoch 12:  90%|█████████ | 18/20 [00:01<00:00, 16.22it/s, train_loss=0.00737, val_loss=0.00682]Epoch 12:  95%|█████████▌| 19/20 [00:01<00:00, 16.46it/s, train_loss=0.00737, val_loss=0.00682]Epoch 12:  95%|█████████▌| 19/20 [00:01<00:00, 16.37it/s, train_loss=0.00597, val_loss=0.00682]Epoch 12: 100%|██████████| 20/20 [00:01<00:00, 16.57it/s, train_loss=0.00597, val_loss=0.00682]Epoch 12: 100%|██████████| 20/20 [00:01<00:00, 16.50it/s, train_loss=0.00712, val_loss=0.00682]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 45.39it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 41.63it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 45.12it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 41.41it/s][A
                                                                      [AEpoch 12: 100%|██████████| 20/20 [00:01<00:00, 15.15it/s, train_loss=0.00712, val_loss=0.00627]Epoch 12: 100%|██████████| 20/20 [00:01<00:00, 15.10it/s, train_loss=0.00712, val_loss=0.00627]Epoch 12:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00712, val_loss=0.00627]         Epoch 13:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00712, val_loss=0.00627]Epoch 13:   5%|▌         | 1/20 [00:00<00:00, 22.84it/s, train_loss=0.00712, val_loss=0.00627]Epoch 13:   5%|▌         | 1/20 [00:00<00:00, 19.24it/s, train_loss=0.00679, val_loss=0.00627]Epoch 13:  10%|█         | 2/20 [00:00<00:00, 19.54it/s, train_loss=0.00679, val_loss=0.00627]Epoch 13:  10%|█         | 2/20 [00:00<00:00, 18.25it/s, train_loss=0.0065, val_loss=0.00627] Epoch 13:  15%|█▌        | 3/20 [00:00<00:00, 19.45it/s, train_loss=0.0065, val_loss=0.00627]Epoch 13:  15%|█▌        | 3/20 [00:00<00:00, 18.64it/s, train_loss=0.00658, val_loss=0.00627]Epoch 13:  20%|██        | 4/20 [00:00<00:00, 18.46it/s, train_loss=0.00658, val_loss=0.00627]Epoch 13:  20%|██        | 4/20 [00:00<00:00, 18.12it/s, train_loss=0.00682, val_loss=0.00627]Epoch 13:  25%|██▌       | 5/20 [00:00<00:00, 18.04it/s, train_loss=0.00682, val_loss=0.00627]Epoch 13:  25%|██▌       | 5/20 [00:00<00:00, 17.57it/s, train_loss=0.00673, val_loss=0.00627]Epoch 13:  30%|███       | 6/20 [00:00<00:00, 17.02it/s, train_loss=0.00673, val_loss=0.00627]Epoch 13:  30%|███       | 6/20 [00:00<00:00, 16.71it/s, train_loss=0.00623, val_loss=0.00627]Epoch 13:  35%|███▌      | 7/20 [00:00<00:00, 17.40it/s, train_loss=0.00623, val_loss=0.00627]Epoch 13:  35%|███▌      | 7/20 [00:00<00:00, 17.10it/s, train_loss=0.0068, val_loss=0.00627] Epoch 13:  40%|████      | 8/20 [00:00<00:00, 17.98it/s, train_loss=0.0068, val_loss=0.00627]Epoch 13:  40%|████      | 8/20 [00:00<00:00, 17.67it/s, train_loss=0.00655, val_loss=0.00627]Epoch 13:  45%|████▌     | 9/20 [00:00<00:00, 17.36it/s, train_loss=0.00655, val_loss=0.00627]Epoch 13:  45%|████▌     | 9/20 [00:00<00:00, 17.23it/s, train_loss=0.00633, val_loss=0.00627]Epoch 13:  50%|█████     | 10/20 [00:00<00:00, 17.54it/s, train_loss=0.00633, val_loss=0.00627]Epoch 13:  50%|█████     | 10/20 [00:00<00:00, 17.27it/s, train_loss=0.00656, val_loss=0.00627]Epoch 13:  55%|█████▌    | 11/20 [00:00<00:00, 17.26it/s, train_loss=0.00656, val_loss=0.00627]Epoch 13:  55%|█████▌    | 11/20 [00:00<00:00, 17.17it/s, train_loss=0.00632, val_loss=0.00627]Epoch 13:  60%|██████    | 12/20 [00:00<00:00, 17.34it/s, train_loss=0.00632, val_loss=0.00627]Epoch 13:  60%|██████    | 12/20 [00:00<00:00, 17.13it/s, train_loss=0.00662, val_loss=0.00627]Epoch 13:  65%|██████▌   | 13/20 [00:00<00:00, 17.10it/s, train_loss=0.00662, val_loss=0.00627]Epoch 13:  65%|██████▌   | 13/20 [00:00<00:00, 16.95it/s, train_loss=0.00599, val_loss=0.00627]Epoch 13:  70%|███████   | 14/20 [00:00<00:00, 17.29it/s, train_loss=0.00599, val_loss=0.00627]Epoch 13:  70%|███████   | 14/20 [00:00<00:00, 17.16it/s, train_loss=0.00646, val_loss=0.00627]Epoch 13:  75%|███████▌  | 15/20 [00:00<00:00, 17.32it/s, train_loss=0.00646, val_loss=0.00627]Epoch 13:  75%|███████▌  | 15/20 [00:00<00:00, 17.14it/s, train_loss=0.00637, val_loss=0.00627]Epoch 13:  80%|████████  | 16/20 [00:00<00:00, 17.38it/s, train_loss=0.00637, val_loss=0.00627]Epoch 13:  80%|████████  | 16/20 [00:00<00:00, 17.25it/s, train_loss=0.0066, val_loss=0.00627] Epoch 13:  85%|████████▌ | 17/20 [00:00<00:00, 17.36it/s, train_loss=0.0066, val_loss=0.00627]Epoch 13:  85%|████████▌ | 17/20 [00:00<00:00, 17.18it/s, train_loss=0.0062, val_loss=0.00627]Epoch 13:  90%|█████████ | 18/20 [00:01<00:00, 17.12it/s, train_loss=0.0062, val_loss=0.00627]Epoch 13:  90%|█████████ | 18/20 [00:01<00:00, 16.99it/s, train_loss=0.00561, val_loss=0.00627]Epoch 13:  95%|█████████▌| 19/20 [00:01<00:00, 17.12it/s, train_loss=0.00561, val_loss=0.00627]Epoch 13:  95%|█████████▌| 19/20 [00:01<00:00, 16.98it/s, train_loss=0.00666, val_loss=0.00627]Epoch 13: 100%|██████████| 20/20 [00:01<00:00, 17.11it/s, train_loss=0.00666, val_loss=0.00627]Epoch 13: 100%|██████████| 20/20 [00:01<00:00, 17.02it/s, train_loss=0.00663, val_loss=0.00627]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 34.99it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 34.10it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 36.19it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 35.34it/s][A
                                                                      [AEpoch 13: 100%|██████████| 20/20 [00:01<00:00, 15.40it/s, train_loss=0.00663, val_loss=0.00591]Epoch 13: 100%|██████████| 20/20 [00:01<00:00, 15.39it/s, train_loss=0.00663, val_loss=0.00591]Epoch 13:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00663, val_loss=0.00591]         Epoch 14:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00663, val_loss=0.00591]Epoch 14:   5%|▌         | 1/20 [00:00<00:01, 15.14it/s, train_loss=0.00663, val_loss=0.00591]Epoch 14:   5%|▌         | 1/20 [00:00<00:01, 14.64it/s, train_loss=0.00637, val_loss=0.00591]Epoch 14:  10%|█         | 2/20 [00:00<00:01, 17.24it/s, train_loss=0.00637, val_loss=0.00591]Epoch 14:  10%|█         | 2/20 [00:00<00:01, 16.29it/s, train_loss=0.00611, val_loss=0.00591]Epoch 14:  15%|█▌        | 3/20 [00:00<00:00, 18.81it/s, train_loss=0.00611, val_loss=0.00591]Epoch 14:  15%|█▌        | 3/20 [00:00<00:00, 17.94it/s, train_loss=0.00616, val_loss=0.00591]Epoch 14:  20%|██        | 4/20 [00:00<00:00, 17.67it/s, train_loss=0.00616, val_loss=0.00591]Epoch 14:  20%|██        | 4/20 [00:00<00:00, 17.45it/s, train_loss=0.00616, val_loss=0.00591]Epoch 14:  25%|██▌       | 5/20 [00:00<00:00, 17.76it/s, train_loss=0.00616, val_loss=0.00591]Epoch 14:  25%|██▌       | 5/20 [00:00<00:00, 17.40it/s, train_loss=0.00632, val_loss=0.00591]Epoch 14:  30%|███       | 6/20 [00:00<00:00, 16.28it/s, train_loss=0.00632, val_loss=0.00591]Epoch 14:  30%|███       | 6/20 [00:00<00:00, 16.20it/s, train_loss=0.00619, val_loss=0.00591]Epoch 14:  35%|███▌      | 7/20 [00:00<00:00, 16.34it/s, train_loss=0.00619, val_loss=0.00591]Epoch 14:  35%|███▌      | 7/20 [00:00<00:00, 16.18it/s, train_loss=0.00593, val_loss=0.00591]Epoch 14:  40%|████      | 8/20 [00:00<00:00, 16.03it/s, train_loss=0.00593, val_loss=0.00591]Epoch 14:  40%|████      | 8/20 [00:00<00:00, 15.80it/s, train_loss=0.00609, val_loss=0.00591]Epoch 14:  45%|████▌     | 9/20 [00:00<00:00, 16.21it/s, train_loss=0.00609, val_loss=0.00591]Epoch 14:  45%|████▌     | 9/20 [00:00<00:00, 16.01it/s, train_loss=0.00613, val_loss=0.00591]Epoch 14:  50%|█████     | 10/20 [00:00<00:00, 16.21it/s, train_loss=0.00613, val_loss=0.00591]Epoch 14:  50%|█████     | 10/20 [00:00<00:00, 16.04it/s, train_loss=0.00639, val_loss=0.00591]Epoch 14:  55%|█████▌    | 11/20 [00:00<00:00, 16.09it/s, train_loss=0.00639, val_loss=0.00591]Epoch 14:  55%|█████▌    | 11/20 [00:00<00:00, 15.88it/s, train_loss=0.00599, val_loss=0.00591]Epoch 14:  60%|██████    | 12/20 [00:00<00:00, 16.01it/s, train_loss=0.00599, val_loss=0.00591]Epoch 14:  60%|██████    | 12/20 [00:00<00:00, 15.83it/s, train_loss=0.0068, val_loss=0.00591] Epoch 14:  65%|██████▌   | 13/20 [00:00<00:00, 16.14it/s, train_loss=0.0068, val_loss=0.00591]Epoch 14:  65%|██████▌   | 13/20 [00:00<00:00, 15.99it/s, train_loss=0.00584, val_loss=0.00591]Epoch 14:  70%|███████   | 14/20 [00:00<00:00, 16.22it/s, train_loss=0.00584, val_loss=0.00591]Epoch 14:  70%|███████   | 14/20 [00:00<00:00, 16.11it/s, train_loss=0.00607, val_loss=0.00591]Epoch 14:  75%|███████▌  | 15/20 [00:00<00:00, 16.36it/s, train_loss=0.00607, val_loss=0.00591]Epoch 14:  75%|███████▌  | 15/20 [00:00<00:00, 16.21it/s, train_loss=0.00606, val_loss=0.00591]Epoch 14:  80%|████████  | 16/20 [00:00<00:00, 16.21it/s, train_loss=0.00606, val_loss=0.00591]Epoch 14:  80%|████████  | 16/20 [00:00<00:00, 16.10it/s, train_loss=0.00584, val_loss=0.00591]Epoch 14:  85%|████████▌ | 17/20 [00:01<00:00, 16.21it/s, train_loss=0.00584, val_loss=0.00591]Epoch 14:  85%|████████▌ | 17/20 [00:01<00:00, 16.03it/s, train_loss=0.00567, val_loss=0.00591]Epoch 14:  90%|█████████ | 18/20 [00:01<00:00, 16.11it/s, train_loss=0.00567, val_loss=0.00591]Epoch 14:  90%|█████████ | 18/20 [00:01<00:00, 16.04it/s, train_loss=0.00582, val_loss=0.00591]Epoch 14:  95%|█████████▌| 19/20 [00:01<00:00, 16.38it/s, train_loss=0.00582, val_loss=0.00591]Epoch 14:  95%|█████████▌| 19/20 [00:01<00:00, 16.22it/s, train_loss=0.00649, val_loss=0.00591]Epoch 14: 100%|██████████| 20/20 [00:01<00:00, 16.57it/s, train_loss=0.00649, val_loss=0.00591]Epoch 14: 100%|██████████| 20/20 [00:01<00:00, 16.50it/s, train_loss=0.00546, val_loss=0.00591]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 30.44it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 35.50it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 39.33it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.86it/s][A
                                                                      [AEpoch 14: 100%|██████████| 20/20 [00:01<00:00, 15.06it/s, train_loss=0.00546, val_loss=0.00577]Epoch 14: 100%|██████████| 20/20 [00:01<00:00, 15.05it/s, train_loss=0.00546, val_loss=0.00577]Epoch 14:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00546, val_loss=0.00577]         Epoch 15:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00546, val_loss=0.00577]Epoch 15:   5%|▌         | 1/20 [00:00<00:01, 17.12it/s, train_loss=0.00546, val_loss=0.00577]Epoch 15:   5%|▌         | 1/20 [00:00<00:01, 16.61it/s, train_loss=0.00569, val_loss=0.00577]Epoch 15:  10%|█         | 2/20 [00:00<00:00, 18.38it/s, train_loss=0.00569, val_loss=0.00577]Epoch 15:  10%|█         | 2/20 [00:00<00:01, 16.98it/s, train_loss=0.00582, val_loss=0.00577]Epoch 15:  15%|█▌        | 3/20 [00:00<00:01, 15.93it/s, train_loss=0.00582, val_loss=0.00577]Epoch 15:  15%|█▌        | 3/20 [00:00<00:01, 15.43it/s, train_loss=0.00626, val_loss=0.00577]Epoch 15:  20%|██        | 4/20 [00:00<00:01, 15.83it/s, train_loss=0.00626, val_loss=0.00577]Epoch 15:  20%|██        | 4/20 [00:00<00:01, 15.34it/s, train_loss=0.00546, val_loss=0.00577]Epoch 15:  25%|██▌       | 5/20 [00:00<00:00, 16.22it/s, train_loss=0.00546, val_loss=0.00577]Epoch 15:  25%|██▌       | 5/20 [00:00<00:00, 16.01it/s, train_loss=0.00618, val_loss=0.00577]Epoch 15:  30%|███       | 6/20 [00:00<00:00, 16.30it/s, train_loss=0.00618, val_loss=0.00577]Epoch 15:  30%|███       | 6/20 [00:00<00:00, 16.05it/s, train_loss=0.0057, val_loss=0.00577] Epoch 15:  35%|███▌      | 7/20 [00:00<00:00, 16.10it/s, train_loss=0.0057, val_loss=0.00577]Epoch 15:  35%|███▌      | 7/20 [00:00<00:00, 15.86it/s, train_loss=0.00635, val_loss=0.00577]Epoch 15:  40%|████      | 8/20 [00:00<00:00, 16.51it/s, train_loss=0.00635, val_loss=0.00577]Epoch 15:  40%|████      | 8/20 [00:00<00:00, 16.27it/s, train_loss=0.00602, val_loss=0.00577]Epoch 15:  45%|████▌     | 9/20 [00:00<00:00, 16.70it/s, train_loss=0.00602, val_loss=0.00577]Epoch 15:  45%|████▌     | 9/20 [00:00<00:00, 16.53it/s, train_loss=0.0061, val_loss=0.00577] Epoch 15:  50%|█████     | 10/20 [00:00<00:00, 16.83it/s, train_loss=0.0061, val_loss=0.00577]Epoch 15:  50%|█████     | 10/20 [00:00<00:00, 16.59it/s, train_loss=0.00558, val_loss=0.00577]Epoch 15:  55%|█████▌    | 11/20 [00:00<00:00, 16.30it/s, train_loss=0.00558, val_loss=0.00577]Epoch 15:  55%|█████▌    | 11/20 [00:00<00:00, 16.19it/s, train_loss=0.0058, val_loss=0.00577] Epoch 15:  60%|██████    | 12/20 [00:00<00:00, 16.43it/s, train_loss=0.0058, val_loss=0.00577]Epoch 15:  60%|██████    | 12/20 [00:00<00:00, 16.28it/s, train_loss=0.00549, val_loss=0.00577]Epoch 15:  65%|██████▌   | 13/20 [00:00<00:00, 16.22it/s, train_loss=0.00549, val_loss=0.00577]Epoch 15:  65%|██████▌   | 13/20 [00:00<00:00, 16.07it/s, train_loss=0.00576, val_loss=0.00577]Epoch 15:  70%|███████   | 14/20 [00:00<00:00, 16.65it/s, train_loss=0.00576, val_loss=0.00577]Epoch 15:  70%|███████   | 14/20 [00:00<00:00, 16.46it/s, train_loss=0.00511, val_loss=0.00577]Epoch 15:  75%|███████▌  | 15/20 [00:00<00:00, 16.57it/s, train_loss=0.00511, val_loss=0.00577]Epoch 15:  75%|███████▌  | 15/20 [00:00<00:00, 16.48it/s, train_loss=0.006, val_loss=0.00577]  Epoch 15:  80%|████████  | 16/20 [00:00<00:00, 16.70it/s, train_loss=0.006, val_loss=0.00577]Epoch 15:  80%|████████  | 16/20 [00:00<00:00, 16.57it/s, train_loss=0.00557, val_loss=0.00577]Epoch 15:  85%|████████▌ | 17/20 [00:01<00:00, 16.81it/s, train_loss=0.00557, val_loss=0.00577]Epoch 15:  85%|████████▌ | 17/20 [00:01<00:00, 16.70it/s, train_loss=0.00568, val_loss=0.00577]Epoch 15:  90%|█████████ | 18/20 [00:01<00:00, 16.65it/s, train_loss=0.00568, val_loss=0.00577]Epoch 15:  90%|█████████ | 18/20 [00:01<00:00, 16.56it/s, train_loss=0.00589, val_loss=0.00577]Epoch 15:  95%|█████████▌| 19/20 [00:01<00:00, 16.70it/s, train_loss=0.00589, val_loss=0.00577]Epoch 15:  95%|█████████▌| 19/20 [00:01<00:00, 16.60it/s, train_loss=0.00557, val_loss=0.00577]Epoch 15: 100%|██████████| 20/20 [00:01<00:00, 16.37it/s, train_loss=0.00557, val_loss=0.00577]Epoch 15: 100%|██████████| 20/20 [00:01<00:00, 16.32it/s, train_loss=0.00578, val_loss=0.00577]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 28.48it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 34.69it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 37.43it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 38.95it/s][A
                                                                      [AEpoch 15: 100%|██████████| 20/20 [00:01<00:00, 14.94it/s, train_loss=0.00578, val_loss=0.00549]Epoch 15: 100%|██████████| 20/20 [00:01<00:00, 14.93it/s, train_loss=0.00578, val_loss=0.00549]Epoch 15:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00578, val_loss=0.00549]         Epoch 16:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00578, val_loss=0.00549]Epoch 16:   5%|▌         | 1/20 [00:00<00:01, 14.49it/s, train_loss=0.00578, val_loss=0.00549]Epoch 16:   5%|▌         | 1/20 [00:00<00:01, 13.39it/s, train_loss=0.00577, val_loss=0.00549]Epoch 16:  10%|█         | 2/20 [00:00<00:01, 15.69it/s, train_loss=0.00577, val_loss=0.00549]Epoch 16:  10%|█         | 2/20 [00:00<00:01, 15.13it/s, train_loss=0.00605, val_loss=0.00549]Epoch 16:  15%|█▌        | 3/20 [00:00<00:01, 16.52it/s, train_loss=0.00605, val_loss=0.00549]Epoch 16:  15%|█▌        | 3/20 [00:00<00:01, 15.76it/s, train_loss=0.00599, val_loss=0.00549]Epoch 16:  20%|██        | 4/20 [00:00<00:00, 16.74it/s, train_loss=0.00599, val_loss=0.00549]Epoch 16:  20%|██        | 4/20 [00:00<00:00, 16.18it/s, train_loss=0.00568, val_loss=0.00549]Epoch 16:  25%|██▌       | 5/20 [00:00<00:00, 16.39it/s, train_loss=0.00568, val_loss=0.00549]Epoch 16:  25%|██▌       | 5/20 [00:00<00:00, 16.10it/s, train_loss=0.00558, val_loss=0.00549]Epoch 16:  30%|███       | 6/20 [00:00<00:00, 16.26it/s, train_loss=0.00558, val_loss=0.00549]Epoch 16:  30%|███       | 6/20 [00:00<00:00, 16.03it/s, train_loss=0.00562, val_loss=0.00549]Epoch 16:  35%|███▌      | 7/20 [00:00<00:00, 16.10it/s, train_loss=0.00562, val_loss=0.00549]Epoch 16:  35%|███▌      | 7/20 [00:00<00:00, 15.82it/s, train_loss=0.00536, val_loss=0.00549]Epoch 16:  40%|████      | 8/20 [00:00<00:00, 16.54it/s, train_loss=0.00536, val_loss=0.00549]Epoch 16:  40%|████      | 8/20 [00:00<00:00, 16.27it/s, train_loss=0.00567, val_loss=0.00549]Epoch 16:  45%|████▌     | 9/20 [00:00<00:00, 17.09it/s, train_loss=0.00567, val_loss=0.00549]Epoch 16:  45%|████▌     | 9/20 [00:00<00:00, 16.75it/s, train_loss=0.0058, val_loss=0.00549] Epoch 16:  50%|█████     | 10/20 [00:00<00:00, 16.50it/s, train_loss=0.0058, val_loss=0.00549]Epoch 16:  50%|█████     | 10/20 [00:00<00:00, 16.29it/s, train_loss=0.00479, val_loss=0.00549]Epoch 16:  55%|█████▌    | 11/20 [00:00<00:00, 16.56it/s, train_loss=0.00479, val_loss=0.00549]Epoch 16:  55%|█████▌    | 11/20 [00:00<00:00, 16.40it/s, train_loss=0.00567, val_loss=0.00549]Epoch 16:  60%|██████    | 12/20 [00:00<00:00, 16.26it/s, train_loss=0.00567, val_loss=0.00549]Epoch 16:  60%|██████    | 12/20 [00:00<00:00, 16.20it/s, train_loss=0.00545, val_loss=0.00549]Epoch 16:  65%|██████▌   | 13/20 [00:00<00:00, 16.45it/s, train_loss=0.00545, val_loss=0.00549]Epoch 16:  65%|██████▌   | 13/20 [00:00<00:00, 16.32it/s, train_loss=0.00545, val_loss=0.00549]Epoch 16:  70%|███████   | 14/20 [00:00<00:00, 16.30it/s, train_loss=0.00545, val_loss=0.00549]Epoch 16:  70%|███████   | 14/20 [00:00<00:00, 16.19it/s, train_loss=0.00512, val_loss=0.00549]Epoch 16:  75%|███████▌  | 15/20 [00:00<00:00, 16.21it/s, train_loss=0.00512, val_loss=0.00549]Epoch 16:  75%|███████▌  | 15/20 [00:00<00:00, 16.10it/s, train_loss=0.00573, val_loss=0.00549]Epoch 16:  80%|████████  | 16/20 [00:00<00:00, 16.31it/s, train_loss=0.00573, val_loss=0.00549]Epoch 16:  80%|████████  | 16/20 [00:00<00:00, 16.21it/s, train_loss=0.00569, val_loss=0.00549]Epoch 16:  85%|████████▌ | 17/20 [00:01<00:00, 16.33it/s, train_loss=0.00569, val_loss=0.00549]Epoch 16:  85%|████████▌ | 17/20 [00:01<00:00, 16.20it/s, train_loss=0.00532, val_loss=0.00549]Epoch 16:  90%|█████████ | 18/20 [00:01<00:00, 16.21it/s, train_loss=0.00532, val_loss=0.00549]Epoch 16:  90%|█████████ | 18/20 [00:01<00:00, 16.10it/s, train_loss=0.00554, val_loss=0.00549]Epoch 16:  95%|█████████▌| 19/20 [00:01<00:00, 16.40it/s, train_loss=0.00554, val_loss=0.00549]Epoch 16:  95%|█████████▌| 19/20 [00:01<00:00, 16.31it/s, train_loss=0.00551, val_loss=0.00549]Epoch 16: 100%|██████████| 20/20 [00:01<00:00, 16.49it/s, train_loss=0.00551, val_loss=0.00549]Epoch 16: 100%|██████████| 20/20 [00:01<00:00, 16.40it/s, train_loss=0.00535, val_loss=0.00549]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 37.70it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 39.70it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 37.07it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 38.27it/s][A
                                                                      [AEpoch 16: 100%|██████████| 20/20 [00:01<00:00, 14.96it/s, train_loss=0.00535, val_loss=0.0053] Epoch 16: 100%|██████████| 20/20 [00:01<00:00, 14.94it/s, train_loss=0.00535, val_loss=0.0053]Epoch 16:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00535, val_loss=0.0053]         Epoch 17:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00535, val_loss=0.0053]Epoch 17:   5%|▌         | 1/20 [00:00<00:00, 21.20it/s, train_loss=0.00535, val_loss=0.0053]Epoch 17:   5%|▌         | 1/20 [00:00<00:01, 18.29it/s, train_loss=0.00551, val_loss=0.0053]Epoch 17:  10%|█         | 2/20 [00:00<00:01, 17.51it/s, train_loss=0.00551, val_loss=0.0053]Epoch 17:  10%|█         | 2/20 [00:00<00:01, 16.46it/s, train_loss=0.00548, val_loss=0.0053]Epoch 17:  15%|█▌        | 3/20 [00:00<00:00, 18.03it/s, train_loss=0.00548, val_loss=0.0053]Epoch 17:  15%|█▌        | 3/20 [00:00<00:00, 17.06it/s, train_loss=0.00542, val_loss=0.0053]Epoch 17:  20%|██        | 4/20 [00:00<00:00, 18.93it/s, train_loss=0.00542, val_loss=0.0053]Epoch 17:  20%|██        | 4/20 [00:00<00:00, 18.33it/s, train_loss=0.00564, val_loss=0.0053]Epoch 17:  25%|██▌       | 5/20 [00:00<00:00, 17.95it/s, train_loss=0.00564, val_loss=0.0053]Epoch 17:  25%|██▌       | 5/20 [00:00<00:00, 17.75it/s, train_loss=0.00538, val_loss=0.0053]Epoch 17:  30%|███       | 6/20 [00:00<00:00, 18.14it/s, train_loss=0.00538, val_loss=0.0053]Epoch 17:  30%|███       | 6/20 [00:00<00:00, 17.75it/s, train_loss=0.00487, val_loss=0.0053]Epoch 17:  35%|███▌      | 7/20 [00:00<00:00, 18.19it/s, train_loss=0.00487, val_loss=0.0053]Epoch 17:  35%|███▌      | 7/20 [00:00<00:00, 17.88it/s, train_loss=0.00554, val_loss=0.0053]Epoch 17:  40%|████      | 8/20 [00:00<00:00, 17.85it/s, train_loss=0.00554, val_loss=0.0053]Epoch 17:  40%|████      | 8/20 [00:00<00:00, 17.55it/s, train_loss=0.00529, val_loss=0.0053]Epoch 17:  45%|████▌     | 9/20 [00:00<00:00, 17.35it/s, train_loss=0.00529, val_loss=0.0053]Epoch 17:  45%|████▌     | 9/20 [00:00<00:00, 17.25it/s, train_loss=0.00541, val_loss=0.0053]Epoch 17:  50%|█████     | 10/20 [00:00<00:00, 17.02it/s, train_loss=0.00541, val_loss=0.0053]Epoch 17:  50%|█████     | 10/20 [00:00<00:00, 16.72it/s, train_loss=0.00526, val_loss=0.0053]Epoch 17:  55%|█████▌    | 11/20 [00:00<00:00, 17.02it/s, train_loss=0.00526, val_loss=0.0053]Epoch 17:  55%|█████▌    | 11/20 [00:00<00:00, 16.84it/s, train_loss=0.00535, val_loss=0.0053]Epoch 17:  60%|██████    | 12/20 [00:00<00:00, 16.99it/s, train_loss=0.00535, val_loss=0.0053]Epoch 17:  60%|██████    | 12/20 [00:00<00:00, 16.90it/s, train_loss=0.0053, val_loss=0.0053] Epoch 17:  65%|██████▌   | 13/20 [00:00<00:00, 17.07it/s, train_loss=0.0053, val_loss=0.0053]Epoch 17:  65%|██████▌   | 13/20 [00:00<00:00, 16.88it/s, train_loss=0.00521, val_loss=0.0053]Epoch 17:  70%|███████   | 14/20 [00:00<00:00, 17.11it/s, train_loss=0.00521, val_loss=0.0053]Epoch 17:  70%|███████   | 14/20 [00:00<00:00, 16.93it/s, train_loss=0.00492, val_loss=0.0053]Epoch 17:  75%|███████▌  | 15/20 [00:00<00:00, 17.18it/s, train_loss=0.00492, val_loss=0.0053]Epoch 17:  75%|███████▌  | 15/20 [00:00<00:00, 17.02it/s, train_loss=0.00541, val_loss=0.0053]Epoch 17:  80%|████████  | 16/20 [00:00<00:00, 17.25it/s, train_loss=0.00541, val_loss=0.0053]Epoch 17:  80%|████████  | 16/20 [00:00<00:00, 17.14it/s, train_loss=0.00545, val_loss=0.0053]Epoch 17:  85%|████████▌ | 17/20 [00:00<00:00, 17.33it/s, train_loss=0.00545, val_loss=0.0053]Epoch 17:  85%|████████▌ | 17/20 [00:00<00:00, 17.24it/s, train_loss=0.00551, val_loss=0.0053]Epoch 17:  90%|█████████ | 18/20 [00:01<00:00, 17.37it/s, train_loss=0.00551, val_loss=0.0053]Epoch 17:  90%|█████████ | 18/20 [00:01<00:00, 17.28it/s, train_loss=0.00536, val_loss=0.0053]Epoch 17:  95%|█████████▌| 19/20 [00:01<00:00, 17.45it/s, train_loss=0.00536, val_loss=0.0053]Epoch 17:  95%|█████████▌| 19/20 [00:01<00:00, 17.34it/s, train_loss=0.00549, val_loss=0.0053]Epoch 17: 100%|██████████| 20/20 [00:01<00:00, 17.42it/s, train_loss=0.00549, val_loss=0.0053]Epoch 17: 100%|██████████| 20/20 [00:01<00:00, 17.33it/s, train_loss=0.00551, val_loss=0.0053]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 52.72it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 49.34it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 54.29it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.88it/s][A
                                                                      [AEpoch 17: 100%|██████████| 20/20 [00:01<00:00, 16.23it/s, train_loss=0.00551, val_loss=0.00521]Epoch 17: 100%|██████████| 20/20 [00:01<00:00, 16.22it/s, train_loss=0.00551, val_loss=0.00521]Epoch 17:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00551, val_loss=0.00521]         Epoch 18:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00551, val_loss=0.00521]Epoch 18:   5%|▌         | 1/20 [00:00<00:00, 26.71it/s, train_loss=0.00551, val_loss=0.00521]Epoch 18:   5%|▌         | 1/20 [00:00<00:00, 22.23it/s, train_loss=0.0051, val_loss=0.00521] Epoch 18:  10%|█         | 2/20 [00:00<00:01, 17.26it/s, train_loss=0.0051, val_loss=0.00521]Epoch 18:  10%|█         | 2/20 [00:00<00:01, 16.22it/s, train_loss=0.0057, val_loss=0.00521]Epoch 18:  15%|█▌        | 3/20 [00:00<00:00, 17.66it/s, train_loss=0.0057, val_loss=0.00521]Epoch 18:  15%|█▌        | 3/20 [00:00<00:01, 16.78it/s, train_loss=0.00558, val_loss=0.00521]Epoch 18:  20%|██        | 4/20 [00:00<00:00, 16.11it/s, train_loss=0.00558, val_loss=0.00521]Epoch 18:  20%|██        | 4/20 [00:00<00:01, 15.72it/s, train_loss=0.00533, val_loss=0.00521]Epoch 18:  25%|██▌       | 5/20 [00:00<00:00, 15.92it/s, train_loss=0.00533, val_loss=0.00521]Epoch 18:  25%|██▌       | 5/20 [00:00<00:00, 15.81it/s, train_loss=0.00518, val_loss=0.00521]Epoch 18:  30%|███       | 6/20 [00:00<00:00, 15.52it/s, train_loss=0.00518, val_loss=0.00521]Epoch 18:  30%|███       | 6/20 [00:00<00:00, 15.26it/s, train_loss=0.00517, val_loss=0.00521]Epoch 18:  35%|███▌      | 7/20 [00:00<00:00, 15.85it/s, train_loss=0.00517, val_loss=0.00521]Epoch 18:  35%|███▌      | 7/20 [00:00<00:00, 15.63it/s, train_loss=0.00502, val_loss=0.00521]Epoch 18:  40%|████      | 8/20 [00:00<00:00, 16.03it/s, train_loss=0.00502, val_loss=0.00521]Epoch 18:  40%|████      | 8/20 [00:00<00:00, 15.79it/s, train_loss=0.005, val_loss=0.00521]  Epoch 18:  45%|████▌     | 9/20 [00:00<00:00, 15.82it/s, train_loss=0.005, val_loss=0.00521]Epoch 18:  45%|████▌     | 9/20 [00:00<00:00, 15.61it/s, train_loss=0.00518, val_loss=0.00521]Epoch 18:  50%|█████     | 10/20 [00:00<00:00, 15.90it/s, train_loss=0.00518, val_loss=0.00521]Epoch 18:  50%|█████     | 10/20 [00:00<00:00, 15.73it/s, train_loss=0.00503, val_loss=0.00521]Epoch 18:  55%|█████▌    | 11/20 [00:00<00:00, 16.15it/s, train_loss=0.00503, val_loss=0.00521]Epoch 18:  55%|█████▌    | 11/20 [00:00<00:00, 15.97it/s, train_loss=0.00504, val_loss=0.00521]Epoch 18:  60%|██████    | 12/20 [00:00<00:00, 16.29it/s, train_loss=0.00504, val_loss=0.00521]Epoch 18:  60%|██████    | 12/20 [00:00<00:00, 16.15it/s, train_loss=0.00526, val_loss=0.00521]Epoch 18:  65%|██████▌   | 13/20 [00:00<00:00, 16.37it/s, train_loss=0.00526, val_loss=0.00521]Epoch 18:  65%|██████▌   | 13/20 [00:00<00:00, 16.29it/s, train_loss=0.00504, val_loss=0.00521]Epoch 18:  70%|███████   | 14/20 [00:00<00:00, 16.18it/s, train_loss=0.00504, val_loss=0.00521]Epoch 18:  70%|███████   | 14/20 [00:00<00:00, 16.10it/s, train_loss=0.00515, val_loss=0.00521]Epoch 18:  75%|███████▌  | 15/20 [00:00<00:00, 16.46it/s, train_loss=0.00515, val_loss=0.00521]Epoch 18:  75%|███████▌  | 15/20 [00:00<00:00, 16.30it/s, train_loss=0.00534, val_loss=0.00521]Epoch 18:  80%|████████  | 16/20 [00:00<00:00, 16.39it/s, train_loss=0.00534, val_loss=0.00521]Epoch 18:  80%|████████  | 16/20 [00:00<00:00, 16.28it/s, train_loss=0.00506, val_loss=0.00521]Epoch 18:  85%|████████▌ | 17/20 [00:01<00:00, 16.70it/s, train_loss=0.00506, val_loss=0.00521]Epoch 18:  85%|████████▌ | 17/20 [00:01<00:00, 16.57it/s, train_loss=0.00518, val_loss=0.00521]Epoch 18:  90%|█████████ | 18/20 [00:01<00:00, 16.97it/s, train_loss=0.00518, val_loss=0.00521]Epoch 18:  90%|█████████ | 18/20 [00:01<00:00, 16.87it/s, train_loss=0.00492, val_loss=0.00521]Epoch 18:  95%|█████████▌| 19/20 [00:01<00:00, 16.78it/s, train_loss=0.00492, val_loss=0.00521]Epoch 18:  95%|█████████▌| 19/20 [00:01<00:00, 16.74it/s, train_loss=0.00486, val_loss=0.00521]Epoch 18: 100%|██████████| 20/20 [00:01<00:00, 16.90it/s, train_loss=0.00486, val_loss=0.00521]Epoch 18: 100%|██████████| 20/20 [00:01<00:00, 16.82it/s, train_loss=0.00486, val_loss=0.00521]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 36.86it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 33.96it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 34.55it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 37.05it/s][A
                                                                      [AEpoch 18: 100%|██████████| 20/20 [00:01<00:00, 15.25it/s, train_loss=0.00486, val_loss=0.00498]Epoch 18: 100%|██████████| 20/20 [00:01<00:00, 15.24it/s, train_loss=0.00486, val_loss=0.00498]Epoch 18:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00486, val_loss=0.00498]         Epoch 19:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00486, val_loss=0.00498]Epoch 19:   5%|▌         | 1/20 [00:00<00:01, 15.08it/s, train_loss=0.00486, val_loss=0.00498]Epoch 19:   5%|▌         | 1/20 [00:00<00:01, 14.69it/s, train_loss=0.00485, val_loss=0.00498]Epoch 19:  10%|█         | 2/20 [00:00<00:01, 16.46it/s, train_loss=0.00485, val_loss=0.00498]Epoch 19:  10%|█         | 2/20 [00:00<00:01, 15.49it/s, train_loss=0.00507, val_loss=0.00498]Epoch 19:  15%|█▌        | 3/20 [00:00<00:01, 16.51it/s, train_loss=0.00507, val_loss=0.00498]Epoch 19:  15%|█▌        | 3/20 [00:00<00:01, 15.72it/s, train_loss=0.00521, val_loss=0.00498]Epoch 19:  20%|██        | 4/20 [00:00<00:01, 15.32it/s, train_loss=0.00521, val_loss=0.00498]Epoch 19:  20%|██        | 4/20 [00:00<00:01, 14.85it/s, train_loss=0.00498, val_loss=0.00498]Epoch 19:  25%|██▌       | 5/20 [00:00<00:00, 15.23it/s, train_loss=0.00498, val_loss=0.00498]Epoch 19:  25%|██▌       | 5/20 [00:00<00:01, 14.76it/s, train_loss=0.00511, val_loss=0.00498]Epoch 19:  30%|███       | 6/20 [00:00<00:00, 15.53it/s, train_loss=0.00511, val_loss=0.00498]Epoch 19:  30%|███       | 6/20 [00:00<00:00, 15.24it/s, train_loss=0.00516, val_loss=0.00498]Epoch 19:  35%|███▌      | 7/20 [00:00<00:00, 15.60it/s, train_loss=0.00516, val_loss=0.00498]Epoch 19:  35%|███▌      | 7/20 [00:00<00:00, 15.37it/s, train_loss=0.00488, val_loss=0.00498]Epoch 19:  40%|████      | 8/20 [00:00<00:00, 15.81it/s, train_loss=0.00488, val_loss=0.00498]Epoch 19:  40%|████      | 8/20 [00:00<00:00, 15.60it/s, train_loss=0.00486, val_loss=0.00498]Epoch 19:  45%|████▌     | 9/20 [00:00<00:00, 15.42it/s, train_loss=0.00486, val_loss=0.00498]Epoch 19:  45%|████▌     | 9/20 [00:00<00:00, 15.19it/s, train_loss=0.00492, val_loss=0.00498]Epoch 19:  50%|█████     | 10/20 [00:00<00:00, 15.23it/s, train_loss=0.00492, val_loss=0.00498]Epoch 19:  50%|█████     | 10/20 [00:00<00:00, 15.00it/s, train_loss=0.00486, val_loss=0.00498]Epoch 19:  55%|█████▌    | 11/20 [00:00<00:00, 15.49it/s, train_loss=0.00486, val_loss=0.00498]Epoch 19:  55%|█████▌    | 11/20 [00:00<00:00, 15.34it/s, train_loss=0.00488, val_loss=0.00498]Epoch 19:  60%|██████    | 12/20 [00:00<00:00, 15.95it/s, train_loss=0.00488, val_loss=0.00498]Epoch 19:  60%|██████    | 12/20 [00:00<00:00, 15.81it/s, train_loss=0.00504, val_loss=0.00498]Epoch 19:  65%|██████▌   | 13/20 [00:00<00:00, 15.57it/s, train_loss=0.00504, val_loss=0.00498]Epoch 19:  65%|██████▌   | 13/20 [00:00<00:00, 15.43it/s, train_loss=0.00461, val_loss=0.00498]Epoch 19:  70%|███████   | 14/20 [00:00<00:00, 15.69it/s, train_loss=0.00461, val_loss=0.00498]Epoch 19:  70%|███████   | 14/20 [00:00<00:00, 15.54it/s, train_loss=0.00506, val_loss=0.00498]Epoch 19:  75%|███████▌  | 15/20 [00:00<00:00, 15.58it/s, train_loss=0.00506, val_loss=0.00498]Epoch 19:  75%|███████▌  | 15/20 [00:00<00:00, 15.44it/s, train_loss=0.00481, val_loss=0.00498]Epoch 19:  80%|████████  | 16/20 [00:01<00:00, 15.37it/s, train_loss=0.00481, val_loss=0.00498]Epoch 19:  80%|████████  | 16/20 [00:01<00:00, 15.29it/s, train_loss=0.00493, val_loss=0.00498]Epoch 19:  85%|████████▌ | 17/20 [00:01<00:00, 15.26it/s, train_loss=0.00493, val_loss=0.00498]Epoch 19:  85%|████████▌ | 17/20 [00:01<00:00, 15.18it/s, train_loss=0.00536, val_loss=0.00498]Epoch 19:  90%|█████████ | 18/20 [00:01<00:00, 15.43it/s, train_loss=0.00536, val_loss=0.00498]Epoch 19:  90%|█████████ | 18/20 [00:01<00:00, 15.34it/s, train_loss=0.00476, val_loss=0.00498]Epoch 19:  95%|█████████▌| 19/20 [00:01<00:00, 15.50it/s, train_loss=0.00476, val_loss=0.00498]Epoch 19:  95%|█████████▌| 19/20 [00:01<00:00, 15.42it/s, train_loss=0.00533, val_loss=0.00498]Epoch 19: 100%|██████████| 20/20 [00:01<00:00, 15.50it/s, train_loss=0.00533, val_loss=0.00498]Epoch 19: 100%|██████████| 20/20 [00:01<00:00, 15.43it/s, train_loss=0.00482, val_loss=0.00498]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 45.19it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 45.13it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 44.45it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.86it/s][A
                                                                      [AEpoch 19: 100%|██████████| 20/20 [00:01<00:00, 14.28it/s, train_loss=0.00482, val_loss=0.00486]Epoch 19: 100%|██████████| 20/20 [00:01<00:00, 14.27it/s, train_loss=0.00482, val_loss=0.00486]Epoch 19:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00482, val_loss=0.00486]         Epoch 20:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00482, val_loss=0.00486]Epoch 20:   5%|▌         | 1/20 [00:00<00:00, 23.31it/s, train_loss=0.00482, val_loss=0.00486]Epoch 20:   5%|▌         | 1/20 [00:00<00:00, 20.62it/s, train_loss=0.0048, val_loss=0.00486] Epoch 20:  10%|█         | 2/20 [00:00<00:00, 19.87it/s, train_loss=0.0048, val_loss=0.00486]Epoch 20:  10%|█         | 2/20 [00:00<00:00, 19.41it/s, train_loss=0.00459, val_loss=0.00486]Epoch 20:  15%|█▌        | 3/20 [00:00<00:00, 17.47it/s, train_loss=0.00459, val_loss=0.00486]Epoch 20:  15%|█▌        | 3/20 [00:00<00:01, 16.95it/s, train_loss=0.00466, val_loss=0.00486]Epoch 20:  20%|██        | 4/20 [00:00<00:00, 16.74it/s, train_loss=0.00466, val_loss=0.00486]Epoch 20:  20%|██        | 4/20 [00:00<00:00, 16.32it/s, train_loss=0.00481, val_loss=0.00486]Epoch 20:  25%|██▌       | 5/20 [00:00<00:00, 17.40it/s, train_loss=0.00481, val_loss=0.00486]Epoch 20:  25%|██▌       | 5/20 [00:00<00:00, 16.97it/s, train_loss=0.00512, val_loss=0.00486]Epoch 20:  30%|███       | 6/20 [00:00<00:00, 18.10it/s, train_loss=0.00512, val_loss=0.00486]Epoch 20:  30%|███       | 6/20 [00:00<00:00, 17.74it/s, train_loss=0.00494, val_loss=0.00486]Epoch 20:  35%|███▌      | 7/20 [00:00<00:00, 17.07it/s, train_loss=0.00494, val_loss=0.00486]Epoch 20:  35%|███▌      | 7/20 [00:00<00:00, 16.96it/s, train_loss=0.00495, val_loss=0.00486]Epoch 20:  40%|████      | 8/20 [00:00<00:00, 17.35it/s, train_loss=0.00495, val_loss=0.00486]Epoch 20:  40%|████      | 8/20 [00:00<00:00, 17.10it/s, train_loss=0.00491, val_loss=0.00486]Epoch 20:  45%|████▌     | 9/20 [00:00<00:00, 16.83it/s, train_loss=0.00491, val_loss=0.00486]Epoch 20:  45%|████▌     | 9/20 [00:00<00:00, 16.76it/s, train_loss=0.00473, val_loss=0.00486]Epoch 20:  50%|█████     | 10/20 [00:00<00:00, 16.99it/s, train_loss=0.00473, val_loss=0.00486]Epoch 20:  50%|█████     | 10/20 [00:00<00:00, 16.74it/s, train_loss=0.00523, val_loss=0.00486]Epoch 20:  55%|█████▌    | 11/20 [00:00<00:00, 16.24it/s, train_loss=0.00523, val_loss=0.00486]Epoch 20:  55%|█████▌    | 11/20 [00:00<00:00, 16.21it/s, train_loss=0.0048, val_loss=0.00486] Epoch 20:  60%|██████    | 12/20 [00:00<00:00, 16.38it/s, train_loss=0.0048, val_loss=0.00486]Epoch 20:  60%|██████    | 12/20 [00:00<00:00, 16.29it/s, train_loss=0.00442, val_loss=0.00486]Epoch 20:  65%|██████▌   | 13/20 [00:00<00:00, 16.64it/s, train_loss=0.00442, val_loss=0.00486]Epoch 20:  65%|██████▌   | 13/20 [00:00<00:00, 16.49it/s, train_loss=0.0046, val_loss=0.00486] Epoch 20:  70%|███████   | 14/20 [00:00<00:00, 16.62it/s, train_loss=0.0046, val_loss=0.00486]Epoch 20:  70%|███████   | 14/20 [00:00<00:00, 16.48it/s, train_loss=0.00497, val_loss=0.00486]Epoch 20:  75%|███████▌  | 15/20 [00:00<00:00, 16.52it/s, train_loss=0.00497, val_loss=0.00486]Epoch 20:  75%|███████▌  | 15/20 [00:00<00:00, 16.41it/s, train_loss=0.00473, val_loss=0.00486]Epoch 20:  80%|████████  | 16/20 [00:00<00:00, 16.47it/s, train_loss=0.00473, val_loss=0.00486]Epoch 20:  80%|████████  | 16/20 [00:00<00:00, 16.37it/s, train_loss=0.00468, val_loss=0.00486]Epoch 20:  85%|████████▌ | 17/20 [00:01<00:00, 16.57it/s, train_loss=0.00468, val_loss=0.00486]Epoch 20:  85%|████████▌ | 17/20 [00:01<00:00, 16.43it/s, train_loss=0.00515, val_loss=0.00486]Epoch 20:  90%|█████████ | 18/20 [00:01<00:00, 16.58it/s, train_loss=0.00515, val_loss=0.00486]Epoch 20:  90%|█████████ | 18/20 [00:01<00:00, 16.52it/s, train_loss=0.00447, val_loss=0.00486]Epoch 20:  95%|█████████▌| 19/20 [00:01<00:00, 16.61it/s, train_loss=0.00447, val_loss=0.00486]Epoch 20:  95%|█████████▌| 19/20 [00:01<00:00, 16.53it/s, train_loss=0.00511, val_loss=0.00486]Epoch 20: 100%|██████████| 20/20 [00:01<00:00, 16.72it/s, train_loss=0.00511, val_loss=0.00486]Epoch 20: 100%|██████████| 20/20 [00:01<00:00, 16.67it/s, train_loss=0.00505, val_loss=0.00486]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 49.00it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 46.18it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 49.79it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.06it/s][A
                                                                      [AEpoch 20: 100%|██████████| 20/20 [00:01<00:00, 15.44it/s, train_loss=0.00505, val_loss=0.0048] Epoch 20: 100%|██████████| 20/20 [00:01<00:00, 15.43it/s, train_loss=0.00505, val_loss=0.0048]Epoch 20:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00505, val_loss=0.0048]         Epoch 21:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00505, val_loss=0.0048]Epoch 21:   5%|▌         | 1/20 [00:00<00:00, 29.10it/s, train_loss=0.00505, val_loss=0.0048]Epoch 21:   5%|▌         | 1/20 [00:00<00:00, 23.40it/s, train_loss=0.00449, val_loss=0.0048]Epoch 21:  10%|█         | 2/20 [00:00<00:01, 17.84it/s, train_loss=0.00449, val_loss=0.0048]Epoch 21:  10%|█         | 2/20 [00:00<00:01, 16.75it/s, train_loss=0.00461, val_loss=0.0048]Epoch 21:  15%|█▌        | 3/20 [00:00<00:00, 18.05it/s, train_loss=0.00461, val_loss=0.0048]Epoch 21:  15%|█▌        | 3/20 [00:00<00:00, 17.15it/s, train_loss=0.00522, val_loss=0.0048]Epoch 21:  20%|██        | 4/20 [00:00<00:00, 16.70it/s, train_loss=0.00522, val_loss=0.0048]Epoch 21:  20%|██        | 4/20 [00:00<00:00, 16.15it/s, train_loss=0.00466, val_loss=0.0048]Epoch 21:  25%|██▌       | 5/20 [00:00<00:00, 16.83it/s, train_loss=0.00466, val_loss=0.0048]Epoch 21:  25%|██▌       | 5/20 [00:00<00:00, 16.42it/s, train_loss=0.00471, val_loss=0.0048]Epoch 21:  30%|███       | 6/20 [00:00<00:00, 16.21it/s, train_loss=0.00471, val_loss=0.0048]Epoch 21:  30%|███       | 6/20 [00:00<00:00, 15.85it/s, train_loss=0.00465, val_loss=0.0048]Epoch 21:  35%|███▌      | 7/20 [00:00<00:00, 16.06it/s, train_loss=0.00465, val_loss=0.0048]Epoch 21:  35%|███▌      | 7/20 [00:00<00:00, 15.81it/s, train_loss=0.00486, val_loss=0.0048]Epoch 21:  40%|████      | 8/20 [00:00<00:00, 16.38it/s, train_loss=0.00486, val_loss=0.0048]Epoch 21:  40%|████      | 8/20 [00:00<00:00, 16.14it/s, train_loss=0.00488, val_loss=0.0048]Epoch 21:  45%|████▌     | 9/20 [00:00<00:00, 16.39it/s, train_loss=0.00488, val_loss=0.0048]Epoch 21:  45%|████▌     | 9/20 [00:00<00:00, 16.14it/s, train_loss=0.00492, val_loss=0.0048]Epoch 21:  50%|█████     | 10/20 [00:00<00:00, 16.38it/s, train_loss=0.00492, val_loss=0.0048]Epoch 21:  50%|█████     | 10/20 [00:00<00:00, 16.19it/s, train_loss=0.00491, val_loss=0.0048]Epoch 21:  55%|█████▌    | 11/20 [00:00<00:00, 16.47it/s, train_loss=0.00491, val_loss=0.0048]Epoch 21:  55%|█████▌    | 11/20 [00:00<00:00, 16.26it/s, train_loss=0.00466, val_loss=0.0048]Epoch 21:  60%|██████    | 12/20 [00:00<00:00, 16.60it/s, train_loss=0.00466, val_loss=0.0048]Epoch 21:  60%|██████    | 12/20 [00:00<00:00, 16.47it/s, train_loss=0.00451, val_loss=0.0048]Epoch 21:  65%|██████▌   | 13/20 [00:00<00:00, 16.80it/s, train_loss=0.00451, val_loss=0.0048]Epoch 21:  65%|██████▌   | 13/20 [00:00<00:00, 16.68it/s, train_loss=0.0046, val_loss=0.0048] Epoch 21:  70%|███████   | 14/20 [00:00<00:00, 16.87it/s, train_loss=0.0046, val_loss=0.0048]Epoch 21:  70%|███████   | 14/20 [00:00<00:00, 16.73it/s, train_loss=0.00472, val_loss=0.0048]Epoch 21:  75%|███████▌  | 15/20 [00:00<00:00, 16.67it/s, train_loss=0.00472, val_loss=0.0048]Epoch 21:  75%|███████▌  | 15/20 [00:00<00:00, 16.56it/s, train_loss=0.00458, val_loss=0.0048]Epoch 21:  80%|████████  | 16/20 [00:00<00:00, 16.61it/s, train_loss=0.00458, val_loss=0.0048]Epoch 21:  80%|████████  | 16/20 [00:00<00:00, 16.50it/s, train_loss=0.00488, val_loss=0.0048]Epoch 21:  85%|████████▌ | 17/20 [00:01<00:00, 16.71it/s, train_loss=0.00488, val_loss=0.0048]Epoch 21:  85%|████████▌ | 17/20 [00:01<00:00, 16.58it/s, train_loss=0.00464, val_loss=0.0048]Epoch 21:  90%|█████████ | 18/20 [00:01<00:00, 16.84it/s, train_loss=0.00464, val_loss=0.0048]Epoch 21:  90%|█████████ | 18/20 [00:01<00:00, 16.81it/s, train_loss=0.00438, val_loss=0.0048]Epoch 21:  95%|█████████▌| 19/20 [00:01<00:00, 16.75it/s, train_loss=0.00438, val_loss=0.0048]Epoch 21:  95%|█████████▌| 19/20 [00:01<00:00, 16.66it/s, train_loss=0.00477, val_loss=0.0048]Epoch 21: 100%|██████████| 20/20 [00:01<00:00, 16.68it/s, train_loss=0.00477, val_loss=0.0048]Epoch 21: 100%|██████████| 20/20 [00:01<00:00, 16.67it/s, train_loss=0.0048, val_loss=0.0048] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 36.98it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 33.76it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 34.63it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 37.38it/s][A
                                                                      [AEpoch 21: 100%|██████████| 20/20 [00:01<00:00, 15.21it/s, train_loss=0.0048, val_loss=0.00474]Epoch 21: 100%|██████████| 20/20 [00:01<00:00, 15.19it/s, train_loss=0.0048, val_loss=0.00474]Epoch 21:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0048, val_loss=0.00474]         Epoch 22:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0048, val_loss=0.00474]Epoch 22:   5%|▌         | 1/20 [00:00<00:01, 14.34it/s, train_loss=0.0048, val_loss=0.00474]Epoch 22:   5%|▌         | 1/20 [00:00<00:01, 13.24it/s, train_loss=0.00462, val_loss=0.00474]Epoch 22:  10%|█         | 2/20 [00:00<00:01, 15.47it/s, train_loss=0.00462, val_loss=0.00474]Epoch 22:  10%|█         | 2/20 [00:00<00:01, 15.19it/s, train_loss=0.00476, val_loss=0.00474]Epoch 22:  15%|█▌        | 3/20 [00:00<00:01, 16.97it/s, train_loss=0.00476, val_loss=0.00474]Epoch 22:  15%|█▌        | 3/20 [00:00<00:01, 16.38it/s, train_loss=0.00449, val_loss=0.00474]Epoch 22:  20%|██        | 4/20 [00:00<00:00, 16.75it/s, train_loss=0.00449, val_loss=0.00474]Epoch 22:  20%|██        | 4/20 [00:00<00:00, 16.22it/s, train_loss=0.00432, val_loss=0.00474]Epoch 22:  25%|██▌       | 5/20 [00:00<00:00, 16.30it/s, train_loss=0.00432, val_loss=0.00474]Epoch 22:  25%|██▌       | 5/20 [00:00<00:00, 16.00it/s, train_loss=0.00461, val_loss=0.00474]Epoch 22:  30%|███       | 6/20 [00:00<00:00, 16.91it/s, train_loss=0.00461, val_loss=0.00474]Epoch 22:  30%|███       | 6/20 [00:00<00:00, 16.62it/s, train_loss=0.0045, val_loss=0.00474] Epoch 22:  35%|███▌      | 7/20 [00:00<00:00, 17.11it/s, train_loss=0.0045, val_loss=0.00474]Epoch 22:  35%|███▌      | 7/20 [00:00<00:00, 16.87it/s, train_loss=0.00455, val_loss=0.00474]Epoch 22:  40%|████      | 8/20 [00:00<00:00, 17.40it/s, train_loss=0.00455, val_loss=0.00474]Epoch 22:  40%|████      | 8/20 [00:00<00:00, 17.13it/s, train_loss=0.00454, val_loss=0.00474]Epoch 22:  45%|████▌     | 9/20 [00:00<00:00, 16.71it/s, train_loss=0.00454, val_loss=0.00474]Epoch 22:  45%|████▌     | 9/20 [00:00<00:00, 16.63it/s, train_loss=0.00476, val_loss=0.00474]Epoch 22:  50%|█████     | 10/20 [00:00<00:00, 17.25it/s, train_loss=0.00476, val_loss=0.00474]Epoch 22:  50%|█████     | 10/20 [00:00<00:00, 16.95it/s, train_loss=0.00467, val_loss=0.00474]Epoch 22:  55%|█████▌    | 11/20 [00:00<00:00, 16.89it/s, train_loss=0.00467, val_loss=0.00474]Epoch 22:  55%|█████▌    | 11/20 [00:00<00:00, 16.66it/s, train_loss=0.00454, val_loss=0.00474]Epoch 22:  60%|██████    | 12/20 [00:00<00:00, 17.07it/s, train_loss=0.00454, val_loss=0.00474]Epoch 22:  60%|██████    | 12/20 [00:00<00:00, 16.90it/s, train_loss=0.00471, val_loss=0.00474]Epoch 22:  65%|██████▌   | 13/20 [00:00<00:00, 17.50it/s, train_loss=0.00471, val_loss=0.00474]Epoch 22:  65%|██████▌   | 13/20 [00:00<00:00, 17.33it/s, train_loss=0.00476, val_loss=0.00474]Epoch 22:  70%|███████   | 14/20 [00:00<00:00, 16.86it/s, train_loss=0.00476, val_loss=0.00474]Epoch 22:  70%|███████   | 14/20 [00:00<00:00, 16.71it/s, train_loss=0.00464, val_loss=0.00474]Epoch 22:  75%|███████▌  | 15/20 [00:00<00:00, 16.88it/s, train_loss=0.00464, val_loss=0.00474]Epoch 22:  75%|███████▌  | 15/20 [00:00<00:00, 16.76it/s, train_loss=0.00458, val_loss=0.00474]Epoch 22:  80%|████████  | 16/20 [00:00<00:00, 16.69it/s, train_loss=0.00458, val_loss=0.00474]Epoch 22:  80%|████████  | 16/20 [00:00<00:00, 16.53it/s, train_loss=0.00448, val_loss=0.00474]Epoch 22:  85%|████████▌ | 17/20 [00:01<00:00, 16.61it/s, train_loss=0.00448, val_loss=0.00474]Epoch 22:  85%|████████▌ | 17/20 [00:01<00:00, 16.52it/s, train_loss=0.00453, val_loss=0.00474]Epoch 22:  90%|█████████ | 18/20 [00:01<00:00, 16.53it/s, train_loss=0.00453, val_loss=0.00474]Epoch 22:  90%|█████████ | 18/20 [00:01<00:00, 16.45it/s, train_loss=0.00459, val_loss=0.00474]Epoch 22:  95%|█████████▌| 19/20 [00:01<00:00, 16.53it/s, train_loss=0.00459, val_loss=0.00474]Epoch 22:  95%|█████████▌| 19/20 [00:01<00:00, 16.45it/s, train_loss=0.00441, val_loss=0.00474]Epoch 22: 100%|██████████| 20/20 [00:01<00:00, 16.64it/s, train_loss=0.00441, val_loss=0.00474]Epoch 22: 100%|██████████| 20/20 [00:01<00:00, 16.52it/s, train_loss=0.00465, val_loss=0.00474]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 36.07it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 34.53it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 37.52it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 37.85it/s][A
                                                                      [AEpoch 22: 100%|██████████| 20/20 [00:01<00:00, 14.97it/s, train_loss=0.00465, val_loss=0.00465]Epoch 22: 100%|██████████| 20/20 [00:01<00:00, 14.96it/s, train_loss=0.00465, val_loss=0.00465]Epoch 22:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00465, val_loss=0.00465]         Epoch 23:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00465, val_loss=0.00465]Epoch 23:   5%|▌         | 1/20 [00:00<00:00, 21.09it/s, train_loss=0.00465, val_loss=0.00465]Epoch 23:   5%|▌         | 1/20 [00:00<00:01, 17.69it/s, train_loss=0.00483, val_loss=0.00465]Epoch 23:  10%|█         | 2/20 [00:00<00:00, 19.81it/s, train_loss=0.00483, val_loss=0.00465]Epoch 23:  10%|█         | 2/20 [00:00<00:00, 18.28it/s, train_loss=0.00442, val_loss=0.00465]Epoch 23:  15%|█▌        | 3/20 [00:00<00:00, 18.11it/s, train_loss=0.00442, val_loss=0.00465]Epoch 23:  15%|█▌        | 3/20 [00:00<00:00, 17.52it/s, train_loss=0.00458, val_loss=0.00465]Epoch 23:  20%|██        | 4/20 [00:00<00:00, 16.67it/s, train_loss=0.00458, val_loss=0.00465]Epoch 23:  20%|██        | 4/20 [00:00<00:00, 16.23it/s, train_loss=0.00455, val_loss=0.00465]Epoch 23:  25%|██▌       | 5/20 [00:00<00:00, 16.29it/s, train_loss=0.00455, val_loss=0.00465]Epoch 23:  25%|██▌       | 5/20 [00:00<00:00, 15.96it/s, train_loss=0.00482, val_loss=0.00465]Epoch 23:  30%|███       | 6/20 [00:00<00:00, 16.84it/s, train_loss=0.00482, val_loss=0.00465]Epoch 23:  30%|███       | 6/20 [00:00<00:00, 16.49it/s, train_loss=0.00424, val_loss=0.00465]Epoch 23:  35%|███▌      | 7/20 [00:00<00:00, 17.58it/s, train_loss=0.00424, val_loss=0.00465]Epoch 23:  35%|███▌      | 7/20 [00:00<00:00, 17.25it/s, train_loss=0.00467, val_loss=0.00465]Epoch 23:  40%|████      | 8/20 [00:00<00:00, 17.19it/s, train_loss=0.00467, val_loss=0.00465]Epoch 23:  40%|████      | 8/20 [00:00<00:00, 17.01it/s, train_loss=0.00405, val_loss=0.00465]Epoch 23:  45%|████▌     | 9/20 [00:00<00:00, 17.22it/s, train_loss=0.00405, val_loss=0.00465]Epoch 23:  45%|████▌     | 9/20 [00:00<00:00, 17.01it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  50%|█████     | 10/20 [00:00<00:00, 17.13it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  50%|█████     | 10/20 [00:00<00:00, 16.94it/s, train_loss=0.00445, val_loss=0.00465]Epoch 23:  55%|█████▌    | 11/20 [00:00<00:00, 16.87it/s, train_loss=0.00445, val_loss=0.00465]Epoch 23:  55%|█████▌    | 11/20 [00:00<00:00, 16.72it/s, train_loss=0.00463, val_loss=0.00465]Epoch 23:  60%|██████    | 12/20 [00:00<00:00, 16.92it/s, train_loss=0.00463, val_loss=0.00465]Epoch 23:  60%|██████    | 12/20 [00:00<00:00, 16.79it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  65%|██████▌   | 13/20 [00:00<00:00, 16.76it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  65%|██████▌   | 13/20 [00:00<00:00, 16.64it/s, train_loss=0.00455, val_loss=0.00465]Epoch 23:  70%|███████   | 14/20 [00:00<00:00, 16.94it/s, train_loss=0.00455, val_loss=0.00465]Epoch 23:  70%|███████   | 14/20 [00:00<00:00, 16.83it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  75%|███████▌  | 15/20 [00:00<00:00, 16.95it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  75%|███████▌  | 15/20 [00:00<00:00, 16.80it/s, train_loss=0.00451, val_loss=0.00465]Epoch 23:  80%|████████  | 16/20 [00:00<00:00, 16.81it/s, train_loss=0.00451, val_loss=0.00465]Epoch 23:  80%|████████  | 16/20 [00:00<00:00, 16.67it/s, train_loss=0.00463, val_loss=0.00465]Epoch 23:  85%|████████▌ | 17/20 [00:01<00:00, 16.77it/s, train_loss=0.00463, val_loss=0.00465]Epoch 23:  85%|████████▌ | 17/20 [00:01<00:00, 16.62it/s, train_loss=0.00443, val_loss=0.00465]Epoch 23:  90%|█████████ | 18/20 [00:01<00:00, 16.83it/s, train_loss=0.00443, val_loss=0.00465]Epoch 23:  90%|█████████ | 18/20 [00:01<00:00, 16.69it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  95%|█████████▌| 19/20 [00:01<00:00, 16.91it/s, train_loss=0.00439, val_loss=0.00465]Epoch 23:  95%|█████████▌| 19/20 [00:01<00:00, 16.80it/s, train_loss=0.00467, val_loss=0.00465]Epoch 23: 100%|██████████| 20/20 [00:01<00:00, 16.92it/s, train_loss=0.00467, val_loss=0.00465]Epoch 23: 100%|██████████| 20/20 [00:01<00:00, 16.87it/s, train_loss=0.00456, val_loss=0.00465]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 33.83it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 35.13it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 38.39it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 40.60it/s][A
                                                                      [AEpoch 23: 100%|██████████| 20/20 [00:01<00:00, 15.35it/s, train_loss=0.00456, val_loss=0.00459]Epoch 23: 100%|██████████| 20/20 [00:01<00:00, 15.31it/s, train_loss=0.00456, val_loss=0.00459]Epoch 23:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00456, val_loss=0.00459]         Epoch 24:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00456, val_loss=0.00459]Epoch 24:   5%|▌         | 1/20 [00:00<00:00, 28.91it/s, train_loss=0.00456, val_loss=0.00459]Epoch 24:   5%|▌         | 1/20 [00:00<00:00, 22.82it/s, train_loss=0.00455, val_loss=0.00459]Epoch 24:  10%|█         | 2/20 [00:00<00:00, 23.44it/s, train_loss=0.00455, val_loss=0.00459]Epoch 24:  10%|█         | 2/20 [00:00<00:00, 21.84it/s, train_loss=0.00474, val_loss=0.00459]Epoch 24:  15%|█▌        | 3/20 [00:00<00:00, 23.43it/s, train_loss=0.00474, val_loss=0.00459]Epoch 24:  15%|█▌        | 3/20 [00:00<00:00, 22.14it/s, train_loss=0.00416, val_loss=0.00459]Epoch 24:  20%|██        | 4/20 [00:00<00:00, 19.11it/s, train_loss=0.00416, val_loss=0.00459]Epoch 24:  20%|██        | 4/20 [00:00<00:00, 18.37it/s, train_loss=0.0043, val_loss=0.00459] Epoch 24:  25%|██▌       | 5/20 [00:00<00:00, 18.78it/s, train_loss=0.0043, val_loss=0.00459]Epoch 24:  25%|██▌       | 5/20 [00:00<00:00, 18.35it/s, train_loss=0.0041, val_loss=0.00459]Epoch 24:  30%|███       | 6/20 [00:00<00:00, 17.85it/s, train_loss=0.0041, val_loss=0.00459]Epoch 24:  30%|███       | 6/20 [00:00<00:00, 17.55it/s, train_loss=0.00434, val_loss=0.00459]Epoch 24:  35%|███▌      | 7/20 [00:00<00:00, 17.63it/s, train_loss=0.00434, val_loss=0.00459]Epoch 24:  35%|███▌      | 7/20 [00:00<00:00, 17.33it/s, train_loss=0.00445, val_loss=0.00459]Epoch 24:  40%|████      | 8/20 [00:00<00:00, 17.09it/s, train_loss=0.00445, val_loss=0.00459]Epoch 24:  40%|████      | 8/20 [00:00<00:00, 16.88it/s, train_loss=0.00438, val_loss=0.00459]Epoch 24:  45%|████▌     | 9/20 [00:00<00:00, 17.11it/s, train_loss=0.00438, val_loss=0.00459]Epoch 24:  45%|████▌     | 9/20 [00:00<00:00, 16.87it/s, train_loss=0.00433, val_loss=0.00459]Epoch 24:  50%|█████     | 10/20 [00:00<00:00, 17.44it/s, train_loss=0.00433, val_loss=0.00459]Epoch 24:  50%|█████     | 10/20 [00:00<00:00, 17.23it/s, train_loss=0.00443, val_loss=0.00459]Epoch 24:  55%|█████▌    | 11/20 [00:00<00:00, 17.13it/s, train_loss=0.00443, val_loss=0.00459]Epoch 24:  55%|█████▌    | 11/20 [00:00<00:00, 16.96it/s, train_loss=0.00432, val_loss=0.00459]Epoch 24:  60%|██████    | 12/20 [00:00<00:00, 17.11it/s, train_loss=0.00432, val_loss=0.00459]Epoch 24:  60%|██████    | 12/20 [00:00<00:00, 16.96it/s, train_loss=0.00457, val_loss=0.00459]Epoch 24:  65%|██████▌   | 13/20 [00:00<00:00, 17.34it/s, train_loss=0.00457, val_loss=0.00459]Epoch 24:  65%|██████▌   | 13/20 [00:00<00:00, 17.18it/s, train_loss=0.00446, val_loss=0.00459]Epoch 24:  70%|███████   | 14/20 [00:00<00:00, 17.38it/s, train_loss=0.00446, val_loss=0.00459]Epoch 24:  70%|███████   | 14/20 [00:00<00:00, 17.25it/s, train_loss=0.00445, val_loss=0.00459]Epoch 24:  75%|███████▌  | 15/20 [00:00<00:00, 17.52it/s, train_loss=0.00445, val_loss=0.00459]Epoch 24:  75%|███████▌  | 15/20 [00:00<00:00, 17.41it/s, train_loss=0.00468, val_loss=0.00459]Epoch 24:  80%|████████  | 16/20 [00:00<00:00, 17.41it/s, train_loss=0.00468, val_loss=0.00459]Epoch 24:  80%|████████  | 16/20 [00:00<00:00, 17.31it/s, train_loss=0.00443, val_loss=0.00459]Epoch 24:  85%|████████▌ | 17/20 [00:00<00:00, 17.17it/s, train_loss=0.00443, val_loss=0.00459]Epoch 24:  85%|████████▌ | 17/20 [00:00<00:00, 17.07it/s, train_loss=0.0043, val_loss=0.00459] Epoch 24:  90%|█████████ | 18/20 [00:01<00:00, 17.01it/s, train_loss=0.0043, val_loss=0.00459]Epoch 24:  90%|█████████ | 18/20 [00:01<00:00, 16.88it/s, train_loss=0.00445, val_loss=0.00459]Epoch 24:  95%|█████████▌| 19/20 [00:01<00:00, 17.10it/s, train_loss=0.00445, val_loss=0.00459]Epoch 24:  95%|█████████▌| 19/20 [00:01<00:00, 16.99it/s, train_loss=0.0042, val_loss=0.00459] Epoch 24: 100%|██████████| 20/20 [00:01<00:00, 17.30it/s, train_loss=0.0042, val_loss=0.00459]Epoch 24: 100%|██████████| 20/20 [00:01<00:00, 17.23it/s, train_loss=0.00423, val_loss=0.00459]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 23.86it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 29.37it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 31.89it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 34.90it/s][A
                                                                      [AEpoch 24: 100%|██████████| 20/20 [00:01<00:00, 15.58it/s, train_loss=0.00423, val_loss=0.00452]Epoch 24: 100%|██████████| 20/20 [00:01<00:00, 15.57it/s, train_loss=0.00423, val_loss=0.00452]Epoch 24:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00423, val_loss=0.00452]         Epoch 25:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00423, val_loss=0.00452]Epoch 25:   5%|▌         | 1/20 [00:00<00:01, 16.25it/s, train_loss=0.00423, val_loss=0.00452]Epoch 25:   5%|▌         | 1/20 [00:00<00:01, 15.22it/s, train_loss=0.00461, val_loss=0.00452]Epoch 25:  10%|█         | 2/20 [00:00<00:00, 18.17it/s, train_loss=0.00461, val_loss=0.00452]Epoch 25:  10%|█         | 2/20 [00:00<00:01, 16.52it/s, train_loss=0.00447, val_loss=0.00452]Epoch 25:  15%|█▌        | 3/20 [00:00<00:01, 16.17it/s, train_loss=0.00447, val_loss=0.00452]Epoch 25:  15%|█▌        | 3/20 [00:00<00:01, 15.60it/s, train_loss=0.00431, val_loss=0.00452]Epoch 25:  20%|██        | 4/20 [00:00<00:00, 16.31it/s, train_loss=0.00431, val_loss=0.00452]Epoch 25:  20%|██        | 4/20 [00:00<00:01, 15.87it/s, train_loss=0.00445, val_loss=0.00452]Epoch 25:  25%|██▌       | 5/20 [00:00<00:00, 16.81it/s, train_loss=0.00445, val_loss=0.00452]Epoch 25:  25%|██▌       | 5/20 [00:00<00:00, 16.46it/s, train_loss=0.00449, val_loss=0.00452]Epoch 25:  30%|███       | 6/20 [00:00<00:00, 17.17it/s, train_loss=0.00449, val_loss=0.00452]Epoch 25:  30%|███       | 6/20 [00:00<00:00, 16.91it/s, train_loss=0.0042, val_loss=0.00452] Epoch 25:  35%|███▌      | 7/20 [00:00<00:00, 16.99it/s, train_loss=0.0042, val_loss=0.00452]Epoch 25:  35%|███▌      | 7/20 [00:00<00:00, 16.86it/s, train_loss=0.00419, val_loss=0.00452]Epoch 25:  40%|████      | 8/20 [00:00<00:00, 17.53it/s, train_loss=0.00419, val_loss=0.00452]Epoch 25:  40%|████      | 8/20 [00:00<00:00, 17.30it/s, train_loss=0.00433, val_loss=0.00452]Epoch 25:  45%|████▌     | 9/20 [00:00<00:00, 17.60it/s, train_loss=0.00433, val_loss=0.00452]Epoch 25:  45%|████▌     | 9/20 [00:00<00:00, 17.23it/s, train_loss=0.00423, val_loss=0.00452]Epoch 25:  50%|█████     | 10/20 [00:00<00:00, 17.52it/s, train_loss=0.00423, val_loss=0.00452]Epoch 25:  50%|█████     | 10/20 [00:00<00:00, 17.35it/s, train_loss=0.0043, val_loss=0.00452] Epoch 25:  55%|█████▌    | 11/20 [00:00<00:00, 17.17it/s, train_loss=0.0043, val_loss=0.00452]Epoch 25:  55%|█████▌    | 11/20 [00:00<00:00, 17.02it/s, train_loss=0.00455, val_loss=0.00452]Epoch 25:  60%|██████    | 12/20 [00:00<00:00, 16.94it/s, train_loss=0.00455, val_loss=0.00452]Epoch 25:  60%|██████    | 12/20 [00:00<00:00, 16.78it/s, train_loss=0.00421, val_loss=0.00452]Epoch 25:  65%|██████▌   | 13/20 [00:00<00:00, 16.60it/s, train_loss=0.00421, val_loss=0.00452]Epoch 25:  65%|██████▌   | 13/20 [00:00<00:00, 16.46it/s, train_loss=0.00413, val_loss=0.00452]Epoch 25:  70%|███████   | 14/20 [00:00<00:00, 16.90it/s, train_loss=0.00413, val_loss=0.00452]Epoch 25:  70%|███████   | 14/20 [00:00<00:00, 16.75it/s, train_loss=0.0043, val_loss=0.00452] Epoch 25:  75%|███████▌  | 15/20 [00:00<00:00, 17.23it/s, train_loss=0.0043, val_loss=0.00452]Epoch 25:  75%|███████▌  | 15/20 [00:00<00:00, 17.07it/s, train_loss=0.00416, val_loss=0.00452]Epoch 25:  80%|████████  | 16/20 [00:00<00:00, 16.95it/s, train_loss=0.00416, val_loss=0.00452]Epoch 25:  80%|████████  | 16/20 [00:00<00:00, 16.83it/s, train_loss=0.00449, val_loss=0.00452]Epoch 25:  85%|████████▌ | 17/20 [00:00<00:00, 17.08it/s, train_loss=0.00449, val_loss=0.00452]Epoch 25:  85%|████████▌ | 17/20 [00:01<00:00, 16.96it/s, train_loss=0.00453, val_loss=0.00452]Epoch 25:  90%|█████████ | 18/20 [00:01<00:00, 16.94it/s, train_loss=0.00453, val_loss=0.00452]Epoch 25:  90%|█████████ | 18/20 [00:01<00:00, 16.83it/s, train_loss=0.00431, val_loss=0.00452]Epoch 25:  95%|█████████▌| 19/20 [00:01<00:00, 16.98it/s, train_loss=0.00431, val_loss=0.00452]Epoch 25:  95%|█████████▌| 19/20 [00:01<00:00, 16.87it/s, train_loss=0.00416, val_loss=0.00452]Epoch 25: 100%|██████████| 20/20 [00:01<00:00, 16.90it/s, train_loss=0.00416, val_loss=0.00452]Epoch 25: 100%|██████████| 20/20 [00:01<00:00, 16.82it/s, train_loss=0.00448, val_loss=0.00452]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 44.73it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 42.92it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 46.44it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.39it/s][A
                                                                      [AEpoch 25: 100%|██████████| 20/20 [00:01<00:00, 15.62it/s, train_loss=0.00448, val_loss=0.00444]Epoch 25: 100%|██████████| 20/20 [00:01<00:00, 15.61it/s, train_loss=0.00448, val_loss=0.00444]Epoch 25:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00448, val_loss=0.00444]         Epoch 26:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00448, val_loss=0.00444]Epoch 26:   5%|▌         | 1/20 [00:00<00:00, 22.05it/s, train_loss=0.00448, val_loss=0.00444]Epoch 26:   5%|▌         | 1/20 [00:00<00:01, 18.41it/s, train_loss=0.00417, val_loss=0.00444]Epoch 26:  10%|█         | 2/20 [00:00<00:01, 17.06it/s, train_loss=0.00417, val_loss=0.00444]Epoch 26:  10%|█         | 2/20 [00:00<00:01, 16.70it/s, train_loss=0.00451, val_loss=0.00444]Epoch 26:  15%|█▌        | 3/20 [00:00<00:00, 18.44it/s, train_loss=0.00451, val_loss=0.00444]Epoch 26:  15%|█▌        | 3/20 [00:00<00:00, 17.72it/s, train_loss=0.00424, val_loss=0.00444]Epoch 26:  20%|██        | 4/20 [00:00<00:00, 18.18it/s, train_loss=0.00424, val_loss=0.00444]Epoch 26:  20%|██        | 4/20 [00:00<00:00, 17.61it/s, train_loss=0.00426, val_loss=0.00444]Epoch 26:  25%|██▌       | 5/20 [00:00<00:00, 17.97it/s, train_loss=0.00426, val_loss=0.00444]Epoch 26:  25%|██▌       | 5/20 [00:00<00:00, 17.38it/s, train_loss=0.00461, val_loss=0.00444]Epoch 26:  30%|███       | 6/20 [00:00<00:00, 17.63it/s, train_loss=0.00461, val_loss=0.00444]Epoch 26:  30%|███       | 6/20 [00:00<00:00, 17.40it/s, train_loss=0.00431, val_loss=0.00444]Epoch 26:  35%|███▌      | 7/20 [00:00<00:00, 17.07it/s, train_loss=0.00431, val_loss=0.00444]Epoch 26:  35%|███▌      | 7/20 [00:00<00:00, 17.00it/s, train_loss=0.00425, val_loss=0.00444]Epoch 26:  40%|████      | 8/20 [00:00<00:00, 17.21it/s, train_loss=0.00425, val_loss=0.00444]Epoch 26:  40%|████      | 8/20 [00:00<00:00, 17.10it/s, train_loss=0.0045, val_loss=0.00444] Epoch 26:  45%|████▌     | 9/20 [00:00<00:00, 17.11it/s, train_loss=0.0045, val_loss=0.00444]Epoch 26:  45%|████▌     | 9/20 [00:00<00:00, 16.80it/s, train_loss=0.00429, val_loss=0.00444]Epoch 26:  50%|█████     | 10/20 [00:00<00:00, 17.51it/s, train_loss=0.00429, val_loss=0.00444]Epoch 26:  50%|█████     | 10/20 [00:00<00:00, 17.30it/s, train_loss=0.00427, val_loss=0.00444]Epoch 26:  55%|█████▌    | 11/20 [00:00<00:00, 17.20it/s, train_loss=0.00427, val_loss=0.00444]Epoch 26:  55%|█████▌    | 11/20 [00:00<00:00, 17.15it/s, train_loss=0.00422, val_loss=0.00444]Epoch 26:  60%|██████    | 12/20 [00:00<00:00, 17.18it/s, train_loss=0.00422, val_loss=0.00444]Epoch 26:  60%|██████    | 12/20 [00:00<00:00, 17.07it/s, train_loss=0.00407, val_loss=0.00444]Epoch 26:  65%|██████▌   | 13/20 [00:00<00:00, 17.19it/s, train_loss=0.00407, val_loss=0.00444]Epoch 26:  65%|██████▌   | 13/20 [00:00<00:00, 16.99it/s, train_loss=0.00411, val_loss=0.00444]Epoch 26:  70%|███████   | 14/20 [00:00<00:00, 17.01it/s, train_loss=0.00411, val_loss=0.00444]Epoch 26:  70%|███████   | 14/20 [00:00<00:00, 16.88it/s, train_loss=0.00422, val_loss=0.00444]Epoch 26:  75%|███████▌  | 15/20 [00:00<00:00, 16.78it/s, train_loss=0.00422, val_loss=0.00444]Epoch 26:  75%|███████▌  | 15/20 [00:00<00:00, 16.70it/s, train_loss=0.00414, val_loss=0.00444]Epoch 26:  80%|████████  | 16/20 [00:00<00:00, 16.76it/s, train_loss=0.00414, val_loss=0.00444]Epoch 26:  80%|████████  | 16/20 [00:00<00:00, 16.64it/s, train_loss=0.00455, val_loss=0.00444]Epoch 26:  85%|████████▌ | 17/20 [00:01<00:00, 16.81it/s, train_loss=0.00455, val_loss=0.00444]Epoch 26:  85%|████████▌ | 17/20 [00:01<00:00, 16.69it/s, train_loss=0.00436, val_loss=0.00444]Epoch 26:  90%|█████████ | 18/20 [00:01<00:00, 16.75it/s, train_loss=0.00436, val_loss=0.00444]Epoch 26:  90%|█████████ | 18/20 [00:01<00:00, 16.70it/s, train_loss=0.00403, val_loss=0.00444]Epoch 26:  95%|█████████▌| 19/20 [00:01<00:00, 16.90it/s, train_loss=0.00403, val_loss=0.00444]Epoch 26:  95%|█████████▌| 19/20 [00:01<00:00, 16.77it/s, train_loss=0.00416, val_loss=0.00444]Epoch 26: 100%|██████████| 20/20 [00:01<00:00, 16.92it/s, train_loss=0.00416, val_loss=0.00444]Epoch 26: 100%|██████████| 20/20 [00:01<00:00, 16.85it/s, train_loss=0.0042, val_loss=0.00444] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 43.61it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 44.29it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 44.66it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.64it/s][A
                                                                      [AEpoch 26: 100%|██████████| 20/20 [00:01<00:00, 15.53it/s, train_loss=0.0042, val_loss=0.00431]Epoch 26: 100%|██████████| 20/20 [00:01<00:00, 15.51it/s, train_loss=0.0042, val_loss=0.00431]Epoch 26:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0042, val_loss=0.00431]         Epoch 27:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0042, val_loss=0.00431]Epoch 27:   5%|▌         | 1/20 [00:00<00:00, 21.29it/s, train_loss=0.0042, val_loss=0.00431]Epoch 27:   5%|▌         | 1/20 [00:00<00:00, 19.15it/s, train_loss=0.0044, val_loss=0.00431]Epoch 27:  10%|█         | 2/20 [00:00<00:00, 19.77it/s, train_loss=0.0044, val_loss=0.00431]Epoch 27:  10%|█         | 2/20 [00:00<00:00, 18.80it/s, train_loss=0.00385, val_loss=0.00431]Epoch 27:  15%|█▌        | 3/20 [00:00<00:00, 19.52it/s, train_loss=0.00385, val_loss=0.00431]Epoch 27:  15%|█▌        | 3/20 [00:00<00:00, 18.69it/s, train_loss=0.00451, val_loss=0.00431]Epoch 27:  20%|██        | 4/20 [00:00<00:00, 18.02it/s, train_loss=0.00451, val_loss=0.00431]Epoch 27:  20%|██        | 4/20 [00:00<00:00, 17.41it/s, train_loss=0.00405, val_loss=0.00431]Epoch 27:  25%|██▌       | 5/20 [00:00<00:00, 18.16it/s, train_loss=0.00405, val_loss=0.00431]Epoch 27:  25%|██▌       | 5/20 [00:00<00:00, 17.67it/s, train_loss=0.00459, val_loss=0.00431]Epoch 27:  30%|███       | 6/20 [00:00<00:00, 19.27it/s, train_loss=0.00459, val_loss=0.00431]Epoch 27:  30%|███       | 6/20 [00:00<00:00, 18.61it/s, train_loss=0.0043, val_loss=0.00431] Epoch 27:  35%|███▌      | 7/20 [00:00<00:00, 17.83it/s, train_loss=0.0043, val_loss=0.00431]Epoch 27:  35%|███▌      | 7/20 [00:00<00:00, 17.43it/s, train_loss=0.00424, val_loss=0.00431]Epoch 27:  40%|████      | 8/20 [00:00<00:00, 17.63it/s, train_loss=0.00424, val_loss=0.00431]Epoch 27:  40%|████      | 8/20 [00:00<00:00, 17.31it/s, train_loss=0.00402, val_loss=0.00431]Epoch 27:  45%|████▌     | 9/20 [00:00<00:00, 16.79it/s, train_loss=0.00402, val_loss=0.00431]Epoch 27:  45%|████▌     | 9/20 [00:00<00:00, 16.58it/s, train_loss=0.00417, val_loss=0.00431]Epoch 27:  50%|█████     | 10/20 [00:00<00:00, 16.69it/s, train_loss=0.00417, val_loss=0.00431]Epoch 27:  50%|█████     | 10/20 [00:00<00:00, 16.59it/s, train_loss=0.00427, val_loss=0.00431]Epoch 27:  55%|█████▌    | 11/20 [00:00<00:00, 17.04it/s, train_loss=0.00427, val_loss=0.00431]Epoch 27:  55%|█████▌    | 11/20 [00:00<00:00, 16.88it/s, train_loss=0.00443, val_loss=0.00431]Epoch 27:  60%|██████    | 12/20 [00:00<00:00, 17.28it/s, train_loss=0.00443, val_loss=0.00431]Epoch 27:  60%|██████    | 12/20 [00:00<00:00, 17.11it/s, train_loss=0.00451, val_loss=0.00431]Epoch 27:  65%|██████▌   | 13/20 [00:00<00:00, 17.54it/s, train_loss=0.00451, val_loss=0.00431]Epoch 27:  65%|██████▌   | 13/20 [00:00<00:00, 17.38it/s, train_loss=0.00406, val_loss=0.00431]Epoch 27:  70%|███████   | 14/20 [00:00<00:00, 17.58it/s, train_loss=0.00406, val_loss=0.00431]Epoch 27:  70%|███████   | 14/20 [00:00<00:00, 17.41it/s, train_loss=0.00417, val_loss=0.00431]Epoch 27:  75%|███████▌  | 15/20 [00:00<00:00, 17.49it/s, train_loss=0.00417, val_loss=0.00431]Epoch 27:  75%|███████▌  | 15/20 [00:00<00:00, 17.33it/s, train_loss=0.00419, val_loss=0.00431]Epoch 27:  80%|████████  | 16/20 [00:00<00:00, 17.38it/s, train_loss=0.00419, val_loss=0.00431]Epoch 27:  80%|████████  | 16/20 [00:00<00:00, 17.21it/s, train_loss=0.00401, val_loss=0.00431]Epoch 27:  85%|████████▌ | 17/20 [00:00<00:00, 17.45it/s, train_loss=0.00401, val_loss=0.00431]Epoch 27:  85%|████████▌ | 17/20 [00:00<00:00, 17.34it/s, train_loss=0.00417, val_loss=0.00431]Epoch 27:  90%|█████████ | 18/20 [00:01<00:00, 17.55it/s, train_loss=0.00417, val_loss=0.00431]Epoch 27:  90%|█████████ | 18/20 [00:01<00:00, 17.45it/s, train_loss=0.0041, val_loss=0.00431] Epoch 27:  95%|█████████▌| 19/20 [00:01<00:00, 17.30it/s, train_loss=0.0041, val_loss=0.00431]Epoch 27:  95%|█████████▌| 19/20 [00:01<00:00, 17.25it/s, train_loss=0.00434, val_loss=0.00431]Epoch 27: 100%|██████████| 20/20 [00:01<00:00, 17.32it/s, train_loss=0.00434, val_loss=0.00431]Epoch 27: 100%|██████████| 20/20 [00:01<00:00, 17.24it/s, train_loss=0.00396, val_loss=0.00431]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 41.47it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 37.29it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 42.81it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 43.89it/s][A
                                                                      [AEpoch 27: 100%|██████████| 20/20 [00:01<00:00, 15.86it/s, train_loss=0.00396, val_loss=0.00434]Epoch 27: 100%|██████████| 20/20 [00:01<00:00, 15.85it/s, train_loss=0.00396, val_loss=0.00434]Epoch 27:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00396, val_loss=0.00434]         Epoch 28:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00396, val_loss=0.00434]Epoch 28:   5%|▌         | 1/20 [00:00<00:00, 28.71it/s, train_loss=0.00396, val_loss=0.00434]Epoch 28:   5%|▌         | 1/20 [00:00<00:00, 23.07it/s, train_loss=0.00419, val_loss=0.00434]Epoch 28:  10%|█         | 2/20 [00:00<00:00, 20.52it/s, train_loss=0.00419, val_loss=0.00434]Epoch 28:  10%|█         | 2/20 [00:00<00:00, 19.62it/s, train_loss=0.00422, val_loss=0.00434]Epoch 28:  15%|█▌        | 3/20 [00:00<00:00, 19.19it/s, train_loss=0.00422, val_loss=0.00434]Epoch 28:  15%|█▌        | 3/20 [00:00<00:00, 17.99it/s, train_loss=0.00414, val_loss=0.00434]Epoch 28:  20%|██        | 4/20 [00:00<00:00, 18.43it/s, train_loss=0.00414, val_loss=0.00434]Epoch 28:  20%|██        | 4/20 [00:00<00:00, 17.87it/s, train_loss=0.00425, val_loss=0.00434]Epoch 28:  25%|██▌       | 5/20 [00:00<00:00, 17.64it/s, train_loss=0.00425, val_loss=0.00434]Epoch 28:  25%|██▌       | 5/20 [00:00<00:00, 17.25it/s, train_loss=0.00404, val_loss=0.00434]Epoch 28:  30%|███       | 6/20 [00:00<00:00, 17.71it/s, train_loss=0.00404, val_loss=0.00434]Epoch 28:  30%|███       | 6/20 [00:00<00:00, 17.35it/s, train_loss=0.00426, val_loss=0.00434]Epoch 28:  35%|███▌      | 7/20 [00:00<00:00, 16.48it/s, train_loss=0.00426, val_loss=0.00434]Epoch 28:  35%|███▌      | 7/20 [00:00<00:00, 16.10it/s, train_loss=0.00397, val_loss=0.00434]Epoch 28:  40%|████      | 8/20 [00:00<00:00, 16.67it/s, train_loss=0.00397, val_loss=0.00434]Epoch 28:  40%|████      | 8/20 [00:00<00:00, 16.42it/s, train_loss=0.00424, val_loss=0.00434]Epoch 28:  45%|████▌     | 9/20 [00:00<00:00, 16.97it/s, train_loss=0.00424, val_loss=0.00434]Epoch 28:  45%|████▌     | 9/20 [00:00<00:00, 16.86it/s, train_loss=0.00434, val_loss=0.00434]Epoch 28:  50%|█████     | 10/20 [00:00<00:00, 17.10it/s, train_loss=0.00434, val_loss=0.00434]Epoch 28:  50%|█████     | 10/20 [00:00<00:00, 16.87it/s, train_loss=0.00396, val_loss=0.00434]Epoch 28:  55%|█████▌    | 11/20 [00:00<00:00, 17.02it/s, train_loss=0.00396, val_loss=0.00434]Epoch 28:  55%|█████▌    | 11/20 [00:00<00:00, 16.84it/s, train_loss=0.00413, val_loss=0.00434]Epoch 28:  60%|██████    | 12/20 [00:00<00:00, 17.18it/s, train_loss=0.00413, val_loss=0.00434]Epoch 28:  60%|██████    | 12/20 [00:00<00:00, 17.02it/s, train_loss=0.00422, val_loss=0.00434]Epoch 28:  65%|██████▌   | 13/20 [00:00<00:00, 17.33it/s, train_loss=0.00422, val_loss=0.00434]Epoch 28:  65%|██████▌   | 13/20 [00:00<00:00, 17.19it/s, train_loss=0.0041, val_loss=0.00434] Epoch 28:  70%|███████   | 14/20 [00:00<00:00, 17.40it/s, train_loss=0.0041, val_loss=0.00434]Epoch 28:  70%|███████   | 14/20 [00:00<00:00, 17.28it/s, train_loss=0.00419, val_loss=0.00434]Epoch 28:  75%|███████▌  | 15/20 [00:00<00:00, 17.23it/s, train_loss=0.00419, val_loss=0.00434]Epoch 28:  75%|███████▌  | 15/20 [00:00<00:00, 17.13it/s, train_loss=0.00407, val_loss=0.00434]Epoch 28:  80%|████████  | 16/20 [00:00<00:00, 17.25it/s, train_loss=0.00407, val_loss=0.00434]Epoch 28:  80%|████████  | 16/20 [00:00<00:00, 17.11it/s, train_loss=0.00409, val_loss=0.00434]Epoch 28:  85%|████████▌ | 17/20 [00:00<00:00, 17.05it/s, train_loss=0.00409, val_loss=0.00434]Epoch 28:  85%|████████▌ | 17/20 [00:01<00:00, 16.97it/s, train_loss=0.00411, val_loss=0.00434]Epoch 28:  90%|█████████ | 18/20 [00:01<00:00, 17.30it/s, train_loss=0.00411, val_loss=0.00434]Epoch 28:  90%|█████████ | 18/20 [00:01<00:00, 17.19it/s, train_loss=0.00406, val_loss=0.00434]Epoch 28:  95%|█████████▌| 19/20 [00:01<00:00, 17.54it/s, train_loss=0.00406, val_loss=0.00434]Epoch 28:  95%|█████████▌| 19/20 [00:01<00:00, 17.39it/s, train_loss=0.004, val_loss=0.00434]  Epoch 28: 100%|██████████| 20/20 [00:01<00:00, 17.32it/s, train_loss=0.004, val_loss=0.00434]Epoch 28: 100%|██████████| 20/20 [00:01<00:00, 17.28it/s, train_loss=0.00455, val_loss=0.00434]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 53.92it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 48.72it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 46.12it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.93it/s][A
                                                                      [AEpoch 28: 100%|██████████| 20/20 [00:01<00:00, 15.91it/s, train_loss=0.00455, val_loss=0.00428]Epoch 28: 100%|██████████| 20/20 [00:01<00:00, 15.90it/s, train_loss=0.00455, val_loss=0.00428]Epoch 28:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00455, val_loss=0.00428]         Epoch 29:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00455, val_loss=0.00428]Epoch 29:   5%|▌         | 1/20 [00:00<00:01, 15.18it/s, train_loss=0.00455, val_loss=0.00428]Epoch 29:   5%|▌         | 1/20 [00:00<00:01, 13.73it/s, train_loss=0.00406, val_loss=0.00428]Epoch 29:  10%|█         | 2/20 [00:00<00:01, 14.32it/s, train_loss=0.00406, val_loss=0.00428]Epoch 29:  10%|█         | 2/20 [00:00<00:01, 13.60it/s, train_loss=0.0042, val_loss=0.00428] Epoch 29:  15%|█▌        | 3/20 [00:00<00:01, 14.49it/s, train_loss=0.0042, val_loss=0.00428]Epoch 29:  15%|█▌        | 3/20 [00:00<00:01, 14.32it/s, train_loss=0.00418, val_loss=0.00428]Epoch 29:  20%|██        | 4/20 [00:00<00:00, 16.07it/s, train_loss=0.00418, val_loss=0.00428]Epoch 29:  20%|██        | 4/20 [00:00<00:01, 15.67it/s, train_loss=0.00391, val_loss=0.00428]Epoch 29:  25%|██▌       | 5/20 [00:00<00:00, 16.02it/s, train_loss=0.00391, val_loss=0.00428]Epoch 29:  25%|██▌       | 5/20 [00:00<00:00, 15.68it/s, train_loss=0.00403, val_loss=0.00428]Epoch 29:  30%|███       | 6/20 [00:00<00:00, 16.04it/s, train_loss=0.00403, val_loss=0.00428]Epoch 29:  30%|███       | 6/20 [00:00<00:00, 15.73it/s, train_loss=0.00416, val_loss=0.00428]Epoch 29:  35%|███▌      | 7/20 [00:00<00:00, 16.24it/s, train_loss=0.00416, val_loss=0.00428]Epoch 29:  35%|███▌      | 7/20 [00:00<00:00, 16.08it/s, train_loss=0.00426, val_loss=0.00428]Epoch 29:  40%|████      | 8/20 [00:00<00:00, 16.49it/s, train_loss=0.00426, val_loss=0.00428]Epoch 29:  40%|████      | 8/20 [00:00<00:00, 16.13it/s, train_loss=0.0042, val_loss=0.00428] Epoch 29:  45%|████▌     | 9/20 [00:00<00:00, 16.29it/s, train_loss=0.0042, val_loss=0.00428]Epoch 29:  45%|████▌     | 9/20 [00:00<00:00, 16.08it/s, train_loss=0.0044, val_loss=0.00428]Epoch 29:  50%|█████     | 10/20 [00:00<00:00, 15.77it/s, train_loss=0.0044, val_loss=0.00428]Epoch 29:  50%|█████     | 10/20 [00:00<00:00, 15.66it/s, train_loss=0.00394, val_loss=0.00428]Epoch 29:  55%|█████▌    | 11/20 [00:00<00:00, 16.02it/s, train_loss=0.00394, val_loss=0.00428]Epoch 29:  55%|█████▌    | 11/20 [00:00<00:00, 15.85it/s, train_loss=0.00385, val_loss=0.00428]Epoch 29:  60%|██████    | 12/20 [00:00<00:00, 15.80it/s, train_loss=0.00385, val_loss=0.00428]Epoch 29:  60%|██████    | 12/20 [00:00<00:00, 15.64it/s, train_loss=0.0041, val_loss=0.00428] Epoch 29:  65%|██████▌   | 13/20 [00:00<00:00, 16.23it/s, train_loss=0.0041, val_loss=0.00428]Epoch 29:  65%|██████▌   | 13/20 [00:00<00:00, 16.02it/s, train_loss=0.00401, val_loss=0.00428]Epoch 29:  70%|███████   | 14/20 [00:00<00:00, 16.08it/s, train_loss=0.00401, val_loss=0.00428]Epoch 29:  70%|███████   | 14/20 [00:00<00:00, 16.03it/s, train_loss=0.00398, val_loss=0.00428]Epoch 29:  75%|███████▌  | 15/20 [00:00<00:00, 16.13it/s, train_loss=0.00398, val_loss=0.00428]Epoch 29:  75%|███████▌  | 15/20 [00:00<00:00, 16.03it/s, train_loss=0.00397, val_loss=0.00428]Epoch 29:  80%|████████  | 16/20 [00:00<00:00, 16.34it/s, train_loss=0.00397, val_loss=0.00428]Epoch 29:  80%|████████  | 16/20 [00:00<00:00, 16.22it/s, train_loss=0.00418, val_loss=0.00428]Epoch 29:  85%|████████▌ | 17/20 [00:01<00:00, 16.27it/s, train_loss=0.00418, val_loss=0.00428]Epoch 29:  85%|████████▌ | 17/20 [00:01<00:00, 16.18it/s, train_loss=0.00401, val_loss=0.00428]Epoch 29:  90%|█████████ | 18/20 [00:01<00:00, 16.37it/s, train_loss=0.00401, val_loss=0.00428]Epoch 29:  90%|█████████ | 18/20 [00:01<00:00, 16.26it/s, train_loss=0.00416, val_loss=0.00428]Epoch 29:  95%|█████████▌| 19/20 [00:01<00:00, 16.29it/s, train_loss=0.00416, val_loss=0.00428]Epoch 29:  95%|█████████▌| 19/20 [00:01<00:00, 16.21it/s, train_loss=0.00422, val_loss=0.00428]Epoch 29: 100%|██████████| 20/20 [00:01<00:00, 16.37it/s, train_loss=0.00422, val_loss=0.00428]Epoch 29: 100%|██████████| 20/20 [00:01<00:00, 16.31it/s, train_loss=0.004, val_loss=0.00428]  
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 49.07it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 45.90it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 37.55it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 38.65it/s][A
                                                                      [AEpoch 29: 100%|██████████| 20/20 [00:01<00:00, 14.90it/s, train_loss=0.004, val_loss=0.00425]Epoch 29: 100%|██████████| 20/20 [00:01<00:00, 14.89it/s, train_loss=0.004, val_loss=0.00425]Epoch 29:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.004, val_loss=0.00425]         Epoch 30:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.004, val_loss=0.00425]Epoch 30:   5%|▌         | 1/20 [00:00<00:01, 16.86it/s, train_loss=0.004, val_loss=0.00425]Epoch 30:   5%|▌         | 1/20 [00:00<00:01, 14.64it/s, train_loss=0.00425, val_loss=0.00425]Epoch 30:  10%|█         | 2/20 [00:00<00:00, 18.18it/s, train_loss=0.00425, val_loss=0.00425]Epoch 30:  10%|█         | 2/20 [00:00<00:01, 16.88it/s, train_loss=0.0042, val_loss=0.00425] Epoch 30:  15%|█▌        | 3/20 [00:00<00:00, 18.38it/s, train_loss=0.0042, val_loss=0.00425]Epoch 30:  15%|█▌        | 3/20 [00:00<00:00, 17.62it/s, train_loss=0.00414, val_loss=0.00425]Epoch 30:  20%|██        | 4/20 [00:00<00:00, 18.59it/s, train_loss=0.00414, val_loss=0.00425]Epoch 30:  20%|██        | 4/20 [00:00<00:00, 18.11it/s, train_loss=0.00378, val_loss=0.00425]Epoch 30:  25%|██▌       | 5/20 [00:00<00:00, 19.05it/s, train_loss=0.00378, val_loss=0.00425]Epoch 30:  25%|██▌       | 5/20 [00:00<00:00, 18.73it/s, train_loss=0.004, val_loss=0.00425]  Epoch 30:  30%|███       | 6/20 [00:00<00:00, 18.73it/s, train_loss=0.004, val_loss=0.00425]Epoch 30:  30%|███       | 6/20 [00:00<00:00, 18.44it/s, train_loss=0.00408, val_loss=0.00425]Epoch 30:  35%|███▌      | 7/20 [00:00<00:00, 18.03it/s, train_loss=0.00408, val_loss=0.00425]Epoch 30:  35%|███▌      | 7/20 [00:00<00:00, 17.73it/s, train_loss=0.00409, val_loss=0.00425]Epoch 30:  40%|████      | 8/20 [00:00<00:00, 18.32it/s, train_loss=0.00409, val_loss=0.00425]Epoch 30:  40%|████      | 8/20 [00:00<00:00, 18.04it/s, train_loss=0.00406, val_loss=0.00425]Epoch 30:  45%|████▌     | 9/20 [00:00<00:00, 18.92it/s, train_loss=0.00406, val_loss=0.00425]Epoch 30:  45%|████▌     | 9/20 [00:00<00:00, 18.61it/s, train_loss=0.00405, val_loss=0.00425]Epoch 30:  50%|█████     | 10/20 [00:00<00:00, 18.86it/s, train_loss=0.00405, val_loss=0.00425]Epoch 30:  50%|█████     | 10/20 [00:00<00:00, 18.76it/s, train_loss=0.00405, val_loss=0.00425]Epoch 30:  55%|█████▌    | 11/20 [00:00<00:00, 18.82it/s, train_loss=0.00405, val_loss=0.00425]Epoch 30:  55%|█████▌    | 11/20 [00:00<00:00, 18.60it/s, train_loss=0.00428, val_loss=0.00425]Epoch 30:  60%|██████    | 12/20 [00:00<00:00, 18.84it/s, train_loss=0.00428, val_loss=0.00425]Epoch 30:  60%|██████    | 12/20 [00:00<00:00, 18.63it/s, train_loss=0.00393, val_loss=0.00425]Epoch 30:  65%|██████▌   | 13/20 [00:00<00:00, 18.34it/s, train_loss=0.00393, val_loss=0.00425]Epoch 30:  65%|██████▌   | 13/20 [00:00<00:00, 18.18it/s, train_loss=0.00418, val_loss=0.00425]Epoch 30:  70%|███████   | 14/20 [00:00<00:00, 18.30it/s, train_loss=0.00418, val_loss=0.00425]Epoch 30:  70%|███████   | 14/20 [00:00<00:00, 18.17it/s, train_loss=0.00403, val_loss=0.00425]Epoch 30:  75%|███████▌  | 15/20 [00:00<00:00, 17.84it/s, train_loss=0.00403, val_loss=0.00425]Epoch 30:  75%|███████▌  | 15/20 [00:00<00:00, 17.76it/s, train_loss=0.00395, val_loss=0.00425]Epoch 30:  80%|████████  | 16/20 [00:00<00:00, 17.91it/s, train_loss=0.00395, val_loss=0.00425]Epoch 30:  80%|████████  | 16/20 [00:00<00:00, 17.72it/s, train_loss=0.0043, val_loss=0.00425] Epoch 30:  85%|████████▌ | 17/20 [00:00<00:00, 17.78it/s, train_loss=0.0043, val_loss=0.00425]Epoch 30:  85%|████████▌ | 17/20 [00:00<00:00, 17.70it/s, train_loss=0.00388, val_loss=0.00425]Epoch 30:  90%|█████████ | 18/20 [00:01<00:00, 17.61it/s, train_loss=0.00388, val_loss=0.00425]Epoch 30:  90%|█████████ | 18/20 [00:01<00:00, 17.49it/s, train_loss=0.00391, val_loss=0.00425]Epoch 30:  95%|█████████▌| 19/20 [00:01<00:00, 17.52it/s, train_loss=0.00391, val_loss=0.00425]Epoch 30:  95%|█████████▌| 19/20 [00:01<00:00, 17.38it/s, train_loss=0.00406, val_loss=0.00425]Epoch 30: 100%|██████████| 20/20 [00:01<00:00, 17.52it/s, train_loss=0.00406, val_loss=0.00425]Epoch 30: 100%|██████████| 20/20 [00:01<00:00, 17.42it/s, train_loss=0.00409, val_loss=0.00425]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 31.87it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 35.02it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 33.80it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 35.63it/s][A
                                                                      [AEpoch 30: 100%|██████████| 20/20 [00:01<00:00, 15.66it/s, train_loss=0.00409, val_loss=0.00425]Epoch 30: 100%|██████████| 20/20 [00:01<00:00, 15.64it/s, train_loss=0.00409, val_loss=0.00425]Epoch 30:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00409, val_loss=0.00425]         Epoch 31:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00409, val_loss=0.00425]Epoch 31:   5%|▌         | 1/20 [00:00<00:00, 22.27it/s, train_loss=0.00409, val_loss=0.00425]Epoch 31:   5%|▌         | 1/20 [00:00<00:00, 19.29it/s, train_loss=0.00399, val_loss=0.00425]Epoch 31:  10%|█         | 2/20 [00:00<00:01, 17.11it/s, train_loss=0.00399, val_loss=0.00425]Epoch 31:  10%|█         | 2/20 [00:00<00:01, 16.42it/s, train_loss=0.00406, val_loss=0.00425]Epoch 31:  15%|█▌        | 3/20 [00:00<00:00, 18.15it/s, train_loss=0.00406, val_loss=0.00425]Epoch 31:  15%|█▌        | 3/20 [00:00<00:00, 17.50it/s, train_loss=0.00394, val_loss=0.00425]Epoch 31:  20%|██        | 4/20 [00:00<00:00, 19.00it/s, train_loss=0.00394, val_loss=0.00425]Epoch 31:  20%|██        | 4/20 [00:00<00:00, 18.40it/s, train_loss=0.00407, val_loss=0.00425]Epoch 31:  25%|██▌       | 5/20 [00:00<00:00, 17.55it/s, train_loss=0.00407, val_loss=0.00425]Epoch 31:  25%|██▌       | 5/20 [00:00<00:00, 17.12it/s, train_loss=0.00407, val_loss=0.00425]Epoch 31:  30%|███       | 6/20 [00:00<00:00, 17.84it/s, train_loss=0.00407, val_loss=0.00425]Epoch 31:  30%|███       | 6/20 [00:00<00:00, 17.49it/s, train_loss=0.00426, val_loss=0.00425]Epoch 31:  35%|███▌      | 7/20 [00:00<00:00, 18.06it/s, train_loss=0.00426, val_loss=0.00425]Epoch 31:  35%|███▌      | 7/20 [00:00<00:00, 17.74it/s, train_loss=0.00396, val_loss=0.00425]Epoch 31:  40%|████      | 8/20 [00:00<00:00, 17.60it/s, train_loss=0.00396, val_loss=0.00425]Epoch 31:  40%|████      | 8/20 [00:00<00:00, 17.34it/s, train_loss=0.00408, val_loss=0.00425]Epoch 31:  45%|████▌     | 9/20 [00:00<00:00, 17.21it/s, train_loss=0.00408, val_loss=0.00425]Epoch 31:  45%|████▌     | 9/20 [00:00<00:00, 17.15it/s, train_loss=0.00397, val_loss=0.00425]Epoch 31:  50%|█████     | 10/20 [00:00<00:00, 17.25it/s, train_loss=0.00397, val_loss=0.00425]Epoch 31:  50%|█████     | 10/20 [00:00<00:00, 16.92it/s, train_loss=0.00394, val_loss=0.00425]Epoch 31:  55%|█████▌    | 11/20 [00:00<00:00, 17.22it/s, train_loss=0.00394, val_loss=0.00425]Epoch 31:  55%|█████▌    | 11/20 [00:00<00:00, 17.03it/s, train_loss=0.00415, val_loss=0.00425]Epoch 31:  60%|██████    | 12/20 [00:00<00:00, 16.98it/s, train_loss=0.00415, val_loss=0.00425]Epoch 31:  60%|██████    | 12/20 [00:00<00:00, 16.86it/s, train_loss=0.00401, val_loss=0.00425]Epoch 31:  65%|██████▌   | 13/20 [00:00<00:00, 16.88it/s, train_loss=0.00401, val_loss=0.00425]Epoch 31:  65%|██████▌   | 13/20 [00:00<00:00, 16.73it/s, train_loss=0.00401, val_loss=0.00425]Epoch 31:  70%|███████   | 14/20 [00:00<00:00, 16.98it/s, train_loss=0.00401, val_loss=0.00425]Epoch 31:  70%|███████   | 14/20 [00:00<00:00, 16.85it/s, train_loss=0.00405, val_loss=0.00425]Epoch 31:  75%|███████▌  | 15/20 [00:00<00:00, 17.09it/s, train_loss=0.00405, val_loss=0.00425]Epoch 31:  75%|███████▌  | 15/20 [00:00<00:00, 16.95it/s, train_loss=0.00391, val_loss=0.00425]Epoch 31:  80%|████████  | 16/20 [00:00<00:00, 17.20it/s, train_loss=0.00391, val_loss=0.00425]Epoch 31:  80%|████████  | 16/20 [00:00<00:00, 17.08it/s, train_loss=0.00403, val_loss=0.00425]Epoch 31:  85%|████████▌ | 17/20 [00:00<00:00, 17.16it/s, train_loss=0.00403, val_loss=0.00425]Epoch 31:  85%|████████▌ | 17/20 [00:00<00:00, 17.05it/s, train_loss=0.00413, val_loss=0.00425]Epoch 31:  90%|█████████ | 18/20 [00:01<00:00, 17.10it/s, train_loss=0.00413, val_loss=0.00425]Epoch 31:  90%|█████████ | 18/20 [00:01<00:00, 17.02it/s, train_loss=0.00405, val_loss=0.00425]Epoch 31:  95%|█████████▌| 19/20 [00:01<00:00, 17.27it/s, train_loss=0.00405, val_loss=0.00425]Epoch 31:  95%|█████████▌| 19/20 [00:01<00:00, 17.14it/s, train_loss=0.0041, val_loss=0.00425] Epoch 31: 100%|██████████| 20/20 [00:01<00:00, 16.94it/s, train_loss=0.0041, val_loss=0.00425]Epoch 31: 100%|██████████| 20/20 [00:01<00:00, 16.86it/s, train_loss=0.00402, val_loss=0.00425]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 63.75it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 66.15it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 69.14it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 65.04it/s][A
                                                                      [AEpoch 31: 100%|██████████| 20/20 [00:01<00:00, 15.92it/s, train_loss=0.00402, val_loss=0.00423]Epoch 31: 100%|██████████| 20/20 [00:01<00:00, 15.83it/s, train_loss=0.00402, val_loss=0.00423]Epoch 31:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00402, val_loss=0.00423]         Epoch 32:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00402, val_loss=0.00423]Epoch 32:   5%|▌         | 1/20 [00:00<00:01, 15.91it/s, train_loss=0.00402, val_loss=0.00423]Epoch 32:   5%|▌         | 1/20 [00:00<00:01, 14.15it/s, train_loss=0.00412, val_loss=0.00423]Epoch 32:  10%|█         | 2/20 [00:00<00:01, 16.99it/s, train_loss=0.00412, val_loss=0.00423]Epoch 32:  10%|█         | 2/20 [00:00<00:01, 16.06it/s, train_loss=0.00409, val_loss=0.00423]Epoch 32:  15%|█▌        | 3/20 [00:00<00:01, 16.54it/s, train_loss=0.00409, val_loss=0.00423]Epoch 32:  15%|█▌        | 3/20 [00:00<00:01, 15.86it/s, train_loss=0.00384, val_loss=0.00423]Epoch 32:  20%|██        | 4/20 [00:00<00:00, 17.01it/s, train_loss=0.00384, val_loss=0.00423]Epoch 32:  20%|██        | 4/20 [00:00<00:00, 16.46it/s, train_loss=0.00405, val_loss=0.00423]Epoch 32:  25%|██▌       | 5/20 [00:00<00:00, 15.90it/s, train_loss=0.00405, val_loss=0.00423]Epoch 32:  25%|██▌       | 5/20 [00:00<00:00, 15.60it/s, train_loss=0.00408, val_loss=0.00423]Epoch 32:  30%|███       | 6/20 [00:00<00:00, 16.22it/s, train_loss=0.00408, val_loss=0.00423]Epoch 32:  30%|███       | 6/20 [00:00<00:00, 15.94it/s, train_loss=0.00417, val_loss=0.00423]Epoch 32:  35%|███▌      | 7/20 [00:00<00:00, 16.40it/s, train_loss=0.00417, val_loss=0.00423]Epoch 32:  35%|███▌      | 7/20 [00:00<00:00, 16.13it/s, train_loss=0.00411, val_loss=0.00423]Epoch 32:  40%|████      | 8/20 [00:00<00:00, 16.23it/s, train_loss=0.00411, val_loss=0.00423]Epoch 32:  40%|████      | 8/20 [00:00<00:00, 15.94it/s, train_loss=0.00384, val_loss=0.00423]Epoch 32:  45%|████▌     | 9/20 [00:00<00:00, 16.14it/s, train_loss=0.00384, val_loss=0.00423]Epoch 32:  45%|████▌     | 9/20 [00:00<00:00, 15.95it/s, train_loss=0.00408, val_loss=0.00423]Epoch 32:  50%|█████     | 10/20 [00:00<00:00, 16.53it/s, train_loss=0.00408, val_loss=0.00423]Epoch 32:  50%|█████     | 10/20 [00:00<00:00, 16.34it/s, train_loss=0.00396, val_loss=0.00423]Epoch 32:  55%|█████▌    | 11/20 [00:00<00:00, 16.73it/s, train_loss=0.00396, val_loss=0.00423]Epoch 32:  55%|█████▌    | 11/20 [00:00<00:00, 16.57it/s, train_loss=0.00398, val_loss=0.00423]Epoch 32:  60%|██████    | 12/20 [00:00<00:00, 16.91it/s, train_loss=0.00398, val_loss=0.00423]Epoch 32:  60%|██████    | 12/20 [00:00<00:00, 16.74it/s, train_loss=0.00409, val_loss=0.00423]Epoch 32:  65%|██████▌   | 13/20 [00:00<00:00, 16.57it/s, train_loss=0.00409, val_loss=0.00423]Epoch 32:  65%|██████▌   | 13/20 [00:00<00:00, 16.48it/s, train_loss=0.0038, val_loss=0.00423] Epoch 32:  70%|███████   | 14/20 [00:00<00:00, 16.62it/s, train_loss=0.0038, val_loss=0.00423]Epoch 32:  70%|███████   | 14/20 [00:00<00:00, 16.48it/s, train_loss=0.004, val_loss=0.00423] Epoch 32:  75%|███████▌  | 15/20 [00:00<00:00, 16.54it/s, train_loss=0.004, val_loss=0.00423]Epoch 32:  75%|███████▌  | 15/20 [00:00<00:00, 16.40it/s, train_loss=0.00399, val_loss=0.00423]Epoch 32:  80%|████████  | 16/20 [00:00<00:00, 16.75it/s, train_loss=0.00399, val_loss=0.00423]Epoch 32:  80%|████████  | 16/20 [00:00<00:00, 16.59it/s, train_loss=0.00419, val_loss=0.00423]Epoch 32:  85%|████████▌ | 17/20 [00:00<00:00, 17.05it/s, train_loss=0.00419, val_loss=0.00423]Epoch 32:  85%|████████▌ | 17/20 [00:01<00:00, 16.88it/s, train_loss=0.00423, val_loss=0.00423]Epoch 32:  90%|█████████ | 18/20 [00:01<00:00, 16.64it/s, train_loss=0.00423, val_loss=0.00423]Epoch 32:  90%|█████████ | 18/20 [00:01<00:00, 16.54it/s, train_loss=0.00396, val_loss=0.00423]Epoch 32:  95%|█████████▌| 19/20 [00:01<00:00, 16.73it/s, train_loss=0.00396, val_loss=0.00423]Epoch 32:  95%|█████████▌| 19/20 [00:01<00:00, 16.60it/s, train_loss=0.00396, val_loss=0.00423]Epoch 32: 100%|██████████| 20/20 [00:01<00:00, 16.56it/s, train_loss=0.00396, val_loss=0.00423]Epoch 32: 100%|██████████| 20/20 [00:01<00:00, 16.50it/s, train_loss=0.00419, val_loss=0.00423]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 30.85it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 36.20it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 33.45it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 36.20it/s][A
                                                                      [AEpoch 32: 100%|██████████| 20/20 [00:01<00:00, 14.94it/s, train_loss=0.00419, val_loss=0.00419]Epoch 32: 100%|██████████| 20/20 [00:01<00:00, 14.91it/s, train_loss=0.00419, val_loss=0.00419]Epoch 32:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00419, val_loss=0.00419]         Epoch 33:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00419, val_loss=0.00419]Epoch 33:   5%|▌         | 1/20 [00:00<00:01, 18.76it/s, train_loss=0.00419, val_loss=0.00419]Epoch 33:   5%|▌         | 1/20 [00:00<00:01, 16.49it/s, train_loss=0.00385, val_loss=0.00419]Epoch 33:  10%|█         | 2/20 [00:00<00:01, 17.29it/s, train_loss=0.00385, val_loss=0.00419]Epoch 33:  10%|█         | 2/20 [00:00<00:01, 16.19it/s, train_loss=0.00386, val_loss=0.00419]Epoch 33:  15%|█▌        | 3/20 [00:00<00:01, 16.41it/s, train_loss=0.00386, val_loss=0.00419]Epoch 33:  15%|█▌        | 3/20 [00:00<00:01, 15.73it/s, train_loss=0.00411, val_loss=0.00419]Epoch 33:  20%|██        | 4/20 [00:00<00:00, 16.92it/s, train_loss=0.00411, val_loss=0.00419]Epoch 33:  20%|██        | 4/20 [00:00<00:00, 16.28it/s, train_loss=0.00396, val_loss=0.00419]Epoch 33:  25%|██▌       | 5/20 [00:00<00:00, 17.21it/s, train_loss=0.00396, val_loss=0.00419]Epoch 33:  25%|██▌       | 5/20 [00:00<00:00, 16.87it/s, train_loss=0.00392, val_loss=0.00419]Epoch 33:  30%|███       | 6/20 [00:00<00:00, 17.16it/s, train_loss=0.00392, val_loss=0.00419]Epoch 33:  30%|███       | 6/20 [00:00<00:00, 16.75it/s, train_loss=0.0039, val_loss=0.00419] Epoch 33:  35%|███▌      | 7/20 [00:00<00:00, 15.93it/s, train_loss=0.0039, val_loss=0.00419]Epoch 33:  35%|███▌      | 7/20 [00:00<00:00, 15.66it/s, train_loss=0.00408, val_loss=0.00419]Epoch 33:  40%|████      | 8/20 [00:00<00:00, 15.93it/s, train_loss=0.00408, val_loss=0.00419]Epoch 33:  40%|████      | 8/20 [00:00<00:00, 15.70it/s, train_loss=0.00378, val_loss=0.00419]Epoch 33:  45%|████▌     | 9/20 [00:00<00:00, 16.16it/s, train_loss=0.00378, val_loss=0.00419]Epoch 33:  45%|████▌     | 9/20 [00:00<00:00, 15.93it/s, train_loss=0.00414, val_loss=0.00419]Epoch 33:  50%|█████     | 10/20 [00:00<00:00, 16.41it/s, train_loss=0.00414, val_loss=0.00419]Epoch 33:  50%|█████     | 10/20 [00:00<00:00, 16.20it/s, train_loss=0.00398, val_loss=0.00419]Epoch 33:  55%|█████▌    | 11/20 [00:00<00:00, 16.96it/s, train_loss=0.00398, val_loss=0.00419]Epoch 33:  55%|█████▌    | 11/20 [00:00<00:00, 16.73it/s, train_loss=0.00401, val_loss=0.00419]Epoch 33:  60%|██████    | 12/20 [00:00<00:00, 16.59it/s, train_loss=0.00401, val_loss=0.00419]Epoch 33:  60%|██████    | 12/20 [00:00<00:00, 16.38it/s, train_loss=0.00373, val_loss=0.00419]Epoch 33:  65%|██████▌   | 13/20 [00:00<00:00, 16.63it/s, train_loss=0.00373, val_loss=0.00419]Epoch 33:  65%|██████▌   | 13/20 [00:00<00:00, 16.49it/s, train_loss=0.00406, val_loss=0.00419]Epoch 33:  70%|███████   | 14/20 [00:00<00:00, 16.52it/s, train_loss=0.00406, val_loss=0.00419]Epoch 33:  70%|███████   | 14/20 [00:00<00:00, 16.44it/s, train_loss=0.0041, val_loss=0.00419] Epoch 33:  75%|███████▌  | 15/20 [00:00<00:00, 16.73it/s, train_loss=0.0041, val_loss=0.00419]Epoch 33:  75%|███████▌  | 15/20 [00:00<00:00, 16.60it/s, train_loss=0.0038, val_loss=0.00419]Epoch 33:  80%|████████  | 16/20 [00:00<00:00, 16.50it/s, train_loss=0.0038, val_loss=0.00419]Epoch 33:  80%|████████  | 16/20 [00:00<00:00, 16.39it/s, train_loss=0.00385, val_loss=0.00419]Epoch 33:  85%|████████▌ | 17/20 [00:01<00:00, 16.59it/s, train_loss=0.00385, val_loss=0.00419]Epoch 33:  85%|████████▌ | 17/20 [00:01<00:00, 16.48it/s, train_loss=0.00404, val_loss=0.00419]Epoch 33:  90%|█████████ | 18/20 [00:01<00:00, 16.59it/s, train_loss=0.00404, val_loss=0.00419]Epoch 33:  90%|█████████ | 18/20 [00:01<00:00, 16.48it/s, train_loss=0.00408, val_loss=0.00419]Epoch 33:  95%|█████████▌| 19/20 [00:01<00:00, 16.58it/s, train_loss=0.00408, val_loss=0.00419]Epoch 33:  95%|█████████▌| 19/20 [00:01<00:00, 16.52it/s, train_loss=0.00413, val_loss=0.00419]Epoch 33: 100%|██████████| 20/20 [00:01<00:00, 16.54it/s, train_loss=0.00413, val_loss=0.00419]Epoch 33: 100%|██████████| 20/20 [00:01<00:00, 16.51it/s, train_loss=0.00396, val_loss=0.00419]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 41.90it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 42.68it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 41.69it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 43.46it/s][A
                                                                      [AEpoch 33: 100%|██████████| 20/20 [00:01<00:00, 15.20it/s, train_loss=0.00396, val_loss=0.00419]Epoch 33: 100%|██████████| 20/20 [00:01<00:00, 15.18it/s, train_loss=0.00396, val_loss=0.00419]Epoch 33:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00396, val_loss=0.00419]         Epoch 34:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00396, val_loss=0.00419]Epoch 34:   5%|▌         | 1/20 [00:00<00:00, 22.65it/s, train_loss=0.00396, val_loss=0.00419]Epoch 34:   5%|▌         | 1/20 [00:00<00:01, 19.00it/s, train_loss=0.00412, val_loss=0.00419]Epoch 34:  10%|█         | 2/20 [00:00<00:01, 17.17it/s, train_loss=0.00412, val_loss=0.00419]Epoch 34:  10%|█         | 2/20 [00:00<00:01, 16.38it/s, train_loss=0.00383, val_loss=0.00419]Epoch 34:  15%|█▌        | 3/20 [00:00<00:00, 17.36it/s, train_loss=0.00383, val_loss=0.00419]Epoch 34:  15%|█▌        | 3/20 [00:00<00:00, 17.08it/s, train_loss=0.00398, val_loss=0.00419]Epoch 34:  20%|██        | 4/20 [00:00<00:00, 16.81it/s, train_loss=0.00398, val_loss=0.00419]Epoch 34:  20%|██        | 4/20 [00:00<00:00, 16.44it/s, train_loss=0.00395, val_loss=0.00419]Epoch 34:  25%|██▌       | 5/20 [00:00<00:00, 17.85it/s, train_loss=0.00395, val_loss=0.00419]Epoch 34:  25%|██▌       | 5/20 [00:00<00:00, 17.37it/s, train_loss=0.004, val_loss=0.00419]  Epoch 34:  30%|███       | 6/20 [00:00<00:00, 18.63it/s, train_loss=0.004, val_loss=0.00419]Epoch 34:  30%|███       | 6/20 [00:00<00:00, 18.20it/s, train_loss=0.00401, val_loss=0.00419]Epoch 34:  35%|███▌      | 7/20 [00:00<00:00, 17.53it/s, train_loss=0.00401, val_loss=0.00419]Epoch 34:  35%|███▌      | 7/20 [00:00<00:00, 17.24it/s, train_loss=0.00398, val_loss=0.00419]Epoch 34:  40%|████      | 8/20 [00:00<00:00, 17.71it/s, train_loss=0.00398, val_loss=0.00419]Epoch 34:  40%|████      | 8/20 [00:00<00:00, 17.48it/s, train_loss=0.00408, val_loss=0.00419]Epoch 34:  45%|████▌     | 9/20 [00:00<00:00, 17.54it/s, train_loss=0.00408, val_loss=0.00419]Epoch 34:  45%|████▌     | 9/20 [00:00<00:00, 17.38it/s, train_loss=0.00424, val_loss=0.00419]Epoch 34:  50%|█████     | 10/20 [00:00<00:00, 17.54it/s, train_loss=0.00424, val_loss=0.00419]Epoch 34:  50%|█████     | 10/20 [00:00<00:00, 17.27it/s, train_loss=0.00408, val_loss=0.00419]Epoch 34:  55%|█████▌    | 11/20 [00:00<00:00, 17.11it/s, train_loss=0.00408, val_loss=0.00419]Epoch 34:  55%|█████▌    | 11/20 [00:00<00:00, 16.92it/s, train_loss=0.00396, val_loss=0.00419]Epoch 34:  60%|██████    | 12/20 [00:00<00:00, 16.99it/s, train_loss=0.00396, val_loss=0.00419]Epoch 34:  60%|██████    | 12/20 [00:00<00:00, 16.78it/s, train_loss=0.0038, val_loss=0.00419] Epoch 34:  65%|██████▌   | 13/20 [00:00<00:00, 16.92it/s, train_loss=0.0038, val_loss=0.00419]Epoch 34:  65%|██████▌   | 13/20 [00:00<00:00, 16.74it/s, train_loss=0.00369, val_loss=0.00419]Epoch 34:  70%|███████   | 14/20 [00:00<00:00, 16.94it/s, train_loss=0.00369, val_loss=0.00419]Epoch 34:  70%|███████   | 14/20 [00:00<00:00, 16.78it/s, train_loss=0.00415, val_loss=0.00419]Epoch 34:  75%|███████▌  | 15/20 [00:00<00:00, 16.98it/s, train_loss=0.00415, val_loss=0.00419]Epoch 34:  75%|███████▌  | 15/20 [00:00<00:00, 16.85it/s, train_loss=0.00387, val_loss=0.00419]Epoch 34:  80%|████████  | 16/20 [00:00<00:00, 17.14it/s, train_loss=0.00387, val_loss=0.00419]Epoch 34:  80%|████████  | 16/20 [00:00<00:00, 17.01it/s, train_loss=0.00405, val_loss=0.00419]Epoch 34:  85%|████████▌ | 17/20 [00:00<00:00, 17.28it/s, train_loss=0.00405, val_loss=0.00419]Epoch 34:  85%|████████▌ | 17/20 [00:00<00:00, 17.17it/s, train_loss=0.0038, val_loss=0.00419] Epoch 34:  90%|█████████ | 18/20 [00:01<00:00, 17.48it/s, train_loss=0.0038, val_loss=0.00419]Epoch 34:  90%|█████████ | 18/20 [00:01<00:00, 17.37it/s, train_loss=0.00388, val_loss=0.00419]Epoch 34:  95%|█████████▌| 19/20 [00:01<00:00, 17.46it/s, train_loss=0.00388, val_loss=0.00419]Epoch 34:  95%|█████████▌| 19/20 [00:01<00:00, 17.40it/s, train_loss=0.00395, val_loss=0.00419]Epoch 34: 100%|██████████| 20/20 [00:01<00:00, 17.33it/s, train_loss=0.00395, val_loss=0.00419]Epoch 34: 100%|██████████| 20/20 [00:01<00:00, 17.30it/s, train_loss=0.0039, val_loss=0.00419] 
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 42.12it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 31.70it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 39.29it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 40.36it/s][A
                                                                      [AEpoch 34: 100%|██████████| 20/20 [00:01<00:00, 15.77it/s, train_loss=0.0039, val_loss=0.00415]Epoch 34: 100%|██████████| 20/20 [00:01<00:00, 15.76it/s, train_loss=0.0039, val_loss=0.00415]Epoch 34:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0039, val_loss=0.00415]         Epoch 35:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.0039, val_loss=0.00415]Epoch 35:   5%|▌         | 1/20 [00:00<00:00, 26.17it/s, train_loss=0.0039, val_loss=0.00415]Epoch 35:   5%|▌         | 1/20 [00:00<00:00, 22.64it/s, train_loss=0.00413, val_loss=0.00415]Epoch 35:  10%|█         | 2/20 [00:00<00:00, 25.24it/s, train_loss=0.00413, val_loss=0.00415]Epoch 35:  10%|█         | 2/20 [00:00<00:00, 23.02it/s, train_loss=0.00404, val_loss=0.00415]Epoch 35:  15%|█▌        | 3/20 [00:00<00:00, 19.91it/s, train_loss=0.00404, val_loss=0.00415]Epoch 35:  15%|█▌        | 3/20 [00:00<00:00, 19.01it/s, train_loss=0.00374, val_loss=0.00415]Epoch 35:  20%|██        | 4/20 [00:00<00:00, 18.85it/s, train_loss=0.00374, val_loss=0.00415]Epoch 35:  20%|██        | 4/20 [00:00<00:00, 18.39it/s, train_loss=0.00409, val_loss=0.00415]Epoch 35:  25%|██▌       | 5/20 [00:00<00:00, 17.82it/s, train_loss=0.00409, val_loss=0.00415]Epoch 35:  25%|██▌       | 5/20 [00:00<00:00, 17.61it/s, train_loss=0.00388, val_loss=0.00415]Epoch 35:  30%|███       | 6/20 [00:00<00:00, 17.82it/s, train_loss=0.00388, val_loss=0.00415]Epoch 35:  30%|███       | 6/20 [00:00<00:00, 17.31it/s, train_loss=0.0039, val_loss=0.00415] Epoch 35:  35%|███▌      | 7/20 [00:00<00:00, 16.97it/s, train_loss=0.0039, val_loss=0.00415]Epoch 35:  35%|███▌      | 7/20 [00:00<00:00, 16.74it/s, train_loss=0.00375, val_loss=0.00415]Epoch 35:  40%|████      | 8/20 [00:00<00:00, 17.07it/s, train_loss=0.00375, val_loss=0.00415]Epoch 35:  40%|████      | 8/20 [00:00<00:00, 16.83it/s, train_loss=0.00399, val_loss=0.00415]Epoch 35:  45%|████▌     | 9/20 [00:00<00:00, 17.10it/s, train_loss=0.00399, val_loss=0.00415]Epoch 35:  45%|████▌     | 9/20 [00:00<00:00, 16.86it/s, train_loss=0.0039, val_loss=0.00415] Epoch 35:  50%|█████     | 10/20 [00:00<00:00, 17.00it/s, train_loss=0.0039, val_loss=0.00415]Epoch 35:  50%|█████     | 10/20 [00:00<00:00, 16.81it/s, train_loss=0.00389, val_loss=0.00415]Epoch 35:  55%|█████▌    | 11/20 [00:00<00:00, 16.97it/s, train_loss=0.00389, val_loss=0.00415]Epoch 35:  55%|█████▌    | 11/20 [00:00<00:00, 16.81it/s, train_loss=0.00372, val_loss=0.00415]Epoch 35:  60%|██████    | 12/20 [00:00<00:00, 17.14it/s, train_loss=0.00372, val_loss=0.00415]Epoch 35:  60%|██████    | 12/20 [00:00<00:00, 16.93it/s, train_loss=0.00402, val_loss=0.00415]Epoch 35:  65%|██████▌   | 13/20 [00:00<00:00, 17.17it/s, train_loss=0.00402, val_loss=0.00415]Epoch 35:  65%|██████▌   | 13/20 [00:00<00:00, 17.00it/s, train_loss=0.00408, val_loss=0.00415]Epoch 35:  70%|███████   | 14/20 [00:00<00:00, 17.12it/s, train_loss=0.00408, val_loss=0.00415]Epoch 35:  70%|███████   | 14/20 [00:00<00:00, 17.00it/s, train_loss=0.00373, val_loss=0.00415]Epoch 35:  75%|███████▌  | 15/20 [00:00<00:00, 17.16it/s, train_loss=0.00373, val_loss=0.00415]Epoch 35:  75%|███████▌  | 15/20 [00:00<00:00, 17.07it/s, train_loss=0.00393, val_loss=0.00415]Epoch 35:  80%|████████  | 16/20 [00:00<00:00, 17.13it/s, train_loss=0.00393, val_loss=0.00415]Epoch 35:  80%|████████  | 16/20 [00:00<00:00, 17.07it/s, train_loss=0.00351, val_loss=0.00415]Epoch 35:  85%|████████▌ | 17/20 [00:00<00:00, 17.20it/s, train_loss=0.00351, val_loss=0.00415]Epoch 35:  85%|████████▌ | 17/20 [00:00<00:00, 17.09it/s, train_loss=0.00403, val_loss=0.00415]Epoch 35:  90%|█████████ | 18/20 [00:01<00:00, 17.48it/s, train_loss=0.00403, val_loss=0.00415]Epoch 35:  90%|█████████ | 18/20 [00:01<00:00, 17.36it/s, train_loss=0.00421, val_loss=0.00415]Epoch 35:  95%|█████████▌| 19/20 [00:01<00:00, 17.58it/s, train_loss=0.00421, val_loss=0.00415]Epoch 35:  95%|█████████▌| 19/20 [00:01<00:00, 17.53it/s, train_loss=0.0042, val_loss=0.00415] Epoch 35: 100%|██████████| 20/20 [00:01<00:00, 17.46it/s, train_loss=0.0042, val_loss=0.00415]Epoch 35: 100%|██████████| 20/20 [00:01<00:00, 17.40it/s, train_loss=0.00409, val_loss=0.00415]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 27.75it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 31.11it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 31.82it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 32.19it/s][A
                                                                      [AEpoch 35: 100%|██████████| 20/20 [00:01<00:00, 15.59it/s, train_loss=0.00409, val_loss=0.00417]Epoch 35: 100%|██████████| 20/20 [00:01<00:00, 15.58it/s, train_loss=0.00409, val_loss=0.00417]Epoch 35:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00409, val_loss=0.00417]         Epoch 36:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00409, val_loss=0.00417]Epoch 36:   5%|▌         | 1/20 [00:00<00:01, 14.81it/s, train_loss=0.00409, val_loss=0.00417]Epoch 36:   5%|▌         | 1/20 [00:00<00:01, 13.76it/s, train_loss=0.00386, val_loss=0.00417]Epoch 36:  10%|█         | 2/20 [00:00<00:01, 15.12it/s, train_loss=0.00386, val_loss=0.00417]Epoch 36:  10%|█         | 2/20 [00:00<00:01, 14.34it/s, train_loss=0.00405, val_loss=0.00417]Epoch 36:  15%|█▌        | 3/20 [00:00<00:01, 15.93it/s, train_loss=0.00405, val_loss=0.00417]Epoch 36:  15%|█▌        | 3/20 [00:00<00:01, 15.31it/s, train_loss=0.00371, val_loss=0.00417]Epoch 36:  20%|██        | 4/20 [00:00<00:00, 16.56it/s, train_loss=0.00371, val_loss=0.00417]Epoch 36:  20%|██        | 4/20 [00:00<00:00, 16.06it/s, train_loss=0.00401, val_loss=0.00417]Epoch 36:  25%|██▌       | 5/20 [00:00<00:00, 16.56it/s, train_loss=0.00401, val_loss=0.00417]Epoch 36:  25%|██▌       | 5/20 [00:00<00:00, 16.10it/s, train_loss=0.00367, val_loss=0.00417]Epoch 36:  30%|███       | 6/20 [00:00<00:00, 16.57it/s, train_loss=0.00367, val_loss=0.00417]Epoch 36:  30%|███       | 6/20 [00:00<00:00, 16.23it/s, train_loss=0.00391, val_loss=0.00417]Epoch 36:  35%|███▌      | 7/20 [00:00<00:00, 16.69it/s, train_loss=0.00391, val_loss=0.00417]Epoch 36:  35%|███▌      | 7/20 [00:00<00:00, 16.47it/s, train_loss=0.00408, val_loss=0.00417]Epoch 36:  40%|████      | 8/20 [00:00<00:00, 16.89it/s, train_loss=0.00408, val_loss=0.00417]Epoch 36:  40%|████      | 8/20 [00:00<00:00, 16.66it/s, train_loss=0.00384, val_loss=0.00417]Epoch 36:  45%|████▌     | 9/20 [00:00<00:00, 16.36it/s, train_loss=0.00384, val_loss=0.00417]Epoch 36:  45%|████▌     | 9/20 [00:00<00:00, 16.29it/s, train_loss=0.00402, val_loss=0.00417]Epoch 36:  50%|█████     | 10/20 [00:00<00:00, 16.34it/s, train_loss=0.00402, val_loss=0.00417]Epoch 36:  50%|█████     | 10/20 [00:00<00:00, 16.15it/s, train_loss=0.004, val_loss=0.00417]  Epoch 36:  55%|█████▌    | 11/20 [00:00<00:00, 16.16it/s, train_loss=0.004, val_loss=0.00417]Epoch 36:  55%|█████▌    | 11/20 [00:00<00:00, 16.02it/s, train_loss=0.0037, val_loss=0.00417]Epoch 36:  60%|██████    | 12/20 [00:00<00:00, 16.54it/s, train_loss=0.0037, val_loss=0.00417]Epoch 36:  60%|██████    | 12/20 [00:00<00:00, 16.38it/s, train_loss=0.00408, val_loss=0.00417]Epoch 36:  65%|██████▌   | 13/20 [00:00<00:00, 17.03it/s, train_loss=0.00408, val_loss=0.00417]Epoch 36:  65%|██████▌   | 13/20 [00:00<00:00, 16.78it/s, train_loss=0.004, val_loss=0.00417]  Epoch 36:  70%|███████   | 14/20 [00:00<00:00, 16.54it/s, train_loss=0.004, val_loss=0.00417]Epoch 36:  70%|███████   | 14/20 [00:00<00:00, 16.41it/s, train_loss=0.00373, val_loss=0.00417]Epoch 36:  75%|███████▌  | 15/20 [00:00<00:00, 16.68it/s, train_loss=0.00373, val_loss=0.00417]Epoch 36:  75%|███████▌  | 15/20 [00:00<00:00, 16.56it/s, train_loss=0.00414, val_loss=0.00417]Epoch 36:  80%|████████  | 16/20 [00:00<00:00, 16.58it/s, train_loss=0.00414, val_loss=0.00417]Epoch 36:  80%|████████  | 16/20 [00:00<00:00, 16.51it/s, train_loss=0.00403, val_loss=0.00417]Epoch 36:  85%|████████▌ | 17/20 [00:01<00:00, 16.59it/s, train_loss=0.00403, val_loss=0.00417]Epoch 36:  85%|████████▌ | 17/20 [00:01<00:00, 16.51it/s, train_loss=0.00415, val_loss=0.00417]Epoch 36:  90%|█████████ | 18/20 [00:01<00:00, 16.54it/s, train_loss=0.00415, val_loss=0.00417]Epoch 36:  90%|█████████ | 18/20 [00:01<00:00, 16.47it/s, train_loss=0.00392, val_loss=0.00417]Epoch 36:  95%|█████████▌| 19/20 [00:01<00:00, 16.52it/s, train_loss=0.00392, val_loss=0.00417]Epoch 36:  95%|█████████▌| 19/20 [00:01<00:00, 16.42it/s, train_loss=0.00386, val_loss=0.00417]Epoch 36: 100%|██████████| 20/20 [00:01<00:00, 16.60it/s, train_loss=0.00386, val_loss=0.00417]Epoch 36: 100%|██████████| 20/20 [00:01<00:00, 16.54it/s, train_loss=0.00397, val_loss=0.00417]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 49.23it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 42.68it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 40.15it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 37.26it/s][A
                                                                      [AEpoch 36: 100%|██████████| 20/20 [00:01<00:00, 15.05it/s, train_loss=0.00397, val_loss=0.00415]Epoch 36: 100%|██████████| 20/20 [00:01<00:00, 15.02it/s, train_loss=0.00397, val_loss=0.00415]Epoch 36:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00397, val_loss=0.00415]         Epoch 37:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00397, val_loss=0.00415]Epoch 37:   5%|▌         | 1/20 [00:00<00:00, 20.82it/s, train_loss=0.00397, val_loss=0.00415]Epoch 37:   5%|▌         | 1/20 [00:00<00:01, 17.88it/s, train_loss=0.00376, val_loss=0.00415]Epoch 37:  10%|█         | 2/20 [00:00<00:00, 19.33it/s, train_loss=0.00376, val_loss=0.00415]Epoch 37:  10%|█         | 2/20 [00:00<00:01, 17.45it/s, train_loss=0.00381, val_loss=0.00415]Epoch 37:  15%|█▌        | 3/20 [00:00<00:00, 17.03it/s, train_loss=0.00381, val_loss=0.00415]Epoch 37:  15%|█▌        | 3/20 [00:00<00:01, 16.89it/s, train_loss=0.00387, val_loss=0.00415]Epoch 37:  20%|██        | 4/20 [00:00<00:00, 16.97it/s, train_loss=0.00387, val_loss=0.00415]Epoch 37:  20%|██        | 4/20 [00:00<00:00, 16.54it/s, train_loss=0.00384, val_loss=0.00415]Epoch 37:  25%|██▌       | 5/20 [00:00<00:00, 16.86it/s, train_loss=0.00384, val_loss=0.00415]Epoch 37:  25%|██▌       | 5/20 [00:00<00:00, 16.69it/s, train_loss=0.00376, val_loss=0.00415]Epoch 37:  30%|███       | 6/20 [00:00<00:00, 17.06it/s, train_loss=0.00376, val_loss=0.00415]Epoch 37:  30%|███       | 6/20 [00:00<00:00, 16.77it/s, train_loss=0.00382, val_loss=0.00415]Epoch 37:  35%|███▌      | 7/20 [00:00<00:00, 17.62it/s, train_loss=0.00382, val_loss=0.00415]Epoch 37:  35%|███▌      | 7/20 [00:00<00:00, 17.30it/s, train_loss=0.00389, val_loss=0.00415]Epoch 37:  40%|████      | 8/20 [00:00<00:00, 18.08it/s, train_loss=0.00389, val_loss=0.00415]Epoch 37:  40%|████      | 8/20 [00:00<00:00, 17.78it/s, train_loss=0.00393, val_loss=0.00415]Epoch 37:  45%|████▌     | 9/20 [00:00<00:00, 17.43it/s, train_loss=0.00393, val_loss=0.00415]Epoch 37:  45%|████▌     | 9/20 [00:00<00:00, 17.24it/s, train_loss=0.00396, val_loss=0.00415]Epoch 37:  50%|█████     | 10/20 [00:00<00:00, 17.52it/s, train_loss=0.00396, val_loss=0.00415]Epoch 37:  50%|█████     | 10/20 [00:00<00:00, 17.43it/s, train_loss=0.0042, val_loss=0.00415] Epoch 37:  55%|█████▌    | 11/20 [00:00<00:00, 17.26it/s, train_loss=0.0042, val_loss=0.00415]Epoch 37:  55%|█████▌    | 11/20 [00:00<00:00, 17.12it/s, train_loss=0.00411, val_loss=0.00415]Epoch 37:  60%|██████    | 12/20 [00:00<00:00, 17.32it/s, train_loss=0.00411, val_loss=0.00415]Epoch 37:  60%|██████    | 12/20 [00:00<00:00, 17.19it/s, train_loss=0.00428, val_loss=0.00415]Epoch 37:  65%|██████▌   | 13/20 [00:00<00:00, 17.10it/s, train_loss=0.00428, val_loss=0.00415]Epoch 37:  65%|██████▌   | 13/20 [00:00<00:00, 16.90it/s, train_loss=0.00394, val_loss=0.00415]Epoch 37:  70%|███████   | 14/20 [00:00<00:00, 16.98it/s, train_loss=0.00394, val_loss=0.00415]Epoch 37:  70%|███████   | 14/20 [00:00<00:00, 16.79it/s, train_loss=0.00369, val_loss=0.00415]Epoch 37:  75%|███████▌  | 15/20 [00:00<00:00, 17.04it/s, train_loss=0.00369, val_loss=0.00415]Epoch 37:  75%|███████▌  | 15/20 [00:00<00:00, 16.91it/s, train_loss=0.00418, val_loss=0.00415]Epoch 37:  80%|████████  | 16/20 [00:00<00:00, 17.02it/s, train_loss=0.00418, val_loss=0.00415]Epoch 37:  80%|████████  | 16/20 [00:00<00:00, 16.89it/s, train_loss=0.00404, val_loss=0.00415]Epoch 37:  85%|████████▌ | 17/20 [00:01<00:00, 16.96it/s, train_loss=0.00404, val_loss=0.00415]Epoch 37:  85%|████████▌ | 17/20 [00:01<00:00, 16.84it/s, train_loss=0.00413, val_loss=0.00415]Epoch 37:  90%|█████████ | 18/20 [00:01<00:00, 16.96it/s, train_loss=0.00413, val_loss=0.00415]Epoch 37:  90%|█████████ | 18/20 [00:01<00:00, 16.82it/s, train_loss=0.00379, val_loss=0.00415]Epoch 37:  95%|█████████▌| 19/20 [00:01<00:00, 16.94it/s, train_loss=0.00379, val_loss=0.00415]Epoch 37:  95%|█████████▌| 19/20 [00:01<00:00, 16.82it/s, train_loss=0.00394, val_loss=0.00415]Epoch 37: 100%|██████████| 20/20 [00:01<00:00, 16.87it/s, train_loss=0.00394, val_loss=0.00415]Epoch 37: 100%|██████████| 20/20 [00:01<00:00, 16.80it/s, train_loss=0.00392, val_loss=0.00415]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 43.73it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 40.95it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 45.94it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.69it/s][A
                                                                      [AEpoch 37: 100%|██████████| 20/20 [00:01<00:00, 15.49it/s, train_loss=0.00392, val_loss=0.00414]Epoch 37: 100%|██████████| 20/20 [00:01<00:00, 15.46it/s, train_loss=0.00392, val_loss=0.00414]Epoch 37:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00392, val_loss=0.00414]         Epoch 38:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00392, val_loss=0.00414]Epoch 38:   5%|▌         | 1/20 [00:00<00:00, 20.93it/s, train_loss=0.00392, val_loss=0.00414]Epoch 38:   5%|▌         | 1/20 [00:00<00:01, 17.79it/s, train_loss=0.00383, val_loss=0.00414]Epoch 38:  10%|█         | 2/20 [00:00<00:00, 20.81it/s, train_loss=0.00383, val_loss=0.00414]Epoch 38:  10%|█         | 2/20 [00:00<00:00, 19.22it/s, train_loss=0.00401, val_loss=0.00414]Epoch 38:  15%|█▌        | 3/20 [00:00<00:00, 22.56it/s, train_loss=0.00401, val_loss=0.00414]Epoch 38:  15%|█▌        | 3/20 [00:00<00:00, 20.33it/s, train_loss=0.00388, val_loss=0.00414]Epoch 38:  20%|██        | 4/20 [00:00<00:00, 18.79it/s, train_loss=0.00388, val_loss=0.00414]Epoch 38:  20%|██        | 4/20 [00:00<00:00, 18.35it/s, train_loss=0.00395, val_loss=0.00414]Epoch 38:  25%|██▌       | 5/20 [00:00<00:00, 18.44it/s, train_loss=0.00395, val_loss=0.00414]Epoch 38:  25%|██▌       | 5/20 [00:00<00:00, 18.02it/s, train_loss=0.00407, val_loss=0.00414]Epoch 38:  30%|███       | 6/20 [00:00<00:00, 18.02it/s, train_loss=0.00407, val_loss=0.00414]Epoch 38:  30%|███       | 6/20 [00:00<00:00, 17.62it/s, train_loss=0.00403, val_loss=0.00414]Epoch 38:  35%|███▌      | 7/20 [00:00<00:00, 17.82it/s, train_loss=0.00403, val_loss=0.00414]Epoch 38:  35%|███▌      | 7/20 [00:00<00:00, 17.42it/s, train_loss=0.00396, val_loss=0.00414]Epoch 38:  40%|████      | 8/20 [00:00<00:00, 16.98it/s, train_loss=0.00396, val_loss=0.00414]Epoch 38:  40%|████      | 8/20 [00:00<00:00, 16.76it/s, train_loss=0.00395, val_loss=0.00414]Epoch 38:  45%|████▌     | 9/20 [00:00<00:00, 17.18it/s, train_loss=0.00395, val_loss=0.00414]Epoch 38:  45%|████▌     | 9/20 [00:00<00:00, 16.97it/s, train_loss=0.00365, val_loss=0.00414]Epoch 38:  50%|█████     | 10/20 [00:00<00:00, 17.37it/s, train_loss=0.00365, val_loss=0.00414]Epoch 38:  50%|█████     | 10/20 [00:00<00:00, 17.19it/s, train_loss=0.00373, val_loss=0.00414]Epoch 38:  55%|█████▌    | 11/20 [00:00<00:00, 17.76it/s, train_loss=0.00373, val_loss=0.00414]Epoch 38:  55%|█████▌    | 11/20 [00:00<00:00, 17.54it/s, train_loss=0.00388, val_loss=0.00414]Epoch 38:  60%|██████    | 12/20 [00:00<00:00, 17.23it/s, train_loss=0.00388, val_loss=0.00414]Epoch 38:  60%|██████    | 12/20 [00:00<00:00, 16.98it/s, train_loss=0.00399, val_loss=0.00414]Epoch 38:  65%|██████▌   | 13/20 [00:00<00:00, 17.24it/s, train_loss=0.00399, val_loss=0.00414]Epoch 38:  65%|██████▌   | 13/20 [00:00<00:00, 17.04it/s, train_loss=0.00414, val_loss=0.00414]Epoch 38:  70%|███████   | 14/20 [00:00<00:00, 17.29it/s, train_loss=0.00414, val_loss=0.00414]Epoch 38:  70%|███████   | 14/20 [00:00<00:00, 17.15it/s, train_loss=0.00399, val_loss=0.00414]Epoch 38:  75%|███████▌  | 15/20 [00:00<00:00, 17.41it/s, train_loss=0.00399, val_loss=0.00414]Epoch 38:  75%|███████▌  | 15/20 [00:00<00:00, 17.28it/s, train_loss=0.00403, val_loss=0.00414]Epoch 38:  80%|████████  | 16/20 [00:00<00:00, 17.19it/s, train_loss=0.00403, val_loss=0.00414]Epoch 38:  80%|████████  | 16/20 [00:00<00:00, 17.09it/s, train_loss=0.00392, val_loss=0.00414]Epoch 38:  85%|████████▌ | 17/20 [00:00<00:00, 17.13it/s, train_loss=0.00392, val_loss=0.00414]Epoch 38:  85%|████████▌ | 17/20 [00:00<00:00, 17.04it/s, train_loss=0.00383, val_loss=0.00414]Epoch 38:  90%|█████████ | 18/20 [00:01<00:00, 16.89it/s, train_loss=0.00383, val_loss=0.00414]Epoch 38:  90%|█████████ | 18/20 [00:01<00:00, 16.80it/s, train_loss=0.00388, val_loss=0.00414]Epoch 38:  95%|█████████▌| 19/20 [00:01<00:00, 17.07it/s, train_loss=0.00388, val_loss=0.00414]Epoch 38:  95%|█████████▌| 19/20 [00:01<00:00, 16.97it/s, train_loss=0.00402, val_loss=0.00414]Epoch 38: 100%|██████████| 20/20 [00:01<00:00, 17.28it/s, train_loss=0.00402, val_loss=0.00414]Epoch 38: 100%|██████████| 20/20 [00:01<00:00, 17.16it/s, train_loss=0.00386, val_loss=0.00414]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 27.78it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 32.02it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 36.11it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 37.90it/s][A
                                                                      [AEpoch 38: 100%|██████████| 20/20 [00:01<00:00, 15.48it/s, train_loss=0.00386, val_loss=0.00414]Epoch 38: 100%|██████████| 20/20 [00:01<00:00, 15.47it/s, train_loss=0.00386, val_loss=0.00414]Epoch 38:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00386, val_loss=0.00414]         Epoch 39:   0%|          | 0/20 [00:00<?, ?it/s, train_loss=0.00386, val_loss=0.00414]Epoch 39:   5%|▌         | 1/20 [00:00<00:01, 17.31it/s, train_loss=0.00386, val_loss=0.00414]Epoch 39:   5%|▌         | 1/20 [00:00<00:01, 15.94it/s, train_loss=0.0039, val_loss=0.00414] Epoch 39:  10%|█         | 2/20 [00:00<00:01, 17.74it/s, train_loss=0.0039, val_loss=0.00414]Epoch 39:  10%|█         | 2/20 [00:00<00:01, 16.81it/s, train_loss=0.00372, val_loss=0.00414]Epoch 39:  15%|█▌        | 3/20 [00:00<00:01, 15.05it/s, train_loss=0.00372, val_loss=0.00414]Epoch 39:  15%|█▌        | 3/20 [00:00<00:01, 14.58it/s, train_loss=0.00402, val_loss=0.00414]Epoch 39:  20%|██        | 4/20 [00:00<00:01, 15.07it/s, train_loss=0.00402, val_loss=0.00414]Epoch 39:  20%|██        | 4/20 [00:00<00:01, 14.78it/s, train_loss=0.00407, val_loss=0.00414]Epoch 39:  25%|██▌       | 5/20 [00:00<00:00, 15.11it/s, train_loss=0.00407, val_loss=0.00414]Epoch 39:  25%|██▌       | 5/20 [00:00<00:01, 14.81it/s, train_loss=0.00389, val_loss=0.00414]Epoch 39:  30%|███       | 6/20 [00:00<00:00, 14.99it/s, train_loss=0.00389, val_loss=0.00414]Epoch 39:  30%|███       | 6/20 [00:00<00:00, 14.66it/s, train_loss=0.00412, val_loss=0.00414]Epoch 39:  35%|███▌      | 7/20 [00:00<00:00, 15.21it/s, train_loss=0.00412, val_loss=0.00414]Epoch 39:  35%|███▌      | 7/20 [00:00<00:00, 15.00it/s, train_loss=0.00401, val_loss=0.00414]Epoch 39:  40%|████      | 8/20 [00:00<00:00, 15.66it/s, train_loss=0.00401, val_loss=0.00414]Epoch 39:  40%|████      | 8/20 [00:00<00:00, 15.47it/s, train_loss=0.00405, val_loss=0.00414]Epoch 39:  45%|████▌     | 9/20 [00:00<00:00, 15.92it/s, train_loss=0.00405, val_loss=0.00414]Epoch 39:  45%|████▌     | 9/20 [00:00<00:00, 15.73it/s, train_loss=0.0039, val_loss=0.00414] Epoch 39:  50%|█████     | 10/20 [00:00<00:00, 15.88it/s, train_loss=0.0039, val_loss=0.00414]Epoch 39:  50%|█████     | 10/20 [00:00<00:00, 15.76it/s, train_loss=0.00409, val_loss=0.00414]Epoch 39:  55%|█████▌    | 11/20 [00:00<00:00, 15.81it/s, train_loss=0.00409, val_loss=0.00414]Epoch 39:  55%|█████▌    | 11/20 [00:00<00:00, 15.64it/s, train_loss=0.004, val_loss=0.00414]  Epoch 39:  60%|██████    | 12/20 [00:00<00:00, 15.83it/s, train_loss=0.004, val_loss=0.00414]Epoch 39:  60%|██████    | 12/20 [00:00<00:00, 15.65it/s, train_loss=0.00401, val_loss=0.00414]Epoch 39:  65%|██████▌   | 13/20 [00:00<00:00, 16.00it/s, train_loss=0.00401, val_loss=0.00414]Epoch 39:  65%|██████▌   | 13/20 [00:00<00:00, 15.85it/s, train_loss=0.00388, val_loss=0.00414]Epoch 39:  70%|███████   | 14/20 [00:00<00:00, 16.43it/s, train_loss=0.00388, val_loss=0.00414]Epoch 39:  70%|███████   | 14/20 [00:00<00:00, 16.25it/s, train_loss=0.00396, val_loss=0.00414]Epoch 39:  75%|███████▌  | 15/20 [00:00<00:00, 16.04it/s, train_loss=0.00396, val_loss=0.00414]Epoch 39:  75%|███████▌  | 15/20 [00:00<00:00, 16.01it/s, train_loss=0.00418, val_loss=0.00414]Epoch 39:  80%|████████  | 16/20 [00:00<00:00, 16.28it/s, train_loss=0.00418, val_loss=0.00414]Epoch 39:  80%|████████  | 16/20 [00:00<00:00, 16.17it/s, train_loss=0.00369, val_loss=0.00414]Epoch 39:  85%|████████▌ | 17/20 [00:01<00:00, 16.13it/s, train_loss=0.00369, val_loss=0.00414]Epoch 39:  85%|████████▌ | 17/20 [00:01<00:00, 16.08it/s, train_loss=0.00414, val_loss=0.00414]Epoch 39:  90%|█████████ | 18/20 [00:01<00:00, 16.23it/s, train_loss=0.00414, val_loss=0.00414]Epoch 39:  90%|█████████ | 18/20 [00:01<00:00, 16.10it/s, train_loss=0.00395, val_loss=0.00414]Epoch 39:  95%|█████████▌| 19/20 [00:01<00:00, 16.13it/s, train_loss=0.00395, val_loss=0.00414]Epoch 39:  95%|█████████▌| 19/20 [00:01<00:00, 16.09it/s, train_loss=0.00379, val_loss=0.00414]Epoch 39: 100%|██████████| 20/20 [00:01<00:00, 16.19it/s, train_loss=0.00379, val_loss=0.00414]Epoch 39: 100%|██████████| 20/20 [00:01<00:00, 16.12it/s, train_loss=0.00416, val_loss=0.00414]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s][A
Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:00, 47.65it/s][A
Validation DataLoader 0:  50%|█████     | 2/4 [00:00<00:00, 42.26it/s][A
Validation DataLoader 0:  75%|███████▌  | 3/4 [00:00<00:00, 42.15it/s][A
Validation DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 40.02it/s][A
                                                                      [AEpoch 39: 100%|██████████| 20/20 [00:01<00:00, 14.79it/s, train_loss=0.00416, val_loss=0.00414]Epoch 39: 100%|██████████| 20/20 [00:01<00:00, 14.76it/s, train_loss=0.00416, val_loss=0.00414]`Trainer.fit` stopped: `max_epochs=40` reached.
Epoch 39: 100%|██████████| 20/20 [00:01<00:00, 14.68it/s, train_loss=0.00416, val_loss=0.00414]GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/22 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s]Predicting DataLoader 0:   5%|▍         | 1/22 [00:00<00:00, 48.98it/s]Predicting DataLoader 0:   9%|▉         | 2/22 [00:00<00:00, 46.21it/s]Predicting DataLoader 0:  14%|█▎        | 3/22 [00:00<00:00, 41.71it/s]Predicting DataLoader 0:  18%|█▊        | 4/22 [00:00<00:00, 40.57it/s]Predicting DataLoader 0:  23%|██▎       | 5/22 [00:00<00:00, 40.51it/s]Predicting DataLoader 0:  27%|██▋       | 6/22 [00:00<00:00, 39.85it/s]Predicting DataLoader 0:  32%|███▏      | 7/22 [00:00<00:00, 39.23it/s]Predicting DataLoader 0:  36%|███▋      | 8/22 [00:00<00:00, 39.30it/s]Predicting DataLoader 0:  41%|████      | 9/22 [00:00<00:00, 39.16it/s]Predicting DataLoader 0:  45%|████▌     | 10/22 [00:00<00:00, 38.41it/s]Predicting DataLoader 0:  50%|█████     | 11/22 [00:00<00:00, 35.47it/s]Predicting DataLoader 0:  55%|█████▍    | 12/22 [00:00<00:00, 34.77it/s]Predicting DataLoader 0:  59%|█████▉    | 13/22 [00:00<00:00, 34.41it/s]Predicting DataLoader 0:  64%|██████▎   | 14/22 [00:00<00:00, 34.69it/s]Predicting DataLoader 0:  68%|██████▊   | 15/22 [00:00<00:00, 35.28it/s]Predicting DataLoader 0:  73%|███████▎  | 16/22 [00:00<00:00, 35.55it/s]Predicting DataLoader 0:  77%|███████▋  | 17/22 [00:00<00:00, 34.81it/s]Predicting DataLoader 0:  82%|████████▏ | 18/22 [00:00<00:00, 34.61it/s]Predicting DataLoader 0:  86%|████████▋ | 19/22 [00:00<00:00, 34.48it/s]Predicting DataLoader 0:  91%|█████████ | 20/22 [00:00<00:00, 34.21it/s]Predicting DataLoader 0:  95%|█████████▌| 21/22 [00:00<00:00, 33.85it/s]Predicting DataLoader 0: 100%|██████████| 22/22 [00:00<00:00, 33.59it/s]Predicting DataLoader 0: 100%|██████████| 22/22 [00:00<00:00, 33.52it/s]
                     observed  ...  mercedes_level_160_30
dt                             ...                       
2018-08-08 07:00:00      1.36  ...                    NaN
2018-08-09 07:00:00      1.55  ...                    NaN
2018-08-10 07:00:00      2.05  ...                    NaN
2018-08-11 07:00:00      1.85  ...                    NaN
2018-08-12 07:00:00      1.95  ...                    NaN
...                       ...  ...                    ...
2020-12-27 07:00:00      0.65  ...               1.638248
2020-12-28 07:00:00      0.80  ...               1.657550
2020-12-29 07:00:00      1.00  ...               1.647142
2020-12-30 07:00:00      0.50  ...               1.648767
2020-12-31 07:00:00      0.75  ...               1.659778

[877 rows x 13 columns]
